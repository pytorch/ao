name: Run Float8 Tests

on:
  push:
    branches:
      - main
      - 'gh/**'
  pull_request:
    branches:
      - main
      - 'gh/**'

concurrency:
  group: float8_test-${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}

jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: SM-89
            runs-on: linux.g6.4xlarge.experimental.nvidia.gpu
            torch-spec: '--pre torch --index-url https://download.pytorch.org/whl/nightly/cu126'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.6"
          - name: H100
            runs-on: linux.aws.h100.4
            torch-spec: '--pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.4"
    permissions:
      id-token: write
      contents: read
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      timeout: 60
      runner: ${{ matrix.runs-on }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      submodules: recursive
      script: |
        conda create -n venv python=3.9 -y
        conda activate venv
        export PATH=/opt/rh/devtoolset-10/root/usr/bin/:$PATH
        python -m pip install --upgrade pip
        pip install uv
        pip install ${{ matrix.torch-spec }}
        uv pip install -r dev-requirements.txt
        uv pip install vllm
        pip install .
        pytest test/float8 --verbose -s
        pytest test/integration --verbose -s
        pytest test/dtypes/test_affine_quantized_float.py --verbose -s
        GPU_COUNT=$(nvidia-smi -L 2>/dev/null | wc -l)
        if [ "$GPU_COUNT" -ge 4 ]; then
            echo "Found $GPU_COUNT GPUs - running test_everything.sh"
            ./test/float8/test_everything.sh
        else
            echo "Only $GPU_COUNT GPUs available. Need at least 4 GPUs to run test_everything.sh"
            exit 0
        fi
