name: Run 1xH100 Tests

on:
  push:
    branches:
      - main
      - 'gh/**'
  pull_request:
    branches:
      - main
      - 'gh/**'

concurrency:
  group: 1xH100_tests-${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}

jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: H100
            runs-on: linux.aws.h100
            torch-spec: '--pre torch torchvision torchaudio fbgemm-gpu-genai --index-url https://download.pytorch.org/whl/nightly/cu126'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.4"
    permissions:
      id-token: write
      contents: read
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      timeout: 90
      runner: ${{ matrix.runs-on }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      submodules: recursive
      script: |
        conda create -n venv python=3.9 -y
        conda activate venv
        export PATH=/opt/rh/devtoolset-10/root/usr/bin/:$PATH
        python -m pip install --upgrade pip
        pip install uv
        pip install ${{ matrix.torch-spec }}
        uv pip install -r dev-requirements.txt
        pip install .
        pytest test/integration --verbose -s
        pytest test/dtypes/test_affine_quantized_float.py --verbose -s
        python test/quantization/quantize_/workflows/float8/test_float8_tensor.py
        ./test/float8/test_everything_single_gpu.sh
        pytest test/prototype/mx_formats/ -s
