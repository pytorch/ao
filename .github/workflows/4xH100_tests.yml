name: Run 4xH100 tests

on:
  push:
    branches:
      - main
      - 'gh/**'
  pull_request:
    branches:
      - main
      - 'gh/**'

concurrency:
  group: 4xH100_tests-${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}

jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: H100
            runs-on: linux.aws.h100.4
            torch-spec: '--pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.4"
    permissions:
      id-token: write
      contents: read
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      timeout: 60
      runner: ${{ matrix.runs-on }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      submodules: recursive
      script: |
        conda create -n venv python=3.9 -y
        conda activate venv
        export PATH=/opt/rh/devtoolset-10/root/usr/bin/:$PATH
        python -m pip install --upgrade pip
        pip install uv
        pip install ${{ matrix.torch-spec }}
        uv pip install -r dev-requirements.txt
        uv pip install vllm
        pip install .
        ./test/float8/test_everything_multi_gpu.sh
