# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

"""
Tests for the _pack_embedding_Xbit ops.

These tests verify that the packing kernels produce output matching
the source of truth from ARM machines on some arbitrary inputs.
"""

import unittest

import torch


def create_weights(
    bit_width: int, num_embeddings: int, embedding_dim: int
) -> torch.Tensor:
    """
    Create quantized weights for testing.

    Uses a simple pattern: each element is (row + col) mod (max_val + 1).

    Args:
        bit_width: Number of bits per weight (1-8)
        num_embeddings: Number of embedding vectors
        embedding_dim: Dimension of each embedding vector

    Returns:
        Tensor of shape (num_embeddings, embedding_dim) with dtype torch.int8
    """
    max_val = (1 << bit_width) - 1
    weight_qvals = torch.zeros((num_embeddings, embedding_dim), dtype=torch.int8)

    for i in range(num_embeddings):
        for j in range(embedding_dim):
            weight_qvals[i, j] = (i + j) % (max_val + 1)

    return weight_qvals


# Expected packed tensor sizes from ARM source of truth
# Formula: header_size + (num_embeddings * embedding_dim * bit_width / 8)
#        = 64 + (16 * 64 * bit_width / 8) = 64 + (128 * bit_width)
EXPECTED_SIZES = {
    1: 192,
    2: 320,
    3: 448,
    4: 576,
    5: 704,
    6: 832,
    7: 960,
}

# Expected header format (first 64 bytes) from ARM source of truth
# Format: [magic(6712), type(2), version(1), bit_width, min_chunk(32), max_chunk(128), zeros...]
EXPECTED_HEADER_TEMPLATE = [
    56,
    26,
    0,
    0,  # magic = 6712 (0x1a38) little-endian
    2,
    0,
    0,
    0,  # type = 2 (embedding_xbit_universal)
    1,
    0,
    0,
    0,  # version = 1
    0,
    0,
    0,
    0,  # bit_width (placeholder, index 12)
    32,
    0,
    0,
    0,  # min_value_chunk_size = 32
    -128,
    0,
    0,
    0,  # max_value_chunk_size = 128 (as int8: -128)
    0,
    0,
    0,
    0,  # padding
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
]

# Expected packed tensor outputs from ARM source of truth
# Generated using deterministic inputs: weight[i,j] = (i + j) % (2^bit_width)
# fmt: off
EXPECTED_PACKED_TENSORS = {
    1: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1, -1, -18, -1, -18, -1, -18, -1, -18, -18, -1, -18, -1, -18, -1, -18, -1],
    2: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84, 85, -86, -1, 84],
    3: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, -28, -19, -10, -1, 8, 9, 26, 27, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, -19, -10, -1, 8, 9, 26, 27, -28, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -10, -1, 8, 9, 26, 27, -28, -19, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, -1, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, -1, 8, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, 26, 27, -28, -19, -10, -1, 8, 9, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, 27, -28, -19, -10, -1, 8, 9, 26, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, -28, -19, -10, -1, 8, 9, 26, 27, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, -19, -10, -1, 8, 9, 26, 27, -28, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -10, -1, 8, 9, 26, 27, -28, -19, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, -1, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 9, 26, 27, -28, -19, -10, -1, 8, -102, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, 26, 27, -28, -19, -10, -1, 8, 9, -37, 36, 109, -74, -1, 8, 73, -102, -37, 36, 109, -74, -1, 8, 73, -102, 27, -28, -19, -10, -1, 8, 9, 26],
    4:  [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118, 119, -120, -103, -86, -69, -52, -35, -18, -1, 16, 17, 50, 51, 84, 85, 118],
    5: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 49, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 16, 49, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 84, 84, 84, 84, 84, 84, 84, 84, 49, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 49, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 84, 84, 84, 84, 84, 84, 84, -35, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 82, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 84, 84, 84, 84, 84, 84, -35, -35, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 115, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 84, 84, 84, 84, 84, -35, -35, -35, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -108, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, 84, 84, 84, 84, -35, -35, -35, -35, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -75, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, 84, 84, 84, -35, -35, -35, -35, -35, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -42, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, 84, 84, -35, -35, -35, -35, -35, -35, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -9, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, 84, -35, -35, -35, -35, -35, -35, -35, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 24, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, -35, -35, -35, -35, -35, -35, -35, -35, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 57, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, -35, -35, -35, -35, -35, -35, -35, -18, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 90, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, -35, -35, -35, -35, -35, -35, -18, -18, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 123, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, -35, -35, -35, -35, -35, -18, -18, -18, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -100, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -35, -35, -35, -35, -18, -18, -18, -18, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -67, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -35, -35, -35, -18, -18, -18, -18, -18, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -83, -34, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -83, -35, -35, -18, -18, -18, -18, -18, -18, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -83, -18, -1, 32, 33, 98, 99, -92, -91, -26, -25, 40, 41, 106, 107, -84, -83, -18, -35, -18, -18, -18, -18, -18, -18, -18],
    6: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 6, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 97, -94, -29, 36, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 49, 50, 51, 116, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 97, -94, -29, 36, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 49, 50, 51, 116, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -94, -29, 36, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, 50, 51, 116, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -29, 36, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, 51, 116, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, 36, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 116, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, 101, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -90, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, 118, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -25, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, 119, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, 40, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, -72, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, 105, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, -71, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, 73, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -86, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, 74, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -21, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -69, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, -54, 75, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, 44, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -5, -4, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, -54, -53, 76, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, 109, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -5, 60, -3, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, -54, -53, -52, 77, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -82, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -5, 60, 125, -2, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, -54, -53, -52, -51, 78, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -17, 48, 113, -78, -13, 52, 117, -74, -9, 56, 121, -70, -5, 60, 125, -66, -1, 64, 65, 66, 67, 68, 69, 70, 71, -56, -55, -54, -53, -52, -51, -50, 79, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34],
    7: [56, 26, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 32, 0, 0, 0, -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, -63, 66, -61, 68, -59, 70, -57, 72, 73, -54, -53, 76, 77, -50, -49, 80, 81, 82, 83, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -63, 66, -61, 68, -59, 70, -57, 72, 73, -54, -53, 76, 77, -50, -49, 80, 81, 82, 83, -44, -43, -42, -41, 88, -39, -38, -37, -36, -35, -34, -33, 96, -31, -30, -29, -28, -27, -26, -25, 104, -23, -22, -21, -20, -19, -18, -17, 112, -15, -14, -13, -12, -11, -10, -9, 120, 66, -61, 68, -59, 70, -57, 72, -55, -54, -53, 76, 77, -50, -49, 80, 81, 82, 83, -44, -43, -42, -41, 88, 89, -38, -37, -36, -35, -34, -33, 96, 97, -30, -29, -28, -27, -26, -25, 104, 105, -22, -21, -20, -19, -18, -17, 112, 113, -14, -13, -12, -11, -10, -9, 120, 121, -61, 68, -59, 70, -57, 72, -55, 74, -53, 76, 77, -50, -49, 80, 81, -46, 83, -44, -43, -42, -41, 88, 89, 90, -37, -36, -35, -34, -33, 96, 97, 98, -29, -28, -27, -26, -25, 104, 105, 106, -21, -20, -19, -18, -17, 112, 113, 114, -13, -12, -11, -10, -9, 120, 121, 122, 68, -59, 70, -57, 72, -55, 74, -53, 76, 77, -50, -49, 80, 81, -46, -45, -44, -43, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, -28, -27, -26, -25, 104, 105, 106, 107, -20, -19, -18, -17, 112, 113, 114, 115, -12, -11, -10, -9, 120, 121, 122, 123, -59, 70, -57, 72, -55, 74, -53, 76, 77, -50, -49, 80, 81, -46, -45, 84, -43, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, -27, -26, -25, 104, 105, 106, 107, 108, -19, -18, -17, 112, 113, 114, 115, 116, -11, -10, -9, 120, 121, 122, 123, 124, 70, -57, 72, -55, 74, -53, 76, -51, -50, -49, 80, 81, -46, -45, 84, 85, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, -26, -25, 104, 105, 106, 107, 108, 109, -18, -17, 112, 113, 114, 115, 116, 117, -10, -9, 120, 121, 122, 123, 124, 125, -57, 72, -55, 74, -53, 76, -51, 78, -49, 80, 81, -46, -45, 84, 85, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, -25, 104, 105, 106, 107, 108, 109, 110, -17, 112, 113, 114, 115, 116, 117, 118, -9, 120, 121, 122, 123, 124, 125, 126, 72, -55, 74, -53, 76, -51, 78, -49, 80, 81, -46, -45, 84, 85, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, -55, 74, -53, 76, -51, 78, -49, 80, 81, -46, -45, 84, 85, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, 103, -24, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 74, -53, 76, -51, 78, -49, 80, -47, -46, -45, 84, 85, -42, -41, 88, 89, 90, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, 103, -24, -23, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, -53, 76, -51, 78, -49, 80, -47, 82, -45, 84, 85, -42, -41, 88, 89, -38, 91, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, 103, -24, -23, -22, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, 2, 76, -51, 78, -49, 80, -47, 82, -45, 84, 85, -42, -41, 88, 89, -38, -37, -36, -35, -34, -33, 96, 97, 98, 99, 100, 101, 102, 103, -24, -23, -22, -21, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, 2, 3, -51, 78, -49, 80, -47, 82, -45, 84, 85, -42, -41, 88, 89, -38, -37, 92, -35, -34, -33, 96, 97, 98, 99, -28, 101, 102, 103, -24, -23, -22, -21, -20, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, 2, 3, 4, 78, -49, 80, -47, 82, -45, 84, -43, -42, -41, 88, 89, -38, -37, 92, 93, -34, -33, 96, 97, 98, 99, -28, -27, 102, 103, -24, -23, -22, -21, -20, -19, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, 2, 3, 4, 5, -49, 80, -47, 82, -45, 84, -43, 86, -41, 88, 89, -38, -37, 92, 93, -34, -33, 96, 97, 98, 99, -28, -27, -26, 103, -24, -23, -22, -21, -20, -19, -18, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 0, 1, 2, 3, 4, 5, 6]
}
# fmt: on


class TestPackEmbedding(unittest.TestCase):
    """Tests for the _pack_embedding_Xbit ops."""

    def test_pack_embedding_size_and_header(self) -> None:
        """Test that packed weights have correct size and header format.

        This test verifies:
        1. Output is a 1D int8 tensor
        2. Size matches expected: 64 + (16 * 64 * bit_width / 8)
        3. Header (first 64 bytes) matches expected format
        """
        num_embeddings = 16
        embedding_dim = 64

        for bit_width in range(1, 8):
            with self.subTest(bit_width=bit_width):
                weight_qvals = create_weights(bit_width, num_embeddings, embedding_dim)

                pack_op = getattr(torch.ops.torchao, f"_pack_embedding_{bit_width}bit")
                packed_weights = pack_op(weight_qvals)

                self.assertEqual(packed_weights.dim(), 1)
                self.assertEqual(packed_weights.dtype, torch.int8)

                expected_size = EXPECTED_SIZES[bit_width]
                self.assertEqual(
                    packed_weights.numel(),
                    expected_size,
                    f"Size mismatch for {bit_width}-bit: expected {expected_size}, got {packed_weights.numel()}",
                )

                expected_header = EXPECTED_HEADER_TEMPLATE.copy()
                expected_header[12] = bit_width

                actual_header = packed_weights[:64].tolist()
                self.assertEqual(
                    actual_header,
                    expected_header,
                    f"Header mismatch for {bit_width}-bit",
                )

    def test_pack_embedding_matches_arm_output(self) -> None:
        """Test that packed weights exactly match ARM source of truth output.

        Uses deterministic inputs where weight[i,j] = (i + j) % (2^bit_width).
        """
        num_embeddings = 16
        embedding_dim = 64

        for bit_width in range(1, 8):
            with self.subTest(bit_width=bit_width):
                weight_qvals = create_weights(bit_width, num_embeddings, embedding_dim)

                pack_op = getattr(torch.ops.torchao, f"_pack_embedding_{bit_width}bit")
                packed_weights = pack_op(weight_qvals)

                expected = EXPECTED_PACKED_TENSORS[bit_width]

                actual = packed_weights.flatten().tolist()

                self.assertEqual(
                    actual,
                    expected,
                    f"Packed tensor mismatch for {bit_width}-bit",
                )


if __name__ == "__main__":
    unittest.main()
