{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-23:03:28:28,196 INFO     [utils.py:148] Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-06-23:03:28:28,197 INFO     [utils.py:161] NumExpr defaulting to 8 threads.\n",
      "2024-06-23:03:28:28,864 INFO     [config.py:58] PyTorch version 2.3.0 available.\n",
      "2024-06-23:03:28:28,865 INFO     [config.py:95] TensorFlow version 2.16.1 available.\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import torchao\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.sysconfig import get_python_lib\n",
    "prefix = get_python_lib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/larryliu/ao/torchao/csrc/executorch', '/Users/larryliu/miniconda3/envs/executorch/lib/python311.zip', '/Users/larryliu/miniconda3/envs/executorch/lib/python3.11', '/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/lib-dynload', '', '/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages', '__editable__.llava-1.2.2.post1.finder.__path_hook__', '/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torchao-0.3.0-py3.11-macosx-11.1-arm64.egg', '/Users/larryliu/CLionProjects/pytorch', '/Users/larryliu/ao', '/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp2gzr6njx', '/Users/larryliu/.cache/huggingface/modules']\n"
     ]
    }
   ],
   "source": [
    "import sys; print(sys.path)\n",
    "\n",
    "torch.ops.load_library(f\"{prefix}/torchao-0.3.0-py3.11-macosx-11.1-arm64.egg/torchao/libexecutorch_kernels.dylib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.extension.pybindings import portable_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::sym_size.int\n",
      "aten::_local_scalar_dense\n",
      "aten::sym_numel\n",
      "executorch_prim::add.Scalar\n",
      "executorch_prim::sub.Scalar\n",
      "executorch_prim::mul.Scalar\n",
      "executorch_prim::floordiv.Scalar\n",
      "executorch_prim::truediv.Scalar\n",
      "executorch_prim::sym_float.Scalar\n",
      "executorch_prim::eq.Scalar\n",
      "executorch_prim::gt.Scalar\n",
      "executorch_prim::lt.Scalar\n",
      "executorch_prim::ge.Scalar\n",
      "executorch_prim::le.Scalar\n",
      "executorch_prim::floordiv.int\n",
      "executorch_prim::et_copy_index.tensor\n",
      "executorch_prim::et_view.default\n",
      "aten::_cdist_forward.out\n",
      "aten::_log_softmax.out\n",
      "aten::_native_batch_norm_legit.out\n",
      "aten::_native_batch_norm_legit.no_stats_out\n",
      "aten::_native_batch_norm_legit_no_training.out\n",
      "aten::_pdist_forward.out\n",
      "aten::_softmax.out\n",
      "aten::_to_copy.out\n",
      "aten::abs.out\n",
      "aten::acos.out\n",
      "aten::acosh.out\n",
      "aten::add.out\n",
      "aten::add.Scalar_out\n",
      "aten::addmm.out\n",
      "aten::alias_copy.out\n",
      "aten::amax.out\n",
      "aten::amin.out\n",
      "aten::any.all_out\n",
      "aten::any.dims_out\n",
      "aten::any.out\n",
      "aten::arange.out\n",
      "aten::arange.start_out\n",
      "aten::argmax.out\n",
      "aten::argmin.out\n",
      "aten::as_strided_copy.out\n",
      "aten::asin.out\n",
      "aten::asinh.out\n",
      "aten::atan.out\n",
      "aten::atan2.out\n",
      "aten::atanh.out\n",
      "aten::avg_pool2d.out\n",
      "aten::bitwise_and.Scalar_out\n",
      "aten::bitwise_and.Tensor_out\n",
      "aten::bitwise_not.out\n",
      "aten::bitwise_or.Scalar_out\n",
      "aten::bitwise_or.Tensor_out\n",
      "aten::bitwise_xor.Scalar_out\n",
      "aten::bitwise_xor.Tensor_out\n",
      "aten::bmm.out\n",
      "aten::cat.out\n",
      "aten::ceil.out\n",
      "aten::clamp.out\n",
      "aten::clamp.Tensor_out\n",
      "aten::clone.out\n",
      "aten::constant_pad_nd.out\n",
      "aten::convolution.out\n",
      "aten::copy.out\n",
      "aten::copy_\n",
      "aten::cos.out\n",
      "aten::cosh.out\n",
      "aten::cumsum.out\n",
      "aten::detach_copy.out\n",
      "aten::diagonal_copy.out\n",
      "aten::div.out\n",
      "aten::div.Scalar_mode_out\n",
      "aten::div.Scalar_out\n",
      "aten::div.out_mode\n",
      "aten::embedding.out\n",
      "aten::empty.out\n",
      "aten::eq.Scalar_out\n",
      "aten::eq.Tensor_out\n",
      "aten::erf.out\n",
      "aten::exp.out\n",
      "aten::expand_copy.out\n",
      "aten::expm1.out\n",
      "aten::fill.Scalar_out\n",
      "aten::fill.Tensor_out\n",
      "aten::flip.out\n",
      "aten::floor.out\n",
      "aten::floor_divide.out\n",
      "aten::fmod.Tensor_out\n",
      "aten::fmod.Scalar_out\n",
      "aten::full.out\n",
      "aten::full_like.out\n",
      "aten::ge.Scalar_out\n",
      "aten::ge.Tensor_out\n",
      "aten::gelu.out\n",
      "aten::glu.out\n",
      "aten::gt.Scalar_out\n",
      "aten::gt.Tensor_out\n",
      "aten::hardtanh.out\n",
      "aten::index.Tensor_out\n",
      "aten::index_put.out\n",
      "aten::index_select.out\n",
      "aten::isinf.out\n",
      "aten::isnan.out\n",
      "aten::le.Scalar_out\n",
      "aten::le.Tensor_out\n",
      "aten::leaky_relu.out\n",
      "aten::lift_fresh_copy.out\n",
      "aten::log.out\n",
      "aten::log10.out\n",
      "aten::log1p.out\n",
      "aten::log2.out\n",
      "aten::logical_and.out\n",
      "aten::logical_not.out\n",
      "aten::logical_or.out\n",
      "aten::logical_xor.out\n",
      "aten::logit.out\n",
      "aten::lt.Scalar_out\n",
      "aten::lt.Tensor_out\n",
      "aten::masked_fill.Scalar_out\n",
      "aten::max.dim_max\n",
      "aten::maximum.out\n",
      "aten::max_pool2d_with_indices.out\n",
      "aten::mean.out\n",
      "aten::min.dim_min\n",
      "aten::minimum.out\n",
      "aten::mm.out\n",
      "aten::mul.out\n",
      "aten::mul.Scalar_out\n",
      "aten::native_group_norm.out\n",
      "aten::native_layer_norm.out\n",
      "aten::ne.Scalar_out\n",
      "aten::ne.Tensor_out\n",
      "aten::neg.out\n",
      "aten::nonzero.out\n",
      "aten::ones.out\n",
      "aten::permute_copy.out\n",
      "aten::pixel_shuffle.out\n",
      "aten::pow.Scalar_out\n",
      "aten::pow.Tensor_Scalar_out\n",
      "aten::pow.Tensor_Tensor_out\n",
      "aten::prod.int_out\n",
      "aten::prod.out\n",
      "aten::reciprocal.out\n",
      "aten::relu.out\n",
      "aten::remainder.Tensor_out\n",
      "aten::remainder.Scalar_out\n",
      "aten::repeat.out\n",
      "aten::reflection_pad1d.out\n",
      "aten::reflection_pad2d.out\n",
      "aten::reflection_pad3d.out\n",
      "aten::replication_pad1d.out\n",
      "aten::replication_pad2d.out\n",
      "aten::replication_pad3d.out\n",
      "aten::roll.out\n",
      "aten::round.out\n",
      "aten::rsqrt.out\n",
      "aten::rsub.Scalar_out\n",
      "aten::scalar_tensor.out\n",
      "aten::scatter_add.out\n",
      "aten::select_copy.int_out\n",
      "aten::select_scatter.out\n",
      "aten::sigmoid.out\n",
      "aten::sign.out\n",
      "aten::sin.out\n",
      "aten::sinh.out\n",
      "aten::slice_copy.Tensor_out\n",
      "aten::slice_scatter.out\n",
      "aten::split_copy.Tensor_out\n",
      "aten::split_with_sizes_copy.out\n",
      "aten::sqrt.out\n",
      "aten::squeeze_copy.dim_out\n",
      "aten::squeeze_copy.dims_out\n",
      "aten::stack.out\n",
      "aten::sub.out\n",
      "aten::sub.Scalar_out\n",
      "aten::sum.IntList_out\n",
      "aten::t_copy.out\n",
      "aten::tan.out\n",
      "aten::tanh.out\n",
      "aten::transpose_copy.int_out\n",
      "aten::tril.out\n",
      "aten::trunc.out\n",
      "aten::unbind_copy.int_out\n",
      "aten::unsqueeze_copy.out\n",
      "aten::var.correction_out\n",
      "aten::var.out\n",
      "aten::view_copy.out\n",
      "aten::where.self_out\n",
      "aten::zeros.out\n",
      "dim_order_ops::_to_dim_order_copy.out\n",
      "quantized_decomposed::add.out\n",
      "quantized_decomposed::choose_qparams.Tensor_out\n",
      "quantized_decomposed::dequantize_per_tensor.out\n",
      "quantized_decomposed::dequantize_per_tensor.Tensor_out\n",
      "quantized_decomposed::quantize_per_channel.out\n",
      "quantized_decomposed::dequantize_per_channel.out\n",
      "quantized_decomposed::embedding_byte.out\n",
      "quantized_decomposed::embedding_byte.dtype_out\n",
      "quantized_decomposed::embedding_4bit.out\n",
      "quantized_decomposed::embedding_4bit.dtype_out\n",
      "quantized_decomposed::mixed_mm.out\n",
      "quantized_decomposed::mixed_linear.out\n",
      "quantized_decomposed::quantize_per_tensor.out\n",
      "quantized_decomposed::quantize_per_tensor.Tensor_out\n",
      "torchao::int4mv.out\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(portable_lib._get_operator_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demo(torch.nn.Module):\n",
    "    def forward(self, A, B, scalesAndZeros):\n",
    "        return torch.ops.torchao.int4mv.default(A, B, 32, scalesAndZeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1\n",
    "K = 4096\n",
    "N = 4096\n",
    "A = torch.randn(M, K, device=\"mps\", dtype=torch.float16) # M x K\n",
    "B = torch.randn(N, K // 2, device=\"mps\", dtype=torch.int8) # N x K / 2\n",
    "scalesAndZeros = torch.randn(N, K // 32, 2, device=\"mps\", dtype=torch.float16) # N x K / 32 x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-555.5000,  268.7500,  210.6250,  ..., 1293.0000,  815.5000,\n",
       "          352.7500]], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = Demo()\n",
    "module.forward(A, B, scalesAndZeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir import EdgeProgramManager, ExecutorchProgramManager, to_edge, EdgeCompileConfig\n",
    "ep = torch.export.export(module, (A, B, scalesAndZeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "executorch_program = to_edge(ep, compile_config=EdgeCompileConfig(_check_ir_validity=False)).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch_from_buffer\n",
    "m = _load_for_executorch_from_buffer(executorch_program.buffer)\n",
    "out = m.forward([A.to(device=\"cpu\"), B.to(device=\"cpu\"), scalesAndZeros.to(device=\"cpu\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, a: \"f16[1, 4096]\", b: \"i8[4096, 2048]\", scalesandzeros: \"f16[4096, 128, 2]\"):\n",
      "            # No stacktrace found for following nodes\n",
      "            alloc: \"f16[1, 4096]\" = executorch_exir_memory_alloc(((1, 4096), torch.float16))\n",
      "            \n",
      "            # File: /var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/ipykernel_1029/39005463.py:3 in forward, code: return torch.ops.torchao.int4mv.default(A, B, 32, scalesAndZeros)\n",
      "            torchao_int4mv_default: \"f16[1, 4096]\" = torch.ops.torchao.int4mv.out(a, b, 32, scalesandzeros, out = alloc);  a = b = scalesandzeros = alloc = None\n",
      "            return (torchao_int4mv_default,)\n",
      "            \n",
      "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='a'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='b'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='scalesandzeros'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='torchao_int4mv_default'), target=None)])\n",
      "Range constraints: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(executorch_program.exported_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16)]\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
