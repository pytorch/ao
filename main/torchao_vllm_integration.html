

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
  <meta name="robots" content="noindex">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta property="og:title" content="Integration with VLLM: Architecture and Usage Guide" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://pytorch.org/torchao_vllm_integration.html" />
<meta property="og:site_name" content="torchao" />
<meta property="og:description" content="This tutorial provides a comprehensive overview of how TorchAO integrates with VLLM, and what needs to be implemented to have a new technique work E2E. Configuration System- 1. HuggingFace Model Co..." />
<meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
<meta property="og:image:alt" content="torchao" />
<meta name="description" content="This tutorial provides a comprehensive overview of how TorchAO integrates with VLLM, and what needs to be implemented to have a new technique work E2E. Configuration System- 1. HuggingFace Model Co..." />

    <title>Integration with VLLM: Architecture and Usage Guide &#8212; torchao main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    <link rel="canonical" href="https://pytorch.org/ao/torchao_vllm_integration.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hugging Face Integration" href="torchao_hf_integration.html" />
    <link rel="prev" title="(Part 3) Serving on vLLM, SGLang, ExecuTorch" href="serving.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="index.html" class="version">main</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick_start.html">
    Quick Start Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quantization_overview.html">
    Quantization Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="contributor_guide.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="sparsity.html">
    Sparsity Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="benchmarking_api_guide.html">
    Benchmarking API Guide
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="benchmarking_user_guide.html">
    Benchmarking User Guide
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_dtypes.html">
    torchao.dtypes
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_quantization.html">
    torchao.quantization
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_qat.html">
    torchao.quantization.qat
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_sparsity.html">
    torchao.sparsity
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_float8.html">
    torchao.float8
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="api_ref_utils.html">
    torchao.utils
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="pretraining.html">
    (Part 1) Pre-training with float8
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="finetuning.html">
    (Part 2) Fine-tuning with QAT, QLoRA, and float8
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="serving.html">
    (Part 3) Serving on vLLM, SGLang, ExecuTorch
  </a>
</li>


<li class=" current active">
  <a class="nav-link dropdown-item nav-internal" href="#">
    Integration with VLLM: Architecture and Usage Guide
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="torchao_hf_integration.html">
    Hugging Face Integration
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="serialization.html">
    Serialization
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="static_quantization.html">
    Static Quantization
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="subclass_basic.html">
    Writing Your Own Quantized Tensor
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="subclass_advanced.html">
    Writing Your Own Quantized Tensor (advanced)
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quant_ptq.html">
    PyTorch 2 Export Post Training Quantization
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quant_qat.html">
    PyTorch 2 Export Quantization-Aware Training (QAT)
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quant_x86_inductor.html">
    PyTorch 2 Export Quantization with X86 Backend through Inductor
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quant_xpu_inductor.html">
    PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quant_openvino_inductor.html">
    PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="tutorials_source/pt2e_quantizer.html">
    How to Write a Quantizer for PyTorch 2 Export Quantization
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick_start.html">
    Quick Start Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quantization_overview.html">
    Quantization Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="contributor_guide.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="sparsity.html">
    Sparsity Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="benchmarking_api_guide.html">
    Benchmarking API Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="benchmarking_user_guide.html">
    Benchmarking User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_dtypes.html">
    torchao.dtypes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_quantization.html">
    torchao.quantization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_qat.html">
    torchao.quantization.qat
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_sparsity.html">
    torchao.sparsity
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_float8.html">
    torchao.float8
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_ref_utils.html">
    torchao.utils
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="pretraining.html">
    (Part 1) Pre-training with float8
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="finetuning.html">
    (Part 2) Fine-tuning with QAT, QLoRA, and float8
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="serving.html">
    (Part 3) Serving on vLLM, SGLang, ExecuTorch
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Integration with VLLM: Architecture and Usage Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="torchao_hf_integration.html">
    Hugging Face Integration
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="serialization.html">
    Serialization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="static_quantization.html">
    Static Quantization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="subclass_basic.html">
    Writing Your Own Quantized Tensor
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="subclass_advanced.html">
    Writing Your Own Quantized Tensor (advanced)
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quant_ptq.html">
    PyTorch 2 Export Post Training Quantization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quant_qat.html">
    PyTorch 2 Export Quantization-Aware Training (QAT)
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quant_x86_inductor.html">
    PyTorch 2 Export Quantization with X86 Backend through Inductor
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quant_xpu_inductor.html">
    PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quant_openvino_inductor.html">
    PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tutorials_source/pt2e_quantizer.html">
    How to Write a Quantizer for PyTorch 2 Export Quantization
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Integration...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Integration with VLLM: Architecture and Usage Guide">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="integration-with-vllm-architecture-and-usage-guide">
<span id="torchao-vllm-integration"></span><h1>Integration with VLLM: Architecture and Usage Guide<a class="headerlink" href="#integration-with-vllm-architecture-and-usage-guide" title="Permalink to this heading">#</a></h1>
<p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Dec 30, 2025 | Last Updated On: Dec 30, 2025</p>
<p>This tutorial provides a comprehensive overview of how TorchAO integrates with VLLM, and what needs to be implemented to have a new technique work E2E.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#configuration-system" id="id11">Configuration System</a></p>
<ul>
<li><p><a class="reference internal" href="#huggingface-model-configuration" id="id12">1. HuggingFace Model Configuration</a></p></li>
<li><p><a class="reference internal" href="#torchao-configuration-classes" id="id13">2. TorchAO Configuration Classes</a></p></li>
<li><p><a class="reference internal" href="#fqn-configuration" id="id14">3. FQN Configuration</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#usage-examples" id="id15">Usage Examples</a></p>
<ul>
<li><p><a class="reference internal" href="#quantizing-models-with-huggingface-integration" id="id16">1. Quantizing Models with HuggingFace Integration</a></p></li>
<li><p><a class="reference internal" href="#serving-with-vllm" id="id17">2. Serving with VLLM</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#adding-new-quantization-methods-to-vllm" id="id18">Adding New Quantization Methods to VLLM</a></p>
<ul>
<li><p><a class="reference internal" href="#minimal-requirements-for-vllm-compatibility" id="id19">Minimal Requirements for VLLM Compatibility</a></p></li>
<li><p><a class="reference internal" href="#why-these" id="id20">Why these ?</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#step-by-step-guide-to-add-a-new-quantization-method" id="id21">Step-by-Step Guide to Add a New Quantization Method</a></p>
<ul>
<li><p><a class="reference internal" href="#create-your-tensor-subclass" id="id22">1. Create Your Tensor Subclass</a></p></li>
<li><p><a class="reference internal" href="#implement-required-vllm-operations" id="id23">2. Implement Required VLLM Operations</a></p></li>
<li><p><a class="reference internal" href="#register-with-torchao-s-quantization-system" id="id24">3. Register with TorchAO’s Quantization System</a></p></li>
<li><p><a class="reference internal" href="#key-implementation-details" id="id25">Key Implementation Details</a></p></li>
<li><p><a class="reference internal" href="#hardware-specific-linear-operations" id="id26">Hardware-Specific Linear Operations</a></p></li>
<li><p><a class="reference internal" href="#compilation-benefits" id="id27">Compilation Benefits</a></p></li>
<li><p><a class="reference internal" href="#trade-off-of-tensor-subclasses" id="id28">Trade Off of Tensor Subclasses</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#serialization-and-model-sharing" id="id29">Serialization and Model Sharing</a></p>
<ul>
<li><p><a class="reference internal" href="#safetensors-support" id="id30">SafeTensors Support</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#integration-architecture-diagrams" id="id31">Integration Architecture Diagrams</a></p>
<ul>
<li><p><a class="reference internal" href="#high-level-model-flow-transformers-vllm-torchao" id="id32">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a></p></li>
<li><p><a class="reference internal" href="#torchao-integration-points-in-vllm" id="id33">2. TorchAO Integration Points in VLLM</a></p></li>
<li><p><a class="reference internal" href="#kernel-dispatch-bringing-external-kernels-to-vllm" id="id34">3. Kernel Dispatch: Bringing External Kernels to VLLM</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="configuration-system">
<span id="id1"></span><h2><a class="toc-backref" href="#id11">Configuration System</a><a class="headerlink" href="#configuration-system" title="Permalink to this heading">#</a></h2>
<section id="huggingface-model-configuration">
<span id="id2"></span><h3><a class="toc-backref" href="#id12">1. HuggingFace Model Configuration</a><a class="headerlink" href="#huggingface-model-configuration" title="Permalink to this heading">#</a></h3>
<p>TorchAO quantization is configured through the model’s <code class="docutils literal notranslate"><span class="pre">config.json</span></code> file:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llama&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;quant_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;default&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Int4WeightOnlyConfig&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;use_hqq&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="torchao-configuration-classes">
<span id="id3"></span><h3><a class="toc-backref" href="#id13">2. TorchAO Configuration Classes</a><a class="headerlink" href="#torchao-configuration-classes" title="Permalink to this heading">#</a></h3>
<p>All quantization methods inherit from <code class="docutils literal notranslate"><span class="pre">AOBaseConfig</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.core.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AOBaseConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">Int4WeightOnlyConfig</span>

<span class="c1"># Example configuration</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span>
    <span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">use_hqq</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">AOBaseConfig</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All quantization configurations inherit from <code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.core.config.AOBaseConfig</span></code>, which provides serialization and validation capabilities.</p>
</div>
</section>
<section id="fqn-configuration">
<span id="id4"></span><h3><a class="toc-backref" href="#id14">3. FQN Configuration</a><a class="headerlink" href="#fqn-configuration" title="Permalink to this heading">#</a></h3>
<p>For granular control, use <code class="docutils literal notranslate"><span class="pre">FqnToConfig</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">FqnToConfig</span><span class="p">,</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">,</span> <span class="n">Int8WeightOnlyConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">FqnToConfig</span><span class="p">({</span>
    <span class="s2">&quot;model.layers.0.self_attn.q_proj&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
    <span class="s2">&quot;model.layers.0.self_attn.k_proj&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
    <span class="s2">&quot;model.layers.0.mlp.gate_proj&quot;</span><span class="p">:</span> <span class="n">Int8WeightOnlyConfig</span><span class="p">(),</span>
    <span class="s2">&quot;_default&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Default for other modules</span>
<span class="p">})</span>
</pre></div>
</div>
</section>
</section>
<section id="usage-examples">
<span id="id5"></span><h2><a class="toc-backref" href="#id15">Usage Examples</a><a class="headerlink" href="#usage-examples" title="Permalink to this heading">#</a></h2>
<section id="quantizing-models-with-huggingface-integration">
<span id="quantizing-models-huggingface"></span><h3><a class="toc-backref" href="#id16">1. Quantizing Models with HuggingFace Integration</a><a class="headerlink" href="#quantizing-models-with-huggingface-integration" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchAoConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">Int4WeightOnlyConfig</span>

<span class="c1"># Create quantization configuration</span>
<span class="n">quantization_config</span> <span class="o">=</span> <span class="n">TorchAoConfig</span><span class="p">(</span>
    <span class="n">quant_type</span><span class="o">=</span><span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">use_hqq</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Load and automatically quantize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;meta-llama/Llama-3.2-1B&quot;</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span>
<span class="p">)</span>

<span class="c1"># Save quantized model (see Serialization section below for safe_serialization details)</span>
<span class="n">model</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;your-username/Llama-3.2-1B-int4&quot;</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For more information on quantization configs, see <a class="reference internal" href="generated/torchao.quantization.Int4WeightOnlyConfig.html#torchao.quantization.Int4WeightOnlyConfig" title="torchao.quantization.Int4WeightOnlyConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.quantization.Int4WeightOnlyConfig</span></code></a> and <a class="reference internal" href="generated/torchao.quantization.Int8WeightOnlyConfig.html#torchao.quantization.Int8WeightOnlyConfig" title="torchao.quantization.Int8WeightOnlyConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.quantization.Int8WeightOnlyConfig</span></code></a>.</p>
</div>
</section>
<section id="serving-with-vllm">
<span id="id6"></span><h3><a class="toc-backref" href="#id17">2. Serving with VLLM</a><a class="headerlink" href="#serving-with-vllm" title="Permalink to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Start VLLM server with TorchAO quantized model</span>
vllm<span class="w"> </span>serve<span class="w"> </span>your-username/Llama-3.2-1B-int4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--quantization<span class="w"> </span>torchao<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
</section>
</section>
<section id="adding-new-quantization-methods-to-vllm">
<span id="adding-new-quantization-methods"></span><h2><a class="toc-backref" href="#id18">Adding New Quantization Methods to VLLM</a><a class="headerlink" href="#adding-new-quantization-methods-to-vllm" title="Permalink to this heading">#</a></h2>
<section id="minimal-requirements-for-vllm-compatibility">
<span id="minimal-requirements-vllm"></span><h3><a class="toc-backref" href="#id19">Minimal Requirements for VLLM Compatibility</a><a class="headerlink" href="#minimal-requirements-for-vllm-compatibility" title="Permalink to this heading">#</a></h3>
<p>To make a new TorchAO quantization method work with VLLM, you need to implement minimal tensor subclass operations that support <strong>tensor parallelism</strong>. VLLM uses <code class="docutils literal notranslate"><span class="pre">narrow()</span></code> and <code class="docutils literal notranslate"><span class="pre">copy_()</span></code> to move data from host cpu loaded in a state dict to the device, these  require these specific aten operations:</p>
</section>
<section id="why-these">
<span id="why-these-operations"></span><h3><a class="toc-backref" href="#id20">Why these ?</a><a class="headerlink" href="#why-these" title="Permalink to this heading">#</a></h3>
<p>VLLM’s tensor parallelism works by:</p>
<ol class="arabic simple">
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.narrow.html#torch.Tensor.narrow" title="(in PyTorch v2.9)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">narrow()</span></code></a></strong> - Slicing weight tensors across different dimensions</p></li>
<li><p><strong>Sharding</strong> - Distributing tensor chunks across multiple GPUs</p></li>
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.copy_.html#torch.Tensor.copy_" title="(in PyTorch v2.9)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">copy_()</span></code></a></strong> - Moving tensor data between devices</p></li>
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.detach.html#torch.Tensor.detach" title="(in PyTorch v2.9)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">detach()</span></code></a></strong></p></li>
</ol>
<p>A helpful pattern for doing this is <code class="docutils literal notranslate"><span class="pre">_apply_fn_to_data</span></code>, a method that applies a given function to all the attributes on your class w/ Tensor types. Below is a generic implementation that should work for most subclasses. We make heavy use of this pattern in the torchao codebase:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_apply_fn_to_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Applies a fn to all tensor components stored on this class&quot;&quot;&quot;</span>
    <span class="n">tensor_names</span><span class="p">,</span> <span class="n">ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tensor_flatten__</span><span class="p">()</span>

    <span class="c1"># Apply the function to each tensor component</span>
    <span class="n">new_tensors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tensor_names</span><span class="p">:</span>
        <span class="n">new_tensors</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__tensor_unflatten__</span><span class="p">(</span>
        <span class="n">new_tensors</span><span class="p">,</span>
        <span class="n">ctx</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>  <span class="c1"># outer_size parameter</span>
        <span class="kc">None</span><span class="p">,</span>  <span class="c1"># outer_stride parameter</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="step-by-step-guide-to-add-a-new-quantization-method">
<span id="step-by-step-guide"></span><h2><a class="toc-backref" href="#id21">Step-by-Step Guide to Add a New Quantization Method</a><a class="headerlink" href="#step-by-step-guide-to-add-a-new-quantization-method" title="Permalink to this heading">#</a></h2>
<section id="create-your-tensor-subclass">
<span id="create-tensor-subclass"></span><h3><a class="toc-backref" href="#id22">1. Create Your Tensor Subclass</a><a class="headerlink" href="#create-your-tensor-subclass" title="Permalink to this heading">#</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For more details on tensor subclasses and their design principles, please refer to the <a class="reference external" href="https://docs.pytorch.org/ao/stable/subclass_basic.html#what-are-tensor-subclasses">What are Tensor Subclasses?</a> documentation.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.core.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AOBaseConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchAOBaseTensor</span>

<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyNewQuantConfig</span><span class="p">(</span><span class="n">AOBaseConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for your new quantization method&quot;&quot;&quot;</span>
    <span class="n">bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">VERSION</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MyQuantizedTensor</span><span class="p">(</span><span class="n">TorchAOBaseTensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Example based on Float8Tensor - stores quantized data + scale&quot;&quot;&quot;</span>

    <span class="n">tensor_data_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;quantized_data&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">]</span>
    <span class="n">tensor_attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">quantized_data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">quantized_data</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">_make_wrapper_subclass</span><span class="p">(</span>
            <span class="bp">cls</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">quantized_data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantized_data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">quantized_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__tensor_flatten__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Serialize tensor subclass into plain tensors and metadata&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_data_attrs</span><span class="p">,</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_attributes</span>
        <span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">__tensor_unflatten__</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">tensor_data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">tensor_attributes</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">outer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">],</span>
        <span class="n">outer_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MyQuantizedTensor&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reconstruct tensor subclass from serialized data&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">tensor_data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">tensor_data_attrs</span><span class="p">],</span>
            <span class="o">*</span><span class="n">tensor_attributes</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="implement-required-vllm-operations">
<span id="implement-vllm-operations"></span><h3><a class="toc-backref" href="#id23">2. Implement Required VLLM Operations</a><a class="headerlink" href="#implement-required-vllm-operations" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils._python_dispatch</span><span class="w"> </span><span class="kn">import</span> <span class="n">return_and_correct_aliasing</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">detach</span><span class="o">.</span><span class="n">default</span><span class="p">,</span> <span class="n">aten</span><span class="o">.</span><span class="n">alias</span><span class="o">.</span><span class="n">default</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
        <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="p">)</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">_to_copy</span><span class="o">.</span><span class="n">default</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
        <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">)</span>
    <span class="p">)</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">slice</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="n">fill_defaults</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># NOTE the slicing here will likely be different for different quant techniques</span>
        <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
            <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span>
            <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aten</span><span class="o">.</span><span class="n">slice</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Slicing along dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="register-with-torchao-s-quantization-system">
<span id="register-with-torchao"></span><h3><a class="toc-backref" href="#id24">3. Register with TorchAO’s Quantization System</a><a class="headerlink" href="#register-with-torchao-s-quantization-system" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization.transform_module</span><span class="w"> </span><span class="kn">import</span> <span class="n">register_quantize_module_handler</span>

<span class="nd">@register_quantize_module_handler</span><span class="p">(</span><span class="n">MyNewQuantConfig</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_my_quant_transform</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">MyNewQuantConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform function that applies your quantization to a module&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span>

    <span class="c1"># Your quantization logic here</span>
    <span class="n">quantized_weight</span> <span class="o">=</span> <span class="n">my_quantization_function</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

    <span class="c1"># Replace the weight with your quantized tensor</span>
    <span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">quantized_weight</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">torchao.quantization.transform_module.register_quantize_module_handler()</span></code> decorator registers your config class with TorchAO’s quantization system.</p>
</div>
</section>
<section id="key-implementation-details">
<span id="id7"></span><h3><a class="toc-backref" href="#id25">Key Implementation Details</a><a class="headerlink" href="#key-implementation-details" title="Permalink to this heading">#</a></h3>
</section>
<section id="hardware-specific-linear-operations">
<span id="hardware-specific-linear-ops"></span><h3><a class="toc-backref" href="#id26">Hardware-Specific Linear Operations</a><a class="headerlink" href="#hardware-specific-linear-operations" title="Permalink to this heading">#</a></h3>
<p>Your quantized tensor’s forward pass determines hardware support and what actually gets called when <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.linear.html#torch.nn.functional.linear" title="(in PyTorch v2.9)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.linear()</span></code></a> is called.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># This is where you define what hardware your method supports</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span> <span class="s1">&#39;use_cutlass_kernel&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">my_cutlass_linear</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span> <span class="s1">&#39;use_triton_kernel&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">my_triton_linear</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fallback - dequantize and use standard linear</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
            <span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">dequantize</span><span class="p">(),</span> <span class="n">bias</span>
        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compilation-benefits">
<span id="id8"></span><h3><a class="toc-backref" href="#id27">Compilation Benefits</a><a class="headerlink" href="#compilation-benefits" title="Permalink to this heading">#</a></h3>
<p>The overhead of tensor subclasses disappears with <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="(in PyTorch v2.9)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code></a>, this is on by default in VLLM.</p>
</section>
<section id="trade-off-of-tensor-subclasses">
<span id="trade-off-tensor-subclasses"></span><h3><a class="toc-backref" href="#id28">Trade Off of Tensor Subclasses</a><a class="headerlink" href="#trade-off-of-tensor-subclasses" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Compilation</strong>: is essential for removing subclass overhead. Without it unless your model is extremely gpu bound the overhead of dispatch on the CPU can severely impact performance.</p></li>
<li><p>The checkpoint defines the behavior of the model. You might be saying “don’t all checkpoints do this”. This is true, however people typically solely think of a torch.Tensor as its data. When in actuality its a true class where it brings the Dispatcher and all the kernels ATen has registered to it. When you define your tensor subclass, you are building a separate little world. One w/ a different representation of data, but also one where you need to explicitly define what ops you support and have implementations for all the hardware you want to support. This can feel a little like spooky action at a distance at first. But it can be very powerful. Case in point is being able to support TP with only 3 definitions.</p></li>
</ol>
</section>
</section>
<section id="serialization-and-model-sharing">
<span id="serialization-model-sharing"></span><h2><a class="toc-backref" href="#id29">Serialization and Model Sharing</a><a class="headerlink" href="#serialization-and-model-sharing" title="Permalink to this heading">#</a></h2>
<section id="safetensors-support">
<span id="id9"></span><h3><a class="toc-backref" href="#id30">SafeTensors Support</a><a class="headerlink" href="#safetensors-support" title="Permalink to this heading">#</a></h3>
<p><strong>Current Status</strong>: TorchAO quantized models cannot yet be serialized with safetensors due to tensor subclass limitations. When saving quantized models, you must use <code class="docutils literal notranslate"><span class="pre">safe_serialization=False</span></code>.</p>
<p><strong>Workaround</strong>: For production use, save models with <code class="docutils literal notranslate"><span class="pre">safe_serialization=False</span></code> when pushing to HuggingFace Hub.</p>
<p><strong>Future Work</strong>: The TorchAO team is actively working on safetensors support for tensor subclasses. Track progress at: <a class="reference external" href="https://github.com/pytorch/ao/issues/2338">pytorch/ao#2338</a></p>
</section>
</section>
<section id="integration-architecture-diagrams">
<span id="id10"></span><h2><a class="toc-backref" href="#id31">Integration Architecture Diagrams</a><a class="headerlink" href="#integration-architecture-diagrams" title="Permalink to this heading">#</a></h2>
<section id="high-level-model-flow-transformers-vllm-torchao">
<span id="high-level-model-flow"></span><h3><a class="toc-backref" href="#id32">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a><a class="headerlink" href="#high-level-model-flow-transformers-vllm-torchao" title="Permalink to this heading">#</a></h3>
<p>This diagram shows the end-to-end flow from model creation to serving:</p>
<pre  class="mermaid">
        graph LR
    A[HuggingFace Model] --&gt; B[Transformers AutoModel]
    B --&gt; C{Quantization Config?}
    C --&gt;|TorchAO Config| D[Apply TorchAO Quantization]
    C --&gt;|No Config| E[Standard Model]

    D --&gt; F[Quantized Model w/ Tensor Subclasses]
    E --&gt; G[Standard PyTorch Model]

    F --&gt; H[VLLM Model Loading]
    G --&gt; H

    H --&gt; I[VLLM Distributed Engine]
    I --&gt; J[Tensor Parallel Sharding]
    J --&gt; K[Optimized Inference]

    style D fill:#e1f5fe
    style F fill:#f3e5f5
    style J fill:#e8f5e8
    </pre></section>
<section id="torchao-integration-points-in-vllm">
<span id="torchao-integration-points"></span><h3><a class="toc-backref" href="#id33">2. TorchAO Integration Points in VLLM</a><a class="headerlink" href="#torchao-integration-points-in-vllm" title="Permalink to this heading">#</a></h3>
<p>This shows how VLLM detects and applies TorchAO quantization:</p>
<pre  class="mermaid">
        graph LR
    A[Model Config Detection] --&gt; B{quantization=torchao?}
    B --&gt;|Yes| C[TorchAOConfig.from_config]
    B --&gt;|No| D[Other Quantization Methods]

    C --&gt; E[Parse HF quant_type]
    E --&gt; F[config_from_dict]
    F --&gt; G[AOBaseConfig Instance]

    G --&gt; H[get_quant_method per layer]
    H --&gt; I{Layer Type?}
    I --&gt;|LinearBase| J[TorchAOLinearMethod]
    I --&gt;|Other| K[UnquantizedLinearMethod]

    J --&gt; L[create_weights]
    L --&gt; M[torchao_quantize_param_data]
    M --&gt; N[Quantized Tensor Subclass]

    style C fill:#e1f5fe
    style G fill:#f3e5f5
    style N fill:#e8f5e8
    </pre></section>
<section id="kernel-dispatch-bringing-external-kernels-to-vllm">
<span id="kernel-dispatch"></span><h3><a class="toc-backref" href="#id34">3. Kernel Dispatch: Bringing External Kernels to VLLM</a><a class="headerlink" href="#kernel-dispatch-bringing-external-kernels-to-vllm" title="Permalink to this heading">#</a></h3>
<p>This illustrates how tensor subclasses enable custom kernel dispatch within VLLM:</p>
<pre  class="mermaid">
        graph LR
    A[F.linear Call in VLLM] --&gt; B[MyQuantTensor torch_function]
    B --&gt; C[Custom implements Handler]
    C --&gt; D{Hardware Check}

    D --&gt; E[Dispatch to External Kernel]
    E --&gt; F[Execute Optimized Kernel]
    F --&gt; G[Return Result to VLLM]

    subgraph &quot;External Libraries&quot;
        H[TorchAO CUTLASS]
        I[TorchAO Triton]
        J[FBGEMM-GPU]
        K[Custom Libraries]
    end

    subgraph &quot;Tensor Subclass Code&quot;
        L[implements F.linear]
        M[custom_linear_impl]
        N[call external kernel]
    end

    E --&gt; H
    E --&gt; I
    E --&gt; J
    E --&gt; K

    C --&gt; L
    L --&gt; M
    M --&gt; N
    N --&gt; E

    style B fill:#e8f6ff,color:#000
    style C fill:#fff3e0,color:#000
    style E fill:#e8f5e8,color:#000
    style L fill:#f3e5f5,color:#000
    </pre></section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="serving.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(Part 3) Serving on vLLM, SGLang, ExecuTorch</p>
      </div>
    </a>
    <a class="right-next"
       href="torchao_hf_integration.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Hugging Face Integration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="serving.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(Part 3) Serving on vLLM, SGLang, ExecuTorch</p>
      </div>
    </a>
    <a class="right-next"
       href="torchao_hf_integration.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Hugging Face Integration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-system">Configuration System</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#huggingface-model-configuration">1. HuggingFace Model Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchao-configuration-classes">2. TorchAO Configuration Classes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fqn-configuration">3. FQN Configuration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#usage-examples">Usage Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantizing-models-with-huggingface-integration">1. Quantizing Models with HuggingFace Integration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#serving-with-vllm">2. Serving with VLLM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-quantization-methods-to-vllm">Adding New Quantization Methods to VLLM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minimal-requirements-for-vllm-compatibility">Minimal Requirements for VLLM Compatibility</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-these">Why these ?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-guide-to-add-a-new-quantization-method">Step-by-Step Guide to Add a New Quantization Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-your-tensor-subclass">1. Create Your Tensor Subclass</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-required-vllm-operations">2. Implement Required VLLM Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#register-with-torchao-s-quantization-system">3. Register with TorchAO’s Quantization System</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-implementation-details">Key Implementation Details</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hardware-specific-linear-operations">Hardware-Specific Linear Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compilation-benefits">Compilation Benefits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trade-off-of-tensor-subclasses">Trade Off of Tensor Subclasses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serialization-and-model-sharing">Serialization and Model Sharing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#safetensors-support">SafeTensors Support</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-architecture-diagrams">Integration Architecture Diagrams</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-level-model-flow-transformers-vllm-torchao">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchao-integration-points-in-vllm">2. TorchAO Integration Points in VLLM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-dispatch-bringing-external-kernels-to-vllm">3. Kernel Dispatch: Bringing External Kernels to VLLM</a></li>
</ul>
</li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/ao/edit/main/docs/source/torchao_vllm_integration.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/torchao_vllm_integration.md.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024-present, torchao Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Integration with VLLM: Architecture and Usage Guide",
       "headline": "Integration with VLLM: Architecture and Usage Guide",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/torchao_vllm_integration.html",
       "articleBody": "Integration with VLLM: Architecture and Usage Guide# Created On: Dec 30, 2025 | Last Updated On: Dec 30, 2025 This tutorial provides a comprehensive overview of how TorchAO integrates with VLLM, and what needs to be implemented to have a new technique work E2E. Configuration System 1. HuggingFace Model Configuration 2. TorchAO Configuration Classes 3. FQN Configuration Usage Examples 1. Quantizing Models with HuggingFace Integration 2. Serving with VLLM Adding New Quantization Methods to VLLM Minimal Requirements for VLLM Compatibility Why these ? Step-by-Step Guide to Add a New Quantization Method 1. Create Your Tensor Subclass 2. Implement Required VLLM Operations 3. Register with TorchAO\u2019s Quantization System Key Implementation Details Hardware-Specific Linear Operations Compilation Benefits Trade Off of Tensor Subclasses Serialization and Model Sharing SafeTensors Support Integration Architecture Diagrams 1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO 2. TorchAO Integration Points in VLLM 3. Kernel Dispatch: Bringing External Kernels to VLLM Configuration System# 1. HuggingFace Model Configuration# TorchAO quantization is configured through the model\u2019s config.json file: { \"model_type\": \"llama\", \"quant_type\": { \"default\": { \"_type\": \"Int4WeightOnlyConfig\", \"_data\": { \"group_size\": 128, \"use_hqq\": true } } } } 2. TorchAO Configuration Classes# All quantization methods inherit from AOBaseConfig: from torchao.core.config import AOBaseConfig from torchao.quantization import Int4WeightOnlyConfig # Example configuration config = Int4WeightOnlyConfig( group_size=128, use_hqq=True, version=1, ) assert isinstance(config, AOBaseConfig) Note All quantization configurations inherit from torchao.core.config.AOBaseConfig, which provides serialization and validation capabilities. 3. FQN Configuration# For granular control, use FqnToConfig: from torchao.quantization import FqnToConfig, Int4WeightOnlyConfig, Int8WeightOnlyConfig config = FqnToConfig({ \"model.layers.0.self_attn.q_proj\": Int4WeightOnlyConfig(group_size=64), \"model.layers.0.self_attn.k_proj\": Int4WeightOnlyConfig(group_size=64), \"model.layers.0.mlp.gate_proj\": Int8WeightOnlyConfig(), \"_default\": Int4WeightOnlyConfig(group_size=128, version=1) # Default for other modules }) Usage Examples# 1. Quantizing Models with HuggingFace Integration# from transformers import TorchAoConfig, AutoModelForCausalLM from torchao.quantization import Int4WeightOnlyConfig # Create quantization configuration quantization_config = TorchAoConfig( quant_type=Int4WeightOnlyConfig(group_size=128, use_hqq=True, version=1) ) # Load and automatically quantize the model model = AutoModelForCausalLM.from_pretrained( \"meta-llama/Llama-3.2-1B\", dtype=\"auto\", device_map=\"auto\", quantization_config=quantization_config ) # Save quantized model (see Serialization section below for safe_serialization details) model.push_to_hub(\"your-username/Llama-3.2-1B-int4\", safe_serialization=False) See also For more information on quantization configs, see torchao.quantization.Int4WeightOnlyConfig and torchao.quantization.Int8WeightOnlyConfig. 2. Serving with VLLM# # Start VLLM server with TorchAO quantized model vllm serve your-username/Llama-3.2-1B-int4 \\ --quantization torchao \\ --dtype bfloat16 \\ Adding New Quantization Methods to VLLM# Minimal Requirements for VLLM Compatibility# To make a new TorchAO quantization method work with VLLM, you need to implement minimal tensor subclass operations that support tensor parallelism. VLLM uses narrow() and copy_() to move data from host cpu loaded in a state dict to the device, these require these specific aten operations: Why these ?# VLLM\u2019s tensor parallelism works by: narrow() - Slicing weight tensors across different dimensions Sharding - Distributing tensor chunks across multiple GPUs copy_() - Moving tensor data between devices detach() A helpful pattern for doing this is _apply_fn_to_data, a method that applies a given function to all the attributes on your class w/ Tensor types. Below is a generic implementation that should work for most subclasses. We make heavy use of this pattern in the torchao codebase: def _apply_fn_to_data(self, fn: Callable): \"\"\"Applies a fn to all tensor components stored on this class\"\"\" tensor_names, ctx = self.__tensor_flatten__() # Apply the function to each tensor component new_tensors = {} for name in tensor_names: new_tensors[name] = fn(getattr(self, name)) return self.__class__.__tensor_unflatten__( new_tensors, ctx, None, # outer_size parameter None, # outer_stride parameter ) Step-by-Step Guide to Add a New Quantization Method# 1. Create Your Tensor Subclass# Note For more details on tensor subclasses and their design principles, please refer to the What are Tensor Subclasses? documentation. from torchao.core.config import AOBaseConfig from torchao.utils import TorchAOBaseTensor @dataclass class MyNewQuantConfig(AOBaseConfig): \"\"\"Configuration for your new quantization method\"\"\" bits: int = 8 VERSION: ClassVar[int] = 1 class MyQuantizedTensor(TorchAOBaseTensor): \"\"\"Example based on Float8Tensor - stores quantized data + scale\"\"\" tensor_data_attrs = [\"quantized_data\", \"scale\"] tensor_attributes = [\"dtype\"] def __new__(cls, quantized_data, scale, dtype): shape = quantized_data.shape return torch.Tensor._make_wrapper_subclass( cls, shape, device=quantized_data.device, dtype=dtype, requires_grad=False ) def __init__(self, quantized_data, scale, dtype): self.quantized_data = quantized_data self.scale = scale def __tensor_flatten__(self) -\u003e Tuple[List[str], List]: \"\"\"Serialize tensor subclass into plain tensors and metadata\"\"\" return self.tensor_data_attrs, [ getattr(self, attr) for attr in self.tensor_attributes ] @classmethod def __tensor_unflatten__( cls, tensor_data_dict: Dict[str, torch.Tensor], tensor_attributes: List, outer_size: Optional[torch.Size], outer_stride: Optional[Tuple], ) -\u003e \"MyQuantizedTensor\": \"\"\"Reconstruct tensor subclass from serialized data\"\"\" return cls( *[tensor_data_dict[name] for name in cls.tensor_data_attrs], *tensor_attributes, ) 2. Implement Required VLLM Operations# from torch.utils._python_dispatch import return_and_correct_aliasing @MyQuantizedTensor.implements([aten.detach.default, aten.alias.default]) def _(func, types, args, kwargs): return return_and_correct_aliasing( func, args, kwargs, args[0]._apply_fn_to_data(func) ) @MyQuantizedTensor.implements([aten._to_copy.default]) def _(func, types, args, kwargs): return return_and_correct_aliasing( func, args, kwargs, args[0]._apply_fn_to_data(torch.clone) ) @MyQuantizedTensor.implements([aten.slice.Tensor]) def _(func, types, args, kwargs): self, dim, start, end, step = fill_defaults(args, 5, [0, None, None, 1]) if dim == 0 or dim == 1: # NOTE the slicing here will likely be different for different quant techniques return return_and_correct_aliasing( func, args, kwargs, args[0]._apply_fn_to_data(lambda x: aten.slice.Tensor(x, dim, start, end, step)) ) else: raise NotImplementedError(f\"Slicing along dim={dim} not supported\") 3. Register with TorchAO\u2019s Quantization System# from torchao.quantization.transform_module import register_quantize_module_handler @register_quantize_module_handler(MyNewQuantConfig) def _my_quant_transform(module: torch.nn.Module, config: MyNewQuantConfig): \"\"\"Transform function that applies your quantization to a module\"\"\" weight = module.weight # Your quantization logic here quantized_weight = my_quantization_function(weight, config) # Replace the weight with your quantized tensor module.weight = torch.nn.Parameter(quantized_weight, requires_grad=False) return module Important The torchao.quantization.transform_module.register_quantize_module_handler() decorator registers your config class with TorchAO\u2019s quantization system. Key Implementation Details# Hardware-Specific Linear Operations# Your quantized tensor\u2019s forward pass determines hardware support and what actually gets called when torch.nn.functional.linear() is called. @MyQuantizedTensor.implements(torch.nn.functional.linear) def _(func, types, args, kwargs): input_tensor, weight_tensor, bias = args[0], args[1], args[2] if len(args) \u003e 2 else None # This is where you define what hardware your method supports if hasattr(weight_tensor, \u0027use_cutlass_kernel\u0027): return my_cutlass_linear(input_tensor, weight_tensor, bias) elif hasattr(weight_tensor, \u0027use_triton_kernel\u0027): return my_triton_linear(input_tensor, weight_tensor, bias) else: # Fallback - dequantize and use standard linear return torch.nn.functional.linear( input_tensor, weight_tensor.dequantize(), bias ) Compilation Benefits# The overhead of tensor subclasses disappears with torch.compile(), this is on by default in VLLM. Trade Off of Tensor Subclasses# Compilation: is essential for removing subclass overhead. Without it unless your model is extremely gpu bound the overhead of dispatch on the CPU can severely impact performance. The checkpoint defines the behavior of the model. You might be saying \u201cdon\u2019t all checkpoints do this\u201d. This is true, however people typically solely think of a torch.Tensor as its data. When in actuality its a true class where it brings the Dispatcher and all the kernels ATen has registered to it. When you define your tensor subclass, you are building a separate little world. One w/ a different representation of data, but also one where you need to explicitly define what ops you support and have implementations for all the hardware you want to support. This can feel a little like spooky action at a distance at first. But it can be very powerful. Case in point is being able to support TP with only 3 definitions. Serialization and Model Sharing# SafeTensors Support# Current Status: TorchAO quantized models cannot yet be serialized with safetensors due to tensor subclass limitations. When saving quantized models, you must use safe_serialization=False. Workaround: For production use, save models with safe_serialization=False when pushing to HuggingFace Hub. Future Work: The TorchAO team is actively working on safetensors support for tensor subclasses. Track progress at: pytorch/ao#2338 Integration Architecture Diagrams# 1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO# This diagram shows the end-to-end flow from model creation to serving: graph LR A[HuggingFace Model] --\u003e B[Transformers AutoModel] B --\u003e C{Quantization Config?} C --\u003e|TorchAO Config| D[Apply TorchAO Quantization] C --\u003e|No Config| E[Standard Model] D --\u003e F[Quantized Model w/ Tensor Subclasses] E --\u003e G[Standard PyTorch Model] F --\u003e H[VLLM Model Loading] G --\u003e H H --\u003e I[VLLM Distributed Engine] I --\u003e J[Tensor Parallel Sharding] J --\u003e K[Optimized Inference] style D fill:#e1f5fe style F fill:#f3e5f5 style J fill:#e8f5e8 2. TorchAO Integration Points in VLLM# This shows how VLLM detects and applies TorchAO quantization: graph LR A[Model Config Detection] --\u003e B{quantization=torchao?} B --\u003e|Yes| C[TorchAOConfig.from_config] B --\u003e|No| D[Other Quantization Methods] C --\u003e E[Parse HF quant_type] E --\u003e F[config_from_dict] F --\u003e G[AOBaseConfig Instance] G --\u003e H[get_quant_method per layer] H --\u003e I{Layer Type?} I --\u003e|LinearBase| J[TorchAOLinearMethod] I --\u003e|Other| K[UnquantizedLinearMethod] J --\u003e L[create_weights] L --\u003e M[torchao_quantize_param_data] M --\u003e N[Quantized Tensor Subclass] style C fill:#e1f5fe style G fill:#f3e5f5 style N fill:#e8f5e8 3. Kernel Dispatch: Bringing External Kernels to VLLM# This illustrates how tensor subclasses enable custom kernel dispatch within VLLM: graph LR A[F.linear Call in VLLM] --\u003e B[MyQuantTensor torch_function] B --\u003e C[Custom implements Handler] C --\u003e D{Hardware Check} D --\u003e E[Dispatch to External Kernel] E --\u003e F[Execute Optimized Kernel] F --\u003e G[Return Result to VLLM] subgraph \"External Libraries\" H[TorchAO CUTLASS] I[TorchAO Triton] J[FBGEMM-GPU] K[Custom Libraries] end subgraph \"Tensor Subclass Code\" L[implements F.linear] M[custom_linear_impl] N[call external kernel] end E --\u003e H E --\u003e I E --\u003e J E --\u003e K C --\u003e L L --\u003e M M --\u003e N N --\u003e E style B fill:#e8f6ff,color:#000 style C fill:#fff3e0,color:#000 style E fill:#e8f5e8,color:#000 style L fill:#f3e5f5,color:#000",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/torchao_vllm_integration.html"
       },
       "datePublished": "Dec 30, 2025T00:00:00Z",
       "dateModified": "Dec 30, 2025T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>