


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Integration with VLLM: Architecture and Usage Guide &mdash; torchao main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Serialization" href="serialization.html" />
    <link rel="prev" title="(Part 3) Serving on vLLM, SGLang, ExecuTorch" href="serving.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
        <a href='https://pytorch.org/ao/versions.html'>main &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick Start Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quantization_overview.html">Quantization Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributor_guide.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparsity.html">Sparsity Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking_api_guide.html">Benchmarking API Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking_user_guide.html">Benchmarking User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_ref_dtypes.html">torchao.dtypes</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_quantization.html">torchao.quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_qat.html">torchao.quantization.qat</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_sparsity.html">torchao.sparsity</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_float8.html">torchao.float8</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_utils.html">torchao.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref_utils.html#torchao-quantization-quantize-common">torchao.quantization.quantize_.common</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Eager Quantization Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="pretraining.html">(Part 1) Pre-training with float8</a></li>
<li class="toctree-l1"><a class="reference internal" href="finetuning.html">(Part 2) Fine-tuning with QAT, QLoRA, and float8</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving.html">(Part 3) Serving on vLLM, SGLang, ExecuTorch</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Integration with VLLM: Architecture and Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Serialization</a></li>
<li class="toctree-l1"><a class="reference internal" href="static_quantization.html">Static Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="subclass_basic.html">Writing Your Own Quantized Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="subclass_advanced.html">Writing Your Own Quantized Tensor (advanced)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PT2E Quantization Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quant_ptq.html">PyTorch 2 Export Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quant_qat.html">PyTorch 2 Export Quantization-Aware Training (QAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quant_x86_inductor.html">PyTorch 2 Export Quantization with X86 Backend through Inductor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quant_xpu_inductor.html">PyTorch 2 Export Quantization with Intel GPU Backend through Inductor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quant_openvino_inductor.html">PyTorch 2 Export Quantization for OpenVINO torch.compile Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials_source/pt2e_quantizer.html">How to Write a <code class="docutils literal notranslate"><span class="pre">Quantizer</span></code> for PyTorch 2 Export Quantization</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Integration with VLLM: Architecture and Usage Guide</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/torchao_vllm_integration.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="integration-with-vllm-architecture-and-usage-guide">
<span id="torchao-vllm-integration"></span><h1>Integration with VLLM: Architecture and Usage Guide<a class="headerlink" href="#integration-with-vllm-architecture-and-usage-guide" title="Permalink to this heading">¶</a></h1>
<p>This tutorial provides a comprehensive overview of how TorchAO integrates with VLLM, and what needs to be implemented to have a new technique work E2E.</p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#configuration-system" id="id11">Configuration System</a></p>
<ul>
<li><p><a class="reference internal" href="#huggingface-model-configuration" id="id12">1. HuggingFace Model Configuration</a></p></li>
<li><p><a class="reference internal" href="#torchao-configuration-classes" id="id13">2. TorchAO Configuration Classes</a></p></li>
<li><p><a class="reference internal" href="#module-level-configuration" id="id14">3. Module-Level Configuration</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#usage-examples" id="id15">Usage Examples</a></p>
<ul>
<li><p><a class="reference internal" href="#quantizing-models-with-huggingface-integration" id="id16">1. Quantizing Models with HuggingFace Integration</a></p></li>
<li><p><a class="reference internal" href="#serving-with-vllm" id="id17">2. Serving with VLLM</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#adding-new-quantization-methods-to-vllm" id="id18">Adding New Quantization Methods to VLLM</a></p>
<ul>
<li><p><a class="reference internal" href="#minimal-requirements-for-vllm-compatibility" id="id19">Minimal Requirements for VLLM Compatibility</a></p></li>
<li><p><a class="reference internal" href="#why-these" id="id20">Why these ?</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#step-by-step-guide-to-add-a-new-quantization-method" id="id21">Step-by-Step Guide to Add a New Quantization Method</a></p>
<ul>
<li><p><a class="reference internal" href="#create-your-tensor-subclass" id="id22">1. Create Your Tensor Subclass</a></p></li>
<li><p><a class="reference internal" href="#implement-required-vllm-operations" id="id23">2. Implement Required VLLM Operations</a></p></li>
<li><p><a class="reference internal" href="#register-with-torchao-s-quantization-system" id="id24">3. Register with TorchAO’s Quantization System</a></p></li>
<li><p><a class="reference internal" href="#key-implementation-details" id="id25">Key Implementation Details</a></p></li>
<li><p><a class="reference internal" href="#hardware-specific-linear-operations" id="id26">Hardware-Specific Linear Operations</a></p></li>
<li><p><a class="reference internal" href="#compilation-benefits" id="id27">Compilation Benefits</a></p></li>
<li><p><a class="reference internal" href="#trade-off-of-tensor-subclasses" id="id28">Trade Off of Tensor Subclasses</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#serialization-and-model-sharing" id="id29">Serialization and Model Sharing</a></p>
<ul>
<li><p><a class="reference internal" href="#safetensors-support" id="id30">SafeTensors Support</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#integration-architecture-diagrams" id="id31">Integration Architecture Diagrams</a></p>
<ul>
<li><p><a class="reference internal" href="#high-level-model-flow-transformers-vllm-torchao" id="id32">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a></p></li>
<li><p><a class="reference internal" href="#torchao-integration-points-in-vllm" id="id33">2. TorchAO Integration Points in VLLM</a></p></li>
<li><p><a class="reference internal" href="#kernel-dispatch-bringing-external-kernels-to-vllm" id="id34">3. Kernel Dispatch: Bringing External Kernels to VLLM</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="configuration-system">
<span id="id1"></span><h2><a class="toc-backref" href="#id11" role="doc-backlink">Configuration System</a><a class="headerlink" href="#configuration-system" title="Permalink to this heading">¶</a></h2>
<section id="huggingface-model-configuration">
<span id="id2"></span><h3><a class="toc-backref" href="#id12" role="doc-backlink">1. HuggingFace Model Configuration</a><a class="headerlink" href="#huggingface-model-configuration" title="Permalink to this heading">¶</a></h3>
<p>TorchAO quantization is configured through the model’s <code class="docutils literal notranslate"><span class="pre">config.json</span></code> file:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llama&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;quant_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;default&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Int4WeightOnlyConfig&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;_data&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;use_hqq&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="torchao-configuration-classes">
<span id="id3"></span><h3><a class="toc-backref" href="#id13" role="doc-backlink">2. TorchAO Configuration Classes</a><a class="headerlink" href="#torchao-configuration-classes" title="Permalink to this heading">¶</a></h3>
<p>All quantization methods inherit from <code class="docutils literal notranslate"><span class="pre">AOBaseConfig</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.core.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AOBaseConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">Int4WeightOnlyConfig</span>

<span class="c1"># Example configuration</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span>
    <span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">use_hqq</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">AOBaseConfig</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All quantization configurations inherit from <code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.core.config.AOBaseConfig</span></code>, which provides serialization and validation capabilities.</p>
</div>
</section>
<section id="module-level-configuration">
<span id="id4"></span><h3><a class="toc-backref" href="#id14" role="doc-backlink">3. Module-Level Configuration</a><a class="headerlink" href="#module-level-configuration" title="Permalink to this heading">¶</a></h3>
<p>For granular control, use <code class="docutils literal notranslate"><span class="pre">ModuleFqnToConfig</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleFqnToConfig</span><span class="p">,</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">,</span> <span class="n">Int8WeightOnlyConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ModuleFqnToConfig</span><span class="p">({</span>
    <span class="s2">&quot;model.layers.0.self_attn.q_proj&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
    <span class="s2">&quot;model.layers.0.self_attn.k_proj&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
    <span class="s2">&quot;model.layers.0.mlp.gate_proj&quot;</span><span class="p">:</span> <span class="n">Int8WeightOnlyConfig</span><span class="p">(),</span>
    <span class="s2">&quot;_default&quot;</span><span class="p">:</span> <span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Default for other modules</span>
<span class="p">})</span>
</pre></div>
</div>
</section>
</section>
<section id="usage-examples">
<span id="id5"></span><h2><a class="toc-backref" href="#id15" role="doc-backlink">Usage Examples</a><a class="headerlink" href="#usage-examples" title="Permalink to this heading">¶</a></h2>
<section id="quantizing-models-with-huggingface-integration">
<span id="quantizing-models-huggingface"></span><h3><a class="toc-backref" href="#id16" role="doc-backlink">1. Quantizing Models with HuggingFace Integration</a><a class="headerlink" href="#quantizing-models-with-huggingface-integration" title="Permalink to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchAoConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization</span><span class="w"> </span><span class="kn">import</span> <span class="n">Int4WeightOnlyConfig</span>

<span class="c1"># Create quantization configuration</span>
<span class="n">quantization_config</span> <span class="o">=</span> <span class="n">TorchAoConfig</span><span class="p">(</span>
    <span class="n">quant_type</span><span class="o">=</span><span class="n">Int4WeightOnlyConfig</span><span class="p">(</span><span class="n">group_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">use_hqq</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Load and automatically quantize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;meta-llama/Llama-3.2-1B&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span>
<span class="p">)</span>

<span class="c1"># Save quantized model (see Serialization section below for safe_serialization details)</span>
<span class="n">model</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;your-username/Llama-3.2-1B-int4&quot;</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For more information on quantization configs, see <a class="reference internal" href="generated/torchao.quantization.Int4WeightOnlyConfig.html#torchao.quantization.Int4WeightOnlyConfig" title="torchao.quantization.Int4WeightOnlyConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.quantization.Int4WeightOnlyConfig</span></code></a> and <a class="reference internal" href="generated/torchao.quantization.Int8WeightOnlyConfig.html#torchao.quantization.Int8WeightOnlyConfig" title="torchao.quantization.Int8WeightOnlyConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchao.quantization.Int8WeightOnlyConfig</span></code></a>.</p>
</div>
</section>
<section id="serving-with-vllm">
<span id="id6"></span><h3><a class="toc-backref" href="#id17" role="doc-backlink">2. Serving with VLLM</a><a class="headerlink" href="#serving-with-vllm" title="Permalink to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Start VLLM server with TorchAO quantized model</span>
vllm<span class="w"> </span>serve<span class="w"> </span>your-username/Llama-3.2-1B-int4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--quantization<span class="w"> </span>torchao<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
</section>
</section>
<section id="adding-new-quantization-methods-to-vllm">
<span id="adding-new-quantization-methods"></span><h2><a class="toc-backref" href="#id18" role="doc-backlink">Adding New Quantization Methods to VLLM</a><a class="headerlink" href="#adding-new-quantization-methods-to-vllm" title="Permalink to this heading">¶</a></h2>
<section id="minimal-requirements-for-vllm-compatibility">
<span id="minimal-requirements-vllm"></span><h3><a class="toc-backref" href="#id19" role="doc-backlink">Minimal Requirements for VLLM Compatibility</a><a class="headerlink" href="#minimal-requirements-for-vllm-compatibility" title="Permalink to this heading">¶</a></h3>
<p>To make a new TorchAO quantization method work with VLLM, you need to implement minimal tensor subclass operations that support <strong>tensor parallelism</strong>. VLLM uses <code class="docutils literal notranslate"><span class="pre">narrow()</span></code> and <code class="docutils literal notranslate"><span class="pre">copy_()</span></code> to move data from host cpu loaded in a state dict to the device, these  require these specific aten operations:</p>
</section>
<section id="why-these">
<span id="why-these-operations"></span><h3><a class="toc-backref" href="#id20" role="doc-backlink">Why these ?</a><a class="headerlink" href="#why-these" title="Permalink to this heading">¶</a></h3>
<p>VLLM’s tensor parallelism works by:</p>
<ol class="arabic simple">
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.narrow.html#torch.Tensor.narrow" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">narrow()</span></code></a></strong> - Slicing weight tensors across different dimensions</p></li>
<li><p><strong>Sharding</strong> - Distributing tensor chunks across multiple GPUs</p></li>
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.copy_.html#torch.Tensor.copy_" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">copy_()</span></code></a></strong> - Moving tensor data between devices</p></li>
<li><p><strong><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.detach.html#torch.Tensor.detach" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">detach()</span></code></a></strong></p></li>
</ol>
<p>A helpful pattern for doing this is <code class="docutils literal notranslate"><span class="pre">_apply_fn_to_data</span></code>, a method that applies a given function to all the attributes on your class w/ Tensor types. Below is a generic implementation that should work for most subclasses. We make heavy use of this pattern in the torchao codebase:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_apply_fn_to_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Applies a fn to all tensor components stored on this class&quot;&quot;&quot;</span>
    <span class="n">tensor_names</span><span class="p">,</span> <span class="n">ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tensor_flatten__</span><span class="p">()</span>

    <span class="c1"># Apply the function to each tensor component</span>
    <span class="n">new_tensors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tensor_names</span><span class="p">:</span>
        <span class="n">new_tensors</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__tensor_unflatten__</span><span class="p">(</span>
        <span class="n">new_tensors</span><span class="p">,</span>
        <span class="n">ctx</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>  <span class="c1"># outer_size parameter</span>
        <span class="kc">None</span><span class="p">,</span>  <span class="c1"># outer_stride parameter</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="step-by-step-guide-to-add-a-new-quantization-method">
<span id="step-by-step-guide"></span><h2><a class="toc-backref" href="#id21" role="doc-backlink">Step-by-Step Guide to Add a New Quantization Method</a><a class="headerlink" href="#step-by-step-guide-to-add-a-new-quantization-method" title="Permalink to this heading">¶</a></h2>
<section id="create-your-tensor-subclass">
<span id="create-tensor-subclass"></span><h3><a class="toc-backref" href="#id22" role="doc-backlink">1. Create Your Tensor Subclass</a><a class="headerlink" href="#create-your-tensor-subclass" title="Permalink to this heading">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For more details on tensor subclasses and their design principles, please refer to the <a class="reference external" href="https://docs.pytorch.org/ao/stable/subclass_basic.html#what-are-tensor-subclasses">What are Tensor Subclasses?</a> documentation.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.core.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AOBaseConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchAOBaseTensor</span>

<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyNewQuantConfig</span><span class="p">(</span><span class="n">AOBaseConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for your new quantization method&quot;&quot;&quot;</span>
    <span class="n">bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">VERSION</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MyQuantizedTensor</span><span class="p">(</span><span class="n">TorchAOBaseTensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Example based on FbgemmFp8Tensor - stores quantized data + scale&quot;&quot;&quot;</span>

    <span class="n">tensor_data_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;quantized_data&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">]</span>
    <span class="n">tensor_attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">quantized_data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">quantized_data</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">_make_wrapper_subclass</span><span class="p">(</span>
            <span class="bp">cls</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">quantized_data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantized_data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">quantized_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__tensor_flatten__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Serialize tensor subclass into plain tensors and metadata&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_data_attrs</span><span class="p">,</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_attributes</span>
        <span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">__tensor_unflatten__</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">tensor_data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">tensor_attributes</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">outer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">],</span>
        <span class="n">outer_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MyQuantizedTensor&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reconstruct tensor subclass from serialized data&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">tensor_data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">tensor_data_attrs</span><span class="p">],</span>
            <span class="o">*</span><span class="n">tensor_attributes</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="implement-required-vllm-operations">
<span id="implement-vllm-operations"></span><h3><a class="toc-backref" href="#id23" role="doc-backlink">2. Implement Required VLLM Operations</a><a class="headerlink" href="#implement-required-vllm-operations" title="Permalink to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils._python_dispatch</span><span class="w"> </span><span class="kn">import</span> <span class="n">return_and_correct_aliasing</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">detach</span><span class="o">.</span><span class="n">default</span><span class="p">,</span> <span class="n">aten</span><span class="o">.</span><span class="n">alias</span><span class="o">.</span><span class="n">default</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
        <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="p">)</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">_to_copy</span><span class="o">.</span><span class="n">default</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
        <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">)</span>
    <span class="p">)</span>

<span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">([</span><span class="n">aten</span><span class="o">.</span><span class="n">slice</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="n">fill_defaults</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># NOTE the slicing here will likely be different for different quant techniques</span>
        <span class="k">return</span> <span class="n">return_and_correct_aliasing</span><span class="p">(</span>
            <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span>
            <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_apply_fn_to_data</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aten</span><span class="o">.</span><span class="n">slice</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Slicing along dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="register-with-torchao-s-quantization-system">
<span id="register-with-torchao"></span><h3><a class="toc-backref" href="#id24" role="doc-backlink">3. Register with TorchAO’s Quantization System</a><a class="headerlink" href="#register-with-torchao-s-quantization-system" title="Permalink to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization.transform_module</span><span class="w"> </span><span class="kn">import</span> <span class="n">register_quantize_module_handler</span>

<span class="nd">@register_quantize_module_handler</span><span class="p">(</span><span class="n">MyNewQuantConfig</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_my_quant_transform</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">MyNewQuantConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform function that applies your quantization to a module&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span>

    <span class="c1"># Your quantization logic here</span>
    <span class="n">quantized_weight</span> <span class="o">=</span> <span class="n">my_quantization_function</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

    <span class="c1"># Replace the weight with your quantized tensor</span>
    <span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">quantized_weight</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">torchao.quantization.transform_module.register_quantize_module_handler()</span></code> decorator registers your config class with TorchAO’s quantization system.</p>
</div>
</section>
<section id="key-implementation-details">
<span id="id7"></span><h3><a class="toc-backref" href="#id25" role="doc-backlink">Key Implementation Details</a><a class="headerlink" href="#key-implementation-details" title="Permalink to this heading">¶</a></h3>
</section>
<section id="hardware-specific-linear-operations">
<span id="hardware-specific-linear-ops"></span><h3><a class="toc-backref" href="#id26" role="doc-backlink">Hardware-Specific Linear Operations</a><a class="headerlink" href="#hardware-specific-linear-operations" title="Permalink to this heading">¶</a></h3>
<p>Your quantized tensor’s forward pass determines hardware support and what actually gets called when <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.linear.html#torch.nn.functional.linear" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.linear()</span></code></a> is called.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@MyQuantizedTensor</span><span class="o">.</span><span class="n">implements</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># This is where you define what hardware your method supports</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span> <span class="s1">&#39;use_cutlass_kernel&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">my_cutlass_linear</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span> <span class="s1">&#39;use_triton_kernel&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">my_triton_linear</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fallback - dequantize and use standard linear</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
            <span class="n">input_tensor</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">dequantize</span><span class="p">(),</span> <span class="n">bias</span>
        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compilation-benefits">
<span id="id8"></span><h3><a class="toc-backref" href="#id27" role="doc-backlink">Compilation Benefits</a><a class="headerlink" href="#compilation-benefits" title="Permalink to this heading">¶</a></h3>
<p>The overhead of tensor subclasses disappears with <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code></a>, this is on by default in VLLM.</p>
</section>
<section id="trade-off-of-tensor-subclasses">
<span id="trade-off-tensor-subclasses"></span><h3><a class="toc-backref" href="#id28" role="doc-backlink">Trade Off of Tensor Subclasses</a><a class="headerlink" href="#trade-off-of-tensor-subclasses" title="Permalink to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Compilation</strong>: is essential for removing subclass overhead. Without it unless your model is extremely gpu bound the overhead of dispatch on the CPU can severely impact performance.</p></li>
<li><p>The checkpoint defines the behavior of the model. You might be saying “don’t all checkpoints do this”. This is true, however people typically solely think of a torch.Tensor as its data. When in actuality its a true class where it brings the Dispatcher and all the kernels ATen has registered to it. When you define your tensor subclass, you are building a separate little world. One w/ a different representation of data, but also one where you need to explicitly define what ops you support and have implementations for all the hardware you want to support. This can feel a little like spooky action at a distance at first. But it can be very powerful. Case in point is being able to support TP with only 3 definitions.</p></li>
</ol>
</section>
</section>
<section id="serialization-and-model-sharing">
<span id="serialization-model-sharing"></span><h2><a class="toc-backref" href="#id29" role="doc-backlink">Serialization and Model Sharing</a><a class="headerlink" href="#serialization-and-model-sharing" title="Permalink to this heading">¶</a></h2>
<section id="safetensors-support">
<span id="id9"></span><h3><a class="toc-backref" href="#id30" role="doc-backlink">SafeTensors Support</a><a class="headerlink" href="#safetensors-support" title="Permalink to this heading">¶</a></h3>
<p><strong>Current Status</strong>: TorchAO quantized models cannot yet be serialized with safetensors due to tensor subclass limitations. When saving quantized models, you must use <code class="docutils literal notranslate"><span class="pre">safe_serialization=False</span></code>.</p>
<p><strong>Workaround</strong>: For production use, save models with <code class="docutils literal notranslate"><span class="pre">safe_serialization=False</span></code> when pushing to HuggingFace Hub.</p>
<p><strong>Future Work</strong>: The TorchAO team is actively working on safetensors support for tensor subclasses. Track progress at: <a class="reference external" href="https://github.com/pytorch/ao/issues/2338">pytorch/ao#2338</a></p>
</section>
</section>
<section id="integration-architecture-diagrams">
<span id="id10"></span><h2><a class="toc-backref" href="#id31" role="doc-backlink">Integration Architecture Diagrams</a><a class="headerlink" href="#integration-architecture-diagrams" title="Permalink to this heading">¶</a></h2>
<section id="high-level-model-flow-transformers-vllm-torchao">
<span id="high-level-model-flow"></span><h3><a class="toc-backref" href="#id32" role="doc-backlink">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a><a class="headerlink" href="#high-level-model-flow-transformers-vllm-torchao" title="Permalink to this heading">¶</a></h3>
<p>This diagram shows the end-to-end flow from model creation to serving:</p>
<pre  class="mermaid">
        graph LR
    A[HuggingFace Model] --&gt; B[Transformers AutoModel]
    B --&gt; C{Quantization Config?}
    C --&gt;|TorchAO Config| D[Apply TorchAO Quantization]
    C --&gt;|No Config| E[Standard Model]

    D --&gt; F[Quantized Model w/ Tensor Subclasses]
    E --&gt; G[Standard PyTorch Model]

    F --&gt; H[VLLM Model Loading]
    G --&gt; H

    H --&gt; I[VLLM Distributed Engine]
    I --&gt; J[Tensor Parallel Sharding]
    J --&gt; K[Optimized Inference]

    style D fill:#e1f5fe
    style F fill:#f3e5f5
    style J fill:#e8f5e8
    </pre></section>
<section id="torchao-integration-points-in-vllm">
<span id="torchao-integration-points"></span><h3><a class="toc-backref" href="#id33" role="doc-backlink">2. TorchAO Integration Points in VLLM</a><a class="headerlink" href="#torchao-integration-points-in-vllm" title="Permalink to this heading">¶</a></h3>
<p>This shows how VLLM detects and applies TorchAO quantization:</p>
<pre  class="mermaid">
        graph LR
    A[Model Config Detection] --&gt; B{quantization=torchao?}
    B --&gt;|Yes| C[TorchAOConfig.from_config]
    B --&gt;|No| D[Other Quantization Methods]

    C --&gt; E[Parse HF quant_type]
    E --&gt; F[config_from_dict]
    F --&gt; G[AOBaseConfig Instance]

    G --&gt; H[get_quant_method per layer]
    H --&gt; I{Layer Type?}
    I --&gt;|LinearBase| J[TorchAOLinearMethod]
    I --&gt;|Other| K[UnquantizedLinearMethod]

    J --&gt; L[create_weights]
    L --&gt; M[torchao_quantize_param_data]
    M --&gt; N[Quantized Tensor Subclass]

    style C fill:#e1f5fe
    style G fill:#f3e5f5
    style N fill:#e8f5e8
    </pre></section>
<section id="kernel-dispatch-bringing-external-kernels-to-vllm">
<span id="kernel-dispatch"></span><h3><a class="toc-backref" href="#id34" role="doc-backlink">3. Kernel Dispatch: Bringing External Kernels to VLLM</a><a class="headerlink" href="#kernel-dispatch-bringing-external-kernels-to-vllm" title="Permalink to this heading">¶</a></h3>
<p>This illustrates how tensor subclasses enable custom kernel dispatch within VLLM:</p>
<pre  class="mermaid">
        graph LR
    A[F.linear Call in VLLM] --&gt; B[MyQuantTensor torch_function]
    B --&gt; C[Custom implements Handler]
    C --&gt; D{Hardware Check}

    D --&gt; E[Dispatch to External Kernel]
    E --&gt; F[Execute Optimized Kernel]
    F --&gt; G[Return Result to VLLM]

    subgraph &quot;External Libraries&quot;
        H[TorchAO CUTLASS]
        I[TorchAO Triton]
        J[FBGEMM-GPU]
        K[Custom Libraries]
    end

    subgraph &quot;Tensor Subclass Code&quot;
        L[implements F.linear]
        M[custom_linear_impl]
        N[call external kernel]
    end

    E --&gt; H
    E --&gt; I
    E --&gt; J
    E --&gt; K

    C --&gt; L
    L --&gt; M
    M --&gt; N
    N --&gt; E

    style B fill:#e8f6ff,color:#000
    style C fill:#fff3e0,color:#000
    style E fill:#e8f5e8,color:#000
    style L fill:#f3e5f5,color:#000
    </pre></section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="serialization.html" class="btn btn-neutral float-right" title="Serialization" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="serving.html" class="btn btn-neutral" title="(Part 3) Serving on vLLM, SGLang, ExecuTorch" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024-present, torchao Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Integration with VLLM: Architecture and Usage Guide</a><ul>
<li><a class="reference internal" href="#configuration-system">Configuration System</a><ul>
<li><a class="reference internal" href="#huggingface-model-configuration">1. HuggingFace Model Configuration</a></li>
<li><a class="reference internal" href="#torchao-configuration-classes">2. TorchAO Configuration Classes</a></li>
<li><a class="reference internal" href="#module-level-configuration">3. Module-Level Configuration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#usage-examples">Usage Examples</a><ul>
<li><a class="reference internal" href="#quantizing-models-with-huggingface-integration">1. Quantizing Models with HuggingFace Integration</a></li>
<li><a class="reference internal" href="#serving-with-vllm">2. Serving with VLLM</a></li>
</ul>
</li>
<li><a class="reference internal" href="#adding-new-quantization-methods-to-vllm">Adding New Quantization Methods to VLLM</a><ul>
<li><a class="reference internal" href="#minimal-requirements-for-vllm-compatibility">Minimal Requirements for VLLM Compatibility</a></li>
<li><a class="reference internal" href="#why-these">Why these ?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#step-by-step-guide-to-add-a-new-quantization-method">Step-by-Step Guide to Add a New Quantization Method</a><ul>
<li><a class="reference internal" href="#create-your-tensor-subclass">1. Create Your Tensor Subclass</a></li>
<li><a class="reference internal" href="#implement-required-vllm-operations">2. Implement Required VLLM Operations</a></li>
<li><a class="reference internal" href="#register-with-torchao-s-quantization-system">3. Register with TorchAO’s Quantization System</a></li>
<li><a class="reference internal" href="#key-implementation-details">Key Implementation Details</a></li>
<li><a class="reference internal" href="#hardware-specific-linear-operations">Hardware-Specific Linear Operations</a></li>
<li><a class="reference internal" href="#compilation-benefits">Compilation Benefits</a></li>
<li><a class="reference internal" href="#trade-off-of-tensor-subclasses">Trade Off of Tensor Subclasses</a></li>
</ul>
</li>
<li><a class="reference internal" href="#serialization-and-model-sharing">Serialization and Model Sharing</a><ul>
<li><a class="reference internal" href="#safetensors-support">SafeTensors Support</a></li>
</ul>
</li>
<li><a class="reference internal" href="#integration-architecture-diagrams">Integration Architecture Diagrams</a><ul>
<li><a class="reference internal" href="#high-level-model-flow-transformers-vllm-torchao">1. High-Level Model Flow: Transformers → VLLM + TorchAO</a></li>
<li><a class="reference internal" href="#torchao-integration-points-in-vllm">2. TorchAO Integration Points in VLLM</a></li>
<li><a class="reference internal" href="#kernel-dispatch-bringing-external-kernels-to-vllm">3. Kernel Dispatch: Bringing External Kernels to VLLM</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
         <script src="_static/design-tabs.js"></script>
         <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
         <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
         <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
         <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
         <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Disabling "auto-collapsing" of sections on the left side bar. Replace script with commented out sections to reenable. -->
<!--  -->
<script script type="text/javascript">
    var collapsedSections = []
</script>

 
<script type="text/javascript">
  $(document).ready(function () {
    // Patch the "GitHub" link at the top of the page
    // to point to the torchao repo.
    var overwrite = function (_) {
      if ($(this).length > 0) {
        $(this)[0].href = "https://github.com/pytorch/ao"
      }
    }
    // PC
    $(".main-menu a:contains('GitHub')").each(overwrite);
    // Mobile
    e$(".mobile-menu a:contains('Github')").each(overwrite);
  });
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>