
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
  <meta name="robots" content="noindex">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="PyTorch 2 Export Quantization for OpenVINO torch.compile Backend" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://pytorch.org/pt2e_quantization/pt2e_quant_openvino_inductor.html" />
<meta property="og:site_name" content="torchao" />
<meta property="og:description" content="Authors: Daniil Lyakhov, Aamir Nazir, Alexander Suslov, Yamini Nimmagadda, Alexander Kozlov Prerequisites: PyTorch 2 Export Post Training Quantization, How to Write a Quantizer for PyTorch 2 Export..." />
<meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
<meta property="og:image:alt" content="torchao" />
<meta name="description" content="Authors: Daniil Lyakhov, Aamir Nazir, Alexander Suslov, Yamini Nimmagadda, Alexander Kozlov Prerequisites: PyTorch 2 Export Post Training Quantization, How to Write a Quantizer for PyTorch 2 Export..." />

    <title>PyTorch 2 Export Quantization for OpenVINO torch.compile Backend &#8212; torchao main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=b417fedc" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=ca3c1c84" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=e5fbc548" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=f533b996" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pt2e_quantization/pt2e_quant_openvino_inductor';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://raw.githubusercontent.com/pytorch/ao/gh-pages/torchao-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="canonical" href="https://pytorch.org/ao/pt2e_quantization/pt2e_quant_openvino_inductor.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to Write a Quantizer for PyTorch 2 Export Quantization" href="pt2e_quantizer.html" />
    <link rel="prev" title="PyTorch 2 Export Quantization with Intel GPU Backend through Inductor" href="pt2e_quant_xpu_inductor.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main (0.17.0+git41e02b5 )');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->


<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="" class="pytorch-body">
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">

<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>

  
  <div class="navbar-header-items__mobile-logo">
    







  
  
  
  


<a class="navbar-brand logo" href="../index.html">
  
    
    <img src="../_static/img/logo-dark.svg" class="logo__image only-light" alt="torchao - Home"/>
    
    
    <script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="torchao - Home"/>`);</script>
    
  
</a>
  </div>

  
  
  <div class=" navbar-header-items__start">
    
      
      
        <div class="navbar-item">
          







  
  
  
  


<a class="navbar-brand logo" href="../index.html">
  
    
    <img src="../_static/img/logo-dark.svg" class="logo__image only-light" alt="torchao - Home"/>
    
    
    <script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="torchao - Home"/>`);</script>
    
  
</a>
        </div>
      
    
      
      
        
        <div class="navbar-item desktop-only-version">
          
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script>
        </div>
      
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">














<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../workflows/index.html">
              Workflows
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-1">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/training.html">
                  Quantized Training
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/qat.html">
                  Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/inference.html">
                  Quantized Inference
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../api_reference/index.html">
              API Reference
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-2">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_quantization.html">
                  torchao.quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_qat.html">
                  torchao.quantization.qat
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_sparsity.html">
                  torchao.sparsity
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_float8.html">
                  torchao.float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_utils.html">
                  torchao.core
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../eager_tutorials/index.html">
              Tutorials
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-3">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/first_quantization_example.html">
                  First Quantization Example
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/pretraining.html">
                  (Part 1) Pre-training with float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/finetuning.html">
                  (Part 2) Fine-tuning with QAT, QLoRA, and float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serving.html">
                  (Part 3) Serving on vLLM, SGLang, ExecuTorch
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_vllm_integration.html">
                  Integration with VLLM: Architecture and Usage Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_hf_integration.html">
                  Hugging Face Integration
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serialization.html">
                  Serialization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/static_quantization.html">
                  Static Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_basic.html">
                  Writing Your Own Quantized Tensor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_advanced.html">
                  Writing Your Own Quantized Tensor (advanced)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/mxfp8_expert_parallel_training.html">
                  MXFP8 Expert Parallel Training
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../contributing/index.html">
              Contributing
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-4">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/quantization_overview.html">
                  Quantization Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/contributor_guide.html">
                  Contributor Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/sparsity.html">
                  Sparsity Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/benchmarking_api_guide.html">
                  Benchmarking API Guide
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown current active">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal active" href="index.html">
              PT2E Quantization
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-5">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_ptq.html">
                  PyTorch 2 Export Post Training Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_qat.html">
                  PyTorch 2 Export Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_x86_inductor.html">
                  PyTorch 2 Export Quantization with X86 Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_xpu_inductor.html">
                  PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="#">
                  PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quantizer.html">
                  How to Write a Quantizer for PyTorch 2 Export Quantization
                </a>
              </li>
            
          </ul>
        
      </li>
    

    
    
  </ul>
</nav>
</div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
      
        <div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a href="https://pytorch.org" class="pytorch-site-link nav-link nav-external" data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org">
  <span class="pytorch-site-link-text">
    <span>Go to</span>
    <span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
  </span>
</a></div>
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        




  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    <div class="sidebar-header-items__start">
      <div class="navbar-item">
        
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script>
      </div>
    </div>
    

    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">














<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../workflows/index.html">
              Workflows
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-1">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/training.html">
                  Quantized Training
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/qat.html">
                  Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/inference.html">
                  Quantized Inference
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../api_reference/index.html">
              API Reference
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-2">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_quantization.html">
                  torchao.quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_qat.html">
                  torchao.quantization.qat
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_sparsity.html">
                  torchao.sparsity
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_float8.html">
                  torchao.float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_utils.html">
                  torchao.core
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../eager_tutorials/index.html">
              Tutorials
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-3">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/first_quantization_example.html">
                  First Quantization Example
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/pretraining.html">
                  (Part 1) Pre-training with float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/finetuning.html">
                  (Part 2) Fine-tuning with QAT, QLoRA, and float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serving.html">
                  (Part 3) Serving on vLLM, SGLang, ExecuTorch
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_vllm_integration.html">
                  Integration with VLLM: Architecture and Usage Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_hf_integration.html">
                  Hugging Face Integration
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serialization.html">
                  Serialization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/static_quantization.html">
                  Static Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_basic.html">
                  Writing Your Own Quantized Tensor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_advanced.html">
                  Writing Your Own Quantized Tensor (advanced)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/mxfp8_expert_parallel_training.html">
                  MXFP8 Expert Parallel Training
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../contributing/index.html">
              Contributing
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-4">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/quantization_overview.html">
                  Quantization Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/contributor_guide.html">
                  Contributor Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/sparsity.html">
                  Sparsity Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../contributing/benchmarking_api_guide.html">
                  Benchmarking API Guide
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown current active">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal active" href="index.html">
              PT2E Quantization
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-5">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_ptq.html">
                  PyTorch 2 Export Post Training Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_qat.html">
                  PyTorch 2 Export Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_x86_inductor.html">
                  PyTorch 2 Export Quantization with X86 Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quant_xpu_inductor.html">
                  PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="#">
                  PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="pt2e_quantizer.html">
                  How to Write a Quantizer for PyTorch 2 Export Quantization
                </a>
              </li>
            
          </ul>
        
      </li>
    

    
    
  </ul>
</nav>
</div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
        
          <div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a href="https://pytorch.org" class="pytorch-site-link nav-link nav-external" data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org">
  <span class="pytorch-site-link-text">
    <span>Go to</span>
    <span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
  </span>
</a></div>
        
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pt2e_quant_ptq.html">PyTorch 2 Export Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="pt2e_quant_qat.html">PyTorch 2 Export Quantization-Aware Training (QAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="pt2e_quant_x86_inductor.html">PyTorch 2 Export Quantization with X86 Backend through Inductor</a></li>
<li class="toctree-l1"><a class="reference internal" href="pt2e_quant_xpu_inductor.html">PyTorch 2 Export Quantization with Intel GPU Backend through Inductor</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">PyTorch 2 Export Quantization for OpenVINO torch.compile Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="pt2e_quantizer.html">How to Write a <code class="docutils literal notranslate"><span class="pre">Quantizer</span></code> for PyTorch 2 Export Quantization</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



<div id="rtd-footer-container"></div>
      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">PT2E Quantization</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">PyTorch 2...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              

<div id="searchbox"></div>
<div id="pytorch-article">
  <!-- Hidden breadcrumb schema for SEO only -->
  <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
    
    <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <link itemprop="item" href="index.html">
      <meta itemprop="name" content="PT2E Quantization">
      <meta itemprop="position" content="1">
    </div>
    
    <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <meta itemprop="name" content="PyTorch 2 Export Quantization for OpenVINO torch.compile Backend">
      <meta itemprop="position" content="2">
    </div>
  </div>

  
  

  
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="pytorch-2-export-quantization-for-openvino-torch-compile-backend">
<h1>PyTorch 2 Export Quantization for OpenVINO torch.compile Backend<a class="headerlink" href="#pytorch-2-export-quantization-for-openvino-torch-compile-backend" title="Link to this heading">#</a></h1>
<p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Feb 13, 2026 | Last Updated On: Feb 13, 2026</p>
<p><strong>Authors</strong>: <a class="reference external" href="https://github.com/daniil-lyakhov">Daniil Lyakhov</a>,  <a class="reference external" href="https://github.com/anzr299">Aamir Nazir</a>,  <a class="reference external" href="https://github.com/alexsu52">Alexander Suslov</a>, <a class="reference external" href="https://github.com/ynimmaga">Yamini Nimmagadda</a>, <a class="reference external" href="https://github.com/AlexKoff88">Alexander Kozlov</a></p>
<section id="prerequisites">
<span id="pt2e-openvino-prerequisites"></span><h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.pytorch.org/ao/stable/tutorial_source/pt2e_quant_ptq.html">PyTorch 2 Export Post Training Quantization</a></p></li>
<li><p><a class="reference external" href="https://docs.pytorch.org/ao/stable/tutorial_source/pt2e_quantizer.html">How to Write a Quantizer for PyTorch 2 Export Quantization</a></p></li>
</ul>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is an experimental feature, the quantization API is subject to change.</p>
</div>
<p>This tutorial demonstrates how to use <code class="docutils literal notranslate"><span class="pre">OpenVINOQuantizer</span></code> from <a class="reference external" href="https://github.com/openvinotoolkit/nncf/tree/develop">Neural Network Compression Framework (NNCF)</a> in PyTorch 2 Export Quantization flow to generate a quantized model customized for the <a class="reference external" href="https://docs.openvino.ai/2024/openvino-workflow/torch-compile.html">OpenVINO torch.compile backend</a> and explains how to lower the quantized model into the <a class="reference external" href="https://docs.openvino.ai/2024/index.html">OpenVINO</a> representation.
<code class="docutils literal notranslate"><span class="pre">OpenVINOQuantizer</span></code> unlocks the full potential of low-precision OpenVINO kernels due to the placement of quantizers designed specifically for the OpenVINO.</p>
<p>The PyTorch 2 export quantization flow uses <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> to capture the model into a graph and performs quantization transformations on top of the ATen graph.
This approach is expected to have significantly higher model coverage, improved flexibility, and a simplified UX.
OpenVINO backend compiles the FX Graph generated by TorchDynamo into an optimized OpenVINO model.</p>
<p>The quantization flow mainly includes four steps:</p>
<ul class="simple">
<li><p>Step 1: Capture the FX Graph from the eager Model based on the <a class="reference external" href="https://pytorch.org/docs/main/export.html">torch export mechanism</a>.</p></li>
<li><p>Step 2: Apply the PyTorch 2 Export Quantization flow with OpenVINOQuantizer based on the captured FX Graph.</p></li>
<li><p>Step 3: Lower the quantized model into OpenVINO representation with the <a class="reference external" href="https://docs.openvino.ai/2024/openvino-workflow/torch-compile.html">torch.compile</a> API.</p></li>
<li><p>Optional step 4: : Improve quantized model metrics via <a class="reference external" href="https://openvinotoolkit.github.io/nncf/autoapi/nncf/experimental/torch/fx/index.html#nncf.experimental.torch.fx.quantize_pt2e">quantize_pt2e</a> method.</p></li>
</ul>
<p>The high-level architecture of this flow could look like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>float_model(Python)                          Example Input
    \                                              /
     \                                            /
—--------------------------------------------------------
|                         export                       |
—--------------------------------------------------------
                            |
                    FX Graph in ATen
                            |
                            |           OpenVINOQuantizer
                            |                 /
—--------------------------------------------------------
|                      prepare_pt2e                     |
|                           |                           |
|                       Calibrate
|                           |                           |
|                      convert_pt2e                     |
—--------------------------------------------------------
                            |
                     Quantized Model
                            |
—--------------------------------------------------------
|                  Lower into Inductor                  |
—--------------------------------------------------------
                            |
                      OpenVINO model
</pre></div>
</div>
</section>
<section id="post-training-quantization">
<h2>Post Training Quantization<a class="headerlink" href="#post-training-quantization" title="Link to this heading">#</a></h2>
<p>Now, we will walk you through a step-by-step tutorial for how to use it with <a class="reference external" href="https://download.pytorch.org/models/resnet18-f37072fd.pth">torchvision resnet18 model</a>
for post training quantization.</p>
<section id="prerequisite-openvino-and-nncf-installation">
<h3>Prerequisite: OpenVINO and NNCF installation<a class="headerlink" href="#prerequisite-openvino-and-nncf-installation" title="Link to this heading">#</a></h3>
<p>OpenVINO and NNCF could be easily installed via <a class="reference external" href="https://docs.openvino.ai/2024/get-started/install-openvino.html">pip distribution</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>pip
pip<span class="w"> </span>install<span class="w"> </span>openvino<span class="w"> </span>nncf
</pre></div>
</div>
</section>
<section id="capture-fx-graph">
<h3>1. Capture FX Graph<a class="headerlink" href="#capture-fx-graph" title="Link to this heading">#</a></h3>
<p>We will start by performing the necessary imports, capturing the FX Graph from the eager module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">openvino.torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization.pt2e.quantize_pt2e</span><span class="w"> </span><span class="kn">import</span> <span class="n">convert_pt2e</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchao.quantization.pt2e.quantize_pt2e</span><span class="w"> </span><span class="kn">import</span> <span class="n">prepare_pt2e</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">nncf.torch</span>

<span class="c1"># Create the Eager Model</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;resnet18&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">model_name</span><span class="p">](</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set the model to eval mode</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Create the data, using the dummy data here as an example</span>
<span class="n">traced_bs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">traced_bs</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>

<span class="c1"># Capture the FX Graph to be quantized</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">exported_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">)</span><span class="o">.</span><span class="n">module</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="apply-quantization">
<h3>2. Apply Quantization<a class="headerlink" href="#apply-quantization" title="Link to this heading">#</a></h3>
<p>After we capture the FX Module to be quantized, we will import the OpenVINOQuantizer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nncf.experimental.torch.fx</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenVINOQuantizer</span>

<span class="n">quantizer</span> <span class="o">=</span> <span class="n">OpenVINOQuantizer</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">OpenVINOQuantizer</span></code> has several optional parameters that allow tuning the quantization process to get a more accurate model.
Below is the list of essential parameters and their description:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">preset</span></code> - defines quantization scheme for the model. Two types of presets are available:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PERFORMANCE</span></code> (default) - defines symmetric quantization of weights and activations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MIXED</span></code> - weights are quantized with symmetric quantization and the activations are quantized with asymmetric quantization. This preset is recommended for models with non-ReLU and asymmetric activation functions, e.g. ELU, PReLU, GELU, etc.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">preset</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">QuantizationPreset</span><span class="o">.</span><span class="n">MIXED</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_type</span></code> - used to specify quantization scheme required for specific type of the model. Transformer is the only supported special quantization scheme to preserve accuracy after quantization of Transformer models (BERT, Llama, etc.). None is default, i.e. no specific scheme is defined.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">model_type</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">ModelType</span><span class="o">.</span><span class="n">Transformer</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ignored_scope</span></code> - this parameter can be used to exclude some layers from the quantization process to preserve the model accuracy.  For example, when you want to exclude the last layer of the model from quantization.  Below are some examples of how to use this parameter:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Exclude by layer name:</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;layer_1&#39;</span><span class="p">,</span> <span class="s1">&#39;layer_2&#39;</span><span class="p">,</span> <span class="s1">&#39;layer_3&#39;</span><span class="p">]</span>
<span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">ignored_scope</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">IgnoredScope</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">))</span>

<span class="c1">#Exclude by layer type:</span>
<span class="n">types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Conv2d&#39;</span><span class="p">,</span> <span class="s1">&#39;Linear&#39;</span><span class="p">]</span>
<span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">ignored_scope</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">IgnoredScope</span><span class="p">(</span><span class="n">types</span><span class="o">=</span><span class="n">types</span><span class="p">))</span>

<span class="c1">#Exclude by regular expression:</span>
<span class="n">regex</span> <span class="o">=</span> <span class="s1">&#39;.*layer_.*&#39;</span>
<span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">ignored_scope</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">IgnoredScope</span><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="n">regex</span><span class="p">))</span>

<span class="c1">#Exclude by subgraphs:</span>
<span class="c1"># In this case, all nodes along all simple paths in the graph</span>
<span class="c1"># from input to output nodes will be excluded from the quantization process.</span>
<span class="n">subgraph</span> <span class="o">=</span> <span class="n">nncf</span><span class="o">.</span><span class="n">Subgraph</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;layer_1&#39;</span><span class="p">,</span> <span class="s1">&#39;layer_2&#39;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;layer_3&#39;</span><span class="p">])</span>
<span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">ignored_scope</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">IgnoredScope</span><span class="p">(</span><span class="n">subgraphs</span><span class="o">=</span><span class="p">[</span><span class="n">subgraph</span><span class="p">]))</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_device</span></code> - defines the target device, the specificity of which will be taken into account during optimization. The following values are supported: <code class="docutils literal notranslate"><span class="pre">ANY</span></code> (default), <code class="docutils literal notranslate"><span class="pre">CPU</span></code>, <code class="docutils literal notranslate"><span class="pre">CPU_SPR</span></code>, <code class="docutils literal notranslate"><span class="pre">GPU</span></code>, and <code class="docutils literal notranslate"><span class="pre">NPU</span></code>.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">OpenVINOQuantizer</span><span class="p">(</span><span class="n">target_device</span><span class="o">=</span><span class="n">nncf</span><span class="o">.</span><span class="n">TargetDevice</span><span class="o">.</span><span class="n">CPU</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<p>For further details on <cite>OpenVINOQuantizer</cite> please see the <a class="reference external" href="https://openvinotoolkit.github.io/nncf/autoapi/nncf/experimental/torch/fx/index.html#nncf.experimental.torch.fx.OpenVINOQuantizer">documentation</a>.</p>
<p>After we import the backend-specific Quantizer, we will prepare the model for post-training quantization.
<code class="docutils literal notranslate"><span class="pre">prepare_pt2e</span></code> folds BatchNorm operators into preceding Conv2d operators, and inserts observers in appropriate places in the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_pt2e</span><span class="p">(</span><span class="n">exported_model</span><span class="p">,</span> <span class="n">quantizer</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, we will calibrate the <code class="docutils literal notranslate"><span class="pre">prepared_model</span></code> after the observers are inserted in the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># We use the dummy data as an example here</span>
<span class="n">prepared_model</span><span class="p">(</span><span class="o">*</span><span class="n">example_inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we will convert the calibrated Model to a quantized Model. <code class="docutils literal notranslate"><span class="pre">convert_pt2e</span></code> takes a calibrated model and produces a quantized model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">convert_pt2e</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span> <span class="n">fold_quantize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>After these steps, we finished running the quantization flow, and we will get the quantized model.</p>
</section>
<section id="lower-into-openvino-representation">
<h3>3. Lower into OpenVINO representation<a class="headerlink" href="#lower-into-openvino-representation" title="Link to this heading">#</a></h3>
<p>After that the FX Graph can utilize OpenVINO optimizations using <a class="reference external" href="https://docs.openvino.ai/2024/openvino-workflow/torch-compile.html">torch.compile(…, backend=”openvino”)</a> functionality.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;openvino&quot;</span><span class="p">)</span>

    <span class="c1"># Running some benchmark</span>
    <span class="n">optimized_model</span><span class="p">(</span><span class="o">*</span><span class="n">example_inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>The optimized model is using low-level kernels designed specifically for Intel CPU.
This should significantly speed up inference time in comparison with the eager model.</p>
</section>
<section id="optional-improve-quantized-model-metrics">
<h3>4. Optional: Improve quantized model metrics<a class="headerlink" href="#optional-improve-quantized-model-metrics" title="Link to this heading">#</a></h3>
<p>NNCF implements advanced quantization algorithms like <a class="reference external" href="https://arxiv.org/abs/2211.10438">SmoothQuant</a> and <a class="reference external" href="https://arxiv.org/abs/1906.04721">BiasCorrection</a>, which help
to improve the quantized model metrics while minimizing the output discrepancies between the original and compressed models.
These advanced NNCF algorithms can be accessed via the NNCF <cite>quantize_pt2e</cite> API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nncf.experimental.torch.fx</span><span class="w"> </span><span class="kn">import</span> <span class="n">quantize_pt2e</span>

<span class="n">calibration_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">transform_fn</span><span class="p">(</span><span class="n">data_item</span><span class="p">):</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_item</span>
    <span class="k">return</span> <span class="n">images</span>


<span class="n">calibration_dataset</span> <span class="o">=</span> <span class="n">nncf</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">calibration_loader</span><span class="p">,</span> <span class="n">transform_fn</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">exported_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">)</span><span class="o">.</span><span class="n">module</span><span class="p">()</span>

<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantize_pt2e</span><span class="p">(</span>
    <span class="n">exported_model</span><span class="p">,</span> <span class="n">quantizer</span><span class="p">,</span> <span class="n">calibration_dataset</span><span class="p">,</span> <span class="n">smooth_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fast_bias_correction</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For further details, please see the <a class="reference external" href="https://openvinotoolkit.github.io/nncf/autoapi/nncf/experimental/torch/fx/index.html#nncf.experimental.torch.fx.quantize_pt2e">documentation</a>
and a complete <a class="reference external" href="https://github.com/openvinotoolkit/nncf/blob/develop/examples/post_training_quantization/torch_fx/resnet18/README.md">example on Resnet18 quantization</a>.</p>
</section>
</section>
<section id="conclusion">
<span id="pt2e-quant-openvino-inductor-conclusion"></span><h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>This tutorial introduces how to use torch.compile with the OpenVINO backend and the OpenVINO quantizer.
For more details on NNCF and the NNCF Quantization Flow for PyTorch models, refer to the <a class="reference external" href="https://docs.openvino.ai/2025/openvino-workflow/model-optimization-guide/quantizing-models-post-training/basic-quantization-flow.html.">NNCF Quantization Guide</a>.
For additional information, check out the <a class="reference external" href="https://docs.openvino.ai/2024/openvino-workflow/torch-compile.html">OpenVINO Deployment via torch.compile Documentation</a>.</p>
</section>
</section>


                </article>
              
</div>

              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="pt2e_quant_xpu_inductor.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">PyTorch 2 Export Quantization with Intel GPU Backend through Inductor</p>
      </div>
    </a>
    <a class="right-next"
       href="pt2e_quantizer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">How to Write a <code class="docutils literal notranslate"><span class="pre">Quantizer</span></code> for PyTorch 2 Export Quantization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pt2e_quant_xpu_inductor.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">PyTorch 2 Export Quantization with Intel GPU Backend through Inductor</p>
      </div>
    </a>
    <a class="right-next"
       href="pt2e_quantizer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">How to Write a <code class="docutils literal notranslate"><span class="pre">Quantizer</span></code> for PyTorch 2 Export Quantization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training-quantization">Post Training Quantization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisite-openvino-and-nncf-installation">Prerequisite: OpenVINO and NNCF installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capture-fx-graph">1. Capture FX Graph</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-quantization">2. Apply Quantization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lower-into-openvino-representation">3. Lower into OpenVINO representation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-improve-quantized-model-metrics">4. Optional: Improve quantized model metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/ao/edit/main/docs/source/pt2e_quantization/pt2e_quant_openvino_inductor.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/pt2e_quantization/pt2e_quant_openvino_inductor.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024-present, torchao Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend",
       "headline": "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/pt2e_quantization/pt2e_quant_openvino_inductor.html",
       "articleBody": "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend# Created On: Feb 13, 2026 | Last Updated On: Feb 13, 2026 Authors: Daniil Lyakhov, Aamir Nazir, Alexander Suslov, Yamini Nimmagadda, Alexander Kozlov Prerequisites# PyTorch 2 Export Post Training Quantization How to Write a Quantizer for PyTorch 2 Export Quantization Introduction# Note This is an experimental feature, the quantization API is subject to change. This tutorial demonstrates how to use OpenVINOQuantizer from Neural Network Compression Framework (NNCF) in PyTorch 2 Export Quantization flow to generate a quantized model customized for the OpenVINO torch.compile backend and explains how to lower the quantized model into the OpenVINO representation. OpenVINOQuantizer unlocks the full potential of low-precision OpenVINO kernels due to the placement of quantizers designed specifically for the OpenVINO. The PyTorch 2 export quantization flow uses torch.export to capture the model into a graph and performs quantization transformations on top of the ATen graph. This approach is expected to have significantly higher model coverage, improved flexibility, and a simplified UX. OpenVINO backend compiles the FX Graph generated by TorchDynamo into an optimized OpenVINO model. The quantization flow mainly includes four steps: Step 1: Capture the FX Graph from the eager Model based on the torch export mechanism. Step 2: Apply the PyTorch 2 Export Quantization flow with OpenVINOQuantizer based on the captured FX Graph. Step 3: Lower the quantized model into OpenVINO representation with the torch.compile API. Optional step 4: : Improve quantized model metrics via quantize_pt2e method. The high-level architecture of this flow could look like this: float_model(Python) Example Input \\ / \\ / \u2014-------------------------------------------------------- | export | \u2014-------------------------------------------------------- | FX Graph in ATen | | OpenVINOQuantizer | / \u2014-------------------------------------------------------- | prepare_pt2e | | | | | Calibrate | | | | convert_pt2e | \u2014-------------------------------------------------------- | Quantized Model | \u2014-------------------------------------------------------- | Lower into Inductor | \u2014-------------------------------------------------------- | OpenVINO model Post Training Quantization# Now, we will walk you through a step-by-step tutorial for how to use it with torchvision resnet18 model for post training quantization. Prerequisite: OpenVINO and NNCF installation# OpenVINO and NNCF could be easily installed via pip distribution: pip install -U pip pip install openvino nncf 1. Capture FX Graph# We will start by performing the necessary imports, capturing the FX Graph from the eager module. import openvino.torch import torch import torchvision.models as models from torchao.quantization.pt2e.quantize_pt2e import convert_pt2e from torchao.quantization.pt2e.quantize_pt2e import prepare_pt2e import nncf.torch # Create the Eager Model model_name = \"resnet18\" model = models.__dict__[model_name](pretrained=True) # Set the model to eval mode model = model.eval() # Create the data, using the dummy data here as an example traced_bs = 50 x = torch.randn(traced_bs, 3, 224, 224) example_inputs = (x,) # Capture the FX Graph to be quantized with torch.no_grad(): exported_model = torch.export.export(model, example_inputs).module() 2. Apply Quantization# After we capture the FX Module to be quantized, we will import the OpenVINOQuantizer. from nncf.experimental.torch.fx import OpenVINOQuantizer quantizer = OpenVINOQuantizer() OpenVINOQuantizer has several optional parameters that allow tuning the quantization process to get a more accurate model. Below is the list of essential parameters and their description: preset - defines quantization scheme for the model. Two types of presets are available: PERFORMANCE (default) - defines symmetric quantization of weights and activations MIXED - weights are quantized with symmetric quantization and the activations are quantized with asymmetric quantization. This preset is recommended for models with non-ReLU and asymmetric activation functions, e.g. ELU, PReLU, GELU, etc. OpenVINOQuantizer(preset=nncf.QuantizationPreset.MIXED) model_type - used to specify quantization scheme required for specific type of the model. Transformer is the only supported special quantization scheme to preserve accuracy after quantization of Transformer models (BERT, Llama, etc.). None is default, i.e. no specific scheme is defined. OpenVINOQuantizer(model_type=nncf.ModelType.Transformer) ignored_scope - this parameter can be used to exclude some layers from the quantization process to preserve the model accuracy. For example, when you want to exclude the last layer of the model from quantization. Below are some examples of how to use this parameter: #Exclude by layer name: names = [\u0027layer_1\u0027, \u0027layer_2\u0027, \u0027layer_3\u0027] OpenVINOQuantizer(ignored_scope=nncf.IgnoredScope(names=names)) #Exclude by layer type: types = [\u0027Conv2d\u0027, \u0027Linear\u0027] OpenVINOQuantizer(ignored_scope=nncf.IgnoredScope(types=types)) #Exclude by regular expression: regex = \u0027.*layer_.*\u0027 OpenVINOQuantizer(ignored_scope=nncf.IgnoredScope(patterns=regex)) #Exclude by subgraphs: # In this case, all nodes along all simple paths in the graph # from input to output nodes will be excluded from the quantization process. subgraph = nncf.Subgraph(inputs=[\u0027layer_1\u0027, \u0027layer_2\u0027], outputs=[\u0027layer_3\u0027]) OpenVINOQuantizer(ignored_scope=nncf.IgnoredScope(subgraphs=[subgraph])) target_device - defines the target device, the specificity of which will be taken into account during optimization. The following values are supported: ANY (default), CPU, CPU_SPR, GPU, and NPU. OpenVINOQuantizer(target_device=nncf.TargetDevice.CPU) For further details on OpenVINOQuantizer please see the documentation. After we import the backend-specific Quantizer, we will prepare the model for post-training quantization. prepare_pt2e folds BatchNorm operators into preceding Conv2d operators, and inserts observers in appropriate places in the model. prepared_model = prepare_pt2e(exported_model, quantizer) Now, we will calibrate the prepared_model after the observers are inserted in the model. # We use the dummy data as an example here prepared_model(*example_inputs) Finally, we will convert the calibrated Model to a quantized Model. convert_pt2e takes a calibrated model and produces a quantized model. quantized_model = convert_pt2e(prepared_model, fold_quantize=False) After these steps, we finished running the quantization flow, and we will get the quantized model. 3. Lower into OpenVINO representation# After that the FX Graph can utilize OpenVINO optimizations using torch.compile(\u2026, backend=\u201dopenvino\u201d) functionality. with torch.no_grad(): optimized_model = torch.compile(quantized_model, backend=\"openvino\") # Running some benchmark optimized_model(*example_inputs) The optimized model is using low-level kernels designed specifically for Intel CPU. This should significantly speed up inference time in comparison with the eager model. 4. Optional: Improve quantized model metrics# NNCF implements advanced quantization algorithms like SmoothQuant and BiasCorrection, which help to improve the quantized model metrics while minimizing the output discrepancies between the original and compressed models. These advanced NNCF algorithms can be accessed via the NNCF quantize_pt2e API: from nncf.experimental.torch.fx import quantize_pt2e calibration_loader = torch.utils.data.DataLoader(...) def transform_fn(data_item): images, _ = data_item return images calibration_dataset = nncf.Dataset(calibration_loader, transform_fn) with torch.no_grad(): exported_model = torch.export.export(model, example_inputs).module() quantized_model = quantize_pt2e( exported_model, quantizer, calibration_dataset, smooth_quant=True, fast_bias_correction=False ) For further details, please see the documentation and a complete example on Resnet18 quantization. Conclusion# This tutorial introduces how to use torch.compile with the OpenVINO backend and the OpenVINO quantizer. For more details on NNCF and the NNCF Quantization Flow for PyTorch models, refer to the NNCF Quantization Guide. For additional information, check out the OpenVINO Deployment via torch.compile Documentation.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/pt2e_quantization/pt2e_quant_openvino_inductor.html"
       },
       "datePublished": "Feb 13, 2026T00:00:00Z",
       "dateModified": "Feb 13, 2026T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>