Search.setIndex({"docnames": ["api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.FqnToConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.FqnToConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [1, 7, 8, 9, 11, 17, 18, 23, 24, 25, 26, 28, 29, 30, 34, 39, 40, 45, 47, 49, 50, 52, 53, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90], "section": [1, 9, 68, 72, 76, 81, 86, 87, 90], "introduc": [1, 11, 85, 86, 88, 89, 90], "dive": 1, "detail": [1, 7, 9, 11, 71, 72, 73, 75, 76, 77, 79, 85, 86, 87, 88], "how": [1, 3, 9, 11, 19, 24, 26, 28, 45, 57, 58, 61, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 85, 88, 89], "integr": [1, 9, 69, 71, 74, 75, 76, 79, 88, 90], "pytorch": [1, 7, 11, 27, 45, 68, 69, 71, 72, 75, 76, 79, 81, 84], "optim": [1, 9, 11, 17, 56, 69, 71, 76, 79, 85, 87, 88, 89], "your": [1, 7, 9, 11, 69, 71, 72, 73, 75, 76, 80, 86, 87, 88, 89, 90], "machin": [1, 87], "learn": [1, 45, 73, 76, 84, 86, 88, 89, 90], "model": [1, 11, 17, 23, 32, 37, 40, 41, 42, 43, 44, 47, 51, 56, 64, 65, 67, 76, 77, 79, 88, 89, 90], "quantiz": [1, 7, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 67, 71, 74, 76], "sparsiti": [1, 7, 11, 63, 64, 65, 66, 67, 69, 71, 74, 75], "tba": [2, 10, 70], "For": [3, 7, 9, 11, 45, 72, 73, 74, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89, 90], "full": [3, 11, 73, 77, 80, 84, 85, 87], "exampl": [3, 7, 9, 11, 17, 26, 32, 34, 35, 40, 44, 45, 47, 51, 56, 57, 64, 67, 68, 72, 74, 75, 76, 77, 79, 82, 84, 85, 86, 87, 88, 89], "us": [3, 7, 8, 11, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 32, 37, 40, 44, 45, 47, 52, 53, 57, 58, 61, 64, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89], "our": [3, 9, 11, 71, 73, 75, 76, 77, 79, 86, 87], "pleas": [3, 8, 9, 11, 40, 44, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89, 90], "refer": [3, 7, 11, 47, 53, 71, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88], "readm": [3, 7, 11, 69, 73, 76], "tutori": [7, 9, 11, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90], "you": [7, 8, 9, 11, 45, 64, 71, 72, 73, 74, 75, 76, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90], "through": [7, 9, 11, 29, 34, 35, 69, 72, 73, 75, 77, 79, 81, 84, 85, 86, 90], "torchao": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 73, 74, 75, 76, 77, 79, 80, 85, 86, 87, 88, 89], "framework": [7, 9, 11, 71, 75, 85], "The": [7, 9, 11, 16, 18, 20, 21, 31, 47, 56, 62, 64, 71, 72, 73, 74, 75, 76, 79, 80, 81, 85, 86, 87, 88, 89, 90], "contain": [7, 59, 60, 76, 79, 87, 90], "new": [7, 11, 68, 71, 72, 77, 79, 86, 87, 88, 90], "architectur": [7, 69, 75, 76, 85, 86, 88, 89], "micro": 7, "current": [7, 18, 22, 23, 37, 38, 47, 56, 64, 67, 71, 72, 73, 76, 79, 80, 81, 86, 87, 89], "support": [7, 11, 18, 19, 21, 22, 23, 37, 44, 45, 47, 57, 59, 60, 67, 68, 71, 72, 73, 74, 75, 76, 79, 85, 86, 87, 88, 89, 90], "which": [7, 9, 11, 47, 52, 57, 71, 72, 74, 75, 76, 77, 81, 85, 86, 87, 88, 89, 90], "can": [7, 9, 11, 18, 26, 32, 45, 56, 57, 61, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89, 90], "quantize_": [7, 9, 11, 40, 44, 47, 56, 57, 58, 59, 60, 67, 69, 72, 73, 74, 75, 77], "sparsity_": 7, "function": [7, 11, 16, 34, 39, 49, 54, 55, 56, 63, 64, 65, 67, 68, 71, 72, 73, 74, 76, 77, 79, 81, 85, 90], "To": [7, 9, 11, 21, 53, 71, 72, 73, 74, 75, 76, 77, 81, 86, 87, 88, 90], "correspond": [7, 11, 40, 47, 56, 72, 74, 76, 79, 89, 90], "string": [7, 13, 45, 64, 68], "string_to_config": 7, "microbenchmark": 7, "util": [7, 9, 68, 69, 72, 74, 79, 81, 85, 86, 87, 88, 89, 90], "py": [7, 9, 68, 83, 84, 88, 89], "def": [7, 9, 11, 59, 67, 68, 71, 72, 73, 74, 77, 79, 81, 85, 86, 87, 88, 89, 90], "option": [7, 9, 12, 13, 16, 18, 21, 24, 25, 28, 29, 30, 34, 35, 37, 38, 42, 44, 45, 47, 49, 50, 56, 57, 60, 61, 64, 67, 68, 71, 72, 73, 80, 81, 86, 87, 88, 89, 90], "str": [7, 13, 16, 21, 45, 47, 56, 64, 67, 68, 71, 79, 81, 89], "kwarg": [7, 9, 34, 35, 36, 37, 41, 45, 50, 60, 63, 64, 65, 68, 72, 79, 81], "aobaseconfig": [7, 21, 47, 56, 67, 77, 81], "code": [7, 9, 71, 72, 73, 75, 76, 77, 79, 82, 84, 86, 87, 88, 89, 90], "elif": [7, 81], "my_new_quant": 7, "If": [7, 8, 9, 11, 16, 18, 24, 25, 31, 44, 45, 47, 62, 64, 68, 72, 75, 76, 79, 86, 87], "addit": [7, 11, 68, 71, 72, 76, 79, 80, 85, 86, 89, 90], "inform": [7, 18, 68, 72, 75, 76, 81, 85, 86], "need": [7, 9, 11, 18, 34, 39, 49, 58, 59, 60, 63, 64, 68, 72, 74, 75, 76, 79, 81, 86, 87, 88, 90], "pass": [7, 16, 24, 29, 34, 35, 39, 47, 49, 63, 68, 72, 77, 79, 81, 87, 90], "process": [7, 11, 72, 76, 84, 85, 89], "here": [7, 8, 47, 53, 61, 72, 73, 74, 75, 77, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90], "return": [7, 9, 11, 16, 31, 45, 56, 62, 67, 68, 71, 72, 73, 74, 77, 79, 81, 85, 86, 87, 88, 89, 90], "mynewquantizationconfig": 7, "my_new_spars": 7, "mynewsparsityconfig": 7, "rest": [7, 58, 79, 87], "now": [7, 9, 11, 19, 22, 28, 71, 72, 73, 76, 77, 79, 80, 85, 86, 88, 90], "we": [7, 9, 11, 21, 22, 24, 26, 28, 29, 30, 44, 45, 47, 53, 56, 61, 67, 68, 71, 72, 73, 74, 75, 76, 77, 80, 81, 85, 86, 87, 88, 89, 90], "throughout": 7, "note": [7, 9, 11, 21, 32, 44, 53, 64, 68, 72, 73, 75, 76, 79, 81, 87, 88, 89], "input": [7, 9, 13, 16, 17, 28, 29, 30, 31, 47, 51, 56, 61, 62, 64, 67, 71, 72, 73, 75, 77, 79, 85, 86, 87, 88, 89, 90], "paramet": [7, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 37, 38, 45, 47, 50, 52, 53, 56, 61, 62, 64, 67, 68, 71, 72, 74, 75, 76, 79, 81, 85, 86], "like": [7, 9, 11, 18, 68, 71, 72, 73, 74, 76, 79, 80, 81, 85, 86, 87, 88, 89, 90], "bit": [7, 11, 46, 75, 79, 80, 81, 86, 88, 89], "width": [7, 46], "group": [7, 9, 11, 18, 19, 23, 25, 37, 41, 42, 43, 45, 49, 50, 52, 53, 57], "size": [7, 9, 22, 23, 25, 28, 30, 45, 61, 71, 74, 75, 76, 77, 79, 81, 87], "etc": [7, 9, 18, 34, 35, 58, 60, 72, 85, 90], "them": [7, 11, 21, 34, 39, 49, 63, 90], "append": [7, 76, 86, 87], "config": [7, 11, 13, 16, 18, 20, 21, 22, 24, 33, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 56, 64, 67, 72, 73, 75, 76, 77, 80, 81, 86, 88, 89], "gemliteuintxweightonlyconfig": 7, "gemlitewo": 7, "bit_width": 7, "group_siz": [7, 11, 19, 22, 23, 25, 34, 35, 37, 41, 44, 45, 47, 49, 50, 56, 80, 81], "system": [7, 9, 58, 75], "model_architectur": 7, "type": [7, 9, 11, 13, 14, 15, 16, 18, 20, 21, 23, 24, 26, 27, 31, 45, 48, 56, 57, 58, 59, 60, 61, 62, 68, 69, 72, 73, 74, 75, 76, 79, 81, 85, 86, 88, 89, 90], "defin": [7, 9, 14, 34, 39, 49, 63, 64, 68, 72, 73, 76, 77, 79, 81, 85, 88, 89, 90], "class": [7, 9, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 63, 64, 68, 73, 74, 77, 79, 86, 87, 88, 90], "mycustommodel": 7, "torch": [7, 11, 13, 16, 18, 20, 28, 30, 31, 34, 35, 37, 38, 41, 42, 43, 44, 45, 47, 49, 50, 52, 53, 56, 57, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 88, 89, 90], "nn": [7, 9, 11, 13, 16, 32, 37, 41, 44, 47, 56, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 81, 86, 87, 88, 90], "modul": [7, 9, 11, 13, 14, 15, 16, 17, 21, 26, 27, 32, 34, 36, 37, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 63, 64, 67, 71, 72, 73, 74, 77, 81, 85, 86, 87, 88, 89, 90], "__init__": [7, 11, 68, 73, 74, 77, 79, 81, 86, 87, 88], "self": [7, 11, 68, 73, 74, 77, 79, 81, 86, 87, 88], "input_dim": [7, 73], "output_dim": [7, 73], "dtype": [7, 9, 11, 12, 18, 20, 27, 28, 29, 30, 34, 35, 37, 38, 41, 42, 43, 45, 49, 50, 52, 53, 60, 61, 67, 71, 73, 74, 75, 77, 79, 80, 81, 86, 88, 89, 90], "bfloat16": [7, 37, 42, 52, 61, 71, 72, 73, 74, 75, 76, 77, 80, 81, 88, 89], "super": [7, 11, 73, 74, 77, 79, 86, 87, 88], "layer1": 7, "linear": [7, 9, 11, 13, 16, 18, 19, 20, 23, 24, 25, 32, 35, 37, 42, 43, 44, 47, 52, 53, 54, 55, 56, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 85, 86, 87, 88, 90], "512": [7, 71], "bia": [7, 11, 35, 52, 53, 72, 73, 74, 77, 79, 81, 87, 90], "fals": [7, 11, 13, 24, 28, 34, 35, 43, 44, 45, 47, 49, 50, 52, 53, 64, 71, 72, 73, 74, 75, 77, 79, 80, 81, 85, 86, 87, 89, 90], "activ": [7, 11, 18, 23, 24, 34, 35, 37, 43, 44, 45, 47, 53, 59, 60, 64, 69, 75, 76, 77, 80, 81, 85, 88, 89, 90], "relu": [7, 73, 85, 90], "layer2": 7, "forward": [7, 24, 34, 35, 39, 46, 49, 52, 63, 73, 74, 76, 77, 79, 81, 86, 87, 88], "x": [7, 34, 35, 39, 46, 49, 71, 73, 74, 75, 77, 79, 81, 84, 85, 86, 87, 88, 89], "updat": [7, 69, 73, 74, 76, 86, 87, 90], "create_model_and_input_data": 7, "handl": [7, 9], "model_typ": [7, 11, 81, 85], "m": [7, 9, 11, 56, 67, 71, 73, 74, 75, 77, 79, 86, 87, 88], "int": [7, 11, 18, 20, 21, 22, 23, 24, 25, 28, 29, 30, 34, 35, 37, 41, 42, 43, 45, 49, 50, 52, 53, 56, 61, 64, 68, 77, 79, 81], "k": [7, 9, 62, 74, 77, 79, 86, 87], "n": [7, 9, 11, 74, 77, 79, 86, 87, 90], "high_precision_dtyp": 7, "devic": [7, 9, 11, 49, 52, 53, 56, 62, 71, 73, 74, 75, 77, 79, 81, 85, 86, 87, 88, 89], "cuda": [7, 9, 11, 56, 71, 73, 74, 75, 76, 77, 79, 80, 87], "my_custom_model": 7, "input_data": 7, "randn": [7, 11, 35, 71, 73, 74, 77, 79, 85, 86, 87, 88, 89], "when": [7, 9, 11, 21, 28, 30, 47, 61, 68, 71, 72, 75, 76, 77, 80, 81, 85, 86, 87, 88, 89, 90], "ad": [7, 11, 30, 64, 68, 72, 76, 77, 79, 87], "dimens": [7, 9, 28, 30, 31, 61, 71, 72, 79, 81, 86, 87], "ensur": [7, 75, 87], "convent": 7, "where": [7, 26, 29, 41, 42, 43, 72, 76, 81, 90], "batch": [7, 75, 77, 87], "sequenc": 7, "length": 7, "featur": [7, 11, 79, 85, 88, 89], "data": [7, 11, 18, 20, 24, 29, 58, 68, 69, 72, 74, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89, 90], "typic": [7, 11, 72, 73, 74, 77, 81, 90], "compat": [7, 9, 45, 73], "work": [7, 9, 11, 71, 74, 76, 79, 80, 81, 86, 87, 88], "cpu": [7, 9, 74, 76, 77, 80, 81, 85, 86, 87, 88], "other": [7, 11, 18, 46, 57, 64, 71, 74, 75, 76, 79, 81, 84, 86, 87, 88, 90], "target": [7, 9, 11, 18, 20, 22, 28, 34, 35, 38, 45, 64, 73, 76, 85, 86, 87, 88, 89, 90], "method": [7, 9, 56, 64, 68, 73, 76, 77, 79, 80, 85, 86, 87, 89, 90], "come": [7, 8, 71, 72, 75, 76, 77, 78, 80, 87, 88, 89], "soon": [7, 8, 75, 78, 87], "file": [7, 9, 71, 73, 75, 79, 81, 83, 86, 87], "microbenchmark_quantization_config": 7, "yml": 7, "benchmark_mod": 7, "infer": [7, 11, 47, 69, 72, 73, 74, 76, 77, 79, 80, 85, 86, 87, 88, 89], "quantization_config_recipe_nam": 7, "int8wo": [7, 80], "int8dq": 7, "float8dq": [7, 75], "tensor": [7, 11, 12, 20, 22, 23, 24, 25, 28, 29, 30, 31, 34, 35, 36, 38, 39, 46, 57, 58, 59, 60, 61, 62, 64, 68, 69, 71, 73, 74, 76, 77, 80, 84, 86, 88, 89], "row": [7, 9, 19, 31, 71, 72, 76], "float8wo": 7, "output_dir": [7, 80], "result": [7, 11, 31, 62, 72, 73, 76, 77, 80, 86, 87, 88, 89, 90], "model_param": 7, "name": [7, 9, 14, 15, 21, 26, 27, 48, 56, 57, 58, 64, 67, 68, 72, 75, 76, 79, 81, 85, 86, 87, 90], "small_bf16_linear": 7, "matrix_shap": 7, "small_sweep": 7, "min_pow": 7, "10": [7, 9, 11, 26, 34, 61, 71, 73, 75, 77, 86, 87], "max_pow": 7, "15": [7, 68, 71, 75], "torch_compile_mod": 7, "max": [7, 9, 26, 72, 73, 77, 79, 86, 87, 90], "autotun": [7, 9, 73, 77], "runner": 7, "gener": [7, 11, 34, 35, 36, 39, 46, 72, 73, 75, 76, 77, 79, 81, 82, 84, 85, 87, 88, 89, 90], "oss": 7, "databas": 7, "python": [7, 9, 21, 73, 75, 76, 82, 84, 85, 86, 88, 89], "ci_microbenchmark_runn": 7, "benchmark_result": 7, "json": [7, 75, 81], "specif": [7, 9, 11, 34, 35, 53, 58, 64, 71, 72, 74, 75, 76, 80, 85, 88, 89, 90], "requir": [7, 11, 57, 68, 72, 73, 75, 76, 79, 80, 85, 88, 90], "mode": [7, 9, 73, 77, 85, 87, 88, 89, 90], "extra_info": 7, "arch": 7, "nvidia": [7, 76], "a100": [7, 11, 80], "sxm4": 7, "80gb": 7, "1024": [7, 56, 67, 73, 74, 88], "custom": [7, 11, 47, 63, 69, 71, 72, 76, 79, 81, 85, 86, 88, 90], "layer": [7, 16, 18, 20, 21, 24, 25, 34, 35, 37, 41, 42, 43, 49, 50, 52, 53, 64, 65, 71, 75, 76, 77, 79, 81, 85, 90], "origin": [7, 11, 20, 24, 40, 61, 64, 72, 73, 74, 75, 76, 85, 86, 90], "metric": [7, 11, 64], "speedup": [7, 9, 11, 71, 72, 75, 76], "wrt": 7, "bf16": [7, 11, 28, 47, 76, 88, 89], "benchmark_valu": 7, "25": 7, "target_valu": 7, "0": [7, 9, 11, 21, 34, 45, 49, 50, 61, 64, 68, 71, 72, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 89, 90], "depend": [7, 74, 76, 79, 86, 87, 89], "step": [7, 11, 17, 47, 48, 71, 72, 76, 85, 86, 87, 88, 89, 90], "workflow": [7, 9, 56, 57, 67, 71, 73, 76, 90], "github": [7, 73, 75, 80], "action": [7, 81, 86, 87], "upload": 7, "verifi": [7, 73, 74, 79], "setup": [7, 75], "suit": [7, 9, 86, 88], "unittest": 7, "discov": 7, "out": [7, 9, 11, 26, 58, 64, 71, 72, 73, 75, 76, 79, 85, 86, 87, 88], "memori": [7, 9, 11, 71, 72, 76, 79, 80, 88, 89], "reduc": [7, 9, 11, 17, 47, 71, 73, 75, 76, 88], "matrix": [7, 18, 31, 57, 62, 64, 72, 76, 88], "miss": [7, 76], "i": [7, 8, 9, 11, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 44, 45, 47, 56, 59, 60, 61, 62, 64, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90], "properli": [7, 74], "instal": [7, 9, 71, 72, 73, 75, 80, 86, 89], "Not": [7, 76], "avail": [7, 9, 58, 72, 75, 85, 86, 87, 88, 89], "check": [7, 9, 11, 68, 72, 73, 74, 75, 79, 85, 87, 90], "driver": 7, "basic": [7, 9, 73, 77, 79], "shape": [7, 9, 31, 58, 62, 72, 77, 79, 81, 86, 89], "comprehens": [7, 73, 81, 88], "analysi": [7, 76], "enabl": [7, 9, 55, 68, 71, 72, 73, 75, 81, 88], "profil": [7, 9], "onli": [7, 9, 11, 16, 18, 19, 20, 21, 22, 24, 25, 37, 47, 53, 71, 73, 74, 75, 76, 79, 80, 81, 85, 86, 88, 89, 90], "overhead": [7, 73, 76, 80, 81, 88], "multipl": [7, 9, 11, 18, 31, 32, 57, 59, 62, 72, 76, 77, 79, 81, 88, 90], "possibl": [7, 72, 76, 86, 87, 88, 90], "consist": [7, 21, 75, 76, 79, 88, 89, 90], "reproduc": [7, 75], "differ": [7, 9, 11, 21, 22, 29, 32, 61, 62, 71, 72, 73, 74, 75, 76, 79, 80, 81, 86, 87, 88, 90], "case": [7, 8, 9, 47, 57, 62, 75, 76, 79, 81, 85, 86, 90], "user": [7, 9, 11, 18, 32, 47, 53, 69, 71, 72, 73, 75, 76, 77, 79, 84, 86, 87, 88, 89, 90], "more": [7, 9, 11, 22, 23, 71, 72, 73, 75, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89], "about": [7, 9, 11, 68, 72, 73, 74, 75, 76, 86, 87, 88, 90], "compon": [7, 72, 79, 81], "see": [7, 9, 11, 68, 71, 72, 73, 74, 76, 77, 79, 80, 81, 85, 86, 90], "directori": [7, 71], "intend": [8, 57, 72, 86], "provid": [8, 9, 11, 28, 32, 51, 68, 71, 72, 73, 75, 76, 79, 81, 86, 87, 89, 90], "instruct": [8, 11, 72, 75, 86, 87, 88], "most": [8, 9, 47, 72, 75, 76, 81, 86, 87, 90], "fequent": 8, "have": [8, 9, 11, 26, 41, 42, 43, 58, 61, 64, 72, 76, 77, 79, 81, 85, 86, 87, 88, 89, 90], "ani": [8, 9, 36, 37, 41, 51, 64, 72, 76, 79, 85, 87, 89], "answer": [8, 76], "creat": [8, 9, 71, 73, 76, 79, 80, 85, 86, 88, 89, 90], "an": [8, 11, 21, 44, 45, 47, 53, 64, 69, 71, 72, 73, 75, 76, 77, 79, 80, 85, 86, 87, 88, 89, 90], "issu": [8, 57, 72, 73, 79, 88], "start": [9, 11, 14, 15, 21, 26, 27, 48, 57, 58, 71, 72, 75, 76, 77, 79, 81, 85, 86, 87, 88, 89, 90], "read": [9, 79], "overview": [9, 69, 73, 81], "page": [9, 73, 88], "first": [9, 21, 31, 47, 64, 68, 72, 75, 77, 79, 80, 81, 86, 87, 90], "contribut": [9, 73, 76], "exist": [9, 27, 47, 71, 72, 76, 77, 79, 86, 90], "base": [9, 18, 21, 26, 33, 46, 47, 51, 59, 60, 64, 68, 72, 73, 76, 79, 80, 81, 85, 86, 87, 88, 89, 90], "api": [9, 72, 73, 76, 77, 79, 85, 86, 87, 88, 89], "quant_api": [9, 56, 74, 75, 77], "float8tensor": [9, 18, 20, 38, 59, 72, 81], "e": [9, 11, 21, 26, 28, 30, 32, 45, 47, 56, 59, 61, 68, 71, 72, 74, 77, 79, 80, 85, 90], "g": [9, 11, 21, 26, 28, 30, 32, 45, 47, 56, 59, 61, 68, 72, 74, 77, 79, 85, 90], "oper": [9, 11, 24, 29, 72, 73, 75, 85, 86, 87, 88, 89], "make": [9, 19, 72, 73, 79, 81, 86, 90], "trainabl": [9, 11, 72, 79], "add": [9, 68, 79, 80, 84, 88, 90], "parallel": [9, 71, 79, 81], "primit": [9, 79, 86], "op": [9, 11, 18, 56, 57, 68, 73, 76, 79, 81, 86, 87, 88, 90], "slight": [9, 76], "variat": [9, 72], "quant_primit": [9, 77], "mp": 9, "csrc": 9, "ar": [9, 11, 16, 18, 21, 22, 28, 30, 32, 34, 35, 44, 47, 56, 57, 58, 61, 62, 64, 68, 71, 72, 73, 74, 75, 76, 77, 81, 85, 86, 87, 88, 89, 90], "structur": [9, 11, 67, 72, 73, 74, 76, 79, 86], "deriv": [9, 29, 60, 61], "pack": [9, 19, 22, 58], "format": [9, 21, 22, 58, 75, 76, 86, 87, 90], "understand": [9, 58, 71, 88, 90], "concept": [9, 72, 84, 86, 88, 89, 90], "doe": [9, 11, 47, 57, 58, 72, 76, 79, 86, 88, 89], "alreadi": [9, 79, 90], "could": [9, 72, 79, 85, 86, 88, 89, 90], "context": [9, 88, 89], "also": [9, 11, 45, 56, 72, 73, 74, 76, 77, 79, 80, 81, 86, 89, 90], "write": [9, 69, 73, 85, 86, 87], "own": [9, 11, 69, 71, 73, 76, 77, 86, 87, 90], "torchaobasetensor": [9, 81], "help": [9, 11, 71, 72, 75, 81, 85, 86], "common": [9, 47, 57, 58, 59, 60, 69, 71, 72, 76], "specifi": [9, 11, 13, 16, 21, 25, 32, 34, 35, 36, 39, 46, 47, 53, 56, 57, 61, 64, 67, 71, 72, 76, 85, 86, 87, 90], "non": [9, 68, 76, 79, 85, 88, 89], "attribut": [9, 11, 68, 72, 79, 81, 88, 89], "mytensor": [9, 68], "tensor_data_nam": [9, 68], "qdata": [9, 72], "scale": [9, 14, 17, 18, 26, 28, 29, 30, 31, 37, 38, 45, 50, 51, 52, 53, 60, 61, 72, 76, 77, 79, 81, 90], "tensor_attribute_nam": [9, 68], "With": [9, 79, 86, 88, 90], "abov": [9, 11, 19, 26, 72, 74, 76, 77, 79, 86, 87, 90], "ll": [9, 26, 71, 72, 79, 86, 87, 90], "doc": [9, 68, 71, 72, 73, 75, 79, 80], "mani": [9, 72, 76, 79], "still": [9, 11, 72, 73, 76, 86, 90], "affinequantizedtensor": [9, 24, 74, 77, 79], "plan": [9, 24, 87], "move": [9, 56, 77, 81, 87, 88], "awai": 9, "from": [9, 11, 21, 23, 29, 40, 44, 47, 56, 57, 61, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90], "abstract": [9, 72], "easier": [9, 90], "peopl": [9, 72, 74, 81, 90], "implement": [9, 11, 13, 22, 49, 50, 52, 53, 57, 68, 72, 74, 76, 77, 85, 86, 90], "regist": [9, 34, 39, 49, 63, 68, 72, 79], "mai": [9, 21, 29, 45, 58, 72, 74, 77, 80, 86, 87, 88, 89, 90], "well": [9, 72, 73, 76, 86, 87, 90], "int4": [9, 11, 19, 22, 23, 26, 34, 35, 37, 41, 42, 43, 44, 45, 47, 49, 50, 52, 53, 56, 72, 74, 75, 80, 81], "access": [9, 24, 85], "my_custom_op": 9, "call": [9, 11, 34, 39, 49, 63, 68, 72, 74, 76, 77, 79, 81, 87, 89], "want": [9, 21, 56, 67, 72, 73, 74, 76, 79, 81, 85, 86, 87, 90], "my_mm_for_mp": 9, "aten": [9, 68, 72, 73, 79, 81, 85, 86, 87, 88, 89], "default": [9, 11, 18, 20, 22, 28, 30, 37, 45, 53, 56, 68, 71, 72, 73, 79, 81, 85, 86, 87, 88, 89, 90], "_": [9, 68, 71, 72, 73, 77, 81, 85, 86, 87, 88], "func": [9, 68, 72, 79, 81], "arg": [9, 22, 34, 35, 36, 37, 41, 50, 64, 68, 72, 79, 81, 87, 90], "re": [9, 21, 71, 72, 74, 75, 79, 86, 87], "input_tensor": [9, 72, 81], "weight_tensor": [9, 72, 81], "some": [9, 21, 56, 64, 68, 72, 73, 75, 76, 77, 79, 85, 86, 87, 88, 89, 90], "choic": [9, 22], "mm": [9, 56, 57, 79, 86], "recommend": [9, 11, 18, 20, 22, 23, 24, 25, 71, 72, 73, 80, 85, 88, 89], "wai": [9, 47, 71, 72, 75, 76, 77, 79, 86, 87, 90], "repres": [9, 13, 33, 45, 58, 61, 64, 72, 74, 79, 86, 87], "group_mm": 9, "auto": [9, 18, 57, 75, 80, 81], "develop": [9, 68, 73, 86, 87, 90], "choos": [9, 22, 60, 72, 76, 79, 86, 88], "whatev": 9, "think": [9, 81], "fastest": 9, "under": [9, 11, 57, 75], "condit": 9, "so": [9, 11, 71, 72, 73, 74, 76, 79, 80, 86, 87, 90], "don": [9, 21, 64, 71, 72, 73, 76, 80, 81, 90], "t": [9, 21, 64, 68, 71, 72, 73, 76, 77, 79, 80, 81, 86, 87, 90], "worri": 9, "debug": [9, 57], "purpos": [9, 71, 72, 79, 86], "ha": [9, 11, 47, 75, 76, 79, 81, 85, 86, 87, 89, 90], "hardwar": [9, 18, 57, 58, 73, 75, 76, 80], "h100": [9, 72, 80], "sm89": 9, "sm90": 9, "librari": [9, 57, 58, 69, 72, 74], "whether": [9, 11, 28, 45, 68, 79], "mslk": [9, 57, 72], "granular": [9, 14, 18, 22, 23, 24, 25, 28, 30, 34, 35, 37, 38, 45, 46, 61, 71, 72, 75, 77, 81], "per": [9, 11, 19, 20, 23, 24, 25, 28, 30, 37, 41, 42, 43, 45, 49, 50, 52, 53, 61, 64, 71, 72, 76, 77, 89], "_choose_scale_float8": [9, 28, 72], "_quantize_affine_float8": [9, 72], "_scaled_mm": [9, 72], "kerenel": 9, "f8f8bf16_rowwis": [9, 72], "level": [9, 64, 72, 76, 79, 85, 86, 88, 89], "reus": [9, 79], "allow": [9, 53, 72, 73, 76, 79, 85, 86, 87, 88, 90], "appli": [9, 11, 18, 19, 20, 21, 23, 24, 25, 32, 36, 37, 39, 44, 46, 47, 56, 67, 68, 72, 75, 76, 81, 87], "convers": [9, 11, 16], "weight": [9, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 37, 41, 42, 43, 45, 47, 49, 50, 52, 53, 56, 59, 64, 67, 69, 71, 74, 76, 77, 79, 80, 81, 85, 86, 87, 88, 89, 90], "filter": [9, 11, 16, 21, 71, 77], "should": [9, 11, 17, 21, 30, 34, 39, 40, 47, 49, 63, 64, 68, 71, 76, 81, 85, 86, 90], "algorithm": [9, 22, 75, 76, 85], "dynam": [9, 11, 12, 13, 17, 18, 19, 23, 24, 37, 43, 45, 53, 67, 75, 77, 79, 80, 86, 87, 88], "quant": [9, 72, 75, 81, 86, 89, 90], "In": [9, 11, 22, 47, 71, 72, 73, 76, 77, 79, 85, 86, 87, 88, 89, 90], "order": [9, 21, 32, 68, 76, 79, 90], "aim": [9, 76, 89], "run": [9, 11, 17, 34, 35, 39, 49, 56, 57, 63, 71, 72, 73, 75, 76, 79, 84, 85, 86, 87, 88, 89, 90], "fullgraph": [9, 73], "true": [9, 11, 13, 18, 20, 22, 23, 24, 25, 28, 29, 34, 35, 44, 45, 47, 55, 56, 67, 71, 73, 74, 75, 77, 79, 80, 81, 85, 86, 87, 88, 90], "remov": [9, 28, 64, 71, 76, 81, 86, 87], "unnecessari": 9, "graph": [9, 73, 86, 87, 90], "break": 9, "torch_log": 9, "output_cod": 9, "script": [9, 73, 75, 77, 79, 84, 87, 88, 89], "inductor": [9, 69, 73, 85, 86], "save": [9, 11, 64, 68, 71, 73, 74, 75, 81], "load": [9, 68, 74, 75, 80, 81], "relev": [9, 72, 84], "object": [9, 56, 67, 72, 79, 86, 87, 90], "safe": [9, 62], "global": [9, 76, 79], "after": [9, 11, 17, 71, 72, 74, 76, 80, 85, 86, 87, 88, 89, 90], "2": [9, 18, 20, 21, 22, 24, 25, 26, 34, 45, 49, 50, 61, 65, 67, 69, 71, 72, 76, 77, 79, 84], "5": [9, 11, 26, 34, 64, 73, 75, 76, 81, 84, 86, 87], "add_safe_glob": 9, "quantizetensortofloat8kwarg": [9, 72], "checkout": [9, 69, 72], "huggingfac": [9, 80], "transform": [9, 11, 68, 77, 85, 86, 87, 88, 89], "deseri": [9, 86, 87], "save_pretrain": [9, 75, 80], "push_to_hub": [9, 75, 80, 81], "from_pretrain": [9, 11, 75, 80, 81], "diffus": [9, 75], "just": [9, 26, 45, 72, 74, 76, 79, 86, 87, 90], "talk": [9, 72, 75], "train": [9, 13, 32, 45, 47, 69, 73, 76, 79, 90], "fsdp": [9, 72], "mydtypetensor": 9, "put": [9, 67, 88, 90], "developer_api_guid": 9, "folder": [9, 75, 86, 87], "cover": [9, 84, 86, 89, 90], "follow": [9, 11, 45, 47, 68, 71, 72, 73, 75, 76, 77, 79, 80, 85, 86, 87, 88, 89, 90], "executorch": [9, 23, 69, 73, 80, 86, 87], "torchchat": 9, "dtensor": [9, 79], "copi": [9, 64, 73, 74, 76, 77, 79, 87, 88], "past": [9, 76], "adapt": [9, 71, 77], "befor": [9, 11, 21, 47, 56, 72, 74, 75, 76, 77, 79, 86, 87, 90], "do": [9, 27, 31, 56, 72, 75, 76, 77, 79, 81, 86, 87, 88, 90], "singl": [9, 11, 12, 17, 18, 29, 71, 76, 86, 90], "comput": [9, 17, 20, 34, 39, 49, 57, 63, 64, 72, 76, 77, 79, 80, 86, 87, 88, 89], "intens": 9, "get": [9, 11, 53, 68, 71, 72, 73, 75, 76, 81, 85, 86, 87, 88, 90], "sens": [9, 72, 79], "d": [9, 68, 75, 87], "benchmark_aq": 9, "": [9, 11, 21, 26, 28, 30, 57, 58, 61, 68, 71, 72, 73, 75, 76, 77, 79, 86, 87, 88, 89, 90], "import": [9, 11, 40, 44, 47, 56, 67, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 88, 89], "A": [9, 11, 29, 57, 63, 68, 72, 76, 79, 80, 81, 86], "quick": [9, 69], "chang": [9, 56, 71, 73, 74, 75, 76, 77, 79, 85, 86, 87, 89, 90], "interest": [9, 76, 79], "print_op_and_shap": 9, "output": [9, 11, 13, 28, 30, 61, 71, 72, 73, 75, 76, 80, 84, 85, 86, 87, 88, 89, 90], "torch_func": 9, "built": [9, 71, 79], "_c": 9, "tensorbas": 9, "all": [9, 17, 21, 26, 29, 34, 37, 39, 41, 49, 51, 63, 64, 65, 68, 72, 73, 74, 75, 76, 77, 79, 81, 82, 85, 86, 88, 90], "benchmark_your_kernel": 9, "helper": [9, 54, 55, 68], "right": [9, 19, 22, 76, 86], "1": [9, 14, 15, 18, 20, 21, 22, 24, 25, 26, 27, 28, 38, 48, 57, 58, 60, 61, 64, 68, 69, 72, 73, 74, 76, 77, 79, 84, 86, 87], "feel": [9, 72, 76, 79, 81], "free": [9, 72, 79], "either": [9, 18, 38, 47, 64, 75, 76, 87, 88, 89], "one": [9, 18, 29, 34, 39, 47, 49, 63, 71, 72, 76, 79, 81, 87, 90], "probabl": 9, "keep": [9, 24, 28, 64, 72, 86], "futur": [9, 77, 80, 81, 86, 87, 88, 90], "llama": [9, 11, 75, 80, 81, 85], "llama2": 9, "llama3": [9, 11, 71, 80], "sam": 9, "modifi": [9, 16, 56, 64, 71, 76, 79], "friendli": 9, "compar": [9, 11, 64, 71, 72, 73, 75, 86, 88, 90], "techniqu": [9, 11, 71, 74, 75, 76, 77, 79, 81], "bound": [9, 18, 38, 75, 76, 81], "each": [9, 37, 45, 50, 52, 53, 63, 68, 72, 76, 77, 79, 81, 86, 87, 90], "profile_path": 9, "chrome": 9, "trace": 9, "let": [9, 26, 61, 72, 73, 76, 77, 79, 90], "u": [9, 76, 85], "know": [9, 79], "end": [11, 71, 72, 75, 76, 79, 80, 81, 87, 90], "pre": [11, 69, 75, 76, 90], "serv": [11, 69, 71, 73, 79, 80, 89], "flow": [11, 23, 71, 75, 76, 77, 85, 86, 87, 88, 89], "leverag": [11, 71, 75, 79, 88, 89], "partner": [11, 71, 75], "showcas": [11, 71, 75], "focus": [11, 71, 72, 75, 76], "domain": [11, 28, 30, 45, 71], "demonstr": [11, 71, 72, 73, 75, 79, 85, 87], "dure": [11, 24, 30, 45, 47, 71, 73, 75, 76, 77, 79, 85, 87], "numer": [11, 47, 52, 53, 57, 71, 76, 86, 87, 88], "goal": [11, 47], "mitig": [11, 76], "degrad": [11, 47, 76], "eventu": [11, 47, 71], "blog": 11, "resourc": [11, 79], "small": [11, 73], "matric": [11, 76], "freez": [11, 87, 88, 89], "checkpoint": [11, 68, 71, 75, 81], "effici": [11, 52, 76, 77, 89], "paper": [11, 76, 84], "speed": [11, 56, 75, 76, 85], "up": [11, 45, 56, 71, 72, 76, 85, 86, 87, 90], "high": [11, 38, 47, 71, 72, 75, 76, 77, 79, 85, 86, 88, 89], "precis": [11, 20, 24, 37, 38, 42, 43, 47, 50, 52, 53, 72, 77, 79, 80, 85, 88, 89], "similar": [11, 76, 77, 87, 88], "inevit": 11, "actual": [11, 20, 47, 57, 72, 77, 79, 81, 86, 87, 90], "presum": 11, "been": [11, 68, 79, 87, 88, 89, 90], "successfulli": [11, 76], "recent": [11, 69], "releas": [11, 88], "1b": [11, 80, 81], "3b": 11, "llamaguard": 11, "8b": [11, 71, 73, 80], "improv": [11, 71, 75, 76, 86, 89, 90], "qualiti": [11, 76, 80], "involv": [11, 47, 76], "two": [11, 18, 47, 68, 72, 73, 76, 79, 85, 86, 87, 88, 90], "separ": [11, 34, 35, 45, 76, 81, 86, 90], "prepar": [11, 32, 37, 41, 47, 64, 76, 85, 88, 89, 90], "convert": [11, 13, 32, 40, 41, 47, 56, 67, 71, 72, 75, 76, 85, 88, 89, 90], "fake": [11, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 71, 86, 87, 90], "mean": [11, 26, 28, 30, 61, 68, 71, 72, 76, 86, 87, 90], "valu": [11, 13, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 30, 38, 48, 57, 58, 61, 64, 72, 76, 77, 79, 85, 86, 87, 90], "map": [11, 24, 26, 45, 68, 72, 79, 86, 90], "without": [11, 40, 72, 76, 81, 88, 90], "cast": [11, 12, 14], "lower": [11, 18, 23, 38, 72, 73, 75, 76, 77, 80, 87], "replac": [11, 21, 76, 81], "real": [11, 72, 73, 86, 90], "perform": [11, 17, 24, 25, 31, 34, 39, 41, 42, 43, 49, 62, 63, 71, 73, 76, 77, 79, 80, 81, 85, 87, 88, 89], "There": [11, 47, 72, 77, 79, 86, 90], "directli": [11, 26, 29, 47, 72, 76, 77, 79], "loop": [11, 71, 76], "distribut": [11, 71, 77, 79, 81, 85], "recip": [11, 13, 34, 39, 49, 63], "instead": [11, 29, 34, 39, 40, 44, 45, 47, 49, 63, 71, 73, 76, 79, 87, 88, 89, 90], "command": [11, 71], "regular": [11, 85, 88, 89], "nnode": 11, "nproc_per_nod": 11, "4": [11, 65, 67, 72, 73, 74, 75, 76, 79, 80, 86, 87], "full_finetune_distribut": 11, "llama3_2": 11, "3b_full": 11, "batch_siz": [11, 73, 74, 75, 77, 86, 87], "16": [11, 35, 71], "equival": [11, 45, 76, 87, 88, 90], "asymmetr": [11, 23, 26, 28, 45, 77, 85, 89, 90], "token": [11, 23, 24, 43, 45, 53, 71, 75, 80], "int8": [11, 23, 24, 25, 35, 43, 44, 45, 47, 53, 56, 60, 67, 72, 73, 75, 79, 86, 88, 89, 90], "symmetr": [11, 18, 20, 23, 24, 25, 26, 28, 34, 37, 45, 79, 85, 86, 89, 90], "configur": [11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 56, 67, 71, 72, 75, 80, 88, 89, 90], "_component_": 11, "qat_distribut": 11, "3b_qat_ful": 11, "evalu": [11, 73, 87], "same": [11, 18, 22, 28, 29, 30, 53, 61, 62, 67, 68, 71, 72, 76, 77, 79, 87, 89, 90], "wa": [11, 79, 87], "llama3_2_3b": 11, "fullmodelhfcheckpoint": 11, "checkpoint_fil": 11, "00001": 11, "00002": 11, "safetensor": [11, 80], "int8dynactint4weightquant": 11, "groupsiz": [11, 42, 43, 52, 53, 61], "32": [11, 22, 23, 35, 44, 45, 47, 49, 50, 56, 67, 71, 74, 75, 77, 79, 87], "hellaswag": [11, 75], "wikitext": 11, "eleuther_ev": 11, "eleuther_evalu": 11, "task": [11, 75], "fullmodeltorchtunecheckpoint": 11, "8da4w": [11, 75], "ckpt": 11, "llama3_token": 11, "path": [11, 56, 62, 73, 75, 85, 86, 87, 88, 90], "tmp": 11, "meta": [11, 74, 80, 81, 90], "print": [11, 64, 73, 74, 75, 79, 84, 86, 87], "version": [11, 18, 20, 21, 22, 24, 25, 45, 68, 72, 79, 81, 86, 87, 90], "shot": [11, 76], "stderr": 11, "none": [11, 12, 13, 14, 15, 16, 17, 18, 21, 25, 26, 27, 28, 29, 30, 34, 35, 37, 38, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 64, 67, 68, 72, 77, 79, 81, 85, 86, 87, 89], "acc": [11, 86, 87], "5021": 11, "0050": 11, "acc_norm": 11, "6797": 11, "0047": 11, "bits_per_byt": 11, "6965": 11, "byte_perplex": 11, "6206": 11, "word_perplex": 11, "13": 11, "2199": 11, "much": [11, 76, 90], "openassist": 11, "oasst1": 11, "dataset": [11, 71, 75, 85, 88, 89], "find": [11, 76, 86, 90], "achiev": [11, 71, 73, 76, 77, 79, 87, 88], "higher": [11, 71, 79, 80, 85, 86, 88, 89], "accuraci": [11, 71, 73, 75, 76, 77, 85, 87, 88], "than": [11, 45, 71, 72, 73, 76, 79, 86], "recov": [11, 76, 87], "69": [11, 77], "8": [11, 26, 34, 35, 42, 52, 71, 72, 75, 81, 88, 89], "overal": [11, 69, 73, 86, 90], "vanilla": 11, "compos": [11, 32, 72, 76, 79, 86, 87, 90], "lora": 11, "yield": [11, 76], "89x": 11, "usag": [11, 17, 32, 34, 35, 40, 44, 45, 47, 68, 69, 71, 75, 88, 89], "36": [11, 71, 75], "qat_lora_finetune_distribut": 11, "3b_qat_lora": 11, "set": [11, 18, 20, 22, 23, 24, 25, 29, 45, 56, 64, 68, 76, 85, 87, 88, 89], "try": [11, 76, 79, 86], "fsdp2": [11, 71], "yaml": 11, "onc": [11, 76], "complet": [11, 75, 85, 89], "qat_out": 11, "quatiz": 11, "document": [11, 79, 81, 85, 86, 88], "prefer": [11, 18, 72, 79], "These": [11, 76, 79, 85, 86, 87, 90], "what": [11, 71, 72, 75, 76, 77, 81, 84, 86, 90], "hood": 11, "mini": [11, 75], "gpu": [11, 69, 71, 73, 80, 81, 84, 85], "smaller": [11, 22, 23, 73, 74], "fit": [11, 72, 74], "adjust": [11, 18, 20, 22, 23, 24, 25], "accordingli": 11, "get_model": 11, "vocab_s": 11, "4096": [11, 71], "num_lay": 11, "num_head": 11, "num_kv_head": 11, "embed_dim": 11, "2048": [11, 71], "max_seq_len": 11, "train_loop": [11, 47], "sgd": 11, "lr": [11, 71], "001": 11, "momentum": [11, 87], "9": [11, 71], "weight_decai": 11, "1e": [11, 71], "loss_fn": 11, "crossentropyloss": [11, 86, 87], "rang": [11, 26, 71, 73, 76, 77, 86, 87], "randint": 11, "loss": [11, 71, 76, 86, 87], "backward": [11, 17, 71, 76, 87], "zero_grad": [11, 71, 87], "next": [11, 71, 77, 86, 87, 88, 89], "scheme": [11, 24, 25, 34, 35, 47, 75, 85], "although": [11, 22, 34, 39, 49, 63, 79], "integ": [11, 26, 28, 30, 31, 45, 46, 62, 77, 86, 87, 88], "arithmet": [11, 47], "float": [11, 18, 26, 28, 29, 30, 34, 38, 45, 49, 50, 61, 64, 72, 73, 74, 79, 86, 87, 90], "float32": [11, 30, 41, 43, 45, 49, 50, 53, 61, 74, 75, 76, 77, 79, 88, 89, 90], "becaus": [11, 71, 73, 74, 76, 79, 87, 90], "int8dynamicactivationint4weightconfig": [11, 47, 53], "qatconfig": [11, 40, 44, 48], "swap": [11, 16, 37, 41, 71, 76, 77, 87], "fakequantizedlinear": [11, 37, 40, 54, 55], "base_config": [11, 47], "exact": [11, 53, 86, 87], "attun": 11, "benefici": 11, "later": [11, 21, 72, 79, 86, 87, 89], "readi": [11, 71, 73, 75, 77, 79, 87], "did": [11, 23], "altern": [11, 45, 77, 79, 88, 89], "legaci": 11, "offer": [11, 73, 79, 86], "customiz": [11, 56], "unlik": [11, 77], "int8dynactint4weightqatquant": 11, "qat_quant": 11, "insert": [11, 73, 77, 85, 86, 87, 88, 89, 90], "int8dynactint4weightqatlinear": 11, "int8dynactint4weightlinear": 11, "fraction": 11, "therebi": 11, "significantli": [11, 73, 85, 86, 88, 89], "footprint": 11, "extens": [11, 79, 86, 88], "addition": [11, 88, 89], "frozen": 11, "further": [11, 79, 85, 86, 87, 88], "nf4": 11, "propos": [11, 64], "express": [11, 73, 79, 85, 86, 87, 90], "subclass": [11, 16, 34, 39, 49, 57, 58, 63, 67, 68, 72, 73, 74, 76, 80], "nf4tensor": 11, "cleanli": 11, "compil": [11, 56, 62, 69, 71, 72, 73, 77, 79, 88, 89], "simpli": [11, 76, 77, 79], "to_nf4": 11, "frozennf4linear": 11, "in_dim": 11, "out_dim": 11, "bool": [11, 13, 16, 18, 20, 22, 23, 24, 25, 28, 29, 34, 35, 43, 45, 49, 50, 52, 53, 55, 56, 67, 77], "quantization_kwarg": 11, "No": [11, 72, 74, 76], "requires_grad_": 11, "nf4_weight": 11, "requires_grad": [11, 72, 77, 79, 81], "though": [11, 79], "shown": [11, 75, 76, 87, 90], "competit": [11, 71], "baselin": [11, 71, 75, 86], "while": [11, 34, 39, 47, 49, 59, 63, 64, 73, 75, 76, 79, 80, 85, 86, 90], "even": [11, 71, 76, 90], "newer": 11, "mxfp4": [11, 72], "nvfp4": [11, 72], "blackwel": 11, "reap": 11, "benefit": [11, 19, 76, 79, 86, 89], "vari": [11, 73, 86, 87, 88, 89], "tradeoff": [11, 76, 80], "incorpor": 11, "its": [11, 76, 79, 81, 86, 90], "loralinear": 11, "lora_finetune_single_devic": 11, "3b_qlora_single_devic": 11, "limit": [11, 71, 72, 79, 81, 86], "yet": [11, 23, 27, 47, 79, 81, 87, 88, 89], "invok": [11, 88], "loraconfig": 11, "get_peft_model": 11, "automodelforcausallm": [11, 75, 80, 81], "torchaoconfig": [11, 75, 80, 81], "int8weightonlyconfig": [11, 56, 80, 81], "base_model": 11, "quantization_config": [11, 75, 80, 81, 89], "peft_config": 11, "throughput": [11, 71, 73, 75], "increas": [11, 76, 86], "torchtitan": 11, "enable_fp8_train": 11, "fp8_recipe_nam": 11, "tensorwis": [11, 12, 13, 72], "initi": [11, 51, 72, 73, 74, 87], "experi": [11, 71, 89], "saw": 11, "experiment_nam": 11, "tok": 11, "peak_mem_reserv": 11, "6502": 11, "143": 11, "000": 11, "30": [11, 71, 86], "090": 11, "fp8_nonam": 11, "7205": 11, "386": 11, "816": 11, "010": 11, "266": 11, "fp8_tensorwis": 11, "7222": 11, "198": 11, "11": [11, 71], "074": [11, 71], "fp8_rowwis": 11, "6387": 11, "968": 11, "756": 11, "29": [11, 71], "158": 11, "096": 11, "fp8_rowwise_with_gw_hp": 11, "7573": 11, "698": 11, "480": 11, "516": 11, "908": 11, "hellaswag_acc": 11, "wikitext_word_perplex": 11, "533": 11, "12": [11, 71, 89, 90], "407": [11, 71], "414": 11, "007": 11, "412": 11, "005": 11, "420": 11, "013": [11, 71], "534": 11, "416": 11, "009": 11, "float8": [12, 13, 14, 15, 16, 17, 18, 19, 20, 37, 38, 39, 60, 69, 75, 77], "scaling_typ": [12, 13], "scalingtyp": [12, 13], "scaling_granular": [12, 13], "scalinggranular": [12, 13], "target_dtyp": [12, 13, 28, 29, 72, 77], "sourc": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 75, 82, 84], "mayb": 12, "cast_config_input": 13, "castconfig": 13, "cast_config_input_for_grad_weight": 13, "cast_config_weight": 13, "cast_config_weight_for_grad_input": 13, "cast_config_grad_output": 13, "cast_config_grad_output_for_grad_weight": 13, "gemm_config_output": 13, "float8gemmconfig": 13, "use_fast_accum": 13, "gemm_config_grad_input": 13, "gemm_config_grad_weight": 13, "enable_fsdp_float8_all_gath": 13, "pad_inner_dim": 13, "emul": [13, 57], "force_recompute_fp8_weight_in_bwd": 13, "round_scales_to_power_of_2": 13, "static": [13, 29, 45, 69, 73, 86, 87, 88, 89, 90], "from_recipe_nam": 13, "recipe_nam": [13, 71], "union": [13, 18, 28, 30, 38, 45, 56, 61], "float8linearrecipenam": 13, "qualnam": [14, 15, 26, 27, 48, 57, 58], "boundari": [14, 15, 26, 27, 48, 57, 58], "strategi": 14, "module_filter_fn": [16, 71], "callabl": [16, 56, 67, 68, 81], "float8linearconfig": 16, "float8linear": [16, 71], "instanc": [16, 34, 39, 49, 56, 63, 67, 68, 74, 79, 86, 88, 89, 90], "fqn": [16, 21, 64, 67, 71, 77], "calcul": [17, 18, 26, 28, 29, 38, 72, 76, 86, 90], "It": [17, 73, 76, 79, 90], "sum": [17, 86, 87], "activation_dtyp": [18, 72], "float8_e4m3fn": [18, 20, 38, 72], "weight_dtyp": [18, 20, 72, 75], "pertensor": [18, 25, 38, 77], "perrow": [18, 24, 25, 38, 72], "list": [18, 30, 32, 64, 68, 73, 79, 80, 81, 85, 87, 90], "packing_format": [18, 22], "float8packingformat": 18, "plain": [18, 22, 58, 72, 81], "mm_config": 18, "float8mmconfig": 18, "activation_value_lb": 18, "activation_value_ub": 18, "kernel_prefer": [18, 72], "kernelprefer": 18, "set_inductor_config": [18, 20, 22, 23, 24, 25], "both": [18, 22, 47, 53, 72, 73, 76, 77, 79, 86, 88, 89, 90], "fp8granular": [18, 38], "tupl": [18, 28, 29, 30, 51, 61, 64, 68, 79, 81, 86, 87, 90], "And": [18, 79, 88, 90], "fast": [18, 76], "accumul": 18, "upper": [18, 38], "kernel": [18, 19, 52, 56, 57, 75, 76, 85, 88, 89], "matmul": [18, 20, 72, 76, 79], "defalut": 18, "chosen": [18, 60, 76], "torchinductor": [18, 20, 22, 23, 24, 25, 88, 89], "deprec": [18, 20, 21, 24, 40, 44, 68], "int4_packing_format": [19, 22], "int4packingformat": [19, 22], "preshuffl": [19, 72], "128": [19, 22, 71, 73, 75, 77, 79, 80, 81, 89, 90], "sinc": [19, 21, 34, 39, 49, 63, 68, 72, 74, 75, 76, 77, 79, 86, 87, 88, 89, 90], "underli": [19, 75, 79], "bigger": 19, "channel": [20, 24, 25, 37, 41, 42, 43, 45, 49, 50, 52, 53, 63, 77, 89], "fqn_to_config": 21, "ordereddict": 21, "core": [21, 27, 56, 77, 81, 86], "factori": 21, "module_fqn_to_config": 21, "fulli": [21, 56, 67, 75, 76, 86], "qualifi": [21, 56, 67, 76], "dictionari": [21, 76], "regex": [21, 85], "prefix": 21, "3": [21, 26, 34, 61, 69, 71, 72, 73, 76, 80, 84, 86, 87], "_default": [21, 75, 81], "param": [21, 28, 29, 64, 75], "kei": [21, 64, 76, 84], "preced": [21, 85, 86, 88, 89], "languag": [21, 75], "q_proj": [21, 81], "must": [21, 32, 45, 47, 53, 71, 76, 80, 81, 87, 89, 90], "match": [21, 30, 31, 52, 53, 68, 76, 86], "whichev": 21, "kept": 21, "fallback": [21, 62, 81], "previou": [21, 72, 75, 86, 87, 88, 89], "subset": [21, 72], "better": [21, 24, 25, 71, 73, 79, 86, 87, 88, 89, 90], "hand": 21, "norm": [21, 63, 64, 76], "linear_config": [21, 75], "filter_fn": [21, 56, 67], "maintain": [21, 68, 75, 76], "bc": [21, 68], "modulefqntoconfig": 21, "pattern": [21, 72, 73, 81, 85, 86], "matter": [21, 72, 76], "ignor": [21, 34, 39, 49, 63, 71, 86, 87], "int4_choose_qparams_algorithm": 22, "int4chooseqparamsalgorithm": 22, "tinygemm": [22, 52, 56], "groupwis": 22, "mainli": [22, 72, 85, 88, 90], "distinguish": [22, 72], "layout": [22, 23, 24, 67, 68, 76], "control": [22, 23, 24, 64, 76, 81, 86], "fine": [22, 23, 69, 71, 75, 76], "grain": [22, 23, 79], "256": [22, 41, 42, 43, 52, 53, 75, 86, 87, 90], "64": [22, 37, 74, 75, 77, 79, 81], "variant": [22, 26, 29, 79], "qparam": [22, 28, 30, 61], "hqq": [22, 72], "plainlayout": [23, 24, 68, 77], "mapping_typ": [23, 28, 29, 45], "mappingtyp": [23, 24, 28, 29, 45, 77], "act_mapping_typ": [23, 24], "produc": [23, 73, 85, 86, 87, 88, 89], "backend": [23, 69, 73, 75, 76, 90], "weight_only_decod": 24, "dim": [24, 25, 38, 77, 79, 81, 86, 87], "store": [24, 59, 63, 72, 76, 80, 81, 86, 87], "around": [24, 71, 72, 73, 74, 86], "zero": [24, 28, 30, 45, 50, 51, 52, 53, 64, 76, 77, 90], "decod": [24, 75], "split": [24, 75, 86, 87], "int8tensor": [24, 72, 73], "otherwis": [25, 32, 45, 87], "point": [26, 30, 38, 45, 50, 51, 52, 53, 71, 72, 73, 74, 76, 77, 79, 86, 90], "number": [26, 37, 50, 52, 53, 64, 75, 76, 79, 87, 88], "sai": [26, 61, 72, 80, 81, 90], "7": [26, 71, 75, 88, 89], "symmetric_no_clipping_err": 26, "smin": 26, "smax": 26, "min_val_neg": [26, 79], "quant_min": [26, 28, 29, 30, 61, 79, 89, 90], "max_val_po": [26, 79], "quant_max": [26, 28, 29, 30, 61, 79, 89, 90], "By": [26, 76], "individu": [26, 76], "less": [26, 76, 79, 86], "round": [26, 79], "error": [26, 45, 71, 79, 86], "neg": 26, "placehold": [27, 72, 89], "block_siz": [28, 29, 30, 61, 72, 77], "ep": [28, 29, 45, 77, 87, 89, 90], "scale_dtyp": [28, 29, 77], "zero_point_dtyp": [28, 29, 77], "int32": [28, 41, 45, 49, 50, 72, 86, 90], "keepdim": [28, 79, 86, 87], "fp32": [28, 30, 45, 53, 77, 79, 86, 88], "fp16": 28, "determin": [28, 47, 71, 76, 81], "element": [28, 30, 37, 50, 52, 53, 61, 68, 72, 76], "share": [28, 30, 61, 76], "minimum": [28, 30, 61], "optioanl": 28, "maximum": [28, 30, 61], "zero_point": [28, 29, 30, 61, 72, 76, 77, 79, 90], "align": 28, "zero_point_domain": [28, 29, 45], "zeropointdomain": [28, 29, 45], "preserve_zero": [28, 29], "preserv": [28, 64, 75, 76, 85], "request": [28, 30, 61], "min_val": [29, 79], "max_val": [29, 79], "choose_qparams_affin": 29, "observ": [29, 63, 72, 76, 77, 85, 86, 87, 88, 89, 90], "obtain": 29, "track": [29, 80, 81], "calibr": [29, 73, 85, 87, 88, 89], "mostli": [29, 47, 73], "input_dtyp": 30, "output_dtyp": [30, 49, 61], "argument": [30, 45, 47, 56, 59, 68, 71, 72, 75, 88], "affin": [30, 61, 72], "uint8": [30, 61, 72, 77, 90], "dequant": [30, 57, 72, 73, 79, 81, 86, 88, 89, 90], "b": [31, 57, 68], "scales1": 31, "multipli": [31, 62, 76], "second": [31, 47, 68, 71, 72, 84, 90], "factor": [31, 71, 76], "rais": [31, 44, 47, 62, 79, 81], "assertionerror": [31, 62, 79], "expect": [31, 71, 76, 79, 85, 86, 88, 89, 90], "qat": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 69, 75, 88], "twostepquant": 32, "easili": [32, 85], "thei": [32, 71, 73, 76, 79, 80, 86, 87, 90], "constructor": [32, 68, 79], "embed": [32, 34, 41, 44, 47, 49, 50], "behavior": [32, 81, 86, 87], "undefin": [32, 64], "my_quant": 32, "qatquantizer1": 32, "qatquantizer2": 32, "qatquantizer3": 32, "num_embed": [34, 49, 50], "embedding_dim": [34, 49, 50], "padding_idx": [34, 49, 50], "max_norm": [34, 49, 50], "norm_typ": [34, 49, 50], "scale_grad_by_freq": [34, 49, 50], "spars": [34, 49, 50, 64, 76], "weight_config": [34, 35, 44, 47], "fakequantizeconfigbas": [34, 35, 44, 47], "intxfakequantizeconfig": [34, 35, 44, 46, 47], "fq_embed": 34, "longtensor": 34, "everi": [34, 39, 49, 63, 76, 79, 86, 87], "overridden": [34, 39, 49, 63], "within": [34, 39, 49, 63, 75, 76, 81, 88, 89], "afterward": [34, 39, 49, 63], "former": [34, 39, 49, 63], "take": [34, 39, 49, 56, 63, 67, 68, 72, 76, 85, 86, 87, 88, 89, 90], "care": [34, 39, 49, 63, 74, 76, 86], "hook": [34, 39, 49, 63, 72], "latter": [34, 39, 49, 63, 87], "silent": [34, 39, 49, 63, 88], "in_featur": [35, 52, 53, 71, 73, 74, 77, 79], "out_featur": [35, 52, 53, 71, 77, 79], "activation_config": [35, 44, 47], "per_token": [35, 44, 45, 47], "is_symmetr": [35, 44, 45, 47], "fq_linear": 35, "scale_precis": [37, 41, 45, 49, 50], "rowwis": [37, 72], "hp_value_lb": 38, "hp_value_ub": 38, "float8fakequantizeconfig": 39, "fakequantizedembed": 40, "back": [40, 79], "model_with_fake_quantized_linear": 40, "zero_point_precis": [41, 45, 49, 50], "int4weightonlyqatembed": 41, "int4weightonlyembed": 41, "inner_k_til": [42, 52], "scales_precis": [42, 43, 52, 53], "padding_allow": 43, "valueerror": [44, 47], "torchaodtyp": 45, "is_dynam": [45, 88, 89, 90], "range_learn": 45, "simul": [45, 47, 65, 76], "older": [45, 68], "6": [45, 71, 72, 75, 76, 86, 87, 88], "int1": [45, 72], "int7": [45, 72], "pergroup": [45, 75], "pertoken": 45, "per_channel": 45, "peraxi": [45, 75, 77], "per_group": [45, 61], "combin": [45, 75, 76, 79, 86, 88], "leav": 45, "field": [45, 48, 90], "empti": [45, 72], "prototyp": [45, 51, 72, 90], "keyword": [45, 47, 59, 72], "properti": [45, 46], "throw": 45, "els": [45, 72, 75, 81, 86, 87], "symmetri": 46, "qatstep": 47, "awar": [47, 64, 69, 73, 76, 79], "post": [47, 69, 72, 73, 79, 87, 90], "ptq": [47, 87, 88], "automat": [47, 71, 75, 79, 80, 81, 84], "phase": [47, 90], "int4weightonlyconfig": [47, 56, 74, 80, 81], "experiment": [47, 85], "qat_config": 47, "act_config": 47, "alwai": [47, 75, 79], "One": [47, 76, 79, 81, 90], "enum": [48, 57], "example_input": [51, 73, 74, 77, 85, 86, 87, 88, 89, 90], "intxfakequantizerbas": 51, "weightonlyint4linear": 52, "hardcod": [53, 90], "mod": [54, 55, 71, 76, 79], "disabl": [54, 79, 87], "_is_linear": [56, 77], "inplac": [56, 64, 73], "final": [56, 72, 73, 76, 85, 86, 87, 88, 89, 90], "predefin": [56, 58, 90], "execut": [56, 79, 83], "int8dynamicactivationint8weightconfig": [56, 67, 73, 80], "sequenti": [56, 67, 71], "affect": [57, 76], "select": [57, 86], "found": [57, 72, 73, 75, 76, 77, 79], "nativ": [57, 69, 71, 72, 79, 86], "gemm_lowp": 57, "gemm_fp32": 57, "ci": 57, "product": [57, 64, 73, 75, 81, 88, 90], "logic": [57, 73, 79, 81], "lowp": 57, "gemm": [57, 71, 88, 89], "laid": [58, 72], "opaqu": 58, "decid": [58, 76, 77], "adopt": [58, 72], "creation": [59, 81], "construct": [59, 72, 86, 90], "classmethod": [59, 68, 77, 79, 81], "from_hp": [59, 72], "cl": [59, 68, 77, 79, 81], "quant_kwarg": [59, 60], "quantizetensorkwarg": 60, "given": [60, 71, 76, 81, 90], "flexibl": [60, 76, 79, 85, 88], "variou": 60, "float16": [61, 76], "tabl": [61, 68, 71, 72, 76], "show": [61, 71, 73, 75, 76, 81, 86, 87], "per_tensor": 61, "per_axi": 61, "axi": [61, 77], "mat2": 62, "consid": [62, 76], "cubla": 62, "j": 62, "l2": [63, 76], "buffer": 63, "x_orig": 63, "sparsity_level": [64, 76], "semi_structured_block_s": 64, "wanda": 64, "sparsifi": [64, 69, 74, 76], "prune": 64, "http": [64, 68, 75, 76, 80, 89], "arxiv": [64, 76], "org": [64, 68, 75, 76, 89], "ab": [64, 76], "2306": 64, "11695": 64, "magnitud": [64, 76], "three": [64, 67, 88, 89], "variabl": [64, 76], "block": [64, 76], "dict": [64, 68, 79, 81, 89, 90], "parametr": 64, "deepcopi": [64, 73, 77, 79, 87], "squash_mask": [64, 76], "params_to_keep": 64, "params_to_keep_per_lay": 64, "squash": 64, "mask": [64, 76], "appropri": [64, 85, 86, 87, 88, 89], "sparse_param": 64, "attach": [64, 76, 90], "xdoctest": 64, "skip": [64, 72, 76], "local": [64, 75, 76], "hasattr": [64, 81], "submodule1": 64, "linear1": [64, 73, 74, 77, 79], "foo": [64, 86], "bar": [64, 86], "submodule2": 64, "linear42": 64, "baz": 64, "42": [64, 77], "24": 64, "ones": [64, 87], "update_mask": 64, "tensor_nam": [64, 81], "statist": [64, 76, 77, 86, 87], "retriev": 64, "act_per_input": 64, "Then": [64, 79, 89, 90], "across": [64, 75, 76, 79, 81], "whole": [64, 90], "alia": [66, 68, 81], "semisparseweightconfig": 66, "sparsify_": 67, "apply_tensor_subclass": 67, "essenti": [67, 81, 85], "semi": [67, 76], "semi_sparse_weight": 67, "semisparselayout": 67, "isinst": [67, 71, 76, 77, 79, 81, 87, 90], "sparse_api": 67, "commonli": [68, 71, 76], "inherit": [68, 79, 81, 88, 89], "tensor_data": 68, "optional_tensor_data_nam": 68, "optional_tensor_attribute_nam": 68, "__new__": [68, 79, 81], "exaclti": 68, "present": [68, 76], "includ": [68, 71, 72, 79, 85, 88, 89, 90], "__tensor_flatten__": [68, 79, 81], "flatten": 68, "valid": [68, 75, 81, 90], "attribute_nam": 68, "__tensor_unflatten__": [68, 79, 81], "tensor_data_dict": [68, 79, 81], "_apply_fn_to_data": [68, 81], "recreat": 68, "__repr__": [68, 79], "represent": [68, 76, 81, 86, 90], "_same_metadata": 68, "metadata": [68, 72, 75, 79, 81], "between": [68, 72, 76, 79, 81, 85, 87, 88, 90], "__setstate__": 68, "serial": [68, 69, 72, 80, 86, 87], "old": 68, "__torch_function__": [68, 72, 79], "contigu": [68, 72, 88, 89], "__torch_dispatch__": [68, 79], "detach": [68, 79, 81], "clone": [68, 75, 81], "copy_": [68, 81], "_to_copi": [68, 81], "c": [68, 73, 79, 88, 89], "f": [68, 71, 72, 73, 74, 75, 76, 77, 79, 81, 86, 87], "h": [68, 75], "get_layout": 68, "part": [68, 69, 76, 79, 80, 87], "stack": [68, 72, 75], "dev": [68, 80], "ao": [68, 76, 81], "main": [68, 72, 73, 75, 76, 77, 79, 80, 86, 90], "quantization_overview": 68, "html": 68, "contributor_guid": 68, "get_tensor_impl_constructor": 68, "layout_class": 68, "tensorimpl": 68, "tensorimplclass": 68, "from_plain": 68, "tensor_class": 68, "impl": 68, "aten_op": 68, "decor": [68, 79, 81], "callback": 68, "implements_torch_funct": 68, "torch_fn": 68, "register_layout": 68, "registr": 68, "aqt": 68, "gradient": [69, 76], "introduct": [69, 72, 75], "highlight": [69, 79, 84], "guid": [69, 72, 75, 85], "contributor": [69, 72, 73], "benchmark": [69, 71, 73, 80, 85, 88, 89], "tune": [69, 71, 75, 76, 85], "qlora": [69, 75], "vllm": [69, 73, 80], "sglang": [69, 80], "hug": [69, 75], "face": [69, 72, 75, 76, 86], "advanc": [69, 77, 79, 85, 88, 89], "export": [69, 72], "x86": [69, 73], "intel": [69, 85, 88], "openvino": [69, 73], "5x": 71, "cluster": [71, 72], "34": 71, "43x": 71, "2k": 71, "h200": 71, "latest": 71, "offic": 71, "offici": [71, 72], "sever": [71, 81, 85, 90], "popular": 71, "flagship": 71, "form": [71, 72, 76], "quickli": [71, 79], "batteri": 71, "fork": 71, "build": [71, 72, 76, 79, 81, 86], "top": [71, 72, 79, 85, 86, 87, 88, 89], "virtual": 71, "environ": [71, 75], "conda": 71, "venv": 71, "download": [71, 75, 82, 84, 86, 87, 89], "job": 71, "below": [71, 72, 76, 79, 80, 81, 84, 85], "root": [71, 75], "launch": 71, "ngpu": 71, "config_fil": 71, "train_config": 71, "llama3_8b": 71, "toml": 71, "run_train": 71, "sh": [71, 75], "hyperparamet": 71, "edit": [71, 75], "line": [71, 76, 80], "flag": [71, 87], "termin": 71, "look": [71, 72, 76, 85, 86, 87, 88, 89], "rank0": 71, "titan": 71, "2025": 71, "06": 71, "04": 71, "08": 71, "51": 71, "48": 71, "info": 71, "2254": 71, "27": 71, "34gib": 71, "28": 71, "78": 71, "tp": [71, 81], "375": 71, "tflop": 71, "21": 71, "73": [71, 77], "mfu": 71, "20": [71, 75, 87], "58": 71, "557": 71, "7069": 71, "99gib": 71, "62": 71, "034": 71, "35": [71, 75, 77], "41": [71, 75], "19": 71, "52": 71, "224": [71, 77, 85, 86, 87, 88, 89], "9196": 71, "022": 71, "406": [71, 86, 87], "65": 71, "904": 71, "1423": 71, "014": 71, "23": [71, 77], "As": [71, 86, 90], "warmup": [71, 73], "7k": 71, "99gb": 71, "peak": [71, 75, 80], "against": 71, "02": 71, "37": 71, "404": 71, "2611": 71, "22gib": 71, "595": 71, "47": 71, "49": [71, 77], "027": 71, "4260": 71, "89gib": 71, "344": 71, "367": 71, "39": 71, "03": 71, "01": 71, "988": 71, "9482": 71, "321": 71, "366": 71, "14": 71, "991": 71, "1183": 71, "300": 71, "364": 71, "89": 71, "40": 71, "4659": 71, "291": 71, "84": 71, "769": 71, "gc": 71, "peform": 71, "period": 71, "collect": [71, 76], "3k": 71, "89gb": 71, "11x": 71, "nearli": 71, "ident": [71, 76], "performan": 71, "v": [71, 76, 86, 90], "curv": [71, 76], "omit": [71, 72, 86, 87, 88], "648": 71, "2648": 71, "28gib": 71, "71": 71, "26": 71, "475": 71, "9106": 71, "91gib": 71, "53": [71, 75], "503": 71, "434": 71, "43": 71, "94": [71, 86], "166": 71, "0774": 71, "663": 71, "443": 71, "44": [71, 77], "87": 71, "50": [71, 76, 77, 85, 86, 88, 89], "885": 71, "3233": 71, "643": 71, "442": 71, "66": [71, 75, 77], "76": 71, "613": 71, "6150": 71, "637": 71, "72": [71, 75], "6k": 71, "91gb": 71, "21x": [71, 75], "tl": 71, "dr": 71, "priorit": 71, "accur": [71, 76, 85], "stabil": 71, "cost": [71, 77], "slightli": [71, 79], "impact": [71, 75, 81], "outlier": 71, "caus": 71, "underflow": 71, "8xh100": 71, "box": [71, 76, 88], "toi": [71, 73, 77, 79, 88], "convert_to_float8_train": 71, "recurs": 71, "kind": [71, 86], "over": [71, 76, 86, 87], "snippet": [71, 86, 87], "float8_linear_util": 71, "float8_linear": 71, "sampl": [71, 86, 88, 89], "adamw": 71, "being": [71, 76, 81, 88, 89], "elig": 71, "last": [71, 85], "divis": 71, "label": 71, "fake_label": 71, "ones_lik": 71, "mse_loss": 71, "model_state_dict": 71, "state_dict": [71, 73, 74, 86, 87], "optimizer_state_dict": 71, "pth": [71, 73, 86, 87], "explor": [71, 73, 89], "few": [71, 79, 86, 87], "lai": 72, "awq": 72, "gptq": 72, "int4tensor": 72, "int4preshuffledtensor": 72, "uint1": 72, "uint7": 72, "float3": 72, "triton": [72, 88, 89], "overload": [72, 76], "term": [72, 76, 86, 90], "extra": [72, 75], "float4_e2m1fn_x2": 72, "float8_e4m3fnuz": 72, "float8_e5m2": 72, "float8_e5m2fnuz": 72, "float8_e8m0fnu": 72, "pr": 72, "shell": 72, "dervi": 72, "mxfp8": 72, "preicison": 72, "choose_qparam": 72, "mention": [72, 86], "accommod": 72, "choose_qparams_affine_with_min_max": 72, "min": [72, 77, 79, 86, 90], "raw": 72, "quantize_fp8_row": 72, "int_matmul": 72, "int_scaled_matmul": 72, "reli": [72, 73, 76, 77, 79], "handwritten": 72, "On": 72, "glue": 72, "everyth": 72, "togeth": [72, 75, 86, 88, 90], "anoth": [72, 76, 79, 86, 90], "side": 72, "swizzl": 72, "dtpype": 72, "float8rowwisetensor": 72, "float8blockwisetensor": 72, "confus": [72, 76, 86], "close": [72, 76], "low_precision_v": 72, "high_precision_v": 72, "procedur": 72, "especi": [72, 74, 76, 88, 89], "bitwidth": [72, 90], "codebook": 72, "index": [72, 75, 76, 89], "vector": [72, 76, 88], "kmean": 72, "tradition": 72, "explain": [72, 85, 88], "simplest": [72, 76], "easi": [72, 75], "linear_modul": 72, "runtim": [72, 73, 86], "question": [72, 74, 76, 79, 90], "activation_granular": 72, "act_quant_kwarg": 72, "weight_granular": [72, 75], "quantized_weight": [72, 81], "float8_dtyp": 72, "haven": 72, "seen": 72, "pt2": [72, 79, 88], "autoround": 72, "multitensor": 72, "sure": [72, 75, 90], "open": [72, 76], "describ": [72, 74, 76, 84, 86, 87], "advis": 72, "finetun": [72, 75], "quantized_train": 72, "extend": [72, 76, 88], "progress": [72, 80, 81], "lot": [72, 76], "connect": [72, 90], "walk": [72, 77, 79, 84, 85, 88], "float8dynamicactivationfloat8weightconfig": [72, 80], "happen": [72, 79, 86, 88], "len": [72, 75, 81, 86, 87, 90], "_choose_quant_func_and_quantize_tensor": 72, "relat": [72, 76], "xq": 72, "reshap": [72, 86, 87], "wq": 72, "x_scale": [72, 86], "w_scale": 72, "out_shap": 72, "entri": 73, "mutat": 73, "simpl": [73, 76, 77, 79, 85, 88, 89], "toylinearmodel": [73, 74, 77], "hidden_dim": 73, "has_bia": 73, "linear2": [73, 74, 77, 79], "eval": [73, 74, 75, 77, 85, 87, 88, 89], "model_w16a16": 73, "model_w8a8": 73, "chapter": 73, "remain": [73, 88, 89], "unchang": 73, "__name__": 73, "approxim": 73, "2x": [73, 75, 76], "reduct": [73, 74, 75, 76, 79], "disk": 73, "o": [73, 86, 87], "original_s": 73, "getsiz": [73, 86, 87], "quantized_s": 73, "2f": [73, 86, 87], "mb": [73, 74, 83, 86, 87], "00x": 73, "00mb": 73, "faster": [73, 76], "time": [73, 76, 79, 80, 84, 85, 86, 87], "synchron": 73, "100": [73, 79, 86, 87], "original_tim": 73, "quantized_tim": 73, "03x": 73, "larger": 73, "best": [73, 76, 88], "enough": 73, "address": [73, 86], "lm": [73, 75], "recogn": [73, 90], "decis": 73, "pt2e": [73, 85, 86, 87, 88, 89], "fuse": [73, 76, 79, 87], "deleg": [73, 86], "x86inductorquant": [73, 88], "quantize_pt2": [73, 85, 86, 87, 88, 89], "prepare_pt2": [73, 85, 86, 88, 89], "x86_inductor_quant": [73, 88], "get_default_x86_inductor_quantization_config": [73, 88], "float_model": [73, 79, 85, 86, 87, 88, 89], "data_load": [73, 86, 87, 88, 89], "no_grad": [73, 79, 85, 86, 87, 88, 89], "imag": [73, 80, 85, 86, 87, 88, 89], "program": [73, 86, 87, 88, 90], "captur": [73, 86, 87, 90], "expos": [73, 86, 87], "set_glob": [73, 86, 87, 88, 89], "xiq": [73, 88], "prepare_qat_pt2": [73, 87, 88], "sample_inference_data": 73, "convert_pt2": [73, 85, 86, 87, 88, 89], "wrapper": [73, 79, 88], "_inductor": [73, 88], "cpp_wrapper": [73, 88], "optimized_model": [73, 85, 88, 89], "converted_model": [73, 88, 89], "xpu": [73, 89], "visit": 73, "would": [73, 76, 79, 87, 89], "forget": 73, "good": [73, 79, 90], "tempfil": [74, 80], "get_model_size_in_byt": 74, "ref": [74, 86], "namedtemporaryfil": 74, "seek": [74, 76], "m_load": 74, "load_state_dict": [74, 86, 87], "assign": 74, "assert": [74, 77, 79, 81, 90], "equal": [74, 76], "thing": [74, 76, 79, 86], "float_weight1": 74, "float_weight2": 74, "quantized_weight1": 74, "quantized_weight2": 74, "go": [74, 79, 90], "techinqu": 74, "4x": [74, 75], "0625": 74, "reason": [74, 76], "avoid": [74, 76], "affine_quantized_tensor": 74, "deploi": 75, "engin": 75, "seamlessli": [75, 79, 88, 89], "seamless": [75, 88], "hf": [75, 80], "signific": [75, 76], "pip": [75, 80, 85, 86], "url": [75, 89], "whl": [75, 89], "nightli": 75, "cu128": 75, "push": [75, 76, 80, 81], "hub": [75, 80, 81], "server": [75, 81], "phi": 75, "fp8": 75, "microsoft": 75, "o3": 75, "client": 75, "curl": 75, "localhost": 75, "8000": 75, "v1": 75, "chat": 75, "content": 75, "applic": 75, "messag": 75, "role": 75, "give": [75, 76, 79], "me": 75, "short": 75, "larg": [75, 79, 88], "temperatur": 75, "top_p": 75, "95": 75, "top_k": 75, "max_token": 75, "32768": 75, "vram": 75, "15x": 75, "littl": [75, 81], "packag": [75, 80], "git": [75, 80], "com": [75, 80], "acceler": [75, 76, 80], "autotoken": [75, 80], "pipelin": 75, "random": [75, 76, 86, 87], "manual_se": [75, 86, 87], "model_path": 75, "device_map": [75, 80, 81], "trust_remote_cod": 75, "ai": 75, "assist": 75, "eat": 75, "banana": 75, "dragonfruit": 75, "smoothi": 75, "blend": 75, "milk": 75, "honei": 75, "salad": 75, "mix": [75, 85, 88, 89], "slice": [75, 81], "lemon": 75, "juic": 75, "solv": [75, 76, 79], "equat": 75, "pipe": [75, 80], "text": 75, "generation_arg": 75, "max_new_token": 75, "500": 75, "return_full_text": 75, "do_sampl": 75, "generated_text": 75, "design": [75, 81, 85, 86, 90], "lm_head": 75, "those": [75, 76, 77, 79], "ti": 75, "autoprocessor": 75, "modeling_util": 75, "find_tied_paramet": 75, "model_id": [75, 80], "untied_model": 75, "getattr": [75, 81], "get_text_config": 75, "tie_word_embed": 75, "setattr": [75, 79], "_tied_weights_kei": 75, "user_id": 75, "your_user_id": 75, "model_nam": [75, 85, 88, 89], "save_to": [75, 80], "save_to_local_path": 75, "int8dynamicactivationintxweightconfig": [75, 80], "ve": [75, 76], "intxweightonlyconfig": [75, 80], "fqntoconfig": [75, 81], "untied_model_id": 75, "untied_model_local_path": 75, "embedding_config": 75, "weight_scale_dtyp": 75, "quant_config": 75, "embed_token": 75, "quant_typ": [75, 80, 81], "include_embed": 75, "untie_embedding_weight": 75, "modules_to_not_convert": 75, "quantized_model": [75, 79, 80, 85, 86, 87], "safe_seri": [75, 80, 81], "pte": 75, "cd": 75, "install_requir": 75, "phi_4_mini": 75, "convert_weight": 75, "pytorch_model": 75, "bin": 75, "pytorch_model_convert": 75, "export_llama": 75, "kv": 75, "use_sdpa_with_kv_cach": 75, "get_bos_id": 75, "199999": 75, "get_eos_id": 75, "200020": 75, "max_seq_length": 75, "max_context_length": 75, "output_nam": 75, "phi4": 75, "phone": 75, "io": 75, "2gb": 75, "iphon": 75, "pro": [75, 76], "17": 75, "sec": 75, "test": [75, 80, 84, 86, 88], "har": 75, "eleutherai": 75, "lm_eval": 75, "model_arg": 75, "pretrain": [75, 76, 85, 86, 87, 88], "reset_peak_memory_stat": 75, "prompt": [75, 80], "hei": 75, "consciou": 75, "templated_prompt": 75, "apply_chat_templ": 75, "add_generation_prompt": 75, "templat": [75, 82, 83], "return_tensor": 75, "pt": 75, "generated_id": 75, "output_text": 75, "batch_decod": 75, "skip_special_token": 75, "clean_up_tokenization_spac": 75, "respons": 75, "mem": 75, "max_memory_reserv": 75, "1e9": 75, "02f": 75, "gb": 75, "hello": [75, 80], "ye": 75, "am": 75, "digit": 75, "todai": 75, "70": [75, 77], "bench": 75, "vllm_disable_compile_cach": 75, "project": 75, "vllm_use_precompil": 75, "sharegpt": 75, "wget": 75, "co": 75, "anon8231489123": 75, "sharegpt_vicuna_unfilt": 75, "resolv": 75, "sharegpt_v3_unfiltered_cleaned_split": 75, "tree": 75, "num": 75, "benchmark_serv": 75, "16x": 75, "14x": 75, "num_prompt": 75, "req": 75, "57": [75, 77], "1000": [75, 88], "68": 75, "80": 75, "entir": [75, 86, 87], "ml": 75, "gain": [75, 76, 89], "eas": 75, "accept": [75, 90], "trade": [75, 76], "off": [75, 76], "neural": [76, 85, 88], "network": [76, 79, 85, 88], "latenc": 76, "carefulli": 76, "pai": 76, "low": [76, 79, 80, 85], "price": 76, "f1": 76, "problem": [76, 79], "research": [76, 84], "fragment": 76, "rightfulli": 76, "spent": 76, "figur": [76, 86], "compress": [76, 85], "place": [76, 85, 86, 87, 88, 89], "dens": 76, "focu": [76, 79], "realli": 76, "concret": [76, 90], "hope": 76, "modular": 76, "nice": 76, "scratch": [76, 84], "minim": [76, 85, 88, 89], "algorthim": 76, "realiz": 76, "theoret": 76, "analog": 76, "fix": [76, 77], "unstructur": 76, "howev": [76, 80, 81, 87, 90], "retrain": 76, "neglig": 76, "area": 76, "agre": 76, "upon": 76, "consensu": 76, "mind": 76, "thought": 76, "subproblem": 76, "satisfi": 76, "my": [76, 87], "independ": 76, "frontend": [76, 88], "arbitrari": 76, "handoff": 76, "piec": 76, "natur": [76, 79, 86, 90], "clear": 76, "contract": 76, "7x": 76, "advantag": 76, "anticip": 76, "solut": 76, "third": 76, "parti": 76, "to_sparse_semi_structur": 76, "sparsesemistructuredtensor": 76, "weightnormsparsifi": 76, "half": 76, "subnetwork": 76, "sparse_config": 76, "named_modul": 76, "tensor_fqn": 76, "sparse_block_shap": 76, "zeros_per_block": 76, "fakespars": 76, "fundament": [76, 87], "manipul": 76, "paramer": 76, "parameter": 76, "necessari": [76, 77, 79, 85, 86, 87, 88, 89], "suitabl": [76, 88], "spot": 76, "definit": [76, 81], "academia": 76, "industri": 76, "often": [76, 79], "interchang": 76, "distinct": 76, "roughli": 76, "idea": 76, "behind": 76, "doesn": [76, 87, 90], "itself": [76, 79], "loos": 76, "speak": 76, "tightli": 76, "coupl": [76, 79], "csc": 76, "fbgemm": 76, "qnnpack": 76, "descript": [76, 85], "coo": 76, "sparse_coo": 76, "coordin": 76, "locat": 76, "bsr": 76, "sparse_bsr": 76, "veri": [76, 81, 87], "except": [76, 79, 90], "scalar": [76, 86], "dimension": 76, "csr": 76, "sparse_csr": 76, "sparse_csc": 76, "column": 76, "indic": [76, 90], "compact": 76, "sparse_matrix": 76, "1d": 76, "indexptr": 76, "storag": 76, "\u00bd": 76, "bitmask": 76, "2bit": 76, "unprun": 76, "quit": [76, 79], "broken": 76, "down": 76, "sensit": 76, "effect": [76, 77, 79, 88, 89, 90], "subsequ": [76, 79, 88, 89], "infinit": 76, "lost": 76, "degre": 76, "drop": 76, "proxi": 76, "aforement": 76, "smallest": 76, "absolut": 76, "scope": 76, "impli": 76, "respect": [76, 87], "con": 76, "potenti": [76, 77, 85, 86, 88, 89], "sub": 76, "span": 76, "threshold": 76, "normal": [76, 86, 87], "complex": 76, "constant": [76, 79, 86], "ctr_mobile_fe": 76, "score": 76, "w": [76, 81], "tenosr": 76, "udpat": 76, "cannot": [76, 77, 81], "histori": 76, "regrow": 76, "dw": 76, "via": [76, 85], "backprop": 76, "pat": 76, "unmask": 76, "resid": 76, "salienc": 76, "lowest": 76, "l1": 76, "abl": [76, 79, 81, 86, 90], "repeat": [76, 86, 87], "movement": 76, "2005": 76, "07683": 76, "rank": [76, 79], "wx": 76, "sqx": 76, "q": [76, 86], "usual": 76, "sort": 76, "wise": 76, "reconstruct": [76, 81], "randomli": 76, "tri": 76, "remedi": 76, "sometim": 76, "item": [76, 84], "along": [76, 81, 85], "ultim": [76, 77], "complic": [76, 86], "literatur": 76, "vision": 76, "nlp": [76, 84, 88], "again": [76, 86, 90], "iter": [76, 86, 87], "ctr_feed": 76, "na": 76, "multimask": 76, "search": 76, "pyspeech": 76, "fastna": 76, "approach": [76, 79, 85, 88, 89], "knowledg": [76, 84], "distil": 76, "pdf": 76, "2204": 76, "09656": 76, "arrang": 76, "recal": 76, "counterpart": 76, "slower": 76, "suffici": 76, "At": [76, 86], "98": 76, "special": [76, 85, 86], "exhibit": 76, "penalti": 76, "expens": [76, 79], "dictat": 76, "characterist": 76, "highest": 76, "wouldn": [76, 79], "visual": 76, "fig": 76, "4x4": 76, "benchmak": 76, "fly": [77, 80], "affinequantizedminmaxobserv": 77, "record": 77, "welcom": 77, "desir": 77, "averag": [77, 86, 87], "histogram": [77, 86], "act_ob": 77, "finfo": 77, "weight_ob": 77, "observedlinear": 77, "observed_input": 77, "observed_weight": 77, "from_float": [77, 79], "float_linear": 77, "observed_linear": 77, "_replace_with_custom_fn_if_matches_filt": 77, "insert_observers_": 77, "lambda": [77, 81], "replacement_fn": 77, "copied_act_ob": 77, "copied_weight_ob": 77, "popul": 77, "feed": 77, "simpler": [77, 86], "quantizedlinear": [77, 79], "isn": 77, "strictli": 77, "to_affine_quantized_intx_stat": 77, "act_scal": [77, 90], "act_zero_point": 77, "calculate_qparam": [77, 90], "weight_scal": [77, 86, 90], "weight_zero_point": [77, 86], "qweight": 77, "qinput": 77, "from_observ": 77, "quantized_linear": [77, 86], "begin": [77, 79], "dataclass": [77, 81, 90], "transform_modul": [77, 81], "register_quantize_module_handl": [77, 81], "staticquantconfig": 77, "_apply_static_qu": 77, "associ": 77, "identifi": [77, 90], "is_observed_linear": 77, "optimizedmodul": 77, "_orig_mod": 77, "0237": 77, "tensor_impl": 77, "plainaqttensorimpl": 77, "142": 77, "31": [77, 90], "113": 77, "157": 77, "59": 77, "160": 77, "150": 77, "67": 77, "241": 77, "238": 77, "235": 77, "228": 77, "255": [77, 90], "201": 77, "114": 77, "236": 77, "88": [77, 86], "83": 77, "109": 77, "209": 77, "92": 77, "184": 77, "141": 77, "110": 77, "0009": 77, "0010": 77, "130": 77, "122": 77, "132": 77, "125": 77, "126": 77, "129": 77, "127": [77, 79, 89, 90], "133": 77, "124": 77, "131": 77, "135": 77, "136": 77, "_layout": 77, "foundat": 79, "autograd": [79, 90], "interpos": 79, "namespac": 79, "continu": [79, 80, 87, 88, 89, 90], "obviou": 79, "int8quantizedlinear": 79, "finer": 79, "intercept": 79, "contrast": 79, "long": [79, 86], "clunki": 79, "distributedlinear": 79, "duplic": 79, "bypass": 79, "wrap": [79, 88, 89], "outer": 79, "inner": 79, "allgath": 79, "bandwidth": 79, "stai": 79, "exactli": 79, "zoo": 79, "podcast": 79, "edward": 79, "yang": 79, "int8_symmetric_quant": 79, "fp32_tensor": 79, "amin": 79, "amax": 79, "zeros_lik": 79, "view": [79, 86, 87], "clamp": [79, 86], "w_int8": 79, "new_linear": 79, "left": [79, 90], "toymodel": 79, "child": 79, "named_children": 79, "drawback": 79, "won": 79, "suppos": 79, "clean": 79, "eleg": 79, "pretti": 79, "power": [79, 81], "overrid": 79, "almost": 79, "shard": [79, 81], "ragged": 79, "rag": 79, "nestedtensor": 79, "who": 79, "link": [79, 84], "why": [79, 84], "googl": 79, "collab": 79, "flopcount": 79, "memorytrack": 79, "bare": 79, "bone": 79, "int8symmetrictensor": 79, "hold": [79, 80], "int_data": 79, "staticmethod": 79, "_dynamo": 79, "_make_wrapper_subclass": [79, 81], "stride": 79, "storage_offset": 79, "ndim": 79, "extra_metadata": 79, "outer_s": [79, 81], "outer_strid": [79, 81], "undo": 79, "repr": 79, "float_tensor": 79, "ahead": 79, "insid": 79, "int8_tensor": 79, "op_implementations_dict": 79, "conveni": 79, "register_op": 79, "_op": 79, "opoverload": 79, "impl_decor": 79, "op_impl": 79, "done": 79, "particular": 79, "largest": 79, "tell": 79, "desugar": 79, "surfac": 79, "coverag": [79, 85, 86, 88, 89], "brute": 79, "forc": 79, "repeatedli": 79, "log": 79, "loggingtensor": 79, "_python_dispatch": [79, 81], "return_and_correct_alias": [79, 81], "int8_mm": 79, "int8_view_op": 79, "out_data": 79, "out_scal": [79, 86], "notic": 79, "hit": 79, "background": 79, "decomposit": 79, "live": 79, "decomp": 79, "shrink": 79, "author": [79, 84, 85, 86, 87, 88, 89, 90], "But": [79, 81, 90], "pain": 79, "rather": 79, "worth": 79, "written": 79, "differenti": 79, "nuanc": 79, "longer": [79, 86, 87], "had": [79, 86], "transpos": 79, "That": 79, "transposit": 79, "got": [79, 86, 90], "propag": [79, 86, 88, 89], "fact": 79, "themselv": [79, 86], "pointwis": [79, 88, 89], "were": 79, "might": [79, 81, 86, 90], "unwrap": 79, "dim0": 79, "dim1": 79, "confirm": 79, "quantized_model_module_swap": 79, "quantized_model_subclass": 79, "subclass_param": 79, "out_module_swap": 79, "allclos": 79, "out_compil": 79, "seri": 79, "discuss": 79, "float8dynamicactivationint4weightconfig": 80, "use_hqq": [80, 81], "torch_dtyp": 80, "fluxpipelin": 80, "fluxtransformer2dmodel": 80, "black": 80, "forest": 80, "lab": 80, "flux": 80, "subfold": 80, "cat": [80, 90], "sign": [80, 89], "world": [80, 81], "num_inference_step": 80, "guidance_scal": 80, "png": 80, "temporarydirectori": 80, "tmp_dir": 80, "uncom": 80, "usernam": [80, 81], "statu": [80, 81], "becom": [80, 86], "stabl": 80, "int4wo": 80, "team": [80, 81], "retain": 80, "thoroughli": 80, "e2": 81, "_type": 81, "_data": 81, "capabl": [81, 86, 88], "self_attn": 81, "k_proj": 81, "mlp": 81, "gate_proj": 81, "narrow": 81, "host": 81, "state": 81, "chunk": 81, "heavi": 81, "codebas": 81, "fn": 81, "ctx": 81, "new_tensor": 81, "__class__": 81, "principl": 81, "mynewquantconfig": 81, "classvar": 81, "myquantizedtensor": 81, "tensor_data_attr": 81, "quantized_data": 81, "tensor_attribut": 81, "attr": 81, "fill_default": 81, "notimplementederror": 81, "_my_quant_transform": 81, "my_quantization_funct": 81, "use_cutlass_kernel": 81, "my_cutlass_linear": 81, "use_triton_kernel": 81, "my_triton_linear": 81, "standard": 81, "disappear": 81, "unless": 81, "extrem": 81, "sole": 81, "explicitli": [81, 90], "spooki": 81, "distanc": 81, "due": [81, 85, 90], "workaround": 81, "2338": 81, "detect": 81, "illustr": 81, "tutorials_python": 82, "zip": 82, "jupyt": [82, 84], "notebook": [82, 84], "tutorials_jupyt": 82, "galleri": [82, 84], "sphinx": [82, 84], "00": 83, "004": [83, 84], "total": [83, 84], "template_tutori": [83, 84], "click": 84, "firstnam": 84, "lastnam": 84, "prerequisit": [84, 86], "v2": 84, "topic": 84, "rand": [84, 86, 87], "9461": 84, "8876": 84, "8289": 84, "3729": 84, "3630": 84, "8896": 84, "8009": 84, "4157": 84, "6176": 84, "3621": 84, "7363": 84, "9976": 84, "8903": 84, "8098": 84, "4784": 84, "practic": 84, "summar": 84, "takeawai": 84, "link1": 84, "link2": 84, "minut": 84, "ipynb": 84, "daniil": 85, "lyakhov": 85, "aamir": 85, "nazir": 85, "alexand": 85, "suslov": 85, "yamini": 85, "nimmagadda": 85, "kozlov": 85, "subject": [85, 87], "openvinoquant": 85, "unlock": 85, "placement": 85, "simplifi": [85, 86, 88, 89], "ux": [85, 86, 88], "torchdynamo": [85, 88, 89, 90], "four": 85, "eager": [85, 86, 87, 88, 89, 90], "mechan": [85, 88, 89], "torchvis": [85, 86, 87, 88, 89, 90], "resnet18": [85, 86, 87, 88, 89], "__dict__": [85, 86, 87, 88, 89], "dummi": [85, 88, 89], "traced_b": [85, 88, 89], "exported_model": [85, 86, 87, 88, 89], "preset": 85, "elu": 85, "prelu": 85, "gelu": 85, "quantizationpreset": 85, "bert": [85, 88], "modeltyp": 85, "ignored_scop": 85, "exclud": 85, "layer_1": 85, "layer_2": 85, "layer_3": 85, "ignoredscop": 85, "conv2d": [85, 86, 87, 88, 89, 90], "layer_": 85, "subgraph": [85, 87], "node": [85, 87, 88, 89, 90], "target_devic": 85, "taken": 85, "account": 85, "cpu_spr": 85, "npu": 85, "targetdevic": 85, "fold": [85, 86, 88, 89], "batchnorm": [85, 86, 87, 88, 89], "prepared_model": [85, 86, 87, 88, 89], "fold_quant": 85, "finish": [85, 88], "comparison": 85, "smoothquant": 85, "biascorrect": 85, "discrep": 85, "calibration_load": 85, "dataload": [85, 86, 87], "transform_fn": 85, "data_item": 85, "calibration_dataset": 85, "smooth_quant": 85, "fast_bias_correct": 85, "deploy": [85, 88], "jerri": [86, 88, 90], "zhang": [86, 88, 89, 90], "_export": [86, 87], "fx": [86, 90], "14k": 86, "programm": [86, 88, 89], "db": 86, "xnnpack": [86, 87, 90], "xnnpack_quant": [86, 87], "get_symmetric_quantization_config": [86, 87], "xnnpackquant": [86, 87, 90], "prior": 86, "qconfigmap": [86, 90], "backendconfig": [86, 90], "rel": 86, "intent": [86, 90], "qconfig": [86, 90], "3d": [86, 90], "incompat": 86, "great": 86, "ideal": 86, "fake_qu": 86, "hidden": 86, "summari": 86, "interact": 86, "thu": 86, "queri": [86, 90], "previous": 86, "embedding_byt": 86, "executorchquant": 86, "concaten": 86, "prone": 86, "cleaner": 86, "composed_quant": 86, "quantization_cap": 86, "concern": 86, "decoupl": 86, "minmax": 86, "freed": 86, "identitc": 86, "imagenet": [86, 87], "unzip": [86, 87], "data_path": [86, 87], "renam": [86, 87], "resnet18_pretrained_float": [86, 87], "sy": [86, 87], "numpi": [86, 87], "np": [86, 87], "resnet": [86, 87, 88], "warn": [86, 87], "filterwarn": [86, 87], "categori": [86, 87], "deprecationwarn": [86, 87], "r": [86, 87], "seed": [86, 87], "191009": [86, 87], "averagemet": [86, 87], "fmt": [86, 87], "reset": [86, 87], "val": [86, 87], "avg": [86, 87], "count": [86, 87], "__str__": [86, 87], "fmtstr": [86, 87], "topk": [86, 87], "predict": [86, 87], "maxk": [86, 87], "pred": [86, 87], "correct": [86, 87], "eq": [86, 87], "expand_a": [86, 87], "correct_k": [86, 87], "mul_": [86, 87], "criterion": [86, 87], "top1": [86, 87], "top5": [86, 87], "cnt": [86, 87], "acc1": [86, 87], "acc5": [86, 87], "load_model": [86, 87], "model_fil": [86, 87], "weights_onli": [86, 87], "print_size_of_model": [86, 87], "temp": [86, 87], "p": [86, 87], "1e6": [86, 87], "prepare_data_load": [86, 87], "485": [86, 87], "456": [86, 87], "std": [86, 87], "229": [86, 87], "225": [86, 87], "randomresizedcrop": [86, 87], "randomhorizontalflip": [86, 87], "totensor": [86, 87], "dataset_test": [86, 87], "resiz": [86, 87], "centercrop": [86, 87], "train_sampl": [86, 87], "randomsampl": [86, 87], "test_sampl": [86, 87], "sequentialsampl": [86, 87], "train_batch_s": [86, 87], "sampler": [86, 87], "data_loader_test": [86, 87, 88, 89], "eval_batch_s": [86, 87], "saved_model_dir": [86, 87], "float_model_fil": [86, 87], "model_to_quant": [86, 87], "capture_pre_autograd_graph": [86, 87], "dynamic_shap": [86, 87], "dynamic_dim": [86, 87], "constraint": [86, 87, 90], "qconfig_opt": 86, "set_object_typ": 86, "set_module_nam": 86, "workload": 86, "themodel": 86, "feedback": 86, "dq": 86, "fp32_op": 86, "qauntiz": 86, "x_int8": 86, "x_zero_point": 86, "weight_int8": 86, "bias_fp32": 86, "output_scal": 86, "output_zero_point": 86, "x_fp32": 86, "quantized_decompos": 86, "dequantize_per_tensor": 86, "x_i8": 86, "x_quant_min": 86, "x_quant_max": 86, "weight_fp32": 86, "weight_i8": 86, "weight_quant_min": 86, "weight_quant_max": 86, "weight_permut": 86, "permute_copi": 86, "out_fp32": 86, "addmm": 86, "out_i8": 86, "quantize_per_tensor": 86, "out_zero_point": 86, "out_quant_min": 86, "out_quant_max": 86, "float32_op": 86, "decompos": 86, "use_reference_represent": 86, "x_int16": 86, "int16": 86, "weight_int16": 86, "acc_int32": 86, "out_dtyp": 86, "bias_scal": 86, "bias_int32": 86, "div": 86, "mul": 86, "out_int8": 86, "qmin": 86, "qmax": 86, "date": 86, "unus": 86, "serila": 86, "consult": 86, "exportedprogram": 86, "pt2e_quantized_model_file_path": 86, "resnet18_pt2e_quant": 86, "quantized_ep": 86, "loaded_quantized_ep": 86, "loaded_quantized_model": 86, "diff": 86, "79": 86, "82": 86, "55": 86, "edg": [86, 90], "went": 86, "andrew": 87, "Or": 87, "move_exported_model_to_ev": [87, 88], "correctli": 87, "certain": 87, "dropout": 87, "move_exported_model_to_train": 87, "jit": 87, "recursivescriptmodul": 87, "train_one_epoch": 87, "ntrain_batch": 87, "avgloss": 87, "5f": 87, "start_tim": 87, "3f": 87, "global_avg": 87, "is_qat": [87, 88], "fusion": 87, "batchnorm2d": 87, "_native_batch_norm_legit": 87, "cudnn_batch_norm": 87, "mobilenetv2": 87, "manual": 87, "recompil": 87, "consolid": 87, "epoch": 87, "far": 87, "num_epoch": 87, "num_train_batch": 87, "num_eval_batch": 87, "num_observer_update_epoch": 87, "num_batch_norm_update_epoch": 87, "num_epochs_between_ev": 87, "nepoch": 87, "stat": 87, "subseq": 87, "disable_observ": 87, "bn": 87, "running_mean": 87, "running_var": 87, "new_arg": 87, "wish": 87, "prepared_model_copi": 87, "neval_batch": 87, "paus": 87, "resum": 87, "fail": [87, 90], "checkpoint_path": 87, "checkpoint_": 87, "behav": 87, "incorrectli": 87, "lesli": [88, 90], "fang": [88, 90], "weiwen": [88, 90], "xia": [88, 90], "jiong": [88, 90], "gong": [88, 90], "cnn": 88, "rnn": 88, "outstand": 88, "fourth": 88, "spr": 88, "xeon": 88, "processor": 88, "boost": 88, "memory_format": [88, 89], "channels_last": [88, 89], "onednn": [88, 89], "assum": [88, 90], "word": 88, "satur": 88, "extern": 88, "pure": 88, "dedic": 88, "scenario": [88, 89], "plai": [88, 89], "convolut": [88, 89, 90], "absenc": [88, 89], "enhanc": [88, 89], "mirror": [88, 89], "autocast": [88, 89], "device_typ": [88, 89], "turn": [88, 89], "cpp": 88, "qconvolut": [88, 89], "qlinear": [88, 89], "presenc": [88, 89], "pair": [88, 89], "conting": [88, 89], "qmaxpool2d": [88, 89], "torchinductor_freez": [88, 89], "example_x86inductorquantizer_pytorch_2_1": 88, "torchbench": 88, "measur": 88, "proven": 88, "depth": 88, "example_x86inductorquantizer_qat": 88, "yan": 89, "zhiwei": 89, "wang": 89, "eikan": 89, "liangang": 89, "liu": 89, "river": 89, "cui": 89, "yifeng": 89, "xpuinductorquant": 89, "pip3": 89, "torchaudio": 89, "xpu_inductor_quantizer_exampl": 89, "xpu_inductor_quant": 89, "xpuiq": 89, "resnet18_weight": 89, "get_default_xpu_inductor_quantization_config": 89, "wherea": 89, "histogramobserv": [89, 90], "perchannelminmaxobserv": 89, "quantizationspec": [89, 90], "quantizationconfig": [89, 90], "type_check": 89, "observerorfakequantizeconstructor": 89, "get_xpu_inductor_symm_quantization_config": 89, "extra_arg": 89, "act_observer_or_fake_quant_ctr": 89, "act_quantization_spec": [89, 90], "qscheme": [89, 90], "per_tensor_symmetr": [89, 90], "observer_or_fake_quant_ctr": [89, 90], "with_arg": [89, 90], "weight_observer_or_fake_quant_ctr": 89, "weight_quantization_spec": [89, 90], "per_channel_symmetr": 89, "ch_axi": 89, "oc": 89, "ic": 89, "kh": 89, "kw": 89, "conv": [89, 90], "bias_quantization_spec": 89, "amp": 89, "indcutor": 89, "kimish": 90, "patel": 90, "made": 90, "explicit": 90, "quantiat": 90, "encod": 90, "convei": 90, "quantizationannot": 90, "furthermor": 90, "minmaxobserv": 90, "input_qspec_map": 90, "output_qspec": 90, "_annot": 90, "conclud": 90, "matcher": 90, "get_source_partit": 90, "add_partit": 90, "gm": 90, "itertool": 90, "chain": 90, "add_nod": 90, "output_nod": 90, "per_tensor_affin": 90, "input_act_qspec": 90, "output_act_qspec": 90, "input_act0": 90, "input_act1": 90, "quantization_annot": 90, "substitut": 90, "among": 90, "sharedquantizationspec": 90, "maxpool": 90, "average_pool": 90, "concat": 90, "whose": 90, "edgeornod": 90, "transit": 90, "spec": 90, "conv1": 90, "conv2": 90, "fed": 90, "conv1_out": 90, "conv2_out": 90, "qspec1": 90, "cat_input0": 90, "cat_input1": 90, "implicitli": 90, "therefor": 90, "ob": 90, "consum": 90, "rewrit": 90, "share_qparams_with_input_act0_qspec": 90, "known": 90, "beforehand": 90, "sigmoid": 90, "fixedqparamsquantizationspec": 90, "act_qspec": 90, "sigmoid_nod": 90, "input_act": 90, "derivedquantizationspec": 90, "derive_qparams_fn": 90, "observerorfakequant": 90, "observerbas": 90, "fakequantizebas": 90, "heurist": 90, "obejct": 90, "obs_or_fq": 90, "fq": 90, "act_obs_or_fq": 90, "weight_obs_or_fq": 90, "act_zp": 90, "weight_zp": 90, "bias_qspec": 90, "derived_from": 90, "backendquant": 90, "get_input_act_qspec": 90, "get_output_act_qspec": 90, "get_weight_qspec": 90, "get_bias_qspec": 90, "intermedi": 90, "straightforward": 90, "call_funct": 90, "relu_": 90, "relu_nod": 90, "maybe_conv_nod": 90, "conv1d": 90, "unexpect": 90, "recognz": 90, "unquant": 90, "subgraphmatch": 90, "conv_relu_pattern": 90, "name_node_map": 90, "input_nod": 90, "weight_nod": 90, "bias_nod": 90, "caveat": 90, "exhaust": 90, "2d": 90, "4d": 90, "symbol": 90, "outcom": 90}, "objects": {"torchao.float8": [[12, 0, 1, "", "CastConfig"], [13, 0, 1, "", "Float8LinearConfig"], [14, 0, 1, "", "ScalingGranularity"], [15, 0, 1, "", "ScalingType"], [16, 2, 1, "", "convert_to_float8_training"], [17, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[13, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[18, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [19, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [20, 0, 1, "", "Float8WeightOnlyConfig"], [21, 0, 1, "", "FqnToConfig"], [22, 0, 1, "", "Int4WeightOnlyConfig"], [23, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [24, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [25, 0, 1, "", "Int8WeightOnlyConfig"], [26, 0, 1, "", "MappingType"], [27, 0, 1, "", "TorchAODType"], [28, 2, 1, "", "choose_qparams_affine"], [29, 2, 1, "", "choose_qparams_affine_with_min_max"], [30, 2, 1, "", "dequantize_affine"], [31, 2, 1, "", "int_scaled_matmul"], [56, 2, 1, "", "quantize_"], [61, 2, 1, "", "quantize_affine"], [62, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[32, 0, 1, "", "ComposableQATQuantizer"], [33, 0, 1, "", "FakeQuantizeConfigBase"], [34, 0, 1, "", "FakeQuantizedEmbedding"], [35, 0, 1, "", "FakeQuantizedLinear"], [36, 0, 1, "", "FakeQuantizerBase"], [37, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [38, 0, 1, "", "Float8FakeQuantizeConfig"], [39, 0, 1, "", "Float8FakeQuantizer"], [40, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [41, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [42, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [43, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [44, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [45, 0, 1, "", "IntxFakeQuantizeConfig"], [46, 0, 1, "", "IntxFakeQuantizer"], [47, 0, 1, "", "QATConfig"], [48, 0, 1, "", "QATStep"], [51, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[34, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[35, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[37, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[39, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[41, 1, 1, "", "convert"], [41, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[45, 3, 1, "", "group_size"], [45, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[46, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[49, 0, 1, "", "Int4WeightOnlyEmbedding"], [50, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[49, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[52, 0, 1, "", "Int4WeightOnlyQATLinear"], [53, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [54, 2, 1, "", "disable_linear_fake_quant"], [55, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[57, 0, 1, "", "KernelPreference"], [58, 0, 1, "", "PackingFormat"], [59, 0, 1, "", "QuantizeTensorKwargs"], [60, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[57, 4, 1, "", "AUTO"], [57, 4, 1, "", "MSLK"], [57, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[58, 4, 1, "", "PLAIN"]], "torchao": [[5, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[63, 0, 1, "", "PerChannelNormObserver"], [64, 0, 1, "", "WandaSparsifier"], [65, 2, 1, "", "apply_fake_sparsity"], [66, 4, 1, "", "semi_sparse_weight"], [67, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[63, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[64, 1, 1, "", "prepare"], [64, 1, 1, "", "squash_mask"], [64, 1, 1, "", "update_mask"]], "torchao.utils": [[68, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[68, 1, 1, "", "get_layout"], [68, 1, 1, "", "get_tensor_impl_constructor"], [68, 1, 1, "", "implements"], [68, 1, 1, "", "implements_torch_function"], [68, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 9, 11, 69, 71, 72, 81], "float8": [0, 11, 71, 72], "main": [0, 3, 4], "train": [0, 11, 71, 72, 75, 85, 86, 87, 88, 89], "api": [0, 1, 3, 4, 6, 7, 11, 69, 71, 90], "other": [0, 9, 72], "type": [0, 80], "refer": [1, 69], "python": 1, "kernel": [2, 9, 70, 72, 81], "quantiz": [3, 4, 6, 11, 56, 69, 72, 73, 75, 77, 78, 79, 80, 81, 85, 86, 87, 88, 89, 90], "qat": [3, 11, 87], "config": 3, "quantize_": [3, 4, 6], "custom": [3, 9], "legaci": 3, "prototyp": 3, "infer": [4, 75], "primit": [4, 72], "sparsiti": [5, 76], "util": 6, "tensor": [6, 9, 72, 78, 79, 81, 90], "subclass": [6, 9, 79, 81], "common": [6, 7, 90], "benchmark": [7, 8, 9, 75], "guid": [7, 8, 9, 73, 81], "add": [7, 81], "an": [7, 74], "recip": [7, 71], "model": [7, 9, 71, 72, 73, 74, 75, 80, 81, 85, 86, 87], "design": [7, 76], "consider": 7, "hf": 7, "ci": 7, "dashboard": 7, "1": [7, 11, 71, 75, 80, 81, 85, 88, 89, 90], "modifi": 7, "exist": 7, "configur": [7, 76, 81, 86, 87], "2": [7, 11, 73, 75, 80, 81, 85, 86, 87, 88, 89, 90], "run": 7, "3": [7, 11, 75, 81, 85, 88, 89, 90], "output": [7, 79], "format": [7, 72], "4": [7, 85, 90], "integr": [7, 11, 80, 81], "pipelin": 7, "troubleshoot": 7, "test": [7, 9], "issu": 7, "best": 7, "practic": 7, "user": 8, "contributor": 9, "gener": 9, "extend": 9, "ad": [9, 81], "new": [9, 81], "effici": [9, 72], "triton": 9, "hand": 9, "written": 9, "us": [9, 90], "kernelprefer": [9, 57], "flow": [9, 72, 74, 81, 90], "torch": [9, 85, 86, 87], "compil": [9, 81, 85], "perform": [9, 70, 75, 86], "serial": [9, 74, 81], "featur": 9, "support": [9, 80, 81], "function": [9, 86, 87], "compos": 9, "microbenchmark": 9, "eval": [9, 86], "dtype": [10, 72], "part": [11, 71, 75], "fine": 11, "tune": 11, "qlora": 11, "awar": [11, 72, 87, 88], "option": [11, 75, 84, 85], "torchtun": 11, "axolotl": 11, "low": [11, 72], "rank": 11, "adapt": 11, "huggingfac": [11, 75, 81], "peft": 11, "castconfig": 12, "float8linearconfig": 13, "scalinggranular": 14, "scalingtyp": 15, "convert_to_float8_train": 16, "precompute_float8_dynamic_scale_for_fsdp": 17, "float8dynamicactivationfloat8weightconfig": 18, "float8dynamicactivationint4weightconfig": 19, "float8weightonlyconfig": 20, "fqntoconfig": 21, "int4weightonlyconfig": 22, "int8dynamicactivationint4weightconfig": 23, "int8dynamicactivationint8weightconfig": 24, "int8weightonlyconfig": 25, "mappingtyp": 26, "torchaodtyp": 27, "choose_qparams_affin": 28, "choose_qparams_affine_with_min_max": 29, "dequantize_affin": 30, "int_scaled_matmul": 31, "composableqatquant": 32, "fakequantizeconfigbas": 33, "fakequantizedembed": 34, "fakequantizedlinear": 35, "fakequantizerbas": 36, "float8actint4weightqatquant": 37, "float8fakequantizeconfig": 38, "float8fakequant": 39, "fromintxquantizationawaretrainingconfig": 40, "int4weightonlyembeddingqatquant": 41, "int4weightonlyqatquant": 42, "int8dynactint4weightqatquant": 43, "intxquantizationawaretrainingconfig": 44, "intxfakequantizeconfig": 45, "intxfakequant": 46, "qatconfig": 47, "qatstep": 48, "int4weightonlyembed": 49, "int4weightonlyqatembed": 50, "initialize_fake_quant": 51, "int4weightonlyqatlinear": 52, "int8dynactint4weightqatlinear": 53, "disable_linear_fake_qu": 54, "enable_linear_fake_qu": 55, "packingformat": 58, "quantizetensorkwarg": 59, "_choose_quant_func_and_quantize_tensor": 60, "quantize_affin": 61, "safe_int_mm": 62, "perchannelnormobserv": 63, "wandasparsifi": 64, "apply_fake_spars": 65, "semi_sparse_weight": 66, "sparsifi": 67, "torchaobasetensor": 68, "welcom": 69, "document": 69, "get": 69, "start": [69, 73, 80], "develop": 69, "note": [69, 71, 90], "eager": 69, "tutori": [69, 84], "pt2e": [69, 90], "pre": 71, "torchtitan": 71, "prerequisit": [71, 85, 88, 89, 90], "rowwis": 71, "scale": 71, "tensorwis": 71, "pick": 71, "import": [71, 86, 87], "directli": [71, 90], "convers": 71, "overview": [72, 76, 84], "basic": 72, "op": 72, "deriv": [72, 90], "pack": 72, "algorithm": 72, "weight": [72, 73, 75], "onli": 72, "dynam": [72, 73], "activ": [72, 73], "static": [72, 77], "bit": [72, 73], "optim": [72, 74, 75], "case": 72, "studi": 72, "how": [72, 86, 87, 90], "work": 72, "dure": 72, "execut": 72, "save": [72, 80, 86, 87], "load": [72, 86, 87], "quick": [73, 80], "first": 73, "exampl": [73, 80, 81, 90], "set": [73, 86], "up": 73, "w8a8": 73, "int": 73, "8": 73, "size": [73, 86], "comparison": 73, "speedup": 73, "pytorch": [73, 85, 86, 87, 88, 89, 90], "export": [73, 75, 85, 86, 87, 88, 89, 90], "next": [73, 79], "step": [73, 75, 79, 81, 84], "deseri": 74, "what": [74, 79], "happen": 74, "when": 74, "serv": [75, 81], "vllm": [75, 81], "sglang": 75, "executorch": 75, "post": [75, 85, 86, 88, 89], "transform": [75, 80, 81], "mobil": 75, "deploy": 75, "unti": 75, "embed": 75, "creat": [75, 81], "characterist": 75, "evalu": [75, 86], "qualiti": 75, "assess": 75, "memori": 75, "latenc": 75, "result": 75, "h100": 75, "machin": 75, "conclus": [75, 84, 85, 86, 87, 88, 89, 90], "goal": 76, "context": 76, "prune": 76, "criteria": 76, "strategi": 76, "pattern": [76, 90], "calibr": [77, 86], "phase": 77, "write": [78, 79, 90], "your": [78, 79, 81], "own": [78, 79], "advanc": 78, "ar": 79, "modul": 79, "swap": 79, "which": 79, "oper": [79, 81, 90], "should": 79, "we": 79, "implement": [79, 81], "compar": 79, "hug": 80, "face": 80, "usag": [80, 81], "diffus": 80, "architectur": 81, "system": 81, "class": 81, "fqn": 81, "method": 81, "minim": 81, "requir": 81, "compat": 81, "why": 81, "regist": 81, "": 81, "kei": 81, "detail": 81, "hardwar": 81, "specif": [81, 86, 87], "linear": 81, "benefit": 81, "trade": 81, "off": 81, "share": [81, 90], "safetensor": 81, "diagram": 81, "high": 81, "level": 81, "point": 81, "dispatch": 81, "bring": 81, "extern": 81, "comput": 83, "time": 83, "templat": 84, "addit": 84, "exercis": 84, "further": 84, "read": 84, "openvino": 85, "backend": [85, 86, 87, 88, 89], "introduct": [85, 88, 89, 90], "nncf": 85, "instal": 85, "captur": [85, 88, 89], "fx": [85, 88, 89], "graph": [85, 88, 89], "appli": [85, 88, 89], "lower": [85, 86, 88, 89], "represent": 85, "improv": 85, "metric": 85, "motiv": [86, 90], "defin": [86, 87], "helper": [86, 87], "prepar": [86, 87], "dataset": [86, 87], "mode": 86, "convert": [86, 87], "check": 86, "accuraci": 86, "debug": 86, "loop": 87, "checkpoint": 87, "x86": 88, "through": [88, 89], "inductor": [88, 89], "intel": 89, "gpu": 89, "annot": 90, "param": 90, "fix": 90, "paramet": 90, "5": 90, "A": 90, "toi": 90, "resnet18": 90, "ir": 90, "problem": 90, "match": 90, "aten": 90, "recommend": 90, "subgraphmatcherwithnamenodemap": 90}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao API Reference": [[1, "torchao-api-reference"]], "Python API Reference": [[1, null]], "torchao.kernel": [[2, "torchao-kernel"]], "torchao.quantization.qat": [[3, "torchao-quantization-qat"]], "Main Config for quantize_": [[3, "main-config-for-quantize"]], "Custom QAT APIs": [[3, "custom-qat-apis"]], "Legacy QAT APIs": [[3, "legacy-qat-apis"]], "Prototype": [[3, "prototype"]], "torchao.quantization": [[4, "torchao-quantization"]], "Main Quantization APIs": [[4, "main-quantization-apis"]], "Inference APIs for quantize_": [[4, "inference-apis-for-quantize"]], "Quantization Primitives": [[4, "quantization-primitives"]], "torchao.sparsity": [[5, "module-torchao.sparsity"]], "torchao.utils": [[6, "torchao-utils"]], "Tensor Subclass Utils": [[6, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[6, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[6, "quantize-api-common-utils"]], "Benchmarking API Guide": [[7, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[7, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[7, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[7, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[7, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[7, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[7, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[7, "run-ci-benchmarks"]], "3. CI Output Format": [[7, "ci-output-format"]], "4. Integration with CI Pipeline": [[7, "integration-with-ci-pipeline"]], "Troubleshooting": [[7, "troubleshooting"]], "Running Tests": [[7, "running-tests"]], "Common Issues": [[7, "common-issues"]], "Best Practices": [[7, "best-practices"]], "Benchmarking User Guide": [[8, "benchmarking-user-guide"]], "Contributor Guide": [[9, "contributor-guide"]], "General Guide on Extending torchao": [[9, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[9, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[9, "adding-efficient-kernels"]], "Custom triton kernels": [[9, "custom-triton-kernels"]], "Custom hand written kernels": [[9, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[9, "using-hand-written-kernels-in-tensor-subclasses"]], "KernelPreference": [[9, "kernelpreference"], [57, "kernelpreference"]], "Flow": [[9, "flow"]], "Using torch.compile for Performance": [[9, "using-torch-compile-for-performance"]], "Serialization": [[9, "serialization"], [74, "serialization"]], "Other Feature Support": [[9, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[9, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[9, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[9, "model-benchmarks-and-eval"]], "Dtypes": [[10, "dtypes"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[11, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[11, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[11, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[11, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[11, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[11, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[11, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[11, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[11, "float8-quantized-fine-tuning"]], "CastConfig": [[12, "castconfig"]], "Float8LinearConfig": [[13, "float8linearconfig"]], "ScalingGranularity": [[14, "scalinggranularity"]], "ScalingType": [[15, "scalingtype"]], "convert_to_float8_training": [[16, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[17, "precompute-float8-dynamic-scale-for-fsdp"]], "Float8DynamicActivationFloat8WeightConfig": [[18, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[19, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[20, "float8weightonlyconfig"]], "FqnToConfig": [[21, "fqntoconfig"]], "Int4WeightOnlyConfig": [[22, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[23, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[24, "int8dynamicactivationint8weightconfig"]], "Int8WeightOnlyConfig": [[25, "int8weightonlyconfig"]], "MappingType": [[26, "mappingtype"]], "TorchAODType": [[27, "torchaodtype"]], "choose_qparams_affine": [[28, "choose-qparams-affine"]], "choose_qparams_affine_with_min_max": [[29, "choose-qparams-affine-with-min-max"]], "dequantize_affine": [[30, "dequantize-affine"]], "int_scaled_matmul": [[31, "int-scaled-matmul"]], "ComposableQATQuantizer": [[32, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[33, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[34, "fakequantizedembedding"]], "FakeQuantizedLinear": [[35, "fakequantizedlinear"]], "FakeQuantizerBase": [[36, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[37, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[38, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[39, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[40, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[41, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[42, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[43, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[44, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[45, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[46, "intxfakequantizer"]], "QATConfig": [[47, "qatconfig"]], "QATStep": [[48, "qatstep"]], "Int4WeightOnlyEmbedding": [[49, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[50, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[51, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[52, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[53, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[54, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[55, "enable-linear-fake-quant"]], "quantize": [[56, "quantize"]], "PackingFormat": [[58, "packingformat"]], "QuantizeTensorKwargs": [[59, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[60, "choose-quant-func-and-quantize-tensor"]], "quantize_affine": [[61, "quantize-affine"]], "safe_int_mm": [[62, "safe-int-mm"]], "PerChannelNormObserver": [[63, "perchannelnormobserver"]], "WandaSparsifier": [[64, "wandasparsifier"]], "apply_fake_sparsity": [[65, "apply-fake-sparsity"]], "semi_sparse_weight": [[66, "semi-sparse-weight"]], "sparsify": [[67, "sparsify"]], "TorchAOBaseTensor": [[68, "torchaobasetensor"]], "Welcome to the torchao Documentation": [[69, "welcome-to-the-torchao-documentation"]], "Getting Started": [[69, null]], "Developer Notes": [[69, null]], "API Reference": [[69, null]], "Eager Quantization Tutorials": [[69, null]], "PT2E Quantization Tutorials": [[69, null]], "Performant Kernels": [[70, "performant-kernels"]], "(Part 1) Pre-training with float8": [[71, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[71, "pre-training-with-torchtitan"]], "Prerequisites": [[71, "prerequisites"], [71, "id1"], [85, "prerequisites"], [88, "prerequisites"], [89, "prerequisites"]], "Rowwise scaling": [[71, "rowwise-scaling"]], "Tensorwise scaling": [[71, "tensorwise-scaling"]], "Picking a recipe": [[71, "picking-a-recipe"]], "Important notes": [[71, "important-notes"]], "Pre-training with torchao directly": [[71, "pre-training-with-torchao-directly"]], "Model conversion API": [[71, "model-conversion-api"]], "Quantization Overview": [[72, "quantization-overview"]], "Basic DTypes": [[72, "basic-dtypes"]], "Quantization Primitive Ops": [[72, "quantization-primitive-ops"]], "Efficient kernels": [[72, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[72, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[72, "quantization-algorithms-flows"]], "Weight Only Quantization": [[72, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[72, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[72, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[72, "other-quantization-flows"]], "Training": [[72, "training"]], "Quantization Aware Training": [[72, "quantization-aware-training"], [88, "quantization-aware-training"]], "Low Bit Optimizers": [[72, "low-bit-optimizers"]], "Quantized Training": [[72, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[72, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[72, "during-quantization"]], "During Model Execution": [[72, "during-model-execution"]], "During Save/Load": [[72, "during-save-load"]], "Quick Start Guide": [[73, "quick-start-guide"]], "First Quantization Example": [[73, "first-quantization-example"]], "Setting Up the Model": [[73, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[73, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[73, "model-size-comparison"]], "Speedup Comparison": [[73, "speedup-comparison"]], "PyTorch 2 Export Quantization": [[73, "pytorch-2-export-quantization"]], "Next Steps": [[73, "next-steps"], [79, "next-steps"]], "Serialization and deserialization flow": [[74, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[74, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[74, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[75, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[75, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[75, "serving-and-inference"]], "Serving and Inference with vLLM": [[75, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[75, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[75, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[75, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[75, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[75, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[75, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[75, "mobile-performance-characteristics"]], "Evaluation": [[75, "evaluation"]], "Model Quality Assessment": [[75, "model-quality-assessment"]], "Memory Benchmarking": [[75, "memory-benchmarking"]], "Performance Benchmarking": [[75, "performance-benchmarking"]], "Latency Benchmarking": [[75, "latency-benchmarking"]], "Serving Benchmarking": [[75, "serving-benchmarking"]], "Results (H100 machine)": [[75, "results-h100-machine"]], "Conclusion": [[75, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [87, "conclusion"], [88, "conclusion"], [89, "conclusion"], [90, "conclusion"]], "Sparsity Overview": [[76, "sparsity-overview"]], "Goal": [[76, "goal"]], "Design": [[76, "design"]], "Context": [[76, "context"]], "Pruning Configuration": [[76, "pruning-configuration"]], "Pruning Criteria": [[76, "pruning-criteria"]], "Pruning Strategy": [[76, "pruning-strategy"]], "Sparsity Pattern": [[76, "sparsity-pattern"]], "Static Quantization": [[77, "static-quantization"]], "Calibration Phase": [[77, "calibration-phase"]], "Quantization Phase": [[77, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[78, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[79, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[79, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[79, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[79, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[79, "which-operators-should-we-implement"]], "Comparing the Outputs": [[79, "comparing-the-outputs"]], "Hugging Face Integration": [[80, "hugging-face-integration"]], "Quick Start: Usage Example": [[80, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[80, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[80, "quantizing-models-with-diffusers"]], "Saving the Model": [[80, "saving-the-model"]], "Supported Quantization Types": [[80, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[81, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[81, "configuration-system"]], "1. HuggingFace Model Configuration": [[81, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[81, "torchao-configuration-classes"]], "3. FQN Configuration": [[81, "fqn-configuration"]], "Usage Examples": [[81, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[81, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[81, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[81, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[81, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[81, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[81, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[81, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[81, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[81, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[81, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[81, "hardware-specific-linear-operations"]], "Compilation Benefits": [[81, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[81, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[81, "serialization-and-model-sharing"]], "SafeTensors Support": [[81, "safetensors-support"]], "Integration Architecture Diagrams": [[81, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[81, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[81, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[81, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Computation times": [[83, "computation-times"]], "Template Tutorial": [[84, "template-tutorial"]], "Overview": [[84, "overview"]], "Steps": [[84, "steps"]], "(Optional) Additional Exercises": [[84, "optional-additional-exercises"]], "Further Reading": [[84, "further-reading"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[85, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[85, "introduction"], [88, "introduction"], [89, "introduction"], [90, "introduction"]], "Post Training Quantization": [[85, "post-training-quantization"], [88, "post-training-quantization"], [89, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[85, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[85, "capture-fx-graph"], [88, "capture-fx-graph"], [89, "capture-fx-graph"]], "2. Apply Quantization": [[85, "apply-quantization"], [88, "apply-quantization"], [89, "apply-quantization"]], "3. Lower into OpenVINO representation": [[85, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[85, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[86, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[86, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[86, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[86, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[86, "export-the-model-with-torch-export"], [87, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[86, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [87, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[86, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[86, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[86, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[86, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[86, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[86, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[86, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[87, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[87, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[87, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[87, "training-loop"]], "Saving and Loading Model Checkpoints": [[87, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[87, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[88, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[88, "lower-into-inductor"], [89, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[89, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[90, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[90, "prerequisites"]], "Annotation API": [[90, "annotation-api"]], "1. Annotate Common Operator Patterns": [[90, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[90, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[90, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[90, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[90, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[90, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[90, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[90, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]]}, "indexentries": {"module": [[5, "module-torchao.sparsity"]], "torchao.sparsity": [[5, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[12, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[13, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[13, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[14, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[15, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[16, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[17, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[19, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[20, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[21, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[25, "torchao.quantization.Int8WeightOnlyConfig"]], "mappingtype (class in torchao.quantization)": [[26, "torchao.quantization.MappingType"]], "torchaodtype (class in torchao.quantization)": [[27, "torchao.quantization.TorchAODType"]], "choose_qparams_affine() (in module torchao.quantization)": [[28, "torchao.quantization.choose_qparams_affine"]], "choose_qparams_affine_with_min_max() (in module torchao.quantization)": [[29, "torchao.quantization.choose_qparams_affine_with_min_max"]], "dequantize_affine() (in module torchao.quantization)": [[30, "torchao.quantization.dequantize_affine"]], "int_scaled_matmul() (in module torchao.quantization)": [[31, "torchao.quantization.int_scaled_matmul"]], "composableqatquantizer (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[34, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[35, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[37, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[39, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[41, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[41, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[43, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[44, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[45, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[45, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[45, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[46, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[46, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[47, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[48, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[49, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[49, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[50, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[51, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[52, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[53, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[54, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[55, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[56, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[57, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[57, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[57, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[57, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[58, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[58, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[59, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[60, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "quantize_affine() (in module torchao.quantization)": [[61, "torchao.quantization.quantize_affine"]], "safe_int_mm() (in module torchao.quantization)": [[62, "torchao.quantization.safe_int_mm"]], "perchannelnormobserver (class in torchao.sparsity)": [[63, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[63, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[64, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[64, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[64, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[64, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[65, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[66, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[67, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[68, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[68, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[68, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[68, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[68, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[68, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})