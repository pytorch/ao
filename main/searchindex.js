Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 22, 23, 24, 25, 27, 40, 41, 42, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 62, 63, 67, 68, 73, 75, 77, 78, 80, 81, 84, 87, 88, 89, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 108, 109, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122], "section": [2, 10, 103, 108, 113, 118, 119, 122], "introduc": [2, 12, 117, 118, 120, 121, 122], "dive": 2, "detail": [2, 8, 10, 12, 41, 47, 55, 102, 103, 104, 106, 108, 109, 111, 117, 118, 119, 120], "how": [2, 4, 10, 12, 13, 19, 27, 43, 49, 51, 56, 73, 85, 86, 89, 100, 102, 104, 105, 106, 108, 109, 111, 112, 113, 117, 120, 121], "integr": [2, 10, 100, 102, 105, 106, 108, 111, 120, 122], "pytorch": [2, 8, 12, 13, 18, 21, 52, 73, 100, 102, 103, 106, 108, 111, 113, 116], "optim": [2, 10, 12, 22, 40, 55, 84, 100, 102, 108, 111, 117, 119, 120, 121], "your": [2, 8, 10, 12, 100, 102, 103, 104, 106, 108, 112, 118, 119, 120, 121, 122], "machin": [2, 119], "learn": [2, 73, 104, 108, 116, 118, 120, 121, 122], "model": [2, 12, 40, 46, 48, 55, 60, 65, 68, 69, 70, 71, 72, 75, 79, 84, 91, 92, 95, 96, 98, 104, 108, 109, 111, 120, 121, 122], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 44, 45, 52, 53, 55, 56, 57, 58, 62, 63, 65, 66, 69, 70, 71, 73, 77, 78, 80, 81, 88, 89, 98, 100, 102, 104, 105, 106, 109, 111, 112, 113, 118, 120, 121, 122], "quantiz": [2, 8, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 31, 33, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 98, 102, 105, 108], "sparsiti": [2, 8, 12, 16, 22, 25, 94, 95, 96, 97, 98, 100, 102, 105, 106], "tba": [3, 11, 101], "For": [4, 8, 10, 12, 13, 41, 47, 73, 103, 104, 105, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "full": [4, 12, 104, 109, 112, 116, 117, 119], "exampl": [4, 8, 10, 12, 13, 40, 51, 55, 60, 62, 63, 68, 72, 73, 75, 79, 84, 85, 95, 98, 99, 103, 105, 106, 107, 108, 109, 111, 114, 115, 116, 117, 118, 119, 120, 121], "us": [4, 8, 9, 12, 13, 17, 18, 19, 22, 23, 24, 27, 29, 32, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 57, 58, 60, 65, 68, 72, 73, 75, 80, 81, 85, 86, 89, 95, 99, 100, 102, 103, 104, 105, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121], "our": [4, 10, 12, 23, 102, 104, 106, 108, 109, 111, 118, 119], "pleas": [4, 9, 10, 12, 13, 21, 41, 68, 72, 100, 103, 104, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "refer": [4, 8, 12, 13, 75, 81, 102, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120], "readm": [4, 8, 12, 100, 104, 108], "tutori": [8, 10, 12, 13, 102, 103, 104, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122], "you": [8, 9, 10, 12, 73, 95, 99, 102, 103, 104, 105, 106, 108, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122], "through": [8, 10, 12, 57, 62, 63, 100, 103, 104, 106, 109, 111, 113, 116, 117, 118, 122], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 104, 105, 106, 108, 109, 111, 112, 117, 118, 119, 120, 121], "framework": [8, 10, 12, 102, 106, 117], "The": [8, 10, 12, 13, 14, 19, 22, 27, 39, 41, 42, 44, 45, 55, 59, 75, 84, 90, 91, 92, 95, 102, 103, 104, 105, 106, 108, 111, 112, 113, 117, 118, 119, 120, 121, 122], "contain": [8, 55, 87, 88, 91, 92, 108, 111, 119, 122], "new": [8, 12, 13, 99, 102, 103, 109, 111, 118, 119, 120, 122], "architectur": [8, 100, 106, 108, 117, 118, 120, 121], "micro": 8, "current": [8, 42, 47, 48, 65, 66, 75, 84, 92, 95, 98, 102, 103, 104, 108, 111, 112, 113, 118, 119, 121], "support": [8, 12, 13, 30, 42, 43, 47, 48, 65, 72, 73, 75, 87, 88, 98, 102, 103, 104, 105, 106, 108, 111, 117, 118, 119, 120, 121, 122], "which": [8, 10, 12, 21, 27, 55, 75, 80, 102, 103, 104, 105, 106, 108, 109, 113, 117, 118, 119, 120, 121, 122], "can": [8, 10, 12, 13, 26, 42, 46, 51, 55, 60, 73, 84, 85, 89, 99, 102, 103, 104, 105, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "quantize_": [8, 10, 12, 68, 72, 75, 84, 85, 86, 87, 88, 98, 100, 103, 104, 105, 106, 109], "sparsity_": 8, "function": [8, 12, 13, 26, 39, 55, 62, 63, 67, 77, 82, 83, 84, 94, 95, 96, 98, 99, 102, 103, 104, 105, 108, 109, 111, 113, 117, 122], "To": [8, 10, 12, 13, 21, 55, 81, 102, 103, 104, 105, 106, 108, 109, 113, 118, 119, 120, 122], "correspond": [8, 12, 68, 75, 84, 103, 105, 108, 111, 121, 122], "string": [8, 36, 73, 95, 99], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 46, 99, 100, 103, 104, 105, 111, 113, 117, 118, 119, 120, 121, 122], "py": [8, 10, 13, 21, 99, 106, 107, 115, 116, 120, 121], "def": [8, 10, 12, 87, 98, 99, 102, 103, 104, 105, 109, 111, 113, 117, 118, 119, 120, 121, 122], "option": [8, 10, 13, 17, 21, 28, 31, 32, 33, 35, 36, 39, 42, 44, 46, 47, 49, 50, 55, 56, 57, 58, 62, 63, 65, 66, 70, 72, 73, 75, 77, 78, 84, 85, 89, 91, 92, 93, 95, 98, 99, 102, 103, 104, 112, 113, 118, 119, 120, 121, 122], "str": [8, 36, 39, 46, 73, 75, 84, 92, 93, 95, 98, 99, 102, 111, 113, 121], "kwarg": [8, 10, 13, 62, 63, 64, 65, 69, 73, 78, 88, 94, 95, 96, 99, 103, 111, 113], "aobaseconfig": [8, 75, 84, 98, 109, 113], "code": [8, 10, 102, 103, 104, 106, 108, 109, 111, 114, 116, 118, 119, 120, 121, 122], "elif": [8, 113], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 17, 39, 42, 49, 50, 55, 59, 72, 73, 75, 90, 91, 95, 99, 103, 104, 106, 108, 111, 118, 119], "addit": [8, 12, 19, 24, 55, 99, 102, 103, 108, 111, 112, 117, 118, 121, 122], "inform": [8, 13, 42, 103, 106, 108, 113, 117, 118], "need": [8, 10, 12, 42, 62, 63, 67, 77, 86, 87, 88, 94, 95, 99, 103, 104, 105, 106, 108, 111, 113, 118, 119, 120, 122], "pass": [8, 39, 49, 55, 57, 62, 63, 67, 75, 77, 94, 99, 103, 109, 111, 113, 119, 122], "process": [8, 12, 19, 22, 24, 26, 27, 55, 92, 103, 108, 116, 117, 121], "here": [8, 9, 13, 75, 81, 89, 103, 104, 105, 106, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "return": [8, 10, 12, 13, 21, 22, 23, 39, 55, 59, 73, 84, 90, 91, 92, 98, 99, 102, 103, 104, 105, 109, 111, 113, 117, 118, 119, 120, 121, 122], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 86, 111, 119], "now": [8, 10, 12, 41, 43, 47, 48, 56, 102, 103, 104, 108, 109, 111, 117, 118, 120, 122], "we": [8, 10, 12, 13, 23, 42, 45, 47, 51, 53, 55, 56, 57, 58, 72, 73, 75, 81, 84, 89, 98, 99, 102, 103, 104, 105, 106, 108, 109, 112, 113, 117, 118, 119, 120, 121, 122], "throughout": 8, "note": [8, 10, 12, 47, 60, 72, 81, 95, 99, 103, 104, 106, 108, 111, 113, 119, 120, 121], "input": [8, 10, 13, 22, 23, 25, 36, 39, 40, 55, 56, 57, 58, 59, 75, 79, 84, 89, 90, 95, 98, 102, 103, 104, 106, 109, 111, 117, 118, 119, 120, 121, 122], "paramet": [8, 12, 13, 19, 22, 23, 29, 32, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 58, 59, 65, 66, 73, 75, 78, 80, 81, 84, 89, 90, 91, 92, 95, 98, 99, 102, 103, 105, 106, 108, 111, 113, 117, 118], "like": [8, 10, 12, 19, 42, 55, 102, 103, 104, 105, 108, 111, 112, 113, 117, 118, 119, 120, 121, 122], "bit": [8, 12, 27, 34, 41, 46, 53, 74, 106, 111, 112, 113, 118, 120, 121], "width": [8, 27, 46, 74], "group": [8, 10, 12, 42, 43, 48, 50, 53, 65, 69, 70, 71, 73, 77, 78, 80, 81, 85, 104], "size": [8, 10, 13, 14, 21, 23, 46, 47, 48, 50, 53, 56, 58, 73, 89, 102, 104, 105, 106, 108, 109, 111, 113, 119], "etc": [8, 10, 42, 62, 63, 86, 88, 103, 117, 122], "them": [8, 12, 55, 62, 63, 67, 77, 94, 122], "append": [8, 108, 118, 119], "config": [8, 12, 36, 39, 42, 45, 47, 55, 61, 62, 63, 64, 66, 67, 68, 72, 73, 74, 75, 84, 95, 98, 103, 104, 106, 108, 109, 113, 118, 120, 121], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": [8, 46], "group_siz": [8, 12, 43, 46, 47, 48, 50, 53, 62, 63, 65, 69, 72, 73, 75, 77, 78, 84, 104, 112, 113], "system": [8, 10, 86, 106], "model_architectur": 8, "type": [8, 10, 12, 13, 22, 23, 27, 36, 37, 38, 39, 42, 44, 45, 47, 48, 49, 51, 52, 54, 55, 59, 73, 76, 85, 86, 87, 88, 89, 90, 99, 100, 103, 105, 106, 108, 111, 113, 117, 118, 120, 121, 122], "defin": [8, 10, 19, 27, 37, 41, 62, 63, 67, 77, 94, 95, 99, 103, 104, 108, 109, 111, 113, 117, 120, 121, 122], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 85, 86, 87, 94, 95, 99, 104, 105, 109, 111, 118, 119, 120, 122], "mycustommodel": 8, "torch": [8, 12, 13, 22, 23, 27, 29, 36, 39, 42, 44, 45, 53, 55, 56, 58, 59, 62, 63, 65, 66, 69, 70, 71, 72, 73, 75, 77, 78, 80, 81, 84, 85, 89, 90, 91, 92, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 111, 112, 113, 116, 120, 121, 122], "nn": [8, 10, 12, 36, 39, 55, 60, 65, 69, 72, 75, 84, 91, 92, 98, 99, 102, 103, 104, 105, 106, 108, 109, 111, 113, 118, 119, 120, 122], "modul": [8, 10, 12, 36, 37, 38, 39, 40, 51, 52, 54, 55, 60, 62, 63, 64, 65, 67, 68, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91, 92, 94, 95, 98, 102, 103, 104, 105, 109, 117, 118, 119, 120, 121, 122], "__init__": [8, 12, 99, 104, 105, 109, 111, 113, 118, 119, 120], "self": [8, 12, 13, 99, 104, 105, 109, 111, 113, 118, 119, 120], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 23, 65, 70, 80, 89, 102, 103, 104, 105, 106, 108, 109, 112, 113, 120, 121], "super": [8, 12, 104, 105, 109, 111, 118, 119, 120], "layer1": 8, "linear": [8, 10, 12, 22, 36, 39, 42, 43, 45, 48, 49, 50, 53, 55, 60, 63, 65, 70, 71, 72, 75, 80, 81, 82, 83, 84, 92, 96, 98, 99, 102, 103, 104, 105, 106, 108, 109, 111, 117, 118, 119, 120, 122], "512": [8, 102], "bia": [8, 12, 63, 80, 81, 103, 104, 105, 109, 111, 113, 119, 122], "fals": [8, 12, 13, 31, 36, 44, 47, 49, 53, 55, 62, 63, 71, 72, 73, 75, 77, 78, 80, 81, 91, 95, 102, 103, 104, 105, 106, 109, 111, 112, 113, 117, 118, 119, 121, 122], "activ": [8, 12, 42, 44, 46, 48, 49, 55, 62, 63, 65, 71, 72, 73, 75, 81, 87, 88, 91, 95, 100, 104, 106, 108, 109, 112, 113, 117, 120, 121, 122], "relu": [8, 104, 117, 122], "layer2": 8, "forward": [8, 49, 55, 62, 63, 67, 74, 77, 80, 94, 104, 105, 108, 109, 111, 113, 118, 119, 120], "x": [8, 53, 62, 63, 67, 74, 77, 102, 104, 105, 106, 109, 111, 113, 116, 117, 118, 119, 120, 121], "updat": [8, 100, 104, 105, 108, 118, 119, 122], "create_model_and_input_data": 8, "handl": [8, 10, 22, 25, 26, 55], "model_typ": [8, 12, 113, 117], "m": [8, 10, 12, 84, 98, 102, 104, 105, 106, 109, 111, 118, 119, 120], "int": [8, 12, 13, 14, 21, 23, 26, 27, 28, 29, 31, 32, 33, 34, 41, 42, 45, 46, 47, 48, 50, 53, 56, 57, 58, 62, 63, 65, 69, 70, 71, 73, 77, 78, 80, 81, 84, 89, 95, 99, 104, 109, 111, 113], "k": [8, 10, 90, 104, 105, 109, 111, 118, 119], "n": [8, 10, 12, 104, 105, 109, 111, 118, 119, 122], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 77, 80, 81, 84, 90, 102, 104, 105, 106, 109, 111, 113, 117, 118, 119, 120, 121], "cuda": [8, 10, 12, 13, 84, 102, 104, 105, 106, 108, 109, 111, 112, 119], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 63, 102, 104, 105, 109, 111, 117, 118, 119, 120, 121], "when": [8, 10, 12, 13, 24, 56, 58, 75, 89, 99, 102, 103, 106, 108, 109, 112, 113, 117, 118, 119, 120, 121, 122], "ad": [8, 12, 13, 58, 95, 99, 103, 108, 109, 111, 119], "dimens": [8, 10, 13, 27, 53, 56, 58, 59, 89, 102, 103, 111, 113, 118, 119], "ensur": [8, 22, 106, 119], "convent": 8, "where": [8, 25, 51, 53, 57, 69, 70, 71, 103, 108, 113, 122], "batch": [8, 106, 109, 119], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 111, 117, 120, 121], "data": [8, 12, 13, 14, 19, 22, 27, 42, 44, 45, 47, 49, 57, 86, 99, 100, 103, 105, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "typic": [8, 12, 23, 24, 103, 104, 105, 109, 113, 122], "compat": [8, 10, 22, 73, 104], "work": [8, 10, 12, 25, 46, 102, 105, 108, 111, 112, 113, 118, 119, 120], "cpu": [8, 10, 13, 18, 105, 108, 109, 112, 113, 117, 118, 119, 120], "other": [8, 12, 13, 19, 42, 47, 74, 85, 95, 102, 105, 106, 108, 111, 113, 116, 118, 119, 120, 122], "target": [8, 10, 12, 13, 42, 44, 45, 47, 56, 62, 63, 66, 73, 95, 104, 108, 117, 118, 119, 120, 121, 122], "method": [8, 10, 19, 22, 25, 26, 55, 84, 95, 104, 108, 109, 111, 112, 117, 118, 119, 121, 122], "come": [8, 9, 102, 103, 106, 108, 109, 110, 112, 119, 120, 121], "soon": [8, 9, 106, 110, 119], "file": [8, 10, 102, 106, 107, 111, 113, 115, 118, 119], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 75, 91, 100, 103, 104, 105, 108, 109, 111, 112, 117, 118, 119, 120, 121], "quantization_config_recipe_nam": 8, "int8wo": [8, 112], "int8dq": 8, "float8dq": [8, 106], "tensor": [8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 47, 48, 49, 55, 56, 57, 58, 59, 62, 63, 64, 66, 67, 74, 85, 86, 87, 88, 89, 90, 93, 95, 99, 100, 102, 104, 105, 108, 109, 112, 116, 118, 120, 121], "row": [8, 10, 43, 59, 102, 103, 108], "float8wo": 8, "output_dir": [8, 112], "result": [8, 12, 13, 55, 59, 90, 103, 108, 109, 112, 118, 119, 120, 121, 122], "model_param": 8, "name": [8, 10, 37, 38, 51, 52, 54, 76, 84, 85, 86, 92, 95, 98, 99, 103, 106, 108, 111, 113, 117, 118, 119, 122], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 51, 62, 89, 102, 104, 106, 109, 118, 119], "max_pow": 8, "15": [8, 47, 102, 104, 106], "torch_compile_mod": 8, "max": [8, 10, 51, 103, 104, 109, 111, 118, 119, 122], "autotun": [8, 10, 104, 109], "runner": 8, "gener": [8, 12, 13, 62, 63, 64, 67, 74, 103, 104, 106, 108, 109, 111, 113, 114, 116, 117, 119, 120, 121, 122], "oss": 8, "databas": 8, "python": [8, 10, 104, 106, 108, 114, 116, 117, 118, 120, 121], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 106, 113], "specif": [8, 10, 12, 19, 22, 24, 25, 62, 63, 81, 86, 95, 102, 103, 104, 105, 106, 108, 112, 117, 120, 121, 122], "requir": [8, 12, 13, 24, 26, 85, 99, 103, 104, 106, 108, 111, 112, 117, 120, 122], "mode": [8, 10, 46, 47, 55, 104, 109, 117, 119, 120, 121, 122], "extra_info": 8, "arch": 8, "nvidia": [8, 108], "a100": [8, 12, 104, 112], "sxm4": 8, "80gb": [8, 104], "1024": [8, 84, 98, 104, 105, 120], "custom": [8, 12, 19, 75, 94, 100, 102, 103, 104, 108, 111, 113, 117, 118, 120, 122], "layer": [8, 22, 39, 42, 45, 49, 50, 53, 55, 62, 63, 65, 69, 70, 71, 77, 78, 80, 81, 91, 92, 95, 96, 102, 106, 108, 109, 111, 113, 117, 122], "origin": [8, 12, 13, 23, 45, 49, 68, 89, 95, 103, 104, 105, 106, 108, 117, 118, 122], "metric": [8, 12, 95], "speedup": [8, 10, 12, 102, 103, 104, 106, 108], "wrt": 8, "bf16": [8, 12, 56, 75, 104, 108, 120, 121], "benchmark_valu": 8, "25": [8, 104], "target_valu": 8, "0": [8, 10, 12, 13, 47, 55, 62, 73, 77, 78, 89, 92, 95, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 121, 122], "depend": [8, 13, 46, 55, 105, 108, 111, 118, 119, 121], "step": [8, 12, 24, 40, 55, 75, 76, 102, 103, 108, 117, 118, 119, 120, 121, 122], "workflow": [8, 10, 84, 85, 98, 102, 104, 108, 122], "github": [8, 13, 21, 41, 104, 106, 112], "action": [8, 113, 118, 119], "upload": 8, "verifi": [8, 104, 105, 111], "setup": [8, 106], "suit": [8, 10, 118, 120], "unittest": 8, "discov": 8, "out": [8, 10, 12, 25, 51, 55, 86, 95, 102, 103, 104, 106, 108, 111, 117, 118, 119, 120], "memori": [8, 10, 12, 13, 102, 103, 104, 108, 111, 112, 120, 121], "reduc": [8, 10, 12, 40, 75, 102, 106, 108, 120], "matrix": [8, 14, 17, 42, 44, 59, 85, 90, 95, 103, 104, 108, 120], "miss": [8, 108], "properli": [8, 105], "instal": [8, 10, 102, 103, 104, 106, 112, 118, 121], "Not": [8, 108], "avail": [8, 10, 86, 103, 117, 118, 119, 120, 121], "check": [8, 10, 12, 13, 21, 103, 104, 105, 106, 111, 117, 119, 122], "driver": 8, "basic": [8, 10, 24, 104, 109, 111], "shape": [8, 10, 13, 21, 55, 59, 86, 90, 103, 104, 109, 111, 113, 118, 121], "comprehens": [8, 113, 120], "analysi": [8, 108], "enabl": [8, 10, 83, 99, 102, 103, 106, 112, 113, 120], "profil": [8, 10], "onli": [8, 10, 12, 13, 18, 39, 42, 43, 45, 46, 47, 48, 49, 50, 53, 65, 75, 81, 98, 102, 104, 105, 106, 108, 111, 112, 113, 117, 118, 120, 121, 122], "overhead": [8, 108, 112, 113, 120], "multipl": [8, 10, 12, 17, 42, 44, 55, 59, 60, 85, 87, 90, 103, 104, 108, 109, 111, 113, 120, 122], "possibl": [8, 13, 103, 108, 118, 119, 120, 122], "consist": [8, 106, 108, 111, 120, 121, 122], "reproduc": [8, 106], "differ": [8, 10, 12, 19, 47, 57, 60, 89, 90, 102, 103, 104, 105, 106, 108, 111, 112, 113, 118, 119, 120, 122], "case": [8, 9, 10, 55, 75, 90, 106, 108, 111, 113, 117, 118, 122], "user": [8, 10, 12, 42, 55, 60, 75, 81, 100, 102, 103, 104, 106, 108, 109, 111, 116, 118, 119, 120, 121, 122], "more": [8, 10, 12, 13, 41, 46, 47, 48, 53, 55, 102, 103, 104, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121], "about": [8, 10, 12, 103, 104, 105, 106, 108, 118, 119, 120, 122], "compon": [8, 103, 111, 113], "see": [8, 10, 12, 13, 21, 41, 47, 99, 102, 103, 104, 105, 108, 109, 111, 112, 113, 117, 118, 122], "directori": [8, 102], "intend": [9, 103, 118], "provid": [9, 10, 12, 19, 22, 25, 26, 55, 56, 60, 79, 99, 102, 103, 106, 108, 111, 113, 118, 119, 121, 122], "instruct": [9, 12, 103, 104, 106, 118, 119, 120], "most": [9, 10, 24, 75, 103, 106, 108, 113, 118, 119, 122], "fequent": 9, "have": [9, 10, 12, 46, 51, 55, 69, 70, 71, 86, 89, 95, 99, 103, 108, 109, 111, 113, 117, 118, 119, 120, 121, 122], "ani": [9, 10, 24, 55, 65, 69, 79, 93, 95, 103, 108, 111, 117, 119, 121], "answer": [9, 108], "creat": [9, 10, 13, 29, 30, 32, 102, 108, 111, 112, 117, 118, 120, 121, 122], "an": [9, 12, 13, 26, 31, 32, 55, 72, 73, 75, 81, 95, 100, 102, 103, 104, 106, 108, 109, 111, 112, 117, 118, 119, 120, 121, 122], "issu": [9, 103, 104, 111, 120], "start": [10, 12, 37, 38, 51, 52, 54, 55, 76, 85, 86, 102, 103, 106, 108, 109, 111, 113, 117, 118, 119, 120, 121, 122], "read": [10, 111], "overview": [10, 100, 104, 113], "page": [10, 104, 120], "first": [10, 23, 55, 59, 75, 95, 99, 103, 106, 109, 111, 112, 113, 118, 119, 122], "contribut": [10, 104, 108], "exist": [10, 52, 75, 102, 103, 108, 109, 111, 118, 122], "base": [10, 19, 24, 42, 51, 61, 74, 75, 79, 87, 88, 95, 99, 103, 104, 108, 111, 112, 113, 117, 118, 119, 120, 121, 122], "api": [10, 55, 103, 104, 108, 109, 111, 117, 118, 119, 120, 121], "quant_api": [10, 84, 105, 106, 109], "float8tensor": [10, 42, 45, 66, 87, 103, 113], "e": [10, 12, 13, 41, 51, 55, 56, 58, 60, 73, 75, 84, 87, 89, 99, 102, 103, 105, 109, 111, 112, 117, 122], "g": [10, 12, 13, 41, 51, 55, 56, 58, 60, 73, 75, 84, 87, 89, 99, 103, 105, 109, 111, 117, 122], "oper": [10, 12, 13, 17, 19, 22, 49, 57, 103, 104, 106, 117, 118, 119, 120, 121], "make": [10, 43, 47, 103, 104, 111, 113, 118, 122], "trainabl": [10, 12, 103, 111], "add": [10, 24, 99, 111, 116, 120, 122], "parallel": [10, 102, 111, 113], "primit": [10, 13, 21, 111, 118], "op": [10, 12, 13, 21, 42, 55, 84, 85, 99, 104, 108, 111, 113, 118, 119, 120, 122], "slight": [10, 108], "variat": [10, 103], "quant_primit": [10, 13, 21, 109], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 17, 25, 27, 39, 41, 42, 46, 47, 55, 56, 58, 60, 62, 63, 72, 75, 84, 86, 89, 90, 95, 99, 102, 103, 104, 105, 106, 108, 109, 113, 117, 118, 119, 120, 121, 122], "structur": [10, 12, 25, 98, 103, 104, 105, 108, 111, 118], "deriv": [10, 13, 57, 88, 89], "pack": [10, 13, 15, 26, 27, 41, 43, 46, 47, 53, 86], "format": [10, 13, 22, 23, 41, 46, 47, 86, 106, 108, 118, 119, 122], "understand": [10, 86, 102, 120, 122], "concept": [10, 103, 116, 118, 120, 121, 122], "i": [10, 12, 90, 102, 103, 106, 108, 112, 117, 118, 119], "doe": [10, 12, 24, 75, 86, 103, 108, 111, 118, 120, 121], "alreadi": [10, 13, 55, 111, 122], "could": [10, 103, 111, 117, 118, 120, 121, 122], "context": [10, 120, 121], "also": [10, 12, 55, 73, 84, 103, 104, 105, 108, 109, 111, 112, 113, 118, 121, 122], "write": [10, 100, 104, 117, 118, 119], "own": [10, 12, 100, 102, 104, 108, 109, 118, 119, 122], "torchaobasetensor": [10, 113], "help": [10, 12, 102, 103, 106, 113, 117, 118], "common": [10, 75, 85, 86, 87, 88, 100, 102, 103, 108], "specifi": [10, 12, 13, 36, 39, 50, 53, 60, 62, 63, 64, 67, 74, 75, 81, 84, 85, 89, 95, 98, 102, 103, 108, 117, 118, 119, 122], "non": [10, 55, 99, 108, 111, 117, 120, 121], "attribut": [10, 12, 99, 103, 111, 113, 120, 121], "mytensor": [10, 99], "tensor_data_nam": [10, 99], "qdata": [10, 103], "scale": [10, 13, 19, 22, 29, 32, 37, 40, 42, 44, 51, 54, 56, 57, 58, 59, 65, 66, 73, 78, 79, 80, 81, 89, 91, 92, 99, 103, 108, 109, 111, 113, 122], "tensor_attribute_nam": [10, 99], "With": [10, 111, 118, 120, 122], "abov": [10, 12, 43, 47, 51, 103, 105, 108, 109, 111, 118, 119, 122], "ll": [10, 51, 102, 103, 111, 118, 119, 122], "doc": [10, 102, 103, 104, 106, 111, 112], "mani": [10, 103, 108, 111], "still": [10, 12, 103, 108, 118, 122], "affinequantizedtensor": [10, 21, 29, 30, 32, 42, 45, 104, 105, 109, 111], "plan": [10, 42, 45, 47, 119], "move": [10, 84, 109, 113, 119, 120], "awai": 10, "from": [10, 12, 13, 23, 24, 29, 30, 32, 41, 48, 57, 68, 72, 75, 84, 85, 89, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122], "abstract": [10, 103], "easier": [10, 122], "peopl": [10, 103, 105, 113, 122], "implement": [10, 12, 36, 47, 77, 78, 80, 81, 85, 99, 103, 105, 108, 109, 117, 118, 122], "regist": [10, 62, 63, 67, 77, 94, 99, 103, 111], "mai": [10, 13, 57, 73, 86, 103, 105, 109, 112, 118, 119, 120, 121, 122], "well": [10, 19, 55, 103, 104, 108, 118, 119, 122], "int4": [10, 12, 15, 18, 43, 47, 48, 51, 62, 63, 65, 69, 70, 71, 72, 73, 75, 77, 78, 80, 81, 84, 98, 103, 104, 105, 106, 112, 113], "access": [10, 49, 117], "my_custom_op": 10, "call": [10, 12, 13, 55, 62, 63, 67, 77, 94, 103, 104, 105, 108, 109, 111, 113, 119, 121], "want": [10, 84, 98, 103, 104, 105, 108, 111, 113, 117, 118, 119, 122], "my_mm_for_mp": 10, "aten": [10, 99, 103, 104, 111, 113, 117, 118, 119, 120, 121], "default": [10, 12, 13, 14, 17, 24, 26, 27, 42, 44, 45, 46, 47, 53, 55, 56, 58, 65, 73, 81, 84, 91, 92, 99, 102, 103, 104, 111, 113, 117, 118, 119, 120, 121, 122], "_": [10, 99, 102, 103, 109, 113, 117, 118, 119, 120], "func": [10, 99, 103, 111, 113], "arg": [10, 13, 47, 62, 63, 64, 65, 69, 78, 95, 99, 103, 111, 113, 119, 122], "re": [10, 102, 103, 105, 106, 111, 118, 119], "input_tensor": [10, 23, 103, 113], "weight_tensor": [10, 103, 113], "some": [10, 55, 84, 95, 99, 103, 104, 106, 108, 109, 111, 117, 118, 119, 120, 121, 122], "choic": [10, 47], "mm": [10, 84, 85, 111, 118], "recommend": [10, 12, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 102, 103, 112, 117, 120, 121], "wai": [10, 13, 55, 75, 102, 103, 106, 108, 109, 111, 118, 119, 122], "repres": [10, 13, 14, 17, 19, 30, 36, 61, 73, 86, 89, 95, 103, 105, 111, 118, 119], "group_mm": 10, "auto": [10, 42, 85, 106, 112, 113], "develop": [10, 104, 118, 119, 122], "choos": [10, 47, 88, 103, 108, 111, 118, 120], "whatev": 10, "think": [10, 113], "fastest": [10, 55], "under": [10, 12, 85, 106], "condit": 10, "so": [10, 12, 55, 102, 103, 104, 105, 108, 111, 112, 118, 119, 122], "don": [10, 95, 102, 103, 104, 108, 112, 113, 122], "t": [10, 95, 99, 102, 103, 104, 108, 109, 111, 112, 113, 118, 119, 122], "worri": 10, "debug": [10, 91], "purpos": [10, 102, 103, 111, 118], "ha": [10, 12, 13, 75, 106, 108, 111, 113, 117, 118, 119, 121, 122], "hardwar": [10, 42, 46, 86, 104, 106, 108, 112], "h100": [10, 103, 112], "sm89": 10, "sm90": 10, "librari": [10, 85, 86, 100, 103, 105], "whether": [10, 12, 47, 53, 54, 55, 56, 73, 99, 111], "fbgemm_gpu_genai": [10, 85, 103], "granular": [10, 13, 37, 42, 44, 46, 47, 48, 50, 53, 56, 58, 62, 63, 65, 66, 73, 74, 89, 102, 103, 106, 109, 113], "per": [10, 12, 13, 43, 45, 48, 49, 50, 53, 56, 58, 65, 69, 70, 71, 73, 77, 78, 80, 81, 89, 95, 102, 103, 104, 108, 109, 121], "_choose_scale_float8": [10, 103], "_quantize_affine_float8": [10, 103], "_scaled_mm": [10, 103], "kerenel": 10, "fbgemm": [10, 103, 108], "f8f8bf16_rowwis": [10, 103], "level": [10, 95, 103, 108, 111, 117, 118, 120, 121], "reus": [10, 111], "allow": [10, 81, 103, 104, 108, 111, 117, 118, 119, 120, 122], "appli": [10, 12, 13, 42, 43, 44, 45, 46, 48, 49, 50, 53, 55, 60, 64, 65, 67, 72, 74, 75, 84, 98, 99, 103, 104, 106, 108, 113, 119], "convers": [10, 12, 13, 39], "weight": [10, 12, 22, 23, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 62, 63, 65, 69, 70, 71, 73, 75, 77, 78, 80, 81, 84, 87, 95, 98, 100, 102, 104, 105, 108, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122], "filter": [10, 12, 39, 55, 102, 109], "should": [10, 12, 13, 40, 46, 58, 62, 63, 67, 68, 75, 77, 94, 95, 99, 102, 108, 113, 117, 118, 122], "algorithm": [10, 47, 53, 106, 108, 117], "dynam": [10, 12, 35, 36, 40, 42, 43, 46, 48, 49, 65, 71, 73, 81, 98, 106, 109, 111, 112, 118, 119, 120], "quant": [10, 13, 21, 41, 103, 106, 113, 118, 121, 122], "In": [10, 12, 47, 75, 102, 103, 104, 108, 109, 111, 117, 118, 119, 120, 121, 122], "order": [10, 55, 60, 99, 108, 111, 122], "aim": [10, 108, 121], "run": [10, 12, 40, 55, 62, 63, 67, 77, 84, 91, 94, 102, 103, 104, 106, 108, 111, 116, 117, 118, 119, 120, 121, 122], "fullgraph": [10, 104], "true": [10, 12, 13, 31, 36, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 62, 63, 72, 73, 75, 83, 84, 91, 98, 102, 104, 105, 106, 109, 111, 112, 113, 117, 118, 119, 120, 122], "remov": [10, 56, 95, 102, 108, 113, 118, 119], "unnecessari": 10, "graph": [10, 104, 118, 119, 122], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 104, 106, 109, 111, 116, 119, 120, 121], "inductor": [10, 55, 100, 104, 117, 118], "save": [10, 12, 95, 99, 102, 104, 105, 106, 113], "load": [10, 99, 105, 106, 112, 113], "relev": [10, 103, 116], "object": [10, 27, 84, 98, 103, 111, 118, 119, 122], "safe": [10, 90], "global": [10, 108, 111], "after": [10, 12, 40, 55, 102, 103, 105, 108, 112, 117, 118, 119, 120, 121, 122], "2": [10, 13, 16, 18, 22, 25, 42, 45, 47, 51, 55, 62, 73, 77, 78, 89, 96, 98, 100, 102, 103, 108, 109, 111, 116], "5": [10, 12, 51, 62, 92, 95, 104, 106, 108, 113, 116, 118, 119], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 103], "checkout": [10, 13, 21, 100, 103], "huggingfac": [10, 112], "transform": [10, 12, 13, 99, 109, 117, 118, 119, 120, 121], "deseri": [10, 118, 119], "save_pretrain": [10, 106, 112], "push_to_hub": [10, 106, 112, 113], "from_pretrain": [10, 12, 106, 112, 113], "diffus": [10, 106], "just": [10, 51, 73, 103, 105, 108, 111, 118, 119, 122], "talk": [10, 103, 106], "train": [10, 36, 60, 73, 75, 100, 104, 108, 111, 122], "fsdp": [10, 103], "mydtypetensor": 10, "put": [10, 98, 120, 122], "developer_api_guid": 10, "folder": [10, 106, 118, 119], "cover": [10, 116, 118, 121, 122], "follow": [10, 12, 73, 75, 99, 102, 103, 104, 106, 108, 109, 111, 112, 117, 118, 119, 120, 121, 122], "executorch": [10, 48, 84, 100, 104, 112, 118, 119], "torchchat": 10, "dtensor": [10, 111], "copi": [10, 13, 95, 104, 105, 108, 109, 111, 119, 120], "past": [10, 108], "adapt": [10, 102, 109], "befor": [10, 12, 75, 84, 103, 105, 106, 108, 109, 111, 118, 119, 122], "do": [10, 52, 55, 59, 84, 103, 106, 108, 109, 111, 113, 118, 119, 120, 122], "singl": [10, 12, 35, 40, 42, 55, 57, 102, 103, 104, 108, 118, 122], "comput": [10, 22, 26, 40, 45, 62, 63, 67, 77, 85, 94, 95, 103, 108, 109, 111, 112, 118, 119, 120, 121], "intens": 10, "get": [10, 12, 23, 81, 99, 102, 103, 104, 106, 108, 113, 117, 118, 119, 120, 122], "sens": [10, 103, 111], "d": [10, 99, 106, 119], "benchmark_aq": 10, "s": [10, 12, 13, 51, 55, 56, 58, 85, 86, 89, 99, 102, 103, 104, 106, 108, 109, 111, 118, 119, 120, 121, 122], "import": [10, 12, 68, 72, 75, 84, 98, 104, 105, 106, 108, 109, 111, 112, 113, 116, 117, 120, 121], "A": [10, 12, 13, 27, 55, 57, 94, 99, 103, 108, 111, 112, 113, 118], "quick": [10, 100], "chang": [10, 84, 102, 104, 105, 106, 108, 109, 111, 117, 118, 119, 121, 122], "interest": [10, 108, 111], "print_op_and_shap": 10, "output": [10, 12, 36, 55, 56, 58, 89, 102, 103, 104, 106, 108, 112, 116, 117, 118, 119, 120, 121, 122], "torch_func": 10, "built": [10, 102, 111], "_c": 10, "tensorbas": 10, "all": [10, 40, 47, 51, 55, 57, 62, 63, 65, 67, 69, 77, 79, 94, 95, 96, 99, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 117, 118, 120, 122], "benchmark_your_kernel": 10, "helper": [10, 82, 83, 99], "right": [10, 43, 47, 108, 118], "1": [10, 22, 27, 37, 38, 42, 45, 47, 51, 52, 53, 54, 55, 76, 84, 85, 86, 88, 89, 95, 100, 103, 104, 105, 107, 108, 109, 111, 115, 116, 118, 119], "feel": [10, 103, 108, 111, 113], "free": [10, 103, 111], "either": [10, 13, 42, 66, 75, 95, 106, 108, 119, 120, 121], "one": [10, 42, 55, 57, 62, 63, 67, 75, 77, 94, 102, 103, 108, 111, 113, 119, 122], "probabl": 10, "keep": [10, 22, 49, 95, 103, 118], "futur": [10, 41, 109, 112, 113, 118, 119, 120, 122], "llama": [10, 12, 106, 112, 113, 117], "llama2": 10, "llama3": [10, 12, 102, 112], "sam": 10, "modifi": [10, 39, 84, 95, 102, 108, 111], "friendli": 10, "compar": [10, 12, 95, 102, 103, 106, 118, 120, 122], "techniqu": [10, 12, 102, 105, 106, 108, 109, 111, 113], "bound": [10, 42, 66, 106, 108, 113], "each": [10, 23, 55, 65, 73, 78, 80, 81, 91, 94, 99, 103, 108, 109, 111, 113, 118, 119, 122], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 51, 89, 103, 104, 108, 109, 111, 122], "know": [10, 55, 111], "end": [12, 102, 103, 106, 108, 111, 112, 113, 116, 119, 122], "pre": [12, 19, 22, 26, 100, 104, 106, 108, 122], "serv": [12, 13, 19, 100, 102, 111, 112, 121], "flow": [12, 48, 102, 106, 108, 109, 117, 118, 119, 120, 121], "leverag": [12, 102, 104, 106, 111, 120, 121], "partner": [12, 102, 106], "showcas": [12, 102, 106], "focus": [12, 102, 103, 106, 108], "domain": [12, 13, 54, 56, 58, 73, 102], "demonstr": [12, 102, 103, 104, 106, 111, 117, 119], "dure": [12, 13, 21, 49, 55, 58, 73, 75, 92, 102, 104, 106, 108, 109, 111, 117, 119], "numer": [12, 55, 75, 80, 81, 102, 108, 118, 119, 120], "goal": [12, 75], "mitig": [12, 108], "degrad": [12, 75, 108], "eventu": [12, 75, 102], "blog": 12, "resourc": [12, 111], "small": 12, "matric": [12, 25, 108], "freez": [12, 119, 120, 121], "checkpoint": [12, 99, 102, 106, 113], "effici": [12, 26, 80, 104, 108, 109, 121], "paper": [12, 41, 108, 116], "speed": [12, 84, 106, 108, 117], "up": [12, 23, 73, 84, 102, 103, 104, 108, 117, 118, 119, 122], "high": [12, 13, 28, 29, 30, 31, 32, 66, 75, 102, 103, 106, 108, 109, 111, 117, 118, 120, 121], "precis": [12, 13, 28, 29, 30, 31, 32, 45, 49, 65, 66, 70, 71, 75, 78, 80, 81, 103, 109, 111, 112, 117, 120, 121], "similar": [12, 108, 109, 119, 120], "inevit": 12, "actual": [12, 45, 75, 103, 109, 111, 113, 118, 119, 122], "presum": 12, "been": [12, 55, 99, 111, 119, 120, 121, 122], "successfulli": [12, 108], "recent": [12, 100], "releas": [12, 104, 120], "1b": [12, 112, 113], "3b": 12, "llamaguard": 12, "8b": [12, 102, 112], "improv": [12, 102, 106, 108, 118, 121, 122], "qualiti": [12, 108, 112], "involv": [12, 17, 75, 108], "two": [12, 21, 25, 42, 75, 99, 103, 104, 108, 111, 117, 118, 119, 120, 122], "separ": [12, 62, 63, 73, 108, 113, 118, 122], "prepar": [12, 55, 60, 65, 69, 75, 91, 95, 108, 117, 120, 121, 122], "convert": [12, 13, 21, 23, 28, 31, 33, 34, 36, 60, 68, 69, 75, 84, 98, 102, 103, 106, 108, 117, 120, 121, 122], "fake": [12, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 80, 81, 82, 83, 102, 118, 119, 122], "mean": [12, 13, 23, 51, 56, 58, 89, 99, 102, 103, 104, 108, 118, 119, 122], "valu": [12, 13, 23, 36, 37, 38, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 66, 76, 85, 86, 89, 91, 95, 103, 108, 109, 111, 117, 118, 119, 122], "map": [12, 49, 51, 73, 99, 103, 111, 118, 122], "without": [12, 68, 103, 108, 113, 120, 122], "cast": [12, 13, 35, 37], "lower": [12, 42, 48, 66, 103, 104, 106, 108, 109, 112, 119], "replac": [12, 92, 108, 113], "real": [12, 103, 104, 118, 122], "perform": [12, 13, 26, 40, 46, 49, 50, 55, 59, 62, 63, 67, 69, 70, 71, 77, 90, 91, 94, 102, 104, 108, 109, 111, 112, 113, 117, 119, 120, 121], "There": [12, 75, 103, 109, 111, 118, 122], "directli": [12, 51, 57, 75, 103, 108, 109, 111], "loop": [12, 102, 108], "distribut": [12, 102, 109, 111, 113, 117], "recip": [12, 36, 62, 63, 67, 77, 94], "instead": [12, 57, 62, 63, 67, 68, 72, 73, 75, 77, 94, 102, 104, 108, 111, 119, 120, 121, 122], "command": [12, 102, 104], "regular": [12, 117, 120, 121], "nnode": 12, "nproc_per_nod": 12, "4": [12, 16, 22, 25, 34, 46, 96, 98, 103, 104, 105, 106, 108, 111, 112, 118, 119], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 105, 106, 109, 118, 119], "16": [12, 63, 102], "equival": [12, 73, 92, 108, 119, 120, 122], "asymmetr": [12, 46, 48, 51, 53, 56, 73, 104, 109, 117, 121, 122], "token": [12, 48, 49, 71, 73, 81, 102, 106, 112], "int8": [12, 23, 48, 49, 50, 63, 71, 72, 73, 75, 81, 84, 88, 98, 103, 106, 111, 118, 120, 121, 122], "symmetr": [12, 42, 44, 45, 46, 48, 49, 50, 51, 56, 62, 65, 73, 111, 117, 118, 121, 122], "configur": [12, 17, 35, 36, 39, 42, 43, 44, 45, 47, 48, 49, 50, 53, 84, 98, 102, 103, 104, 106, 112, 120, 121, 122], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 119], "same": [12, 13, 42, 47, 56, 57, 58, 81, 89, 90, 98, 99, 102, 103, 108, 109, 111, 119, 121, 122], "wa": [12, 111, 119], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 112], "int8dynactint4weightquant": 12, "groupsiz": [12, 70, 71, 80, 81, 89], "32": [12, 46, 47, 48, 63, 72, 73, 75, 77, 78, 84, 98, 102, 104, 105, 106, 109, 111, 119], "hellaswag": [12, 106], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 106], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 106], "ckpt": 12, "llama3_token": 12, "path": [12, 84, 90, 104, 106, 117, 118, 119, 120, 122], "tmp": [12, 104], "meta": [12, 105, 112, 113, 122], "print": [12, 95, 104, 105, 106, 111, 116, 118, 119], "version": [12, 18, 42, 45, 47, 73, 84, 103, 104, 105, 111, 113, 118, 119, 122], "shot": [12, 108], "stderr": 12, "none": [12, 13, 17, 21, 28, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 50, 51, 52, 54, 55, 56, 57, 58, 62, 63, 65, 66, 72, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 89, 91, 92, 93, 95, 98, 99, 103, 109, 111, 113, 117, 118, 119, 121], "acc": [12, 118, 119], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 104, 108, 122], "openassist": 12, "oasst1": 12, "dataset": [12, 102, 106, 117, 120, 121], "find": [12, 23, 108, 118, 122], "achiev": [12, 23, 102, 108, 109, 111, 119, 120], "higher": [12, 102, 111, 112, 117, 118, 120, 121], "accuraci": [12, 102, 106, 108, 109, 117, 119, 120], "than": [12, 27, 73, 102, 103, 108, 111, 118], "recov": [12, 108, 119], "69": [12, 109], "8": [12, 26, 27, 46, 47, 51, 62, 63, 70, 80, 102, 103, 104, 106, 113, 120, 121], "overal": [12, 100, 104, 118, 122], "vanilla": 12, "compos": [12, 60, 103, 108, 111, 118, 119, 122], "lora": 12, "yield": [12, 108], "89x": 12, "usag": [12, 13, 40, 55, 60, 62, 63, 68, 72, 73, 75, 99, 100, 102, 106, 120, 121], "36": [12, 102, 106], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 17, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 57, 73, 84, 91, 95, 99, 104, 108, 117, 119, 120, 121], "try": [12, 108, 111, 118], "fsdp2": [12, 102], "yaml": 12, "onc": [12, 55, 108], "complet": [12, 55, 106, 117, 121], "qat_out": 12, "quatiz": 12, "document": [12, 111, 113, 117, 118, 120], "prefer": [12, 42, 103, 104, 111], "These": [12, 108, 111, 117, 118, 119, 122], "what": [12, 13, 21, 55, 102, 103, 104, 106, 108, 109, 113, 116, 118, 122], "hood": 12, "mini": [12, 106], "gpu": [12, 100, 102, 104, 112, 113, 116, 117], "smaller": [12, 27, 46, 47, 48, 53, 104, 105], "fit": [12, 13, 26, 103, 105], "adjust": [12, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 102], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 102], "max_seq_len": 12, "train_loop": [12, 75], "sgd": 12, "lr": [12, 102], "001": 12, "momentum": [12, 119], "9": [12, 102], "weight_decai": 12, "1e": [12, 102], "loss_fn": 12, "crossentropyloss": [12, 118, 119], "rang": [12, 51, 102, 108, 109, 118, 119], "randint": 12, "loss": [12, 102, 108, 118, 119], "backward": [12, 40, 102, 108, 119], "zero_grad": [12, 102, 119], "next": [12, 102, 109, 118, 119, 120, 121], "scheme": [12, 49, 50, 62, 63, 75, 106, 117], "although": [12, 47, 62, 63, 67, 77, 94, 111], "integ": [12, 13, 31, 32, 46, 51, 54, 56, 58, 59, 73, 74, 90, 109, 118, 119, 120], "arithmet": [12, 75], "float": [12, 13, 21, 23, 31, 33, 34, 41, 42, 47, 51, 54, 55, 56, 57, 58, 62, 66, 73, 77, 78, 89, 92, 95, 103, 104, 105, 111, 118, 119, 122], "float32": [12, 13, 29, 58, 69, 71, 73, 77, 78, 81, 89, 105, 106, 108, 109, 111, 120, 121, 122], "becaus": [12, 13, 22, 102, 105, 108, 111, 119, 122], "int8dynamicactivationint4weightconfig": [12, 75, 81, 84], "qatconfig": [12, 68, 72, 76], "swap": [12, 39, 65, 69, 102, 108, 109, 119], "fakequantizedlinear": [12, 65, 68, 82, 83], "base_config": [12, 75], "exact": [12, 81, 118, 119], "attun": 12, "benefici": 12, "later": [12, 103, 111, 118, 119, 121], "readi": [12, 102, 104, 106, 109, 111, 119], "did": [12, 48], "altern": [12, 73, 109, 111, 120, 121], "legaci": [12, 47], "offer": [12, 111, 118], "customiz": [12, 84], "unlik": [12, 109], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 104, 109, 117, 118, 119, 120, 121, 122], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 117, 118, 120, 121], "footprint": 12, "extens": [12, 111, 118, 120], "addition": [12, 120, 121], "frozen": 12, "further": [12, 111, 117, 118, 119, 120], "nf4": [12, 23], "propos": [12, 95], "express": [12, 104, 111, 117, 118, 119, 122], "subclass": [12, 13, 21, 39, 55, 62, 63, 67, 77, 85, 86, 94, 98, 99, 104, 105, 108, 112], "nf4tensor": 12, "cleanli": 12, "compil": [12, 55, 84, 90, 100, 102, 103, 104, 109, 111, 120, 121], "simpli": [12, 55, 108, 109, 111], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 31, 36, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 62, 63, 71, 73, 77, 78, 80, 81, 83, 84, 91, 98, 109], "quantization_kwarg": 12, "No": [12, 103, 105, 108], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 103, 109, 111, 113], "though": [12, 111], "shown": [12, 106, 108, 119, 122], "competit": [12, 102], "baselin": [12, 102, 106, 118], "while": [12, 62, 63, 67, 75, 77, 87, 94, 95, 106, 108, 111, 112, 117, 118, 122], "even": [12, 13, 102, 108, 122], "newer": 12, "mxfp4": [12, 103], "nvfp4": [12, 103], "blackwel": 12, "reap": 12, "benefit": [12, 43, 108, 111, 118, 121], "vari": [12, 13, 118, 119, 120, 121], "tradeoff": [12, 108, 112], "incorpor": 12, "its": [12, 46, 108, 111, 113, 118, 122], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 102, 103, 111, 112, 113, 118], "yet": [12, 48, 52, 75, 111, 112, 113, 119, 120, 121], "invok": [12, 120], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 106, 112, 113], "torchaoconfig": [12, 106, 112, 113], "int8weightonlyconfig": [12, 84, 113], "base_model": 12, "quantization_config": [12, 106, 112, 113, 121], "peft_config": 12, "throughput": [12, 102, 106], "increas": [12, 108, 118], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 35, 36, 103], "initi": [12, 13, 79, 103, 104, 105, 119], "experi": [12, 102, 121], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 102, 104, 118], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 102], "074": [12, 102], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 102], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 102, 121, 122], "407": [12, 102], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 102], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 21, 99, 109], "aqttensorimpl": [13, 21], "block_siz": [13, 19, 21, 23, 28, 29, 31, 32, 33, 34, 56, 57, 58, 89, 103, 104, 109], "tupl": [13, 21, 23, 28, 29, 31, 32, 33, 42, 44, 56, 57, 58, 79, 89, 95, 99, 111, 113, 118, 119, 122], "quant_min": [13, 21, 31, 32, 33, 51, 56, 57, 58, 89, 104, 111, 121, 122], "union": [13, 21, 36, 42, 44, 56, 58, 66, 73, 84, 89], "quant_max": [13, 21, 31, 32, 33, 51, 56, 57, 58, 89, 104, 111, 121, 122], "zero_point_domain": [13, 21, 31, 32, 33, 47, 56, 57, 73], "zeropointdomain": [13, 21, 31, 32, 33, 47, 56, 57, 73], "stride": [13, 21, 111], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 106, 114, 116], "affin": [13, 15, 16, 17, 18, 22, 25, 26, 31, 58, 89, 103], "point": [13, 21, 33, 41, 47, 51, 54, 58, 66, 73, 78, 79, 80, 81, 102, 103, 104, 105, 108, 109, 111, 118, 122], "quantized_tensor": 13, "float_tensor": [13, 111], "zero_point": [13, 19, 32, 54, 56, 57, 58, 89, 99, 103, 108, 109, 111, 122], "happen": [13, 21, 55, 103, 111, 118, 120], "choose_qparam": [13, 103], "dequant": [13, 21, 23, 58, 103, 104, 111, 113, 118, 120, 121, 122], "http": [13, 21, 41, 55, 95, 104, 106, 108, 112, 121], "com": [13, 21, 41, 106, 112], "ao": [13, 21, 108, 113], "blob": [13, 21], "main": [13, 21, 103, 104, 106, 108, 109, 111, 112, 118, 122], "three": [13, 55, 95, 98, 120, 121], "choose_qparams_affin": [13, 57], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 102, 103, 108, 117, 118, 119, 120, 121], "extern": [13, 120], "regardless": 13, "intern": [13, 26], "represent": [13, 19, 30, 99, 108, 113, 118, 122], "orient": 13, "field": [13, 73, 76, 99, 122], "impl": [13, 99], "storag": [13, 22, 108], "store": [13, 22, 23, 27, 49, 87, 94, 103, 108, 112, 113, 118, 119], "plain": [13, 47, 86, 103, 113], "int_data": [13, 111], "kernel": [13, 15, 16, 18, 22, 26, 41, 42, 43, 46, 80, 84, 85, 104, 106, 108, 117, 120, 121], "element": [13, 25, 27, 55, 56, 58, 65, 78, 80, 81, 89, 99, 103, 108], "share": [13, 56, 58, 89, 108], "qparam": [13, 47, 56, 58, 89], "minimum": [13, 55, 56, 58, 89], "maximum": [13, 56, 58, 89, 91], "zero": [13, 25, 47, 49, 56, 58, 73, 78, 79, 80, 81, 95, 108, 109, 122], "subtract": [13, 23], "unquant": [13, 122], "given": [13, 21, 34, 88, 102, 108, 113, 122], "classmethod": [13, 21, 87, 99, 109, 111, 113], "from_hp_to_floatx": 13, "input_float": [13, 21, 28, 29, 30, 31, 32, 33, 93], "target_dtyp": [13, 28, 29, 31, 32, 35, 36, 56, 57, 103, 109], "_layout": [13, 21, 28, 29, 30, 31, 32, 33, 99, 104, 109], "layout": [13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 47, 48, 49, 98, 99, 108], "scale_dtyp": [13, 28, 29, 31, 56, 57, 109], "float8": [13, 16, 17, 28, 29, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 65, 66, 67, 88, 100, 106, 109], "from_hp_to_floatx_stat": 13, "static": [13, 19, 23, 29, 32, 36, 44, 57, 73, 100, 104, 118, 119, 120, 121, 122], "from_hp_to_fpx": 13, "floatx": [13, 30], "ebit": [13, 30, 41], "mbit": [13, 30, 41], "float1": [13, 30], "float7": [13, 30], "from_hp_to_intx": [13, 21], "mapping_typ": [13, 31, 48, 56, 57, 73], "mappingtyp": [13, 31, 48, 49, 56, 57, 73, 109], "ep": [13, 31, 56, 57, 73, 109, 119, 121, 122], "zero_point_dtyp": [13, 31, 56, 57, 109], "preserve_zero": [13, 31, 47, 56, 57], "plainlayout": [13, 31, 32, 48, 49, 99, 109], "use_hqq": [13, 31, 47, 53, 112, 113], "custom_scal": [13, 31], "custom_zero_point": [13, 31], "from_hp_to_intx_stat": 13, "argument": [13, 26, 55, 58, 73, 75, 84, 87, 99, 102, 103, 106, 120], "correct": [13, 22, 118, 119], "otherwis": [13, 50, 60, 73, 119], "desir": [13, 55, 109], "gradient": [13, 100, 108], "implicitli": [13, 122], "complex": [13, 108], "non_block": 13, "memory_format": [13, 120, 121], "preserve_format": 13, "accord": 13, "c": [13, 99, 104, 111, 120, 121], "rule": 13, "truncat": 13, "part": [13, 100, 108, 111, 112, 119], "cannot": [13, 108, 109, 112, 113], "inf": 13, "long": [13, 111, 118], "behavior": [13, 19, 60, 113, 118, 119], "undefin": [13, 60, 95], "across": [13, 95, 106, 108, 111, 113], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 108, 119], "host": [13, 113], "both": [13, 42, 47, 75, 81, 103, 104, 108, 109, 111, 118, 120, 121, 122], "pin": 13, "pageabl": 13, "howev": [13, 108, 112, 113, 119, 122], "caution": 13, "advis": [13, 103], "good": [13, 104, 111, 122], "pin_memori": 13, "match": [13, 58, 59, 80, 81, 99, 108, 118], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "blocksiz": 14, "64": [14, 34, 47, 53, 65, 105, 106, 109, 111, 113], "block": [14, 23, 95, 108], "spars": [14, 22, 25, 62, 77, 78, 95, 108], "variabl": [14, 17, 26, 27, 95, 99, 108], "cutlass": [15, 16], "mm_config": [17, 42, 44], "float8mmconfig": [17, 42, 44], "tinygemm": [18, 47, 80, 84, 104], "_weight_int4pack_mm_for_cpu": 18, "least": 18, "6": [18, 73, 102, 103, 104, 106, 108, 118, 119, 120], "It": [19, 22, 24, 26, 40, 104, 108, 111, 122], "post": [19, 26, 75, 100, 103, 104, 111, 119, 122], "design": [19, 22, 25, 106, 113, 117, 118, 122], "extend": [19, 103, 108, 120], "conjunct": 19, "tensorimpl": [19, 99], "interact": [19, 118], "marlin": [20, 21, 22, 33], "qqq": [20, 21, 33], "marlinqqq": 21, "inherit": [21, 24, 99, 111, 113, 120, 121], "_choose_qparams_and_quantize_affine_qqq": 21, "_dequantize_affine_qqq": 21, "pattern": [22, 25, 103, 104, 113, 117, 118], "preprocess": [22, 25], "manag": 22, "pre_process": 22, "1\u00ba": 22, "transpos": [22, 111], "sinc": [22, 43, 62, 63, 67, 77, 94, 103, 105, 106, 108, 109, 111, 118, 119, 120, 121, 122], "2\u00ba": 22, "inject": 22, "3\u00ba": 22, "again": [22, 23, 108, 118, 122], "dim": [22, 109, 111, 113, 118, 119], "tensor_meta": 23, "subclasstensorarg": 23, "n_block": 23, "scaler_block_s": [23, 34], "quantized_scal": 23, "quantization_factor": 23, "scaler_mean": 23, "quantized_data": [23, 113], "qlora": [23, 100, 106], "convert_to_norm_float_weight": 23, "normal": [23, 34, 55, 108, 118, 119], "dequantize_scal": 23, "unpack": 23, "doubl": 23, "scaler": 23, "per_scaler_block": 23, "factor": [23, 59, 92, 102, 108], "inpt_weight": 23, "double_quantize_scal": 23, "take": [23, 62, 63, 67, 77, 84, 94, 98, 99, 103, 108, 117, 118, 119, 120, 121, 122], "calcul": [23, 40, 42, 51, 56, 57, 66, 91, 103, 108, 118, 122], "absmax": 23, "posit": 23, "And": [23, 42, 111, 120, 122], "per_block": 23, "int16": [23, 118], "n_scaler_block": 23, "get_original_weight": 23, "quantize_tensor_nearest": 23, "float16": [23, 89, 108], "nearest": 23, "round": [23, 51, 111], "metadata": [24, 99, 103, 106, 111, 113], "semi": [25, 98, 108], "everi": [25, 62, 63, 67, 77, 94, 108, 111, 118, 119], "four": [25, 117], "prune": [25, 95], "conform": 25, "inner_k_til": [26, 47, 70, 80, 104], "core": [26, 52, 109, 113, 118], "tile": 26, "affect": [26, 85, 108], "matmul": [26, 42, 45, 103, 108, 111], "pack_dim": [27, 53], "uintx": [27, 53], "standard": [27, 113], "byte": [27, 41, 53], "uintxtensor": 27, "determin": [27, 56, 75, 102, 108, 113], "along": [27, 108, 113, 117], "indic": [27, 54, 108, 122], "last": [27, 102, 117], "256": [34, 47, 69, 70, 71, 80, 81, 106, 118, 119, 122], "scaling_typ": [35, 36], "scalingtyp": [35, 36], "scaling_granular": [35, 36], "scalinggranular": [35, 36], "mayb": 35, "cast_config_input": 36, "castconfig": 36, "cast_config_input_for_grad_weight": 36, "cast_config_weight": 36, "cast_config_weight_for_grad_input": 36, "cast_config_grad_output": 36, "cast_config_grad_output_for_grad_weight": 36, "gemm_config_output": 36, "float8gemmconfig": 36, "use_fast_accum": [36, 44], "gemm_config_grad_input": 36, "gemm_config_grad_weight": 36, "enable_fsdp_float8_all_gath": 36, "pad_inner_dim": [36, 44], "emul": [36, 44], "force_recompute_fp8_weight_in_bwd": 36, "round_scales_to_power_of_2": 36, "from_recipe_nam": 36, "recipe_nam": [36, 102], "float8linearrecipenam": 36, "qualnam": [37, 38, 51, 52, 54, 76, 85, 86], "boundari": [37, 38, 51, 52, 54, 76, 85, 86], "strategi": 37, "module_filter_fn": [39, 102], "callabl": [39, 55, 84, 93, 98, 99, 113], "float8linearconfig": 39, "float8linear": [39, 102], "instanc": [39, 62, 63, 67, 77, 84, 94, 98, 99, 105, 111, 118, 120, 121, 122], "fqn": [39, 95, 98, 102, 109], "sum": [40, 118, 119], "set_inductor_config": [41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55], "sub": [41, 53, 108], "expon": 41, "mantissa": 41, "fp6_e3_m2": 41, "fp6_e2_m3": 41, "fp6": 41, "llm": 41, "arxiv": [41, 95, 108], "org": [41, 55, 95, 104, 106, 108, 121], "ab": [41, 95, 108], "2401": 41, "14112": 41, "repo": 41, "usyd": 41, "fsalab": 41, "fp6_llm": 41, "renam": [41, 118, 119], "fpxtensorcoreaqttensorimpl": 41, "experiment": [41, 75, 117], "merg": 41, "to_affine_quantized_floatx": 41, "activation_dtyp": [42, 44, 103], "float8_e4m3fn": [42, 44, 45, 66, 103], "weight_dtyp": [42, 44, 45, 103, 106], "pertensor": [42, 44, 66, 109], "perrow": [42, 44, 66, 103], "list": [42, 55, 58, 60, 92, 95, 99, 104, 111, 113, 117, 119, 122], "activation_value_lb": 42, "activation_value_ub": 42, "kernel_prefer": [42, 103], "kernelprefer": 42, "fp8granular": [42, 66], "fast": [42, 44, 108], "accumul": [42, 44], "upper": [42, 66], "defalut": 42, "chosen": [42, 88, 108], "torchinductor": [42, 44, 45, 46, 47, 48, 49, 50, 53, 120, 121], "deprec": [42, 45, 47, 68, 72], "split": [42, 45, 106, 118, 119], "int4_packing_format": [43, 47], "int4packingformat": [43, 47], "preshuffl": [43, 103], "128": [43, 46, 47, 102, 106, 109, 111, 112, 113, 121, 122], "underli": [43, 106, 111], "bigger": 43, "float8_e4m": 44, "channel": [45, 49, 50, 65, 69, 70, 71, 73, 77, 78, 80, 81, 94, 109, 121], "packing_bitwidth": 46, "weight_onli": 46, "gemlit": 46, "triton": [46, 103, 120, 121], "associ": [46, 109], "fp16": [46, 56], "control": [46, 47, 48, 49, 50, 53, 95, 108, 113, 118], "fine": [46, 47, 48, 53, 100, 102, 106, 108], "grain": [46, 47, 48, 53, 111], "impact": [46, 55, 102, 106, 113], "runtim": [46, 103, 118], "tensorcoretiledlayout": [47, 104], "int4_choose_qparams_algorithm": 47, "int4chooseqparamsalgorithm": 47, "groupwis": 47, "mainli": [47, 103, 117, 120, 122], "distinguish": [47, 103], "packing_format": 47, "variant": [47, 51, 57, 111], "hqq": [47, 53, 103], "preserv": [47, 56, 95, 106, 108, 117], "Will": 47, "subset": [47, 103], "valid": [47, 99, 106, 113, 122], "state": [47, 113], "v1": [47, 106], "v2": [47, 116], "ignor": [47, 62, 63, 67, 77, 94, 102, 118, 119], "less": [47, 51, 108, 111, 118], "confus": [47, 103, 108, 118], "act_mapping_typ": [48, 49], "produc": [48, 104, 117, 118, 119, 120, 121], "backend": [48, 100, 104, 106, 108, 122], "marlinqqqlayout": 48, "cutlassint4packedlayout": 48, "weight_only_decod": 49, "around": [49, 102, 103, 104, 105, 118], "decod": [49, 106], "better": [49, 50, 102, 111, 118, 119, 120, 121, 122], "number": [51, 53, 55, 65, 78, 80, 81, 95, 106, 108, 111, 119, 120], "sai": [51, 89, 103, 112, 113, 122], "3": [51, 55, 62, 89, 100, 102, 103, 104, 108, 112, 116, 118, 119], "7": [51, 102, 106, 120, 121], "symmetric_no_clipping_err": 51, "smin": 51, "smax": 51, "min_val_neg": [51, 111], "max_val_po": [51, 111], "By": [51, 108], "individu": [51, 108], "error": [51, 55, 73, 102, 111, 118], "neg": 51, "placehold": [52, 103, 121], "uint1": [53, 103], "uint7": [53, 103], "enum": [54, 76, 85], "quantized_v": 54, "float_val": 54, "mid_point": 54, "example_input": [55, 79, 104, 105, 109, 117, 118, 119, 120, 121, 122], "qtensor_class_list": 55, "aqdefaultlinearweight": 55, "aqint8weightonlyquantizedlinearweight": 55, "aqint8weightonlyquantizedlinearweight2": 55, "aqint8dynamicallyquantizedlinearweight": 55, "filter_fn": [55, 84, 98], "interpol": 55, "85": 55, "manual": [55, 119], "supress_autoquant_error": 55, "min_sqnr": 55, "aq_kwarg": 55, "autoquant": 55, "identifi": [55, 109, 122], "over": [55, 102, 108, 118, 119], "potenti": [55, 108, 109, 117, 118, 120, 121], "qtensor": 55, "search": [55, 108], "whose": [55, 122], "exchang": 55, "autoquantizablelinearweight": 55, "calibr": [55, 57, 104, 117, 119, 120, 121], "seen": [55, 103], "record": [55, 109], "final": [55, 84, 103, 104, 108, 117, 118, 119, 120, 121, 122], "benchmark": [55, 91, 100, 102, 104, 112, 117, 120, 121], "member": 55, "pick": 55, "highli": 55, "had": [55, 111, 118], "proce": 55, "combin": [55, 73, 106, 108, 111, 118, 120], "finalize_autoqu": 55, "log": [55, 111], "fulli": [55, 84, 92, 98, 106, 108, 118], "unless": [55, 113], "default_autoquant_class_list": 55, "second": [55, 59, 75, 99, 102, 103, 116, 122], "stop": 55, "wait": 55, "sever": [55, 102, 113, 117, 122], "automat": [55, 75, 102, 106, 111, 112, 113, 116], "suppress": 55, "accept": [55, 106, 122], "signal": 55, "nois": 55, "ration": 55, "en": 55, "wikipedia": 55, "wiki": 55, "noise_ratio": 55, "v": [55, 122], "caus": [55, 102], "too": 55, "larg": [55, 106, 111, 120], "resaon": 55, "40": [55, 102], "keyword": [55, 73, 75, 87, 103], "wrap": [55, 111, 120, 121], "example_input1": 55, "example_input2": 55, "int32": [56, 69, 73, 77, 78, 103, 104, 118, 122], "fp32": [56, 58, 73, 81, 109, 111, 118, 120], "optioanl": 56, "param": [56, 57, 95, 106], "request": [56, 58, 89], "min_val": [57, 111], "max_val": [57, 111], "observ": [57, 94, 103, 108, 109, 117, 118, 119, 120, 121, 122], "obtain": 57, "track": [57, 112, 113], "mostli": [57, 75, 104], "input_dtyp": 58, "output_dtyp": [58, 77, 89], "uint8": [58, 89, 103, 109, 122], "b": [59, 99], "scales1": 59, "multipli": [59, 90, 108], "rais": [59, 72, 75, 90, 111, 113], "assertionerror": [59, 90, 111], "expect": [59, 102, 108, 111, 117, 118, 120, 121, 122], "qat": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 100, 106, 120], "twostepquant": 60, "easili": [60, 117], "thei": [60, 102, 104, 108, 111, 118, 119, 122], "constructor": [60, 99, 111], "must": [60, 73, 75, 81, 102, 108, 112, 113, 119, 121, 122], "embed": [60, 62, 69, 72, 75, 77, 78], "my_quant": 60, "qatquantizer1": 60, "qatquantizer2": 60, "qatquantizer3": 60, "num_embed": [62, 77, 78], "embedding_dim": [62, 77, 78], "padding_idx": [62, 77, 78], "max_norm": [62, 77, 78], "norm_typ": [62, 77, 78], "scale_grad_by_freq": [62, 77, 78], "weight_config": [62, 63, 72, 75], "fakequantizeconfigbas": [62, 63, 72, 75], "intxfakequantizeconfig": [62, 63, 72, 74, 75], "fq_embed": 62, "longtensor": 62, "overridden": [62, 63, 67, 77, 94], "within": [62, 63, 67, 77, 94, 106, 108, 113, 120, 121], "afterward": [62, 63, 67, 77, 94], "former": [62, 63, 67, 77, 94], "care": [62, 63, 67, 77, 94, 105, 108, 118], "hook": [62, 63, 67, 77, 94, 103], "latter": [62, 63, 67, 77, 94, 119], "silent": [62, 63, 67, 77, 94, 120], "in_featur": [63, 80, 81, 102, 104, 105, 109, 111], "out_featur": [63, 80, 81, 102, 104, 109, 111], "activation_config": [63, 72, 75], "per_token": [63, 72, 73, 75], "is_symmetr": [63, 72, 73, 75], "fq_linear": 63, "scale_precis": [65, 69, 73, 77, 78], "rowwis": [65, 103], "hp_value_lb": 66, "hp_value_ub": 66, "float8fakequantizeconfig": 67, "fakequantizedembed": 68, "back": [68, 111], "model_with_fake_quantized_linear": 68, "zero_point_precis": [69, 73, 77, 78], "int4weightonlyqatembed": 69, "int4weightonlyembed": 69, "scales_precis": [70, 71, 80, 81], "padding_allow": 71, "valueerror": [72, 75], "torchaodtyp": 73, "is_dynam": [73, 120, 121, 122], "range_learn": 73, "simul": [73, 75, 96, 108], "older": 73, "int1": [73, 103], "int7": [73, 103], "pergroup": [73, 106], "pertoken": 73, "per_channel": 73, "peraxi": [73, 106, 109], "per_group": [73, 89], "leav": 73, "empti": [73, 103], "prototyp": [73, 79, 103, 122], "properti": [73, 74], "throw": 73, "els": [73, 103, 106, 113, 118, 119], "symmetri": 74, "qatstep": 75, "awar": [75, 95, 100, 104, 108, 111], "ptq": [75, 119, 120], "phase": [75, 122], "int4weightonlyconfig": [75, 84, 104, 105, 113], "qat_config": 75, "act_config": 75, "alwai": [75, 106, 111], "One": [75, 108, 111, 113, 122], "intxfakequantizerbas": 79, "weightonlyint4linear": 80, "hardcod": [81, 122], "mod": [82, 83, 102, 108, 111], "disabl": [82, 111, 119], "inplac": [84, 95, 104], "qualifi": [84, 92, 98, 108], "predefin": [84, 86, 122], "execut": [84, 107, 111, 115], "int8dynamicactivationint8weightconfig": [84, 98], "int4_weight_onli": 84, "sequenti": [84, 98, 102], "select": [85, 118], "found": [85, 103, 104, 106, 108, 109, 111], "nativ": [85, 100, 102, 103, 111, 118], "laid": [86, 103], "opaqu": 86, "decid": [86, 108, 109], "adopt": [86, 103], "creation": [87, 113], "construct": [87, 103, 118, 122], "from_hp": [87, 103], "cl": [87, 99, 109, 111, 113], "quant_kwarg": [87, 88, 93], "quantizetensorkwarg": 88, "flexibl": [88, 108, 111, 117, 120], "variou": 88, "tabl": [89, 99, 102, 103, 108], "show": [89, 102, 104, 106, 108, 113, 118, 119], "per_tensor": 89, "per_axi": 89, "axi": [89, 109], "mat2": 90, "consid": [90, 108], "cubla": 90, "fallback": [90, 113], "j": 90, "debug_skip_calibr": 91, "smoothquant": [91, 92, 117], "smoothfakedynamicallyquantizedlinear": [91, 92], "skip_fqn_list": 92, "cur_fqn": 92, "alpha": 92, "skip": [92, 95, 103, 108], "being": [92, 102, 108, 113, 120, 121], "input_quant_func": 93, "dict": [93, 95, 99, 111, 113, 121, 122], "l2": [94, 108], "norm": [94, 95, 108], "buffer": 94, "x_orig": 94, "sparsity_level": [95, 108], "semi_structured_block_s": 95, "wanda": 95, "sparsifi": [95, 100, 105, 108], "2306": 95, "11695": 95, "product": [95, 106, 112, 113, 120, 122], "magnitud": [95, 108], "parametr": 95, "deepcopi": [95, 104, 109, 111, 119], "squash_mask": [95, 108], "params_to_keep": 95, "params_to_keep_per_lay": 95, "squash": 95, "mask": [95, 108], "appropri": [95, 117, 118, 119, 120, 121], "sparse_param": 95, "attach": [95, 108, 122], "kei": [95, 108, 116], "xdoctest": 95, "local": [95, 106, 108], "hasattr": [95, 113], "submodule1": 95, "linear1": [95, 104, 105, 109, 111], "foo": [95, 118], "bar": [95, 118], "submodule2": 95, "linear42": 95, "baz": 95, "42": [95, 109], "24": 95, "ones": [95, 119], "update_mask": 95, "tensor_nam": [95, 113], "statist": [95, 108, 109, 118, 119], "retriev": 95, "act_per_input": 95, "Then": [95, 111, 121, 122], "whole": [95, 122], "alia": [97, 99, 113], "semisparseweightconfig": 97, "sparsify_": 98, "apply_tensor_subclass": 98, "essenti": [98, 113, 117], "semi_sparse_weight": 98, "semisparselayout": 98, "sparsemarlinlayout": 98, "isinst": [98, 102, 108, 109, 111, 113, 119, 122], "sparse_api": 98, "commonli": [99, 102, 108], "includ": [99, 102, 103, 111, 117, 120, 121, 122], "_get_to_kwarg": 99, "register_layout": 99, "plainaqttensorimpl": [99, 109], "get_tensor_impl_constructor": 99, "tensor_impl_ctr": 99, "simplifi": [99, 117, 118, 120, 121], "implment": 99, "tensor_data": 99, "optional_tensor_data_nam": 99, "boilerpl": 99, "optional_tensor_attribute_nam": 99, "__new__": [99, 111, 113], "exaclti": 99, "present": [99, 108], "__tensor_flatten__": [99, 111, 113], "flatten": 99, "attribute_nam": 99, "__tensor_unflatten__": [99, 111, 113], "tensor_data_dict": [99, 111, 113], "_apply_fn_to_data": [99, 113], "recreat": 99, "__repr__": [99, 111], "_same_metadata": 99, "between": [99, 103, 108, 111, 113, 117, 119, 120, 122], "__setstate__": 99, "serial": [99, 100, 103, 112, 118, 119], "old": 99, "maintain": [99, 106, 108], "bc": 99, "contigu": [99, 103, 120, 121], "detach": [99, 111, 113], "clone": [99, 106, 113], "copy_": [99, 113], "_to_copi": [99, 113], "f": [99, 102, 103, 105, 106, 108, 109, 111, 113, 118, 119], "h": [99, 106], "layout_class": 99, "tensorimplclass": 99, "from_plain": 99, "tensor_class": 99, "aten_op": 99, "decor": [99, 111, 113], "__torch_dispatch__": [99, 111], "implements_torch_funct": 99, "torch_fn": 99, "__torch_function__": [99, 103, 111], "registr": 99, "aqt": 99, "introduct": [100, 103, 106], "highlight": [100, 111, 116], "guid": [100, 103, 106, 117], "contributor": [100, 103, 104], "tune": [100, 102, 106, 108, 117], "vllm": [100, 112], "sglang": [100, 112], "hug": [100, 106], "face": [100, 103, 106, 108, 118], "advanc": [100, 109, 111, 117, 120, 121], "export": [100, 103], "x86": [100, 104], "intel": [100, 117, 120], "openvino": [100, 104], "5x": 102, "cluster": [102, 103], "34": 102, "43x": 102, "2k": 102, "h200": 102, "latest": [102, 104], "offic": 102, "offici": [102, 103], "popular": 102, "flagship": 102, "form": [102, 103, 108], "quickli": [102, 111], "batteri": 102, "fork": 102, "build": [102, 103, 108, 111, 113, 118], "top": [102, 103, 111, 117, 118, 119, 120, 121], "virtual": 102, "environ": [102, 106], "conda": 102, "venv": 102, "download": [102, 104, 106, 114, 116, 118, 119, 121], "job": 102, "below": [102, 103, 108, 111, 112, 113, 116, 117], "root": [102, 106], "launch": 102, "ngpu": 102, "config_fil": 102, "train_config": 102, "llama3_8b": 102, "toml": 102, "run_train": 102, "sh": [102, 106], "hyperparamet": 102, "edit": [102, 106], "line": [102, 108, 112], "flag": [102, 119], "termin": 102, "rank0": 102, "titan": 102, "2025": 102, "06": 102, "04": 102, "08": 102, "51": 102, "48": 102, "info": 102, "2254": 102, "27": 102, "34gib": 102, "28": 102, "78": 102, "tp": [102, 113], "375": 102, "tflop": 102, "21": 102, "73": [102, 109], "mfu": 102, "20": [102, 106, 119], "58": 102, "557": 102, "7069": 102, "99gib": 102, "62": 102, "034": 102, "35": [102, 106, 109], "41": [102, 106], "19": 102, "52": 102, "224": [102, 109, 117, 118, 119, 120, 121], "9196": 102, "022": 102, "406": [102, 118, 119], "65": 102, "904": 102, "1423": 102, "014": 102, "23": [102, 109], "As": [102, 118, 122], "warmup": 102, "7k": 102, "99gb": 102, "peak": [102, 106, 112], "against": 102, "02": 102, "37": 102, "404": 102, "2611": 102, "22gib": 102, "595": 102, "47": 102, "49": [102, 109], "027": 102, "4260": 102, "89gib": 102, "344": 102, "367": 102, "39": 102, "03": 102, "01": 102, "988": 102, "9482": 102, "321": 102, "366": 102, "14": 102, "991": 102, "1183": 102, "300": 102, "364": 102, "89": 102, "4659": 102, "291": 102, "84": 102, "769": 102, "gc": 102, "peform": 102, "period": 102, "collect": [102, 108], "3k": 102, "89gb": 102, "11x": 102, "nearli": 102, "ident": [102, 108], "performan": 102, "vs": [102, 108, 118, 122], "curv": [102, 108], "omit": [102, 103, 118, 119, 120], "648": 102, "2648": 102, "28gib": 102, "71": 102, "26": 102, "475": 102, "9106": 102, "91gib": 102, "53": [102, 106], "503": 102, "434": 102, "43": 102, "94": [102, 118], "166": 102, "0774": 102, "663": 102, "443": 102, "44": [102, 109], "87": 102, "50": [102, 108, 109, 117, 118, 120, 121], "885": 102, "3233": 102, "643": 102, "442": 102, "66": [102, 106, 109], "76": 102, "613": 102, "6150": 102, "637": 102, "72": [102, 106], "6k": 102, "91gb": 102, "21x": [102, 106], "tl": 102, "dr": 102, "priorit": 102, "accur": [102, 108, 117], "stabil": 102, "cost": [102, 109], "slightli": [102, 111], "outlier": 102, "underflow": 102, "8xh100": 102, "box": [102, 108, 120], "toi": [102, 104, 109, 111, 120], "convert_to_float8_train": 102, "recurs": 102, "kind": [102, 118], "gemm": [102, 120, 121], "snippet": [102, 118, 119], "float8_linear_util": 102, "float8_linear": 102, "sampl": [102, 118, 120, 121], "adamw": 102, "elig": 102, "divis": 102, "label": 102, "fake_label": 102, "ones_lik": 102, "mse_loss": 102, "model_state_dict": 102, "state_dict": [102, 105, 118, 119], "optimizer_state_dict": 102, "pth": [102, 118, 119], "explor": [102, 104, 121], "few": [102, 111, 118, 119], "lai": 103, "stack": [103, 106], "awq": 103, "gptq": 103, "int4tensor": 103, "int4preshuffledtensor": 103, "float3": 103, "overload": [103, 108], "term": [103, 108, 118, 122], "extra": [103, 106], "matter": [103, 108], "float4_e2m1fn_x2": 103, "float8_e4m3fnuz": 103, "float8_e5m2": 103, "float8_e5m2fnuz": 103, "float8_e8m0fnu": 103, "pr": 103, "shell": 103, "dervi": 103, "mxfp8": 103, "preicison": 103, "mention": [103, 118], "previou": [103, 106, 118, 119, 120, 121], "accommod": 103, "choose_qparams_affine_with_min_max": 103, "min": [103, 109, 111, 118, 122], "raw": 103, "quantize_fp8_row": 103, "int_matmul": 103, "int_scaled_matmul": 103, "reli": [103, 104, 108, 109, 111], "handwritten": 103, "On": [103, 104], "glue": 103, "everyth": 103, "togeth": [103, 106, 118, 120, 122], "anoth": [103, 108, 111, 118, 122], "side": 103, "swizzl": 103, "dtpype": 103, "act": 103, "adjac": 103, "special": [103, 108, 117, 118], "float8rowwisetensor": 103, "float8blockwisetensor": 103, "close": [103, 108], "low_precision_v": 103, "high_precision_v": 103, "procedur": 103, "especi": [103, 105, 108, 120, 121], "bitwidth": [103, 122], "codebook": 103, "index": [103, 104, 106, 108, 121], "vector": [103, 108, 120], "kmean": 103, "tradition": 103, "explain": [103, 117, 120], "simplest": [103, 108], "easi": [103, 106], "linear_modul": 103, "question": [103, 105, 108, 111, 122], "activation_granular": 103, "act_quant_kwarg": 103, "weight_granular": [103, 106], "quantized_weight": [103, 113], "float8_dtyp": 103, "haven": 103, "pt2": [103, 111, 120], "autoround": 103, "multitensor": 103, "sure": [103, 106, 122], "open": [103, 108], "describ": [103, 105, 108, 116, 118, 119], "finetun": [103, 106], "quantized_train": 103, "progress": [103, 112, 113], "lot": [103, 108], "connect": [103, 122], "walk": [103, 109, 111, 116, 117, 120], "float8dynamicactivationfloat8weightconfig": 103, "len": [103, 106, 113, 118, 119, 122], "_choose_quant_func_and_quantize_tensor": 103, "relat": [103, 108], "xq": 103, "reshap": [103, 118, 119], "wq": 103, "x_scale": [103, 118], "w_scale": 103, "out_shap": 103, "stabl": 104, "pip": [104, 106, 112, 117, 118], "nightli": [104, 106], "url": [104, 106, 121], "whl": [104, 106, 121], "cu121": 104, "major": 104, "entri": 104, "mutat": 104, "logic": [104, 111, 113], "toylinearmodel": [104, 105, 109], "linear2": [104, 105, 109, 111], "eval": [104, 105, 106, 109, 117, 119, 120, 121], "faster": [104, 108], "model_bf16": 104, "uint4": 104, "int4mm": 104, "mix": [104, 106, 117, 120, 121], "stai": [104, 111], "tensor_impl_dtyp": 104, "roughli": [104, 108], "quarter": 104, "os": [104, 118, 119], "int4_model": 104, "pt": [104, 106], "bfloat16_model": 104, "int4_model_size_mb": 104, "getsiz": [104, 118, 119], "bfloat16_model_size_mb": 104, "2f": [104, 118, 119], "mb": [104, 105, 107, 115, 118, 119], "00": [104, 107, 115], "benchmark_model": 104, "unwrap_tensor_subclass": 104, "num_run": 104, "100": [104, 111, 118, 119], "_dynamo": [104, 111], "reset": [104, 118, 119], "bf16_time": 104, "int4_tim": 104, "time": [104, 108, 111, 112, 116, 117, 118, 119], "3f": [104, 119], "ms": 104, "1fx": 104, "393": 104, "410": 104, "9x": 104, "recogn": [104, 122], "decis": 104, "pt2e": [104, 117, 118, 119, 120, 121], "fuse": [104, 108, 111, 119], "deleg": [104, 118], "x86inductorquant": [104, 120], "quantize_pt2": [104, 117, 118, 119, 120, 121], "prepare_pt2": [104, 117, 118, 120, 121], "x86_inductor_quant": [104, 120], "get_default_x86_inductor_quantization_config": [104, 120], "float_model": [104, 111, 117, 118, 119, 120, 121], "data_load": [104, 118, 119, 120, 121], "no_grad": [104, 111, 117, 118, 119, 120, 121], "imag": [104, 112, 117, 118, 119, 120, 121], "program": [104, 118, 119, 120, 122], "captur": [104, 118, 119, 122], "expos": [104, 118, 119], "set_glob": [104, 118, 119, 120, 121], "xiq": [104, 120], "prepare_qat_pt2": [104, 119, 120], "sample_inference_data": 104, "convert_pt2": [104, 117, 118, 119, 120, 121], "wrapper": [104, 111, 120], "_inductor": [104, 120], "cpp_wrapper": [104, 120], "optimized_model": [104, 117, 120, 121], "converted_model": [104, 120, 121], "xpu": [104, 121], "simpl": [104, 108, 109, 111, 117, 120, 121], "visit": 104, "would": [104, 108, 111, 119, 121], "forget": 104, "tempfil": [105, 112], "get_model_size_in_byt": 105, "ref": [105, 118], "namedtemporaryfil": 105, "seek": [105, 108], "m_load": 105, "load_state_dict": [105, 118, 119], "assign": 105, "assert": [105, 109, 111, 113, 122], "equal": [105, 108], "thing": [105, 108, 111, 118], "float_weight1": 105, "float_weight2": 105, "quantized_weight1": 105, "quantized_weight2": 105, "go": [105, 111, 116, 122], "techinqu": 105, "reduct": [105, 106, 108, 111], "4x": [105, 106], "0625": 105, "reason": [105, 108], "avoid": [105, 108], "affine_quantized_tensor": 105, "deploi": 106, "engin": 106, "seamlessli": [106, 111, 120, 121], "seamless": [106, 120], "hf": [106, 112], "signific": [106, 108], "wheel": 106, "ai": 106, "cu126": 106, "push": [106, 108, 112, 113], "hub": [106, 112, 113], "server": [106, 113], "phi": 106, "microsoft": 106, "o3": 106, "client": 106, "curl": 106, "localhost": 106, "8000": 106, "chat": 106, "content": 106, "applic": 106, "messag": 106, "role": 106, "give": [106, 108, 111], "me": 106, "short": 106, "languag": 106, "temperatur": 106, "top_p": 106, "95": 106, "top_k": 106, "max_token": 106, "32768": 106, "vram": 106, "15x": 106, "2x": [106, 108], "littl": [106, 113], "packag": [106, 112], "git": [106, 112], "acceler": [106, 108, 112], "autotoken": [106, 112], "pipelin": 106, "random": [106, 108, 118, 119], "manual_se": [106, 118, 119], "model_path": 106, "device_map": [106, 112, 113], "trust_remote_cod": 106, "assist": 106, "eat": 106, "banana": 106, "dragonfruit": 106, "smoothi": 106, "blend": 106, "milk": 106, "honei": 106, "salad": 106, "slice": [106, 113], "lemon": 106, "juic": 106, "solv": [106, 108, 111], "equat": 106, "pipe": [106, 112], "text": 106, "generation_arg": 106, "max_new_token": 106, "500": 106, "return_full_text": 106, "do_sampl": 106, "generated_text": 106, "lm_head": 106, "those": [106, 108, 109, 111], "ti": 106, "autoprocessor": 106, "modeling_util": 106, "find_tied_paramet": 106, "model_id": [106, 112], "untied_model": 106, "getattr": [106, 113], "get_text_config": 106, "tie_word_embed": 106, "setattr": [106, 111], "_tied_weights_kei": 106, "user_id": 106, "your_user_id": 106, "model_nam": [106, 117, 120, 121], "save_to": [106, 112], "save_to_local_path": 106, "int8dynamicactivationintxweightconfig": 106, "ve": [106, 108], "intxweightonlyconfig": 106, "modulefqntoconfig": [106, 113], "untied_model_id": 106, "untied_model_local_path": 106, "embedding_config": 106, "linear_config": 106, "weight_scale_dtyp": 106, "quant_config": 106, "_default": [106, 113], "embed_token": 106, "quant_typ": [106, 112, 113], "include_embed": 106, "untie_embedding_weight": 106, "modules_to_not_convert": 106, "quantized_model": [106, 111, 112, 117, 118, 119], "safe_seri": [106, 112, 113], "pte": 106, "cd": 106, "install_requir": 106, "phi_4_mini": 106, "convert_weight": 106, "pytorch_model": 106, "bin": 106, "pytorch_model_convert": 106, "export_llama": 106, "kv": 106, "use_sdpa_with_kv_cach": 106, "get_bos_id": 106, "199999": 106, "get_eos_id": 106, "200020": 106, "max_seq_length": 106, "max_context_length": 106, "output_nam": 106, "phi4": 106, "phone": 106, "io": 106, "2gb": 106, "iphon": 106, "pro": [106, 108], "17": 106, "sec": 106, "test": [106, 112, 116, 118, 120], "lm": 106, "har": 106, "eleutherai": 106, "lm_eval": 106, "model_arg": 106, "pretrain": [106, 108, 117, 118, 119, 120], "reset_peak_memory_stat": 106, "prompt": [106, 112], "hei": 106, "consciou": 106, "templated_prompt": 106, "apply_chat_templ": 106, "add_generation_prompt": 106, "templat": [106, 107, 114, 115], "return_tensor": 106, "generated_id": 106, "output_text": 106, "batch_decod": 106, "skip_special_token": 106, "clean_up_tokenization_spac": 106, "respons": 106, "mem": [106, 107, 115], "max_memory_reserv": 106, "1e9": 106, "02f": 106, "gb": 106, "hello": [106, 112], "ye": 106, "am": 106, "digit": 106, "todai": 106, "70": [106, 109], "91": 106, "benchmark_lat": 106, "vllm_disable_compile_cach": 106, "project": 106, "vllm_use_precompil": 106, "sharegpt": 106, "wget": 106, "co": 106, "anon8231489123": 106, "sharegpt_vicuna_unfilt": 106, "resolv": 106, "sharegpt_v3_unfiltered_cleaned_split": 106, "tree": 106, "num": 106, "benchmark_serv": 106, "16x": 106, "1s": 106, "14x": 106, "num_prompt": 106, "req": 106, "57": [106, 109], "1000": [106, 120], "68": 106, "80": 106, "entir": [106, 118, 119], "ml": 106, "gain": [106, 108, 121], "eas": 106, "trade": [106, 108], "off": [106, 108], "003": [107, 115, 116], "total": [107, 115, 116], "galleri": [107, 114, 116], "tutorials_sourc": 107, "template_tutori": [107, 115, 116], "neural": [108, 117, 120], "network": [108, 111, 117, 120], "latenc": 108, "carefulli": 108, "pai": 108, "low": [108, 111, 112, 117], "price": 108, "f1": 108, "problem": [108, 111], "research": [108, 116], "fragment": 108, "rightfulli": 108, "spent": 108, "figur": [108, 118], "compress": [108, 117], "place": [108, 117, 118, 119, 120, 121], "dens": 108, "focu": [108, 111], "realli": 108, "concret": [108, 122], "hope": 108, "modular": 108, "nice": 108, "scratch": [108, 116], "minim": [108, 117, 120, 121], "algorthim": 108, "realiz": 108, "theoret": 108, "analog": 108, "fix": [108, 109], "unstructur": 108, "retrain": 108, "neglig": 108, "area": 108, "agre": 108, "upon": 108, "consensu": 108, "mind": 108, "thought": 108, "subproblem": 108, "satisfi": 108, "my": [108, 119], "independ": 108, "frontend": [108, 120], "arbitrari": 108, "handoff": 108, "piec": 108, "natur": [108, 111, 118, 122], "clear": 108, "contract": 108, "7x": 108, "advantag": 108, "anticip": 108, "solut": 108, "third": 108, "parti": 108, "to_sparse_semi_structur": 108, "sparsesemistructuredtensor": 108, "weightnormsparsifi": 108, "half": 108, "subnetwork": 108, "sparse_config": 108, "named_modul": 108, "tensor_fqn": 108, "sparse_block_shap": 108, "zeros_per_block": 108, "fakespars": 108, "fundament": [108, 119], "manipul": 108, "dictionari": 108, "paramer": 108, "parameter": 108, "necessari": [108, 109, 111, 117, 118, 119, 120, 121], "suitabl": [108, 120], "0s": 108, "spot": 108, "definit": [108, 113], "academia": 108, "industri": 108, "often": [108, 111], "interchang": 108, "distinct": 108, "idea": 108, "behind": 108, "doesn": [108, 119, 122], "itself": [108, 111], "loos": 108, "speak": 108, "tightli": 108, "coupl": [108, 111], "csc": 108, "qnnpack": 108, "descript": [108, 117], "coo": 108, "sparse_coo": 108, "coordin": 108, "locat": 108, "bsr": 108, "sparse_bsr": 108, "veri": [108, 113, 119], "except": [108, 111, 122], "scalar": [108, 118], "dimension": 108, "csr": 108, "sparse_csr": 108, "sparse_csc": 108, "column": 108, "compact": 108, "sparse_matrix": 108, "1d": 108, "indexptr": 108, "\u00bd": 108, "bitmask": 108, "2bit": 108, "unprun": 108, "quit": [108, 111], "broken": 108, "down": 108, "sensit": 108, "effect": [108, 109, 111, 120, 121, 122], "best": [108, 120], "subsequ": [108, 111, 120, 121], "infinit": 108, "lost": 108, "degre": 108, "drop": 108, "proxi": 108, "aforement": 108, "smallest": 108, "absolut": 108, "scope": 108, "impli": 108, "con": 108, "span": 108, "threshold": 108, "constant": [108, 111, 118], "ctr_mobile_fe": 108, "score": 108, "w": [108, 113], "tenosr": 108, "udpat": 108, "histori": 108, "regrow": 108, "dw": 108, "via": [108, 117], "backprop": 108, "pat": 108, "unmask": 108, "resid": 108, "salienc": 108, "lowest": 108, "l1": 108, "abl": [108, 111, 113, 118, 122], "repeat": [108, 118, 119], "movement": 108, "2005": 108, "07683": 108, "rank": [108, 111], "wx": 108, "sqx": 108, "q": [108, 118], "usual": 108, "sort": 108, "wise": 108, "reconstruct": [108, 113], "randomli": 108, "tri": 108, "remedi": 108, "sometim": 108, "item": [108, 116], "ultim": [108, 109], "complic": [108, 118], "literatur": 108, "vision": 108, "nlp": [108, 116, 120], "iter": [108, 118, 119], "ctr_feed": 108, "na": 108, "multimask": 108, "pyspeech": 108, "fastna": 108, "approach": [108, 111, 117, 120, 121], "knowledg": [108, 116], "distil": 108, "pdf": 108, "2204": 108, "09656": 108, "arrang": 108, "recal": 108, "counterpart": 108, "slower": 108, "suffici": 108, "At": [108, 118], "98": 108, "exhibit": 108, "penalti": 108, "expens": [108, 111], "dictat": 108, "characterist": 108, "highest": 108, "wouldn": [108, 111], "visual": 108, "fig": 108, "4x4": 108, "benchmak": 108, "fly": [109, 112], "affinequantizedminmaxobserv": 109, "welcom": 109, "averag": [109, 118, 119], "histogram": [109, 118], "act_ob": 109, "finfo": 109, "weight_ob": 109, "observedlinear": 109, "observed_input": 109, "observed_weight": 109, "from_float": [109, 111], "float_linear": 109, "observed_linear": 109, "_replace_with_custom_fn_if_matches_filt": 109, "insert_observers_": 109, "_is_linear": 109, "lambda": [109, 113], "replacement_fn": 109, "copied_act_ob": 109, "copied_weight_ob": 109, "popul": 109, "feed": 109, "simpler": [109, 118], "quantizedlinear": [109, 111], "isn": 109, "strictli": 109, "to_affine_quantized_intx_stat": 109, "act_scal": [109, 122], "act_zero_point": 109, "calculate_qparam": [109, 122], "weight_scal": [109, 118, 122], "weight_zero_point": [109, 118], "qweight": 109, "qinput": 109, "from_observ": 109, "quantized_linear": [109, 118], "begin": [109, 111], "dataclass": [109, 113, 122], "transform_modul": [109, 113], "register_quantize_module_handl": [109, 113], "staticquantconfig": 109, "_apply_static_qu": 109, "is_observed_linear": 109, "optimizedmodul": 109, "_orig_mod": 109, "0237": 109, "142": 109, "31": [109, 122], "113": 109, "157": 109, "59": 109, "160": 109, "150": 109, "67": 109, "241": 109, "238": 109, "235": 109, "228": 109, "255": [109, 122], "201": 109, "114": 109, "236": 109, "88": [109, 118], "83": 109, "109": 109, "209": 109, "92": 109, "184": 109, "141": 109, "110": 109, "0009": 109, "0010": 109, "130": 109, "122": 109, "132": 109, "125": 109, "126": 109, "129": 109, "127": [109, 111, 121, 122], "133": 109, "124": 109, "131": 109, "135": 109, "136": 109, "foundat": 111, "autograd": [111, 122], "interpos": 111, "namespac": 111, "continu": [111, 119, 120, 121, 122], "obviou": 111, "int8quantizedlinear": 111, "finer": 111, "intercept": 111, "contrast": 111, "clunki": 111, "distributedlinear": 111, "duplic": 111, "bypass": 111, "outer": 111, "inner": 111, "allgath": 111, "bandwidth": 111, "exactli": 111, "zoo": 111, "podcast": 111, "edward": 111, "yang": 111, "int8_symmetric_quant": 111, "fp32_tensor": 111, "amin": 111, "keepdim": [111, 118, 119], "amax": 111, "zeros_lik": 111, "view": [111, 118, 119], "clamp": [111, 118], "w_int8": 111, "new_linear": 111, "left": [111, 122], "toymodel": 111, "child": 111, "named_children": 111, "drawback": 111, "won": 111, "suppos": 111, "clean": 111, "eleg": 111, "pretti": 111, "power": [111, 113], "overrid": 111, "almost": 111, "shard": [111, 113], "ragged": 111, "rag": 111, "nestedtensor": 111, "who": 111, "link": [111, 116], "why": [111, 116], "googl": 111, "collab": 111, "flopcount": 111, "memorytrack": 111, "bare": 111, "bone": 111, "int8symmetrictensor": 111, "hold": [111, 112], "staticmethod": 111, "_make_wrapper_subclass": [111, 113], "storage_offset": 111, "ndim": 111, "extra_metadata": 111, "outer_s": [111, 113], "outer_strid": [111, 113], "undo": 111, "repr": 111, "ahead": 111, "insid": 111, "int8_tensor": 111, "op_implementations_dict": 111, "conveni": 111, "register_op": 111, "_op": 111, "opoverload": 111, "impl_decor": 111, "op_impl": 111, "done": 111, "particular": 111, "largest": 111, "tell": 111, "desugar": 111, "surfac": 111, "coverag": [111, 117, 118, 120, 121], "brute": 111, "forc": 111, "repeatedli": 111, "loggingtensor": 111, "_python_dispatch": [111, 113], "return_and_correct_alias": [111, 113], "int8_mm": 111, "int8_view_op": 111, "out_data": 111, "out_scal": [111, 118], "notic": 111, "hit": 111, "background": 111, "decomposit": 111, "live": 111, "decomp": 111, "shrink": 111, "author": [111, 116, 117, 118, 119, 120, 121, 122], "But": [111, 113, 122], "pain": 111, "rather": 111, "worth": 111, "written": 111, "differenti": 111, "nuanc": 111, "longer": [111, 118, 119], "That": 111, "transposit": 111, "got": [111, 118, 122], "propag": [111, 118, 120, 121], "fact": 111, "themselv": [111, 118], "pointwis": [111, 120, 121], "were": 111, "might": [111, 113, 118, 122], "unwrap": 111, "dim0": 111, "dim1": 111, "confirm": 111, "quantized_model_module_swap": 111, "quantized_model_subclass": 111, "subclass_param": 111, "out_module_swap": 111, "allclos": 111, "out_compil": 111, "seri": 111, "discuss": 111, "float8dynamicactivationint4weightconfig": 112, "torch_dtyp": 112, "fluxpipelin": 112, "fluxtransformer2dmodel": 112, "black": 112, "forest": 112, "lab": 112, "flux": 112, "dev": 112, "subfold": 112, "cat": [112, 122], "sign": [112, 121], "world": [112, 113], "num_inference_step": 112, "guidance_scal": 112, "png": 112, "temporarydirectori": 112, "tmp_dir": 112, "uncom": 112, "usernam": [112, 113], "statu": [112, 113], "due": [112, 113, 117, 122], "int4wo": 112, "workaround": [112, 113], "team": [112, 113], "retain": 112, "thoroughli": 112, "e2": 113, "_type": 113, "_data": 113, "capabl": [113, 118, 120], "self_attn": 113, "q_proj": 113, "k_proj": 113, "mlp": 113, "gate_proj": 113, "narrow": 113, "chunk": 113, "heavi": 113, "codebas": 113, "fn": 113, "ctx": 113, "new_tensor": 113, "__class__": 113, "principl": 113, "mynewquantconfig": 113, "classvar": 113, "myquantizedtensor": 113, "tensor_data_attr": 113, "tensor_attribut": 113, "attr": 113, "fill_default": 113, "notimplementederror": 113, "_my_quant_transform": 113, "my_quantization_funct": 113, "use_cutlass_kernel": 113, "my_cutlass_linear": 113, "use_triton_kernel": 113, "my_triton_linear": 113, "disappear": 113, "extrem": 113, "sole": 113, "explicitli": [113, 122], "spooki": 113, "distanc": 113, "2338": 113, "detect": 113, "illustr": 113, "tutorials_python": 114, "zip": [114, 116], "jupyt": [114, 116], "notebook": [114, 116], "tutorials_jupyt": 114, "sphinx": [114, 116], "firstnam": 116, "lastnam": 116, "prerequisit": [116, 118], "topic": 116, "rand": [116, 118, 119], "7304": 116, "7048": 116, "3449": 116, "5058": 116, "7886": 116, "3363": 116, "2489": 116, "7424": 116, "5033": 116, "1698": 116, "7466": 116, "5824": 116, "1966": 116, "9786": 116, "3206": 116, "practic": 116, "summar": 116, "takeawai": 116, "link1": 116, "link2": 116, "minut": 116, "ipynb": 116, "daniil": 117, "lyakhov": 117, "aamir": 117, "nazir": 117, "alexand": 117, "suslov": 117, "yamini": 117, "nimmagadda": 117, "kozlov": 117, "subject": [117, 119], "openvinoquant": 117, "unlock": 117, "placement": 117, "ux": [117, 118, 120], "torchdynamo": [117, 120, 121, 122], "eager": [117, 118, 119, 120, 121, 122], "mechan": [117, 120, 121], "torchvis": [117, 118, 119, 120, 121, 122], "resnet18": [117, 118, 119, 120, 121], "u": 117, "__dict__": [117, 118, 119, 120, 121], "dummi": [117, 120, 121], "traced_b": [117, 120, 121], "exported_model": [117, 118, 119, 120, 121], "preset": 117, "elu": 117, "prelu": 117, "gelu": 117, "quantizationpreset": 117, "bert": [117, 120], "modeltyp": 117, "ignored_scop": 117, "exclud": 117, "layer_1": 117, "layer_2": 117, "layer_3": 117, "ignoredscop": 117, "conv2d": [117, 118, 119, 120, 121, 122], "regex": 117, "layer_": 117, "subgraph": [117, 119], "node": [117, 119, 120, 121, 122], "target_devic": 117, "taken": 117, "account": 117, "cpu_spr": 117, "npu": 117, "targetdevic": 117, "fold": [117, 118, 120, 121], "batchnorm": [117, 118, 119, 120, 121], "preced": [117, 118, 120, 121], "prepared_model": [117, 118, 119, 120, 121], "fold_quant": 117, "finish": [117, 120], "comparison": 117, "biascorrect": 117, "discrep": 117, "calibration_load": 117, "dataload": [117, 118, 119], "transform_fn": 117, "data_item": 117, "calibration_dataset": 117, "smooth_quant": 117, "fast_bias_correct": 117, "deploy": [117, 120], "jerri": [118, 120, 122], "zhang": [118, 120, 121, 122], "_export": [118, 119], "fx": [118, 122], "14k": 118, "programm": [118, 120, 121], "db": 118, "xnnpack": [118, 119, 122], "xnnpack_quant": [118, 119], "get_symmetric_quantization_config": [118, 119], "xnnpackquant": [118, 119, 122], "prior": 118, "qconfigmap": [118, 122], "backendconfig": [118, 122], "rel": 118, "intent": [118, 122], "qconfig": [118, 122], "3d": [118, 122], "incompat": 118, "great": 118, "ideal": 118, "fake_qu": 118, "hidden": 118, "summari": 118, "address": 118, "thu": 118, "queri": [118, 122], "becom": 118, "previous": 118, "embedding_byt": 118, "executorchquant": 118, "concaten": 118, "prone": 118, "cleaner": 118, "composed_quant": 118, "quantization_cap": 118, "concern": 118, "decoupl": 118, "minmax": 118, "freed": 118, "identitc": 118, "imagenet": [118, 119], "unzip": [118, 119], "data_path": [118, 119], "resnet18_pretrained_float": [118, 119], "sy": [118, 119], "numpi": [118, 119], "np": [118, 119], "resnet": [118, 119, 120], "warn": [118, 119], "filterwarn": [118, 119], "categori": [118, 119], "deprecationwarn": [118, 119], "r": [118, 119], "seed": [118, 119], "191009": [118, 119], "averagemet": [118, 119], "fmt": [118, 119], "val": [118, 119], "avg": [118, 119], "count": [118, 119], "__str__": [118, 119], "fmtstr": [118, 119], "topk": [118, 119], "predict": [118, 119], "maxk": [118, 119], "pred": [118, 119], "eq": [118, 119], "expand_a": [118, 119], "correct_k": [118, 119], "mul_": [118, 119], "criterion": [118, 119], "top1": [118, 119], "top5": [118, 119], "cnt": [118, 119], "acc1": [118, 119], "acc5": [118, 119], "load_model": [118, 119], "model_fil": [118, 119], "weights_onli": [118, 119], "print_size_of_model": [118, 119], "temp": [118, 119], "p": [118, 119], "1e6": [118, 119], "prepare_data_load": [118, 119], "485": [118, 119], "456": [118, 119], "std": [118, 119], "229": [118, 119], "225": [118, 119], "randomresizedcrop": [118, 119], "randomhorizontalflip": [118, 119], "totensor": [118, 119], "dataset_test": [118, 119], "resiz": [118, 119], "centercrop": [118, 119], "train_sampl": [118, 119], "randomsampl": [118, 119], "test_sampl": [118, 119], "sequentialsampl": [118, 119], "train_batch_s": [118, 119], "sampler": [118, 119], "data_loader_test": [118, 119, 120, 121], "eval_batch_s": [118, 119], "saved_model_dir": [118, 119], "float_model_fil": [118, 119], "model_to_quant": [118, 119], "capture_pre_autograd_graph": [118, 119], "dynamic_shap": [118, 119], "dynamic_dim": [118, 119], "constraint": [118, 119, 122], "qconfig_opt": 118, "set_object_typ": 118, "set_module_nam": 118, "workload": 118, "themodel": 118, "feedback": 118, "dq": 118, "fp32_op": 118, "qauntiz": 118, "x_int8": 118, "x_zero_point": 118, "weight_int8": 118, "bias_fp32": 118, "output_scal": 118, "output_zero_point": 118, "x_fp32": 118, "quantized_decompos": 118, "dequantize_per_tensor": 118, "x_i8": 118, "x_quant_min": 118, "x_quant_max": 118, "weight_fp32": 118, "weight_i8": 118, "weight_quant_min": 118, "weight_quant_max": 118, "weight_permut": 118, "permute_copi": 118, "out_fp32": 118, "addmm": 118, "out_i8": 118, "quantize_per_tensor": 118, "out_zero_point": 118, "out_quant_min": 118, "out_quant_max": 118, "float32_op": 118, "decompos": 118, "use_reference_represent": 118, "x_int16": 118, "weight_int16": 118, "acc_int32": 118, "out_dtyp": 118, "bias_scal": 118, "bias_int32": 118, "div": 118, "mul": 118, "out_int8": 118, "qmin": 118, "qmax": 118, "date": 118, "unus": 118, "serila": 118, "consult": 118, "exportedprogram": 118, "pt2e_quantized_model_file_path": 118, "resnet18_pt2e_quant": 118, "quantized_ep": 118, "loaded_quantized_ep": 118, "loaded_quantized_model": 118, "diff": 118, "79": 118, "82": 118, "55": 118, "edg": [118, 122], "went": 118, "andrew": 119, "Or": 119, "move_exported_model_to_ev": [119, 120], "correctli": 119, "certain": 119, "dropout": 119, "move_exported_model_to_train": 119, "jit": 119, "recursivescriptmodul": 119, "train_one_epoch": 119, "ntrain_batch": 119, "avgloss": 119, "5f": 119, "start_tim": 119, "global_avg": 119, "is_qat": [119, 120], "fusion": 119, "batchnorm2d": 119, "_native_batch_norm_legit": 119, "cudnn_batch_norm": 119, "mobilenetv2": 119, "recompil": 119, "consolid": 119, "epoch": 119, "far": 119, "num_epoch": 119, "num_train_batch": 119, "num_eval_batch": 119, "num_observer_update_epoch": 119, "num_batch_norm_update_epoch": 119, "num_epochs_between_ev": 119, "nepoch": 119, "stat": 119, "subseq": 119, "disable_observ": 119, "bn": 119, "running_mean": 119, "running_var": 119, "new_arg": 119, "wish": 119, "prepared_model_copi": 119, "neval_batch": 119, "paus": 119, "resum": 119, "fail": [119, 122], "checkpoint_path": 119, "checkpoint_": 119, "behav": 119, "incorrectli": 119, "lesli": [120, 122], "fang": [120, 122], "weiwen": [120, 122], "xia": [120, 122], "jiong": [120, 122], "gong": [120, 122], "cnn": 120, "rnn": 120, "outstand": 120, "fourth": 120, "spr": 120, "xeon": 120, "processor": 120, "boost": 120, "channels_last": [120, 121], "onednn": [120, 121], "assum": [120, 122], "word": 120, "satur": 120, "pure": 120, "dedic": 120, "scenario": [120, 121], "plai": [120, 121], "convolut": [120, 121, 122], "absenc": [120, 121], "enhanc": [120, 121], "mirror": [120, 121], "autocast": [120, 121], "device_typ": [120, 121], "turn": [120, 121], "cpp": 120, "qconvolut": [120, 121], "qlinear": [120, 121], "presenc": [120, 121], "pair": [120, 121], "remain": [120, 121], "conting": [120, 121], "qmaxpool2d": [120, 121], "torchinductor_freez": [120, 121], "example_x86inductorquantizer_pytorch_2_1": 120, "torchbench": 120, "measur": 120, "proven": 120, "depth": 120, "example_x86inductorquantizer_qat": 120, "yan": 121, "zhiwei": 121, "wang": 121, "eikan": 121, "liangang": 121, "liu": 121, "river": 121, "cui": 121, "yifeng": 121, "xpuinductorquant": 121, "pip3": 121, "torchaudio": 121, "xpu_inductor_quantizer_exampl": 121, "xpu_inductor_quant": 121, "xpuiq": 121, "resnet18_weight": 121, "get_default_xpu_inductor_quantization_config": 121, "wherea": 121, "histogramobserv": [121, 122], "perchannelminmaxobserv": 121, "quantizationspec": [121, 122], "quantizationconfig": [121, 122], "type_check": 121, "observerorfakequantizeconstructor": 121, "get_xpu_inductor_symm_quantization_config": 121, "extra_arg": 121, "act_observer_or_fake_quant_ctr": 121, "act_quantization_spec": [121, 122], "qscheme": [121, 122], "per_tensor_symmetr": [121, 122], "observer_or_fake_quant_ctr": [121, 122], "with_arg": [121, 122], "weight_observer_or_fake_quant_ctr": 121, "weight_quantization_spec": [121, 122], "per_channel_symmetr": 121, "ch_axi": 121, "oc": 121, "ic": 121, "kh": 121, "kw": 121, "conv": [121, 122], "bias_quantization_spec": 121, "amp": 121, "indcutor": 121, "kimish": 122, "patel": 122, "made": 122, "explicit": 122, "quantiat": 122, "encod": 122, "convei": 122, "quantizationannot": 122, "furthermor": 122, "minmaxobserv": 122, "input_qspec_map": 122, "output_qspec": 122, "_annot": 122, "conclud": 122, "matcher": 122, "get_source_partit": 122, "add_partit": 122, "gm": 122, "itertool": 122, "chain": 122, "add_nod": 122, "output_nod": 122, "per_tensor_affin": 122, "input_act_qspec": 122, "output_act_qspec": 122, "input_act0": 122, "input_act1": 122, "quantization_annot": 122, "substitut": 122, "among": 122, "sharedquantizationspec": 122, "maxpool": 122, "average_pool": 122, "concat": 122, "edgeornod": 122, "transit": 122, "spec": 122, "conv1": 122, "conv2": 122, "fed": 122, "conv1_out": 122, "conv2_out": 122, "qspec1": 122, "cat_input0": 122, "cat_input1": 122, "therefor": 122, "ob": 122, "consum": 122, "rewrit": 122, "share_qparams_with_input_act0_qspec": 122, "known": 122, "beforehand": 122, "sigmoid": 122, "fixedqparamsquantizationspec": 122, "act_qspec": 122, "sigmoid_nod": 122, "input_act": 122, "derivedquantizationspec": 122, "derive_qparams_fn": 122, "observerorfakequant": 122, "observerbas": 122, "fakequantizebas": 122, "heurist": 122, "obejct": 122, "obs_or_fq": 122, "fq": 122, "act_obs_or_fq": 122, "weight_obs_or_fq": 122, "act_zp": 122, "weight_zp": 122, "bias_qspec": 122, "derived_from": 122, "backendquant": 122, "get_input_act_qspec": 122, "get_output_act_qspec": 122, "get_weight_qspec": 122, "get_bias_qspec": 122, "intermedi": 122, "straightforward": 122, "call_funct": 122, "relu_": 122, "relu_nod": 122, "maybe_conv_nod": 122, "conv1d": 122, "unexpect": 122, "recognz": 122, "subgraphmatch": 122, "conv_relu_pattern": 122, "name_node_map": 122, "input_nod": 122, "weight_nod": 122, "bias_nod": 122, "caveat": 122, "exhaust": 122, "2d": 122, "4d": 122, "symbol": 122, "outcom": 122}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "BlockSparseLayout"], [15, 0, 1, "", "CutlassInt4PackedLayout"], [16, 0, 1, "", "CutlassSemiSparseLayout"], [17, 0, 1, "", "Float8Layout"], [18, 0, 1, "", "Int4CPULayout"], [19, 0, 1, "", "Layout"], [20, 0, 1, "", "MarlinQQQLayout"], [21, 0, 1, "", "MarlinQQQTensor"], [22, 0, 1, "", "MarlinSparseLayout"], [23, 0, 1, "", "NF4Tensor"], [24, 0, 1, "", "PlainLayout"], [25, 0, 1, "", "SemiSparseLayout"], [26, 0, 1, "", "TensorCoreTiledLayout"], [27, 0, 1, "", "UintxLayout"], [28, 2, 1, "", "to_affine_quantized_floatx"], [29, 2, 1, "", "to_affine_quantized_floatx_static"], [30, 2, 1, "", "to_affine_quantized_fpx"], [31, 2, 1, "", "to_affine_quantized_intx"], [32, 2, 1, "", "to_affine_quantized_intx_static"], [33, 2, 1, "", "to_marlinqqq_quantized_intx"], [34, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[21, 1, 1, "", "dequantize"], [21, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[22, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[23, 1, 1, "", "convert_to_norm_float_weight"], [23, 1, 1, "", "dequantize"], [23, 1, 1, "", "dequantize_scalers"], [23, 1, 1, "", "double_quantize_scalers"], [23, 1, 1, "", "get_original_weight"], [23, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[35, 0, 1, "", "CastConfig"], [36, 0, 1, "", "Float8LinearConfig"], [37, 0, 1, "", "ScalingGranularity"], [38, 0, 1, "", "ScalingType"], [39, 2, 1, "", "convert_to_float8_training"], [40, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[36, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[41, 0, 1, "", "FPXWeightOnlyConfig"], [42, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [43, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [44, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [45, 0, 1, "", "Float8WeightOnlyConfig"], [46, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [47, 0, 1, "", "Int4WeightOnlyConfig"], [48, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [49, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [50, 0, 1, "", "Int8WeightOnlyConfig"], [51, 0, 1, "", "MappingType"], [52, 0, 1, "", "TorchAODType"], [53, 0, 1, "", "UIntXWeightOnlyConfig"], [54, 0, 1, "", "ZeroPointDomain"], [55, 2, 1, "", "autoquant"], [56, 2, 1, "", "choose_qparams_affine"], [57, 2, 1, "", "choose_qparams_affine_with_min_max"], [58, 2, 1, "", "dequantize_affine"], [59, 2, 1, "", "int_scaled_matmul"], [84, 2, 1, "", "quantize_"], [89, 2, 1, "", "quantize_affine"], [90, 2, 1, "", "safe_int_mm"], [91, 2, 1, "", "smooth_fq_linear_to_inference"], [92, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [93, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[60, 0, 1, "", "ComposableQATQuantizer"], [61, 0, 1, "", "FakeQuantizeConfigBase"], [62, 0, 1, "", "FakeQuantizedEmbedding"], [63, 0, 1, "", "FakeQuantizedLinear"], [64, 0, 1, "", "FakeQuantizerBase"], [65, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [66, 0, 1, "", "Float8FakeQuantizeConfig"], [67, 0, 1, "", "Float8FakeQuantizer"], [68, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [69, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [70, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [71, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [72, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [73, 0, 1, "", "IntxFakeQuantizeConfig"], [74, 0, 1, "", "IntxFakeQuantizer"], [75, 0, 1, "", "QATConfig"], [76, 0, 1, "", "QATStep"], [79, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[62, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[63, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[65, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[67, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[69, 1, 1, "", "convert"], [69, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[73, 3, 1, "", "group_size"], [73, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[74, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[77, 0, 1, "", "Int4WeightOnlyEmbedding"], [78, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[77, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[80, 0, 1, "", "Int4WeightOnlyQATLinear"], [81, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [82, 2, 1, "", "disable_linear_fake_quant"], [83, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[85, 0, 1, "", "KernelPreference"], [86, 0, 1, "", "PackingFormat"], [87, 0, 1, "", "QuantizeTensorKwargs"], [88, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[85, 4, 1, "", "AUTO"], [85, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[86, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[94, 0, 1, "", "PerChannelNormObserver"], [95, 0, 1, "", "WandaSparsifier"], [96, 2, 1, "", "apply_fake_sparsity"], [97, 4, 1, "", "semi_sparse_weight"], [98, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[94, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[95, 1, 1, "", "prepare"], [95, 1, 1, "", "squash_mask"], [95, 1, 1, "", "update_mask"]], "torchao.utils": [[99, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[99, 1, 1, "", "get_tensor_impl_constructor"], [99, 1, 1, "", "implements"], [99, 1, 1, "", "implements_torch_function"], [99, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 100, 102, 103, 113], "dtype": [0, 11, 103], "layout": [0, 19], "tensor": [0, 7, 10, 103, 110, 111, 113, 122], "subclass": [0, 7, 10, 103, 111, 113], "quantiz": [0, 4, 5, 7, 12, 84, 100, 103, 104, 106, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122], "techniqu": 0, "float8": [1, 12, 102, 103], "main": [1, 4, 5], "train": [1, 12, 102, 103, 106, 117, 118, 119, 120, 121], "api": [1, 2, 4, 5, 7, 8, 12, 100, 102, 122], "other": [1, 5, 10, 103], "type": [1, 112], "refer": [2, 100], "python": 2, "kernel": [3, 10, 101, 103, 113], "qat": [4, 12, 119], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "prototyp": 4, "infer": [5, 106], "primit": [5, 103], "sparsiti": [6, 108], "util": 7, "common": [7, 8, 122], "benchmark": [8, 9, 10, 106], "guid": [8, 9, 10, 104, 113], "add": [8, 113], "an": [8, 105], "recip": [8, 102], "model": [8, 10, 102, 103, 105, 106, 112, 113, 117, 118, 119], "design": [8, 108], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 102, 106, 112, 113, 117, 120, 121, 122], "modifi": 8, "exist": 8, "configur": [8, 108, 113, 118, 119], "2": [8, 12, 104, 106, 112, 113, 117, 118, 119, 120, 121, 122], "run": 8, "3": [8, 12, 106, 113, 117, 120, 121, 122], "output": [8, 111], "format": [8, 103], "4": [8, 117, 122], "integr": [8, 12, 112, 113], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 113], "new": [10, 113], "effici": [10, 103], "triton": 10, "hand": 10, "written": 10, "us": [10, 122], "kernelprefer": [10, 85], "flow": [10, 103, 105, 113, 122], "torch": [10, 117, 118, 119], "compil": [10, 113, 117], "perform": [10, 101, 106, 118], "serial": [10, 105, 113], "featur": 10, "support": [10, 112, 113], "function": [10, 118, 119], "compos": 10, "microbenchmark": 10, "eval": [10, 118], "part": [12, 102, 106], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 103, 119, 120], "option": [12, 106, 116, 117], "torchtun": 12, "axolotl": 12, "low": [12, 103], "rank": 12, "adapt": 12, "huggingfac": [12, 106, 113], "peft": 12, "affinequantizedtensor": 13, "blocksparselayout": 14, "cutlassint4packedlayout": 15, "cutlasssemisparselayout": 16, "float8layout": 17, "int4cpulayout": 18, "marlinqqqlayout": 20, "marlinqqqtensor": 21, "marlinsparselayout": 22, "nf4tensor": 23, "plainlayout": 24, "semisparselayout": 25, "tensorcoretiledlayout": 26, "uintxlayout": 27, "to_affine_quantized_floatx": 28, "to_affine_quantized_floatx_stat": 29, "to_affine_quantized_fpx": 30, "to_affine_quantized_intx": 31, "to_affine_quantized_intx_stat": 32, "to_marlinqqq_quantized_intx": 33, "to_nf4": 34, "castconfig": 35, "float8linearconfig": 36, "scalinggranular": 37, "scalingtyp": 38, "convert_to_float8_train": 39, "precompute_float8_dynamic_scale_for_fsdp": 40, "fpxweightonlyconfig": 41, "float8dynamicactivationfloat8weightconfig": 42, "float8dynamicactivationint4weightconfig": 43, "float8staticactivationfloat8weightconfig": 44, "float8weightonlyconfig": 45, "gemliteuintxweightonlyconfig": 46, "int4weightonlyconfig": 47, "int8dynamicactivationint4weightconfig": 48, "int8dynamicactivationint8weightconfig": 49, "int8weightonlyconfig": 50, "mappingtyp": 51, "torchaodtyp": 52, "uintxweightonlyconfig": 53, "zeropointdomain": 54, "autoqu": 55, "choose_qparams_affin": 56, "choose_qparams_affine_with_min_max": 57, "dequantize_affin": 58, "int_scaled_matmul": 59, "composableqatquant": 60, "fakequantizeconfigbas": 61, "fakequantizedembed": 62, "fakequantizedlinear": 63, "fakequantizerbas": 64, "float8actint4weightqatquant": 65, "float8fakequantizeconfig": 66, "float8fakequant": 67, "fromintxquantizationawaretrainingconfig": 68, "int4weightonlyembeddingqatquant": 69, "int4weightonlyqatquant": 70, "int8dynactint4weightqatquant": 71, "intxquantizationawaretrainingconfig": 72, "intxfakequantizeconfig": 73, "intxfakequant": 74, "qatconfig": 75, "qatstep": 76, "int4weightonlyembed": 77, "int4weightonlyqatembed": 78, "initialize_fake_quant": 79, "int4weightonlyqatlinear": 80, "int8dynactint4weightqatlinear": 81, "disable_linear_fake_qu": 82, "enable_linear_fake_qu": 83, "packingformat": 86, "quantizetensorkwarg": 87, "_choose_quant_func_and_quantize_tensor": 88, "quantize_affin": 89, "safe_int_mm": 90, "smooth_fq_linear_to_infer": 91, "swap_linear_with_smooth_fq_linear": 92, "to_linear_activation_quant": 93, "perchannelnormobserv": 94, "wandasparsifi": 95, "apply_fake_spars": 96, "semi_sparse_weight": 97, "sparsifi": 98, "torchaobasetensor": 99, "welcom": 100, "document": 100, "get": 100, "start": [100, 104, 112], "develop": 100, "note": [100, 102, 122], "eager": 100, "tutori": [100, 116], "pt2e": [100, 122], "pre": 102, "torchtitan": 102, "prerequisit": [102, 117, 120, 121, 122], "rowwis": 102, "scale": 102, "tensorwis": 102, "pick": 102, "import": [102, 118, 119], "directli": [102, 122], "convers": 102, "overview": [103, 108, 116], "basic": 103, "op": 103, "deriv": [103, 122], "pack": 103, "algorithm": 103, "weight": [103, 106], "onli": 103, "dynam": 103, "activ": 103, "static": [103, 109], "bit": 103, "optim": [103, 105, 106], "case": 103, "studi": 103, "how": [103, 118, 119, 122], "work": 103, "dure": 103, "execut": 103, "save": [103, 112, 118, 119], "load": [103, 118, 119], "quick": [104, 112], "first": 104, "exampl": [104, 112, 113, 122], "pytorch": [104, 117, 118, 119, 120, 121, 122], "export": [104, 106, 117, 118, 119, 120, 121, 122], "next": [104, 111], "step": [104, 106, 111, 113, 116], "deseri": 105, "what": [105, 111], "happen": 105, "when": 105, "serv": [106, 113], "vllm": [106, 113], "sglang": 106, "executorch": 106, "post": [106, 117, 118, 120, 121], "transform": [106, 112, 113], "mobil": 106, "deploy": 106, "unti": 106, "embed": 106, "creat": [106, 113], "characterist": 106, "evalu": [106, 118], "qualiti": 106, "assess": 106, "memori": 106, "latenc": 106, "result": 106, "h100": 106, "machin": 106, "conclus": [106, 116, 117, 118, 119, 120, 121, 122], "comput": [107, 115], "time": [107, 115], "goal": 108, "context": 108, "prune": 108, "criteria": 108, "strategi": 108, "pattern": [108, 122], "calibr": [109, 118], "phase": 109, "write": [110, 111, 122], "your": [110, 111, 113], "own": [110, 111], "advanc": 110, "ar": 111, "modul": [111, 113], "swap": 111, "which": 111, "oper": [111, 113, 122], "should": 111, "we": 111, "implement": [111, 113], "compar": 111, "hug": 112, "face": 112, "usag": [112, 113], "diffus": 112, "architectur": 113, "system": 113, "class": 113, "level": 113, "method": 113, "minim": 113, "requir": 113, "compat": 113, "why": 113, "regist": 113, "s": 113, "kei": 113, "detail": 113, "hardwar": 113, "specif": [113, 118, 119], "linear": 113, "benefit": 113, "trade": 113, "off": 113, "share": [113, 122], "safetensor": 113, "diagram": 113, "high": 113, "point": 113, "dispatch": 113, "bring": 113, "extern": 113, "templat": 116, "addit": 116, "exercis": 116, "further": 116, "read": 116, "openvino": 117, "backend": [117, 118, 119, 120, 121], "introduct": [117, 120, 121, 122], "nncf": 117, "instal": 117, "captur": [117, 120, 121], "fx": [117, 120, 121], "graph": [117, 120, 121], "appli": [117, 120, 121], "lower": [117, 118, 120, 121], "represent": 117, "improv": 117, "metric": 117, "motiv": [118, 122], "defin": [118, 119], "helper": [118, 119], "prepar": [118, 119], "dataset": [118, 119], "set": 118, "mode": 118, "convert": [118, 119], "check": 118, "size": 118, "accuraci": 118, "debug": 118, "loop": 119, "checkpoint": 119, "x86": 120, "through": [120, 121], "inductor": [120, 121], "intel": 121, "gpu": 121, "annot": 122, "param": 122, "fix": 122, "paramet": 122, "5": 122, "A": 122, "toi": 122, "resnet18": 122, "ir": 122, "problem": 122, "match": 122, "aten": 122, "recommend": 122, "subgraphmatcherwithnamenodemap": 122}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})