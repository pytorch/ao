Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfig", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfig", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "initialize_fake_quantizers", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "int8_dynamic_activation_int8_semi_sparse_weight", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Pretraining with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [2, 6, 8, 17, 18, 19, 20, 22, 35, 36, 40, 41, 42, 45, 49, 50, 52, 54, 56, 57, 60, 61, 67, 68, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 90, 91, 94], "section": [2, 6, 83, 87, 91], "introduc": 2, "dive": 2, "detail": [2, 6, 36, 49, 82, 83, 84, 87, 88, 90], "how": [2, 6, 8, 14, 22, 41, 45, 50, 60, 61, 68, 82, 84, 85, 87, 88, 90, 91], "integr": [2, 6, 80, 82, 85, 87, 90], "pytorch": [2, 6, 8, 13, 16, 46, 60, 80, 82, 84, 87, 90, 91, 94], "optim": [2, 6, 17, 35, 49, 53, 67, 80, 82, 87, 90], "your": [2, 6, 80, 82, 83, 84, 87], "machin": 2, "learn": [2, 41, 60, 84, 87, 94], "model": [2, 35, 40, 42, 49, 59, 61, 62, 63, 64, 66, 67, 71, 72, 75, 76, 79, 84, 87, 88, 90], "dtype": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 68, 79, 80, 82, 84, 85, 88, 90, 91], "quantiz": [2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 26, 28, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 77, 79, 80, 82, 85, 87], "sparsiti": [2, 11, 17, 20, 74, 75, 76, 77, 78, 79, 80, 83, 85], "tba": [3, 7, 81], "For": [6, 8, 36, 60, 83, 84, 85, 87, 88, 90, 91], "new": [6, 8, 82, 83, 88, 90], "case": [6, 49, 70, 87, 90, 91], "exampl": [6, 8, 35, 45, 49, 59, 60, 61, 66, 67, 75, 79, 83, 85, 86, 87, 88, 90, 92, 93, 94], "train": [6, 31, 56, 57, 59, 60, 80, 82, 87, 90], "like": [6, 14, 49, 82, 83, 84, 85, 87, 90, 91], "fp4": 6, "s": [6, 8, 45, 49, 50, 54, 56, 68, 69, 82, 83, 84, 87, 88, 90], "fine": [6, 40, 41, 42, 47, 87], "start": [6, 32, 33, 45, 46, 48, 49, 82, 83, 87, 88, 90, 91], "prototyp": [6, 60, 66, 83], "folder": 6, "you": [6, 60, 75, 82, 83, 84, 85, 87, 90, 91, 94], "could": [6, 83, 90], "also": [6, 49, 60, 67, 83, 84, 85, 87, 88, 90, 91], "take": [6, 18, 67, 74, 79, 83, 87], "look": [6, 8, 82, 83, 87], "affinequantizedtensor": [6, 16, 24, 25, 27, 83, 84, 85, 88, 90], "what": [6, 8, 16, 49, 82, 83, 84, 87, 88, 91, 94], "want": [6, 67, 79, 83, 85, 87, 90, 91], "do": [6, 46, 49, 58, 67, 83, 87, 88, 90, 91], "mostli": [6, 52], "e": [6, 8, 36, 45, 49, 50, 54, 56, 59, 60, 67, 68, 69, 82, 83, 85, 88, 90], "g": [6, 8, 36, 45, 49, 50, 54, 56, 59, 60, 67, 68, 83, 85, 88, 90], "int3": 6, "exact": 6, "same": [6, 8, 37, 50, 52, 54, 56, 57, 68, 70, 79, 82, 83, 87, 88, 90], "affin": [6, 8, 10, 11, 12, 13, 17, 20, 21, 26, 54, 56, 68, 83], "pleas": [6, 8, 16, 36, 41, 80, 83, 87, 88, 90, 91], "feel": [6, 83, 87, 90, 91], "free": [6, 83, 90], "open": [6, 83, 87], "an": [6, 8, 21, 26, 27, 49, 57, 60, 75, 80, 83, 87, 88, 90], "issu": [6, 83, 84, 90], "have": [6, 40, 41, 45, 49, 62, 63, 64, 68, 75, 83, 87, 88, 90, 91], "question": [6, 83, 85, 87, 90], "specif": [6, 14, 17, 19, 20, 75, 83, 84, 85, 87], "more": [6, 8, 36, 40, 41, 42, 47, 49, 57, 82, 83, 84, 87, 88, 90, 91], "refer": [6, 8, 82, 87, 88, 90, 91], "our": [6, 18, 82, 84, 87, 88, 90], "overview": [6, 80, 84, 91], "page": [6, 84], "To": [6, 8, 16, 49, 82, 83, 84, 85, 87, 88, 91], "contribut": [6, 84, 87], "exist": [6, 46, 82, 83, 87, 88, 90], "code": [6, 41, 82, 83, 84, 87, 88, 90, 92, 94], "base": [6, 14, 19, 45, 66, 75, 83, 84, 87, 90, 91], "make": [6, 83, 90, 91], "trainabl": [6, 83, 90], "add": [6, 19, 90, 94], "parallel": [6, 82, 90, 91], "etc": [6, 83], "affine_quantized_tensor": [6, 85], "py": [6, 8, 16, 86, 93, 94], "api": [6, 49, 65, 83, 84, 87, 88, 90], "quant_api": [6, 67, 85, 88], "primit": [6, 8, 16, 90], "op": [6, 8, 16, 41, 49, 56, 57, 67, 87, 90, 91], "slight": [6, 87], "variat": [6, 83], "quant_primit": [6, 8, 16, 88], "autotun": [6, 84, 88], "cpu": [6, 8, 13, 85, 87, 88, 91], "cuda": [6, 8, 53, 67, 82, 84, 85, 87, 88, 90], "mp": 6, "csrc": 6, "mayb": [6, 30], "well": [6, 14, 49, 83, 87], "spars": [6, 9, 17, 20, 75, 83, 87], "marlin": [6, 15, 16, 17, 28], "aqt": 6, "621": 6, "we": [6, 8, 18, 45, 47, 49, 50, 52, 54, 56, 60, 67, 68, 79, 82, 83, 84, 85, 87, 88, 91], "ar": [6, 8, 12, 20, 22, 34, 36, 37, 40, 41, 49, 50, 54, 56, 59, 67, 68, 70, 75, 82, 83, 84, 85, 87, 88, 91], "still": [6, 83, 87], "decid": [6, 83, 87, 88], "split": 6, "can": [6, 21, 37, 40, 45, 49, 59, 60, 67, 68, 82, 83, 84, 85, 87, 88, 90, 91], "implement": [6, 31, 85, 87, 88], "regist": [6, 74, 90], "mai": [6, 52, 60, 83, 85, 88], "need": [6, 37, 74, 75, 83, 84, 85, 87, 90, 91], "defin": [6, 14, 22, 32, 36, 74, 75, 87, 88, 90, 91], "own": [6, 80, 82, 87, 88], "through": [6, 52, 83, 84, 88, 90, 91, 94], "int4": [6, 10, 13, 42, 45, 60, 62, 63, 64, 67, 79, 84, 85, 91], "access": 6, "my_custom_op": 6, "devic": [6, 8, 53, 67, 70, 82, 84, 85, 88, 90, 91], "check": [6, 8, 16, 83, 84, 85, 90], "condit": [6, 83], "__torch_function__": [6, 83, 90], "__torch_dispatch__": [6, 90], "target": [6, 37, 38, 39, 41, 50, 75, 87], "oper": [6, 8, 12, 14, 17, 52], "bfloat16": [6, 18, 56, 63, 68, 82, 83, 84, 85, 87, 88, 91], "activ": [6, 37, 38, 40, 42, 43, 49, 60, 64, 71, 75, 77, 80, 87, 88, 91], "uint4": [6, 41, 83, 84], "weight": [6, 17, 18, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 60, 62, 63, 64, 67, 75, 77, 79, 80, 82, 84, 85, 87, 88, 90, 91], "found": [6, 83, 84, 87, 88, 90], "here": [6, 8, 68, 83, 85, 88, 90, 91], "allow": [6, 87, 90], "peopl": [6, 83, 85, 91], "linear": [6, 17, 31, 34, 37, 39, 41, 42, 43, 44, 47, 49, 59, 63, 64, 67, 72, 76, 77, 79, 82, 83, 84, 85, 87, 88, 90], "two": [6, 16, 20, 37, 83, 87, 90], "dispatch_condit": [6, 83], "impl": [6, 8, 83], "actual": [6, 39, 83, 88, 90, 91], "bia": [6, 83, 84, 85, 88, 90, 91], "run": [6, 35, 49, 67, 71, 74, 82, 83, 87, 90, 94], "both": [6, 8, 37, 83, 87, 88, 90], "input_tensor": [6, 18, 83, 91], "weight_tensor": [6, 83, 91], "argument": [6, 8, 21, 49, 54, 67, 82, 83], "register_aqt_quantized_linear_dispatch": 6, "show": [6, 68, 82, 83, 87, 91], "work": [6, 20, 40, 82, 85, 87, 90, 91], "sometim": [6, 87], "ha": [6, 8, 83, 87, 90, 91], "pack": [6, 8, 10, 21, 22, 36, 40, 47, 83], "order": [6, 49, 59, 83, 87, 90], "yield": [6, 87], "And": [6, 18, 37, 83, 90], "abstract": [6, 83], "see": [6, 8, 16, 36, 82, 83, 84, 85, 87, 88, 90, 91], "full": [6, 88, 94], "after": [6, 35, 49, 83, 85, 87], "wrap": [6, 49, 90], "factori": 6, "convert": [6, 8, 16, 18, 23, 26, 28, 29, 31, 59, 61, 62, 67, 69, 79, 82, 83, 87], "from": [6, 8, 18, 19, 24, 25, 27, 36, 42, 52, 56, 61, 67, 68, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94], "float": [6, 8, 16, 18, 26, 28, 29, 36, 41, 45, 48, 49, 50, 52, 53, 54, 56, 57, 60, 68, 69, 72, 75, 83, 85, 90], "point": [6, 8, 16, 28, 36, 41, 45, 48, 54, 56, 60, 66, 69, 82, 83, 84, 85, 87, 88, 90], "my": [6, 87], "to_my_dtyp": 6, "mydtypetensor": 6, "from_float": [6, 88, 90], "level": [6, 75, 83, 87, 90], "reus": [6, 83, 90], "quantize_": [6, 61, 67, 79, 83, 84, 85, 88], "appli": [6, 8, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 59, 67, 77, 79, 83, 84, 87, 91], "convers": [6, 8, 34, 83], "filter": [6, 34, 49, 82, 88], "choos": [6, 83, 87, 90], "which": [6, 16, 22, 49, 82, 83, 84, 85, 87, 88, 91], "modul": [6, 31, 32, 33, 34, 35, 45, 46, 48, 49, 59, 61, 62, 66, 67, 71, 72, 74, 75, 79, 82, 84, 85, 88], "should": [6, 8, 35, 40, 54, 56, 61, 74, 75, 82, 83, 87, 91], "algorithm": [6, 41, 47, 87], "onli": [6, 13, 34, 37, 39, 40, 41, 42, 44, 47, 79, 82, 84, 85, 87, 90, 91], "dynam": [6, 30, 31, 35, 37, 40, 42, 43, 60, 64, 79, 88, 90], "quant": [6, 8, 16, 36, 83, 91], "static": [6, 8, 14, 18, 24, 27, 31, 38, 52, 60, 80], "type": [6, 8, 17, 18, 22, 31, 32, 33, 34, 37, 38, 39, 41, 42, 45, 46, 48, 49, 53, 58, 60, 68, 70, 80, 83, 85, 87, 90, 91], "note": [6, 57, 59, 75, 83, 84, 87, 90, 91], "2": [6, 8, 11, 13, 17, 20, 41, 45, 49, 57, 60, 68, 76, 77, 79, 82, 83, 84, 87, 88, 90, 94], "4": [6, 11, 17, 20, 29, 40, 53, 76, 77, 79, 83, 84, 85, 87, 90], "below": [6, 82, 83, 87, 90, 91, 94], "follow": [6, 41, 60, 82, 83, 84, 87, 88, 90], "util": [6, 40, 82, 83, 84, 85, 90, 91], "import": [6, 61, 67, 79, 84, 85, 87, 88, 90, 91, 94], "unwrap_tensor_subclass": [6, 84], "m_unwrap": 6, "m": [6, 67, 69, 79, 82, 84, 85, 88, 90], "In": [6, 82, 83, 84, 87, 88, 90], "compat": [6, 17, 60, 84], "aim": [6, 83, 87], "fullgraph": [6, 84], "true": [6, 8, 26, 31, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 52, 53, 60, 67, 71, 79, 82, 84, 85, 88, 90, 91], "first": [6, 18, 49, 58, 75, 83, 88, 90, 91], "remov": [6, 50, 75, 82, 87, 91], "ani": [6, 19, 49, 62, 66, 73, 75, 83, 87, 90], "unnecessari": 6, "graph": 6, "break": 6, "torch_log": 6, "output_cod": 6, "when": [6, 8, 19, 50, 54, 56, 68, 82, 83, 87, 88, 91], "script": [6, 84, 88, 90, 94], "inductor": [6, 49], "python": [6, 83, 87, 92, 94], "mode": [6, 40, 41, 49, 84, 88], "max": [6, 45, 83, 84, 88, 90], "checkout": [6, 8, 16, 80, 83], "doc": [6, 82, 83, 90], "huggingfac": 6, "transform": [6, 8, 83, 88], "deseri": [6, 83], "save_pretrain": 6, "push_to_hub": [6, 91], "from_pretrain": [6, 91], "http": [6, 8, 16, 36, 49, 75, 84, 87], "co": 6, "main": [6, 8, 16, 41, 83, 84, 87, 88, 90], "en": [6, 49], "anoth": [6, 83, 87, 90], "diffus": 6, "github": [6, 8, 16, 36, 84], "com": [6, 8, 16, 36], "sayakpaul": 6, "blob": [6, 8, 16], "infer": [6, 8, 71, 80, 83, 84, 85, 87, 88, 90], "serialization_and_load": 6, "md": 6, "The": [6, 8, 9, 14, 17, 22, 34, 36, 37, 38, 39, 49, 58, 67, 70, 71, 72, 75, 82, 83, 84, 85, 87, 90, 91], "abov": [6, 45, 83, 85, 87, 88, 90], "just": [6, 45, 60, 83, 85, 87, 90], "talk": [6, 83], "about": [6, 41, 83, 84, 85, 87], "basic": [6, 19, 84, 88, 90], "provid": [6, 14, 17, 20, 21, 49, 50, 59, 66, 82, 83, 87, 90, 91], "fsdp": [6, 83], "ll": [6, 45, 82, 83, 90], "put": [6, 79], "developer_api_guid": 6, "cover": [6, 83, 94], "executorch": [6, 42, 67], "torchchat": 6, "todo": [6, 83], "qat": [6, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66], "suit": 6, "out": [6, 20, 45, 49, 75, 82, 83, 84, 87, 90], "differ": [6, 14, 41, 52, 59, 68, 70, 82, 83, 84, 85, 87, 90, 91], "system": 6, "dtensor": [6, 90], "recommend": [6, 37, 38, 39, 40, 41, 42, 47, 49, 82], "copi": [6, 8, 75, 84, 85, 87, 88, 90], "past": [6, 87], "adapt": [6, 88], "now": [6, 36, 42, 50, 82, 83, 84, 87, 88, 90], "befor": [6, 67, 83, 85, 87, 88, 90], "some": [6, 49, 67, 75, 83, 87, 88, 90], "singl": [6, 30, 35, 37, 49, 52, 82, 84, 87], "comput": [6, 17, 21, 35, 39, 74, 75, 87, 88, 90], "intens": 6, "memori": [6, 8, 57, 82, 84, 87, 90], "input": [6, 8, 17, 18, 20, 31, 34, 35, 49, 50, 52, 54, 56, 57, 58, 66, 67, 68, 70, 75, 79, 82, 83, 88, 90], "dimens": [6, 8, 22, 47, 50, 54, 56, 58, 68, 82, 90, 91], "get": [6, 18, 82, 83, 87, 91], "sens": [6, 83, 90], "speedup": [6, 41, 82, 83, 84, 87], "d": [6, 83], "creat": [6, 8, 24, 25, 27, 82, 83, 87, 90], "file": [6, 82, 86, 90, 91, 93], "benchmark_aq": 6, "shape": [6, 8, 16, 49, 58, 70, 84, 88, 90, 91], "A": [6, 8, 22, 49, 52, 57, 74, 87, 90, 91], "quick": [6, 80], "wai": [6, 8, 49, 82, 83, 87, 88, 90], "relev": [6, 41, 83, 94], "chang": [6, 67, 82, 83, 84, 85, 87, 88, 90], "interest": [6, 83, 87, 90], "tutori": [6, 8, 82, 83, 86, 87, 88, 90, 91, 92, 93], "print_op_and_shap": 6, "output": [6, 31, 49, 50, 54, 56, 68, 82, 83, 87, 94], "torch_func": 6, "built": [6, 82, 90], "k": [6, 70, 84, 85, 88, 90], "n": [6, 84, 85, 88, 90], "10": [6, 45, 68, 82, 88], "method": [6, 14, 17, 20, 21, 49, 67, 75, 87, 88, 90], "_c": 6, "tensorbas": 6, "object": [6, 22, 61, 67, 79, 90], "arg": [6, 8, 62, 75, 90, 91], "0": [6, 8, 49, 60, 68, 72, 75, 82, 84, 85, 86, 87, 88, 90, 91, 93, 94], "size": [6, 8, 9, 16, 18, 40, 41, 42, 47, 50, 54, 56, 60, 68, 82, 84, 85, 87, 88, 90, 91], "all": [6, 35, 45, 49, 52, 62, 66, 74, 75, 76, 83, 84, 85, 86, 87, 88, 90, 91, 92], "under": 6, "benchmark_your_kernel": 6, "helper": 6, "right": [6, 83, 87], "1": [6, 17, 22, 32, 33, 41, 45, 46, 47, 48, 49, 53, 68, 75, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94], "either": [6, 8, 37, 56, 75, 87], "one": [6, 37, 49, 52, 74, 82, 83, 87, 90, 91], "probabl": 6, "keep": [6, 17, 75], "futur": [6, 36, 88, 91], "llama": [6, 91], "llama2": 6, "llama3": [6, 82], "sam": 6, "alreadi": [6, 8, 49, 90], "modifi": [6, 34, 67, 75, 82, 83, 87, 90], "friendli": [6, 83], "compar": [6, 41, 57, 75, 82, 83], "techniqu": [6, 85, 87, 88, 90, 91], "repres": [6, 8, 9, 12, 14, 25, 31, 60, 68, 75, 83, 85, 90], "bound": [6, 87, 91], "help": [6, 82, 83, 91], "option": [6, 8, 12, 16, 23, 26, 27, 28, 30, 31, 34, 37, 38, 40, 41, 43, 44, 49, 50, 52, 54, 56, 57, 60, 63, 65, 67, 68, 71, 72, 73, 75, 79, 82, 84, 91], "each": [6, 18, 49, 60, 71, 74, 83, 87, 88, 90, 91], "understand": [6, 82], "profil": 6, "profile_path": 6, "chrome": 6, "trace": [6, 83], "let": [6, 45, 68, 83, 84, 87, 88, 90], "know": [6, 49, 61, 90], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 63, 64, 65, 74, 75, 83, 84, 85, 88, 90], "torchao": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 87, 88, 90], "tensor_impl": [8, 16, 83, 88], "aqttensorimpl": [8, 16], "block_siz": [8, 14, 16, 18, 23, 24, 26, 27, 28, 29, 50, 52, 54, 56, 57, 68, 84, 88], "tupl": [8, 16, 18, 23, 24, 26, 27, 28, 37, 38, 50, 52, 53, 54, 56, 57, 66, 68, 75, 90, 91], "int": [8, 9, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 36, 40, 41, 42, 44, 47, 50, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 67, 68, 69, 75, 84, 88, 90, 91], "quant_min": [8, 16, 26, 27, 28, 45, 50, 52, 54, 56, 57, 68, 83, 84, 90], "union": [8, 16, 31, 37, 38, 50, 54, 56, 57, 60, 67, 68], "none": [8, 12, 16, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 44, 45, 46, 48, 49, 50, 52, 54, 56, 57, 60, 65, 66, 67, 68, 71, 72, 73, 75, 79, 88, 90, 91], "quant_max": [8, 16, 26, 27, 28, 45, 50, 52, 54, 56, 57, 68, 83, 84, 90], "zero_point_domain": [8, 16, 26, 27, 28, 41, 50, 52, 56, 57, 60], "zeropointdomain": [8, 16, 26, 27, 28, 41, 50, 52, 56, 57, 60], "stride": [8, 16, 83, 90], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 92, 94], "tensor": [8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 38, 39, 41, 42, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 68, 69, 70, 73, 75, 80, 82, 84, 85, 87, 88, 94], "subclass": [8, 16, 34, 49, 74, 79, 84, 85, 87], "mean": [8, 18, 45, 50, 54, 56, 68, 69, 82, 83, 84, 87], "quantized_tensor": 8, "float_tensor": [8, 90], "scale": [8, 14, 17, 24, 27, 32, 35, 38, 45, 48, 50, 52, 54, 55, 56, 57, 58, 60, 66, 68, 69, 71, 72, 83, 87, 88, 90, 91], "zero_point": [8, 14, 27, 41, 48, 50, 52, 54, 56, 57, 68, 83, 87, 88, 90], "happen": [8, 16, 49, 83, 90], "dure": [8, 16, 49, 54, 56, 60, 72, 82, 87, 88, 90], "choose_qparam": [8, 83], "dequant": [8, 16, 18, 41, 54, 83, 90, 91], "ao": [8, 16, 87, 91], "three": [8, 49, 75, 79, 83], "choose_qparams_affin": [8, 41, 52, 83], "quantize_affin": [8, 41, 56, 57, 83], "qand": 8, "dequantize_affin": [8, 41, 56, 57], "extern": 8, "regardless": 8, "intern": [8, 21], "represent": [8, 14, 25, 41, 83, 87, 91], "orient": 8, "field": [8, 60], "serv": [8, 14, 90], "gener": [8, 56, 57, 83, 84, 87, 88, 90, 91, 92, 94], "storag": [8, 17, 83, 87], "data": [8, 9, 14, 17, 22, 37, 38, 39, 41, 52, 80, 83, 85, 87, 88, 90, 91], "store": [8, 17, 18, 22, 74, 83, 87, 91], "plain": [8, 91], "int_data": [8, 90], "format": [8, 17, 18, 36, 40, 69, 83, 87], "depend": [8, 40, 49, 85, 87, 90], "kernel": [8, 10, 11, 13, 17, 21, 36, 40, 41, 67, 84, 87], "granular": [8, 32, 37, 38, 40, 41, 42, 47, 50, 54, 56, 60, 68, 82, 83, 88, 91], "element": [8, 20, 22, 49, 50, 54, 56, 68, 87], "share": [8, 50, 54, 56, 68, 87], "qparam": [8, 50, 54, 56, 68], "us": [8, 12, 13, 14, 17, 18, 19, 22, 24, 27, 37, 38, 41, 42, 45, 47, 49, 50, 52, 54, 56, 59, 60, 61, 68, 75, 80, 82, 83, 84, 85, 87, 88, 90, 91], "per": [8, 39, 41, 42, 43, 44, 47, 50, 54, 56, 60, 62, 63, 64, 68, 75, 77, 82, 83, 84, 87, 88], "torch": [8, 17, 18, 22, 24, 31, 34, 37, 38, 39, 41, 47, 49, 50, 53, 54, 55, 56, 58, 60, 62, 63, 64, 67, 68, 70, 71, 72, 79, 82, 83, 84, 85, 87, 88, 90, 91, 94], "origin": [8, 18, 39, 56, 61, 68, 75, 83, 84, 85, 87], "high": [8, 23, 24, 25, 26, 27, 69, 82, 83, 87, 88, 90], "precis": [8, 23, 24, 25, 26, 27, 39, 63, 64, 69, 83, 88, 90], "minimum": [8, 49, 50, 54, 56, 68], "valu": [8, 18, 31, 32, 33, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 54, 56, 57, 68, 71, 75, 83, 87, 88, 90], "specifi": [8, 31, 34, 47, 56, 59, 67, 68, 75, 79, 82, 87], "deriv": [8, 52, 56, 68], "maximum": [8, 50, 54, 56, 68, 71], "domain": [8, 41, 48, 50, 54, 56, 60], "integ": [8, 26, 27, 40, 41, 45, 48, 50, 54, 56, 58, 60, 70, 88], "zero": [8, 20, 41, 50, 54, 56, 60, 66, 75, 87, 88], "ad": [8, 54, 56, 75, 87, 88, 90], "subtract": [8, 18, 56], "unquant": [8, 56], "default": [8, 9, 12, 19, 21, 22, 37, 38, 39, 40, 41, 47, 49, 50, 54, 56, 60, 67, 71, 72, 82, 90, 91], "float32": [8, 24, 54, 55, 56, 60, 62, 64, 68, 69, 85, 87, 88, 90], "given": [8, 16, 29, 82, 87, 91], "return": [8, 16, 17, 18, 34, 49, 57, 58, 60, 67, 70, 71, 72, 79, 82, 83, 84, 85, 88, 90, 91], "classmethod": [8, 16, 88, 90, 91], "from_hp_to_floatx": 8, "input_float": [8, 16, 23, 24, 25, 26, 27, 28, 73], "target_dtyp": [8, 23, 24, 26, 27, 30, 31, 50, 52, 83, 88], "_layout": [8, 16, 23, 24, 25, 26, 27, 28, 83, 84, 88], "layout": [8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 41, 42, 43, 79, 87], "scale_dtyp": [8, 23, 24, 26, 50, 52, 88], "float8": [8, 11, 12, 23, 24, 30, 31, 32, 33, 34, 35, 37, 38, 39, 80, 83, 88], "from_hp_to_floatx_stat": 8, "paramet": [8, 14, 17, 18, 24, 27, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 49, 50, 54, 56, 58, 60, 67, 68, 70, 71, 72, 75, 79, 82, 83, 85, 87, 90, 91], "from_hp_to_fpx": 8, "floatx": [8, 25, 83], "ebit": [8, 25, 36, 51, 55, 69], "mbit": [8, 25, 36, 51, 55, 69], "support": [8, 25, 37, 42, 60, 79, 82, 84, 85, 87, 90], "float1": [8, 25], "float7": [8, 25], "from_hp_to_intx": [8, 16], "mapping_typ": [8, 26, 42, 50, 52, 60], "mappingtyp": [8, 26, 42, 43, 50, 52, 60, 88], "ep": [8, 26, 50, 52, 60, 88], "zero_point_dtyp": [8, 26, 50, 52, 88], "preserve_zero": [8, 26, 41, 50, 52], "bool": [8, 26, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 52, 53, 60, 64, 67, 71, 79, 88], "plainlayout": [8, 26, 27, 42, 43, 88], "use_hqq": [8, 26, 41, 47, 91], "fals": [8, 26, 31, 41, 43, 47, 49, 53, 60, 64, 71, 75, 82, 83, 84, 85, 88, 90, 91], "from_hp_to_intx_stat": 8, "kwarg": [8, 60, 62, 74, 75, 76, 90, 91], "perform": [8, 21, 35, 40, 49, 58, 62, 63, 64, 70, 71, 74, 82, 84, 87, 88, 90, 91], "self": [8, 83, 84, 85, 88, 90, 91], "If": [8, 12, 34, 37, 49, 58, 60, 70, 71, 75, 83, 84, 87, 90], "correct": [8, 17], "otherwis": [8, 59, 60, 83], "desir": [8, 49, 56, 88], "call": [8, 49, 56, 57, 74, 83, 84, 85, 87, 88, 90, 91], "non_block": 8, "memory_format": 8, "preserve_format": 8, "set": [8, 12, 37, 38, 39, 40, 41, 42, 47, 49, 52, 60, 67, 71, 75, 84, 87], "function": [8, 21, 34, 49, 53, 67, 74, 75, 76, 79, 82, 84, 85, 87, 88, 90, 91], "attempt": 8, "asynchron": 8, "respect": [8, 87], "host": [8, 91], "possibl": [8, 87], "behavior": [8, 14, 59, 91], "pin": 8, "pageabl": 8, "howev": [8, 87, 91], "caution": 8, "advis": [8, 83], "featur": [8, 90], "inform": [8, 87, 91], "good": [8, 84, 90], "usag": [8, 35, 49, 59, 60, 61, 80, 82], "pin_memori": 8, "even": [8, 82, 87], "match": [8, 54, 58, 87], "other": [8, 14, 75, 82, 85, 87, 90, 91, 94], "randn": [8, 82, 84, 85, 88, 90], "initi": [8, 66, 83, 85], "float64": 8, "5044": 8, "0005": 8, "3310": 8, "0584": 8, "cuda0": 8, "blocksiz": 9, "64": [9, 29, 41, 47, 53, 85, 88, 90, 91], "block": [9, 18, 75, 87], "matrix": [9, 12, 37, 38, 58, 70, 75, 84, 87], "variabl": [9, 12, 21, 22, 75, 87], "cutlass": [10, 11], "mm_config": [12, 37, 38], "float8mmconfig": [12, 37, 38], "configur": [12, 30, 31, 34, 37, 38, 39, 41, 42, 43, 44, 47, 67, 79, 82, 83, 84], "multipl": [12, 37, 38, 49, 58, 59, 70, 84, 87, 88, 90, 91], "involv": [12, 87], "tinygemm": [13, 41, 67, 83, 84], "_weight_int4pack_mm_for_cpu": [13, 41], "version": [13, 60, 82, 84, 90, 91], "least": 13, "6": [13, 60, 82, 83, 84, 87], "It": [14, 17, 19, 21, 35, 87, 90], "pre": [14, 17, 21, 84, 87], "process": [14, 17, 19, 21, 22, 49, 72, 83, 87, 94], "post": [14, 21, 90], "addit": [14, 19, 49, 57, 82, 87, 90], "design": [14, 17, 20, 91], "extend": [14, 83, 87], "conjunct": 14, "tensorimpl": 14, "custom": [14, 74, 80, 82, 83, 84, 87, 90, 91], "interact": [14, 83], "qqq": [15, 16, 28], "marlinqqq": 16, "inherit": [16, 19, 90, 91], "choose_qparams_and_quantize_affine_qqq": 16, "dequantize_affine_qqq": 16, "handl": [17, 20, 21, 49, 83], "pattern": [17, 20, 83, 91], "ensur": 17, "preprocess": [17, 20], "manag": 17, "pre_process": 17, "1\u00ba": 17, "transpos": [17, 83, 90], "sinc": [17, 74, 83, 85, 87, 88, 90], "layer": [17, 34, 37, 39, 41, 43, 44, 47, 49, 62, 63, 64, 71, 72, 75, 76, 77, 82, 87, 88, 90, 91], "2\u00ba": 17, "inject": 17, "3\u00ba": 17, "again": [17, 18, 87], "becaus": [17, 82, 83, 85, 87, 90], "dim": [17, 88, 90, 91], "tensor_meta": 18, "subclasstensorarg": 18, "n_block": 18, "scaler_block_s": [18, 29], "quantized_scal": 18, "quantization_factor": 18, "scaler_mean": 18, "quantized_data": [18, 91], "nf4": 18, "qlora": 18, "convert_to_norm_float_weight": 18, "normal": [18, 29, 49, 87], "dequantize_scal": 18, "unpack": [18, 69, 83], "doubl": 18, "scaler": 18, "int8": [18, 42, 43, 44, 60, 64, 67, 77, 79, 83, 90], "per_scaler_block": 18, "factor": [18, 58, 72, 82, 87], "inpt_weight": 18, "double_quantize_scal": 18, "achiev": [18, 82, 87, 88, 90], "calcul": [18, 35, 45, 50, 52, 71, 83, 87], "absmax": 18, "find": [18, 87], "posit": 18, "typic": [18, 19, 83, 85, 88, 91], "per_block": 18, "int16": 18, "n_scaler_block": 18, "get_original_weight": 18, "quantize_tensor_nearest": 18, "float16": [18, 53, 56, 68, 87], "nearest": 18, "round": [18, 45, 90], "up": [18, 67, 82, 83, 84, 87], "most": [19, 83, 87, 91], "doe": [19, 41, 83, 87, 90], "metadata": [19, 83, 90, 91], "step": [19, 35, 49, 82, 83, 87], "requir": [19, 21, 82, 83, 87, 90], "semi": [20, 79, 87], "structur": [20, 79, 84, 85, 87, 90], "matric": [20, 87], "where": [20, 45, 47, 52, 62, 63, 64, 69, 83, 87, 91], "everi": [20, 74, 87, 90], "four": 20, "prune": [20, 75], "conform": 20, "inner_k_til": [21, 41, 63, 84], "8": [21, 22, 40, 41, 45, 63, 82, 83, 84, 91], "core": [21, 46, 83, 88, 91], "tile": [21, 83], "fit": [21, 83, 85], "effici": [21, 84, 87, 88], "affect": [21, 87], "matmul": [21, 39, 83, 87, 90], "pack_dim": [22, 47], "uintx": [22, 47, 83], "smaller": [22, 40, 41, 42, 47, 84, 85], "bit": [22, 29, 36, 40, 47, 69, 90, 91], "width": [22, 40], "than": [22, 60, 82, 83, 87, 90], "standard": [22, 83, 91], "byte": [22, 36, 47], "uintxtensor": 22, "determin": [22, 50, 56, 82, 87, 91], "along": [22, 87, 91], "indic": [22, 48, 87], "last": [22, 82], "256": [29, 41, 62, 63, 64], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "tensorwis": [30, 31], "cast": [30, 32, 56, 57], "cast_config_input": 31, "config": [31, 34, 49, 60, 67, 75, 79, 87, 88, 91], "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "nn": [31, 34, 49, 59, 62, 67, 71, 72, 79, 82, 83, 84, 85, 87, 88, 90, 91], "from_recipe_nam": 31, "recipe_nam": [31, 82], "float8linearrecipenam": 31, "str": [31, 34, 40, 53, 60, 67, 72, 73, 75, 79, 82, 90, 91], "string": [31, 60, 75], "recip": [31, 74], "name": [32, 33, 45, 46, 48, 67, 72, 75, 79, 87, 90, 91], "qualnam": [32, 33, 45, 46, 48], "boundari": [32, 33, 45, 46, 48], "strategi": 32, "module_filter_fn": [34, 82], "callabl": [34, 49, 53, 67, 73, 79, 91], "float8linearconfig": 34, "swap": [34, 62, 82, 83, 87, 88], "float8linear": [34, 82], "pass": [34, 49, 52, 74, 83, 88, 90, 91], "instanc": [34, 67, 74, 79, 85, 90], "fqn": [34, 75, 79, 82, 88], "reduc": [35, 82, 87], "sum": 35, "backward": [35, 82, 87], "set_inductor_config": [36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49], "sub": [36, 47, 87], "expon": [36, 69], "mantissa": [36, 69], "fp6_e3_m2": 36, "fp6_e2_m3": 36, "fp6": 36, "llm": 36, "paper": [36, 87, 94], "arxiv": [36, 75, 87], "org": [36, 49, 75, 83, 84, 87], "ab": [36, 75, 87], "2401": 36, "14112": 36, "repo": 36, "usyd": 36, "fsalab": 36, "fp6_llm": 36, "renam": 36, "fpxtensorcoreaqttensorimpl": 36, "experiment": 36, "merg": 36, "to_affine_quantized_floatx": 36, "activation_dtyp": [37, 38], "float8_e4m3fn": [37, 38, 39, 83], "weight_dtyp": [37, 38, 39], "pertensor": [37, 38, 88], "perrow": [37, 38], "list": [37, 49, 54, 59, 72, 75, 83, 84, 90, 91], "symmetr": [37, 38, 39, 40, 42, 43, 44, 45, 50, 60, 77, 90], "current": [37, 42, 67, 72, 75, 79, 82, 87, 90, 91], "fast": [37, 38, 87], "accumul": [37, 38], "adjust": [37, 38, 39, 40, 41, 42, 47, 49], "torchinductor": [37, 38, 39, 40, 41, 42, 47], "float8_e4m": 38, "channel": [39, 43, 44, 60, 62, 63, 64, 74, 77, 88], "group_siz": [40, 41, 42, 44, 47, 53, 60, 62, 67, 84, 91], "128": [40, 41, 82, 88, 90, 91], "bit_width": 40, "packing_bitwidth": 40, "weight_onli": 40, "gemlit": 40, "triton": [40, 83], "its": [40, 87, 90, 91], "associ": [40, 88], "fp16": [40, 50], "asymmetr": [40, 41, 42, 45, 47, 50, 60, 83, 84, 88], "control": [40, 41, 42, 47, 75, 87, 91], "grain": [40, 41, 42, 47, 90], "32": [40, 41, 42, 60, 67, 79, 82, 84, 85, 88, 90], "impact": [40, 49, 82, 91], "hardwar": [40, 83, 87], "runtim": [40, 83], "tensorcoretiledlayout": [41, 83, 84], "group": [41, 42, 47, 60, 62, 63, 64, 83, 84], "tensor_core_til": [41, 83], "int4mm": [41, 84], "aten": [41, 83, 90, 91], "_weight_int4pack_mm": [41, 83], "tradit": 41, "instead": [41, 52, 60, 74, 82, 83, 84, 87, 90], "exactli": [41, 90], "chosen": [41, 87], "choic": 41, "whether": [41, 47, 48, 49, 50, 60, 90], "hqq": [41, 47, 83], "preserv": [41, 50, 75, 87], "Will": 41, "act_mapping_typ": [42, 43], "token": [42, 43, 60, 64, 77, 82], "produc": 42, "backend": [42, 87], "did": 42, "lower": [42, 83, 87, 88], "flow": [42, 87, 88], "yet": [42, 46, 90, 91], "marlinqqqlayout": 42, "cutlassint4packedlayout": 42, "weight_only_decod": 43, "number": [45, 47, 49, 69, 75, 87, 90], "map": [45, 60, 83, 90], "rang": [45, 82, 87, 88], "sai": [45, 68, 83, 91], "3": [45, 49, 68, 82, 83, 84, 87, 94], "5": [45, 72, 75, 82, 84, 87, 91, 94], "7": [45, 82], "symmetric_no_clipping_err": 45, "variant": [45, 52, 90], "smin": 45, "smax": 45, "min_val_neg": [45, 90], "max_val_po": [45, 90], "By": [45, 87], "individu": [45, 87], "less": [45, 87, 90], "error": [45, 49, 60, 82, 90], "neg": 45, "directli": [45, 52, 83, 87, 88, 90], "placehold": 46, "x": [47, 82, 84, 85, 88, 90, 91, 94], "uint1": [47, 83], "uint7": [47, 83], "enum": 48, "quantized_v": 48, "float_val": 48, "mid_point": 48, "example_input": [49, 66, 84, 85, 88], "qtensor_class_list": 49, "aqdefaultlinearweight": 49, "aqint8weightonlyquantizedlinearweight": 49, "aqint8weightonlyquantizedlinearweight2": 49, "aqint8dynamicallyquantizedlinearweight": 49, "filter_fn": [49, 67, 79], "interpol": 49, "85": 49, "manual": 49, "supress_autoquant_error": 49, "min_sqnr": 49, "aq_kwarg": 49, "autoquant": 49, "identifi": [49, 88], "fastest": 49, "over": [49, 82, 87], "potenti": [49, 87, 88], "qtensor": 49, "prepar": [49, 59, 62, 71, 75, 83, 87], "search": [49, 87], "whose": 49, "exchang": 49, "autoquantizablelinearweight": 49, "calibr": [49, 52], "user": [49, 59, 82, 83, 84, 87, 88, 90, 94], "seen": 49, "record": [49, 83, 88], "so": [49, 82, 83, 84, 85, 87, 90], "final": [49, 57, 67, 83, 84, 87], "benchmark": [49, 71, 82], "member": 49, "pick": 49, "result": [49, 58, 69, 70, 83, 87, 88], "highli": 49, "complet": 49, "simpli": [49, 87, 88, 90], "had": [49, 90], "compil": [49, 67, 70, 82, 83, 84, 88, 90], "them": [49, 74, 83], "onc": [49, 87], "proce": 49, "combin": [49, 60, 87, 90], "finalize_autoqu": 49, "been": [49, 90], "log": [49, 90], "forward": [49, 74, 83, 84, 85, 87, 88, 90, 91], "fulli": [49, 67, 72, 79, 87], "unless": [49, 91], "default_autoquant_class_list": 49, "contain": [49, 71, 72, 87, 90], "second": [49, 58, 82, 83, 94], "stop": 49, "wait": [49, 83], "sever": [49, 82, 91], "automat": [49, 82, 90, 91, 94], "suppress": 49, "accept": 49, "signal": 49, "nois": 49, "ration": 49, "wikipedia": 49, "wiki": 49, "noise_ratio": 49, "v": 49, "non": [49, 83, 87, 90], "caus": [49, 82], "too": 49, "larg": [49, 90], "numer": [49, 82, 87], "resaon": 49, "40": [49, 82], "keyword": 49, "example_input1": 49, "example_input2": 49, "int32": [50, 60, 62, 83, 84], "fp32": [50, 54, 60, 88, 90], "bf16": [50, 83, 84, 87], "optioanl": 50, "param": [50, 52, 57, 75], "request": [50, 54, 68], "min_val": [52, 83, 90], "max_val": [52, 83, 90], "observ": [52, 74, 87, 88], "obtain": 52, "track": [52, 83, 91], "nbit": 53, "axi": [53, 68, 88], "compute_dtyp": 53, "verbos": 53, "raw_output": 53, "optimize_weight": 53, "optimize_weights_proximal_legaci": 53, "input_dtyp": 54, "output_dtyp": [54, 55, 68], "uint8": [54, 68, 83, 88], "quant_dtyp": [56, 57], "fake": [56, 57, 60, 61, 62, 63, 64, 82], "awar": [56, 57, 75, 87, 90], "equival": [56, 57, 60, 72, 87], "without": [56, 57, 61, 83, 87, 91], "valid": [56, 91], "fake_quantize_affin": 57, "consum": 57, "outlier": [57, 82], "mask": [57, 75, 87], "intermedi": 57, "b": 58, "scales1": 58, "multipli": [58, 70, 87], "row": [58, 82, 87], "rais": [58, 70, 82, 90, 91], "assertionerror": [58, 70, 82, 90], "expect": [58, 82, 87, 90], "twostepquant": 59, "compos": [59, 83, 87, 90], "easili": 59, "thei": [59, 82, 83, 87, 90], "constructor": [59, 90], "must": [59, 60, 82, 87, 91], "embed": [59, 62], "undefin": [59, 75], "my_quant": 59, "qatquantizer1": 59, "qatquantizer2": 59, "qatquantizer3": 59, "torchaodtyp": 60, "scale_precis": [60, 62], "zero_point_precis": [60, 62], "is_dynam": 60, "range_learn": 60, "is_symmetr": 60, "simul": [60, 76, 83, 87], "older": 60, "int1": [60, 83], "int7": 60, "pergroup": 60, "per_token": 60, "pertoken": 60, "per_channel": 60, "peraxi": [60, 88], "per_group": [60, 68], "separ": [60, 87, 91], "altern": [60, 83, 88, 90], "leav": 60, "empti": [60, 83], "properti": [60, 83], "throw": 60, "els": [60, 91], "fakequantizedlinear": 61, "fakequantizedembed": 61, "back": [61, 90], "correspond": [61, 67, 83, 85, 87, 90], "model_with_fake_quantized_linear": 61, "int4weightonlyqatembed": 62, "int4weightonlyembed": 62, "groupsiz": [63, 64, 68], "scales_precis": [63, 64], "padding_allow": 64, "activation_config": 65, "fakequantizeconfig": 65, "weight_config": 65, "fakequant": 66, "aobaseconfig": [67, 79, 88, 91], "inplac": [67, 75, 84], "workflow": [67, 79, 82, 84, 87], "qualifi": [67, 72, 79, 87], "move": [67, 83, 88, 91], "speed": [67, 87], "predefin": 67, "execut": [67, 86, 90, 93], "path": [67, 70, 84], "customiz": 67, "int8_dynamic_activation_int4_weight": 67, "int8_dynamic_activation_int8_weight": [67, 79], "mm": [67, 90], "int4_weight_onli": [67, 83, 84, 85], "int8_weight_onli": 67, "sequenti": [67, 79, 82], "1024": [67, 79, 84, 85], "tabl": [68, 82, 83, 87], "per_tensor": 68, "per_axi": 68, "low": [69, 87, 90], "00seeemm": 69, "fp6_e3m2": 69, "sign": 69, "mat2": 70, "safe": 70, "consid": [70, 83, 87], "cubla": 70, "fallback": [70, 91], "i": [70, 82, 87], "j": 70, "debug_skip_calibr": 71, "smoothquant": [71, 72], "smoothfakedynamicallyquantizedlinear": [71, 72], "debug": 71, "skip_fqn_list": 72, "cur_fqn": 72, "alpha": 72, "replac": [72, 87, 91], "skip": [72, 75, 87], "being": [72, 82, 83, 87, 91], "input_quant_func": [73, 83], "quant_kwarg": 73, "dict": [73, 75, 90, 91], "l2": [74, 87], "norm": [74, 75, 87], "buffer": 74, "x_orig": 74, "overridden": 74, "although": [74, 90], "within": [74, 87, 91], "afterward": 74, "former": 74, "care": [74, 85, 87], "hook": [74, 83], "while": [74, 75, 87, 90], "latter": 74, "silent": 74, "ignor": [74, 82], "sparsity_level": [75, 87], "semi_structured_block_s": 75, "wanda": 75, "sparsifi": [75, 80, 85, 87], "propos": 75, "2306": 75, "11695": 75, "product": [75, 91], "magnitud": [75, 87], "parametr": 75, "deepcopi": [75, 84, 88, 90], "squash_mask": [75, 87], "params_to_keep": 75, "params_to_keep_per_lay": 75, "squash": 75, "appropri": [75, 83], "sparse_param": 75, "attach": [75, 87], "kei": [75, 87, 94], "save": [75, 82, 84, 85, 91], "xdoctest": 75, "local": [75, 87], "don": [75, 82, 84, 87, 91], "t": [75, 82, 83, 84, 87, 88, 90, 91], "hasattr": [75, 91], "submodule1": 75, "linear1": [75, 84, 85, 88, 90], "foo": 75, "bar": 75, "submodule2": 75, "linear42": 75, "baz": 75, "print": [75, 84, 85, 90, 94], "42": [75, 88], "24": 75, "ones": [75, 83], "update_mask": 75, "tensor_nam": [75, 91], "statist": [75, 83, 87, 88], "retriev": 75, "act_per_input": 75, "Then": [75, 90], "metric": 75, "across": [75, 87, 90, 91], "whole": 75, "dnynam": 77, "alia": [78, 91], "semisparseweightconfig": 78, "sparsify_": 79, "apply_tensor_subclass": [79, 83], "essenti": [79, 91], "semi_sparse_weight": 79, "semisparselayout": 79, "sparsemarlinlayout": 79, "def": [79, 82, 83, 84, 85, 88, 90, 91], "isinst": [79, 82, 87, 88, 90, 91], "sparse_api": 79, "librari": [80, 85], "gradient": [80, 87], "nativ": [80, 82, 90], "readm": [80, 84, 87], "overal": [80, 84], "introduct": [80, 83], "recent": 80, "highlight": [80, 90, 94], "updat": [80, 84, 85, 87], "guid": [80, 83], "contributor": [80, 84], "serial": [80, 83], "write": 80, "advanc": [80, 88, 90], "pretrain": [80, 87], "vllm": 80, "architectur": [80, 87], "5x": 82, "512": 82, "gpu": [82, 84, 91, 94], "cluster": 82, "34": 82, "43x": 82, "2k": 82, "h200": 82, "latest": [82, 84], "offic": 82, "framework": 82, "8b": 82, "offici": 82, "popular": [82, 83], "flagship": 82, "common": [82, 83, 87], "form": [82, 83, 87], "distribut": [82, 88, 90, 91], "checkpoint": [82, 91], "quickli": [82, 90], "batteri": 82, "includ": [82, 83, 90], "experi": 82, "commonli": [82, 87], "fork": 82, "build": [82, 83, 87, 90, 91], "top": [82, 83, 90], "re": [82, 85, 90], "readi": [82, 84, 88, 90], "virtual": 82, "environ": 82, "conda": 82, "venv": 82, "instal": [82, 84], "download": [82, 84, 92, 94], "job": 82, "command": [82, 84], "root": 82, "directori": 82, "launch": 82, "ngpu": 82, "config_fil": 82, "train_config": 82, "llama3_8b": 82, "toml": 82, "run_train": 82, "sh": 82, "fsdp2": 82, "hyperparamet": 82, "edit": 82, "line": [82, 87], "flag": 82, "termin": 82, "rank0": 82, "titan": 82, "2025": 82, "06": 82, "04": 82, "08": 82, "51": 82, "48": 82, "074": 82, "info": 82, "loss": [82, 87], "12": 82, "2254": 82, "27": 82, "34gib": 82, "28": 82, "78": 82, "tp": [82, 91], "375": 82, "tflop": 82, "21": 82, "73": [82, 88], "mfu": 82, "20": 82, "58": 82, "557": 82, "7069": 82, "30": [82, 84], "99gib": 82, "62": 82, "034": 82, "407": 82, "35": [82, 88], "41": 82, "19": 82, "52": 82, "224": [82, 88], "9196": 82, "022": 82, "406": 82, "65": 82, "904": 82, "1423": 82, "014": 82, "23": [82, 88], "As": [82, 83], "warmup": 82, "around": [82, 85], "7k": 82, "99gb": 82, "peak": 82, "against": 82, "baselin": 82, "11": 82, "02": 82, "37": 82, "404": 82, "2611": 82, "22gib": 82, "595": 82, "47": 82, "49": [82, 88], "027": 82, "4260": 82, "89gib": 82, "344": 82, "367": 82, "39": 82, "15": [82, 84], "03": 82, "01": 82, "988": 82, "9482": 82, "321": 82, "366": 82, "14": 82, "991": 82, "1183": 82, "300": 82, "364": 82, "89": 82, "36": 82, "013": 82, "4659": 82, "291": 82, "84": 82, "769": 82, "gc": 82, "peform": 82, "period": 82, "collect": [82, 83, 87], "3k": 82, "89gb": 82, "11x": 82, "higher": [82, 83, 90], "throughput": 82, "nearli": 82, "ident": [82, 87], "improv": [82, 87], "performan": 82, "vs": [82, 87], "accuraci": [82, 87, 88], "curv": [82, 87], "omit": 82, "648": 82, "2648": 82, "28gib": 82, "71": 82, "29": 82, "26": 82, "475": 82, "9106": 82, "91gib": 82, "53": 82, "503": 82, "434": 82, "43": 82, "94": 82, "166": 82, "9": 82, "0774": 82, "663": 82, "443": 82, "44": [82, 88], "87": 82, "50": [82, 87, 88], "885": 82, "3233": 82, "643": 82, "442": 82, "66": [82, 88], "76": 82, "613": 82, "6150": 82, "637": 82, "72": 82, "6k": 82, "91gb": 82, "21x": 82, "tl": 82, "dr": 82, "better": [82, 90], "priorit": 82, "accur": [82, 87], "stabil": 82, "come": [82, 83, 87, 88, 89], "cost": [82, 88], "slightli": [82, 90], "limit": [82, 90, 91], "underflow": 82, "8xh100": 82, "box": [82, 87], "toi": [82, 84, 88, 90], "convert_to_float8_train": 82, "recurs": 82, "kind": 82, "gemm": 82, "snippet": 82, "f": [82, 83, 85, 87, 88, 90, 91], "float8_linear_util": 82, "float8_linear": 82, "torch_version_at_least_2_5": [82, 84], "greater": 82, "sampl": [82, 83], "2048": 82, "4096": 82, "adamw": 82, "lr": 82, "1e": 82, "elig": 82, "mod": [82, 87, 90], "divis": 82, "16": 82, "in_featur": [82, 84, 85, 88, 90], "out_featur": [82, 84, 88, 90], "enabl": [82, 83, 91], "competit": 82, "loop": [82, 87], "_": [82, 88, 91], "zero_grad": 82, "label": 82, "demonstr": [82, 83, 84, 90], "purpos": [82, 83, 90], "fake_label": 82, "ones_lik": 82, "mse_loss": 82, "model_state_dict": 82, "state_dict": [82, 85], "optimizer_state_dict": 82, "pth": 82, "lai": 83, "stack": 83, "awq": 83, "gptq": 83, "codebookquantizedtensor": 83, "float3": 83, "compon": [83, 90, 91], "overload": [83, 87], "term": [83, 87], "extra": 83, "dev": 83, "discuss": [83, 90], "1833": 83, "No": [83, 85, 87], "matter": [83, 87], "end": [83, 87, 90, 91, 94], "avail": 83, "later": [83, 90], "float3_e2_m0": 83, "float4_e2_m1": 83, "float4_e3_m0": 83, "float5_e2_m2": 83, "float5_e3_m1": 83, "float6_e2_m3": 83, "float6_e3_m2": 83, "float8_e5m2": 83, "float8_e4m3fnuz": 83, "float8_e5m2fnuz": 83, "plan": 83, "float4": 83, "float6": 83, "becom": 83, "part": [83, 87, 90], "uint2": 83, "117208": 83, "outsid": 83, "mention": 83, "criteria": 83, "wide": 83, "adopt": 83, "fundament": [83, 87], "until": 83, "evid": 83, "hopefulli": 83, "amen": 83, "haven": 83, "enough": 83, "ont": 83, "revisit": 83, "intx": 83, "connect": 83, "int4tensor": 83, "previou": 83, "between": [83, 87, 90, 91], "preicison": 83, "mainli": 83, "There": [83, 88, 90], "accommod": 83, "choose_qparams_affine_with_min_max": 83, "min": [83, 88, 90], "int_matmul": 83, "int_scaled_matmul": 83, "reli": [83, 87, 88, 90], "On": [83, 84], "glue": 83, "everyth": 83, "togeth": 83, "construct": 83, "low_precision_v": 83, "high_precision_v": 83, "procedur": 83, "veri": [83, 87, 91], "straightforward": 83, "try": [83, 87, 90], "high_preicsion_v": 83, "especi": [83, 85, 87], "bitwidth": 83, "codebook": 83, "hardcod": 83, "select": 83, "multi": 83, "dimension": [83, 87], "view": [83, 90], "mkldnn": 83, "coo": [83, 87], "sparse_coo": [83, 87], "sparsetensorimpl": 83, "idea": [83, 87], "nice": [83, 87], "concept": [83, 94], "why": [83, 90, 94], "c": [83, 90], "conflict": 83, "quantized_linear": [83, 88], "semant": 83, "stai": [83, 84, 90], "develop": 83, "tradition": 83, "to_affine_quant": 83, "simplic": 83, "explain": 83, "simplest": [83, 87], "easi": 83, "linear_modul": 83, "to_affine_quantized_intx": 83, "requires_grad": [83, 88, 90, 91], "to_linear_activation_quant": 83, "quantized_weight": [83, 91], "activation_and_weight_quant": 83, "encount": 83, "input_qunat_func": 83, "redispatch": 83, "fx": 83, "symbolic_trac": 83, "But": [83, 90, 91], "prefer": [83, 84, 90], "easier": 83, "further": [83, 90], "modif": 83, "figur": [83, 87], "At": [83, 87], "thing": [83, 85, 87, 90], "address": 83, "stat": 83, "averag": [83, 88], "calculate_qparam": [83, 88], "affinequantizedminmaxobserv": [83, 88], "insert_observer_": 83, "observedlinear": [83, 88], "dataset": 83, "complic": [83, 87], "next": [83, 88], "done": [83, 90], "manner": 83, "intend": 83, "autoround": 83, "multitensor": 83, "sure": 83, "describ": [83, 85, 87, 94], "focus": [83, 87], "todai": 83, "low_bit_optim": 83, "similar": [83, 87, 88], "quantized_train": 83, "progress": [83, 91], "lot": [83, 87], "walk": [83, 88, 90, 94], "_convert_weight_to_int4pack": 83, "tensorcoretiledaqttensorimpl": 83, "_quantized_linear_op": 83, "goe": 83, "_aqt_qlinear_dispatch_t": 83, "dispatch": 83, "explan": 83, "wint4": 83, "explor": 84, "stabl": 84, "releas": 84, "pip": 84, "nightli": 84, "index": [84, 87], "url": 84, "whl": 84, "cu121": 84, "major": 84, "instruct": 84, "entri": 84, "mutat": 84, "insert": [84, 88], "logic": [84, 90, 91], "toylinearmodel": [84, 85, 88], "__init__": [84, 85, 88, 90, 91], "super": [84, 85, 88, 90], "linear2": [84, 85, 88, 90], "eval": [84, 85, 88], "faster": [84, 87], "model_bf16": 84, "leverag": [84, 90], "mix": 84, "tensor_impl_dtyp": 84, "verifi": [84, 85, 90], "roughli": [84, 87], "quarter": 84, "os": 84, "tmp": 84, "int4_model": 84, "pt": 84, "bfloat16_model": 84, "int4_model_size_mb": 84, "getsiz": 84, "bfloat16_model_size_mb": 84, "2f": 84, "mb": [84, 85, 86, 93], "25": 84, "00": [84, 86, 93], "much": [84, 87], "benchmark_model": 84, "temporari": 84, "workaround": [84, 91], "num_run": 84, "100": [84, 90], "_dynamo": [84, 90], "reset": 84, "bf16_time": 84, "int4_tim": 84, "time": [84, 87, 90, 94], "3f": 84, "ms": 84, "1fx": 84, "a100": 84, "80gb": 84, "393": 84, "410": 84, "9x": 84, "simpl": [84, 87, 88, 90], "visit": 84, "would": [84, 87, 90], "forget": 84, "tempfil": 85, "get_model_size_in_byt": 85, "batch_siz": [85, 88], "ref": 85, "namedtemporaryfil": 85, "seek": [85, 87], "load": [85, 91], "meta": [85, 91], "m_load": 85, "load_state_dict": 85, "assign": 85, "assert": [85, 88, 90, 91], "equal": [85, 87], "float_weight1": 85, "float_weight2": 85, "quantized_weight1": 85, "quantized_weight2": 85, "go": [85, 90, 94], "techinqu": 85, "reduct": [85, 87, 90], "4x": 85, "0625": 85, "reason": [85, 87], "avoid": [85, 87], "properli": 85, "003": [86, 93, 94], "total": [86, 93, 94], "galleri": [86, 92, 94], "mem": [86, 93], "templat": [86, 92, 93], "tutorials_sourc": 86, "template_tutori": [86, 93, 94], "neural": 87, "network": [87, 90], "overhead": [87, 91], "latenc": 87, "carefulli": 87, "signific": 87, "pai": 87, "price": 87, "qualiti": 87, "f1": 87, "problem": [87, 90], "research": [87, 94], "face": 87, "fragment": 87, "rightfulli": 87, "spent": 87, "compress": 87, "place": 87, "dens": 87, "solv": [87, 90], "focu": [87, 90], "realli": 87, "push": [87, 91], "concret": 87, "hope": 87, "modular": 87, "acceler": 87, "scratch": [87, 94], "minim": 87, "recov": 87, "algorthim": 87, "realiz": 87, "trade": 87, "off": 87, "degrad": 87, "theoret": 87, "gain": 87, "2x": 87, "analog": 87, "fix": [87, 88], "unstructur": 87, "One": [87, 90, 91], "close": 87, "relat": 87, "mitig": 87, "retrain": 87, "neglig": 87, "area": 87, "agre": 87, "upon": 87, "consensu": 87, "mind": 87, "thought": 87, "subproblem": 87, "satisfi": 87, "consist": [87, 90], "answer": 87, "independ": 87, "frontend": 87, "arbitrari": 87, "handoff": 87, "piec": 87, "miss": 87, "natur": [87, 90], "present": 87, "clear": 87, "contract": 87, "7x": 87, "advantag": 87, "anticip": 87, "mani": [87, 90], "solut": 87, "third": 87, "parti": 87, "to_sparse_semi_structur": 87, "sparsesemistructuredtensor": 87, "weightnormsparsifi": 87, "half": 87, "subnetwork": 87, "sparse_config": 87, "named_modul": 87, "append": 87, "tensor_fqn": 87, "sparse_block_shap": 87, "zeros_per_block": 87, "fakespars": 87, "manipul": 87, "dictionari": 87, "paramer": 87, "parameter": 87, "necessari": [87, 88, 90], "ve": 87, "suitabl": 87, "fuse": [87, 90], "0s": 87, "spot": 87, "definit": [87, 91], "academia": 87, "industri": 87, "often": [87, 90], "interchang": 87, "confus": 87, "distinct": 87, "behind": 87, "doesn": 87, "itself": [87, 90], "those": [87, 88, 90], "loos": 87, "speak": 87, "tightli": 87, "coupl": [87, 90], "nvidia": 87, "csc": 87, "fbgemm": 87, "qnnpack": 87, "descript": 87, "coordin": 87, "vector": 87, "locat": 87, "bsr": 87, "sparse_bsr": 87, "except": [87, 90], "scalar": 87, "csr": 87, "sparse_csr": 87, "sparse_csc": 87, "column": 87, "compact": 87, "sparse_matrix": 87, "1d": 87, "indexptr": 87, "\u00bd": 87, "bitmask": 87, "2bit": 87, "unprun": 87, "quit": [87, 90], "successfulli": 87, "These": [87, 90], "broken": 87, "down": 87, "Not": 87, "sensit": 87, "effect": [87, 88, 90], "best": 87, "subsequ": [87, 90], "infinit": 87, "lost": 87, "degre": 87, "analysi": 87, "drop": 87, "give": [87, 90], "proxi": 87, "aforement": 87, "smallest": 87, "absolut": 87, "global": [87, 90], "scope": 87, "impli": 87, "pro": 87, "con": 87, "tradeoff": 87, "span": 87, "threshold": 87, "increas": 87, "complex": 87, "constant": [87, 90], "ctr_mobile_fe": 87, "score": 87, "w": [87, 91], "tenosr": 87, "udpat": 87, "cannot": [87, 88, 91], "histori": 87, "regrow": 87, "dw": 87, "via": 87, "backprop": 87, "pat": 87, "unmask": 87, "resid": 87, "salienc": 87, "lowest": 87, "l1": 87, "shown": 87, "abl": [87, 90, 91], "repeat": 87, "shot": 87, "movement": 87, "tune": 87, "2005": 87, "07683": 87, "rank": [87, 90], "wx": 87, "sqx": 87, "q": 87, "usual": 87, "sort": 87, "wise": 87, "reconstruct": [87, 91], "random": 87, "randomli": 87, "tri": 87, "remedi": 87, "item": [87, 94], "ultim": [87, 88], "literatur": 87, "vision": 87, "nlp": [87, 94], "iter": 87, "ctr_feed": 87, "na": 87, "multimask": 87, "pyspeech": 87, "fastna": 87, "approach": [87, 90], "knowledg": [87, 94], "distil": 87, "pdf": 87, "2204": 87, "09656": 87, "arrang": 87, "recal": 87, "counterpart": 87, "slower": 87, "suffici": 87, "flexibl": [87, 90], "98": 87, "benefit": [87, 90], "special": 87, "exhibit": 87, "maintain": 87, "penalti": 87, "expens": [87, 90], "dictat": 87, "characterist": 87, "highest": 87, "wouldn": [87, 90], "visual": 87, "fig": 87, "4x4": 87, "benchmak": 87, "unlik": 88, "batch": 88, "fly": 88, "welcom": 88, "histogram": 88, "act_ob": 88, "finfo": 88, "weight_ob": 88, "observed_input": 88, "observed_weight": 88, "cl": [88, 90, 91], "float_linear": 88, "observed_linear": 88, "_replace_with_custom_fn_if_matches_filt": 88, "insert_observers_": 88, "_is_linear": 88, "lambda": [88, 91], "replacement_fn": 88, "copied_act_ob": 88, "copied_weight_ob": 88, "popul": 88, "feed": 88, "simpler": 88, "quantizedlinear": [88, 90], "isn": 88, "strictli": 88, "to_affine_quantized_intx_stat": 88, "act_scal": 88, "act_zero_point": 88, "weight_scal": 88, "weight_zero_point": 88, "qweight": 88, "qinput": 88, "from_observ": 88, "begin": [88, 90], "dataclass": [88, 91], "transform_modul": [88, 91], "register_quantize_module_handl": [88, 91], "staticquantconfig": 88, "_apply_static_qu": 88, "is_observed_linear": 88, "optimizedmodul": 88, "_orig_mod": 88, "0237": 88, "plainaqttensorimpl": 88, "142": 88, "31": 88, "113": 88, "157": 88, "57": 88, "59": 88, "160": 88, "70": 88, "150": 88, "67": 88, "241": 88, "238": 88, "69": 88, "235": 88, "228": 88, "255": 88, "201": 88, "114": 88, "236": 88, "88": 88, "83": 88, "109": 88, "209": 88, "92": 88, "184": 88, "141": 88, "110": 88, "0009": 88, "0010": 88, "130": 88, "122": 88, "132": 88, "125": 88, "126": 88, "129": 88, "127": [88, 90], "133": 88, "124": 88, "131": 88, "135": 88, "136": 88, "soon": 89, "foundat": 90, "extens": 90, "autograd": 90, "express": 90, "interpos": 90, "namespac": 90, "continu": 90, "seamlessli": 90, "obviou": 90, "int8quantizedlinear": 90, "few": 90, "finer": 90, "intercept": 90, "contrast": 90, "long": 90, "clunki": 90, "distributedlinear": 90, "duplic": 90, "bypass": 90, "offer": 90, "outer": 90, "inner": 90, "allgath": 90, "bandwidth": 90, "rest": 90, "read": 90, "document": [90, 91], "zoo": 90, "podcast": 90, "edward": 90, "yang": 90, "int8_symmetric_quant": 90, "fp32_tensor": 90, "amin": 90, "keepdim": 90, "amax": 90, "zeros_lik": 90, "clamp": 90, "w_int8": 90, "new_linear": 90, "left": 90, "toymodel": 90, "float_model": 90, "quantized_model": 90, "child": 90, "named_children": 90, "setattr": 90, "drawback": 90, "won": 90, "suppos": 90, "clean": 90, "eleg": 90, "pretti": 90, "power": [90, 91], "overrid": 90, "almost": 90, "shard": [90, 91], "ragged": 90, "rag": 90, "nestedtensor": 90, "resourc": 90, "who": 90, "link": [90, 94], "googl": 90, "collab": 90, "flopcount": 90, "memorytrack": 90, "With": 90, "bare": 90, "bone": 90, "int8symmetrictensor": 90, "hold": 90, "staticmethod": 90, "disabl": 90, "__new__": [90, 91], "_make_wrapper_subclass": [90, 91], "storage_offset": 90, "ndim": 90, "__tensor_flatten__": [90, 91], "attribut": [90, 91], "pt2": 90, "__tensor_unflatten__": [90, 91], "tensor_data_dict": [90, 91], "extra_metadata": 90, "outer_s": [90, 91], "outer_strid": [90, 91], "undo": 90, "__repr__": 90, "repr": 90, "ahead": 90, "insid": 90, "int8_tensor": 90, "func": [90, 91], "op_implementations_dict": 90, "conveni": 90, "register_op": 90, "_op": 90, "opoverload": 90, "impl_decor": 90, "op_impl": 90, "wrapper": 90, "particular": 90, "largest": 90, "tell": 90, "desugar": 90, "decor": [90, 91], "surfac": 90, "coverag": 90, "though": 90, "brute": 90, "forc": 90, "repeatedli": 90, "loggingtensor": 90, "_python_dispatch": [90, 91], "return_and_correct_alias": [90, 91], "int8_mm": 90, "detach": [90, 91], "int8_view_op": 90, "out_data": 90, "out_scal": 90, "notic": 90, "hit": 90, "background": 90, "decomposit": 90, "live": 90, "decomp": 90, "shrink": 90, "author": [90, 94], "pain": 90, "rather": 90, "underli": 90, "worth": 90, "written": 90, "differenti": 90, "nuanc": 90, "longer": 90, "That": 90, "transposit": 90, "got": 90, "propag": 90, "fact": 90, "themselv": 90, "pointwis": 90, "alwai": 90, "were": 90, "might": [90, 91], "unwrap": 90, "dim0": 90, "dim1": 90, "confirm": 90, "quantized_model_module_swap": 90, "quantized_model_subclass": 90, "subclass_param": 90, "no_grad": 90, "out_module_swap": 90, "allclos": 90, "out_compil": 90, "seri": 90, "wa": 90, "comprehens": 91, "e2": 91, "json": 91, "model_typ": 91, "quant_typ": 91, "_type": 91, "int4weightonlyconfig": 91, "_data": 91, "capabl": 91, "modulefqntoconfig": 91, "int8weightonlyconfig": 91, "self_attn": 91, "q_proj": 91, "k_proj": 91, "mlp": 91, "gate_proj": 91, "_default": 91, "torchaoconfig": 91, "automodelforcausallm": 91, "quantization_config": 91, "1b": 91, "torch_dtyp": 91, "auto": 91, "device_map": 91, "safe_seri": 91, "usernam": 91, "server": 91, "narrow": 91, "copy_": 91, "state": 91, "slice": 91, "chunk": 91, "_apply_fn_to_data": 91, "heavi": 91, "codebas": 91, "fn": 91, "ctx": 91, "new_tensor": 91, "getattr": 91, "__class__": 91, "principl": 91, "torchaobasetensor": 91, "mynewquantconfig": 91, "classvar": 91, "myquantizedtensor": 91, "fbgemmfp8tensor": 91, "tensor_data_attr": 91, "tensor_attribut": 91, "attr": 91, "_to_copi": 91, "clone": 91, "fill_default": 91, "notimplementederror": 91, "_my_quant_transform": 91, "my_quantization_funct": 91, "len": 91, "use_cutlass_kernel": 91, "my_cutlass_linear": 91, "elif": 91, "use_triton_kernel": 91, "my_triton_linear": 91, "disappear": 91, "extrem": 91, "sole": 91, "think": 91, "littl": 91, "world": 91, "explicitli": 91, "spooki": 91, "action": 91, "distanc": 91, "statu": 91, "due": 91, "hub": 91, "team": 91, "2338": 91, "creation": 91, "detect": 91, "illustr": 91, "tutorials_python": 92, "zip": [92, 94], "jupyt": [92, 94], "notebook": [92, 94], "tutorials_jupyt": 92, "sphinx": [92, 94], "firstnam": 94, "lastnam": 94, "prerequisit": 94, "v2": 94, "topic": 94, "rand": 94, "2172": 94, "1202": 94, "9321": 94, "5316": 94, "0105": 94, "2214": 94, "7006": 94, "3852": 94, "0332": 94, "0336": 94, "2980": 94, "8532": 94, "3065": 94, "5227": 94, "0592": 94, "practic": 94, "test": 94, "summar": 94, "takeawai": 94, "link1": 94, "link2": 94, "minut": 94, "ipynb": 94}, "objects": {"torchao.dtypes": [[8, 0, 1, "", "AffineQuantizedTensor"], [9, 0, 1, "", "BlockSparseLayout"], [10, 0, 1, "", "CutlassInt4PackedLayout"], [11, 0, 1, "", "CutlassSemiSparseLayout"], [12, 0, 1, "", "Float8Layout"], [13, 0, 1, "", "Int4CPULayout"], [14, 0, 1, "", "Layout"], [15, 0, 1, "", "MarlinQQQLayout"], [16, 0, 1, "", "MarlinQQQTensor"], [17, 0, 1, "", "MarlinSparseLayout"], [18, 0, 1, "", "NF4Tensor"], [19, 0, 1, "", "PlainLayout"], [20, 0, 1, "", "SemiSparseLayout"], [21, 0, 1, "", "TensorCoreTiledLayout"], [22, 0, 1, "", "UintxLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[8, 1, 1, "", "dequantize"], [8, 1, 1, "", "from_hp_to_floatx"], [8, 1, 1, "", "from_hp_to_floatx_static"], [8, 1, 1, "", "from_hp_to_fpx"], [8, 1, 1, "", "from_hp_to_intx"], [8, 1, 1, "", "from_hp_to_intx_static"], [8, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[17, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[18, 1, 1, "", "convert_to_norm_float_weight"], [18, 1, 1, "", "dequantize"], [18, 1, 1, "", "dequantize_scalers"], [18, 1, 1, "", "double_quantize_scalers"], [18, 1, 1, "", "get_original_weight"], [18, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingGranularity"], [33, 0, 1, "", "ScalingType"], [34, 2, 1, "", "convert_to_float8_training"], [35, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[36, 0, 1, "", "FPXWeightOnlyConfig"], [37, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [38, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [39, 0, 1, "", "Float8WeightOnlyConfig"], [40, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [41, 0, 1, "", "Int4WeightOnlyConfig"], [42, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [43, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [44, 0, 1, "", "Int8WeightOnlyConfig"], [45, 0, 1, "", "MappingType"], [46, 0, 1, "", "TorchAODType"], [47, 0, 1, "", "UIntXWeightOnlyConfig"], [48, 0, 1, "", "ZeroPointDomain"], [49, 2, 1, "", "autoquant"], [50, 2, 1, "", "choose_qparams_affine"], [51, 2, 1, "", "choose_qparams_affine_floatx"], [52, 2, 1, "", "choose_qparams_affine_with_min_max"], [53, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [54, 2, 1, "", "dequantize_affine"], [55, 2, 1, "", "dequantize_affine_floatx"], [56, 2, 1, "", "fake_quantize_affine"], [57, 2, 1, "", "fake_quantize_affine_cachemask"], [58, 2, 1, "", "int_scaled_matmul"], [67, 2, 1, "", "quantize_"], [68, 2, 1, "", "quantize_affine"], [69, 2, 1, "", "quantize_affine_floatx"], [70, 2, 1, "", "safe_int_mm"], [71, 2, 1, "", "smooth_fq_linear_to_inference"], [72, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [73, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[59, 0, 1, "", "ComposableQATQuantizer"], [60, 0, 1, "", "FakeQuantizeConfig"], [61, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [62, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [63, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [64, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [65, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [66, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizeConfig": [[60, 3, 1, "", "group_size"], [60, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[62, 1, 1, "", "convert"], [62, 1, 1, "", "prepare"]], "torchao": [[5, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[74, 0, 1, "", "PerChannelNormObserver"], [75, 0, 1, "", "WandaSparsifier"], [76, 2, 1, "", "apply_fake_sparsity"], [77, 2, 1, "", "int8_dynamic_activation_int8_semi_sparse_weight"], [78, 5, 1, "", "semi_sparse_weight"], [79, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[74, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[75, 1, 1, "", "prepare"], [75, 1, 1, "", "squash_mask"], [75, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:module", "5": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "module", "Python module"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 80, 82, 83, 91], "dtype": [0, 7, 83], "layout": [0, 6, 14, 83], "tensor": [0, 6, 83, 89, 90, 91], "subclass": [0, 6, 83, 90, 91], "quantiz": [0, 4, 67, 83, 84, 88, 89, 90, 91], "techniqu": 0, "float8": [1, 82], "main": [1, 4], "train": [1, 83], "api": [1, 2, 4, 80, 82], "other": [1, 4, 6, 83], "type": 1, "refer": [2, 80], "python": 2, "kernel": [3, 6, 81, 83, 91], "infer": 4, "quantize_": 4, "qat": 4, "primit": [4, 83], "sparsiti": [5, 87], "contributor": 6, "guid": [6, 84, 91], "gener": 6, "extend": 6, "ad": [6, 83, 91], "effici": [6, 83], "custom": 6, "triton": 6, "hand": 6, "written": 6, "dispatch": [6, 91], "tensorimpl": [6, 83], "flow": [6, 83, 85, 91], "us": 6, "torch": 6, "compil": [6, 91], "perform": [6, 81], "serial": [6, 85, 91], "featur": 6, "support": [6, 83, 91], "function": [6, 83], "compos": 6, "test": 6, "microbenchmark": 6, "model": [6, 82, 83, 85, 91], "benchmark": 6, "eval": 6, "affinequantizedtensor": 8, "blocksparselayout": 9, "cutlassint4packedlayout": 10, "cutlasssemisparselayout": 11, "float8layout": 12, "int4cpulayout": 13, "marlinqqqlayout": 15, "marlinqqqtensor": 16, "marlinsparselayout": 17, "nf4tensor": 18, "plainlayout": 19, "semisparselayout": 20, "tensorcoretiledlayout": 21, "uintxlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalinggranular": 32, "scalingtyp": 33, "convert_to_float8_train": 34, "precompute_float8_dynamic_scale_for_fsdp": 35, "fpxweightonlyconfig": 36, "float8dynamicactivationfloat8weightconfig": 37, "float8staticactivationfloat8weightconfig": 38, "float8weightonlyconfig": 39, "gemliteuintxweightonlyconfig": 40, "int4weightonlyconfig": 41, "int8dynamicactivationint4weightconfig": 42, "int8dynamicactivationint8weightconfig": 43, "int8weightonlyconfig": 44, "mappingtyp": 45, "torchaodtyp": 46, "uintxweightonlyconfig": 47, "zeropointdomain": 48, "autoqu": 49, "choose_qparams_affin": 50, "choose_qparams_affine_floatx": 51, "choose_qparams_affine_with_min_max": 52, "choose_qparams_and_quantize_affine_hqq": 53, "dequantize_affin": 54, "dequantize_affine_floatx": 55, "fake_quantize_affin": 56, "fake_quantize_affine_cachemask": 57, "int_scaled_matmul": 58, "composableqatquant": 59, "fakequantizeconfig": 60, "fromintxquantizationawaretrainingconfig": 61, "int4weightonlyembeddingqatquant": 62, "int4weightonlyqatquant": 63, "int8dynactint4weightqatquant": 64, "intxquantizationawaretrainingconfig": 65, "initialize_fake_quant": 66, "quantize_affin": 68, "quantize_affine_floatx": 69, "safe_int_mm": 70, "smooth_fq_linear_to_infer": 71, "swap_linear_with_smooth_fq_linear": 72, "to_linear_activation_quant": 73, "perchannelnormobserv": 74, "wandasparsifi": 75, "apply_fake_spars": 76, "int8_dynamic_activation_int8_semi_sparse_weight": 77, "semi_sparse_weight": 78, "sparsifi": 79, "welcom": 80, "document": 80, "get": 80, "start": [80, 84], "develop": 80, "note": [80, 82], "tutori": [80, 94], "pretrain": 82, "torchtitan": 82, "prerequisit": 82, "rowwis": 82, "scale": 82, "tensorwis": 82, "pick": 82, "recip": 82, "import": 82, "directli": 82, "convers": 82, "overview": [83, 87, 94], "basic": 83, "current": 83, "placehold": 83, "pytorch": 83, "implement": [83, 90, 91], "oper": [83, 90, 91], "integr": [83, 91], "nativ": 83, "factori": 83, "op": 83, "deriv": 83, "algorithm": 83, "weight": 83, "onli": 83, "dynam": 83, "activ": 83, "static": [83, 88], "insert": 83, "observ": 83, "how": 83, "defin": 83, "modul": [83, 90, 91], "add": [83, 91], "calibr": [83, 88], "awar": 83, "low": 83, "bit": 83, "optim": [83, 85], "case": 83, "studi": 83, "int4": 83, "work": 83, "dure": 83, "execut": 83, "save": 83, "load": 83, "quick": 84, "first": 84, "exampl": [84, 91], "next": [84, 90], "step": [84, 90, 91, 94], "deseri": 85, "what": [85, 90], "happen": 85, "when": 85, "an": 85, "comput": [86, 93], "time": [86, 93], "goal": 87, "design": 87, "context": 87, "prune": 87, "configur": [87, 91], "criteria": 87, "strategi": 87, "pattern": 87, "phase": 88, "write": [89, 90], "your": [89, 90, 91], "own": [89, 90], "advanc": 89, "ar": 90, "swap": 90, "which": 90, "should": 90, "we": 90, "compar": 90, "output": 90, "vllm": 91, "architectur": 91, "usag": 91, "system": 91, "1": 91, "huggingfac": 91, "2": 91, "class": 91, "3": 91, "level": 91, "serv": 91, "new": 91, "method": 91, "minim": 91, "requir": 91, "compat": 91, "why": 91, "creat": 91, "regist": 91, "s": 91, "kei": 91, "detail": 91, "hardwar": 91, "specif": 91, "linear": 91, "benefit": 91, "trade": 91, "off": 91, "share": 91, "safetensor": 91, "diagram": 91, "high": 91, "transform": 91, "point": 91, "bring": 91, "extern": 91, "templat": 94, "option": 94, "addit": 94, "exercis": 94, "conclus": 94, "further": 94, "read": 94}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})