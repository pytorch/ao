Search.setIndex({"docnames": ["api_reference/api_ref_float8", "api_reference/api_ref_kernel", "api_reference/api_ref_qat", "api_reference/api_ref_quantization", "api_reference/api_ref_sparsity", "api_reference/api_ref_utils", "api_reference/generated/torchao.float8.CastConfig", "api_reference/generated/torchao.float8.Float8LinearConfig", "api_reference/generated/torchao.float8.Float8LinearRecipeName", "api_reference/generated/torchao.float8.ScalingGranularity", "api_reference/generated/torchao.float8.ScalingType", "api_reference/generated/torchao.float8.convert_to_float8_training", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig", "api_reference/generated/torchao.quantization.FqnToConfig", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer", "api_reference/generated/torchao.quantization.qat.QATConfig", "api_reference/generated/torchao.quantization.qat.QATStep", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "api_reference/generated/torchao.quantization.quantize_", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "api_reference/generated/torchao.sparsity.PerChannelNormObserver", "api_reference/generated/torchao.sparsity.WandaSparsifier", "api_reference/generated/torchao.sparsity.apply_fake_sparsity", "api_reference/generated/torchao.sparsity.semi_sparse_weight", "api_reference/generated/torchao.sparsity.sparsify_", "api_reference/generated/torchao.utils.TorchAOBaseTensor", "api_reference/index", "developer_notes/benchmarking_api_guide", "developer_notes/benchmarking_user_guide", "developer_notes/contributor_guide", "developer_notes/index", "developer_notes/quantization_overview", "developer_notes/sparsity", "eager_quantization/finetuning", "eager_quantization/first_quantization_example", "eager_quantization/index", "eager_quantization/pretraining", "eager_quantization/serialization", "eager_quantization/serving", "eager_quantization/static_quantization", "eager_quantization/subclass_advanced", "eager_quantization/subclass_basic", "eager_quantization/torchao_hf_integration", "eager_quantization/torchao_vllm_integration", "index", "performant_kernels", "pt2e_quantization/index", "pt2e_quantization/pt2e_quant_openvino_inductor", "pt2e_quantization/pt2e_quant_ptq", "pt2e_quantization/pt2e_quant_qat", "pt2e_quantization/pt2e_quant_x86_inductor", "pt2e_quantization/pt2e_quant_xpu_inductor", "pt2e_quantization/pt2e_quantizer", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "workflows/index", "workflows/qat"], "filenames": ["api_reference/api_ref_float8.rst", "api_reference/api_ref_kernel.rst", "api_reference/api_ref_qat.rst", "api_reference/api_ref_quantization.rst", "api_reference/api_ref_sparsity.rst", "api_reference/api_ref_utils.rst", "api_reference/generated/torchao.float8.CastConfig.rst", "api_reference/generated/torchao.float8.Float8LinearConfig.rst", "api_reference/generated/torchao.float8.Float8LinearRecipeName.rst", "api_reference/generated/torchao.float8.ScalingGranularity.rst", "api_reference/generated/torchao.float8.ScalingType.rst", "api_reference/generated/torchao.float8.convert_to_float8_training.rst", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.FqnToConfig.rst", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.rst", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.rst", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.QATConfig.rst", "api_reference/generated/torchao.quantization.qat.QATStep.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.quantize_.rst", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.rst", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.rst", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "api_reference/generated/torchao.sparsity.PerChannelNormObserver.rst", "api_reference/generated/torchao.sparsity.WandaSparsifier.rst", "api_reference/generated/torchao.sparsity.apply_fake_sparsity.rst", "api_reference/generated/torchao.sparsity.semi_sparse_weight.rst", "api_reference/generated/torchao.sparsity.sparsify_.rst", "api_reference/generated/torchao.utils.TorchAOBaseTensor.rst", "api_reference/index.rst", "developer_notes/benchmarking_api_guide.md", "developer_notes/benchmarking_user_guide.md", "developer_notes/contributor_guide.rst", "developer_notes/index.rst", "developer_notes/quantization_overview.rst", "developer_notes/sparsity.rst", "eager_quantization/finetuning.rst", "eager_quantization/first_quantization_example.rst", "eager_quantization/index.rst", "eager_quantization/pretraining.rst", "eager_quantization/serialization.rst", "eager_quantization/serving.rst", "eager_quantization/static_quantization.rst", "eager_quantization/subclass_advanced.rst", "eager_quantization/subclass_basic.rst", "eager_quantization/torchao_hf_integration.md", "eager_quantization/torchao_vllm_integration.md", "index.rst", "performant_kernels.rst", "pt2e_quantization/index.rst", "pt2e_quantization/pt2e_quant_openvino_inductor.rst", "pt2e_quantization/pt2e_quant_ptq.rst", "pt2e_quantization/pt2e_quant_qat.rst", "pt2e_quantization/pt2e_quant_x86_inductor.rst", "pt2e_quantization/pt2e_quant_xpu_inductor.rst", "pt2e_quantization/pt2e_quantizer.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "workflows/index.md", "workflows/qat.md"], "titles": ["torchao.float8", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "CastConfig", "Float8LinearConfig", "Float8LinearRecipeName", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MXDynamicActivationMXWeightConfig", "NVFP4DynamicActivationNVFP4WeightConfig", "NVFP4WeightOnlyConfig", "Float8DynamicActivationFloat8SemiSparseWeightConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8DynamicActivationIntxWeightConfig", "Int8WeightOnlyConfig", "IntxWeightOnlyConfig", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "API Reference", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Developer Notes", "Quantization Overview", "Sparsity Overview", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "First Quantization Example", "Eager Quantization Tutorials", "(Part 1) Pre-training with float8", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "Welcome to the torchao Documentation", "Performant Kernels", "PT2E Quantization Tutorials", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization", "&lt;no title&gt;", "Computation times", "Template Tutorial", "Workflows", "Quantization-Aware Training (QAT)"], "terms": {"tba": [1, 81], "For": [2, 40, 63, 65, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 93], "full": [2, 69, 75, 78, 82, 83, 85, 91, 93], "exampl": [2, 11, 12, 17, 19, 21, 23, 25, 27, 29, 30, 35, 39, 40, 42, 46, 51, 52, 57, 60, 61, 63, 65, 67, 68, 69, 71, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 87, 89, 91, 93], "how": [2, 18, 23, 40, 52, 53, 65, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 82, 83, 86, 87, 92], "us": [2, 6, 8, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 35, 39, 40, 42, 47, 48, 52, 53, 57, 61, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 92, 93], "our": [2, 65, 68, 69, 70, 72, 74, 75, 77, 80, 84, 85, 93], "pleas": [2, 35, 39, 61, 64, 65, 67, 68, 69, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 93], "refer": [2, 42, 48, 63, 68, 69, 72, 74, 75, 77, 78, 79, 83, 84, 85, 86, 93], "readm": [2, 63, 68, 69, 70, 80, 92], "class": [6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52, 53, 54, 56, 57, 61, 63, 65, 69, 70, 73, 75, 77, 82, 84, 85, 86, 88, 93], "torchao": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 70, 73, 74, 75, 77, 78, 82, 83, 84, 85, 86, 87, 92], "float8": [6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 55, 62, 71, 74, 75, 80, 92], "scaling_typ": [6, 7], "scalingtyp": [6, 7], "dynam": [6, 7, 8, 10, 12, 14, 16, 17, 18, 22, 23, 24, 32, 38, 40, 48, 60, 65, 69, 74, 75, 77, 78, 84, 85, 86, 93], "scaling_granular": [6, 7], "scalinggranular": [6, 7], "tensorwis": [6, 7, 8, 9, 11, 17, 67, 69], "target_dtyp": [6, 7, 67, 75], "option": [6, 7, 8, 11, 17, 20, 23, 24, 25, 26, 29, 30, 32, 33, 37, 39, 40, 42, 44, 45, 51, 52, 55, 57, 60, 61, 63, 65, 67, 70, 72, 78, 79, 80, 82, 84, 85, 86, 87, 88], "dtype": [6, 11, 13, 16, 17, 19, 24, 26, 29, 30, 32, 33, 36, 37, 38, 40, 44, 45, 47, 48, 55, 60, 63, 65, 69, 70, 72, 73, 74, 75, 77, 78, 79, 84, 86, 87, 88, 93], "none": [6, 7, 8, 9, 10, 11, 12, 17, 20, 24, 25, 26, 29, 30, 32, 33, 39, 40, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 55, 57, 60, 61, 67, 69, 75, 77, 79, 83, 84, 85, 87], "sourc": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 74, 89, 91], "configur": [6, 7, 8, 11, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 51, 60, 67, 69, 72, 74, 78, 86, 87, 88, 93], "cast": [6, 9, 10, 69, 93], "singl": [6, 9, 12, 17, 65, 68, 69, 72, 84, 88, 93], "tensor": [6, 8, 9, 10, 14, 16, 19, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 41, 52, 53, 54, 55, 57, 61, 63, 68, 69, 70, 71, 72, 73, 75, 78, 84, 86, 87, 91, 92], "paramet": [6, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 40, 42, 45, 47, 48, 51, 57, 60, 61, 63, 67, 68, 69, 72, 73, 74, 77, 79, 83, 84, 93], "The": [6, 11, 12, 17, 19, 20, 24, 26, 42, 51, 57, 63, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 83, 84, 85, 86, 87, 88, 93], "type": [6, 7, 8, 9, 10, 11, 16, 17, 19, 20, 22, 23, 24, 26, 40, 43, 51, 52, 53, 54, 55, 61, 63, 65, 67, 68, 69, 70, 73, 74, 77, 79, 80, 83, 84, 86, 87, 88, 93], "scale": [6, 8, 9, 10, 12, 14, 17, 24, 26, 32, 33, 40, 45, 46, 47, 48, 55, 65, 67, 68, 75, 77, 79, 88, 93], "see": [6, 24, 26, 61, 63, 65, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80, 83, 84, 88, 92, 93], "default": [6, 8, 14, 17, 19, 21, 24, 32, 40, 48, 51, 61, 65, 67, 69, 72, 77, 79, 82, 83, 84, 85, 86, 87, 88], "granular": [6, 9, 17, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 40, 41, 65, 67, 72, 74, 75, 79], "target": [6, 17, 19, 21, 29, 30, 33, 40, 57, 63, 65, 68, 69, 82, 83, 84, 85, 86, 87, 88, 93], "e": [6, 20, 27, 40, 42, 51, 54, 61, 65, 67, 69, 72, 73, 75, 77, 78, 80, 83, 88, 93], "g": [6, 20, 27, 40, 42, 51, 54, 61, 65, 67, 69, 73, 75, 77, 83, 88, 93], "torch": [6, 7, 11, 13, 16, 17, 19, 21, 24, 26, 29, 30, 32, 33, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 51, 52, 60, 61, 63, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 82, 86, 87, 88, 91, 93], "float8_e4m3fn": [6, 13, 14, 16, 17, 19, 33, 67], "set": [6, 17, 19, 21, 22, 23, 25, 40, 51, 57, 61, 68, 69, 83, 85, 86, 87, 93], "base": [6, 10, 17, 20, 24, 26, 28, 41, 42, 46, 52, 54, 55, 57, 61, 65, 67, 68, 70, 77, 78, 79, 83, 84, 85, 86, 87, 88, 93], "recip": [6, 7, 8, 11, 29, 34, 44, 56, 69, 93], "cast_config_input": 7, "config": [7, 11, 17, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 51, 57, 60, 63, 67, 68, 69, 70, 74, 75, 78, 79, 82, 84, 86, 87, 93], "castconfig": 7, "cast_config_input_for_grad_weight": 7, "cast_config_weight": 7, "cast_config_weight_for_grad_input": 7, "cast_config_grad_output": 7, "cast_config_grad_output_for_grad_weight": 7, "gemm_config_output": 7, "float8gemmconfig": 7, "use_fast_accum": 7, "true": [7, 11, 14, 15, 17, 19, 21, 22, 23, 25, 29, 30, 39, 40, 42, 50, 51, 60, 65, 69, 70, 72, 73, 74, 75, 77, 78, 79, 82, 83, 84, 85, 86, 88], "gemm_config_grad_input": 7, "fals": [7, 11, 23, 29, 30, 38, 39, 40, 42, 44, 45, 47, 48, 57, 63, 67, 69, 70, 72, 73, 74, 75, 77, 78, 79, 83, 84, 85, 87, 88, 93], "gemm_config_grad_weight": 7, "enable_fsdp_float8_all_gath": 7, "bool": [7, 11, 14, 15, 17, 19, 21, 22, 23, 25, 29, 30, 38, 40, 44, 45, 47, 48, 50, 51, 60, 69, 75], "pad_inner_dim": 7, "emul": [7, 52], "force_recompute_fp8_weight_in_bwd": 7, "round_scales_to_power_of_2": 7, "convert": [7, 11, 27, 35, 36, 42, 51, 60, 67, 68, 69, 72, 74, 83, 86, 87, 88, 93], "nn": [7, 11, 27, 32, 36, 39, 42, 51, 60, 61, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 79, 82, 84, 85, 86, 88, 93], "linear": [7, 11, 16, 17, 18, 19, 22, 23, 25, 27, 30, 32, 37, 38, 39, 42, 47, 48, 49, 50, 51, 58, 60, 61, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 82, 83, 84, 85, 86, 88, 93], "modul": [7, 8, 9, 10, 11, 12, 13, 20, 27, 29, 31, 32, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 60, 63, 65, 67, 69, 70, 72, 73, 75, 79, 82, 83, 84, 85, 86, 87, 88, 93], "train": [7, 8, 11, 27, 40, 42, 65, 68, 71, 77, 82, 88], "static": [7, 40, 71, 82, 84, 85, 86, 87, 88], "from_recipe_nam": [7, 11], "recipe_nam": [7, 72], "union": [7, 17, 33, 40, 51], "float8linearrecipenam": 7, "str": [7, 11, 20, 40, 42, 51, 57, 60, 61, 63, 72, 77, 79, 87], "input": [7, 11, 12, 14, 42, 46, 51, 57, 60, 63, 65, 67, 70, 72, 74, 75, 77, 82, 83, 84, 85, 86, 87, 88], "valu": [7, 8, 9, 10, 17, 19, 21, 22, 23, 25, 33, 43, 52, 53, 57, 67, 68, 69, 75, 77, 83, 84, 85, 88, 93], "string": [7, 40, 57, 61, 63], "repres": [7, 28, 40, 53, 57, 65, 67, 73, 77, 84, 85, 93], "output": [7, 65, 67, 68, 69, 70, 72, 74, 78, 82, 83, 84, 85, 86, 87, 88, 91, 93], "implement": [7, 21, 44, 45, 47, 48, 52, 61, 65, 67, 68, 69, 73, 75, 83, 84, 88], "specifi": [7, 11, 20, 24, 25, 26, 27, 29, 30, 31, 34, 41, 42, 48, 51, 52, 57, 60, 65, 67, 68, 69, 72, 83, 84, 85, 88, 93], "name": [8, 9, 10, 11, 20, 43, 51, 52, 53, 57, 60, 61, 63, 65, 67, 68, 74, 77, 79, 83, 84, 85, 88], "qualnam": [8, 9, 10, 43, 52, 53], "start": [8, 9, 10, 20, 43, 52, 53, 65, 67, 68, 69, 70, 72, 74, 75, 77, 79, 83, 84, 85, 86, 87, 88], "1": [8, 9, 10, 11, 17, 19, 20, 21, 23, 24, 25, 26, 33, 43, 52, 53, 55, 57, 61, 65, 67, 68, 70, 71, 73, 75, 77, 80, 82, 84, 85, 91, 92, 93], "boundari": [8, 9, 10, 43, 52, 53], "pre": [8, 68, 69, 71, 74, 80, 88], "made": [8, 88], "common": [8, 42, 52, 53, 54, 55, 62, 65, 67, 68, 72], "per": [8, 14, 18, 19, 22, 23, 24, 25, 32, 36, 37, 38, 40, 44, 45, 47, 48, 57, 65, 67, 68, 69, 72, 75, 87, 93], "cubla": 8, "kernel": [8, 14, 17, 18, 47, 51, 52, 62, 68, 74, 83, 86, 87, 93], "fastest": [8, 65], "rowwis": [8, 9, 11, 17, 32, 67, 92], "cutlass": 8, "e4m3": 8, "activ": [8, 14, 16, 17, 22, 23, 24, 29, 30, 32, 38, 39, 40, 42, 48, 54, 55, 57, 63, 68, 69, 74, 75, 78, 79, 80, 82, 83, 86, 87, 88, 92, 93], "weight": [8, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 36, 37, 38, 40, 42, 44, 45, 47, 48, 51, 54, 57, 60, 65, 68, 69, 72, 73, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 92, 93], "gradient": [8, 68, 80, 93], "ar": [8, 11, 17, 20, 21, 24, 26, 27, 29, 30, 39, 42, 51, 52, 53, 57, 61, 65, 67, 68, 69, 70, 72, 73, 74, 75, 79, 82, 83, 84, 85, 86, 87, 88, 93], "round": [8, 77, 93], "floor": 8, "nearest": 8, "power": [8, 77, 79], "two": [8, 17, 42, 61, 67, 68, 69, 77, 82, 83, 84, 85, 86, 88, 93], "increas": [8, 68, 69, 84], "accuraci": [8, 68, 69, 70, 72, 74, 75, 80, 83, 85, 86, 92, 93], "rowwise_with_gw_hp": [8, 11], "A": [8, 9, 52, 56, 61, 65, 67, 68, 69, 77, 78, 79, 84, 93], "modif": 8, "grad_weight": 8, "keep": [8, 23, 57, 65, 67, 84], "comput": [8, 9, 10, 12, 14, 19, 29, 34, 44, 52, 56, 57, 65, 67, 68, 75, 77, 78, 84, 85, 86, 87], "high": [8, 33, 42, 67, 68, 69, 72, 74, 75, 77, 83, 84, 86, 87], "precis": [8, 10, 19, 23, 32, 33, 37, 38, 42, 45, 47, 48, 67, 69, 75, 77, 78, 83, 86, 87], "most": [8, 42, 52, 64, 65, 67, 68, 74, 79, 84, 85, 88, 93], "accur": [8, 68, 72, 83], "defin": [9, 10, 29, 34, 44, 56, 57, 61, 63, 65, 67, 68, 75, 77, 79, 82, 83, 86, 87, 88], "strategi": 9, "factor": [9, 10, 68, 72], "entir": [9, 74, 84, 85], "axiswis": 9, "along": [9, 14, 68, 79, 83], "one": [9, 17, 24, 26, 29, 34, 42, 44, 56, 65, 67, 68, 72, 77, 79, 85, 88, 93], "axi": [9, 24, 26, 75], "": [10, 14, 20, 52, 53, 61, 65, 67, 68, 69, 70, 72, 74, 75, 77, 84, 85, 86, 87, 88, 93], "disabl": [10, 49, 77, 85], "skip": [10, 57, 67, 68], "thi": [10, 12, 13, 14, 17, 22, 23, 24, 25, 29, 34, 35, 40, 42, 44, 45, 47, 48, 51, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 83, 84, 85, 86, 87, 88, 91, 92, 93], "leav": [10, 40], "its": [10, 68, 69, 77, 79, 84, 88], "origin": [10, 19, 23, 35, 57, 63, 67, 68, 69, 70, 73, 74, 83, 84, 88], "module_filter_fn": [11, 72], "callabl": [11, 51, 60, 61, 79], "float8linearconfig": 11, "swap": [11, 32, 36, 68, 69, 72, 75, 85, 93], "float8linear": [11, 72], "modifi": [11, 51, 57, 65, 68, 72, 77], "If": [11, 17, 23, 25, 39, 40, 42, 57, 61, 63, 64, 65, 67, 68, 69, 74, 77, 84, 85], "onli": [11, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 32, 42, 48, 63, 65, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 83, 84, 86, 87, 88, 93], "subclass": [11, 29, 34, 44, 52, 53, 56, 60, 61, 67, 68, 69, 70, 73, 78], "pass": [11, 23, 29, 30, 34, 42, 44, 56, 61, 63, 67, 75, 77, 79, 85, 88], "filter": [11, 20, 65, 69, 72, 75, 93], "function": [11, 29, 34, 44, 49, 50, 51, 56, 57, 58, 60, 61, 63, 67, 68, 69, 70, 72, 73, 75, 77, 79, 82, 83, 88, 93], "instanc": [11, 29, 34, 44, 51, 56, 60, 61, 73, 77, 84, 86, 87, 88], "fqn": [11, 20, 57, 60, 72, 75], "convers": [11, 65, 69, 93], "return": [11, 40, 51, 60, 61, 63, 65, 67, 69, 70, 72, 73, 75, 77, 79, 82, 83, 84, 85, 86, 87, 88, 93], "layer": [11, 16, 17, 19, 20, 23, 25, 29, 30, 32, 36, 37, 38, 44, 45, 47, 48, 57, 58, 63, 68, 72, 74, 75, 77, 79, 83, 88, 93], "import": [11, 17, 19, 21, 23, 25, 35, 39, 42, 51, 60, 65, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80, 82, 83, 86, 87, 91, 93], "from": [11, 17, 19, 20, 21, 22, 23, 25, 35, 39, 42, 51, 52, 60, 61, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 91, 93], "creat": [11, 64, 65, 68, 70, 72, 77, 78, 83, 84, 86, 87, 88], "model": [11, 12, 17, 19, 21, 22, 23, 25, 27, 32, 35, 36, 37, 38, 39, 42, 46, 51, 57, 58, 60, 68, 69, 75, 77, 82, 86, 87, 88, 92, 93], "sampl": [11, 72, 84, 86, 87], "m": [11, 14, 51, 60, 63, 65, 69, 72, 73, 74, 75, 77, 82, 84, 85, 86, 93], "sequenti": [11, 51, 60, 72], "8192": 11, "4096": [11, 69, 72, 93], "bia": [11, 30, 47, 48, 63, 67, 69, 70, 73, 75, 77, 79, 85, 88], "128": [11, 14, 18, 21, 70, 72, 74, 75, 77, 78, 79, 87, 88, 93], "bfloat16": [11, 32, 37, 47, 63, 67, 68, 70, 72, 73, 74, 75, 78, 79, 86, 87, 92, 93], "cuda": [11, 21, 51, 63, 65, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 85, 93], "optim": [11, 12, 21, 24, 51, 65, 68, 69, 72, 77, 83, 85, 86, 87, 93], "sgd": [11, 69, 93], "lr": [11, 69, 72, 93], "0": [11, 14, 20, 24, 26, 29, 40, 44, 45, 57, 61, 63, 65, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 91, 93], "being": [11, 68, 72, 79, 86, 87], "elig": [11, 72], "def": [11, 54, 60, 61, 63, 65, 67, 69, 70, 72, 73, 75, 77, 79, 82, 83, 84, 85, 86, 87, 88, 93], "mod": [11, 49, 50, 68, 72, 77], "don": [11, 20, 57, 65, 67, 68, 70, 72, 78, 79, 88], "t": [11, 14, 20, 57, 61, 65, 67, 68, 70, 72, 75, 77, 78, 79, 84, 85, 88], "last": [11, 72, 83], "dimens": [11, 14, 63, 65, 67, 72, 77, 79, 84, 85], "divis": [11, 72], "16": [11, 14, 30, 69, 72, 93], "isinst": [11, 60, 68, 72, 75, 77, 79, 85, 88, 93], "in_featur": [11, 30, 47, 48, 70, 72, 73, 75, 77], "out_featur": [11, 30, 47, 48, 72, 75, 77], "valid": [11, 24, 26, 61, 74, 79, 88], "enabl": [11, 50, 61, 63, 65, 67, 70, 72, 74, 79, 86], "compil": [11, 51, 67, 69, 70, 72, 75, 77, 82, 86, 87], "competit": [11, 69, 72], "perform": [11, 12, 23, 24, 25, 29, 34, 36, 37, 38, 44, 56, 68, 69, 70, 72, 75, 77, 78, 79, 83, 85, 86, 87, 93], "loop": [11, 68, 69, 72, 93], "x": [11, 24, 26, 29, 30, 34, 41, 44, 63, 70, 72, 73, 74, 75, 77, 79, 82, 83, 84, 85, 86, 87, 91], "randn": [11, 30, 63, 69, 70, 72, 73, 75, 77, 83, 84, 85, 86, 87, 93], "devic": [11, 44, 47, 48, 51, 63, 65, 69, 70, 72, 73, 74, 75, 77, 79, 83, 84, 85, 86, 87], "_": [11, 61, 65, 67, 70, 72, 75, 79, 83, 84, 85, 86, 93], "rang": [11, 68, 69, 70, 72, 75, 84, 85, 93], "10": [11, 29, 63, 65, 69, 70, 72, 74, 75, 82, 84, 85, 93], "zero_grad": [11, 69, 72, 85, 93], "y": 11, "sum": [11, 12, 84, 85], "backward": [11, 12, 68, 69, 72, 85, 93], "step": [11, 12, 42, 43, 63, 67, 68, 69, 72, 82, 83, 84, 85, 86, 87, 88, 93], "calcul": [12, 17, 33, 67, 68, 84, 88], "all": [12, 20, 29, 32, 34, 36, 44, 46, 56, 57, 58, 61, 65, 67, 68, 70, 73, 74, 75, 77, 79, 82, 83, 84, 86, 88, 89], "should": [12, 20, 29, 34, 35, 42, 44, 56, 57, 61, 65, 68, 69, 72, 79, 83, 84, 88, 93], "run": [12, 13, 29, 30, 34, 44, 51, 52, 56, 65, 67, 68, 69, 72, 74, 77, 82, 83, 84, 85, 86, 87, 88, 91, 93], "after": [12, 65, 67, 68, 69, 72, 73, 78, 83, 84, 85, 86, 87, 88, 92, 93], "It": [12, 68, 77, 82, 88], "reduc": [12, 42, 63, 65, 68, 69, 70, 72, 74, 86], "contain": [12, 54, 55, 63, 68, 77, 85, 88], "prototyp": [13, 14, 15, 40, 46, 67, 88], "mx_format": [13, 14, 15], "block_siz": [13, 67, 75], "int": [13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 36, 37, 38, 40, 44, 45, 47, 48, 51, 57, 61, 63, 69, 75, 77, 79], "32": [13, 21, 22, 24, 30, 39, 40, 42, 44, 45, 51, 60, 69, 72, 73, 74, 75, 77, 80, 85, 93], "activation_dtyp": [13, 16, 17, 67], "weight_dtyp": [13, 16, 17, 19, 24, 26, 67, 74], "kernel_prefer": [13, 17, 67], "kernelprefer": [13, 17], "auto": [13, 17, 52, 65, 74, 78, 79], "mx": 13, "format": [13, 14, 20, 21, 24, 26, 53, 65, 68, 74, 84, 85, 88], "infer": [13, 14, 42, 63, 67, 68, 69, 70, 73, 75, 77, 78, 80, 83, 84, 85, 86, 87, 92, 93], "quantiz": [13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 62, 63, 65, 66, 68, 72, 73], "provid": [13, 27, 46, 61, 64, 65, 67, 68, 69, 70, 72, 74, 77, 79, 84, 85, 87, 88, 92, 93], "support": [13, 16, 17, 18, 20, 21, 22, 24, 32, 39, 40, 42, 52, 54, 55, 60, 61, 63, 67, 68, 69, 70, 72, 73, 74, 77, 83, 84, 85, 86, 87, 88, 92, 93], "requir": [13, 24, 52, 61, 63, 67, 68, 69, 70, 74, 77, 78, 80, 82, 83, 86, 88], "nvidia": [13, 14, 63, 68], "sm100": 13, "hardwar": [13, 17, 52, 53, 65, 68, 70, 74, 78, 82, 92], "blackwel": [13, 69], "newer": [13, 69], "i": [13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 39, 40, 42, 51, 54, 55, 57, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 91, 93], "execut": [13, 51, 71, 77, 90], "pytorch": [13, 40, 61, 63, 67, 68, 69, 72, 74, 77, 79, 82, 91], "2": [13, 17, 19, 20, 21, 23, 24, 25, 26, 29, 40, 44, 45, 58, 60, 65, 67, 68, 70, 71, 72, 75, 77, 82, 91, 92, 93], "5": [13, 17, 19, 29, 57, 65, 68, 69, 74, 79, 82, 84, 85, 91, 93], "proper": 13, "serial": [13, 61, 67, 71, 78, 84, 85], "use_triton_kernel": [14, 79], "use_dynamic_per_tensor_scal": [14, 15], "fp4": 14, "nvfp4": [14, 67, 69, 92, 93], "special": [14, 68, 83, 84], "whether": [14, 40, 61, 65, 69, 77], "fuse": [14, 68, 77, 82, 85, 93], "triton": [14, 67, 86, 87], "data": [14, 16, 17, 19, 23, 53, 61, 63, 67, 68, 69, 73, 75, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 92], "float4_e2m1fn_x2": [14, 67], "block": [14, 57, 68, 92], "size": [14, 21, 22, 25, 40, 63, 65, 68, 72, 73, 74, 75, 77, 79, 85, 93], "reduct": [14, 68, 70, 73, 74, 77], "dim": [14, 23, 25, 33, 75, 77, 79, 84, 85], "note": [14, 20, 21, 24, 26, 27, 39, 48, 57, 61, 63, 65, 67, 68, 69, 70, 74, 77, 79, 85, 86, 87], "work": [14, 63, 65, 66, 68, 69, 72, 73, 77, 78, 79, 84, 85, 86], "mode": [14, 63, 65, 70, 71, 75, 83, 85, 86, 87, 88], "ha": [14, 42, 65, 68, 69, 74, 77, 79, 83, 84, 85, 87, 88], "constraint": [14, 84, 85, 88], "must": [14, 20, 24, 26, 27, 40, 42, 48, 68, 72, 78, 79, 85, 87, 88], "satisfi": [14, 68], "k": [14, 63, 65, 73, 75, 77, 84, 85], "64": [14, 21, 32, 73, 74, 75, 77, 79, 93], "Will": 14, "automat": [14, 42, 72, 74, 77, 78, 79, 91, 93], "fallback": [14, 20, 79], "when": [14, 20, 24, 42, 61, 63, 65, 67, 68, 69, 72, 74, 75, 78, 79, 83, 84, 85, 86, 87, 88], "aren": 14, "met": 14, "layout": [16, 21, 22, 23, 24, 60, 61, 68], "cutlasssemisparselayout": 16, "float8_e5m2": [16, 67], "appli": [16, 17, 18, 19, 20, 22, 23, 25, 27, 31, 32, 34, 39, 41, 42, 51, 60, 61, 65, 67, 68, 69, 74, 79, 85, 93], "follow": [16, 40, 42, 61, 65, 67, 68, 69, 72, 74, 75, 77, 78, 82, 83, 84, 85, 86, 87, 88, 93], "compress": [16, 68, 83], "spars": [16, 29, 44, 45, 57, 68], "semi": [16, 60, 68], "structur": [16, 60, 65, 67, 68, 69, 70, 73, 77, 84], "moment": 16, "pertensor": [17, 25, 33, 75], "perrow": [17, 23, 25, 33, 67], "list": [17, 27, 57, 61, 70, 77, 78, 79, 83, 85, 88], "packing_format": [17, 21], "float8packingformat": 17, "plain": [17, 21, 53, 67, 79], "mm_config": 17, "float8mmconfig": 17, "activation_value_lb": 17, "float": [17, 29, 33, 40, 44, 45, 57, 67, 69, 73, 77, 82, 84, 85, 88, 93], "activation_value_ub": 17, "set_inductor_config": [17, 19, 21, 22, 23, 25], "version": [17, 19, 20, 21, 23, 24, 25, 26, 40, 52, 61, 67, 69, 77, 79, 80, 84, 85, 88, 93], "symmetr": [17, 19, 22, 23, 24, 25, 26, 29, 32, 40, 69, 77, 83, 84, 87, 88, 93], "both": [17, 21, 42, 48, 67, 68, 70, 75, 77, 82, 84, 86, 87, 88, 93], "fp8granular": [17, 33], "can": [17, 27, 40, 51, 52, 61, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 83, 84, 85, 86, 87, 88, 93], "either": [17, 33, 42, 57, 65, 68, 74, 85, 86, 87], "tupl": [17, 46, 57, 61, 77, 79, 84, 85, 88], "current": [17, 21, 22, 32, 33, 42, 51, 57, 60, 63, 67, 68, 72, 77, 78, 79, 82, 84, 85, 87, 93], "need": [17, 29, 34, 44, 53, 54, 55, 56, 57, 61, 63, 65, 67, 68, 69, 73, 74, 77, 79, 84, 85, 86, 88], "same": [17, 21, 24, 48, 60, 61, 67, 68, 69, 72, 75, 77, 85, 87, 88, 93], "And": [17, 77, 86, 88], "matrix": [17, 52, 57, 63, 67, 68, 86], "multipl": [17, 27, 52, 54, 63, 65, 67, 68, 69, 75, 77, 79, 86, 88, 93], "fast": [17, 68], "accumul": [17, 93], "lower": [17, 22, 33, 67, 68, 69, 74, 75, 78, 82, 85, 93], "bound": [17, 33, 65, 68, 74, 79], "upper": [17, 33], "prefer": [17, 67, 69, 77], "op": [17, 51, 52, 61, 65, 68, 69, 77, 79, 82, 84, 85, 86, 88, 93], "like": [17, 24, 61, 63, 65, 67, 68, 69, 70, 72, 73, 77, 78, 79, 83, 84, 85, 86, 87, 88], "matmul": [17, 19, 67, 68, 77], "group": [17, 18, 22, 25, 32, 36, 37, 38, 40, 44, 45, 47, 48, 52, 63, 65, 69, 93], "etc": [17, 29, 30, 52, 53, 55, 63, 65, 67, 83, 88], "defalut": 17, "chosen": [17, 52, 55, 68], "user": [17, 27, 42, 48, 52, 63, 65, 66, 67, 68, 69, 72, 74, 75, 77, 82, 84, 85, 86, 87, 88, 91, 93], "other": [17, 24, 41, 52, 57, 63, 68, 69, 72, 73, 74, 77, 79, 80, 84, 85, 86, 88, 91], "inform": [17, 61, 63, 67, 68, 74, 79, 83, 84], "adjust": [17, 19, 21, 22, 23, 25, 69], "torchinductor": [17, 19, 21, 22, 23, 25, 86, 87], "recommend": [17, 19, 21, 22, 23, 25, 65, 67, 69, 70, 72, 78, 80, 83, 86, 87, 92], "deprec": [17, 19, 20, 23, 35, 39, 61], "float8tensor": [17, 19, 33, 54, 65, 67, 79], "quantize_": [17, 19, 21, 23, 25, 35, 39, 42, 51, 52, 53, 54, 55, 60, 62, 63, 65, 67, 69, 70, 73, 74, 75, 80], "int4_packing_format": [18, 21, 80], "int4packingformat": [18, 21], "preshuffl": [18, 67], "row": [18, 63, 65, 67, 68, 72], "int4": [18, 21, 22, 24, 29, 30, 32, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 51, 65, 67, 69, 73, 74, 78, 79, 80, 92, 93], "group_siz": [18, 21, 22, 24, 25, 29, 30, 32, 36, 39, 40, 42, 44, 45, 51, 63, 69, 78, 79, 80, 93], "right": [18, 21, 65, 68, 84], "now": [18, 21, 63, 65, 67, 68, 69, 70, 72, 75, 77, 78, 83, 84, 86, 88, 93], "sinc": [18, 20, 29, 34, 44, 56, 61, 67, 68, 73, 74, 75, 77, 84, 85, 86, 87, 88], "underli": [18, 74, 77], "abov": [18, 24, 26, 65, 67, 68, 69, 73, 75, 77, 84, 85, 88, 93], "benefit": [18, 68, 69, 77, 84, 87], "make": [18, 65, 67, 77, 79, 82, 84, 88], "bigger": 18, "pack": [18, 21, 24, 26, 53, 65], "channel": [19, 23, 25, 32, 36, 37, 38, 40, 44, 45, 47, 48, 56, 75, 87], "actual": [19, 42, 52, 67, 69, 75, 77, 79, 84, 85, 88, 93], "fqn_to_config": 20, "ordereddict": 20, "core": [20, 51, 75, 79, 84], "aobaseconfig": [20, 42, 51, 60, 63, 75, 79], "factori": 20, "module_fqn_to_config": 20, "differ": [20, 21, 27, 63, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 84, 85, 86, 88, 92, 93], "fulli": [20, 51, 60, 68, 74, 84], "qualifi": [20, 51, 60, 68], "an": [20, 39, 40, 42, 48, 57, 64, 67, 68, 69, 72, 74, 75, 77, 78, 80, 82, 83, 84, 85, 86, 87, 88, 92], "order": [20, 27, 61, 65, 68, 77, 88], "dictionari": [20, 68], "regex": [20, 83], "python": [20, 63, 65, 68, 74, 82, 83, 84, 86, 87, 89, 91], "re": [20, 65, 67, 72, 73, 74, 77, 84, 85], "prefix": 20, "3": [20, 29, 67, 68, 71, 72, 78, 80, 82, 84, 85, 91, 93], "_default": [20, 74, 79], "we": [20, 21, 23, 39, 40, 42, 48, 51, 60, 61, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88], "want": [20, 51, 60, 65, 67, 68, 73, 77, 79, 82, 83, 84, 85, 88], "param": [20, 26, 57, 74], "kei": [20, 57, 68, 91], "preced": [20, 83, 84, 86, 87], "languag": [20, 74], "q_proj": [20, 79, 93], "first": [20, 42, 57, 61, 65, 67, 71, 74, 75, 77, 78, 79, 80, 84, 85, 88, 93], "match": [20, 47, 48, 61, 68, 84], "whichev": 20, "kept": 20, "consist": [20, 63, 68, 74, 77, 86, 87, 88], "previou": [20, 67, 74, 84, 85, 86, 87], "subset": [20, 24, 26, 67], "some": [20, 51, 57, 61, 65, 67, 68, 74, 75, 77, 82, 83, 84, 85, 86, 87, 88], "better": [20, 23, 25, 70, 72, 77, 84, 85, 86, 87, 88], "befor": [20, 42, 51, 65, 67, 68, 69, 73, 74, 75, 77, 84, 85, 88, 93], "hand": 20, "them": [20, 29, 34, 44, 56, 63, 69, 88, 93], "norm": [20, 56, 57, 68], "linear_config": [20, 74], "filter_fn": [20, 51, 60, 93], "To": [20, 48, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 79, 80, 84, 85, 86, 88, 93], "maintain": [20, 61, 68, 74], "bc": [20, 61], "modulefqntoconfig": 20, "later": [20, 67, 69, 77, 84, 85, 87], "pattern": [20, 67, 79, 82, 83, 84], "mai": [20, 40, 53, 65, 67, 73, 75, 78, 84, 85, 86, 87, 88, 93], "matter": [20, 67, 68], "ignor": [20, 29, 34, 44, 56, 72, 84, 85], "replac": [20, 68, 69, 79], "int4_choose_qparams_algorithm": [21, 80], "int4chooseqparamsalgorithm": 21, "tinygemm": [21, 47, 51, 93], "groupwis": [21, 24, 26], "although": [21, 29, 34, 44, 56, 69, 77], "In": [21, 42, 65, 67, 68, 69, 70, 72, 75, 77, 83, 84, 85, 86, 87, 88, 93], "mainli": [21, 67, 83, 86, 88], "distinguish": [21, 67], "arg": [21, 24, 26, 29, 30, 31, 32, 36, 45, 57, 61, 65, 67, 77, 79, 85, 88], "control": [21, 22, 23, 57, 68, 79, 84], "smaller": [21, 22, 69, 70, 73, 93], "more": [21, 22, 24, 26, 63, 65, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 83, 84, 85, 86, 87, 93], "fine": [21, 22, 68, 71, 72, 74, 93], "grain": [21, 22, 77], "choic": [21, 65], "256": [21, 36, 37, 38, 47, 48, 74, 84, 85, 88], "variant": [21, 77], "choos": [21, 24, 26, 55, 65, 67, 68, 77, 84, 86], "qparam": 21, "algorithm": [21, 24, 26, 65, 68, 74, 83, 92], "hqq": [21, 67, 80, 92], "vari": [21, 69, 70, 84, 85, 86, 87], "backend": [21, 22, 68, 74, 82, 88], "is_avail": [21, 80], "tile": 21, "tile_packed_to_4d": [21, 80], "elif": [21, 63, 79, 80], "xpu": [21, 80, 82, 87], "plain_int32": [21, 80], "plainlayout": [22, 23, 61, 75], "mapping_typ": [22, 26, 40], "mappingtyp": [22, 23, 24, 26, 40, 75], "act_mapping_typ": [22, 23, 24], "asymmetr": [22, 24, 26, 40, 69, 75, 83, 87, 88, 93], "int8": [22, 23, 24, 25, 26, 30, 38, 39, 40, 42, 48, 51, 55, 60, 67, 69, 70, 74, 77, 84, 86, 87, 88, 92, 93], "token": [22, 23, 24, 38, 40, 48, 69, 72, 74, 78, 93], "produc": [22, 82, 83, 84, 85, 86, 87, 93], "executorch": [22, 24, 65, 71, 78, 82, 84, 85], "did": [22, 69], "flow": [22, 68, 69, 72, 74, 75, 83, 84, 85, 86, 87], "yet": [22, 42, 69, 77, 79, 85, 86, 87], "weight_only_decod": 23, "store": [23, 54, 56, 67, 68, 78, 79, 84, 85], "access": [23, 65, 83], "map": [23, 24, 26, 40, 61, 67, 69, 77, 84, 88], "around": [23, 67, 72, 73, 82, 84], "zero": [23, 24, 26, 40, 45, 46, 47, 48, 57, 68, 75, 88, 93], "dure": [23, 40, 42, 68, 69, 72, 74, 75, 77, 82, 83, 85, 93], "forward": [23, 29, 30, 34, 41, 44, 47, 56, 63, 68, 70, 73, 75, 77, 79, 82, 84, 85, 86], "decod": [23, 74], "oper": [23, 65, 67, 69, 74, 82, 83, 84, 85, 86, 87, 93], "scheme": [23, 25, 29, 30, 42, 69, 74, 83], "affinequantizedtensor": [23, 65, 73, 75, 77], "plan": [23, 65, 85, 92], "split": [23, 74, 84, 85], "int8tensor": [23, 67, 70], "weight_granular": [24, 67, 74], "pergroup": [24, 26, 40, 74], "weight_mapping_typ": 24, "weight_scale_dtyp": [24, 74], "intx_packing_format": [24, 26], "intxpackingformat": [24, 26], "unpacked_to_int8": [24, 26], "intx_choose_qparams_algorithm": [24, 26], "intxchooseqparamsalgorithm": [24, 26], "affin": [24, 26, 67], "intx": [24, 26, 92], "8": [24, 26, 29, 30, 37, 47, 67, 69, 72, 74, 79, 86, 87, 93], "specif": [24, 29, 30, 48, 53, 57, 63, 65, 67, 68, 69, 72, 73, 74, 78, 83, 86, 87, 88, 93], "bit": [24, 26, 41, 63, 69, 74, 77, 78, 79, 84, 86, 87, 93], "channelwis": [24, 26], "manner": [24, 26], "number": [24, 26, 32, 45, 47, 48, 57, 68, 74, 77, 85, 86], "ident": [24, 68, 72], "int8dynamicactivationint4weightconfig": [24, 42, 48, 69, 93], "howev": [24, 68, 78, 79, 85, 88], "gener": [24, 29, 30, 31, 34, 41, 63, 67, 68, 69, 70, 74, 75, 77, 79, 83, 85, 86, 87, 88, 89, 91, 93], "where": [24, 26, 36, 37, 38, 63, 67, 68, 79, 88], "peraxi": [24, 26, 40, 74, 75], "zeropointdomain": [24, 40], "intend": [24, 52, 64, 67, 84], "export": [24, 67, 82], "applic": [24, 74], "opaque_torchao_auto": 24, "cpu": [24, 63, 65, 68, 73, 75, 78, 79, 80, 83, 84, 85, 86], "detail": [24, 26, 63, 65, 67, 68, 69, 70, 72, 74, 75, 77, 80, 83, 84, 85, 86, 92, 93], "otherwis": [25, 27, 40, 85], "scale_dtyp": [26, 75], "qat": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 62, 71, 74, 80, 86], "twostepquant": 27, "compos": [27, 67, 68, 69, 77, 84, 85, 88], "easili": [27, 83], "thei": [27, 68, 72, 77, 78, 82, 84, 85, 88], "constructor": [27, 61, 77], "embed": [27, 29, 36, 39, 42, 44, 45, 93], "behavior": [27, 79, 84, 85], "undefin": [27, 57], "usag": [27, 29, 30, 35, 39, 40, 42, 61, 69, 71, 72, 74, 86, 87, 93], "my_quant": 27, "qatquantizer1": 27, "qatquantizer2": 27, "qatquantizer3": 27, "prepar": [27, 32, 36, 42, 57, 68, 69, 83, 86, 87, 88, 93], "fake": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 69, 72, 84, 85, 88, 93], "num_embed": [29, 44, 45], "embedding_dim": [29, 44, 45], "padding_idx": [29, 44, 45], "max_norm": [29, 44, 45], "norm_typ": [29, 44, 45], "scale_grad_by_freq": [29, 44, 45], "weight_config": [29, 30, 39, 42, 93], "fakequantizeconfigbas": [29, 30, 39, 42], "kwarg": [29, 30, 31, 32, 36, 40, 45, 55, 56, 57, 58, 61, 63, 65, 67, 77, 79], "through": [29, 30, 63, 65, 67, 69, 70, 74, 75, 77, 79, 82, 83, 84, 88, 91, 93], "separ": [29, 30, 40, 68, 69, 79, 84, 88], "intxfakequantizeconfig": [29, 30, 39, 41, 42, 93], "fq_embed": 29, "longtensor": 29, "everi": [29, 34, 44, 56, 68, 77, 84, 85], "call": [29, 34, 44, 56, 61, 65, 67, 68, 69, 73, 75, 77, 79, 85, 87, 93], "overridden": [29, 34, 44, 56], "within": [29, 34, 44, 56, 68, 74, 79, 86, 87], "afterward": [29, 34, 44, 56], "instead": [29, 34, 35, 39, 40, 42, 44, 56, 68, 69, 72, 77, 82, 85, 86, 87, 88], "former": [29, 34, 44, 56], "take": [29, 34, 44, 51, 56, 60, 61, 67, 68, 83, 84, 85, 86, 87, 88], "care": [29, 34, 44, 56, 68, 73, 84], "regist": [29, 34, 44, 56, 61, 65, 67, 77], "hook": [29, 34, 44, 56, 67], "while": [29, 34, 42, 44, 54, 56, 57, 68, 69, 70, 74, 77, 78, 83, 84, 88, 93], "latter": [29, 34, 44, 56, 85], "silent": [29, 34, 44, 56, 86], "activation_config": [30, 39, 42, 93], "per_token": [30, 39, 40, 42, 93], "is_symmetr": [30, 39, 40, 42, 93], "fq_linear": 30, "ani": [31, 32, 36, 46, 57, 64, 65, 67, 68, 77, 83, 85, 87], "scale_precis": [32, 36, 40, 44, 45], "element": [32, 45, 47, 48, 61, 67, 68], "each": [32, 40, 45, 47, 48, 56, 61, 65, 67, 68, 75, 77, 79, 84, 85, 88, 93], "fakequantizedlinear": [32, 35, 49, 50, 69, 93], "hp_value_lb": 33, "hp_value_ub": 33, "point": [33, 40, 45, 46, 47, 48, 67, 68, 70, 72, 73, 75, 77, 82, 84, 88, 93], "float8fakequantizeconfig": 34, "qatconfig": [35, 39, 43, 69, 93], "fakequantizedembed": 35, "back": [35, 77], "correspond": [35, 42, 51, 63, 67, 68, 69, 73, 77, 87, 88, 93], "without": [35, 67, 68, 69, 79, 86, 88, 93], "model_with_fake_quantized_linear": 35, "float32": [36, 38, 40, 44, 45, 48, 68, 69, 73, 74, 75, 77, 86, 87, 88], "zero_point_precis": [36, 40, 44, 45], "int32": [36, 40, 44, 45, 67, 84, 88], "have": [36, 37, 38, 53, 57, 64, 65, 67, 68, 69, 75, 77, 79, 83, 84, 85, 86, 87, 88, 93], "int4weightonlyqatembed": 36, "int4weightonlyembed": 36, "groupsiz": [37, 38, 47, 48, 69, 93], "inner_k_til": [37, 47], "scales_precis": [37, 38, 47, 48], "padding_allow": 38, "rais": [39, 42, 77, 79], "valueerror": [39, 42], "torchaodtyp": 40, "zero_point_domain": 40, "is_dynam": [40, 86, 87, 88], "range_learn": 40, "ep": [40, 75, 85, 87, 88], "integ": [40, 41, 69, 75, 84, 85, 86], "up": [40, 51, 67, 68, 69, 72, 83, 84, 85, 88, 93], "simul": [40, 42, 58, 68, 93], "older": [40, 61], "than": [40, 67, 68, 69, 70, 72, 77, 84], "6": [40, 67, 68, 72, 74, 80, 84, 85, 86], "you": [40, 57, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 83, 84, 85, 86, 87, 88, 91, 93], "int1": [40, 67], "int7": [40, 67], "also": [40, 51, 65, 67, 68, 69, 70, 73, 75, 77, 78, 79, 84, 87, 88, 93], "equival": [40, 68, 69, 85, 86, 88, 93], "pertoken": 40, "per_channel": 40, "per_group": 40, "combin": [40, 68, 74, 77, 84, 86], "altern": [40, 69, 75, 77, 86, 87, 93], "just": [40, 65, 67, 68, 73, 77, 84, 85, 88], "field": [40, 43, 88], "empti": [40, 67], "fp32": [40, 48, 75, 77, 84, 86], "domain": [40, 69, 72], "learn": [40, 68, 70, 84, 86, 87, 88, 91, 93], "compat": [40, 63, 65, 80], "keyword": [40, 42, 54, 67], "argument": [40, 42, 51, 54, 61, 67, 72, 74, 86], "properti": [40, 41], "throw": 40, "error": [40, 72, 77, 84], "els": [40, 67, 74, 79, 84, 85], "width": [41, 63, 93], "symmetri": 41, "base_config": [42, 69, 93], "qatstep": 42, "awar": [42, 57, 68, 77, 82], "here": [42, 48, 63, 64, 67, 73, 74, 75, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 93], "numer": [42, 47, 48, 52, 68, 69, 72, 84, 85, 86, 93], "arithmet": [42, 69], "bf16": [42, 63, 68, 69, 86, 87, 93], "goal": [42, 69], "eventu": [42, 69, 72], "degrad": [42, 68, 69, 80], "There": [42, 67, 69, 75, 77, 84, 88], "wai": [42, 65, 67, 68, 72, 74, 75, 77, 84, 85, 88, 93], "involv": [42, 68, 69, 93], "post": [42, 67, 70, 77, 82, 85, 88, 92, 93], "ptq": [42, 85, 86, 92, 93], "which": [42, 47, 52, 63, 65, 67, 68, 69, 72, 73, 74, 75, 79, 83, 84, 85, 86, 87, 88, 93], "phase": [42, 88], "case": [42, 52, 63, 64, 65, 68, 74, 77, 79, 83, 84, 88, 93], "train_loop": [42, 69, 93], "int4weightonlyconfig": [42, 51, 73, 78, 79, 80, 93], "second": [42, 61, 67, 72, 88, 91], "directli": [42, 67, 68, 69, 75, 77], "mostli": [42, 82], "experiment": [42, 83, 93], "doe": [42, 52, 53, 65, 67, 68, 69, 77, 84, 86, 87, 93], "exist": [42, 65, 67, 68, 72, 75, 77, 84, 88], "qat_config": [42, 93], "act_config": 42, "custom": [42, 56, 63, 67, 68, 69, 72, 77, 79, 80, 83, 84, 86, 88, 93], "alwai": [42, 74, 77], "One": [42, 68, 77, 79, 88], "determin": [42, 68, 72, 79], "enum": [43, 52], "output_dtyp": 44, "example_input": [46, 70, 73, 75, 82, 83, 84, 85, 86, 87, 88], "initi": [46, 67, 69, 73, 82, 85], "intxfakequantizerbas": 46, "weightonlyint4linear": 47, "effici": [47, 52, 68, 69, 75, 87, 93], "hardcod": [48, 88, 93], "allow": [48, 65, 67, 68, 77, 82, 83, 84, 85, 86, 88, 93], "get": [48, 61, 65, 67, 68, 69, 70, 72, 74, 79, 82, 83, 84, 85, 86, 88], "exact": [48, 69, 84, 85], "helper": [49, 50, 61, 65], "_is_linear": [51, 75], "inplac": [51, 57, 70], "workflow": [51, 52, 60, 63, 65, 68, 70, 72, 82, 88], "object": [51, 60, 65, 67, 77, 84, 85, 88], "move": [51, 65, 75, 79, 85, 86], "speed": [51, 68, 69, 74, 83], "final": [51, 67, 68, 70, 83, 84, 85, 86, 87, 88, 93], "do": [51, 65, 67, 68, 74, 75, 77, 79, 84, 85, 86, 88], "chang": [51, 65, 68, 70, 72, 73, 74, 75, 77, 83, 84, 85, 87, 88], "predefin": [51, 53, 88], "method": [51, 57, 61, 63, 65, 68, 75, 77, 78, 82, 83, 84, 85, 87, 88], "path": [51, 69, 70, 74, 82, 83, 84, 85, 86, 88], "customiz": [51, 69], "int8dynamicactivationint8weightconfig": [51, 60, 70, 78], "mm": [51, 52, 65, 77, 84], "int8weightonlyconfig": [51, 69, 78, 79], "quant_api": [51, 65, 73, 74, 75], "1024": [51, 60, 63, 70, 73, 86], "affect": [52, 68], "select": [52, 84], "found": [52, 67, 68, 70, 74, 75, 77], "under": [52, 65, 69, 74], "librari": [52, 53, 65, 67, 73, 80], "avail": [52, 53, 63, 65, 67, 74, 83, 84, 85, 86, 87, 92], "gemm_lowp": 52, "b": [52, 61], "gemm_fp32": 52, "dequant": [52, 67, 77, 79, 82, 84, 86, 87, 88, 93], "ci": 52, "product": [52, 57, 70, 74, 79, 86, 88], "logic": [52, 70, 77, 79], "lowp": 52, "gemm": [52, 72, 86, 87], "debug": [52, 65], "issu": [52, 64, 67, 70, 77, 86], "mslk": [52, 65, 67], "nativ": [52, 67, 72, 77, 84], "laid": [53, 67], "out": [53, 57, 63, 65, 67, 68, 69, 70, 72, 74, 77, 82, 83, 84, 85, 86], "opaqu": 53, "decid": [53, 68, 75], "shape": [53, 63, 65, 67, 75, 77, 79, 84, 87], "rest": [53, 63, 77, 85], "system": [53, 63, 65, 74], "understand": [53, 65, 72, 86, 88], "adopt": [53, 67], "creation": [54, 79], "construct": [54, 67, 84, 88], "classmethod": [54, 61, 75, 77, 79], "from_hp": [54, 67], "cl": [54, 61, 75, 77, 79], "quant_kwarg": [54, 55], "quantizetensorkwarg": 55, "given": [55, 68, 72, 79, 88], "deriv": [55, 65], "flexibl": [55, 68, 77, 83, 86, 93], "variou": 55, "sparsiti": [56, 57, 58, 59, 60, 62, 63, 66, 69, 72, 73, 74, 92], "observ": [56, 67, 68, 75, 83, 84, 85, 86, 87, 88], "l2": [56, 68], "buffer": 56, "x_orig": 56, "sparsity_level": [57, 68], "semi_structured_block_s": 57, "wanda": 57, "sparsifi": [57, 68, 73, 80], "prune": 57, "propos": [57, 69], "http": [57, 61, 68, 74, 78, 80, 87, 93], "arxiv": [57, 68], "org": [57, 61, 68, 74, 80, 87], "ab": [57, 68], "2306": 57, "11695": 57, "remov": [57, 65, 68, 72, 79, 84, 85, 93], "magnitud": [57, 68], "three": [57, 60, 86, 87], "variabl": [57, 68], "level": [57, 65, 67, 68, 77, 83, 84, 86, 87], "dict": [57, 61, 77, 79, 87, 88], "ad": [57, 61, 63, 67, 68, 69, 75, 77, 85], "parametr": 57, "preserv": [57, 68, 74, 83], "copi": [57, 65, 68, 70, 73, 75, 77, 85, 86], "deepcopi": [57, 70, 75, 77, 85], "squash_mask": [57, 68], "params_to_keep": 57, "params_to_keep_per_lay": 57, "squash": 57, "mask": [57, 68], "appropri": [57, 83, 84, 85, 86, 87], "sparse_param": 57, "attach": [57, 68, 88], "save": [57, 61, 65, 69, 70, 72, 73, 74, 79, 93], "xdoctest": 57, "local": [57, 68, 74], "hasattr": [57, 79], "submodule1": 57, "linear1": [57, 70, 73, 75, 77], "foo": [57, 84], "bar": [57, 84], "submodule2": 57, "linear42": 57, "baz": 57, "print": [57, 69, 70, 73, 74, 77, 84, 85, 91], "42": [57, 75], "24": 57, "ones": [57, 85], "update_mask": 57, "tensor_nam": [57, 79], "statist": [57, 68, 75, 84, 85], "retriev": 57, "act_per_input": 57, "Then": [57, 77, 87, 88, 93], "metric": [57, 63, 69], "compar": [57, 65, 67, 69, 70, 72, 74, 84, 86, 88, 93], "across": [57, 68, 74, 77, 79], "whole": [57, 88], "4": [58, 60, 67, 68, 69, 70, 73, 74, 77, 78, 84, 85, 92, 93], "alia": [59, 61, 79], "semisparseweightconfig": 59, "sparsify_": 60, "apply_tensor_subclass": 60, "essenti": [60, 79, 83], "put": [60, 65, 86, 88], "semi_sparse_weight": 60, "semisparselayout": 60, "sparse_api": 60, "util": [61, 62, 63, 65, 67, 73, 77, 79, 83, 84, 85, 86, 87, 88], "commonli": [61, 68, 72], "new": [61, 63, 67, 69, 72, 75, 77, 84, 85, 86, 88], "inherit": [61, 77, 79, 86, 87], "attribut": [61, 65, 67, 69, 77, 79, 86, 87], "tensor_data_nam": [61, 65], "tensor_data": 61, "__init__": [61, 63, 69, 70, 73, 75, 77, 79, 82, 84, 85, 86], "been": [61, 69, 77, 85, 86, 87, 88], "section": [61, 65, 67, 68, 79, 84, 85, 88], "tensor_attribute_nam": [61, 65], "non": [61, 65, 68, 77, 83, 86, 87], "optional_tensor_data_nam": 61, "addit": [61, 63, 67, 68, 69, 72, 77, 78, 83, 84, 87, 88, 93], "optional_tensor_attribute_nam": 61, "__new__": [61, 77, 79], "exaclti": 61, "present": [61, 68], "includ": [61, 67, 72, 77, 83, 86, 87, 88, 92], "__tensor_flatten__": [61, 77, 79], "flatten": 61, "attribute_nam": 61, "__tensor_unflatten__": [61, 77, 79], "tensor_data_dict": [61, 77, 79], "_apply_fn_to_data": [61, 79], "recreat": 61, "transform": [61, 65, 69, 75, 83, 84, 85, 86, 87, 93], "__repr__": [61, 77], "represent": [61, 68, 79, 84, 88], "_same_metadata": 61, "metadata": [61, 67, 74, 77, 79], "between": [61, 67, 68, 77, 79, 83, 85, 86, 88, 93], "__setstate__": 61, "load": [61, 65, 73, 74, 78, 79], "checkpoint": [61, 69, 72, 74, 79], "old": 61, "add": [61, 65, 77, 78, 86, 88, 91], "__torch_function__": [61, 67, 77], "contigu": [61, 67, 86, 87], "aten": [61, 65, 67, 77, 79, 82, 83, 84, 85, 86, 87], "__torch_dispatch__": [61, 77], "detach": [61, 77, 79], "clone": [61, 74, 79], "copy_": [61, 79], "_to_copi": [61, 79], "mytensor": [61, 65], "c": [61, 77, 82, 86, 87], "d": [61, 65, 74, 85], "f": [61, 67, 68, 70, 72, 73, 74, 75, 77, 79, 84, 85], "h": [61, 74], "self": [61, 63, 69, 70, 73, 75, 77, 79, 82, 84, 85, 86], "get_layout": 61, "15": [61, 63, 72, 74], "part": [61, 68, 71, 77, 78, 85], "develop": [61, 65, 82, 84, 85, 88], "stack": [61, 67, 74], "about": [61, 63, 65, 67, 68, 69, 70, 73, 74, 84, 85, 86, 88, 93], "dev": [61, 78], "check": [61, 63, 65, 67, 69, 70, 73, 74, 77, 82, 83, 85, 88], "doc": [61, 65, 67, 72, 74, 77, 78, 82], "ao": [61, 68, 79], "main": [61, 67, 68, 70, 74, 75, 77, 78, 84, 88, 93], "quantization_overview": 61, "html": 61, "contributor_guid": 61, "get_tensor_impl_constructor": 61, "layout_class": 61, "tensorimpl": 61, "tensorimplclass": 61, "from_plain": 61, "tensor_class": 61, "mean": [61, 67, 68, 69, 72, 84, 85, 88], "impl": 61, "aten_op": 61, "decor": [61, 77, 79], "callback": 61, "func": [61, 65, 67, 77, 79], "implements_torch_funct": 61, "torch_fn": 61, "register_layout": 61, "registr": 61, "aqt": 61, "py": [61, 63, 65, 86, 87, 90, 91], "tabl": [61, 67, 68, 72, 80], "comprehens": [62, 63, 70, 79, 86], "document": [62, 66, 69, 77, 79, 83, 84, 86, 92, 93], "tutori": [63, 65, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 83, 84, 85, 86, 87, 88, 89, 90, 93], "framework": [63, 65, 69, 72, 74, 83], "architectur": [63, 68, 71, 74, 83, 84, 86, 87], "micro": 63, "sparsity_": 63, "string_to_config": 63, "microbenchmark": 63, "code": [63, 65, 67, 68, 70, 72, 74, 75, 77, 84, 85, 86, 87, 88, 89, 91], "my_new_quant": 63, "process": [63, 67, 68, 69, 83, 87, 91, 93], "mynewquantizationconfig": 63, "my_new_spars": 63, "mynewsparsityconfig": 63, "throughout": 63, "append": [63, 68, 84, 85], "gemliteuintxweightonlyconfig": 63, "gemlitewo": 63, "bit_width": 63, "model_architectur": 63, "your": [63, 65, 67, 68, 69, 70, 71, 72, 74, 78, 80, 84, 85, 86, 87, 88, 93], "mycustommodel": 63, "input_dim": [63, 70], "output_dim": [63, 70], "super": [63, 69, 70, 73, 75, 77, 82, 84, 85, 86], "layer1": 63, "512": [63, 72], "relu": [63, 82, 83, 88], "layer2": 63, "updat": [63, 68, 70, 73, 80, 84, 85, 88], "create_model_and_input_data": 63, "handl": [63, 65], "model_typ": [63, 69, 79, 83], "n": [63, 65, 69, 73, 75, 77, 84, 85, 88], "high_precision_dtyp": 63, "my_custom_model": 63, "input_data": 63, "ensur": [63, 74, 85], "convent": 63, "batch": [63, 74, 75, 85, 93], "sequenc": 63, "length": 63, "featur": [63, 69, 77, 83, 86, 87, 92], "typic": [63, 67, 69, 73, 75, 79, 82, 88, 93], "come": [63, 64, 67, 68, 72, 74, 75, 76, 78, 85, 86, 87, 93], "soon": [63, 64, 74, 76, 85, 93], "file": [63, 65, 70, 72, 74, 77, 79, 84, 85, 90], "microbenchmark_quantization_config": 63, "yml": 63, "benchmark_mod": 63, "quantization_config_recipe_nam": 63, "int8wo": [63, 78], "int8dq": 63, "float8dq": [63, 74], "float8wo": 63, "output_dir": [63, 78], "result": [63, 67, 68, 69, 70, 75, 78, 84, 85, 86, 87, 88], "model_param": 63, "small_bf16_linear": 63, "matrix_shap": 63, "small_sweep": 63, "min_pow": 63, "max_pow": 63, "torch_compile_mod": 63, "max": [63, 65, 67, 70, 75, 77, 84, 85, 88], "autotun": [63, 65, 70, 75], "runner": 63, "oss": 63, "databas": 63, "ci_microbenchmark_runn": 63, "benchmark_result": 63, "json": [63, 74, 79], "extra_info": 63, "arch": 63, "a100": [63, 69, 78, 92], "sxm4": 63, "80gb": 63, "speedup": [63, 65, 67, 68, 69, 72, 74], "wrt": 63, "benchmark_valu": 63, "25": 63, "target_valu": 63, "depend": [63, 68, 73, 77, 80, 84, 85, 87], "github": [63, 70, 74, 78, 93], "action": [63, 79, 84, 85], "upload": 63, "verifi": [63, 70, 73, 77], "setup": [63, 74], "suit": [63, 65, 84, 86], "unittest": 63, "discov": 63, "memori": [63, 65, 67, 68, 69, 72, 77, 78, 80, 86, 87, 93], "miss": [63, 68], "properli": [63, 73], "instal": [63, 65, 67, 72, 74, 78, 84, 87], "Not": [63, 68], "driver": 63, "basic": [63, 65, 75, 77], "analysi": [63, 68], "profil": [63, 65], "overhead": [63, 68, 70, 78, 79, 86], "possibl": [63, 67, 68, 84, 85, 86, 88], "reproduc": [63, 74], "compon": [63, 67, 77, 79], "directori": [63, 72], "instruct": [64, 67, 69, 74, 84, 85, 86, 93], "fequent": 64, "answer": [64, 68], "read": [65, 77, 93], "overview": [65, 66, 70, 79, 92], "page": [65, 70, 86, 92], "contribut": [65, 68, 70], "api": [65, 66, 67, 68, 70, 75, 77, 82, 83, 84, 85, 86, 87], "trainabl": [65, 67, 69, 77], "parallel": [65, 72, 77, 79], "primit": [65, 77, 84], "slight": [65, 68], "variat": [65, 67], "quant_primit": [65, 75], "mp": 65, "csrc": 65, "concept": [65, 67, 84, 86, 87, 88, 91], "alreadi": [65, 77, 88], "could": [65, 67, 77, 83, 84, 86, 87, 88], "context": [65, 86, 87], "write": [65, 71, 82, 83, 84, 85], "own": [65, 68, 69, 71, 72, 75, 82, 84, 85, 88], "torchaobasetensor": [65, 79], "help": [65, 67, 69, 72, 74, 79, 83, 84], "qdata": [65, 67], "With": [65, 77, 84, 86, 88], "ll": [65, 67, 72, 77, 84, 85, 88], "mani": [65, 67, 68, 77], "still": [65, 67, 68, 69, 70, 84, 88, 93], "awai": 65, "abstract": [65, 67], "easier": [65, 88], "peopl": [65, 67, 73, 79, 88], "well": [65, 67, 68, 82, 84, 85, 88], "my_custom_op": 65, "my_mm_for_mp": 65, "input_tensor": [65, 67, 79], "weight_tensor": [65, 67, 79], "group_mm": 65, "whatev": 65, "think": [65, 79], "condit": 65, "so": [65, 67, 68, 69, 70, 72, 73, 77, 78, 84, 85, 88], "worri": 65, "purpos": [65, 67, 72, 77, 84, 93], "h100": [65, 67, 78, 92, 93], "sm89": 65, "sm90": 65, "_choose_scale_float8": [65, 67], "_quantize_affine_float8": [65, 67], "_scaled_mm": [65, 67], "kerenel": 65, "f8f8bf16_rowwis": [65, 67], "reus": [65, 77], "quant": [65, 67, 74, 79, 84, 87, 88], "aim": [65, 68, 87], "fullgraph": [65, 70], "unnecessari": 65, "graph": [65, 82, 84, 85, 88], "break": 65, "torch_log": 65, "output_cod": 65, "script": [65, 70, 74, 75, 77, 85, 86, 87, 91], "inductor": [65, 82, 83, 84], "relev": [65, 67, 91], "safe": 65, "global": [65, 68, 77], "add_safe_glob": 65, "quantizetensortofloat8kwarg": [65, 67], "checkout": [65, 67, 80], "integr": [65, 68, 71, 72, 73, 74, 77, 86, 88], "huggingfac": [65, 78], "deseri": [65, 84, 85], "save_pretrain": [65, 74, 78], "push_to_hub": [65, 74, 78, 79], "from_pretrain": [65, 69, 74, 78, 79, 93], "diffus": [65, 74], "talk": [65, 67, 74], "fsdp": [65, 67], "mydtypetensor": 65, "developer_api_guid": 65, "folder": [65, 74, 84, 85, 92], "cover": [65, 84, 87, 88, 91], "torchchat": 65, "dtensor": [65, 77], "past": [65, 68], "adapt": [65, 72, 75], "intens": 65, "sens": [65, 67, 77], "benchmark_aq": 65, "quick": 65, "interest": [65, 68, 77], "print_op_and_shap": 65, "torch_func": 65, "built": [65, 72, 77], "_c": 65, "tensorbas": 65, "benchmark_your_kernel": 65, "feel": [65, 67, 68, 77, 79], "free": [65, 67, 77], "probabl": 65, "futur": [65, 75, 78, 79, 84, 85, 86, 88], "llama": [65, 69, 74, 78, 79, 80, 83, 93], "llama2": 65, "llama3": [65, 69, 72, 78, 93], "sam": 65, "friendli": 65, "techniqu": [65, 68, 69, 72, 73, 74, 75, 77, 79, 92], "profile_path": 65, "chrome": 65, "trace": 65, "let": [65, 67, 68, 70, 75, 77, 88], "u": [65, 68, 83], "know": [65, 77], "technic": 66, "contributor": [66, 67, 70], "guid": [66, 67, 70, 71, 74, 83], "benchmark": [66, 70, 72, 78, 82, 83, 86, 87], "lai": 67, "awq": [67, 92], "gptq": 67, "int4tensor": 67, "int4preshuffledtensor": 67, "uint1": 67, "uint7": 67, "float3": 67, "overload": [67, 68], "term": [67, 68, 84, 88], "extra": [67, 74], "No": [67, 68, 69, 73], "what": [67, 68, 69, 72, 74, 75, 79, 84, 88, 91], "end": [67, 68, 69, 72, 74, 77, 78, 79, 85, 88], "float8_e4m3fnuz": 67, "float8_e5m2fnuz": 67, "float8_e8m0fnu": 67, "placehold": [67, 87], "real": [67, 69, 82, 84, 88], "pr": 67, "shell": 67, "limit": [67, 69, 72, 77, 79, 84], "offici": [67, 72], "dervi": 67, "mxfp8": [67, 92], "mxfp4": [67, 69, 92], "preicison": 67, "choose_qparam": 67, "zero_point": [67, 68, 75, 77, 88], "mention": [67, 84], "accommod": 67, "choose_qparams_affine_with_min_max": 67, "min": [67, 75, 77, 84, 88], "raw": 67, "quantize_fp8_row": 67, "int_matmul": 67, "int_scaled_matmul": 67, "reli": [67, 68, 75, 77, 82], "handwritten": 67, "On": 67, "top": [67, 72, 77, 83, 84, 85, 86, 87], "glue": 67, "everyth": 67, "togeth": [67, 74, 84, 86, 88], "build": [67, 68, 72, 77, 79, 80, 84], "anoth": [67, 68, 77, 84, 88], "side": 67, "uint8": [67, 75, 88], "swizzl": 67, "dtpype": 67, "float8rowwisetensor": 67, "float8blockwisetensor": 67, "confus": [67, 68, 84], "close": [67, 68], "low_precision_v": 67, "high_precision_v": 67, "procedur": 67, "especi": [67, 68, 73, 86, 87], "bitwidth": [67, 88], "codebook": 67, "look": [67, 68, 72, 83, 84, 85, 86, 87], "index": [67, 68, 74, 80, 87], "vector": [67, 68, 86], "kmean": 67, "cluster": [67, 72], "tradition": 67, "demonstr": [67, 69, 70, 72, 74, 77, 83, 85], "sai": [67, 78, 79, 88], "below": [67, 68, 72, 77, 78, 79, 83, 91], "explain": [67, 83, 86], "introduct": [67, 74, 80], "simplest": [67, 68], "form": [67, 68, 72], "easi": [67, 74], "linear_modul": 67, "requires_grad": [67, 69, 75, 77, 79], "runtim": [67, 70, 84], "question": [67, 68, 73, 77, 88], "activation_granular": 67, "act_quant_kwarg": 67, "quantized_weight": [67, 79], "float8_dtyp": 67, "haven": 67, "seen": 67, "pt2": [67, 77, 86], "fit": [67, 69, 73, 93], "autoround": 67, "multitensor": 67, "sure": [67, 74, 88], "open": [67, 68], "describ": [67, 68, 73, 84, 85, 91], "advis": 67, "focus": [67, 68, 69, 72, 74], "face": [67, 68, 71, 74, 84], "finetun": [67, 74], "quantized_train": 67, "extend": [67, 68, 86], "progress": [67, 78, 79], "lot": [67, 68], "connect": [67, 88], "walk": [67, 75, 77, 83, 86, 91], "float8dynamicactivationfloat8weightconfig": [67, 78], "happen": [67, 77, 84, 86], "len": [67, 74, 79, 84, 85, 88], "_choose_quant_func_and_quantize_tensor": 67, "omit": [67, 72, 84, 85, 86], "relat": [67, 68], "xq": 67, "reshap": [67, 84, 85], "wq": 67, "x_scale": [67, 84], "w_scale": 67, "out_shap": 67, "neural": [68, 83, 86], "network": [68, 77, 83, 86], "latenc": 68, "By": 68, "carefulli": 68, "achiev": [68, 69, 70, 72, 75, 77, 85, 86], "signific": [68, 74], "pai": 68, "reason": [68, 73, 93], "low": [68, 77, 78, 83], "price": 68, "qualiti": [68, 69, 78], "f1": 68, "problem": [68, 77], "research": [68, 91, 93], "fragment": 68, "rightfulli": 68, "show": [68, 72, 74, 79, 82, 84, 85], "time": [68, 70, 77, 78, 83, 84, 85, 91], "spent": 68, "figur": [68, 84], "place": [68, 83, 84, 85, 86, 87], "dens": [68, 92], "solv": [68, 74, 77], "onc": [68, 69, 93], "focu": [68, 77], "realli": 68, "push": [68, 74, 78, 79], "concret": [68, 88], "hope": 68, "modular": 68, "acceler": [68, 74, 78], "nice": 68, "scratch": [68, 91], "minim": [68, 83, 86, 87], "loss": [68, 69, 72, 84, 85, 93], "recov": [68, 69, 80, 85, 93], "algorthim": 68, "realiz": 68, "improv": [68, 69, 72, 74, 84, 87, 88, 92], "trade": [68, 74], "off": [68, 74], "theoret": 68, "gain": [68, 74, 87], "float16": [68, 92], "yield": [68, 69], "2x": [68, 70, 74], "analog": 68, "would": [68, 70, 77, 85, 87], "fix": [68, 75], "50": [68, 72, 75, 83, 84, 86, 87], "expect": [68, 72, 77, 83, 84, 86, 87, 88], "matric": [68, 69], "unstructur": 68, "share": 68, "mitig": [68, 69], "retrain": 68, "neglig": 68, "even": [68, 69, 72, 88], "area": 68, "agre": 68, "upon": 68, "consensu": 68, "mind": 68, "thought": 68, "subproblem": 68, "find": [68, 69, 84, 88], "my": [68, 85], "independ": 68, "frontend": [68, 86], "arbitrari": 68, "collect": [68, 72], "handoff": 68, "piec": 68, "natur": [68, 77, 84, 88], "becaus": [68, 69, 70, 72, 73, 77, 85, 88], "clear": 68, "contract": 68, "7x": 68, "advantag": 68, "anticip": 68, "solut": 68, "third": 68, "parti": 68, "to_sparse_semi_structur": 68, "sparsesemistructuredtensor": 68, "weightnormsparsifi": 68, "half": 68, "subnetwork": 68, "sparse_config": 68, "named_modul": 68, "tensor_fqn": 68, "sparse_block_shap": 68, "zeros_per_block": 68, "fakespars": 68, "fundament": [68, 85], "manipul": 68, "paramer": 68, "parameter": 68, "necessari": [68, 75, 77, 83, 84, 85, 86, 87], "ve": [68, 74], "suitabl": [68, 86], "spot": 68, "definit": [68, 79], "academia": 68, "industri": 68, "often": [68, 77], "interchang": 68, "thing": [68, 73, 77, 84], "distinct": 68, "pretrain": [68, 74, 83, 84, 85, 86], "avoid": [68, 73], "try": [68, 69, 77, 84], "roughli": 68, "idea": 68, "behind": 68, "doesn": [68, 85, 88], "box": [68, 72, 86], "itself": [68, 77], "those": [68, 74, 75, 77], "multipli": 68, "loos": 68, "speak": 68, "tightli": 68, "coupl": [68, 77], "csc": 68, "fbgemm": 68, "qnnpack": 68, "descript": [68, 83], "coo": 68, "sparse_coo": 68, "coordin": 68, "locat": 68, "bsr": 68, "sparse_bsr": 68, "veri": [68, 79, 85], "similar": [68, 69, 75, 85, 86], "except": [68, 77, 88], "individu": 68, "scalar": [68, 84], "dimension": 68, "csr": 68, "sparse_csr": 68, "sparse_csc": 68, "column": 68, "indic": [68, 88], "compact": 68, "sparse_matrix": 68, "1d": 68, "indexptr": 68, "storag": 68, "\u00bd": 68, "bitmask": 68, "2bit": 68, "unprun": 68, "quit": [68, 77], "simpl": [68, 70, 75, 77, 83, 86, 87], "successfulli": [68, 69], "These": [68, 69, 77, 83, 84, 85, 88], "broken": 68, "down": 68, "equal": [68, 73], "sensit": 68, "effect": [68, 75, 77, 86, 87, 88], "best": [68, 70, 86], "subsequ": [68, 77, 86, 87], "infinit": 68, "lost": 68, "degre": 68, "drop": 68, "give": [68, 74, 77], "curv": [68, 72], "proxi": 68, "much": [68, 69, 88], "aforement": 68, "less": [68, 77, 80, 84], "smallest": 68, "absolut": 68, "consid": 68, "v": [68, 72, 84, 88], "scope": 68, "impli": 68, "respect": [68, 85], "pro": [68, 74, 93], "con": 68, "potenti": [68, 75, 83, 84, 86, 87], "sub": 68, "tradeoff": [68, 69, 78], "span": 68, "over": [68, 72, 84, 85], "threshold": 68, "normal": [68, 84, 85], "complex": 68, "constant": [68, 77, 84], "ctr_mobile_fe": 68, "paper": [68, 69, 91], "score": 68, "w": [68, 79], "tenosr": 68, "udpat": 68, "cannot": [68, 75, 79], "histori": 68, "regrow": 68, "dw": 68, "via": [68, 83], "backprop": 68, "pat": 68, "unmask": 68, "resid": 68, "salienc": 68, "lowest": 68, "l1": 68, "shown": [68, 69, 74, 85, 88, 93], "abl": [68, 77, 79, 84, 88], "repeat": [68, 84, 85], "shot": [68, 69], "movement": 68, "tune": [68, 71, 72, 74, 83, 93], "2005": 68, "07683": 68, "rank": [68, 77], "wx": 68, "sqx": 68, "q": [68, 84], "usual": 68, "sort": 68, "wise": 68, "reconstruct": [68, 79], "seek": [68, 73], "random": [68, 74, 84, 85], "randomli": 68, "tri": 68, "remedi": 68, "line": [68, 72, 78], "sometim": 68, "item": [68, 91], "ultim": [68, 75], "complic": [68, 84], "literatur": 68, "vision": 68, "nlp": [68, 86, 91], "simpli": [68, 69, 75, 77], "again": [68, 84, 88], "iter": [68, 84, 85], "ctr_feed": 68, "na": 68, "multimask": 68, "search": 68, "pyspeech": 68, "fastna": 68, "approach": [68, 77, 83, 86, 87], "knowledg": [68, 91], "distil": 68, "pdf": 68, "2204": 68, "09656": 68, "arrang": 68, "recal": 68, "faster": [68, 70, 80, 93], "counterpart": 68, "slower": 68, "suffici": 68, "At": [68, 84], "98": 68, "exhibit": [68, 93], "penalti": 68, "expens": [68, 77], "dictat": 68, "characterist": 68, "highest": 68, "wouldn": [68, 77], "visual": 68, "fig": 68, "4x4": 68, "benchmak": 68, "serv": [69, 70, 71, 72, 77, 78, 87], "leverag": [69, 72, 74, 77, 86, 87, 93], "partner": [69, 72, 74], "showcas": [69, 72, 74], "blog": [69, 93], "resourc": [69, 77], "introduc": [69, 83, 84, 86, 87, 88], "small": [69, 70], "freez": [69, 85, 86, 87], "inevit": 69, "presum": 69, "recent": [69, 80], "releas": [69, 86], "1b": [69, 78, 79], "3b": [69, 93], "llamaguard": 69, "8b": [69, 70, 72, 78, 80, 93], "distribut": [69, 72, 75, 77, 79, 83, 93], "command": [69, 72, 93], "regular": [69, 83, 86, 87], "nnode": [69, 93], "nproc_per_nod": [69, 93], "full_finetune_distribut": 69, "llama3_2": 69, "3b_full": 69, "batch_siz": [69, 70, 73, 74, 75, 84, 85], "_component_": 69, "qat_distribut": [69, 93], "3b_qat_ful": 69, "evalu": [69, 70, 85], "wa": [69, 77, 85, 93], "llama3_2_3b": 69, "fullmodelhfcheckpoint": 69, "checkpoint_fil": 69, "00001": 69, "00002": 69, "safetensor": [69, 78], "int8dynactint4weightquant": 69, "hellaswag": [69, 74], "wikitext": [69, 93], "eleuther_ev": 69, "eleuther_evalu": 69, "task": [69, 74, 93], "fullmodeltorchtunecheckpoint": 69, "8da4w": [69, 74], "ckpt": 69, "llama3_token": 69, "tmp": 69, "meta": [69, 73, 78, 79, 88], "stderr": 69, "acc": [69, 84, 85], "5021": 69, "0050": 69, "acc_norm": 69, "6797": 69, "0047": 69, "bits_per_byt": 69, "6965": 69, "byte_perplex": 69, "6206": 69, "word_perplex": 69, "13": [69, 93], "2199": 69, "openassist": 69, "oasst1": 69, "dataset": [69, 72, 74, 83, 86, 87, 93], "higher": [69, 72, 77, 78, 83, 84, 86, 87, 93], "69": [69, 75], "overal": [69, 70, 80, 84, 88], "vanilla": [69, 93], "lora": [69, 93], "89x": [69, 80, 93], "36": [69, 72, 74, 93], "qat_lora_finetune_distribut": [69, 93], "3b_qat_lora": 69, "fsdp2": [69, 72, 93], "yaml": [69, 93], "complet": [69, 74, 83, 87, 93], "qat_out": [69, 93], "quatiz": [69, 93], "hood": 69, "mini": [69, 74], "gpu": [69, 70, 72, 78, 79, 83, 91, 92, 93], "accordingli": 69, "get_model": [69, 93], "vocab_s": [69, 93], "num_lay": [69, 93], "num_head": [69, 93], "num_kv_head": [69, 93], "embed_dim": [69, 93], "2048": [69, 72, 93], "max_seq_len": [69, 93], "001": [69, 93], "momentum": [69, 85, 93], "9": [69, 72, 80, 93], "weight_decai": [69, 93], "1e": [69, 72, 93], "loss_fn": [69, 93], "crossentropyloss": [69, 84, 85, 93], "randint": [69, 93], "next": [69, 72, 75, 84, 85, 86, 87], "attun": 69, "benefici": 69, "readi": [69, 70, 72, 74, 75, 77, 85], "legaci": [69, 93], "offer": [69, 70, 77, 84], "unlik": [69, 75], "int8dynactint4weightqatquant": [69, 93], "qat_quant": [69, 93], "insert": [69, 70, 75, 82, 83, 84, 85, 86, 87, 88, 93], "int8dynactint4weightqatlinear": [69, 93], "int8dynactint4weightlinear": [69, 93], "fraction": 69, "therebi": [69, 93], "significantli": [69, 70, 83, 84, 86, 87], "footprint": 69, "extens": [69, 77, 84, 86], "addition": [69, 86, 87, 93], "frozen": 69, "further": [69, 77, 83, 84, 85, 86], "nf4": 69, "express": [69, 77, 82, 83, 84, 85, 88], "nf4tensor": 69, "cleanli": 69, "to_nf4": 69, "frozennf4linear": 69, "in_dim": 69, "out_dim": 69, "quantization_kwarg": 69, "requires_grad_": 69, "nf4_weight": 69, "though": [69, 77], "baselin": [69, 72, 74, 84, 93], "reap": 69, "incorpor": 69, "loralinear": 69, "lora_finetune_single_devic": 69, "3b_qlora_single_devic": 69, "invok": [69, 86], "loraconfig": 69, "get_peft_model": [69, 93], "automodelforcausallm": [69, 74, 78, 79], "torchaoconfig": [69, 74, 78, 79], "base_model": 69, "quantization_config": [69, 74, 78, 79, 87], "peft_config": 69, "throughput": [69, 70, 72, 74], "torchtitan": 69, "enable_fp8_train": 69, "fp8_recipe_nam": 69, "experi": [69, 72, 87, 93], "saw": 69, "experiment_nam": 69, "tok": 69, "peak_mem_reserv": 69, "6502": 69, "143": 69, "000": 69, "30": [69, 72, 84], "090": 69, "fp8_nonam": 69, "7205": 69, "386": 69, "816": 69, "010": 69, "266": 69, "fp8_tensorwis": 69, "7222": [69, 93], "198": 69, "11": [69, 72], "074": [69, 72], "fp8_rowwis": 69, "6387": 69, "968": 69, "756": 69, "29": [69, 72], "158": 69, "096": 69, "fp8_rowwise_with_gw_hp": 69, "7573": 69, "698": 69, "480": 69, "516": 69, "908": 69, "hellaswag_acc": 69, "wikitext_word_perplex": 69, "533": 69, "12": [69, 72, 80, 87, 88, 93], "407": [69, 72], "414": 69, "007": 69, "412": 69, "005": 69, "420": [69, 93], "013": [69, 72], "534": 69, "416": 69, "009": 69, "entri": 70, "mutat": 70, "toylinearmodel": [70, 73, 75], "hidden_dim": 70, "has_bia": 70, "linear2": [70, 73, 75, 77], "eval": [70, 73, 74, 75, 82, 83, 85, 86, 87, 93], "model_w16a16": 70, "model_w8a8": 70, "chapter": 70, "remain": [70, 86, 87], "unchang": 70, "__name__": 70, "approxim": 70, "disk": 70, "o": [70, 84, 85], "state_dict": [70, 72, 73, 84, 85], "pth": [70, 72, 84, 85], "original_s": 70, "getsiz": [70, 84, 85], "quantized_s": 70, "2f": [70, 84, 85], "mb": [70, 73, 84, 85, 90], "00x": 70, "00mb": 70, "warmup": [70, 72], "synchron": 70, "100": [70, 77, 84, 85], "original_tim": 70, "quantized_tim": 70, "03x": 70, "larger": 70, "enough": 70, "toi": [70, 72, 75, 77, 86], "address": [70, 84], "vllm": [70, 71, 78], "lm": [70, 74], "visit": 70, "forget": 70, "good": [70, 77, 88], "qlora": [71, 74], "sglang": [71, 78], "hug": [71, 74], "advanc": [71, 75, 77, 83, 86, 87], "5x": [72, 80], "34": 72, "43x": 72, "2k": 72, "h200": 72, "latest": [72, 80], "offic": 72, "sever": [72, 79, 83, 88], "popular": 72, "flagship": 72, "quickli": [72, 77], "batteri": 72, "fork": 72, "virtual": 72, "environ": [72, 74], "conda": 72, "venv": 72, "download": [72, 74, 80, 84, 85, 87, 89, 91], "job": 72, "root": [72, 74], "launch": 72, "ngpu": 72, "config_fil": 72, "train_config": 72, "llama3_8b": 72, "toml": 72, "run_train": 72, "sh": [72, 74], "hyperparamet": 72, "edit": [72, 74], "flag": [72, 80, 85], "termin": 72, "rank0": 72, "titan": 72, "2025": 72, "06": 72, "04": 72, "08": 72, "51": 72, "48": 72, "info": 72, "2254": 72, "27": 72, "34gib": 72, "28": 72, "78": 72, "tp": [72, 79], "375": 72, "tflop": 72, "21": 72, "73": [72, 75], "mfu": 72, "20": [72, 74, 85], "58": [72, 80], "557": 72, "7069": 72, "99gib": 72, "62": 72, "7": [72, 74, 86, 87, 92], "034": 72, "35": [72, 74, 75], "41": [72, 74], "19": 72, "52": 72, "224": [72, 75, 83, 84, 85, 86, 87], "9196": 72, "022": 72, "406": [72, 84, 85], "65": 72, "904": 72, "1423": 72, "014": 72, "23": [72, 75], "As": [72, 84, 88], "7k": 72, "99gb": 72, "peak": [72, 74, 78], "against": 72, "02": 72, "37": 72, "404": 72, "2611": 72, "22gib": 72, "595": 72, "47": 72, "49": [72, 75], "027": 72, "4260": 72, "89gib": 72, "344": 72, "367": 72, "39": [72, 93], "03": 72, "01": 72, "988": 72, "9482": 72, "321": 72, "366": 72, "14": 72, "991": 72, "1183": 72, "300": 72, "364": 72, "89": 72, "40": [72, 93], "4659": 72, "291": 72, "84": 72, "769": 72, "gc": 72, "peform": 72, "period": 72, "3k": 72, "89gb": 72, "11x": 72, "nearli": 72, "performan": 72, "648": 72, "2648": 72, "28gib": 72, "71": 72, "26": [72, 93], "475": 72, "9106": 72, "91gib": 72, "53": [72, 74], "503": 72, "434": 72, "43": 72, "94": [72, 84], "166": 72, "0774": 72, "663": 72, "443": 72, "44": [72, 75], "87": 72, "885": 72, "3233": 72, "643": 72, "442": 72, "66": [72, 74, 75, 93], "76": 72, "613": 72, "6150": 72, "637": 72, "72": [72, 74], "6k": 72, "91gb": 72, "21x": [72, 74], "tl": 72, "dr": 72, "priorit": 72, "stabil": 72, "cost": [72, 75], "slightli": [72, 77], "impact": [72, 74, 79], "outlier": 72, "caus": 72, "underflow": 72, "8xh100": 72, "convert_to_float8_train": 72, "recurs": 72, "kind": [72, 84], "snippet": [72, 84, 85], "float8_linear_util": 72, "float8_linear": 72, "adamw": 72, "label": 72, "fake_label": 72, "ones_lik": 72, "mse_loss": 72, "model_state_dict": 72, "optimizer_state_dict": 72, "explor": [72, 87], "few": [72, 77, 84, 85, 93], "tempfil": [73, 78], "get_model_size_in_byt": 73, "ref": [73, 84], "namedtemporaryfil": 73, "m_load": 73, "load_state_dict": [73, 84, 85], "assign": 73, "assert": [73, 75, 77, 79, 88], "float_weight1": 73, "float_weight2": 73, "quantized_weight1": 73, "quantized_weight2": 73, "go": [73, 77, 88], "techinqu": 73, "4x": [73, 74], "0625": 73, "affine_quantized_tensor": 73, "deploi": 74, "engin": 74, "seamlessli": [74, 77, 86, 87], "seamless": [74, 86], "hf": [74, 78], "pip": [74, 78, 80, 83, 84], "url": [74, 80, 87], "whl": [74, 80, 87], "nightli": [74, 80], "cu128": [74, 80], "hub": [74, 78, 79], "server": [74, 79], "phi": 74, "fp8": 74, "microsoft": 74, "o3": 74, "client": 74, "curl": 74, "localhost": 74, "8000": 74, "v1": 74, "chat": 74, "content": 74, "messag": 74, "role": 74, "me": 74, "short": 74, "larg": [74, 77, 86], "temperatur": 74, "top_p": 74, "95": 74, "top_k": 74, "max_token": 74, "32768": 74, "vram": 74, "15x": 74, "littl": [74, 79], "packag": [74, 78], "git": [74, 78], "com": [74, 78, 93], "autotoken": [74, 78], "pipelin": 74, "manual_se": [74, 84, 85], "model_path": 74, "device_map": [74, 78, 79], "trust_remote_cod": 74, "ai": 74, "assist": 74, "eat": 74, "banana": 74, "dragonfruit": 74, "smoothi": 74, "blend": 74, "milk": 74, "honei": 74, "salad": 74, "mix": [74, 83, 86, 87], "slice": [74, 79], "lemon": 74, "juic": 74, "equat": 74, "pipe": [74, 78], "text": 74, "generation_arg": 74, "max_new_token": 74, "500": 74, "return_full_text": 74, "do_sampl": 74, "generated_text": 74, "design": [74, 79, 83, 84, 88], "lm_head": 74, "ti": 74, "autoprocessor": 74, "modeling_util": 74, "find_tied_paramet": 74, "model_id": [74, 78], "untied_model": 74, "getattr": [74, 79], "get_text_config": 74, "tie_word_embed": 74, "setattr": [74, 77], "_tied_weights_kei": 74, "user_id": 74, "your_user_id": 74, "model_nam": [74, 83, 86, 87], "save_to": [74, 78], "save_to_local_path": 74, "int8dynamicactivationintxweightconfig": [74, 78], "intxweightonlyconfig": [74, 78], "fqntoconfig": [74, 79], "untied_model_id": 74, "untied_model_local_path": 74, "embedding_config": 74, "quant_config": 74, "embed_token": 74, "quant_typ": [74, 78, 79], "include_embed": 74, "untie_embedding_weight": 74, "modules_to_not_convert": 74, "quantized_model": [74, 77, 78, 83, 84, 85], "safe_seri": [74, 78, 79], "pte": 74, "cd": 74, "install_requir": 74, "phi_4_mini": 74, "convert_weight": 74, "pytorch_model": 74, "bin": 74, "pytorch_model_convert": 74, "export_llama": 74, "kv": 74, "use_sdpa_with_kv_cach": 74, "get_bos_id": 74, "199999": 74, "get_eos_id": 74, "200020": 74, "max_seq_length": 74, "max_context_length": 74, "output_nam": 74, "phi4": 74, "phone": 74, "io": 74, "2gb": 74, "iphon": 74, "17": [74, 93], "sec": 74, "test": [74, 78, 84, 86, 91], "har": 74, "eleutherai": 74, "lm_eval": 74, "model_arg": 74, "reset_peak_memory_stat": 74, "prompt": [74, 78], "hei": 74, "consciou": 74, "templated_prompt": 74, "apply_chat_templ": 74, "add_generation_prompt": 74, "templat": [74, 89, 90], "return_tensor": 74, "pt": 74, "generated_id": 74, "output_text": 74, "batch_decod": 74, "skip_special_token": 74, "clean_up_tokenization_spac": 74, "respons": 74, "mem": 74, "max_memory_reserv": 74, "1e9": 74, "02f": 74, "gb": 74, "hello": [74, 78], "ye": 74, "am": 74, "digit": 74, "todai": 74, "70": [74, 75], "bench": 74, "vllm_disable_compile_cach": 74, "project": 74, "vllm_use_precompil": 74, "sharegpt": 74, "wget": 74, "co": 74, "anon8231489123": 74, "sharegpt_vicuna_unfilt": 74, "resolv": 74, "sharegpt_v3_unfiltered_cleaned_split": 74, "tree": 74, "num": 74, "benchmark_serv": 74, "16x": 74, "14x": 74, "num_prompt": 74, "req": 74, "57": [74, 75], "1000": [74, 86], "68": 74, "80": 74, "ml": 74, "eas": 74, "accept": [74, 88, 93], "fly": [75, 78], "affinequantizedminmaxobserv": 75, "record": 75, "welcom": 75, "desir": 75, "averag": [75, 84, 85], "histogram": [75, 84], "act_ob": 75, "finfo": 75, "zero_point_dtyp": 75, "weight_ob": 75, "observedlinear": 75, "observed_input": 75, "observed_weight": 75, "from_float": [75, 77], "float_linear": 75, "observed_linear": 75, "_replace_with_custom_fn_if_matches_filt": 75, "insert_observers_": 75, "lambda": [75, 79, 93], "replacement_fn": 75, "copied_act_ob": 75, "copied_weight_ob": 75, "popul": 75, "feed": 75, "simpler": [75, 84], "quantizedlinear": [75, 77], "isn": 75, "strictli": 75, "to_affine_quantized_intx_stat": 75, "act_scal": [75, 88], "act_zero_point": 75, "calculate_qparam": [75, 88], "weight_scal": [75, 84, 88], "weight_zero_point": [75, 84], "qweight": 75, "qinput": 75, "from_observ": 75, "quantized_linear": [75, 84], "begin": [75, 77], "dataclass": [75, 79, 88], "transform_modul": [75, 79], "register_quantize_module_handl": [75, 79], "staticquantconfig": 75, "_apply_static_qu": 75, "associ": 75, "identifi": [75, 88], "is_observed_linear": 75, "optimizedmodul": 75, "_orig_mod": 75, "0237": 75, "tensor_impl": 75, "plainaqttensorimpl": 75, "142": 75, "31": [75, 88], "113": 75, "157": 75, "59": 75, "160": 75, "150": 75, "67": [75, 80], "241": 75, "238": 75, "235": 75, "228": 75, "255": [75, 88], "201": 75, "114": 75, "236": 75, "88": [75, 84], "83": 75, "109": 75, "209": 75, "92": 75, "184": 75, "141": 75, "110": 75, "0009": 75, "0010": 75, "130": 75, "122": 75, "132": 75, "125": 75, "126": 75, "129": 75, "127": [75, 77, 87, 88], "133": 75, "124": 75, "131": 75, "135": 75, "136": 75, "_layout": 75, "foundat": 77, "autograd": [77, 88], "highlight": [77, 80, 91], "interpos": 77, "namespac": 77, "continu": [77, 78, 85, 86, 87, 88], "obviou": 77, "int8quantizedlinear": 77, "finer": 77, "intercept": 77, "contrast": [77, 93], "long": [77, 84], "clunki": 77, "distributedlinear": 77, "duplic": 77, "bypass": 77, "wrap": [77, 86, 87], "outer": 77, "inner": 77, "allgath": 77, "bandwidth": 77, "stai": 77, "exactli": [77, 93], "zoo": 77, "podcast": 77, "edward": 77, "yang": 77, "int8_symmetric_quant": 77, "fp32_tensor": 77, "quant_min": [77, 87, 88], "quant_max": [77, 87, 88], "min_val": 77, "amin": 77, "keepdim": [77, 84, 85], "max_val": 77, "amax": 77, "min_val_neg": 77, "zeros_lik": 77, "max_val_po": 77, "view": [77, 84, 85], "clamp": [77, 84, 93], "w_int8": 77, "new_linear": 77, "left": [77, 88], "toymodel": 77, "float_model": [77, 82, 83, 84, 85, 86, 87], "child": 77, "named_children": 77, "drawback": 77, "won": 77, "suppos": 77, "clean": [77, 93], "eleg": 77, "pretti": 77, "overrid": 77, "almost": 77, "shard": [77, 79], "ragged": 77, "rag": 77, "nestedtensor": 77, "who": 77, "link": [77, 91, 92], "why": [77, 91], "googl": [77, 93], "collab": 77, "flopcount": 77, "memorytrack": 77, "bare": 77, "bone": 77, "int8symmetrictensor": 77, "hold": [77, 78], "int_data": 77, "staticmethod": 77, "_dynamo": 77, "_make_wrapper_subclass": [77, 79], "stride": 77, "storage_offset": 77, "ndim": 77, "extra_metadata": 77, "outer_s": [77, 79], "outer_strid": [77, 79], "undo": 77, "repr": 77, "float_tensor": 77, "ahead": 77, "insid": 77, "int8_tensor": 77, "op_implementations_dict": 77, "assertionerror": 77, "conveni": 77, "register_op": 77, "_op": 77, "opoverload": 77, "impl_decor": 77, "op_impl": 77, "done": [77, 93], "wrapper": [77, 82, 86], "particular": 77, "largest": 77, "tell": 77, "desugar": 77, "surfac": 77, "coverag": [77, 83, 84, 86, 87], "brute": 77, "forc": 77, "repeatedli": 77, "log": 77, "loggingtensor": 77, "_python_dispatch": [77, 79], "return_and_correct_alias": [77, 79], "int8_mm": 77, "int8_view_op": 77, "out_data": 77, "out_scal": [77, 84], "notic": 77, "hit": 77, "background": 77, "decomposit": 77, "live": 77, "decomp": 77, "shrink": 77, "author": [77, 83, 84, 85, 86, 87, 88, 91], "But": [77, 79, 88], "pain": 77, "rather": 77, "worth": 77, "written": 77, "differenti": 77, "nuanc": 77, "longer": [77, 84, 85], "had": [77, 84], "transpos": 77, "That": 77, "transposit": 77, "got": [77, 84, 88], "propag": [77, 84, 86, 87], "fact": 77, "themselv": [77, 84], "pointwis": [77, 86, 87], "were": 77, "might": [77, 79, 84, 88], "unwrap": 77, "dim0": 77, "dim1": 77, "confirm": 77, "quantized_model_module_swap": 77, "quantized_model_subclass": 77, "subclass_param": 77, "no_grad": [77, 82, 83, 84, 85, 86, 87], "out_module_swap": 77, "allclos": 77, "out_compil": 77, "seri": 77, "discuss": 77, "float8dynamicactivationint4weightconfig": 78, "use_hqq": [78, 79], "torch_dtyp": 78, "fluxpipelin": 78, "fluxtransformer2dmodel": 78, "black": 78, "forest": 78, "lab": 78, "flux": 78, "subfold": 78, "cat": [78, 88], "sign": [78, 87], "world": [78, 79], "imag": [78, 82, 83, 84, 85, 86, 87], "num_inference_step": 78, "guidance_scal": 78, "png": 78, "temporarydirectori": 78, "tmp_dir": 78, "uncom": 78, "usernam": [78, 79], "statu": [78, 79], "becom": [78, 84], "stabl": [78, 80], "int4wo": 78, "team": [78, 79], "track": [78, 79], "retain": 78, "thoroughli": 78, "e2": 79, "_type": 79, "_data": 79, "capabl": [79, 84, 86], "self_attn": 79, "k_proj": [79, 93], "mlp": 79, "gate_proj": [79, 93], "narrow": 79, "host": 79, "state": 79, "chunk": 79, "heavi": 79, "codebas": 79, "fn": 79, "ctx": 79, "new_tensor": 79, "__class__": 79, "principl": 79, "mynewquantconfig": 79, "classvar": 79, "myquantizedtensor": 79, "tensor_data_attr": 79, "quantized_data": 79, "tensor_attribut": 79, "attr": 79, "fill_default": 79, "notimplementederror": 79, "_my_quant_transform": 79, "my_quantization_funct": 79, "use_cutlass_kernel": 79, "my_cutlass_linear": 79, "my_triton_linear": 79, "standard": 79, "disappear": 79, "unless": 79, "extrem": 79, "sole": 79, "explicitli": [79, 88], "spooki": 79, "distanc": 79, "due": [79, 83, 88], "workaround": 79, "2338": 79, "detect": 79, "illustr": 79, "70b": 80, "gemma3": [80, 93], "4b": [80, 93], "cu126": 80, "cu129": 80, "isol": 80, "use_cuda": 80, "use_xpu": 80, "use_cpp": 80, "recogn": [82, 88], "decis": 82, "deleg": [82, 84], "x86inductorquant": [82, 86], "quantize_pt2": [82, 83, 84, 85, 86, 87], "prepare_pt2": [82, 83, 84, 86, 87], "x86_inductor_quant": [82, 86], "get_default_x86_inductor_quantization_config": [82, 86], "calibr": [82, 83, 85, 86, 87], "data_load": [82, 84, 85, 86, 87], "program": [82, 84, 85, 86, 88], "captur": [82, 84, 85, 88], "expos": [82, 84, 85], "set_glob": [82, 84, 85, 86, 87], "xiq": [82, 86], "prepare_qat_pt2": [82, 85, 86], "sample_inference_data": 82, "convert_pt2": [82, 83, 84, 85, 86, 87], "_inductor": [82, 86], "cpp_wrapper": [82, 86], "optimized_model": [82, 83, 86, 87], "converted_model": [82, 86, 87], "x86": 82, "openvino": 82, "daniil": 83, "lyakhov": 83, "aamir": 83, "nazir": 83, "alexand": 83, "suslov": 83, "yamini": 83, "nimmagadda": 83, "kozlov": 83, "subject": [83, 85], "openvinoquant": 83, "unlock": 83, "placement": 83, "simplifi": [83, 84, 86, 87], "ux": [83, 84, 86], "torchdynamo": [83, 86, 87, 88], "four": 83, "eager": [83, 84, 85, 86, 87, 88], "mechan": [83, 86, 87], "torchvis": [83, 84, 85, 86, 87, 88], "resnet18": [83, 84, 85, 86, 87], "pt2e": [83, 84, 85, 86, 87], "__dict__": [83, 84, 85, 86, 87], "dummi": [83, 86, 87], "traced_b": [83, 86, 87], "exported_model": [83, 84, 85, 86, 87], "preset": 83, "elu": 83, "prelu": 83, "gelu": 83, "quantizationpreset": 83, "bert": [83, 86], "modeltyp": 83, "ignored_scop": 83, "exclud": 83, "layer_1": 83, "layer_2": 83, "layer_3": 83, "ignoredscop": 83, "conv2d": [83, 84, 85, 86, 87, 88], "layer_": 83, "subgraph": [83, 85], "node": [83, 85, 86, 87, 88], "target_devic": 83, "taken": 83, "account": 83, "cpu_spr": 83, "npu": 83, "targetdevic": 83, "fold": [83, 84, 86, 87], "batchnorm": [83, 84, 85, 86, 87], "prepared_model": [83, 84, 85, 86, 87], "fold_quant": 83, "finish": [83, 86], "intel": [83, 86, 92], "comparison": 83, "smoothquant": 83, "biascorrect": 83, "discrep": 83, "calibration_load": 83, "dataload": [83, 84, 85], "transform_fn": 83, "data_item": 83, "calibration_dataset": 83, "smooth_quant": 83, "fast_bias_correct": 83, "deploy": [83, 86], "jerri": [84, 86, 88], "zhang": [84, 86, 87, 88], "_export": [84, 85], "fx": [84, 88], "14k": 84, "programm": [84, 86, 87], "prerequisit": [84, 91], "db": 84, "xnnpack": [84, 85, 88], "xnnpack_quant": [84, 85], "get_symmetric_quantization_config": [84, 85], "xnnpackquant": [84, 85, 88], "prior": 84, "qconfigmap": [84, 88], "backendconfig": [84, 88], "rel": 84, "intent": [84, 88], "qconfig": [84, 88], "3d": [84, 88], "incompat": 84, "great": 84, "ideal": 84, "fake_qu": 84, "hidden": 84, "summari": 84, "interact": 84, "thu": 84, "queri": [84, 88], "previous": 84, "embedding_byt": 84, "executorchquant": 84, "concaten": 84, "prone": 84, "cleaner": 84, "composed_quant": 84, "quantization_cap": 84, "concern": 84, "decoupl": 84, "minmax": 84, "freed": 84, "identitc": 84, "imagenet": [84, 85], "unzip": [84, 85], "data_path": [84, 85], "renam": [84, 85], "resnet18_pretrained_float": [84, 85], "sy": [84, 85], "numpi": [84, 85], "np": [84, 85], "resnet": [84, 85, 86], "warn": [84, 85], "filterwarn": [84, 85], "categori": [84, 85], "deprecationwarn": [84, 85], "r": [84, 85, 93], "seed": [84, 85], "191009": [84, 85], "averagemet": [84, 85], "fmt": [84, 85], "reset": [84, 85], "val": [84, 85], "avg": [84, 85], "count": [84, 85], "__str__": [84, 85], "fmtstr": [84, 85], "topk": [84, 85], "predict": [84, 85], "maxk": [84, 85], "pred": [84, 85], "correct": [84, 85], "eq": [84, 85], "expand_a": [84, 85], "correct_k": [84, 85], "mul_": [84, 85], "criterion": [84, 85], "top1": [84, 85], "top5": [84, 85], "cnt": [84, 85], "acc1": [84, 85], "acc5": [84, 85], "load_model": [84, 85], "model_fil": [84, 85], "weights_onli": [84, 85], "print_size_of_model": [84, 85], "temp": [84, 85], "p": [84, 85], "1e6": [84, 85], "prepare_data_load": [84, 85], "485": [84, 85], "456": [84, 85], "std": [84, 85], "229": [84, 85], "225": [84, 85], "randomresizedcrop": [84, 85], "randomhorizontalflip": [84, 85], "totensor": [84, 85], "dataset_test": [84, 85], "resiz": [84, 85], "centercrop": [84, 85], "train_sampl": [84, 85], "randomsampl": [84, 85], "test_sampl": [84, 85], "sequentialsampl": [84, 85], "train_batch_s": [84, 85], "sampler": [84, 85], "data_loader_test": [84, 85, 86, 87], "eval_batch_s": [84, 85], "saved_model_dir": [84, 85], "float_model_fil": [84, 85], "model_to_quant": [84, 85], "rand": [84, 85, 91], "capture_pre_autograd_graph": [84, 85], "dynamic_shap": [84, 85], "dynamic_dim": [84, 85], "qconfig_opt": 84, "set_object_typ": 84, "set_module_nam": 84, "workload": 84, "themodel": 84, "feedback": 84, "dq": 84, "fp32_op": 84, "qauntiz": 84, "x_int8": 84, "x_zero_point": 84, "weight_int8": 84, "bias_fp32": 84, "output_scal": 84, "output_zero_point": 84, "x_fp32": 84, "quantized_decompos": 84, "dequantize_per_tensor": 84, "x_i8": 84, "x_quant_min": 84, "x_quant_max": 84, "weight_fp32": 84, "weight_i8": 84, "weight_quant_min": 84, "weight_quant_max": 84, "weight_permut": 84, "permute_copi": 84, "out_fp32": 84, "addmm": 84, "out_i8": 84, "quantize_per_tensor": 84, "out_zero_point": 84, "out_quant_min": 84, "out_quant_max": 84, "float32_op": 84, "decompos": 84, "use_reference_represent": 84, "x_int16": 84, "int16": 84, "weight_int16": 84, "acc_int32": 84, "out_dtyp": 84, "bias_scal": 84, "bias_int32": 84, "div": 84, "mul": 84, "out_int8": 84, "qmin": [84, 93], "qmax": [84, 93], "date": 84, "unus": 84, "serila": 84, "consult": 84, "exportedprogram": 84, "pt2e_quantized_model_file_path": 84, "resnet18_pt2e_quant": 84, "quantized_ep": 84, "loaded_quantized_ep": 84, "loaded_quantized_model": 84, "diff": 84, "79": 84, "82": 84, "55": 84, "edg": [84, 88, 92], "went": 84, "andrew": 85, "Or": 85, "move_exported_model_to_ev": [85, 86], "correctli": 85, "certain": 85, "dropout": 85, "move_exported_model_to_train": 85, "jit": 85, "recursivescriptmodul": 85, "train_one_epoch": 85, "ntrain_batch": 85, "avgloss": 85, "5f": 85, "start_tim": 85, "3f": 85, "global_avg": 85, "is_qat": [85, 86], "fusion": 85, "batchnorm2d": 85, "_native_batch_norm_legit": 85, "cudnn_batch_norm": 85, "mobilenetv2": 85, "manual": 85, "recompil": 85, "consolid": 85, "epoch": 85, "far": 85, "num_epoch": 85, "num_train_batch": 85, "num_eval_batch": 85, "num_observer_update_epoch": 85, "num_batch_norm_update_epoch": 85, "num_epochs_between_ev": 85, "nepoch": 85, "stat": 85, "subseq": 85, "disable_observ": 85, "bn": 85, "running_mean": 85, "running_var": 85, "new_arg": 85, "wish": 85, "prepared_model_copi": 85, "neval_batch": 85, "paus": 85, "resum": 85, "fail": [85, 88], "machin": 85, "checkpoint_path": 85, "checkpoint_": 85, "behav": 85, "incorrectli": 85, "lesli": [86, 88], "fang": [86, 88], "weiwen": [86, 88], "xia": [86, 88], "jiong": [86, 88], "gong": [86, 88], "cnn": 86, "rnn": 86, "outstand": 86, "fourth": 86, "spr": 86, "xeon": 86, "processor": 86, "boost": 86, "memory_format": [86, 87], "channels_last": [86, 87], "onednn": [86, 87], "assum": [86, 88], "word": 86, "satur": 86, "extern": 86, "pure": 86, "dedic": 86, "scenario": [86, 87], "plai": [86, 87], "convolut": [86, 87, 88], "absenc": [86, 87], "enhanc": [86, 87], "mirror": [86, 87], "autocast": [86, 87], "device_typ": [86, 87], "turn": [86, 87], "cpp": 86, "qconvolut": [86, 87], "qlinear": [86, 87], "presenc": [86, 87], "pair": [86, 87], "conting": [86, 87], "qmaxpool2d": [86, 87], "torchinductor_freez": [86, 87], "example_x86inductorquantizer_pytorch_2_1": 86, "torchbench": 86, "measur": 86, "proven": 86, "depth": 86, "example_x86inductorquantizer_qat": 86, "yan": 87, "zhiwei": 87, "wang": 87, "eikan": 87, "liangang": 87, "liu": 87, "river": 87, "cui": 87, "yifeng": 87, "xpuinductorquant": 87, "pip3": 87, "torchaudio": 87, "xpu_inductor_quantizer_exampl": 87, "xpu_inductor_quant": 87, "xpuiq": 87, "resnet18_weight": 87, "get_default_xpu_inductor_quantization_config": 87, "wherea": 87, "histogramobserv": [87, 88], "perchannelminmaxobserv": 87, "quantizationspec": [87, 88], "quantizationconfig": [87, 88], "type_check": 87, "observerorfakequantizeconstructor": 87, "get_xpu_inductor_symm_quantization_config": 87, "extra_arg": 87, "act_observer_or_fake_quant_ctr": 87, "act_quantization_spec": [87, 88], "qscheme": [87, 88], "per_tensor_symmetr": [87, 88], "observer_or_fake_quant_ctr": [87, 88], "with_arg": [87, 88], "weight_observer_or_fake_quant_ctr": 87, "weight_quantization_spec": [87, 88], "per_channel_symmetr": 87, "ch_axi": 87, "oc": 87, "ic": 87, "kh": 87, "kw": 87, "conv": [87, 88], "bias_quantization_spec": 87, "amp": 87, "indcutor": 87, "kimish": 88, "patel": 88, "explicit": 88, "quantiat": 88, "encod": 88, "convei": 88, "quantizationannot": 88, "furthermor": 88, "minmaxobserv": 88, "input_qspec_map": 88, "output_qspec": 88, "_annot": 88, "conclud": 88, "matcher": 88, "get_source_partit": 88, "add_partit": 88, "gm": 88, "itertool": 88, "chain": 88, "add_nod": 88, "output_nod": 88, "per_tensor_affin": 88, "input_act_qspec": 88, "output_act_qspec": 88, "input_act0": 88, "input_act1": 88, "quantization_annot": 88, "substitut": 88, "among": 88, "sharedquantizationspec": 88, "maxpool": 88, "average_pool": 88, "concat": 88, "whose": 88, "edgeornod": 88, "transit": 88, "spec": 88, "conv1": 88, "conv2": 88, "fed": 88, "conv1_out": 88, "conv2_out": 88, "qspec1": 88, "cat_input0": 88, "cat_input1": 88, "implicitli": 88, "therefor": 88, "ob": 88, "consum": 88, "rewrit": 88, "share_qparams_with_input_act0_qspec": 88, "known": 88, "beforehand": 88, "sigmoid": 88, "fixedqparamsquantizationspec": 88, "act_qspec": 88, "sigmoid_nod": 88, "input_act": 88, "derivedquantizationspec": 88, "derive_qparams_fn": 88, "observerorfakequant": 88, "observerbas": 88, "fakequantizebas": 88, "heurist": 88, "obejct": 88, "obs_or_fq": 88, "fq": 88, "act_obs_or_fq": 88, "weight_obs_or_fq": 88, "act_zp": 88, "weight_zp": 88, "bias_qspec": 88, "derived_from": 88, "backendquant": 88, "get_input_act_qspec": 88, "get_output_act_qspec": 88, "get_weight_qspec": 88, "get_bias_qspec": 88, "intermedi": 88, "straightforward": 88, "call_funct": 88, "relu_": 88, "relu_nod": 88, "maybe_conv_nod": 88, "conv1d": 88, "unexpect": 88, "recognz": 88, "unquant": 88, "subgraphmatch": 88, "conv_relu_pattern": 88, "name_node_map": 88, "input_nod": 88, "weight_nod": 88, "bias_nod": 88, "caveat": 88, "exhaust": 88, "2d": 88, "4d": 88, "symbol": 88, "outcom": 88, "tutorials_python": 89, "zip": 89, "jupyt": [89, 91], "notebook": [89, 91, 93], "tutorials_jupyt": 89, "galleri": [89, 91], "sphinx": [89, 91], "00": 90, "004": [90, 91], "total": [90, 91], "template_tutori": [90, 91], "click": 91, "firstnam": 91, "lastnam": 91, "v2": 91, "topic": 91, "8375": 91, "5692": 91, "3580": 91, "8303": 91, "1641": 91, "6754": 91, "9618": 91, "5853": 91, "5764": 91, "8472": 91, "3030": 91, "9159": 91, "7183": 91, "4224": 91, "0481": 91, "practic": 91, "summar": 91, "takeawai": 91, "link1": 91, "link2": 91, "minut": 91, "ipynb": [91, 93], "b200": [92, 93], "bmg": 92, "mi350x": 92, "moe": 92, "128x128": 92, "blockwis": 92, "1x128": 92, "md": 92, "perplex": 93, "x_q": 93, "zp": 93, "x_float": 93, "x_fq": 93, "proce": 93, "torchtun": 93, "int8dynactint4qatquant": 93, "int4weightonlyqatquant": 93, "int4weightonlyembeddingqatquant": 93, "composableqatquant": 93, "fastlanguagemodel": 93, "qwen3": 93, "2507": 93, "load_in_4bit": 93, "full_finetun": 93, "target_modul": 93, "v_proj": 93, "o_proj": 93, "up_proj": 93, "down_proj": 93, "lora_alpha": 93, "qat_schem": 93, "colab": 93, "unslothai": 93, "blob": 93, "nb": 93, "qwen3_": 93, "14b": 93, "8b_qat_ful": 93, "earli": 93, "8b_qat_lora": 93, "mlabonn": 93, "finetom": 93, "100k": 93, "rate": 93, "2e": 93, "12b": 93, "1477": 93, "7745": 93, "5631": 93, "33": 93, "727": 93, "bbh": 93, "8079": 93, "7624": 93, "7831": 93, "45": 93, "495": 93, "1155": 93, "247": 93, "797": 93, "770": 93, "7074": 93, "6415": 93, "6666": 93, "38": 93, "088": 93, "gpqa": 93, "3232": 93, "3081": 93, "3182": 93, "887": 93, "mmlu": 93, "4909": 93, "4328": 93, "4524": 93, "735": 93, "1322": 93, "3459": 93, "8796": 93, "5483": 93, "4967": 93, "5174": 93, "116": 93, "3333": 93, "2879": 93, "303": 93, "260": 93, "2771": 93, "2562": 93, "2629": 93, "057": 93, "8x": 93, "yahma": 93, "alpaca": 93, "7527": 93, "7068": 93, "551": 93, "4074": 93, "3621": 93, "3702": 93, "881": 93, "7771": 93, "7262": 93, "7397": 93, "523": 93, "4929": 93, "4519": 93, "4686": 93, "732": 93}, "objects": {"torchao.float8": [[6, 0, 1, "", "CastConfig"], [7, 0, 1, "", "Float8LinearConfig"], [8, 0, 1, "", "Float8LinearRecipeName"], [9, 0, 1, "", "ScalingGranularity"], [10, 0, 1, "", "ScalingType"], [11, 2, 1, "", "convert_to_float8_training"], [12, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[7, 1, 1, "", "from_recipe_name"]], "torchao.prototype.mx_formats": [[13, 0, 1, "", "MXDynamicActivationMXWeightConfig"], [14, 0, 1, "", "NVFP4DynamicActivationNVFP4WeightConfig"], [15, 0, 1, "", "NVFP4WeightOnlyConfig"]], "torchao.quantization": [[16, 0, 1, "", "Float8DynamicActivationFloat8SemiSparseWeightConfig"], [17, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [18, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [19, 0, 1, "", "Float8WeightOnlyConfig"], [20, 0, 1, "", "FqnToConfig"], [21, 0, 1, "", "Int4WeightOnlyConfig"], [22, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [23, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [24, 0, 1, "", "Int8DynamicActivationIntxWeightConfig"], [25, 0, 1, "", "Int8WeightOnlyConfig"], [26, 0, 1, "", "IntxWeightOnlyConfig"], [51, 2, 1, "", "quantize_"]], "torchao.quantization.qat": [[27, 0, 1, "", "ComposableQATQuantizer"], [28, 0, 1, "", "FakeQuantizeConfigBase"], [29, 0, 1, "", "FakeQuantizedEmbedding"], [30, 0, 1, "", "FakeQuantizedLinear"], [31, 0, 1, "", "FakeQuantizerBase"], [32, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [33, 0, 1, "", "Float8FakeQuantizeConfig"], [34, 0, 1, "", "Float8FakeQuantizer"], [35, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [36, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [37, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [38, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [39, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [40, 0, 1, "", "IntxFakeQuantizeConfig"], [41, 0, 1, "", "IntxFakeQuantizer"], [42, 0, 1, "", "QATConfig"], [43, 0, 1, "", "QATStep"], [46, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[29, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[30, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[32, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[34, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[36, 1, 1, "", "convert"], [36, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[40, 3, 1, "", "group_size"], [40, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[41, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[44, 0, 1, "", "Int4WeightOnlyEmbedding"], [45, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[44, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[47, 0, 1, "", "Int4WeightOnlyQATLinear"], [48, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [49, 2, 1, "", "disable_linear_fake_quant"], [50, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[52, 0, 1, "", "KernelPreference"], [53, 0, 1, "", "PackingFormat"], [54, 0, 1, "", "QuantizeTensorKwargs"], [55, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[52, 4, 1, "", "AUTO"], [52, 4, 1, "", "EMULATED"], [52, 4, 1, "", "MSLK"], [52, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[53, 4, 1, "", "PLAIN"]], "torchao": [[4, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[56, 0, 1, "", "PerChannelNormObserver"], [57, 0, 1, "", "WandaSparsifier"], [58, 2, 1, "", "apply_fake_sparsity"], [59, 4, 1, "", "semi_sparse_weight"], [60, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[56, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[57, 1, 1, "", "prepare"], [57, 1, 1, "", "squash_mask"], [57, 1, 1, "", "update_mask"]], "torchao.utils": [[61, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[61, 1, 1, "", "get_layout"], [61, 1, 1, "", "get_tensor_impl_constructor"], [61, 1, 1, "", "implements"], [61, 1, 1, "", "implements_torch_function"], [61, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 65, 67, 69, 72, 79, 80, 93], "float8": [0, 3, 67, 69, 72], "main": [0, 2, 3], "train": [0, 67, 69, 72, 74, 80, 83, 84, 85, 86, 87, 92, 93], "api": [0, 2, 3, 5, 62, 63, 69, 72, 80, 88, 93], "other": [0, 65, 67, 92], "type": [0, 78], "kernel": [1, 65, 67, 79, 81], "quantiz": [2, 3, 5, 51, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 92, 93], "qat": [2, 69, 85, 92, 93], "config": [2, 3], "quantize_": [2, 5, 93], "custom": [2, 65], "legaci": 2, "prototyp": [2, 3, 92], "workflow": [3, 80, 92], "weight": [3, 67, 70, 74], "int8": 3, "int4": 3, "intx": 3, "mx": 3, "nvfp4": 3, "sparsiti": [4, 68], "util": 5, "tensor": [5, 65, 67, 76, 77, 79, 88], "subclass": [5, 65, 77, 79], "common": [5, 63, 88], "castconfig": 6, "float8linearconfig": 7, "float8linearrecipenam": 8, "scalinggranular": 9, "scalingtyp": 10, "convert_to_float8_train": 11, "precompute_float8_dynamic_scale_for_fsdp": 12, "mxdynamicactivationmxweightconfig": 13, "nvfp4dynamicactivationnvfp4weightconfig": 14, "nvfp4weightonlyconfig": 15, "float8dynamicactivationfloat8semisparseweightconfig": 16, "float8dynamicactivationfloat8weightconfig": 17, "float8dynamicactivationint4weightconfig": 18, "float8weightonlyconfig": 19, "fqntoconfig": 20, "int4weightonlyconfig": 21, "int8dynamicactivationint4weightconfig": 22, "int8dynamicactivationint8weightconfig": 23, "int8dynamicactivationintxweightconfig": 24, "int8weightonlyconfig": 25, "intxweightonlyconfig": 26, "composableqatquant": 27, "fakequantizeconfigbas": 28, "fakequantizedembed": 29, "fakequantizedlinear": 30, "fakequantizerbas": 31, "float8actint4weightqatquant": 32, "float8fakequantizeconfig": 33, "float8fakequant": 34, "fromintxquantizationawaretrainingconfig": 35, "int4weightonlyembeddingqatquant": 36, "int4weightonlyqatquant": 37, "int8dynactint4weightqatquant": 38, "intxquantizationawaretrainingconfig": 39, "intxfakequantizeconfig": 40, "intxfakequant": 41, "qatconfig": 42, "qatstep": 43, "int4weightonlyembed": 44, "int4weightonlyqatembed": 45, "initialize_fake_quant": 46, "int4weightonlyqatlinear": 47, "int8dynactint4weightqatlinear": 48, "disable_linear_fake_qu": 49, "enable_linear_fake_qu": 50, "kernelprefer": [52, 65], "packingformat": 53, "quantizetensorkwarg": 54, "_choose_quant_func_and_quantize_tensor": 55, "perchannelnormobserv": 56, "wandasparsifi": 57, "apply_fake_spars": 58, "semi_sparse_weight": 59, "sparsifi": 60, "torchaobasetensor": 61, "refer": [62, 80], "benchmark": [63, 64, 65, 74], "guid": [63, 64, 65, 79], "add": [63, 79], "an": [63, 73], "recip": [63, 72], "model": [63, 65, 67, 70, 72, 73, 74, 78, 79, 80, 83, 84, 85], "design": [63, 68], "consider": 63, "hf": 63, "ci": 63, "dashboard": 63, "1": [63, 69, 72, 74, 78, 79, 83, 86, 87, 88], "modifi": 63, "exist": 63, "configur": [63, 68, 79, 84, 85], "2": [63, 69, 74, 78, 79, 83, 84, 85, 86, 87, 88], "run": 63, "3": [63, 69, 74, 79, 83, 86, 87, 88], "output": [63, 77], "format": [63, 67], "4": [63, 83, 88], "integr": [63, 69, 78, 79, 93], "pipelin": 63, "troubleshoot": 63, "test": [63, 65], "issu": 63, "best": 63, "practic": 63, "user": 64, "contributor": 65, "gener": 65, "extend": 65, "ad": [65, 79], "new": [65, 79], "effici": [65, 67], "triton": 65, "hand": 65, "written": 65, "us": [65, 88], "flow": [65, 67, 73, 79, 88], "torch": [65, 83, 84, 85], "compil": [65, 79, 83], "perform": [65, 74, 81, 84], "serial": [65, 73, 79], "featur": 65, "support": [65, 78, 79], "function": [65, 84, 85], "compos": 65, "microbenchmark": 65, "eval": [65, 84], "develop": [66, 80], "note": [66, 72, 80, 88], "overview": [67, 68, 91], "basic": 67, "dtype": 67, "primit": 67, "op": 67, "deriv": [67, 88], "pack": 67, "algorithm": 67, "onli": 67, "dynam": [67, 70], "activ": [67, 70], "static": [67, 75], "awar": [67, 69, 85, 86, 92, 93], "low": [67, 69], "bit": [67, 70], "optim": [67, 73, 74, 80], "case": 67, "studi": 67, "how": [67, 84, 85, 88], "work": 67, "dure": 67, "execut": 67, "save": [67, 78, 84, 85], "load": [67, 84, 85], "goal": 68, "context": 68, "prune": 68, "criteria": 68, "strategi": 68, "pattern": [68, 88], "part": [69, 72, 74], "fine": 69, "tune": 69, "qlora": 69, "option": [69, 74, 83, 91], "torchtun": 69, "axolotl": [69, 93], "rank": 69, "adapt": 69, "huggingfac": [69, 74, 79], "peft": 69, "first": 70, "exampl": [70, 78, 79, 88], "set": [70, 84], "up": 70, "w8a8": 70, "int": 70, "8": 70, "size": [70, 84], "comparison": 70, "speedup": 70, "next": [70, 77], "step": [70, 74, 77, 79, 91], "eager": [71, 80], "tutori": [71, 80, 82, 91], "pre": 72, "torchtitan": 72, "prerequisit": [72, 83, 86, 87, 88], "rowwis": 72, "scale": 72, "tensorwis": 72, "pick": 72, "import": [72, 84, 85], "directli": [72, 88], "convers": 72, "deseri": 73, "what": [73, 77], "happen": 73, "when": 73, "serv": [74, 79, 80], "vllm": [74, 79], "sglang": 74, "executorch": 74, "post": [74, 83, 84, 86, 87], "infer": 74, "transform": [74, 78, 79], "mobil": 74, "deploy": 74, "unti": 74, "embed": 74, "creat": [74, 79], "export": [74, 83, 84, 85, 86, 87, 88], "characterist": 74, "evalu": [74, 84, 93], "qualiti": 74, "assess": 74, "memori": 74, "latenc": 74, "result": [74, 93], "h100": 74, "machin": 74, "conclus": [74, 83, 84, 85, 86, 87, 88, 91], "calibr": [75, 84], "phase": 75, "write": [76, 77, 88], "your": [76, 77, 79], "own": [76, 77], "advanc": 76, "ar": 77, "modul": 77, "swap": 77, "which": 77, "oper": [77, 79, 88], "should": 77, "we": 77, "implement": [77, 79], "compar": 77, "hug": 78, "face": 78, "quick": [78, 80, 82], "start": [78, 80, 82], "usag": [78, 79], "diffus": 78, "architectur": 79, "system": 79, "class": 79, "fqn": 79, "method": 79, "minim": 79, "requir": 79, "compat": 79, "why": 79, "regist": 79, "": 79, "kei": 79, "detail": 79, "hardwar": 79, "specif": [79, 84, 85], "linear": 79, "benefit": 79, "trade": 79, "off": 79, "share": [79, 88], "safetensor": 79, "diagram": 79, "high": 79, "level": 79, "point": 79, "dispatch": 79, "bring": 79, "extern": 79, "welcom": 80, "document": 80, "pytorch": [80, 83, 84, 85, 86, 87, 88], "nativ": 80, "instal": [80, 83], "pt2e": [80, 82, 88], "openvino": 83, "backend": [83, 84, 85, 86, 87], "introduct": [83, 86, 87, 88], "nncf": 83, "captur": [83, 86, 87], "fx": [83, 86, 87], "graph": [83, 86, 87], "appli": [83, 86, 87], "lower": [83, 84, 86, 87], "represent": 83, "improv": 83, "metric": 83, "motiv": [84, 88], "defin": [84, 85], "helper": [84, 85], "prepar": [84, 85], "dataset": [84, 85], "mode": 84, "convert": [84, 85], "check": 84, "accuraci": 84, "debug": 84, "loop": 85, "checkpoint": 85, "x86": 86, "through": [86, 87], "inductor": [86, 87], "intel": 87, "gpu": 87, "annot": 88, "param": 88, "fix": 88, "paramet": 88, "5": 88, "A": 88, "toi": 88, "resnet18": 88, "ir": 88, "problem": 88, "match": 88, "aten": 88, "recommend": [88, 93], "subgraphmatcherwithnamenodemap": 88, "comput": 90, "time": 90, "templat": 91, "addit": 91, "exercis": 91, "further": 91, "read": 91, "stabl": 92, "unsloth": 93}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao.kernel": [[1, "torchao-kernel"]], "torchao.quantization.qat": [[2, "torchao-quantization-qat"]], "Main Config for quantize_": [[2, "main-config-for-quantize"]], "Custom QAT APIs": [[2, "custom-qat-apis"]], "Legacy QAT APIs": [[2, "legacy-qat-apis"]], "Prototype": [[2, "prototype"]], "torchao.quantization": [[3, "torchao-quantization"]], "Main Quantization APIs": [[3, "main-quantization-apis"]], "Workflow Configs": [[3, "workflow-configs"]], "float8 weight configs": [[3, "float8-weight-configs"]], "int8 weight configs": [[3, "int8-weight-configs"]], "int4 weight configs": [[3, "int4-weight-configs"]], "intx weight configs": [[3, "intx-weight-configs"]], "mx weight configs (prototype)": [[3, "mx-weight-configs-prototype"]], "nvfp4 weight configs (prototype)": [[3, "nvfp4-weight-configs-prototype"]], "torchao.sparsity": [[4, "module-torchao.sparsity"]], "torchao.utils": [[5, "torchao-utils"]], "Tensor Subclass Utils": [[5, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[5, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[5, "quantize-api-common-utils"]], "CastConfig": [[6, "castconfig"]], "Float8LinearConfig": [[7, "float8linearconfig"]], "Float8LinearRecipeName": [[8, "float8linearrecipename"]], "ScalingGranularity": [[9, "scalinggranularity"]], "ScalingType": [[10, "scalingtype"]], "convert_to_float8_training": [[11, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[12, "precompute-float8-dynamic-scale-for-fsdp"]], "MXDynamicActivationMXWeightConfig": [[13, "mxdynamicactivationmxweightconfig"]], "NVFP4DynamicActivationNVFP4WeightConfig": [[14, "nvfp4dynamicactivationnvfp4weightconfig"]], "NVFP4WeightOnlyConfig": [[15, "nvfp4weightonlyconfig"]], "Float8DynamicActivationFloat8SemiSparseWeightConfig": [[16, "float8dynamicactivationfloat8semisparseweightconfig"]], "Float8DynamicActivationFloat8WeightConfig": [[17, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[18, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[19, "float8weightonlyconfig"]], "FqnToConfig": [[20, "fqntoconfig"]], "Int4WeightOnlyConfig": [[21, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[22, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[23, "int8dynamicactivationint8weightconfig"]], "Int8DynamicActivationIntxWeightConfig": [[24, "int8dynamicactivationintxweightconfig"]], "Int8WeightOnlyConfig": [[25, "int8weightonlyconfig"]], "IntxWeightOnlyConfig": [[26, "intxweightonlyconfig"]], "ComposableQATQuantizer": [[27, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[28, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[29, "fakequantizedembedding"]], "FakeQuantizedLinear": [[30, "fakequantizedlinear"]], "FakeQuantizerBase": [[31, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[32, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[33, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[34, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[35, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[36, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[37, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[38, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[39, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[40, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[41, "intxfakequantizer"]], "QATConfig": [[42, "qatconfig"]], "QATStep": [[43, "qatstep"]], "Int4WeightOnlyEmbedding": [[44, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[45, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[46, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[47, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[48, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[49, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[50, "enable-linear-fake-quant"]], "quantize": [[51, "quantize"]], "KernelPreference": [[52, "kernelpreference"], [65, "kernelpreference"]], "PackingFormat": [[53, "packingformat"]], "QuantizeTensorKwargs": [[54, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[55, "choose-quant-func-and-quantize-tensor"]], "PerChannelNormObserver": [[56, "perchannelnormobserver"]], "WandaSparsifier": [[57, "wandasparsifier"]], "apply_fake_sparsity": [[58, "apply-fake-sparsity"]], "semi_sparse_weight": [[59, "semi-sparse-weight"]], "sparsify": [[60, "sparsify"]], "TorchAOBaseTensor": [[61, "torchaobasetensor"]], "API Reference": [[62, "api-reference"], [80, null]], "Benchmarking API Guide": [[63, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[63, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[63, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[63, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[63, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[63, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[63, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[63, "run-ci-benchmarks"]], "3. CI Output Format": [[63, "ci-output-format"]], "4. Integration with CI Pipeline": [[63, "integration-with-ci-pipeline"]], "Troubleshooting": [[63, "troubleshooting"]], "Running Tests": [[63, "running-tests"]], "Common Issues": [[63, "common-issues"]], "Best Practices": [[63, "best-practices"]], "Benchmarking User Guide": [[64, "benchmarking-user-guide"]], "Contributor Guide": [[65, "contributor-guide"]], "General Guide on Extending torchao": [[65, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[65, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[65, "adding-efficient-kernels"]], "Custom triton kernels": [[65, "custom-triton-kernels"]], "Custom hand written kernels": [[65, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[65, "using-hand-written-kernels-in-tensor-subclasses"]], "Flow": [[65, "flow"]], "Using torch.compile for Performance": [[65, "using-torch-compile-for-performance"]], "Serialization": [[65, "serialization"], [73, "serialization"]], "Other Feature Support": [[65, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[65, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[65, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[65, "model-benchmarks-and-eval"]], "Developer Notes": [[66, "developer-notes"], [80, null]], "Quantization Overview": [[67, "quantization-overview"]], "Basic DTypes": [[67, "basic-dtypes"]], "Quantization Primitive Ops": [[67, "quantization-primitive-ops"]], "Efficient kernels": [[67, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[67, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[67, "quantization-algorithms-flows"]], "Weight Only Quantization": [[67, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[67, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[67, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[67, "other-quantization-flows"]], "Training": [[67, "training"]], "Quantization Aware Training": [[67, "quantization-aware-training"], [86, "quantization-aware-training"]], "Low Bit Optimizers": [[67, "low-bit-optimizers"]], "Quantized Training": [[67, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[67, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[67, "during-quantization"]], "During Model Execution": [[67, "during-model-execution"]], "During Save/Load": [[67, "during-save-load"]], "Sparsity Overview": [[68, "sparsity-overview"]], "Goal": [[68, "goal"]], "Design": [[68, "design"]], "Context": [[68, "context"]], "Pruning Configuration": [[68, "pruning-configuration"]], "Pruning Criteria": [[68, "pruning-criteria"]], "Pruning Strategy": [[68, "pruning-strategy"]], "Sparsity Pattern": [[68, "sparsity-pattern"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[69, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[69, "quantization-aware-training-qat"], [92, "quantization-aware-training-qat"], [93, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[69, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[69, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[69, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[69, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[69, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[69, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[69, "float8-quantized-fine-tuning"]], "First Quantization Example": [[70, "first-quantization-example"]], "Setting Up the Model": [[70, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[70, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[70, "model-size-comparison"]], "Speedup Comparison": [[70, "speedup-comparison"]], "Next Steps": [[70, "next-steps"], [77, "next-steps"]], "Eager Quantization Tutorials": [[71, "eager-quantization-tutorials"], [80, null]], "(Part 1) Pre-training with float8": [[72, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[72, "pre-training-with-torchtitan"]], "Prerequisites": [[72, "prerequisites"], [72, "id1"], [83, "prerequisites"], [86, "prerequisites"], [87, "prerequisites"]], "Rowwise scaling": [[72, "rowwise-scaling"]], "Tensorwise scaling": [[72, "tensorwise-scaling"]], "Picking a recipe": [[72, "picking-a-recipe"]], "Important notes": [[72, "important-notes"]], "Pre-training with torchao directly": [[72, "pre-training-with-torchao-directly"]], "Model conversion API": [[72, "model-conversion-api"]], "Serialization and deserialization flow": [[73, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[73, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[73, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[74, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[74, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[74, "serving-and-inference"]], "Serving and Inference with vLLM": [[74, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[74, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[74, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[74, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[74, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[74, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[74, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[74, "mobile-performance-characteristics"]], "Evaluation": [[74, "evaluation"]], "Model Quality Assessment": [[74, "model-quality-assessment"]], "Memory Benchmarking": [[74, "memory-benchmarking"]], "Performance Benchmarking": [[74, "performance-benchmarking"]], "Latency Benchmarking": [[74, "latency-benchmarking"]], "Serving Benchmarking": [[74, "serving-benchmarking"]], "Results (H100 machine)": [[74, "results-h100-machine"]], "Conclusion": [[74, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [87, "conclusion"], [88, "conclusion"], [91, "conclusion"]], "Static Quantization": [[75, "static-quantization"]], "Calibration Phase": [[75, "calibration-phase"]], "Quantization Phase": [[75, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[76, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[77, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[77, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[77, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[77, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[77, "which-operators-should-we-implement"]], "Comparing the Outputs": [[77, "comparing-the-outputs"]], "Hugging Face Integration": [[78, "hugging-face-integration"]], "Quick Start: Usage Example": [[78, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[78, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[78, "quantizing-models-with-diffusers"]], "Saving the Model": [[78, "saving-the-model"]], "Supported Quantization Types": [[78, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[79, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[79, "configuration-system"]], "1. HuggingFace Model Configuration": [[79, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[79, "torchao-configuration-classes"]], "3. FQN Configuration": [[79, "fqn-configuration"]], "Usage Examples": [[79, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[79, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[79, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[79, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[79, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[79, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[79, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[79, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[79, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[79, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[79, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[79, "hardware-specific-linear-operations"]], "Compilation Benefits": [[79, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[79, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[79, "serialization-and-model-sharing"]], "SafeTensors Support": [[79, "safetensors-support"]], "Integration Architecture Diagrams": [[79, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[79, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[79, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[79, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Welcome to the torchao Documentation": [[80, "welcome-to-the-torchao-documentation"]], "PyTorch-Native Training-to-Serving Model Optimization": [[80, "pytorch-native-training-to-serving-model-optimization"]], "Quick Start": [[80, "quick-start"], [82, "quick-start"]], "Installation": [[80, "installation"]], "Workflows": [[80, null], [92, "workflows"]], "PT2E Quantization Tutorials": [[80, null], [82, "pt2e-quantization-tutorials"]], "Performant Kernels": [[81, "performant-kernels"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[83, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[83, "introduction"], [86, "introduction"], [87, "introduction"], [88, "introduction"]], "Post Training Quantization": [[83, "post-training-quantization"], [86, "post-training-quantization"], [87, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[83, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[83, "capture-fx-graph"], [86, "capture-fx-graph"], [87, "capture-fx-graph"]], "2. Apply Quantization": [[83, "apply-quantization"], [86, "apply-quantization"], [87, "apply-quantization"]], "3. Lower into OpenVINO representation": [[83, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[83, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[84, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[84, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[84, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[84, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[84, "export-the-model-with-torch-export"], [85, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[84, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [85, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[84, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[84, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[84, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[84, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[84, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[84, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[84, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[85, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[85, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[85, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[85, "training-loop"]], "Saving and Loading Model Checkpoints": [[85, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[85, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[86, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[86, "lower-into-inductor"], [87, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[87, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[88, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[88, "prerequisites"]], "Annotation API": [[88, "annotation-api"]], "1. Annotate Common Operator Patterns": [[88, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[88, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[88, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[88, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[88, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[88, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[88, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[88, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]], "Computation times": [[90, "computation-times"]], "Template Tutorial": [[91, "template-tutorial"]], "Overview": [[91, "overview"]], "Steps": [[91, "steps"]], "(Optional) Additional Exercises": [[91, "optional-additional-exercises"]], "Further Reading": [[91, "further-reading"]], "Stable Workflows": [[92, "stable-workflows"]], "Prototype Workflows": [[92, "prototype-workflows"]], "Other": [[92, "other"]], "torchao APIs": [[93, "torchao-apis"]], "quantize_ API (recommended)": [[93, "quantize-api-recommended"]], "Axolotl integration": [[93, "axolotl-integration"]], "Unsloth integration": [[93, "unsloth-integration"]], "Evaluation Results": [[93, "evaluation-results"]]}, "indexentries": {"module": [[4, "module-torchao.sparsity"]], "torchao.sparsity": [[4, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[6, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[7, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[7, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "float8linearrecipename (class in torchao.float8)": [[8, "torchao.float8.Float8LinearRecipeName"]], "scalinggranularity (class in torchao.float8)": [[9, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[10, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[11, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[12, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "mxdynamicactivationmxweightconfig (class in torchao.prototype.mx_formats)": [[13, "torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig"]], "nvfp4dynamicactivationnvfp4weightconfig (class in torchao.prototype.mx_formats)": [[14, "torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig"]], "nvfp4weightonlyconfig (class in torchao.prototype.mx_formats)": [[15, "torchao.prototype.mx_formats.NVFP4WeightOnlyConfig"]], "float8dynamicactivationfloat8semisparseweightconfig (class in torchao.quantization)": [[16, "torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[17, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[19, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[20, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8dynamicactivationintxweightconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8DynamicActivationIntxWeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[25, "torchao.quantization.Int8WeightOnlyConfig"]], "intxweightonlyconfig (class in torchao.quantization)": [[26, "torchao.quantization.IntxWeightOnlyConfig"]], "composableqatquantizer (class in torchao.quantization.qat)": [[27, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[28, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[29, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[29, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[30, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[30, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[32, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[34, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[36, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[36, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[40, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[40, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[41, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[43, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[44, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[44, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[45, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[46, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[47, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[48, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[49, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[50, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[51, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[52, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "emulated (torchao.quantization.quantize_.common.kernelpreference attribute)": [[52, "torchao.quantization.quantize_.common.KernelPreference.EMULATED"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[52, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[52, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[52, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[53, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[53, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[54, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[55, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "perchannelnormobserver (class in torchao.sparsity)": [[56, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[56, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[57, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[57, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[57, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[57, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[58, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[59, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[60, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[61, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[61, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[61, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[61, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[61, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[61, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})