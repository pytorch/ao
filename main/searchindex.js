Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.prototype.dtypes.FloatxTensorCoreLayout", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout", "generated/torchao.prototype.dtypes.MarlinQQQLayout", "generated/torchao.prototype.dtypes.MarlinQQQTensor", "generated/torchao.prototype.dtypes.UintxLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.prototype.dtypes.FloatxTensorCoreLayout.rst", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQLayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQTensor.rst", "generated/torchao.prototype.dtypes.UintxLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "FloatxTensorCoreLayout", "Int8DynamicActInt4WeightCPULayout", "MarlinQQQLayout", "MarlinQQQTensor", "UintxLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 18, 19, 20, 21, 35, 38, 42, 43, 46, 47, 48, 49, 50, 52, 53, 54, 58, 63, 64, 69, 71, 73, 74, 76, 77, 80, 83, 84, 85, 87, 88, 89, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "section": [2, 10, 96, 100, 105, 110, 111, 114], "introduc": [2, 12, 109, 110, 112, 113, 114], "dive": 2, "detail": [2, 8, 10, 12, 46, 95, 96, 97, 99, 100, 101, 103, 109, 110, 111, 112], "how": [2, 4, 10, 12, 13, 17, 42, 44, 48, 50, 52, 69, 81, 82, 85, 93, 95, 97, 98, 99, 100, 101, 103, 104, 105, 109, 112, 113], "integr": [2, 10, 93, 95, 98, 99, 100, 103, 112, 114], "pytorch": [2, 8, 12, 13, 16, 41, 51, 69, 93, 95, 96, 99, 100, 103, 105, 108], "optim": [2, 10, 12, 18, 35, 38, 80, 93, 95, 100, 103, 109, 111, 112, 113], "your": [2, 8, 10, 12, 93, 95, 96, 97, 99, 100, 104, 110, 111, 112, 113, 114], "machin": [2, 111], "learn": [2, 69, 97, 100, 108, 110, 112, 113, 114], "model": [2, 12, 35, 47, 56, 61, 64, 65, 66, 67, 68, 71, 75, 80, 88, 89, 91, 97, 100, 101, 103, 112, 113, 114], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 40, 41, 42, 43, 45, 51, 52, 53, 54, 58, 59, 61, 62, 65, 66, 67, 69, 73, 74, 76, 77, 84, 85, 91, 93, 95, 97, 98, 99, 101, 103, 104, 105, 110, 112, 113, 114], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 28, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 91, 95, 98, 100], "sparsiti": [2, 8, 12, 14, 18, 21, 87, 88, 89, 90, 91, 93, 95, 98, 99], "tba": [3, 11, 94], "For": [4, 8, 10, 12, 13, 46, 69, 96, 97, 98, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "full": [4, 12, 97, 101, 104, 108, 109, 111], "exampl": [4, 8, 10, 12, 13, 35, 50, 56, 58, 59, 64, 68, 69, 71, 75, 80, 81, 88, 91, 92, 96, 98, 99, 100, 101, 103, 106, 108, 109, 110, 111, 112, 113], "us": [4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 61, 64, 68, 69, 71, 76, 77, 81, 82, 85, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113], "our": [4, 10, 12, 19, 95, 97, 99, 100, 101, 103, 110, 111], "pleas": [4, 9, 10, 12, 13, 41, 64, 68, 93, 96, 97, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "refer": [4, 8, 12, 13, 71, 77, 95, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112], "readm": [4, 8, 12, 93, 97, 100], "tutori": [8, 10, 12, 13, 95, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114], "you": [8, 9, 10, 12, 69, 88, 92, 95, 96, 97, 98, 99, 100, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "through": [8, 10, 12, 53, 58, 59, 93, 96, 97, 99, 101, 103, 105, 108, 109, 110, 114], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 97, 98, 99, 100, 101, 103, 104, 109, 110, 111, 112, 113], "framework": [8, 10, 12, 95, 99, 109], "The": [8, 10, 12, 13, 17, 18, 34, 36, 42, 43, 45, 55, 71, 80, 86, 88, 95, 96, 97, 98, 99, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "contain": [8, 83, 84, 100, 103, 111, 114], "new": [8, 12, 13, 92, 95, 96, 101, 103, 110, 111, 112, 114], "architectur": [8, 93, 99, 100, 109, 110, 112, 113], "micro": 8, "current": [8, 43, 46, 47, 61, 62, 71, 80, 88, 91, 95, 96, 97, 100, 103, 104, 105, 110, 111, 113], "support": [8, 12, 13, 25, 43, 44, 46, 47, 61, 68, 69, 71, 81, 83, 84, 91, 95, 96, 97, 98, 99, 100, 103, 109, 110, 111, 112, 113, 114], "which": [8, 10, 12, 41, 42, 71, 76, 81, 95, 96, 98, 99, 100, 101, 105, 109, 110, 111, 112, 113, 114], "can": [8, 10, 12, 13, 22, 43, 50, 56, 69, 80, 81, 85, 92, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "quantize_": [8, 10, 12, 64, 68, 71, 80, 81, 82, 83, 84, 91, 93, 96, 97, 98, 99, 101], "sparsity_": 8, "function": [8, 12, 13, 22, 34, 58, 63, 73, 78, 79, 80, 87, 88, 89, 91, 92, 95, 96, 97, 98, 100, 101, 103, 105, 109, 114], "To": [8, 10, 12, 13, 41, 77, 95, 96, 97, 98, 99, 100, 101, 105, 110, 111, 112, 114], "correspond": [8, 12, 64, 71, 80, 96, 98, 100, 103, 113, 114], "string": [8, 31, 69, 88, 92], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 92, 93, 96, 97, 98, 103, 105, 109, 110, 111, 112, 113, 114], "py": [8, 10, 92, 107, 108, 112, 113], "def": [8, 10, 12, 83, 91, 92, 95, 96, 97, 98, 101, 103, 105, 109, 110, 111, 112, 113, 114], "option": [8, 10, 13, 15, 23, 26, 27, 28, 30, 31, 34, 41, 43, 46, 48, 49, 52, 53, 54, 58, 59, 61, 62, 66, 68, 69, 71, 73, 74, 80, 81, 84, 85, 88, 91, 92, 95, 96, 97, 104, 105, 110, 111, 112, 113, 114], "str": [8, 31, 34, 69, 71, 80, 88, 91, 92, 95, 103, 105, 113], "kwarg": [8, 10, 13, 58, 59, 60, 61, 65, 69, 74, 84, 87, 88, 89, 92, 96, 103, 105], "aobaseconfig": [8, 71, 80, 91, 101, 105], "code": [8, 10, 95, 96, 97, 99, 100, 101, 103, 106, 108, 110, 111, 112, 113, 114], "elif": [8, 105], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 34, 43, 48, 49, 55, 68, 69, 71, 86, 88, 92, 96, 99, 100, 103, 110, 111], "addit": [8, 12, 17, 20, 92, 95, 96, 100, 103, 104, 109, 110, 113, 114], "inform": [8, 13, 43, 96, 99, 100, 105, 109, 110], "need": [8, 10, 12, 43, 58, 63, 73, 82, 83, 84, 87, 88, 92, 96, 98, 99, 100, 103, 105, 110, 111, 112, 114], "pass": [8, 34, 48, 53, 58, 59, 63, 71, 73, 87, 92, 96, 101, 103, 105, 111, 114], "process": [8, 12, 17, 18, 20, 22, 42, 96, 100, 108, 109, 113], "here": [8, 9, 13, 71, 77, 85, 96, 97, 98, 99, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "return": [8, 10, 12, 13, 18, 19, 34, 41, 55, 69, 80, 86, 91, 92, 95, 96, 97, 98, 101, 103, 105, 109, 110, 111, 112, 113, 114], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 82, 103, 111], "now": [8, 10, 12, 44, 46, 47, 52, 95, 96, 97, 100, 101, 103, 104, 109, 110, 112, 114], "we": [8, 10, 12, 13, 19, 46, 48, 50, 52, 53, 54, 68, 69, 71, 77, 80, 85, 91, 92, 95, 96, 97, 98, 99, 100, 101, 104, 105, 109, 110, 111, 112, 113, 114], "throughout": 8, "note": [8, 10, 12, 46, 56, 68, 77, 88, 92, 96, 97, 99, 100, 103, 105, 111, 112, 113], "input": [8, 10, 13, 18, 19, 21, 31, 34, 35, 52, 53, 54, 55, 71, 75, 80, 85, 86, 88, 91, 95, 96, 97, 99, 101, 103, 109, 110, 111, 112, 113, 114], "paramet": [8, 12, 13, 17, 18, 19, 24, 27, 34, 35, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 61, 62, 69, 71, 74, 76, 77, 80, 85, 86, 88, 91, 92, 95, 96, 98, 99, 100, 103, 105, 109, 110], "like": [8, 10, 12, 17, 43, 95, 96, 97, 98, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "bit": [8, 12, 29, 38, 42, 70, 99, 103, 104, 105, 110, 112, 113], "width": [8, 42, 70], "group": [8, 10, 12, 43, 44, 47, 49, 61, 65, 66, 67, 69, 73, 74, 76, 77, 81, 97], "size": [8, 10, 13, 19, 36, 41, 46, 47, 49, 52, 54, 69, 85, 95, 97, 98, 99, 100, 101, 103, 105, 111], "etc": [8, 10, 43, 58, 59, 82, 84, 96, 109, 114], "them": [8, 12, 58, 63, 73, 87, 114], "append": [8, 100, 110, 111], "config": [8, 12, 31, 34, 43, 45, 46, 48, 57, 58, 59, 60, 62, 63, 64, 68, 69, 70, 71, 80, 88, 91, 96, 97, 99, 100, 101, 104, 105, 110, 112, 113], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 44, 46, 47, 49, 58, 59, 61, 65, 68, 69, 71, 73, 74, 80, 97, 104, 105], "system": [8, 10, 82, 99], "model_architectur": 8, "type": [8, 10, 12, 13, 18, 19, 31, 32, 33, 34, 42, 43, 45, 46, 47, 48, 50, 51, 55, 69, 72, 80, 81, 82, 83, 84, 85, 86, 92, 93, 96, 98, 99, 100, 103, 105, 109, 110, 112, 113, 114], "defin": [8, 10, 17, 32, 38, 42, 58, 63, 73, 87, 88, 92, 96, 97, 100, 101, 103, 105, 109, 112, 113, 114], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 81, 82, 83, 87, 88, 92, 97, 98, 101, 103, 110, 111, 112, 114], "mycustommodel": 8, "torch": [8, 12, 13, 18, 19, 24, 31, 34, 42, 43, 45, 52, 54, 55, 58, 59, 61, 62, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 80, 81, 85, 86, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108, 112, 113, 114], "nn": [8, 10, 12, 31, 34, 56, 61, 65, 68, 71, 80, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 105, 110, 111, 112, 114], "modul": [8, 10, 12, 31, 32, 33, 34, 35, 50, 51, 56, 58, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 87, 88, 91, 95, 96, 97, 98, 101, 105, 109, 110, 111, 112, 113, 114], "__init__": [8, 12, 92, 97, 98, 101, 103, 105, 110, 111, 112], "self": [8, 12, 13, 92, 97, 98, 101, 103, 105, 110, 111, 112], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 19, 61, 66, 76, 85, 95, 96, 97, 98, 99, 100, 101, 104, 105, 112, 113], "super": [8, 12, 97, 98, 101, 103, 110, 111, 112], "layer1": 8, "linear": [8, 10, 12, 18, 31, 34, 43, 44, 45, 47, 48, 49, 56, 59, 61, 66, 67, 68, 71, 76, 77, 78, 79, 80, 89, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 109, 110, 111, 112, 114], "512": [8, 95], "bia": [8, 12, 59, 76, 77, 96, 97, 98, 101, 103, 105, 111, 114], "fals": [8, 12, 13, 26, 31, 46, 48, 52, 58, 59, 67, 68, 69, 71, 73, 74, 76, 77, 88, 95, 96, 97, 98, 99, 101, 103, 104, 105, 109, 110, 111, 113, 114], "activ": [8, 12, 43, 47, 48, 58, 59, 61, 67, 68, 69, 71, 77, 83, 84, 88, 93, 97, 99, 100, 101, 104, 105, 109, 112, 113, 114], "relu": [8, 97, 109, 114], "layer2": 8, "forward": [8, 48, 58, 59, 63, 70, 73, 76, 87, 97, 98, 100, 101, 103, 105, 110, 111, 112], "x": [8, 58, 59, 63, 70, 73, 95, 97, 98, 99, 101, 103, 105, 108, 109, 110, 111, 112, 113], "updat": [8, 93, 97, 98, 100, 110, 111, 114], "create_model_and_input_data": 8, "handl": [8, 10, 18, 21, 22], "model_typ": [8, 12, 105, 109], "m": [8, 10, 12, 80, 91, 95, 97, 98, 99, 101, 103, 110, 111, 112], "int": [8, 12, 13, 19, 22, 23, 24, 26, 27, 28, 29, 36, 38, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 58, 59, 61, 65, 66, 67, 69, 73, 74, 76, 77, 80, 85, 88, 92, 97, 101, 103, 105], "k": [8, 10, 86, 97, 98, 101, 103, 110, 111], "n": [8, 10, 12, 97, 98, 101, 103, 110, 111, 114], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 73, 76, 77, 80, 86, 95, 97, 98, 99, 101, 103, 105, 109, 110, 111, 112, 113], "cuda": [8, 10, 12, 13, 80, 95, 97, 98, 99, 100, 101, 103, 104, 111], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 59, 95, 97, 98, 101, 103, 109, 110, 111, 112, 113], "when": [8, 10, 12, 13, 20, 52, 54, 71, 85, 92, 95, 96, 99, 100, 101, 104, 105, 109, 110, 111, 112, 113, 114], "ad": [8, 12, 13, 54, 88, 92, 96, 100, 101, 103, 111], "dimens": [8, 10, 13, 42, 52, 54, 55, 85, 95, 96, 103, 105, 110, 111], "ensur": [8, 18, 99, 111], "convent": 8, "where": [8, 21, 50, 53, 65, 66, 67, 96, 100, 105, 114], "batch": [8, 99, 101, 111], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 103, 109, 112, 113], "data": [8, 12, 13, 17, 18, 36, 38, 42, 43, 45, 46, 48, 53, 82, 92, 93, 96, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "typic": [8, 12, 19, 20, 96, 97, 98, 101, 105, 114], "compat": [8, 10, 18, 69, 97], "work": [8, 10, 12, 21, 95, 98, 100, 103, 104, 105, 110, 111, 112], "cpu": [8, 10, 13, 16, 39, 98, 100, 101, 104, 105, 109, 110, 111, 112], "other": [8, 12, 13, 17, 43, 46, 70, 81, 88, 95, 98, 99, 100, 103, 105, 108, 110, 111, 112, 114], "target": [8, 10, 12, 13, 43, 45, 46, 52, 58, 59, 62, 69, 88, 97, 100, 109, 110, 111, 112, 113, 114], "method": [8, 10, 17, 18, 21, 22, 80, 88, 97, 100, 101, 103, 104, 109, 110, 111, 113, 114], "come": [8, 9, 95, 96, 99, 100, 101, 102, 104, 111, 112, 113], "soon": [8, 9, 99, 102, 111], "file": [8, 10, 95, 99, 103, 105, 107, 110, 111], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 71, 93, 96, 97, 98, 100, 101, 103, 104, 109, 110, 111, 112, 113], "quantization_config_recipe_nam": 8, "int8wo": [8, 104], "int8dq": 8, "float8dq": [8, 99], "tensor": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 59, 60, 62, 63, 70, 81, 82, 83, 84, 85, 86, 88, 92, 93, 95, 97, 98, 100, 101, 104, 108, 110, 112, 113], "row": [8, 10, 44, 55, 95, 96, 100], "float8wo": 8, "output_dir": [8, 104], "result": [8, 12, 13, 55, 86, 96, 100, 101, 104, 110, 111, 112, 113, 114], "model_param": 8, "name": [8, 10, 32, 33, 50, 51, 72, 80, 81, 82, 88, 91, 92, 96, 99, 100, 103, 105, 109, 110, 111, 114], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 50, 58, 85, 95, 97, 99, 101, 110, 111], "max_pow": 8, "15": [8, 46, 95, 97, 99], "torch_compile_mod": 8, "max": [8, 10, 50, 96, 97, 101, 103, 110, 111, 114], "autotun": [8, 10, 97, 101], "runner": 8, "gener": [8, 12, 13, 58, 59, 60, 63, 70, 96, 97, 99, 100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114], "oss": 8, "databas": 8, "python": [8, 10, 97, 99, 100, 106, 108, 109, 110, 112, 113], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 99, 105], "specif": [8, 10, 12, 17, 18, 20, 21, 38, 58, 59, 77, 82, 88, 95, 96, 97, 98, 99, 100, 104, 109, 112, 113, 114], "requir": [8, 12, 13, 20, 22, 81, 92, 96, 97, 99, 100, 103, 104, 109, 112, 114], "mode": [8, 10, 46, 97, 101, 109, 111, 112, 113, 114], "extra_info": 8, "arch": 8, "nvidia": [8, 100], "a100": [8, 12, 97, 104], "sxm4": 8, "80gb": [8, 97], "1024": [8, 80, 91, 97, 98, 112], "custom": [8, 12, 17, 71, 87, 93, 95, 96, 97, 100, 103, 105, 109, 110, 112, 114], "layer": [8, 18, 34, 43, 45, 48, 49, 58, 59, 61, 65, 66, 67, 73, 74, 76, 77, 88, 89, 95, 99, 100, 101, 103, 105, 109, 114], "origin": [8, 12, 13, 19, 45, 48, 64, 85, 88, 96, 97, 98, 99, 100, 109, 110, 114], "metric": [8, 12, 88], "speedup": [8, 10, 12, 95, 96, 97, 99, 100], "wrt": 8, "bf16": [8, 12, 52, 71, 97, 100, 112, 113], "benchmark_valu": 8, "25": [8, 97], "target_valu": 8, "0": [8, 10, 12, 13, 46, 58, 69, 73, 74, 85, 88, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 108, 110, 111, 113, 114], "depend": [8, 13, 98, 100, 103, 110, 111, 113], "step": [8, 12, 20, 35, 71, 72, 95, 96, 100, 109, 110, 111, 112, 113, 114], "workflow": [8, 10, 80, 81, 91, 95, 97, 100, 114], "github": [8, 97, 99, 104], "action": [8, 105, 110, 111], "upload": 8, "verifi": [8, 97, 98, 103], "setup": [8, 99], "suit": [8, 10, 110, 112], "unittest": 8, "discov": 8, "out": [8, 10, 12, 21, 50, 82, 88, 95, 96, 97, 99, 100, 103, 109, 110, 111, 112], "memori": [8, 10, 12, 13, 95, 96, 97, 100, 103, 104, 112, 113], "reduc": [8, 10, 12, 35, 71, 95, 99, 100, 112], "matrix": [8, 15, 36, 43, 55, 81, 86, 88, 96, 97, 100, 112], "miss": [8, 100], "i": [8, 9, 10, 12, 13, 17, 18, 19, 20, 21, 22, 25, 36, 38, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 68, 69, 71, 80, 83, 84, 85, 86, 88, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "properli": [8, 98], "instal": [8, 10, 95, 96, 97, 99, 104, 110, 113], "Not": [8, 100], "avail": [8, 10, 82, 96, 99, 109, 110, 111, 112, 113], "check": [8, 10, 12, 13, 41, 96, 97, 98, 99, 103, 109, 111, 114], "driver": 8, "basic": [8, 10, 20, 97, 101, 103], "shape": [8, 10, 13, 41, 55, 82, 86, 96, 97, 101, 103, 105, 110, 113], "comprehens": [8, 105, 112], "analysi": [8, 100], "enabl": [8, 10, 79, 92, 95, 96, 99, 105, 112], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 34, 43, 44, 45, 46, 47, 48, 49, 61, 71, 77, 91, 95, 97, 98, 99, 100, 103, 104, 105, 109, 110, 112, 113, 114], "overhead": [8, 100, 104, 105, 112], "multipl": [8, 10, 12, 15, 43, 55, 56, 81, 83, 86, 96, 97, 100, 101, 103, 105, 112, 114], "possibl": [8, 13, 96, 100, 110, 111, 112, 114], "consist": [8, 99, 100, 103, 112, 113, 114], "reproduc": [8, 99], "differ": [8, 10, 12, 17, 46, 53, 56, 85, 86, 95, 96, 97, 98, 99, 100, 103, 104, 105, 110, 111, 112, 114], "case": [8, 9, 10, 71, 81, 86, 99, 100, 103, 105, 109, 110, 114], "user": [8, 10, 12, 43, 56, 71, 77, 93, 95, 96, 97, 99, 100, 101, 103, 108, 110, 111, 112, 113, 114], "more": [8, 10, 12, 13, 46, 47, 95, 96, 97, 99, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113], "about": [8, 10, 12, 96, 97, 98, 99, 100, 110, 111, 112, 114], "compon": [8, 96, 103, 105], "see": [8, 10, 12, 13, 41, 46, 92, 95, 96, 97, 98, 100, 101, 103, 104, 105, 109, 110, 114], "directori": [8, 95], "intend": [9, 81, 96, 110], "provid": [9, 10, 12, 17, 18, 21, 22, 52, 56, 75, 92, 95, 96, 99, 100, 103, 105, 110, 111, 113, 114], "instruct": [9, 12, 96, 99, 110, 111, 112], "most": [9, 10, 20, 71, 96, 99, 100, 105, 110, 111, 114], "fequent": 9, "have": [9, 10, 12, 50, 65, 66, 67, 82, 85, 88, 92, 96, 100, 101, 103, 105, 109, 110, 111, 112, 113, 114], "ani": [9, 10, 20, 61, 65, 75, 88, 96, 100, 103, 109, 111, 113], "answer": [9, 100], "creat": [9, 10, 13, 24, 25, 27, 95, 100, 103, 104, 109, 110, 112, 113, 114], "an": [9, 12, 13, 22, 26, 27, 68, 69, 71, 77, 88, 93, 95, 96, 97, 99, 100, 101, 103, 104, 109, 110, 111, 112, 113, 114], "issu": [9, 81, 96, 97, 103, 112], "start": [10, 12, 32, 33, 50, 51, 72, 81, 82, 95, 96, 99, 100, 101, 103, 105, 109, 110, 111, 112, 113, 114], "read": [10, 103], "overview": [10, 93, 97, 105], "page": [10, 97, 112], "first": [10, 19, 55, 71, 88, 92, 96, 99, 101, 103, 104, 105, 110, 111, 114], "contribut": [10, 97, 100], "exist": [10, 51, 71, 95, 96, 100, 101, 103, 110, 114], "base": [10, 17, 20, 43, 50, 57, 70, 71, 75, 83, 84, 88, 92, 96, 97, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "api": [10, 96, 97, 100, 101, 103, 109, 110, 111, 112, 113], "quant_api": [10, 80, 98, 99, 101], "float8tensor": [10, 43, 45, 62, 83, 96, 105], "e": [10, 12, 13, 50, 52, 54, 56, 69, 71, 80, 83, 85, 92, 95, 96, 98, 101, 103, 104, 109, 114], "g": [10, 12, 13, 50, 52, 54, 56, 69, 71, 80, 83, 85, 92, 96, 98, 101, 103, 109, 114], "oper": [10, 12, 13, 15, 17, 18, 38, 48, 53, 96, 97, 99, 109, 110, 111, 112, 113], "make": [10, 44, 46, 96, 97, 103, 105, 110, 114], "trainabl": [10, 12, 96, 103], "add": [10, 20, 92, 103, 104, 108, 112, 114], "parallel": [10, 95, 103, 105], "primit": [10, 13, 41, 103, 110], "op": [10, 12, 13, 41, 43, 80, 81, 92, 97, 100, 103, 105, 110, 111, 112, 114], "slight": [10, 100], "variat": [10, 96], "quant_primit": [10, 101], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 21, 34, 42, 43, 46, 52, 54, 56, 58, 59, 68, 71, 80, 81, 82, 85, 86, 88, 92, 95, 96, 97, 98, 99, 100, 101, 105, 109, 110, 111, 112, 113, 114], "structur": [10, 12, 21, 91, 96, 97, 98, 100, 103, 110], "deriv": [10, 13, 53, 84, 85], "pack": [10, 13, 22, 37, 38, 42, 44, 46, 82], "format": [10, 13, 18, 19, 46, 82, 99, 100, 110, 111, 114], "understand": [10, 82, 95, 112, 114], "concept": [10, 96, 108, 110, 112, 113, 114], "doe": [10, 12, 20, 71, 81, 82, 96, 100, 103, 110, 112, 113], "alreadi": [10, 13, 103, 114], "could": [10, 96, 103, 109, 110, 112, 113, 114], "context": [10, 38, 112, 113], "also": [10, 12, 69, 80, 96, 97, 98, 100, 101, 103, 104, 105, 110, 113, 114], "write": [10, 93, 97, 109, 110, 111], "own": [10, 12, 93, 95, 97, 100, 101, 110, 111, 114], "torchaobasetensor": [10, 105], "help": [10, 12, 95, 96, 99, 105, 109, 110], "common": [10, 71, 81, 82, 83, 84, 93, 95, 96, 100], "specifi": [10, 12, 13, 31, 34, 49, 56, 58, 59, 60, 63, 70, 71, 77, 80, 81, 85, 88, 91, 95, 96, 100, 109, 110, 111, 114], "non": [10, 92, 100, 103, 109, 112, 113], "attribut": [10, 12, 92, 96, 103, 105, 112, 113], "mytensor": [10, 92], "tensor_data_nam": [10, 92], "qdata": [10, 96], "scale": [10, 13, 17, 18, 24, 27, 32, 35, 43, 50, 52, 53, 54, 55, 61, 62, 69, 74, 75, 76, 77, 84, 85, 92, 96, 100, 101, 103, 105, 114], "tensor_attribute_nam": [10, 92], "With": [10, 103, 110, 112, 114], "abov": [10, 12, 44, 46, 50, 96, 98, 100, 101, 103, 110, 111, 114], "ll": [10, 50, 95, 96, 103, 110, 111, 114], "doc": [10, 95, 96, 97, 99, 103, 104], "mani": [10, 96, 100, 103], "still": [10, 12, 96, 100, 110, 114], "affinequantizedtensor": [10, 24, 25, 27, 41, 48, 97, 98, 101, 103], "plan": [10, 46, 48, 111], "move": [10, 80, 101, 105, 111, 112], "awai": 10, "from": [10, 12, 13, 19, 20, 24, 25, 27, 47, 53, 64, 68, 71, 80, 81, 85, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "abstract": [10, 96], "easier": [10, 114], "peopl": [10, 96, 98, 105, 114], "implement": [10, 12, 31, 46, 73, 74, 76, 77, 81, 92, 96, 98, 100, 101, 109, 110, 114], "regist": [10, 58, 63, 73, 87, 92, 96, 103], "mai": [10, 13, 53, 69, 82, 96, 98, 101, 104, 110, 111, 112, 113, 114], "well": [10, 17, 96, 97, 100, 110, 111, 114], "int4": [10, 12, 16, 37, 44, 46, 47, 50, 58, 59, 61, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 80, 91, 96, 97, 98, 99, 104, 105], "access": [10, 48, 109], "my_custom_op": 10, "call": [10, 12, 13, 58, 63, 73, 87, 96, 97, 98, 100, 101, 103, 105, 111, 113], "want": [10, 80, 91, 96, 97, 98, 100, 103, 105, 109, 110, 111, 114], "my_mm_for_mp": 10, "aten": [10, 92, 96, 97, 103, 105, 109, 110, 111, 112, 113], "default": [10, 12, 13, 15, 20, 22, 36, 42, 43, 45, 46, 52, 54, 61, 69, 77, 80, 92, 95, 96, 97, 103, 105, 109, 110, 111, 112, 113, 114], "_": [10, 92, 95, 96, 101, 105, 109, 110, 111, 112], "func": [10, 92, 96, 103, 105], "arg": [10, 13, 46, 58, 59, 60, 61, 65, 74, 88, 92, 96, 103, 105, 111, 114], "re": [10, 95, 96, 98, 99, 103, 110, 111], "input_tensor": [10, 19, 96, 105], "weight_tensor": [10, 96, 105], "some": [10, 80, 88, 92, 96, 97, 99, 100, 101, 103, 109, 110, 111, 112, 113, 114], "choic": [10, 46], "mm": [10, 80, 81, 103, 110], "recommend": [10, 12, 43, 45, 46, 47, 48, 49, 95, 96, 104, 109, 112, 113], "wai": [10, 13, 71, 95, 96, 99, 100, 101, 103, 110, 111, 114], "repres": [10, 13, 15, 17, 25, 31, 36, 57, 69, 82, 85, 88, 96, 98, 103, 110, 111], "group_mm": 10, "auto": [10, 43, 81, 99, 104, 105], "develop": [10, 97, 110, 111, 114], "choos": [10, 46, 84, 96, 100, 103, 110, 112], "whatev": 10, "think": [10, 105], "fastest": 10, "under": [10, 12, 81, 99], "condit": 10, "so": [10, 12, 95, 96, 97, 98, 100, 103, 104, 110, 111, 114], "don": [10, 88, 95, 96, 97, 100, 104, 105, 114], "t": [10, 88, 92, 95, 96, 97, 100, 101, 103, 104, 105, 110, 111, 114], "worri": 10, "debug": [10, 81], "purpos": [10, 95, 96, 103, 110], "ha": [10, 12, 13, 71, 99, 100, 103, 105, 109, 110, 111, 113, 114], "hardwar": [10, 43, 81, 82, 97, 99, 100, 104], "h100": [10, 96, 104], "sm89": 10, "sm90": 10, "librari": [10, 81, 82, 93, 96, 98], "whether": [10, 12, 46, 52, 69, 92, 103], "fbgemm_gpu_genai": [10, 81, 96], "granular": [10, 13, 32, 43, 46, 47, 48, 49, 52, 54, 58, 59, 61, 62, 69, 70, 85, 95, 96, 99, 101, 105], "per": [10, 12, 13, 44, 45, 47, 48, 49, 52, 54, 61, 65, 66, 67, 69, 73, 74, 76, 77, 85, 88, 95, 96, 97, 100, 101, 113], "_choose_scale_float8": [10, 96], "_quantize_affine_float8": [10, 96], "_scaled_mm": [10, 96], "kerenel": 10, "fbgemm": [10, 81, 96, 100], "f8f8bf16_rowwis": [10, 96], "level": [10, 88, 96, 100, 103, 109, 110, 112, 113], "reus": [10, 103], "allow": [10, 77, 96, 97, 100, 103, 109, 110, 111, 112, 114], "appli": [10, 12, 13, 43, 44, 45, 47, 48, 49, 56, 60, 61, 63, 68, 70, 71, 80, 91, 92, 96, 97, 99, 100, 105, 111], "convers": [10, 12, 13, 34], "weight": [10, 12, 18, 19, 35, 43, 44, 45, 46, 47, 48, 49, 58, 59, 61, 65, 66, 67, 69, 71, 73, 74, 76, 77, 80, 83, 88, 91, 93, 95, 97, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "filter": [10, 12, 34, 95, 101], "should": [10, 12, 13, 35, 54, 58, 63, 64, 71, 73, 87, 88, 92, 95, 100, 105, 109, 110, 114], "algorithm": [10, 46, 99, 100, 109], "dynam": [10, 12, 30, 31, 35, 43, 44, 47, 48, 61, 67, 69, 77, 91, 99, 101, 103, 104, 110, 111, 112], "quant": [10, 13, 41, 96, 99, 105, 110, 113, 114], "In": [10, 12, 46, 71, 95, 96, 97, 100, 101, 103, 109, 110, 111, 112, 113, 114], "order": [10, 56, 92, 100, 103, 114], "aim": [10, 100, 113], "run": [10, 12, 35, 58, 59, 63, 73, 80, 81, 87, 95, 96, 97, 99, 100, 103, 108, 109, 110, 111, 112, 113, 114], "fullgraph": [10, 97], "true": [10, 12, 13, 26, 31, 43, 45, 46, 47, 48, 49, 52, 53, 58, 59, 68, 69, 71, 79, 80, 91, 95, 97, 98, 99, 101, 103, 104, 105, 109, 110, 111, 112, 114], "remov": [10, 52, 88, 95, 100, 105, 110, 111], "unnecessari": 10, "graph": [10, 97, 110, 111, 114], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 97, 99, 101, 103, 108, 111, 112, 113], "inductor": [10, 93, 97, 109, 110], "save": [10, 12, 88, 92, 95, 97, 98, 99, 105], "load": [10, 92, 98, 99, 104, 105], "relev": [10, 96, 108], "object": [10, 42, 80, 91, 96, 103, 110, 111, 114], "safe": [10, 86], "global": [10, 100, 103], "after": [10, 12, 35, 95, 96, 98, 100, 104, 109, 110, 111, 112, 113, 114], "2": [10, 13, 14, 16, 18, 21, 43, 45, 46, 48, 49, 50, 58, 69, 73, 74, 85, 89, 91, 93, 95, 96, 100, 101, 103, 108], "5": [10, 12, 50, 58, 88, 97, 99, 100, 105, 108, 110, 111], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 96], "checkout": [10, 13, 41, 93, 96], "huggingfac": [10, 104], "transform": [10, 12, 13, 92, 101, 109, 110, 111, 112, 113], "deseri": [10, 110, 111], "save_pretrain": [10, 99, 104], "push_to_hub": [10, 99, 104, 105], "from_pretrain": [10, 12, 99, 104, 105], "diffus": [10, 99], "just": [10, 50, 69, 96, 98, 100, 103, 110, 111, 114], "talk": [10, 96, 99], "train": [10, 31, 56, 69, 71, 93, 97, 100, 103, 114], "fsdp": [10, 96], "mydtypetensor": 10, "put": [10, 91, 112, 114], "developer_api_guid": 10, "folder": [10, 99, 110, 111], "cover": [10, 108, 110, 113, 114], "follow": [10, 12, 69, 71, 92, 95, 96, 97, 99, 100, 101, 103, 104, 109, 110, 111, 112, 113, 114], "executorch": [10, 47, 93, 97, 104, 110, 111], "torchchat": 10, "dtensor": [10, 103], "copi": [10, 13, 88, 97, 98, 100, 101, 103, 111, 112], "past": [10, 100], "adapt": [10, 95, 101], "befor": [10, 12, 71, 80, 96, 98, 99, 100, 101, 103, 110, 111, 114], "do": [10, 51, 55, 80, 96, 99, 100, 101, 103, 105, 110, 111, 112, 114], "singl": [10, 12, 30, 35, 43, 53, 95, 97, 100, 110, 114], "comput": [10, 18, 22, 35, 45, 58, 63, 73, 81, 87, 88, 96, 100, 101, 103, 104, 110, 111, 112, 113], "intens": 10, "get": [10, 12, 19, 77, 92, 95, 96, 97, 99, 100, 105, 109, 110, 111, 112, 114], "sens": [10, 96, 103], "d": [10, 92, 99, 111], "benchmark_aq": 10, "": [10, 12, 13, 50, 52, 54, 81, 82, 85, 92, 95, 96, 97, 99, 100, 101, 103, 110, 111, 112, 113, 114], "import": [10, 12, 64, 68, 71, 80, 91, 97, 98, 99, 100, 101, 103, 104, 105, 108, 109, 112, 113], "A": [10, 12, 13, 42, 53, 81, 87, 92, 96, 100, 103, 104, 105, 110], "quick": [10, 93], "chang": [10, 80, 95, 97, 98, 99, 100, 101, 103, 109, 110, 111, 113, 114], "interest": [10, 100, 103], "print_op_and_shap": 10, "output": [10, 12, 31, 52, 54, 85, 95, 96, 97, 99, 100, 104, 108, 109, 110, 111, 112, 113, 114], "torch_func": 10, "built": [10, 95, 103], "_c": 10, "tensorbas": 10, "all": [10, 35, 46, 50, 53, 58, 61, 63, 65, 73, 75, 87, 88, 89, 92, 96, 97, 98, 99, 100, 101, 103, 105, 106, 109, 110, 112, 114], "benchmark_your_kernel": 10, "helper": [10, 78, 79, 92], "right": [10, 44, 46, 100, 110], "1": [10, 18, 32, 33, 42, 43, 45, 46, 48, 49, 50, 51, 62, 72, 80, 81, 82, 84, 85, 88, 93, 96, 97, 98, 100, 101, 103, 108, 110, 111], "feel": [10, 96, 100, 103, 105], "free": [10, 96, 103], "either": [10, 13, 43, 62, 71, 88, 99, 100, 111, 112, 113], "one": [10, 43, 53, 58, 63, 71, 73, 87, 95, 96, 100, 103, 105, 111, 114], "probabl": 10, "keep": [10, 18, 48, 88, 96, 110], "futur": [10, 101, 104, 105, 110, 111, 112, 114], "llama": [10, 12, 99, 104, 105, 109], "llama2": 10, "llama3": [10, 12, 95, 104], "sam": 10, "modifi": [10, 34, 80, 88, 95, 100, 103], "friendli": 10, "compar": [10, 12, 88, 95, 96, 99, 110, 112, 114], "techniqu": [10, 12, 95, 98, 99, 100, 101, 103, 105], "bound": [10, 43, 62, 99, 100, 105], "each": [10, 19, 61, 69, 74, 76, 77, 87, 92, 96, 100, 101, 103, 105, 110, 111, 114], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 50, 85, 96, 97, 100, 101, 103, 114], "u": [10, 100, 109], "know": [10, 103], "end": [12, 95, 96, 99, 100, 103, 104, 105, 111, 114], "pre": [12, 17, 18, 22, 93, 99, 100, 114], "serv": [12, 13, 17, 93, 95, 103, 104, 113], "flow": [12, 47, 95, 99, 100, 101, 109, 110, 111, 112, 113], "leverag": [12, 95, 97, 99, 103, 112, 113], "partner": [12, 95, 99], "showcas": [12, 95, 99], "focus": [12, 95, 96, 99, 100], "domain": [12, 13, 52, 54, 69, 95], "demonstr": [12, 95, 96, 97, 99, 103, 109, 111], "dure": [12, 13, 41, 48, 54, 69, 71, 95, 97, 99, 100, 101, 103, 109, 111], "numer": [12, 71, 76, 77, 81, 95, 100, 110, 111, 112], "goal": [12, 71], "mitig": [12, 100], "degrad": [12, 71, 100], "eventu": [12, 71, 95], "blog": 12, "resourc": [12, 103], "small": 12, "matric": [12, 21, 100], "freez": [12, 111, 112, 113], "checkpoint": [12, 92, 95, 99, 105], "effici": [12, 22, 76, 97, 100, 101, 113], "paper": [12, 100, 108], "speed": [12, 80, 99, 100, 109], "up": [12, 19, 69, 80, 95, 96, 97, 100, 109, 110, 111, 114], "high": [12, 13, 23, 24, 25, 26, 27, 62, 71, 95, 96, 99, 100, 101, 103, 109, 110, 112, 113], "precis": [12, 13, 23, 24, 25, 26, 27, 45, 48, 61, 62, 66, 67, 71, 74, 76, 77, 96, 101, 103, 104, 109, 112, 113], "similar": [12, 100, 101, 111, 112], "inevit": 12, "actual": [12, 45, 71, 81, 96, 101, 103, 105, 110, 111, 114], "presum": 12, "been": [12, 92, 103, 111, 112, 113, 114], "successfulli": [12, 100], "recent": [12, 93], "releas": [12, 112], "1b": [12, 104, 105], "3b": 12, "llamaguard": 12, "8b": [12, 95, 104], "improv": [12, 95, 99, 100, 110, 113, 114], "qualiti": [12, 100, 104], "involv": [12, 15, 71, 100], "two": [12, 21, 41, 43, 71, 92, 96, 97, 100, 103, 109, 110, 111, 112, 114], "separ": [12, 58, 59, 69, 100, 105, 110, 114], "prepar": [12, 56, 61, 65, 71, 88, 100, 109, 112, 113, 114], "convert": [12, 13, 19, 23, 26, 28, 29, 31, 41, 56, 64, 65, 71, 80, 91, 95, 96, 99, 100, 109, 112, 113, 114], "fake": [12, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 95, 110, 111, 114], "mean": [12, 13, 19, 50, 52, 54, 85, 92, 95, 96, 97, 100, 110, 111, 114], "valu": [12, 13, 19, 31, 32, 33, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 62, 72, 81, 82, 85, 88, 96, 100, 101, 103, 109, 110, 111, 114], "map": [12, 48, 50, 69, 92, 96, 103, 110, 114], "without": [12, 64, 96, 100, 105, 112, 114], "cast": [12, 13, 30, 32], "lower": [12, 43, 47, 62, 96, 97, 99, 100, 101, 104, 111], "replac": [12, 100, 105], "real": [12, 96, 97, 110, 114], "perform": [12, 13, 22, 35, 48, 49, 55, 58, 63, 65, 66, 67, 73, 86, 87, 95, 97, 100, 101, 103, 104, 105, 109, 111, 112, 113], "There": [12, 71, 96, 101, 103, 110, 114], "directli": [12, 50, 53, 71, 96, 100, 101, 103], "loop": [12, 95, 100], "distribut": [12, 95, 101, 103, 105, 109], "recip": [12, 31, 58, 63, 73, 87], "instead": [12, 53, 58, 63, 64, 68, 69, 71, 73, 87, 95, 97, 100, 103, 111, 112, 113, 114], "command": [12, 95], "regular": [12, 109, 112, 113], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 18, 21, 29, 89, 91, 96, 97, 98, 99, 100, 103, 104, 110, 111], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 98, 99, 101, 110, 111], "16": [12, 59, 95], "equival": [12, 69, 100, 111, 112, 114], "asymmetr": [12, 47, 50, 52, 69, 97, 101, 109, 113, 114], "token": [12, 47, 48, 67, 69, 77, 95, 99, 104], "int8": [12, 19, 47, 48, 49, 59, 67, 68, 69, 71, 77, 80, 84, 91, 96, 99, 103, 110, 112, 113, 114], "symmetr": [12, 43, 45, 47, 48, 49, 50, 52, 58, 61, 69, 103, 109, 110, 113, 114], "configur": [12, 15, 30, 31, 34, 43, 44, 45, 46, 47, 48, 49, 80, 91, 95, 96, 97, 99, 104, 112, 113, 114], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 111], "same": [12, 13, 43, 46, 52, 53, 54, 77, 85, 86, 91, 92, 95, 96, 100, 101, 103, 111, 113, 114], "wa": [12, 103, 111], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 104], "int8dynactint4weightquant": 12, "groupsiz": [12, 66, 67, 76, 77, 85], "32": [12, 46, 47, 59, 68, 69, 71, 73, 74, 80, 91, 95, 97, 98, 99, 101, 103, 111], "hellaswag": [12, 99], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 99], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 99], "ckpt": 12, "llama3_token": 12, "path": [12, 80, 86, 97, 99, 109, 110, 111, 112, 114], "tmp": [12, 97], "meta": [12, 98, 104, 105, 114], "print": [12, 88, 97, 98, 99, 103, 108, 110, 111], "version": [12, 16, 43, 45, 46, 48, 49, 69, 80, 96, 98, 103, 105, 110, 111, 114], "shot": [12, 100], "stderr": 12, "none": [12, 13, 15, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 41, 43, 46, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 68, 69, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 84, 85, 88, 91, 92, 96, 101, 103, 105, 109, 110, 111, 113], "acc": [12, 110, 111], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 97, 100, 114], "openassist": 12, "oasst1": 12, "dataset": [12, 95, 99, 109, 112, 113], "find": [12, 19, 100, 110, 114], "achiev": [12, 19, 95, 100, 101, 103, 111, 112], "higher": [12, 95, 103, 104, 109, 110, 112, 113], "accuraci": [12, 95, 99, 100, 101, 109, 111, 112], "than": [12, 42, 69, 95, 96, 100, 103, 110], "recov": [12, 100, 111], "69": [12, 101], "8": [12, 22, 42, 46, 50, 58, 59, 66, 76, 95, 96, 97, 99, 105, 112, 113], "overal": [12, 93, 97, 110, 114], "vanilla": 12, "compos": [12, 56, 96, 100, 103, 110, 111, 114], "lora": 12, "yield": [12, 100], "89x": 12, "usag": [12, 13, 35, 56, 58, 59, 64, 68, 69, 71, 92, 93, 95, 99, 112, 113], "36": [12, 95, 99], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 43, 45, 46, 47, 48, 49, 53, 69, 80, 88, 92, 97, 100, 109, 111, 112, 113], "try": [12, 100, 103, 110], "fsdp2": [12, 95], "yaml": 12, "onc": [12, 100], "complet": [12, 99, 109, 113], "qat_out": 12, "quatiz": 12, "document": [12, 103, 105, 109, 110, 112], "prefer": [12, 43, 96, 103], "These": [12, 100, 103, 109, 110, 111, 114], "what": [12, 13, 41, 95, 96, 97, 99, 100, 101, 105, 108, 110, 114], "hood": 12, "mini": [12, 99], "gpu": [12, 93, 95, 97, 104, 105, 108, 109], "smaller": [12, 42, 46, 47, 97, 98], "fit": [12, 13, 22, 96, 98], "adjust": [12, 43, 45, 46, 47, 48, 49], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 95], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 95], "max_seq_len": 12, "train_loop": [12, 71], "sgd": 12, "lr": [12, 95], "001": 12, "momentum": [12, 111], "9": [12, 95], "weight_decai": 12, "1e": [12, 95], "loss_fn": 12, "crossentropyloss": [12, 110, 111], "rang": [12, 50, 95, 100, 101, 110, 111], "randint": 12, "loss": [12, 95, 100, 110, 111], "backward": [12, 35, 95, 100, 111], "zero_grad": [12, 95, 111], "next": [12, 95, 101, 110, 111, 112, 113], "scheme": [12, 48, 49, 58, 59, 71, 99, 109], "although": [12, 46, 58, 63, 73, 87, 103], "integ": [12, 13, 26, 27, 50, 52, 54, 55, 69, 70, 86, 101, 110, 111, 112], "arithmet": [12, 71], "float": [12, 13, 19, 26, 28, 29, 41, 43, 46, 50, 52, 53, 54, 58, 62, 69, 73, 74, 85, 88, 96, 97, 98, 103, 110, 111, 114], "float32": [12, 13, 24, 54, 65, 67, 69, 73, 74, 77, 85, 98, 99, 100, 101, 103, 112, 113, 114], "becaus": [12, 13, 18, 95, 98, 100, 103, 111, 114], "int8dynamicactivationint4weightconfig": [12, 71, 77], "qatconfig": [12, 64, 68, 72], "swap": [12, 34, 61, 65, 95, 100, 101, 111], "fakequantizedlinear": [12, 61, 64, 78, 79], "base_config": [12, 71], "exact": [12, 77, 110, 111], "attun": 12, "benefici": 12, "later": [12, 96, 103, 110, 111, 113], "readi": [12, 95, 97, 99, 101, 103, 111], "did": [12, 47], "altern": [12, 69, 101, 103, 112, 113], "legaci": [12, 46], "offer": [12, 103, 110], "customiz": [12, 80], "unlik": [12, 101], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 97, 101, 109, 110, 111, 112, 113, 114], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 109, 110, 112, 113], "footprint": 12, "extens": [12, 103, 110, 112], "addition": [12, 112, 113], "frozen": 12, "further": [12, 103, 109, 110, 111, 112], "nf4": [12, 19], "propos": [12, 88], "express": [12, 97, 103, 109, 110, 111, 114], "subclass": [12, 13, 34, 41, 58, 63, 73, 81, 82, 87, 91, 92, 96, 97, 98, 100, 104], "nf4tensor": 12, "cleanli": 12, "compil": [12, 80, 86, 93, 95, 96, 97, 101, 103, 112, 113], "simpli": [12, 100, 101, 103], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 26, 31, 34, 43, 45, 46, 47, 48, 49, 52, 53, 58, 59, 67, 69, 73, 74, 76, 77, 79, 80, 91, 101], "quantization_kwarg": 12, "No": [12, 96, 98, 100], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 96, 101, 103, 105], "though": [12, 103], "shown": [12, 99, 100, 111, 114], "competit": [12, 95], "baselin": [12, 95, 99, 110], "while": [12, 58, 63, 71, 73, 83, 87, 88, 99, 100, 103, 104, 109, 110, 114], "even": [12, 13, 95, 100, 114], "newer": 12, "mxfp4": [12, 96], "nvfp4": [12, 96], "blackwel": 12, "reap": 12, "benefit": [12, 44, 100, 103, 110, 113], "vari": [12, 13, 110, 111, 112, 113], "tradeoff": [12, 100, 104], "incorpor": 12, "its": [12, 100, 103, 105, 110, 114], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 95, 96, 103, 105, 110], "yet": [12, 47, 51, 71, 103, 105, 111, 112, 113], "invok": [12, 112], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 99, 104, 105], "torchaoconfig": [12, 99, 104, 105], "int8weightonlyconfig": [12, 80, 104, 105], "base_model": 12, "quantization_config": [12, 99, 104, 105, 113], "peft_config": 12, "throughput": [12, 95, 99], "increas": [12, 100, 110], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 30, 31, 96], "initi": [12, 13, 75, 96, 97, 98, 111], "experi": [12, 95, 113], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 95, 97, 110], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 95], "074": [12, 95], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 95], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 95, 113, 114], "407": [12, 95], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 95], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 41, 92, 101], "aqttensorimpl": [13, 41], "block_siz": [13, 17, 19, 23, 24, 26, 27, 28, 29, 41, 52, 53, 54, 85, 96, 97, 101], "tupl": [13, 19, 23, 24, 26, 27, 28, 41, 43, 52, 53, 54, 75, 85, 88, 92, 103, 105, 110, 111, 114], "quant_min": [13, 26, 27, 28, 41, 50, 52, 53, 54, 85, 97, 103, 113, 114], "union": [13, 31, 41, 43, 52, 54, 62, 69, 80, 85], "quant_max": [13, 26, 27, 28, 41, 50, 52, 53, 54, 85, 97, 103, 113, 114], "zero_point_domain": [13, 26, 27, 28, 41, 46, 52, 53, 69], "zeropointdomain": [13, 26, 27, 28, 41, 46, 52, 53, 69], "stride": [13, 41, 103], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 99, 106, 108], "affin": [13, 14, 15, 16, 18, 21, 22, 26, 37, 39, 54, 85, 96], "point": [13, 28, 41, 46, 50, 54, 62, 69, 74, 75, 76, 77, 95, 96, 97, 98, 100, 101, 103, 110, 114], "quantized_tensor": 13, "float_tensor": [13, 103], "zero_point": [13, 17, 27, 52, 53, 54, 85, 92, 96, 100, 101, 103, 114], "happen": [13, 41, 96, 103, 110, 112], "choose_qparam": [13, 96], "dequant": [13, 19, 41, 54, 81, 96, 97, 103, 105, 110, 112, 113, 114], "ao": [13, 41, 100, 105], "three": [13, 88, 91, 112, 113], "choose_qparams_affin": [13, 53], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 95, 96, 100, 109, 110, 111, 112, 113], "extern": [13, 112], "regardless": 13, "intern": [13, 22], "represent": [13, 17, 25, 92, 100, 105, 110, 114], "orient": 13, "field": [13, 69, 72, 92, 114], "impl": [13, 92], "storag": [13, 18, 100], "store": [13, 18, 19, 42, 48, 83, 87, 96, 100, 104, 105, 110, 111], "plain": [13, 43, 46, 82, 96, 105], "int_data": [13, 103], "kernel": [13, 14, 16, 18, 22, 37, 43, 44, 76, 80, 81, 97, 99, 100, 109, 112, 113], "element": [13, 21, 42, 52, 54, 61, 74, 76, 77, 85, 92, 96, 100], "share": [13, 52, 54, 85, 100], "qparam": [13, 46, 52, 54, 85], "minimum": [13, 52, 54, 85], "maximum": [13, 52, 54, 85], "zero": [13, 21, 46, 48, 52, 54, 69, 74, 75, 76, 77, 88, 100, 101, 114], "subtract": [13, 19], "unquant": [13, 114], "given": [13, 29, 41, 84, 95, 100, 105, 114], "classmethod": [13, 41, 83, 92, 101, 103, 105], "from_hp_to_floatx": 13, "input_float": [13, 23, 24, 25, 26, 27, 28, 41], "target_dtyp": [13, 23, 24, 26, 27, 30, 31, 52, 53, 96, 101], "_layout": [13, 23, 24, 25, 26, 27, 28, 41, 92, 97, 101], "layout": [13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 91, 92, 100], "scale_dtyp": [13, 23, 24, 26, 52, 53, 101], "float8": [13, 14, 15, 23, 24, 30, 31, 32, 33, 34, 35, 43, 44, 45, 61, 62, 63, 84, 93, 99, 101], "from_hp_to_floatx_stat": 13, "static": [13, 17, 19, 24, 27, 31, 53, 69, 93, 97, 110, 111, 112, 113, 114], "from_hp_to_fpx": 13, "floatx": [13, 25], "ebit": [13, 25, 38], "mbit": [13, 25, 38], "float1": [13, 25], "float7": [13, 25], "from_hp_to_intx": [13, 41], "mapping_typ": [13, 26, 47, 52, 53, 69], "mappingtyp": [13, 26, 47, 48, 52, 53, 69, 101], "ep": [13, 26, 52, 53, 69, 101, 111, 113, 114], "zero_point_dtyp": [13, 26, 52, 53, 101], "preserve_zero": [13, 26, 46, 52, 53], "plainlayout": [13, 26, 27, 47, 48, 92, 101], "use_hqq": [13, 26, 46, 104, 105], "custom_scal": [13, 26], "custom_zero_point": [13, 26], "from_hp_to_intx_stat": 13, "argument": [13, 22, 54, 69, 71, 80, 83, 92, 95, 96, 99, 112], "correct": [13, 18, 110, 111], "otherwis": [13, 49, 56, 69, 111], "desir": [13, 101], "gradient": [13, 93, 100], "implicitli": [13, 114], "complex": [13, 100], "non_block": 13, "memory_format": [13, 112, 113], "preserve_format": 13, "accord": 13, "c": [13, 92, 97, 103, 112, 113], "rule": 13, "truncat": 13, "part": [13, 93, 100, 103, 104, 111], "cannot": [13, 100, 101, 105], "inf": 13, "long": [13, 103, 110], "behavior": [13, 17, 56, 105, 110, 111], "undefin": [13, 56, 88], "across": [13, 88, 99, 100, 103, 105], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 100, 111], "host": [13, 105], "both": [13, 43, 46, 71, 77, 96, 97, 100, 101, 103, 110, 112, 113, 114], "pin": 13, "pageabl": 13, "howev": [13, 100, 104, 105, 111, 114], "caution": 13, "advis": [13, 96], "good": [13, 97, 103, 114], "pin_memori": 13, "match": [13, 54, 55, 76, 77, 92, 100, 110], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 37], "mm_config": [15, 43], "float8mmconfig": [15, 43], "variabl": [15, 22, 36, 42, 88, 92, 100], "tinygemm": [16, 46, 76, 80, 97], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 69, 95, 96, 97, 99, 100, 110, 111, 112], "It": [17, 18, 20, 22, 35, 97, 100, 103, 114], "post": [17, 22, 71, 93, 96, 97, 103, 111, 114], "design": [17, 18, 21, 99, 105, 109, 110, 114], "extend": [17, 96, 100, 112], "conjunct": 17, "tensorimpl": [17, 92], "interact": [17, 110], "spars": [18, 21, 36, 58, 73, 74, 88, 100], "marlin": [18, 28, 40, 41], "pattern": [18, 21, 96, 97, 105, 109, 110], "preprocess": [18, 21], "manag": 18, "pre_process": 18, "1\u00ba": 18, "transpos": [18, 103], "sinc": [18, 44, 58, 63, 73, 87, 96, 98, 99, 100, 101, 103, 110, 111, 112, 113, 114], "2\u00ba": 18, "inject": 18, "3\u00ba": 18, "again": [18, 19, 100, 110, 114], "dim": [18, 48, 49, 62, 101, 103, 105, 110, 111], "tensor_meta": 19, "subclasstensorarg": 19, "n_block": 19, "scaler_block_s": [19, 29], "quantized_scal": 19, "quantization_factor": 19, "scaler_mean": 19, "quantized_data": [19, 105], "qlora": [19, 93, 99], "convert_to_norm_float_weight": 19, "normal": [19, 29, 100, 110, 111], "dequantize_scal": 19, "unpack": 19, "doubl": 19, "scaler": 19, "per_scaler_block": 19, "factor": [19, 55, 95, 100], "inpt_weight": 19, "block": [19, 36, 88, 100], "double_quantize_scal": 19, "take": [19, 58, 63, 73, 80, 87, 91, 92, 96, 100, 109, 110, 111, 112, 113, 114], "calcul": [19, 35, 43, 50, 52, 53, 62, 96, 100, 110, 114], "absmax": 19, "posit": 19, "And": [19, 43, 103, 112, 114], "per_block": 19, "int16": [19, 110], "n_scaler_block": 19, "get_original_weight": 19, "quantize_tensor_nearest": 19, "float16": [19, 85, 100], "nearest": 19, "round": [19, 50, 103], "inherit": [20, 41, 92, 103, 105, 112, 113], "metadata": [20, 92, 96, 99, 103, 105], "semi": [21, 91, 100], "everi": [21, 58, 63, 73, 87, 100, 103, 110, 111], "four": [21, 109], "prune": [21, 88], "conform": 21, "inner_k_til": [22, 46, 66, 76, 97], "core": [22, 51, 80, 101, 105, 110], "tile": 22, "affect": [22, 81, 100], "matmul": [22, 43, 45, 96, 100, 103], "qqq": [28, 40, 41], "64": [29, 36, 46, 61, 98, 99, 101, 103, 105], "256": [29, 46, 65, 66, 67, 76, 77, 99, 110, 111, 114], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "mayb": 30, "cast_config_input": 31, "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": [31, 81], "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "from_recipe_nam": 31, "recipe_nam": [31, 95], "float8linearrecipenam": 31, "qualnam": [32, 33, 50, 51, 72, 81, 82], "boundari": [32, 33, 50, 51, 72, 81, 82], "strategi": 32, "module_filter_fn": [34, 95], "callabl": [34, 80, 91, 92, 105], "float8linearconfig": 34, "float8linear": [34, 95], "instanc": [34, 58, 63, 73, 80, 87, 91, 92, 98, 103, 110, 112, 113, 114], "fqn": [34, 88, 91, 95, 101], "sum": [35, 110, 111], "prototyp": [36, 37, 38, 39, 40, 41, 42, 69, 75, 96, 114], "blocksiz": 36, "number": [38, 50, 61, 74, 76, 77, 88, 99, 100, 103, 111, 112], "expon": 38, "mantissa": 38, "tensorcor": 38, "da8w4": 39, "marlinqqq": 41, "_choose_qparams_and_quantize_affine_qqq": 41, "_dequantize_affine_qqq": 41, "pack_dim": 42, "uintx": 42, "standard": [42, 105], "byte": 42, "uintxtensor": 42, "determin": [42, 52, 71, 95, 100, 105], "along": [42, 100, 105, 109], "indic": [42, 100, 114], "last": [42, 95, 109], "activation_dtyp": [43, 96], "float8_e4m3fn": [43, 45, 62, 96], "weight_dtyp": [43, 45, 96, 99], "pertensor": [43, 49, 62, 101], "perrow": [43, 48, 49, 62, 96], "list": [43, 54, 56, 88, 92, 97, 103, 104, 105, 109, 111, 114], "packing_format": [43, 46], "float8packingformat": 43, "activation_value_lb": 43, "activation_value_ub": 43, "kernel_prefer": [43, 96], "kernelprefer": 43, "set_inductor_config": [43, 45, 46, 47, 48, 49], "fp8granular": [43, 62], "fast": [43, 100], "accumul": 43, "upper": [43, 62], "defalut": 43, "chosen": [43, 84, 100], "torchinductor": [43, 45, 46, 47, 48, 49, 112, 113], "deprec": [43, 45, 46, 48, 64, 68], "int4_packing_format": [44, 46, 97], "int4packingformat": [44, 46], "preshuffl": [44, 96], "128": [44, 46, 95, 99, 101, 103, 104, 105, 113, 114], "underli": [44, 99, 103], "bigger": 44, "channel": [45, 48, 49, 61, 65, 66, 67, 69, 73, 74, 76, 77, 87, 101, 113], "tensorcoretiledlayout": [46, 97], "int4_choose_qparams_algorithm": [46, 97], "int4chooseqparamsalgorithm": 46, "groupwis": 46, "mainli": [46, 96, 109, 112, 114], "distinguish": [46, 96], "control": [46, 47, 48, 88, 100, 105, 110], "fine": [46, 47, 93, 95, 99, 100], "grain": [46, 47, 103], "variant": [46, 50, 53, 103], "hqq": [46, 96, 97], "preserv": [46, 52, 88, 99, 100, 109], "Will": 46, "subset": [46, 96], "valid": [46, 92, 99, 105, 114], "state": [46, 105], "v1": [46, 99], "v2": [46, 108], "ignor": [46, 58, 63, 73, 87, 95, 110, 111], "less": [46, 50, 100, 103, 110], "confus": [46, 96, 100, 110], "act_mapping_typ": [47, 48], "produc": [47, 97, 109, 110, 111, 112, 113], "backend": [47, 93, 97, 99, 100, 114], "marlinqqqlayout": 47, "cutlassint4packedlayout": 47, "weight_only_decod": 48, "around": [48, 95, 96, 97, 98, 110], "decod": [48, 99], "better": [48, 49, 95, 103, 110, 111, 112, 113, 114], "split": [48, 99, 110, 111], "int8tensor": [48, 96], "sai": [50, 85, 96, 104, 105, 114], "3": [50, 58, 85, 93, 95, 96, 97, 100, 104, 108, 110, 111], "7": [50, 95, 99, 112, 113], "symmetric_no_clipping_err": 50, "smin": 50, "smax": 50, "min_val_neg": [50, 103], "max_val_po": [50, 103], "By": [50, 100], "individu": [50, 100], "error": [50, 69, 95, 103, 110], "neg": 50, "placehold": [51, 96, 113], "int32": [52, 65, 69, 73, 74, 96, 97, 110, 114], "keepdim": [52, 103, 110, 111], "fp32": [52, 54, 69, 77, 101, 103, 110, 112], "fp16": 52, "optioanl": 52, "param": [52, 53, 88, 99], "request": [52, 54, 85], "min_val": [53, 103], "max_val": [53, 103], "observ": [53, 87, 96, 100, 101, 109, 110, 111, 112, 113, 114], "obtain": 53, "track": [53, 104, 105], "calibr": [53, 97, 109, 111, 112, 113], "mostli": [53, 71, 97], "input_dtyp": 54, "output_dtyp": [54, 73, 85], "uint8": [54, 85, 96, 101, 114], "b": [55, 81, 92], "scales1": 55, "multipli": [55, 86, 100], "second": [55, 71, 92, 95, 96, 108, 114], "rais": [55, 68, 71, 86, 103, 105], "assertionerror": [55, 86, 103], "expect": [55, 95, 100, 103, 109, 110, 112, 113, 114], "qat": [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 93, 99, 112], "twostepquant": 56, "easili": [56, 109], "thei": [56, 95, 97, 100, 103, 104, 110, 111, 114], "constructor": [56, 92, 103], "must": [56, 69, 71, 77, 95, 100, 104, 105, 111, 113, 114], "embed": [56, 58, 65, 68, 71, 73, 74], "my_quant": 56, "qatquantizer1": 56, "qatquantizer2": 56, "qatquantizer3": 56, "num_embed": [58, 73, 74], "embedding_dim": [58, 73, 74], "padding_idx": [58, 73, 74], "max_norm": [58, 73, 74], "norm_typ": [58, 73, 74], "scale_grad_by_freq": [58, 73, 74], "weight_config": [58, 59, 68, 71], "fakequantizeconfigbas": [58, 59, 68, 71], "intxfakequantizeconfig": [58, 59, 68, 70, 71], "fq_embed": 58, "longtensor": 58, "overridden": [58, 63, 73, 87], "within": [58, 63, 73, 87, 99, 100, 105, 112, 113], "afterward": [58, 63, 73, 87], "former": [58, 63, 73, 87], "care": [58, 63, 73, 87, 98, 100, 110], "hook": [58, 63, 73, 87, 96], "latter": [58, 63, 73, 87, 111], "silent": [58, 63, 73, 87, 112], "in_featur": [59, 76, 77, 95, 97, 98, 101, 103], "out_featur": [59, 76, 77, 95, 97, 101, 103], "activation_config": [59, 68, 71], "per_token": [59, 68, 69, 71], "is_symmetr": [59, 68, 69, 71], "fq_linear": 59, "scale_precis": [61, 65, 69, 73, 74], "rowwis": [61, 96], "hp_value_lb": 62, "hp_value_ub": 62, "float8fakequantizeconfig": 63, "fakequantizedembed": 64, "back": [64, 103], "model_with_fake_quantized_linear": 64, "zero_point_precis": [65, 69, 73, 74], "int4weightonlyqatembed": 65, "int4weightonlyembed": 65, "scales_precis": [66, 67, 76, 77], "padding_allow": 67, "valueerror": [68, 71], "torchaodtyp": 69, "is_dynam": [69, 112, 113, 114], "range_learn": 69, "simul": [69, 71, 89, 100], "older": 69, "int1": [69, 96], "int7": [69, 96], "pergroup": [69, 99], "pertoken": 69, "per_channel": 69, "peraxi": [69, 99, 101], "per_group": [69, 85], "combin": [69, 99, 100, 103, 110, 112], "leav": 69, "empti": [69, 96], "keyword": [69, 71, 83, 96], "properti": [69, 70], "throw": 69, "els": [69, 96, 99, 105, 110, 111], "symmetri": 70, "qatstep": 71, "awar": [71, 88, 93, 97, 100, 103], "ptq": [71, 111, 112], "automat": [71, 95, 99, 103, 104, 105, 108], "phase": [71, 114], "int4weightonlyconfig": [71, 80, 97, 98, 104, 105], "experiment": [71, 109], "qat_config": 71, "act_config": 71, "alwai": [71, 99, 103], "One": [71, 100, 103, 105, 114], "enum": [72, 81], "example_input": [75, 97, 98, 101, 109, 110, 111, 112, 113, 114], "intxfakequantizerbas": 75, "weightonlyint4linear": 76, "hardcod": [77, 114], "mod": [78, 79, 95, 100, 103], "disabl": [78, 103, 111], "filter_fn": [80, 91], "_is_linear": [80, 101], "inplac": [80, 88, 97], "fulli": [80, 91, 99, 100, 110], "qualifi": [80, 91, 100], "final": [80, 96, 97, 100, 109, 110, 111, 112, 113, 114], "predefin": [80, 82, 114], "execut": [80, 103, 107], "int8dynamicactivationint8weightconfig": [80, 91, 104], "sequenti": [80, 91, 95], "select": [81, 110], "found": [81, 96, 97, 99, 100, 101, 103], "nativ": [81, 93, 95, 96, 103, 110], "gemm_lowp": 81, "gemm_fp32": 81, "ci": 81, "product": [81, 88, 99, 105, 112, 114], "logic": [81, 97, 103, 105], "lowp": 81, "gemm": [81, 95, 112, 113], "laid": [82, 96], "opaqu": 82, "decid": [82, 100, 101], "adopt": [82, 96], "creation": [83, 105], "construct": [83, 96, 110, 114], "from_hp": [83, 96], "cl": [83, 92, 101, 103, 105], "quant_kwarg": [83, 84], "quantizetensorkwarg": 84, "flexibl": [84, 100, 103, 109, 112], "variou": 84, "tabl": [85, 92, 95, 96, 100], "show": [85, 95, 97, 99, 100, 105, 110, 111], "per_tensor": 85, "per_axi": 85, "axi": [85, 101], "mat2": 86, "consid": [86, 100], "cubla": 86, "fallback": [86, 105], "j": 86, "l2": [87, 100], "norm": [87, 88, 100], "buffer": 87, "x_orig": 87, "sparsity_level": [88, 100], "semi_structured_block_s": 88, "wanda": 88, "sparsifi": [88, 93, 98, 100], "http": [88, 99, 100, 104, 113], "arxiv": [88, 100], "org": [88, 99, 100, 113], "ab": [88, 100], "2306": 88, "11695": 88, "magnitud": [88, 100], "dict": [88, 92, 103, 105, 113, 114], "parametr": 88, "deepcopi": [88, 97, 101, 103, 111], "squash_mask": [88, 100], "params_to_keep": 88, "params_to_keep_per_lay": 88, "squash": 88, "mask": [88, 100], "appropri": [88, 109, 110, 111, 112, 113], "sparse_param": 88, "attach": [88, 100, 114], "kei": [88, 100, 108], "xdoctest": 88, "skip": [88, 96, 100], "local": [88, 99, 100], "hasattr": [88, 105], "submodule1": 88, "linear1": [88, 97, 98, 101, 103], "foo": [88, 110], "bar": [88, 110], "submodule2": 88, "linear42": 88, "baz": 88, "42": [88, 101], "24": 88, "ones": [88, 111], "update_mask": 88, "tensor_nam": [88, 105], "statist": [88, 100, 101, 110, 111], "retriev": 88, "act_per_input": 88, "Then": [88, 103, 113, 114], "whole": [88, 114], "alia": [90, 92, 105], "semisparseweightconfig": 90, "sparsify_": 91, "apply_tensor_subclass": 91, "essenti": [91, 105, 109], "semi_sparse_weight": 91, "semisparselayout": 91, "sparsemarlinlayout": 91, "isinst": [91, 95, 100, 101, 103, 105, 111, 114], "sparse_api": 91, "commonli": [92, 95, 100], "includ": [92, 95, 96, 103, 109, 112, 113, 114], "_get_to_kwarg": 92, "register_layout": 92, "plainaqttensorimpl": [92, 101], "get_tensor_impl_constructor": 92, "tensor_impl_ctr": 92, "simplifi": [92, 109, 110, 112, 113], "implment": 92, "tensor_data": 92, "optional_tensor_data_nam": 92, "boilerpl": 92, "optional_tensor_attribute_nam": 92, "__new__": [92, 103, 105], "exaclti": 92, "present": [92, 100], "__tensor_flatten__": [92, 103, 105], "flatten": 92, "attribute_nam": 92, "__tensor_unflatten__": [92, 103, 105], "tensor_data_dict": [92, 103, 105], "_apply_fn_to_data": [92, 105], "recreat": 92, "__repr__": [92, 103], "_same_metadata": 92, "between": [92, 96, 100, 103, 105, 109, 111, 112, 114], "__setstate__": 92, "serial": [92, 93, 96, 104, 110, 111], "old": 92, "maintain": [92, 99, 100], "bc": 92, "contigu": [92, 96, 112, 113], "detach": [92, 103, 105], "clone": [92, 99, 105], "copy_": [92, 105], "_to_copi": [92, 105], "f": [92, 95, 96, 98, 99, 100, 101, 103, 105, 110, 111], "h": [92, 99], "layout_class": 92, "tensorimplclass": 92, "from_plain": 92, "tensor_class": 92, "aten_op": 92, "decor": [92, 103, 105], "__torch_dispatch__": [92, 103], "implements_torch_funct": 92, "torch_fn": 92, "__torch_function__": [92, 96, 103], "registr": 92, "aqt": 92, "introduct": [93, 96, 99], "highlight": [93, 103, 108], "guid": [93, 96, 99, 109], "contributor": [93, 96, 97], "benchmark": [93, 95, 97, 104, 109, 112, 113], "tune": [93, 95, 99, 100, 109], "vllm": [93, 104], "sglang": [93, 104], "hug": [93, 99], "face": [93, 96, 99, 100, 110], "advanc": [93, 101, 103, 109, 112, 113], "export": [93, 96], "x86": [93, 97], "intel": [93, 109, 112], "openvino": [93, 97], "5x": 95, "cluster": [95, 96], "34": 95, "43x": 95, "2k": 95, "h200": 95, "latest": 95, "offic": 95, "offici": [95, 96], "sever": [95, 105, 109, 114], "popular": 95, "flagship": 95, "form": [95, 96, 100], "quickli": [95, 103], "batteri": 95, "fork": 95, "build": [95, 96, 100, 103, 105, 110], "top": [95, 96, 103, 109, 110, 111, 112, 113], "virtual": 95, "environ": [95, 99], "conda": 95, "venv": 95, "download": [95, 99, 106, 108, 110, 111, 113], "job": 95, "below": [95, 96, 100, 103, 104, 105, 108, 109], "root": [95, 99], "launch": 95, "ngpu": 95, "config_fil": 95, "train_config": 95, "llama3_8b": 95, "toml": 95, "run_train": 95, "sh": [95, 99], "hyperparamet": 95, "edit": [95, 99], "line": [95, 100, 104], "flag": [95, 111], "termin": 95, "rank0": 95, "titan": 95, "2025": 95, "06": 95, "04": 95, "08": 95, "51": 95, "48": 95, "info": 95, "2254": 95, "27": 95, "34gib": 95, "28": 95, "78": 95, "tp": [95, 105], "375": 95, "tflop": 95, "21": 95, "73": [95, 101], "mfu": 95, "20": [95, 99, 111], "58": 95, "557": 95, "7069": 95, "99gib": 95, "62": 95, "034": 95, "35": [95, 99, 101], "41": [95, 99], "19": 95, "52": 95, "224": [95, 101, 109, 110, 111, 112, 113], "9196": 95, "022": 95, "406": [95, 110, 111], "65": 95, "904": 95, "1423": 95, "014": 95, "23": [95, 101], "As": [95, 110, 114], "warmup": 95, "7k": 95, "99gb": 95, "peak": [95, 99, 104], "against": 95, "02": 95, "37": 95, "404": 95, "2611": 95, "22gib": 95, "595": 95, "47": 95, "49": [95, 101], "027": 95, "4260": 95, "89gib": 95, "344": 95, "367": 95, "39": 95, "03": 95, "01": 95, "988": 95, "9482": 95, "321": 95, "366": 95, "14": 95, "991": 95, "1183": 95, "300": 95, "364": 95, "89": 95, "40": 95, "4659": 95, "291": 95, "84": 95, "769": 95, "gc": 95, "peform": 95, "period": 95, "collect": [95, 100], "3k": 95, "89gb": 95, "11x": 95, "nearli": 95, "ident": [95, 100], "performan": 95, "v": [95, 100, 110, 114], "curv": [95, 100], "omit": [95, 96, 110, 111, 112], "648": 95, "2648": 95, "28gib": 95, "71": 95, "26": 95, "475": 95, "9106": 95, "91gib": 95, "53": [95, 99], "503": 95, "434": 95, "43": 95, "94": [95, 110], "166": 95, "0774": 95, "663": 95, "443": 95, "44": [95, 101], "87": 95, "50": [95, 100, 101, 109, 110, 112, 113], "885": 95, "3233": 95, "643": 95, "442": 95, "66": [95, 99, 101], "76": 95, "613": 95, "6150": 95, "637": 95, "72": [95, 99], "6k": 95, "91gb": 95, "21x": [95, 99], "tl": 95, "dr": 95, "priorit": 95, "accur": [95, 100, 109], "stabil": 95, "cost": [95, 101], "slightli": [95, 103], "impact": [95, 99, 105], "outlier": 95, "caus": 95, "underflow": 95, "8xh100": 95, "box": [95, 100, 112], "toi": [95, 97, 101, 103, 112], "convert_to_float8_train": 95, "recurs": 95, "kind": [95, 110], "over": [95, 100, 110, 111], "snippet": [95, 110, 111], "float8_linear_util": 95, "float8_linear": 95, "sampl": [95, 110, 112, 113], "adamw": 95, "being": [95, 100, 105, 112, 113], "elig": 95, "divis": 95, "label": 95, "fake_label": 95, "ones_lik": 95, "mse_loss": 95, "model_state_dict": 95, "state_dict": [95, 98, 110, 111], "optimizer_state_dict": 95, "pth": [95, 110, 111], "explor": [95, 97, 113], "few": [95, 103, 110, 111], "lai": 96, "stack": [96, 99], "awq": 96, "gptq": 96, "int4tensor": 96, "int4preshuffledtensor": 96, "uint1": 96, "uint7": 96, "float3": 96, "triton": [96, 112, 113], "overload": [96, 100], "term": [96, 100, 110, 114], "extra": [96, 99], "matter": [96, 100], "float4_e2m1fn_x2": 96, "float8_e4m3fnuz": 96, "float8_e5m2": 96, "float8_e5m2fnuz": 96, "float8_e8m0fnu": 96, "pr": 96, "shell": 96, "dervi": 96, "mxfp8": 96, "preicison": 96, "mention": [96, 110], "previou": [96, 99, 110, 111, 112, 113], "accommod": 96, "choose_qparams_affine_with_min_max": 96, "min": [96, 101, 103, 110, 114], "raw": 96, "quantize_fp8_row": 96, "int_matmul": 96, "int_scaled_matmul": 96, "reli": [96, 97, 100, 101, 103], "handwritten": 96, "On": [96, 97], "glue": 96, "everyth": 96, "togeth": [96, 99, 110, 112, 114], "anoth": [96, 100, 103, 110, 114], "side": 96, "swizzl": 96, "dtpype": 96, "float8rowwisetensor": 96, "float8blockwisetensor": 96, "close": [96, 100], "low_precision_v": 96, "high_precision_v": 96, "procedur": 96, "especi": [96, 98, 100, 112, 113], "bitwidth": [96, 114], "codebook": 96, "index": [96, 99, 100, 113], "vector": [96, 100, 112], "kmean": 96, "tradition": 96, "explain": [96, 109, 112], "simplest": [96, 100], "easi": [96, 99], "linear_modul": 96, "runtim": [96, 110], "main": [96, 97, 99, 100, 101, 103, 104, 110, 114], "question": [96, 98, 100, 103, 114], "activation_granular": 96, "act_quant_kwarg": 96, "weight_granular": [96, 99], "quantized_weight": [96, 105], "float8_dtyp": 96, "haven": 96, "seen": 96, "pt2": [96, 103, 112], "autoround": 96, "multitensor": 96, "sure": [96, 99, 114], "open": [96, 100], "describ": [96, 98, 100, 108, 110, 111], "finetun": [96, 99], "quantized_train": 96, "progress": [96, 104, 105], "lot": [96, 100], "connect": [96, 114], "walk": [96, 101, 103, 108, 109, 112], "float8dynamicactivationfloat8weightconfig": [96, 104], "len": [96, 99, 105, 110, 111, 114], "_choose_quant_func_and_quantize_tensor": 96, "relat": [96, 100], "xq": 96, "reshap": [96, 110, 111], "wq": 96, "x_scale": [96, 110], "w_scale": 96, "out_shap": 96, "entri": 97, "mutat": 97, "toylinearmodel": [97, 98, 101], "linear2": [97, 98, 101, 103], "eval": [97, 98, 99, 101, 109, 111, 112, 113], "faster": [97, 100], "model_bf16": 97, "uint4": 97, "int4mm": 97, "mix": [97, 99, 109, 112, 113], "tile_packed_to_4d": 97, "stai": [97, 103], "tensor_impl_dtyp": 97, "roughli": [97, 100], "quarter": 97, "o": [97, 110, 111], "int4_model": 97, "pt": [97, 99], "bfloat16_model": 97, "int4_model_size_mb": 97, "getsiz": [97, 110, 111], "bfloat16_model_size_mb": 97, "2f": [97, 110, 111], "mb": [97, 98, 107, 110, 111], "00": [97, 107], "benchmark_model": 97, "unwrap_tensor_subclass": 97, "num_run": 97, "100": [97, 103, 110, 111], "_dynamo": [97, 103], "reset": [97, 110, 111], "bf16_time": 97, "int4_tim": 97, "time": [97, 100, 103, 104, 108, 109, 110, 111], "3f": [97, 111], "1fx": 97, "393": 97, "410": 97, "9x": 97, "recogn": [97, 114], "decis": 97, "pt2e": [97, 109, 110, 111, 112, 113], "fuse": [97, 100, 103, 111], "deleg": [97, 110], "x86inductorquant": [97, 112], "quantize_pt2": [97, 109, 110, 111, 112, 113], "prepare_pt2": [97, 109, 110, 112, 113], "x86_inductor_quant": [97, 112], "get_default_x86_inductor_quantization_config": [97, 112], "float_model": [97, 103, 109, 110, 111, 112, 113], "data_load": [97, 110, 111, 112, 113], "no_grad": [97, 103, 109, 110, 111, 112, 113], "imag": [97, 104, 109, 110, 111, 112, 113], "program": [97, 110, 111, 112, 114], "captur": [97, 110, 111, 114], "expos": [97, 110, 111], "set_glob": [97, 110, 111, 112, 113], "xiq": [97, 112], "prepare_qat_pt2": [97, 111, 112], "sample_inference_data": 97, "convert_pt2": [97, 109, 110, 111, 112, 113], "wrapper": [97, 103, 112], "_inductor": [97, 112], "cpp_wrapper": [97, 112], "optimized_model": [97, 109, 112, 113], "converted_model": [97, 112, 113], "xpu": [97, 113], "simpl": [97, 100, 101, 103, 109, 112, 113], "visit": 97, "would": [97, 100, 103, 111, 113], "forget": 97, "tempfil": [98, 104], "get_model_size_in_byt": 98, "ref": [98, 110], "namedtemporaryfil": 98, "seek": [98, 100], "m_load": 98, "load_state_dict": [98, 110, 111], "assign": 98, "assert": [98, 101, 103, 105, 114], "equal": [98, 100], "thing": [98, 100, 103, 110], "float_weight1": 98, "float_weight2": 98, "quantized_weight1": 98, "quantized_weight2": 98, "go": [98, 103, 114], "techinqu": 98, "reduct": [98, 99, 100, 103], "4x": [98, 99], "0625": 98, "reason": [98, 100], "avoid": [98, 100], "affine_quantized_tensor": 98, "deploi": 99, "engin": 99, "seamlessli": [99, 103, 112, 113], "seamless": [99, 112], "hf": [99, 104], "signific": [99, 100], "pip": [99, 104, 109, 110], "url": [99, 113], "whl": [99, 113], "nightli": 99, "cu128": 99, "push": [99, 100, 104, 105], "hub": [99, 104, 105], "server": [99, 105], "phi": 99, "fp8": 99, "microsoft": 99, "o3": 99, "client": 99, "curl": 99, "localhost": 99, "8000": 99, "chat": 99, "content": 99, "applic": 99, "messag": 99, "role": 99, "give": [99, 100, 103], "me": 99, "short": 99, "larg": [99, 103, 112], "languag": 99, "temperatur": 99, "top_p": 99, "95": 99, "top_k": 99, "max_token": 99, "32768": 99, "vram": 99, "15x": 99, "2x": [99, 100], "littl": [99, 105], "packag": [99, 104], "git": [99, 104], "com": [99, 104], "acceler": [99, 100, 104], "autotoken": [99, 104], "pipelin": 99, "random": [99, 100, 110, 111], "manual_se": [99, 110, 111], "model_path": 99, "device_map": [99, 104, 105], "trust_remote_cod": 99, "ai": 99, "assist": 99, "eat": 99, "banana": 99, "dragonfruit": 99, "smoothi": 99, "blend": 99, "milk": 99, "honei": 99, "salad": 99, "slice": [99, 105], "lemon": 99, "juic": 99, "solv": [99, 100, 103], "equat": 99, "pipe": [99, 104], "text": 99, "generation_arg": 99, "max_new_token": 99, "500": 99, "return_full_text": 99, "do_sampl": 99, "generated_text": 99, "lm_head": 99, "those": [99, 100, 101, 103], "ti": 99, "autoprocessor": 99, "modeling_util": 99, "find_tied_paramet": 99, "model_id": [99, 104], "untied_model": 99, "getattr": [99, 105], "get_text_config": 99, "tie_word_embed": 99, "setattr": [99, 103], "_tied_weights_kei": 99, "user_id": 99, "your_user_id": 99, "model_nam": [99, 109, 112, 113], "save_to": [99, 104], "save_to_local_path": 99, "int8dynamicactivationintxweightconfig": [99, 104], "ve": [99, 100], "intxweightonlyconfig": [99, 104], "fqntoconfig": [99, 105], "untied_model_id": 99, "untied_model_local_path": 99, "embedding_config": 99, "linear_config": 99, "weight_scale_dtyp": 99, "quant_config": 99, "_default": [99, 105], "embed_token": 99, "quant_typ": [99, 104, 105], "include_embed": 99, "untie_embedding_weight": 99, "modules_to_not_convert": 99, "quantized_model": [99, 103, 104, 109, 110, 111], "safe_seri": [99, 104, 105], "pte": 99, "cd": 99, "install_requir": 99, "phi_4_mini": 99, "convert_weight": 99, "pytorch_model": 99, "bin": 99, "pytorch_model_convert": 99, "export_llama": 99, "kv": 99, "use_sdpa_with_kv_cach": 99, "get_bos_id": 99, "199999": 99, "get_eos_id": 99, "200020": 99, "max_seq_length": 99, "max_context_length": 99, "output_nam": 99, "phi4": 99, "phone": 99, "io": 99, "2gb": 99, "iphon": 99, "pro": [99, 100], "17": 99, "sec": 99, "test": [99, 104, 108, 110, 112], "lm": 99, "har": 99, "eleutherai": 99, "lm_eval": 99, "model_arg": 99, "pretrain": [99, 100, 109, 110, 111, 112], "reset_peak_memory_stat": 99, "prompt": [99, 104], "hei": 99, "consciou": 99, "templated_prompt": 99, "apply_chat_templ": 99, "add_generation_prompt": 99, "templat": [99, 106, 107], "return_tensor": 99, "generated_id": 99, "output_text": 99, "batch_decod": 99, "skip_special_token": 99, "clean_up_tokenization_spac": 99, "respons": 99, "mem": 99, "max_memory_reserv": 99, "1e9": 99, "02f": 99, "gb": 99, "hello": [99, 104], "ye": 99, "am": 99, "digit": 99, "todai": 99, "70": [99, 101], "bench": 99, "vllm_disable_compile_cach": 99, "project": 99, "vllm_use_precompil": 99, "sharegpt": 99, "wget": 99, "co": 99, "anon8231489123": 99, "sharegpt_vicuna_unfilt": 99, "resolv": 99, "sharegpt_v3_unfiltered_cleaned_split": 99, "tree": 99, "num": 99, "benchmark_serv": 99, "16x": 99, "14x": 99, "num_prompt": 99, "req": 99, "57": [99, 101], "1000": [99, 112], "68": 99, "80": 99, "entir": [99, 110, 111], "ml": 99, "gain": [99, 100, 113], "eas": 99, "accept": [99, 114], "trade": [99, 100], "off": [99, 100], "neural": [100, 109, 112], "network": [100, 103, 109, 112], "latenc": 100, "carefulli": 100, "pai": 100, "low": [100, 103, 104, 109], "price": 100, "f1": 100, "problem": [100, 103], "research": [100, 108], "fragment": 100, "rightfulli": 100, "spent": 100, "figur": [100, 110], "compress": [100, 109], "place": [100, 109, 110, 111, 112, 113], "dens": 100, "focu": [100, 103], "realli": 100, "concret": [100, 114], "hope": 100, "modular": 100, "nice": 100, "scratch": [100, 108], "minim": [100, 109, 112, 113], "algorthim": 100, "realiz": 100, "theoret": 100, "analog": 100, "fix": [100, 101], "unstructur": 100, "retrain": 100, "neglig": 100, "area": 100, "agre": 100, "upon": 100, "consensu": 100, "mind": 100, "thought": 100, "subproblem": 100, "satisfi": 100, "my": [100, 111], "independ": 100, "frontend": [100, 112], "arbitrari": 100, "handoff": 100, "piec": 100, "natur": [100, 103, 110, 114], "clear": 100, "contract": 100, "7x": 100, "advantag": 100, "anticip": 100, "solut": 100, "third": 100, "parti": 100, "to_sparse_semi_structur": 100, "sparsesemistructuredtensor": 100, "weightnormsparsifi": 100, "half": 100, "subnetwork": 100, "sparse_config": 100, "named_modul": 100, "tensor_fqn": 100, "sparse_block_shap": 100, "zeros_per_block": 100, "fakespars": 100, "fundament": [100, 111], "manipul": 100, "dictionari": 100, "paramer": 100, "parameter": 100, "necessari": [100, 101, 103, 109, 110, 111, 112, 113], "suitabl": [100, 112], "spot": 100, "definit": [100, 105], "academia": 100, "industri": 100, "often": [100, 103], "interchang": 100, "distinct": 100, "idea": 100, "behind": 100, "doesn": [100, 111, 114], "itself": [100, 103], "loos": 100, "speak": 100, "tightli": 100, "coupl": [100, 103], "csc": 100, "qnnpack": 100, "descript": [100, 109], "coo": 100, "sparse_coo": 100, "coordin": 100, "locat": 100, "bsr": 100, "sparse_bsr": 100, "veri": [100, 105, 111], "except": [100, 103, 114], "scalar": [100, 110], "dimension": 100, "csr": 100, "sparse_csr": 100, "sparse_csc": 100, "column": 100, "compact": 100, "sparse_matrix": 100, "1d": 100, "indexptr": 100, "\u00bd": 100, "bitmask": 100, "2bit": 100, "unprun": 100, "quit": [100, 103], "broken": 100, "down": 100, "sensit": 100, "effect": [100, 101, 103, 112, 113, 114], "best": [100, 112], "subsequ": [100, 103, 112, 113], "infinit": 100, "lost": 100, "degre": 100, "drop": 100, "proxi": 100, "aforement": 100, "smallest": 100, "absolut": 100, "scope": 100, "impli": 100, "con": 100, "potenti": [100, 101, 109, 110, 112, 113], "sub": 100, "span": 100, "threshold": 100, "constant": [100, 103, 110], "ctr_mobile_fe": 100, "score": 100, "w": [100, 105], "tenosr": 100, "udpat": 100, "histori": 100, "regrow": 100, "dw": 100, "via": [100, 109], "backprop": 100, "pat": 100, "unmask": 100, "resid": 100, "salienc": 100, "lowest": 100, "l1": 100, "abl": [100, 103, 105, 110, 114], "repeat": [100, 110, 111], "movement": 100, "2005": 100, "07683": 100, "rank": [100, 103], "wx": 100, "sqx": 100, "q": [100, 110], "usual": 100, "sort": 100, "wise": 100, "reconstruct": [100, 105], "randomli": 100, "tri": 100, "remedi": 100, "sometim": 100, "item": [100, 108], "ultim": [100, 101], "complic": [100, 110], "literatur": 100, "vision": 100, "nlp": [100, 108, 112], "iter": [100, 110, 111], "ctr_feed": 100, "na": 100, "multimask": 100, "search": 100, "pyspeech": 100, "fastna": 100, "approach": [100, 103, 109, 112, 113], "knowledg": [100, 108], "distil": 100, "pdf": 100, "2204": 100, "09656": 100, "arrang": 100, "recal": 100, "counterpart": 100, "slower": 100, "suffici": 100, "At": [100, 110], "98": 100, "special": [100, 109, 110], "exhibit": 100, "penalti": 100, "expens": [100, 103], "dictat": 100, "characterist": 100, "highest": 100, "wouldn": [100, 103], "visual": 100, "fig": 100, "4x4": 100, "benchmak": 100, "fly": [101, 104], "affinequantizedminmaxobserv": 101, "record": 101, "welcom": 101, "averag": [101, 110, 111], "histogram": [101, 110], "act_ob": 101, "finfo": 101, "weight_ob": 101, "observedlinear": 101, "observed_input": 101, "observed_weight": 101, "from_float": [101, 103], "float_linear": 101, "observed_linear": 101, "_replace_with_custom_fn_if_matches_filt": 101, "insert_observers_": 101, "lambda": [101, 105], "replacement_fn": 101, "copied_act_ob": 101, "copied_weight_ob": 101, "popul": 101, "feed": 101, "simpler": [101, 110], "quantizedlinear": [101, 103], "isn": 101, "strictli": 101, "to_affine_quantized_intx_stat": 101, "act_scal": [101, 114], "act_zero_point": 101, "calculate_qparam": [101, 114], "weight_scal": [101, 110, 114], "weight_zero_point": [101, 110], "qweight": 101, "qinput": 101, "from_observ": 101, "quantized_linear": [101, 110], "begin": [101, 103], "dataclass": [101, 105, 114], "transform_modul": [101, 105], "register_quantize_module_handl": [101, 105], "staticquantconfig": 101, "_apply_static_qu": 101, "associ": 101, "identifi": [101, 114], "is_observed_linear": 101, "optimizedmodul": 101, "_orig_mod": 101, "0237": 101, "142": 101, "31": [101, 114], "113": 101, "157": 101, "59": 101, "160": 101, "150": 101, "67": 101, "241": 101, "238": 101, "235": 101, "228": 101, "255": [101, 114], "201": 101, "114": 101, "236": 101, "88": [101, 110], "83": 101, "109": 101, "209": 101, "92": 101, "184": 101, "141": 101, "110": 101, "0009": 101, "0010": 101, "130": 101, "122": 101, "132": 101, "125": 101, "126": 101, "129": 101, "127": [101, 103, 113, 114], "133": 101, "124": 101, "131": 101, "135": 101, "136": 101, "foundat": 103, "autograd": [103, 114], "interpos": 103, "namespac": 103, "continu": [103, 104, 111, 112, 113, 114], "obviou": 103, "int8quantizedlinear": 103, "finer": 103, "intercept": 103, "contrast": 103, "clunki": 103, "distributedlinear": 103, "duplic": 103, "bypass": 103, "wrap": [103, 112, 113], "outer": 103, "inner": 103, "allgath": 103, "bandwidth": 103, "exactli": 103, "zoo": 103, "podcast": 103, "edward": 103, "yang": 103, "int8_symmetric_quant": 103, "fp32_tensor": 103, "amin": 103, "amax": 103, "zeros_lik": 103, "view": [103, 110, 111], "clamp": [103, 110], "w_int8": 103, "new_linear": 103, "left": [103, 114], "toymodel": 103, "child": 103, "named_children": 103, "drawback": 103, "won": 103, "suppos": 103, "clean": 103, "eleg": 103, "pretti": 103, "power": [103, 105], "overrid": 103, "almost": 103, "shard": [103, 105], "ragged": 103, "rag": 103, "nestedtensor": 103, "who": 103, "link": [103, 108], "why": [103, 108], "googl": 103, "collab": 103, "flopcount": 103, "memorytrack": 103, "bare": 103, "bone": 103, "int8symmetrictensor": 103, "hold": [103, 104], "staticmethod": 103, "_make_wrapper_subclass": [103, 105], "storage_offset": 103, "ndim": 103, "extra_metadata": 103, "outer_s": [103, 105], "outer_strid": [103, 105], "undo": 103, "repr": 103, "ahead": 103, "insid": 103, "int8_tensor": 103, "op_implementations_dict": 103, "conveni": 103, "register_op": 103, "_op": 103, "opoverload": 103, "impl_decor": 103, "op_impl": 103, "done": 103, "particular": 103, "largest": 103, "tell": 103, "desugar": 103, "surfac": 103, "coverag": [103, 109, 110, 112, 113], "brute": 103, "forc": 103, "repeatedli": 103, "log": 103, "loggingtensor": 103, "_python_dispatch": [103, 105], "return_and_correct_alias": [103, 105], "int8_mm": 103, "int8_view_op": 103, "out_data": 103, "out_scal": [103, 110], "notic": 103, "hit": 103, "background": 103, "decomposit": 103, "live": 103, "decomp": 103, "shrink": 103, "author": [103, 108, 109, 110, 111, 112, 113, 114], "But": [103, 105, 114], "pain": 103, "rather": 103, "worth": 103, "written": 103, "differenti": 103, "nuanc": 103, "longer": [103, 110, 111], "had": [103, 110], "That": 103, "transposit": 103, "got": [103, 110, 114], "propag": [103, 110, 112, 113], "fact": 103, "themselv": [103, 110], "pointwis": [103, 112, 113], "were": 103, "might": [103, 105, 110, 114], "unwrap": 103, "dim0": 103, "dim1": 103, "confirm": 103, "quantized_model_module_swap": 103, "quantized_model_subclass": 103, "subclass_param": 103, "out_module_swap": 103, "allclos": 103, "out_compil": 103, "seri": 103, "discuss": 103, "float8dynamicactivationint4weightconfig": 104, "torch_dtyp": 104, "fluxpipelin": 104, "fluxtransformer2dmodel": 104, "black": 104, "forest": 104, "lab": 104, "flux": 104, "dev": 104, "subfold": 104, "cat": [104, 114], "sign": [104, 113], "world": [104, 105], "num_inference_step": 104, "guidance_scal": 104, "png": 104, "temporarydirectori": 104, "tmp_dir": 104, "uncom": 104, "usernam": [104, 105], "statu": [104, 105], "becom": [104, 110], "stabl": 104, "int4wo": 104, "team": [104, 105], "retain": 104, "thoroughli": 104, "e2": 105, "_type": 105, "_data": 105, "capabl": [105, 110, 112], "self_attn": 105, "q_proj": 105, "k_proj": 105, "mlp": 105, "gate_proj": 105, "narrow": 105, "chunk": 105, "heavi": 105, "codebas": 105, "fn": 105, "ctx": 105, "new_tensor": 105, "__class__": 105, "principl": 105, "mynewquantconfig": 105, "classvar": 105, "myquantizedtensor": 105, "tensor_data_attr": 105, "tensor_attribut": 105, "attr": 105, "fill_default": 105, "notimplementederror": 105, "_my_quant_transform": 105, "my_quantization_funct": 105, "use_cutlass_kernel": 105, "my_cutlass_linear": 105, "use_triton_kernel": 105, "my_triton_linear": 105, "disappear": 105, "unless": 105, "extrem": 105, "sole": 105, "explicitli": [105, 114], "spooki": 105, "distanc": 105, "due": [105, 109, 114], "workaround": 105, "2338": 105, "detect": 105, "illustr": 105, "tutorials_python": 106, "zip": 106, "jupyt": [106, 108], "notebook": [106, 108], "tutorials_jupyt": 106, "galleri": [106, 108], "sphinx": [106, 108], "004": [107, 108], "total": [107, 108], "template_tutori": [107, 108], "click": 108, "firstnam": 108, "lastnam": 108, "prerequisit": [108, 110], "topic": 108, "rand": [108, 110, 111], "5698": 108, "0042": 108, "1902": 108, "6717": 108, "5275": 108, "8042": 108, "1532": 108, "6712": 108, "7165": 108, "0199": 108, "3523": 108, "0839": 108, "1433": 108, "3225": 108, "3489": 108, "practic": 108, "summar": 108, "takeawai": 108, "link1": 108, "link2": 108, "minut": 108, "ipynb": 108, "daniil": 109, "lyakhov": 109, "aamir": 109, "nazir": 109, "alexand": 109, "suslov": 109, "yamini": 109, "nimmagadda": 109, "kozlov": 109, "subject": [109, 111], "openvinoquant": 109, "unlock": 109, "placement": 109, "ux": [109, 110, 112], "torchdynamo": [109, 112, 113, 114], "eager": [109, 110, 111, 112, 113, 114], "mechan": [109, 112, 113], "torchvis": [109, 110, 111, 112, 113, 114], "resnet18": [109, 110, 111, 112, 113], "__dict__": [109, 110, 111, 112, 113], "dummi": [109, 112, 113], "traced_b": [109, 112, 113], "exported_model": [109, 110, 111, 112, 113], "preset": 109, "elu": 109, "prelu": 109, "gelu": 109, "quantizationpreset": 109, "bert": [109, 112], "modeltyp": 109, "ignored_scop": 109, "exclud": 109, "layer_1": 109, "layer_2": 109, "layer_3": 109, "ignoredscop": 109, "conv2d": [109, 110, 111, 112, 113, 114], "regex": 109, "layer_": 109, "subgraph": [109, 111], "node": [109, 111, 112, 113, 114], "target_devic": 109, "taken": 109, "account": 109, "cpu_spr": 109, "npu": 109, "targetdevic": 109, "fold": [109, 110, 112, 113], "batchnorm": [109, 110, 111, 112, 113], "preced": [109, 110, 112, 113], "prepared_model": [109, 110, 111, 112, 113], "fold_quant": 109, "finish": [109, 112], "comparison": 109, "smoothquant": 109, "biascorrect": 109, "discrep": 109, "calibration_load": 109, "dataload": [109, 110, 111], "transform_fn": 109, "data_item": 109, "calibration_dataset": 109, "smooth_quant": 109, "fast_bias_correct": 109, "deploy": [109, 112], "jerri": [110, 112, 114], "zhang": [110, 112, 113, 114], "_export": [110, 111], "fx": [110, 114], "14k": 110, "programm": [110, 112, 113], "db": 110, "xnnpack": [110, 111, 114], "xnnpack_quant": [110, 111], "get_symmetric_quantization_config": [110, 111], "xnnpackquant": [110, 111, 114], "prior": 110, "qconfigmap": [110, 114], "backendconfig": [110, 114], "rel": 110, "intent": [110, 114], "qconfig": [110, 114], "3d": [110, 114], "incompat": 110, "great": 110, "ideal": 110, "fake_qu": 110, "hidden": 110, "summari": 110, "address": 110, "thu": 110, "queri": [110, 114], "previous": 110, "embedding_byt": 110, "executorchquant": 110, "concaten": 110, "prone": 110, "cleaner": 110, "composed_quant": 110, "quantization_cap": 110, "concern": 110, "decoupl": 110, "minmax": 110, "freed": 110, "identitc": 110, "imagenet": [110, 111], "unzip": [110, 111], "data_path": [110, 111], "renam": [110, 111], "resnet18_pretrained_float": [110, 111], "sy": [110, 111], "numpi": [110, 111], "np": [110, 111], "resnet": [110, 111, 112], "warn": [110, 111], "filterwarn": [110, 111], "categori": [110, 111], "deprecationwarn": [110, 111], "r": [110, 111], "seed": [110, 111], "191009": [110, 111], "averagemet": [110, 111], "fmt": [110, 111], "val": [110, 111], "avg": [110, 111], "count": [110, 111], "__str__": [110, 111], "fmtstr": [110, 111], "topk": [110, 111], "predict": [110, 111], "maxk": [110, 111], "pred": [110, 111], "eq": [110, 111], "expand_a": [110, 111], "correct_k": [110, 111], "mul_": [110, 111], "criterion": [110, 111], "top1": [110, 111], "top5": [110, 111], "cnt": [110, 111], "acc1": [110, 111], "acc5": [110, 111], "load_model": [110, 111], "model_fil": [110, 111], "weights_onli": [110, 111], "print_size_of_model": [110, 111], "temp": [110, 111], "p": [110, 111], "1e6": [110, 111], "prepare_data_load": [110, 111], "485": [110, 111], "456": [110, 111], "std": [110, 111], "229": [110, 111], "225": [110, 111], "randomresizedcrop": [110, 111], "randomhorizontalflip": [110, 111], "totensor": [110, 111], "dataset_test": [110, 111], "resiz": [110, 111], "centercrop": [110, 111], "train_sampl": [110, 111], "randomsampl": [110, 111], "test_sampl": [110, 111], "sequentialsampl": [110, 111], "train_batch_s": [110, 111], "sampler": [110, 111], "data_loader_test": [110, 111, 112, 113], "eval_batch_s": [110, 111], "saved_model_dir": [110, 111], "float_model_fil": [110, 111], "model_to_quant": [110, 111], "capture_pre_autograd_graph": [110, 111], "dynamic_shap": [110, 111], "dynamic_dim": [110, 111], "constraint": [110, 111, 114], "qconfig_opt": 110, "set_object_typ": 110, "set_module_nam": 110, "workload": 110, "themodel": 110, "feedback": 110, "dq": 110, "fp32_op": 110, "qauntiz": 110, "x_int8": 110, "x_zero_point": 110, "weight_int8": 110, "bias_fp32": 110, "output_scal": 110, "output_zero_point": 110, "x_fp32": 110, "quantized_decompos": 110, "dequantize_per_tensor": 110, "x_i8": 110, "x_quant_min": 110, "x_quant_max": 110, "weight_fp32": 110, "weight_i8": 110, "weight_quant_min": 110, "weight_quant_max": 110, "weight_permut": 110, "permute_copi": 110, "out_fp32": 110, "addmm": 110, "out_i8": 110, "quantize_per_tensor": 110, "out_zero_point": 110, "out_quant_min": 110, "out_quant_max": 110, "float32_op": 110, "decompos": 110, "use_reference_represent": 110, "x_int16": 110, "weight_int16": 110, "acc_int32": 110, "out_dtyp": 110, "bias_scal": 110, "bias_int32": 110, "div": 110, "mul": 110, "out_int8": 110, "qmin": 110, "qmax": 110, "date": 110, "unus": 110, "serila": 110, "consult": 110, "exportedprogram": 110, "pt2e_quantized_model_file_path": 110, "resnet18_pt2e_quant": 110, "quantized_ep": 110, "loaded_quantized_ep": 110, "loaded_quantized_model": 110, "diff": 110, "79": 110, "82": 110, "55": 110, "edg": [110, 114], "went": 110, "andrew": 111, "Or": 111, "move_exported_model_to_ev": [111, 112], "correctli": 111, "certain": 111, "dropout": 111, "move_exported_model_to_train": 111, "jit": 111, "recursivescriptmodul": 111, "train_one_epoch": 111, "ntrain_batch": 111, "avgloss": 111, "5f": 111, "start_tim": 111, "global_avg": 111, "is_qat": [111, 112], "fusion": 111, "batchnorm2d": 111, "_native_batch_norm_legit": 111, "cudnn_batch_norm": 111, "mobilenetv2": 111, "manual": 111, "recompil": 111, "consolid": 111, "epoch": 111, "far": 111, "num_epoch": 111, "num_train_batch": 111, "num_eval_batch": 111, "num_observer_update_epoch": 111, "num_batch_norm_update_epoch": 111, "num_epochs_between_ev": 111, "nepoch": 111, "stat": 111, "subseq": 111, "disable_observ": 111, "bn": 111, "running_mean": 111, "running_var": 111, "new_arg": 111, "wish": 111, "prepared_model_copi": 111, "neval_batch": 111, "paus": 111, "resum": 111, "fail": [111, 114], "checkpoint_path": 111, "checkpoint_": 111, "behav": 111, "incorrectli": 111, "lesli": [112, 114], "fang": [112, 114], "weiwen": [112, 114], "xia": [112, 114], "jiong": [112, 114], "gong": [112, 114], "cnn": 112, "rnn": 112, "outstand": 112, "fourth": 112, "spr": 112, "xeon": 112, "processor": 112, "boost": 112, "channels_last": [112, 113], "onednn": [112, 113], "assum": [112, 114], "word": 112, "satur": 112, "pure": 112, "dedic": 112, "scenario": [112, 113], "plai": [112, 113], "convolut": [112, 113, 114], "absenc": [112, 113], "enhanc": [112, 113], "mirror": [112, 113], "autocast": [112, 113], "device_typ": [112, 113], "turn": [112, 113], "cpp": 112, "qconvolut": [112, 113], "qlinear": [112, 113], "presenc": [112, 113], "pair": [112, 113], "remain": [112, 113], "conting": [112, 113], "qmaxpool2d": [112, 113], "torchinductor_freez": [112, 113], "example_x86inductorquantizer_pytorch_2_1": 112, "torchbench": 112, "measur": 112, "proven": 112, "depth": 112, "example_x86inductorquantizer_qat": 112, "yan": 113, "zhiwei": 113, "wang": 113, "eikan": 113, "liangang": 113, "liu": 113, "river": 113, "cui": 113, "yifeng": 113, "xpuinductorquant": 113, "pip3": 113, "torchaudio": 113, "xpu_inductor_quantizer_exampl": 113, "xpu_inductor_quant": 113, "xpuiq": 113, "resnet18_weight": 113, "get_default_xpu_inductor_quantization_config": 113, "wherea": 113, "histogramobserv": [113, 114], "perchannelminmaxobserv": 113, "quantizationspec": [113, 114], "quantizationconfig": [113, 114], "type_check": 113, "observerorfakequantizeconstructor": 113, "get_xpu_inductor_symm_quantization_config": 113, "extra_arg": 113, "act_observer_or_fake_quant_ctr": 113, "act_quantization_spec": [113, 114], "qscheme": [113, 114], "per_tensor_symmetr": [113, 114], "observer_or_fake_quant_ctr": [113, 114], "with_arg": [113, 114], "weight_observer_or_fake_quant_ctr": 113, "weight_quantization_spec": [113, 114], "per_channel_symmetr": 113, "ch_axi": 113, "oc": 113, "ic": 113, "kh": 113, "kw": 113, "conv": [113, 114], "bias_quantization_spec": 113, "amp": 113, "indcutor": 113, "kimish": 114, "patel": 114, "made": 114, "explicit": 114, "quantiat": 114, "encod": 114, "convei": 114, "quantizationannot": 114, "furthermor": 114, "minmaxobserv": 114, "input_qspec_map": 114, "output_qspec": 114, "_annot": 114, "conclud": 114, "matcher": 114, "get_source_partit": 114, "add_partit": 114, "gm": 114, "itertool": 114, "chain": 114, "add_nod": 114, "output_nod": 114, "per_tensor_affin": 114, "input_act_qspec": 114, "output_act_qspec": 114, "input_act0": 114, "input_act1": 114, "quantization_annot": 114, "substitut": 114, "among": 114, "sharedquantizationspec": 114, "maxpool": 114, "average_pool": 114, "concat": 114, "whose": 114, "edgeornod": 114, "transit": 114, "spec": 114, "conv1": 114, "conv2": 114, "fed": 114, "conv1_out": 114, "conv2_out": 114, "qspec1": 114, "cat_input0": 114, "cat_input1": 114, "therefor": 114, "ob": 114, "consum": 114, "rewrit": 114, "share_qparams_with_input_act0_qspec": 114, "known": 114, "beforehand": 114, "sigmoid": 114, "fixedqparamsquantizationspec": 114, "act_qspec": 114, "sigmoid_nod": 114, "input_act": 114, "derivedquantizationspec": 114, "derive_qparams_fn": 114, "observerorfakequant": 114, "observerbas": 114, "fakequantizebas": 114, "heurist": 114, "obejct": 114, "obs_or_fq": 114, "fq": 114, "act_obs_or_fq": 114, "weight_obs_or_fq": 114, "act_zp": 114, "weight_zp": 114, "bias_qspec": 114, "derived_from": 114, "backendquant": 114, "get_input_act_qspec": 114, "get_output_act_qspec": 114, "get_weight_qspec": 114, "get_bias_qspec": 114, "intermedi": 114, "straightforward": 114, "call_funct": 114, "relu_": 114, "relu_nod": 114, "maybe_conv_nod": 114, "conv1d": 114, "unexpect": 114, "recognz": 114, "subgraphmatch": 114, "conv_relu_pattern": 114, "name_node_map": 114, "input_nod": 114, "weight_nod": 114, "bias_nod": 114, "caveat": 114, "exhaust": 114, "2d": 114, "4d": 114, "symbol": 114, "outcom": 114}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "MarlinSparseLayout"], [19, 0, 1, "", "NF4Tensor"], [20, 0, 1, "", "PlainLayout"], [21, 0, 1, "", "SemiSparseLayout"], [22, 0, 1, "", "TensorCoreTiledLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinSparseLayout": [[18, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[19, 1, 1, "", "convert_to_norm_float_weight"], [19, 1, 1, "", "dequantize"], [19, 1, 1, "", "dequantize_scalers"], [19, 1, 1, "", "double_quantize_scalers"], [19, 1, 1, "", "get_original_weight"], [19, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingGranularity"], [33, 0, 1, "", "ScalingType"], [34, 2, 1, "", "convert_to_float8_training"], [35, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[36, 0, 1, "", "BlockSparseLayout"], [37, 0, 1, "", "CutlassInt4PackedLayout"], [38, 0, 1, "", "FloatxTensorCoreLayout"], [39, 0, 1, "", "Int8DynamicActInt4WeightCPULayout"], [40, 0, 1, "", "MarlinQQQLayout"], [41, 0, 1, "", "MarlinQQQTensor"], [42, 0, 1, "", "UintxLayout"]], "torchao.prototype.dtypes.MarlinQQQTensor": [[41, 1, 1, "", "dequantize"], [41, 1, 1, "", "from_hp_to_intx"]], "torchao.quantization": [[43, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [44, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [45, 0, 1, "", "Float8WeightOnlyConfig"], [46, 0, 1, "", "Int4WeightOnlyConfig"], [47, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [48, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [49, 0, 1, "", "Int8WeightOnlyConfig"], [50, 0, 1, "", "MappingType"], [51, 0, 1, "", "TorchAODType"], [52, 2, 1, "", "choose_qparams_affine"], [53, 2, 1, "", "choose_qparams_affine_with_min_max"], [54, 2, 1, "", "dequantize_affine"], [55, 2, 1, "", "int_scaled_matmul"], [80, 2, 1, "", "quantize_"], [85, 2, 1, "", "quantize_affine"], [86, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[56, 0, 1, "", "ComposableQATQuantizer"], [57, 0, 1, "", "FakeQuantizeConfigBase"], [58, 0, 1, "", "FakeQuantizedEmbedding"], [59, 0, 1, "", "FakeQuantizedLinear"], [60, 0, 1, "", "FakeQuantizerBase"], [61, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [62, 0, 1, "", "Float8FakeQuantizeConfig"], [63, 0, 1, "", "Float8FakeQuantizer"], [64, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [65, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [66, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [67, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [68, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [69, 0, 1, "", "IntxFakeQuantizeConfig"], [70, 0, 1, "", "IntxFakeQuantizer"], [71, 0, 1, "", "QATConfig"], [72, 0, 1, "", "QATStep"], [75, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[58, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[59, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[61, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[63, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[65, 1, 1, "", "convert"], [65, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[69, 3, 1, "", "group_size"], [69, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[70, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[73, 0, 1, "", "Int4WeightOnlyEmbedding"], [74, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[73, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[76, 0, 1, "", "Int4WeightOnlyQATLinear"], [77, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [78, 2, 1, "", "disable_linear_fake_quant"], [79, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[81, 0, 1, "", "KernelPreference"], [82, 0, 1, "", "PackingFormat"], [83, 0, 1, "", "QuantizeTensorKwargs"], [84, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[81, 4, 1, "", "AUTO"], [81, 4, 1, "", "FBGEMM"], [81, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[82, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[87, 0, 1, "", "PerChannelNormObserver"], [88, 0, 1, "", "WandaSparsifier"], [89, 2, 1, "", "apply_fake_sparsity"], [90, 4, 1, "", "semi_sparse_weight"], [91, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[87, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[88, 1, 1, "", "prepare"], [88, 1, 1, "", "squash_mask"], [88, 1, 1, "", "update_mask"]], "torchao.utils": [[92, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[92, 1, 1, "", "get_tensor_impl_constructor"], [92, 1, 1, "", "implements"], [92, 1, 1, "", "implements_torch_function"], [92, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 93, 95, 96, 105], "dtype": [0, 11, 96], "layout": [0, 17], "tensor": [0, 7, 10, 96, 102, 103, 105, 114], "subclass": [0, 7, 10, 103, 105], "quantiz": [0, 4, 5, 7, 12, 80, 93, 96, 97, 99, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 95, 96], "main": [1, 4, 5], "train": [1, 12, 95, 96, 99, 109, 110, 111, 112, 113], "api": [1, 2, 4, 5, 7, 8, 12, 93, 95, 114], "other": [1, 10, 96], "type": [1, 104], "refer": [2, 93], "python": 2, "kernel": [3, 10, 94, 96, 105], "qat": [4, 12, 111], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 99], "primit": [5, 96], "sparsiti": [6, 100], "util": 7, "common": [7, 8, 114], "benchmark": [8, 9, 10, 99], "guid": [8, 9, 10, 97, 105], "add": [8, 105], "an": [8, 98], "recip": [8, 95], "model": [8, 10, 95, 96, 98, 99, 104, 105, 109, 110, 111], "design": [8, 100], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 95, 99, 104, 105, 109, 112, 113, 114], "modifi": 8, "exist": 8, "configur": [8, 100, 105, 110, 111], "2": [8, 12, 97, 99, 104, 105, 109, 110, 111, 112, 113, 114], "run": 8, "3": [8, 12, 99, 105, 109, 112, 113, 114], "output": [8, 103], "format": [8, 96], "4": [8, 109, 114], "integr": [8, 12, 104, 105], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 105], "new": [10, 105], "effici": [10, 96], "triton": 10, "hand": 10, "written": 10, "us": [10, 114], "kernelprefer": [10, 81], "flow": [10, 96, 98, 105, 114], "torch": [10, 109, 110, 111], "compil": [10, 105, 109], "perform": [10, 94, 99, 110], "serial": [10, 98, 105], "featur": 10, "support": [10, 104, 105], "function": [10, 110, 111], "compos": 10, "microbenchmark": 10, "eval": [10, 110], "part": [12, 95, 99], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 96, 111, 112], "option": [12, 99, 108, 109], "torchtun": 12, "axolotl": 12, "low": [12, 96], "rank": 12, "adapt": 12, "huggingfac": [12, 99, 105], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "marlinsparselayout": 18, "nf4tensor": 19, "plainlayout": 20, "semisparselayout": 21, "tensorcoretiledlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalinggranular": 32, "scalingtyp": 33, "convert_to_float8_train": 34, "precompute_float8_dynamic_scale_for_fsdp": 35, "blocksparselayout": 36, "cutlassint4packedlayout": 37, "floatxtensorcorelayout": 38, "int8dynamicactint4weightcpulayout": 39, "marlinqqqlayout": 40, "marlinqqqtensor": 41, "uintxlayout": 42, "float8dynamicactivationfloat8weightconfig": 43, "float8dynamicactivationint4weightconfig": 44, "float8weightonlyconfig": 45, "int4weightonlyconfig": 46, "int8dynamicactivationint4weightconfig": 47, "int8dynamicactivationint8weightconfig": 48, "int8weightonlyconfig": 49, "mappingtyp": 50, "torchaodtyp": 51, "choose_qparams_affin": 52, "choose_qparams_affine_with_min_max": 53, "dequantize_affin": 54, "int_scaled_matmul": 55, "composableqatquant": 56, "fakequantizeconfigbas": 57, "fakequantizedembed": 58, "fakequantizedlinear": 59, "fakequantizerbas": 60, "float8actint4weightqatquant": 61, "float8fakequantizeconfig": 62, "float8fakequant": 63, "fromintxquantizationawaretrainingconfig": 64, "int4weightonlyembeddingqatquant": 65, "int4weightonlyqatquant": 66, "int8dynactint4weightqatquant": 67, "intxquantizationawaretrainingconfig": 68, "intxfakequantizeconfig": 69, "intxfakequant": 70, "qatconfig": 71, "qatstep": 72, "int4weightonlyembed": 73, "int4weightonlyqatembed": 74, "initialize_fake_quant": 75, "int4weightonlyqatlinear": 76, "int8dynactint4weightqatlinear": 77, "disable_linear_fake_qu": 78, "enable_linear_fake_qu": 79, "packingformat": 82, "quantizetensorkwarg": 83, "_choose_quant_func_and_quantize_tensor": 84, "quantize_affin": 85, "safe_int_mm": 86, "perchannelnormobserv": 87, "wandasparsifi": 88, "apply_fake_spars": 89, "semi_sparse_weight": 90, "sparsifi": 91, "torchaobasetensor": 92, "welcom": 93, "document": 93, "get": 93, "start": [93, 97, 104], "develop": 93, "note": [93, 95, 114], "eager": 93, "tutori": [93, 108], "pt2e": [93, 114], "pre": 95, "torchtitan": 95, "prerequisit": [95, 109, 112, 113, 114], "rowwis": 95, "scale": 95, "tensorwis": 95, "pick": 95, "import": [95, 110, 111], "directli": [95, 114], "convers": 95, "overview": [96, 100, 108], "basic": 96, "op": 96, "deriv": [96, 114], "pack": 96, "algorithm": 96, "weight": [96, 99], "onli": 96, "dynam": 96, "activ": 96, "static": [96, 101], "bit": 96, "optim": [96, 98, 99], "case": 96, "studi": 96, "how": [96, 110, 111, 114], "work": 96, "dure": 96, "execut": 96, "save": [96, 104, 110, 111], "load": [96, 110, 111], "quick": [97, 104], "first": 97, "exampl": [97, 104, 105, 114], "pytorch": [97, 109, 110, 111, 112, 113, 114], "export": [97, 99, 109, 110, 111, 112, 113, 114], "next": [97, 103], "step": [97, 99, 103, 105, 108], "deseri": 98, "what": [98, 103], "happen": 98, "when": 98, "serv": [99, 105], "vllm": [99, 105], "sglang": 99, "executorch": 99, "post": [99, 109, 110, 112, 113], "transform": [99, 104, 105], "mobil": 99, "deploy": 99, "unti": 99, "embed": 99, "creat": [99, 105], "characterist": 99, "evalu": [99, 110], "qualiti": 99, "assess": 99, "memori": 99, "latenc": 99, "result": 99, "h100": 99, "machin": 99, "conclus": [99, 108, 109, 110, 111, 112, 113, 114], "goal": 100, "context": 100, "prune": 100, "criteria": 100, "strategi": 100, "pattern": [100, 114], "calibr": [101, 110], "phase": 101, "write": [102, 103, 114], "your": [102, 103, 105], "own": [102, 103], "advanc": 102, "ar": 103, "modul": 103, "swap": 103, "which": 103, "oper": [103, 105, 114], "should": 103, "we": 103, "implement": [103, 105], "compar": 103, "hug": 104, "face": 104, "usag": [104, 105], "diffus": 104, "architectur": 105, "system": 105, "class": 105, "fqn": 105, "method": 105, "minim": 105, "requir": 105, "compat": 105, "why": 105, "regist": 105, "": 105, "kei": 105, "detail": 105, "hardwar": 105, "specif": [105, 110, 111], "linear": 105, "benefit": 105, "trade": 105, "off": 105, "share": [105, 114], "safetensor": 105, "diagram": 105, "high": 105, "level": 105, "point": 105, "dispatch": 105, "bring": 105, "extern": 105, "comput": 107, "time": 107, "templat": 108, "addit": 108, "exercis": 108, "further": 108, "read": 108, "openvino": 109, "backend": [109, 110, 111, 112, 113], "introduct": [109, 112, 113, 114], "nncf": 109, "instal": 109, "captur": [109, 112, 113], "fx": [109, 112, 113], "graph": [109, 112, 113], "appli": [109, 112, 113], "lower": [109, 110, 112, 113], "represent": 109, "improv": 109, "metric": 109, "motiv": [110, 114], "defin": [110, 111], "helper": [110, 111], "prepar": [110, 111], "dataset": [110, 111], "set": 110, "mode": 110, "convert": [110, 111], "check": 110, "size": 110, "accuraci": 110, "debug": 110, "loop": 111, "checkpoint": 111, "x86": 112, "through": [112, 113], "inductor": [112, 113], "intel": 113, "gpu": 113, "annot": 114, "param": 114, "fix": 114, "paramet": 114, "5": 114, "A": 114, "toi": 114, "resnet18": 114, "ir": 114, "problem": 114, "match": 114, "aten": 114, "recommend": 114, "subgraphmatcherwithnamenodemap": 114}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.dtypes": [[0, "torchao-dtypes"]], "Layouts and Tensor Subclasses": [[0, "layouts-and-tensor-subclasses"]], "Quantization techniques": [[0, "quantization-techniques"]], "Prototype": [[0, "prototype"], [4, "prototype"]], "torchao.float8": [[1, "torchao-float8"]], "Main float8 training APIs": [[1, "main-float8-training-apis"]], "Other float8 training types": [[1, "other-float8-training-types"]], "torchao API Reference": [[2, "torchao-api-reference"]], "Python API Reference": [[2, null]], "torchao.kernel": [[3, "torchao-kernel"]], "torchao.quantization.qat": [[4, "torchao-quantization-qat"]], "Main Config for quantize_": [[4, "main-config-for-quantize"]], "Custom QAT APIs": [[4, "custom-qat-apis"]], "Legacy QAT APIs": [[4, "legacy-qat-apis"]], "torchao.quantization": [[5, "torchao-quantization"]], "Main Quantization APIs": [[5, "main-quantization-apis"]], "Inference APIs for quantize_": [[5, "inference-apis-for-quantize"]], "Quantization Primitives": [[5, "quantization-primitives"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "torchao.utils": [[7, "torchao-utils"]], "Tensor Subclass Utils": [[7, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[7, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[7, "quantize-api-common-utils"]], "Benchmarking API Guide": [[8, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[8, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[8, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[8, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[8, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[8, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[8, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[8, "run-ci-benchmarks"]], "3. CI Output Format": [[8, "ci-output-format"]], "4. Integration with CI Pipeline": [[8, "integration-with-ci-pipeline"]], "Troubleshooting": [[8, "troubleshooting"]], "Running Tests": [[8, "running-tests"]], "Common Issues": [[8, "common-issues"]], "Best Practices": [[8, "best-practices"]], "Benchmarking User Guide": [[9, "benchmarking-user-guide"]], "Contributor Guide": [[10, "contributor-guide"]], "General Guide on Extending torchao": [[10, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[10, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[10, "adding-efficient-kernels"]], "Custom triton kernels": [[10, "custom-triton-kernels"]], "Custom hand written kernels": [[10, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[10, "using-hand-written-kernels-in-tensor-subclasses"]], "KernelPreference": [[10, "kernelpreference"], [81, "kernelpreference"]], "Flow": [[10, "flow"]], "Using torch.compile for Performance": [[10, "using-torch-compile-for-performance"]], "Serialization": [[10, "serialization"], [98, "serialization"]], "Other Feature Support": [[10, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[10, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[10, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[10, "model-benchmarks-and-eval"]], "Dtypes": [[11, "dtypes"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[12, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[12, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[12, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[12, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[12, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[12, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[12, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[12, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[12, "float8-quantized-fine-tuning"]], "AffineQuantizedTensor": [[13, "affinequantizedtensor"]], "CutlassSemiSparseLayout": [[14, "cutlasssemisparselayout"]], "Float8Layout": [[15, "float8layout"]], "Int4CPULayout": [[16, "int4cpulayout"]], "Layout": [[17, "layout"]], "MarlinSparseLayout": [[18, "marlinsparselayout"]], "NF4Tensor": [[19, "nf4tensor"]], "PlainLayout": [[20, "plainlayout"]], "SemiSparseLayout": [[21, "semisparselayout"]], "TensorCoreTiledLayout": [[22, "tensorcoretiledlayout"]], "to_affine_quantized_floatx": [[23, "to-affine-quantized-floatx"]], "to_affine_quantized_floatx_static": [[24, "to-affine-quantized-floatx-static"]], "to_affine_quantized_fpx": [[25, "to-affine-quantized-fpx"]], "to_affine_quantized_intx": [[26, "to-affine-quantized-intx"]], "to_affine_quantized_intx_static": [[27, "to-affine-quantized-intx-static"]], "to_marlinqqq_quantized_intx": [[28, "to-marlinqqq-quantized-intx"]], "to_nf4": [[29, "to-nf4"]], "CastConfig": [[30, "castconfig"]], "Float8LinearConfig": [[31, "float8linearconfig"]], "ScalingGranularity": [[32, "scalinggranularity"]], "ScalingType": [[33, "scalingtype"]], "convert_to_float8_training": [[34, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[35, "precompute-float8-dynamic-scale-for-fsdp"]], "BlockSparseLayout": [[36, "blocksparselayout"]], "CutlassInt4PackedLayout": [[37, "cutlassint4packedlayout"]], "FloatxTensorCoreLayout": [[38, "floatxtensorcorelayout"]], "Int8DynamicActInt4WeightCPULayout": [[39, "int8dynamicactint4weightcpulayout"]], "MarlinQQQLayout": [[40, "marlinqqqlayout"]], "MarlinQQQTensor": [[41, "marlinqqqtensor"]], "UintxLayout": [[42, "uintxlayout"]], "Float8DynamicActivationFloat8WeightConfig": [[43, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[44, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[45, "float8weightonlyconfig"]], "Int4WeightOnlyConfig": [[46, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[47, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[48, "int8dynamicactivationint8weightconfig"]], "Int8WeightOnlyConfig": [[49, "int8weightonlyconfig"]], "MappingType": [[50, "mappingtype"]], "TorchAODType": [[51, "torchaodtype"]], "choose_qparams_affine": [[52, "choose-qparams-affine"]], "choose_qparams_affine_with_min_max": [[53, "choose-qparams-affine-with-min-max"]], "dequantize_affine": [[54, "dequantize-affine"]], "int_scaled_matmul": [[55, "int-scaled-matmul"]], "ComposableQATQuantizer": [[56, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[57, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[58, "fakequantizedembedding"]], "FakeQuantizedLinear": [[59, "fakequantizedlinear"]], "FakeQuantizerBase": [[60, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[61, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[62, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[63, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[64, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[65, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[66, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[67, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[68, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[69, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[70, "intxfakequantizer"]], "QATConfig": [[71, "qatconfig"]], "QATStep": [[72, "qatstep"]], "Int4WeightOnlyEmbedding": [[73, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[74, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[75, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[76, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[77, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[78, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[79, "enable-linear-fake-quant"]], "quantize": [[80, "quantize"]], "PackingFormat": [[82, "packingformat"]], "QuantizeTensorKwargs": [[83, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[84, "choose-quant-func-and-quantize-tensor"]], "quantize_affine": [[85, "quantize-affine"]], "safe_int_mm": [[86, "safe-int-mm"]], "PerChannelNormObserver": [[87, "perchannelnormobserver"]], "WandaSparsifier": [[88, "wandasparsifier"]], "apply_fake_sparsity": [[89, "apply-fake-sparsity"]], "semi_sparse_weight": [[90, "semi-sparse-weight"]], "sparsify": [[91, "sparsify"]], "TorchAOBaseTensor": [[92, "torchaobasetensor"]], "Welcome to the torchao Documentation": [[93, "welcome-to-the-torchao-documentation"]], "Getting Started": [[93, null]], "Developer Notes": [[93, null]], "API Reference": [[93, null]], "Eager Quantization Tutorials": [[93, null]], "PT2E Quantization Tutorials": [[93, null]], "Performant Kernels": [[94, "performant-kernels"]], "(Part 1) Pre-training with float8": [[95, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[95, "pre-training-with-torchtitan"]], "Prerequisites": [[95, "prerequisites"], [95, "id1"], [109, "prerequisites"], [112, "prerequisites"], [113, "prerequisites"]], "Rowwise scaling": [[95, "rowwise-scaling"]], "Tensorwise scaling": [[95, "tensorwise-scaling"]], "Picking a recipe": [[95, "picking-a-recipe"]], "Important notes": [[95, "important-notes"]], "Pre-training with torchao directly": [[95, "pre-training-with-torchao-directly"]], "Model conversion API": [[95, "model-conversion-api"]], "Quantization Overview": [[96, "quantization-overview"]], "Basic DTypes": [[96, "basic-dtypes"]], "Quantization Primitive Ops": [[96, "quantization-primitive-ops"]], "Efficient kernels": [[96, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[96, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[96, "quantization-algorithms-flows"]], "Weight Only Quantization": [[96, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[96, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[96, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[96, "other-quantization-flows"]], "Training": [[96, "training"]], "Quantization Aware Training": [[96, "quantization-aware-training"], [112, "quantization-aware-training"]], "Low Bit Optimizers": [[96, "low-bit-optimizers"]], "Quantized Training": [[96, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[96, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[96, "during-quantization"]], "During Model Execution": [[96, "during-model-execution"]], "During Save/Load": [[96, "during-save-load"]], "Quick Start Guide": [[97, "quick-start-guide"]], "First Quantization Example": [[97, "first-quantization-example"]], "PyTorch 2 Export Quantization": [[97, "pytorch-2-export-quantization"]], "Next Steps": [[97, "next-steps"], [103, "next-steps"]], "Serialization and deserialization flow": [[98, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[98, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[98, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[99, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[99, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[99, "serving-and-inference"]], "Serving and Inference with vLLM": [[99, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[99, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[99, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[99, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[99, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[99, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[99, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[99, "mobile-performance-characteristics"]], "Evaluation": [[99, "evaluation"]], "Model Quality Assessment": [[99, "model-quality-assessment"]], "Memory Benchmarking": [[99, "memory-benchmarking"]], "Performance Benchmarking": [[99, "performance-benchmarking"]], "Latency Benchmarking": [[99, "latency-benchmarking"]], "Serving Benchmarking": [[99, "serving-benchmarking"]], "Results (H100 machine)": [[99, "results-h100-machine"]], "Conclusion": [[99, "conclusion"], [108, "conclusion"], [109, "conclusion"], [110, "conclusion"], [111, "conclusion"], [112, "conclusion"], [113, "conclusion"], [114, "conclusion"]], "Sparsity Overview": [[100, "sparsity-overview"]], "Goal": [[100, "goal"]], "Design": [[100, "design"]], "Context": [[100, "context"]], "Pruning Configuration": [[100, "pruning-configuration"]], "Pruning Criteria": [[100, "pruning-criteria"]], "Pruning Strategy": [[100, "pruning-strategy"]], "Sparsity Pattern": [[100, "sparsity-pattern"]], "Static Quantization": [[101, "static-quantization"]], "Calibration Phase": [[101, "calibration-phase"]], "Quantization Phase": [[101, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[102, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[103, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[103, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[103, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[103, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[103, "which-operators-should-we-implement"]], "Comparing the Outputs": [[103, "comparing-the-outputs"]], "Hugging Face Integration": [[104, "hugging-face-integration"]], "Quick Start: Usage Example": [[104, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[104, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[104, "quantizing-models-with-diffusers"]], "Saving the Model": [[104, "saving-the-model"]], "Supported Quantization Types": [[104, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[105, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[105, "configuration-system"]], "1. HuggingFace Model Configuration": [[105, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[105, "torchao-configuration-classes"]], "3. FQN Configuration": [[105, "fqn-configuration"]], "Usage Examples": [[105, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[105, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[105, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[105, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[105, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[105, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[105, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[105, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[105, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[105, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[105, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[105, "hardware-specific-linear-operations"]], "Compilation Benefits": [[105, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[105, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[105, "serialization-and-model-sharing"]], "SafeTensors Support": [[105, "safetensors-support"]], "Integration Architecture Diagrams": [[105, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[105, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[105, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[105, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Computation times": [[107, "computation-times"]], "Template Tutorial": [[108, "template-tutorial"]], "Overview": [[108, "overview"]], "Steps": [[108, "steps"]], "(Optional) Additional Exercises": [[108, "optional-additional-exercises"]], "Further Reading": [[108, "further-reading"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[109, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[109, "introduction"], [112, "introduction"], [113, "introduction"], [114, "introduction"]], "Post Training Quantization": [[109, "post-training-quantization"], [112, "post-training-quantization"], [113, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[109, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[109, "capture-fx-graph"], [112, "capture-fx-graph"], [113, "capture-fx-graph"]], "2. Apply Quantization": [[109, "apply-quantization"], [112, "apply-quantization"], [113, "apply-quantization"]], "3. Lower into OpenVINO representation": [[109, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[109, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[110, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[110, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[110, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[110, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[110, "export-the-model-with-torch-export"], [111, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[110, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [111, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[110, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[110, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[110, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[110, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[110, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[110, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[110, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[111, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[111, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[111, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[111, "training-loop"]], "Saving and Loading Model Checkpoints": [[111, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[111, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[112, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[112, "lower-into-inductor"], [113, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[113, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[114, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[114, "prerequisites"]], "Annotation API": [[114, "annotation-api"]], "1. Annotate Common Operator Patterns": [[114, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[114, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[114, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[114, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[114, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[114, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[114, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[114, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]]}, "indexentries": {"module": [[6, "module-torchao.sparsity"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "affinequantizedtensor (class in torchao.dtypes)": [[13, "torchao.dtypes.AffineQuantizedTensor"]], "dequantize() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.dequantize"]], "from_hp_to_floatx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx"]], "from_hp_to_floatx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx_static"]], "from_hp_to_fpx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_fpx"]], "from_hp_to_intx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx"]], "from_hp_to_intx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx_static"]], "to() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.to"]], "cutlasssemisparselayout (class in torchao.dtypes)": [[14, "torchao.dtypes.CutlassSemiSparseLayout"]], "float8layout (class in torchao.dtypes)": [[15, "torchao.dtypes.Float8Layout"]], "int4cpulayout (class in torchao.dtypes)": [[16, "torchao.dtypes.Int4CPULayout"]], "layout (class in torchao.dtypes)": [[17, "torchao.dtypes.Layout"]], "marlinsparselayout (class in torchao.dtypes)": [[18, "torchao.dtypes.MarlinSparseLayout"]], "pre_process() (torchao.dtypes.marlinsparselayout method)": [[18, "torchao.dtypes.MarlinSparseLayout.pre_process"]], "nf4tensor (class in torchao.dtypes)": [[19, "torchao.dtypes.NF4Tensor"]], "convert_to_norm_float_weight() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.convert_to_norm_float_weight"]], "dequantize() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.dequantize"]], "dequantize_scalers() (torchao.dtypes.nf4tensor method)": [[19, "torchao.dtypes.NF4Tensor.dequantize_scalers"]], "double_quantize_scalers() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.double_quantize_scalers"]], "get_original_weight() (torchao.dtypes.nf4tensor method)": [[19, "torchao.dtypes.NF4Tensor.get_original_weight"]], "quantize_tensor_nearest() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.quantize_tensor_nearest"]], "plainlayout (class in torchao.dtypes)": [[20, "torchao.dtypes.PlainLayout"]], "semisparselayout (class in torchao.dtypes)": [[21, "torchao.dtypes.SemiSparseLayout"]], "tensorcoretiledlayout (class in torchao.dtypes)": [[22, "torchao.dtypes.TensorCoreTiledLayout"]], "to_affine_quantized_floatx() (in module torchao.dtypes)": [[23, "torchao.dtypes.to_affine_quantized_floatx"]], "to_affine_quantized_floatx_static() (in module torchao.dtypes)": [[24, "torchao.dtypes.to_affine_quantized_floatx_static"]], "to_affine_quantized_fpx() (in module torchao.dtypes)": [[25, "torchao.dtypes.to_affine_quantized_fpx"]], "to_affine_quantized_intx() (in module torchao.dtypes)": [[26, "torchao.dtypes.to_affine_quantized_intx"]], "to_affine_quantized_intx_static() (in module torchao.dtypes)": [[27, "torchao.dtypes.to_affine_quantized_intx_static"]], "to_marlinqqq_quantized_intx() (in module torchao.dtypes)": [[28, "torchao.dtypes.to_marlinqqq_quantized_intx"]], "to_nf4() (in module torchao.dtypes)": [[29, "torchao.dtypes.to_nf4"]], "castconfig (class in torchao.float8)": [[30, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[31, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[31, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[32, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[33, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[34, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[35, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "blocksparselayout (class in torchao.prototype.dtypes)": [[36, "torchao.prototype.dtypes.BlockSparseLayout"]], "cutlassint4packedlayout (class in torchao.prototype.dtypes)": [[37, "torchao.prototype.dtypes.CutlassInt4PackedLayout"]], "floatxtensorcorelayout (class in torchao.prototype.dtypes)": [[38, "torchao.prototype.dtypes.FloatxTensorCoreLayout"]], "int8dynamicactint4weightcpulayout (class in torchao.prototype.dtypes)": [[39, "torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout"]], "marlinqqqlayout (class in torchao.prototype.dtypes)": [[40, "torchao.prototype.dtypes.MarlinQQQLayout"]], "marlinqqqtensor (class in torchao.prototype.dtypes)": [[41, "torchao.prototype.dtypes.MarlinQQQTensor"]], "dequantize() (torchao.prototype.dtypes.marlinqqqtensor method)": [[41, "torchao.prototype.dtypes.MarlinQQQTensor.dequantize"]], "from_hp_to_intx() (torchao.prototype.dtypes.marlinqqqtensor class method)": [[41, "torchao.prototype.dtypes.MarlinQQQTensor.from_hp_to_intx"]], "uintxlayout (class in torchao.prototype.dtypes)": [[42, "torchao.prototype.dtypes.UintxLayout"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[43, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[44, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[45, "torchao.quantization.Float8WeightOnlyConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[46, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[47, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[48, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[49, "torchao.quantization.Int8WeightOnlyConfig"]], "mappingtype (class in torchao.quantization)": [[50, "torchao.quantization.MappingType"]], "torchaodtype (class in torchao.quantization)": [[51, "torchao.quantization.TorchAODType"]], "choose_qparams_affine() (in module torchao.quantization)": [[52, "torchao.quantization.choose_qparams_affine"]], "choose_qparams_affine_with_min_max() (in module torchao.quantization)": [[53, "torchao.quantization.choose_qparams_affine_with_min_max"]], "dequantize_affine() (in module torchao.quantization)": [[54, "torchao.quantization.dequantize_affine"]], "int_scaled_matmul() (in module torchao.quantization)": [[55, "torchao.quantization.int_scaled_matmul"]], "composableqatquantizer (class in torchao.quantization.qat)": [[56, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[57, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[58, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[58, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[59, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[59, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[60, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[61, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[61, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[62, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[63, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[63, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[64, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[65, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[65, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[65, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[66, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[67, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[68, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[69, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[69, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[69, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[70, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[70, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[71, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[72, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[73, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[73, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[74, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[75, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[76, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[77, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[78, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[79, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[80, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[81, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "fbgemm (torchao.quantization.quantize_.common.kernelpreference attribute)": [[81, "torchao.quantization.quantize_.common.KernelPreference.FBGEMM"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[81, "torchao.quantization.quantize_.common.KernelPreference"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[81, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[82, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[82, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[83, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[84, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "quantize_affine() (in module torchao.quantization)": [[85, "torchao.quantization.quantize_affine"]], "safe_int_mm() (in module torchao.quantization)": [[86, "torchao.quantization.safe_int_mm"]], "perchannelnormobserver (class in torchao.sparsity)": [[87, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[87, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[88, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[88, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[88, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[88, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[89, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[90, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[91, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[92, "torchao.utils.TorchAOBaseTensor"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[92, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[92, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[92, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[92, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})