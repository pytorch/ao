Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfig", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "subclass_advanced", "subclass_basic", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "subclass_advanced.rst", "subclass_basic.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfig", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "initialize_fake_quantizers", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "int8_dynamic_activation_int8_semi_sparse_weight", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Pretraining with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [2, 6, 8, 17, 18, 19, 20, 22, 34, 35, 39, 40, 41, 44, 48, 49, 51, 53, 55, 56, 59, 60, 66, 67, 73, 74, 75, 78, 81, 82, 83, 84, 86, 88, 91], "section": [2, 6, 82, 86], "introduc": 2, "dive": 2, "detail": [2, 6, 35, 48, 81, 82, 83, 86, 88], "how": [2, 6, 8, 14, 22, 40, 44, 49, 59, 60, 67, 81, 83, 84, 86, 88], "integr": [2, 6, 81, 84, 86, 88], "pytorch": [2, 6, 8, 13, 16, 45, 59, 79, 81, 83, 86, 88, 91], "optim": [2, 6, 17, 34, 48, 52, 66, 79, 81, 86, 88], "your": [2, 6, 79, 81, 82, 83, 86], "machin": 2, "learn": [2, 40, 59, 83, 86, 91], "model": [2, 34, 39, 41, 48, 58, 60, 61, 62, 63, 65, 66, 70, 71, 74, 75, 78, 83, 86, 88], "dtype": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 35, 36, 37, 38, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 59, 61, 62, 63, 67, 78, 79, 81, 83, 84, 88], "quantiz": [2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 26, 28, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 76, 78, 79, 81, 84, 86], "sparsiti": [2, 11, 17, 20, 73, 74, 75, 76, 77, 78, 79, 82, 84], "tba": [3, 7, 80], "For": [6, 8, 35, 59, 82, 83, 84, 86, 88], "new": [6, 8, 81, 82, 88], "case": [6, 48, 69, 86, 88], "exampl": [6, 8, 34, 44, 48, 58, 59, 60, 65, 66, 74, 78, 82, 84, 85, 86, 88, 89, 90, 91], "train": [6, 31, 55, 56, 58, 59, 79, 81, 86, 88], "like": [6, 14, 48, 81, 82, 83, 84, 86, 88], "fp4": 6, "s": [6, 8, 44, 48, 49, 53, 55, 67, 68, 81, 82, 83, 86, 88], "fine": [6, 39, 40, 41, 46, 86], "start": [6, 32, 44, 45, 47, 48, 81, 82, 86, 88], "prototyp": [6, 59, 65, 82], "folder": 6, "you": [6, 59, 74, 81, 82, 83, 84, 86, 88, 91], "could": [6, 82, 88], "also": [6, 48, 59, 66, 82, 83, 84, 86, 88], "take": [6, 18, 66, 73, 78, 82, 86], "look": [6, 8, 81, 82, 86], "affinequantizedtensor": [6, 16, 24, 25, 27, 82, 83, 84, 88], "what": [6, 8, 16, 48, 81, 82, 83, 86, 91], "want": [6, 66, 78, 82, 84, 86, 88], "do": [6, 45, 48, 57, 66, 82, 86, 88], "mostli": [6, 51], "e": [6, 8, 35, 44, 48, 49, 53, 55, 58, 59, 66, 67, 68, 81, 82, 84, 88], "g": [6, 8, 35, 44, 48, 49, 53, 55, 58, 59, 66, 67, 82, 84, 88], "int3": 6, "exact": 6, "same": [6, 8, 36, 49, 51, 53, 55, 56, 67, 69, 78, 81, 82, 86, 88], "affin": [6, 8, 10, 11, 12, 13, 17, 20, 21, 26, 53, 55, 67, 82], "pleas": [6, 8, 16, 35, 40, 79, 82, 86, 88], "feel": [6, 82, 86, 88], "free": [6, 82, 88], "open": [6, 82, 86], "an": [6, 8, 21, 26, 27, 48, 56, 59, 74, 79, 82, 86, 88], "issu": [6, 82, 83, 88], "have": [6, 39, 40, 44, 48, 61, 62, 63, 67, 74, 82, 86, 88], "question": [6, 82, 84, 86, 88], "specif": [6, 14, 17, 19, 20, 74, 82, 83, 84, 86], "more": [6, 8, 35, 39, 40, 41, 46, 48, 56, 81, 82, 83, 86, 88], "refer": [6, 8, 81, 86, 88], "our": [6, 18, 81, 83, 86, 88], "overview": [6, 79, 83], "page": [6, 83], "To": [6, 8, 16, 48, 81, 82, 83, 84, 86], "contribut": [6, 83, 86], "exist": [6, 45, 81, 82, 86, 88], "code": [6, 40, 81, 82, 83, 86, 88, 89, 91], "base": [6, 14, 19, 44, 65, 74, 82, 83, 86, 88], "make": [6, 82, 88], "trainabl": [6, 82, 88], "add": [6, 19, 88, 91], "parallel": [6, 81, 88], "etc": [6, 82], "affine_quantized_tensor": [6, 84], "py": [6, 8, 16, 85, 90, 91], "api": [6, 48, 64, 82, 83, 86, 88], "quant_api": [6, 66, 84], "primit": [6, 8, 16, 88], "op": [6, 8, 16, 40, 48, 55, 56, 66, 86, 88], "slight": [6, 86], "variat": [6, 82], "quant_primit": [6, 8, 16], "autotun": [6, 83], "cpu": [6, 8, 13, 84, 86], "cuda": [6, 8, 52, 66, 81, 83, 84, 86, 88], "mp": 6, "csrc": 6, "mayb": [6, 30], "well": [6, 14, 48, 82, 86], "spars": [6, 9, 17, 20, 74, 82, 86], "marlin": [6, 15, 16, 17, 28], "aqt": 6, "621": 6, "we": [6, 8, 18, 44, 46, 48, 49, 51, 53, 55, 59, 66, 67, 78, 81, 82, 83, 84, 86], "ar": [6, 8, 12, 20, 22, 33, 35, 36, 40, 48, 49, 53, 55, 58, 66, 67, 69, 74, 81, 82, 83, 84, 86], "still": [6, 82, 86], "decid": [6, 82, 86], "split": 6, "can": [6, 21, 36, 39, 44, 48, 58, 59, 66, 67, 81, 82, 83, 84, 86, 88], "implement": [6, 31, 84, 86], "regist": [6, 73, 88], "mai": [6, 51, 59, 82, 84], "need": [6, 36, 73, 74, 82, 83, 84, 86, 88], "defin": [6, 14, 22, 35, 73, 74, 86, 88], "own": [6, 79, 81, 86], "through": [6, 51, 82, 83, 88, 91], "int4": [6, 10, 13, 41, 44, 59, 61, 62, 63, 66, 78, 83, 84], "access": 6, "my_custom_op": 6, "devic": [6, 8, 52, 66, 69, 81, 83, 84, 88], "check": [6, 8, 16, 82, 83, 84, 88], "condit": [6, 82], "__torch_function__": [6, 82, 88], "__torch_dispatch__": [6, 88], "target": [6, 36, 37, 38, 40, 49, 74, 86], "oper": [6, 8, 12, 14, 17, 51], "bfloat16": [6, 18, 55, 62, 67, 81, 82, 83, 84, 86], "activ": [6, 36, 37, 41, 42, 48, 59, 63, 70, 74, 76, 79, 86], "uint4": [6, 40, 82, 83], "weight": [6, 17, 18, 34, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 59, 61, 62, 63, 66, 74, 76, 78, 79, 81, 83, 84, 86, 88], "found": [6, 82, 83, 86, 88], "here": [6, 8, 67, 82, 84, 88], "allow": [6, 86, 88], "peopl": [6, 82, 84], "linear": [6, 17, 31, 33, 36, 38, 40, 41, 42, 43, 46, 48, 58, 62, 63, 66, 71, 75, 76, 78, 81, 82, 83, 84, 86, 88], "two": [6, 16, 20, 36, 82, 86, 88], "dispatch_condit": [6, 82], "impl": [6, 8, 82], "actual": [6, 38, 82, 88], "bia": [6, 82, 83, 84, 88], "run": [6, 34, 48, 66, 70, 73, 81, 82, 86, 88, 91], "both": [6, 8, 36, 82, 86, 88], "input_tensor": [6, 18, 82], "weight_tensor": [6, 82], "argument": [6, 8, 21, 48, 53, 66, 81, 82], "register_aqt_quantized_linear_dispatch": 6, "show": [6, 67, 81, 82, 86], "work": [6, 20, 39, 81, 84, 86, 88], "sometim": [6, 86], "ha": [6, 8, 82, 86, 88], "pack": [6, 8, 10, 21, 22, 35, 39, 46, 82], "order": [6, 48, 58, 82, 86, 88], "yield": [6, 86], "And": [6, 18, 36, 82, 88], "abstract": [6, 82], "see": [6, 8, 16, 35, 81, 82, 83, 84, 86, 88], "full": [6, 91], "after": [6, 34, 48, 82, 84, 86], "wrap": [6, 48, 88], "factori": 6, "convert": [6, 8, 16, 18, 23, 26, 28, 29, 31, 58, 60, 61, 66, 68, 78, 81, 82, 86], "from": [6, 8, 18, 19, 24, 25, 27, 35, 41, 51, 55, 60, 66, 67, 78, 81, 82, 83, 84, 85, 86, 88, 90, 91], "float": [6, 8, 16, 18, 26, 28, 29, 35, 40, 44, 47, 48, 49, 51, 52, 53, 55, 56, 59, 67, 68, 71, 74, 82, 84, 88], "point": [6, 8, 16, 28, 35, 40, 44, 47, 53, 55, 59, 65, 68, 81, 82, 83, 84, 86, 88], "my": [6, 86], "to_my_dtyp": 6, "mydtypetensor": 6, "from_float": [6, 88], "level": [6, 74, 82, 86, 88], "reus": [6, 82, 88], "quantize_": [6, 60, 66, 78, 82, 83, 84], "appli": [6, 8, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 58, 66, 76, 78, 82, 83, 86], "convers": [6, 8, 33, 82], "filter": [6, 33, 48, 81], "choos": [6, 82, 86, 88], "which": [6, 16, 22, 48, 81, 82, 83, 84, 86], "modul": [6, 31, 32, 33, 34, 44, 45, 47, 48, 58, 60, 61, 65, 66, 70, 71, 73, 74, 78, 81, 83, 84], "should": [6, 8, 34, 39, 53, 55, 60, 73, 74, 81, 82, 86], "algorithm": [6, 40, 46, 86], "onli": [6, 13, 33, 36, 38, 39, 40, 41, 43, 46, 78, 81, 83, 84, 86, 88], "dynam": [6, 30, 31, 34, 36, 41, 42, 59, 63, 78, 88], "quant": [6, 8, 16, 35, 82], "static": [6, 8, 14, 18, 24, 27, 31, 37, 51, 59], "type": [6, 8, 17, 18, 22, 31, 32, 33, 36, 37, 38, 40, 41, 44, 45, 47, 48, 52, 57, 59, 67, 69, 79, 82, 84, 86, 88], "note": [6, 56, 58, 74, 82, 83, 86, 88], "2": [6, 8, 11, 13, 17, 20, 40, 44, 48, 56, 59, 67, 75, 76, 78, 81, 82, 83, 86, 88, 91], "4": [6, 11, 17, 20, 29, 39, 52, 75, 76, 78, 82, 83, 84, 86, 88], "below": [6, 81, 82, 86, 88, 91], "follow": [6, 40, 59, 81, 82, 83, 86, 88], "util": [6, 39, 81, 82, 83, 84, 88], "import": [6, 60, 66, 78, 83, 84, 86, 88, 91], "unwrap_tensor_subclass": [6, 83], "m_unwrap": 6, "m": [6, 66, 68, 78, 81, 83, 84, 88], "In": [6, 81, 82, 83, 86, 88], "compat": [6, 17, 59, 83], "aim": [6, 82, 86], "fullgraph": [6, 83], "true": [6, 8, 26, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 51, 52, 59, 66, 70, 78, 81, 83, 84, 88], "first": [6, 18, 48, 57, 74, 82, 88], "remov": [6, 49, 74, 81, 86], "ani": [6, 19, 48, 61, 65, 72, 74, 82, 86, 88], "unnecessari": 6, "graph": 6, "break": 6, "torch_log": 6, "output_cod": 6, "when": [6, 8, 19, 49, 53, 55, 67, 81, 82, 86], "script": [6, 83, 88, 91], "inductor": [6, 48], "python": [6, 82, 86, 89, 91], "mode": [6, 40, 48, 83], "max": [6, 44, 82, 83, 88], "checkout": [6, 8, 16, 79, 82], "doc": [6, 81, 82, 88], "huggingfac": 6, "transform": [6, 8, 82], "deseri": [6, 82], "save_pretrain": 6, "push_to_hub": 6, "from_pretrain": 6, "http": [6, 8, 16, 35, 48, 74, 83, 86], "co": 6, "main": [6, 8, 16, 40, 82, 83, 86, 88], "en": [6, 48], "anoth": [6, 82, 86, 88], "diffus": 6, "github": [6, 8, 16, 35, 83], "com": [6, 8, 16, 35], "sayakpaul": 6, "blob": [6, 8, 16], "infer": [6, 8, 70, 79, 82, 83, 84, 86, 88], "serialization_and_load": 6, "md": 6, "The": [6, 8, 9, 14, 17, 22, 33, 35, 36, 37, 38, 48, 57, 66, 69, 70, 71, 74, 81, 82, 83, 84, 86, 88], "abov": [6, 44, 82, 84, 86, 88], "just": [6, 44, 59, 82, 84, 86, 88], "talk": [6, 82], "about": [6, 40, 82, 83, 84, 86], "basic": [6, 19, 83, 88], "provid": [6, 14, 17, 20, 21, 48, 49, 58, 65, 81, 82, 86, 88], "fsdp": [6, 82], "ll": [6, 44, 81, 82, 88], "put": [6, 78], "developer_api_guid": 6, "cover": [6, 82, 91], "executorch": [6, 41, 66], "torchchat": 6, "todo": [6, 82], "qat": [6, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65], "suit": 6, "out": [6, 20, 44, 48, 74, 81, 82, 83, 86, 88], "differ": [6, 14, 40, 51, 58, 67, 69, 81, 82, 83, 84, 86, 88], "system": 6, "dtensor": [6, 88], "recommend": [6, 36, 37, 38, 39, 40, 41, 46, 48, 81], "copi": [6, 8, 74, 83, 84, 86, 88], "past": [6, 86], "adapt": 6, "now": [6, 35, 41, 49, 81, 82, 83, 86, 88], "befor": [6, 66, 82, 84, 86, 88], "some": [6, 48, 66, 74, 82, 86, 88], "singl": [6, 30, 34, 36, 48, 51, 81, 83, 86], "comput": [6, 17, 21, 34, 38, 73, 74, 86, 88], "intens": 6, "memori": [6, 8, 56, 81, 83, 86, 88], "input": [6, 8, 17, 18, 20, 31, 33, 34, 48, 49, 51, 53, 55, 56, 57, 65, 66, 67, 69, 74, 78, 81, 82, 88], "dimens": [6, 8, 22, 46, 49, 53, 55, 57, 67, 81, 88], "get": [6, 18, 81, 82, 86], "sens": [6, 82, 88], "speedup": [6, 40, 81, 82, 83, 86], "d": [6, 82], "creat": [6, 8, 24, 25, 27, 81, 82, 86, 88], "file": [6, 81, 85, 88, 90], "benchmark_aq": 6, "shape": [6, 8, 16, 48, 57, 69, 83, 88], "A": [6, 8, 22, 48, 51, 56, 73, 86, 88], "quick": [6, 79], "wai": [6, 8, 48, 81, 82, 86, 88], "relev": [6, 40, 82, 91], "chang": [6, 66, 81, 82, 83, 84, 86, 88], "interest": [6, 82, 86, 88], "tutori": [6, 8, 81, 82, 85, 86, 88, 89, 90], "print_op_and_shap": 6, "output": [6, 31, 48, 49, 53, 55, 67, 81, 82, 86, 91], "torch_func": 6, "built": [6, 81, 88], "k": [6, 69, 83, 84, 88], "n": [6, 83, 84, 88], "10": [6, 44, 67, 81], "method": [6, 14, 17, 20, 21, 48, 66, 74, 86, 88], "_c": 6, "tensorbas": 6, "object": [6, 22, 60, 66, 78, 88], "arg": [6, 8, 61, 74, 88], "0": [6, 8, 48, 59, 67, 71, 74, 81, 83, 84, 85, 86, 88, 90, 91], "size": [6, 8, 9, 16, 18, 39, 40, 41, 46, 49, 53, 55, 59, 67, 81, 83, 84, 86, 88], "all": [6, 34, 44, 48, 51, 61, 65, 73, 74, 75, 82, 83, 84, 85, 86, 88, 89], "under": 6, "benchmark_your_kernel": 6, "helper": 6, "right": [6, 82, 86], "1": [6, 17, 22, 32, 40, 44, 45, 46, 47, 48, 52, 67, 74, 81, 82, 83, 84, 85, 86, 88, 90, 91], "either": [6, 8, 36, 55, 74, 86], "one": [6, 36, 48, 51, 73, 81, 82, 86, 88], "probabl": 6, "keep": [6, 17, 74], "futur": [6, 35], "llama": 6, "llama2": 6, "llama3": [6, 81], "sam": 6, "alreadi": [6, 8, 48, 88], "modifi": [6, 33, 66, 74, 81, 82, 86, 88], "friendli": [6, 82], "compar": [6, 40, 56, 74, 81, 82], "techniqu": [6, 84, 86, 88], "repres": [6, 8, 9, 12, 14, 25, 31, 59, 67, 74, 82, 84, 88], "bound": [6, 86], "help": [6, 81, 82], "option": [6, 8, 12, 16, 23, 26, 27, 28, 30, 31, 33, 36, 37, 39, 40, 42, 43, 48, 49, 51, 53, 55, 56, 59, 62, 64, 66, 67, 70, 71, 72, 74, 78, 81, 83], "each": [6, 18, 48, 59, 70, 73, 82, 86, 88], "understand": [6, 81], "profil": 6, "profile_path": 6, "chrome": 6, "trace": [6, 82], "let": [6, 39, 44, 67, 82, 83, 86, 88], "know": [6, 48, 60, 88], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 58, 59, 60, 61, 62, 63, 64, 73, 74, 82, 83, 84, 88], "torchao": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 86, 88], "tensor_impl": [8, 16, 82], "aqttensorimpl": [8, 16], "block_siz": [8, 14, 16, 18, 23, 24, 26, 27, 28, 29, 49, 51, 53, 55, 56, 67, 83], "tupl": [8, 16, 18, 23, 24, 26, 27, 28, 36, 37, 49, 51, 52, 53, 55, 56, 65, 67, 74, 88], "int": [8, 9, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 35, 39, 40, 41, 43, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 61, 62, 63, 66, 67, 68, 74, 83, 88], "quant_min": [8, 16, 26, 27, 28, 44, 49, 51, 53, 55, 56, 67, 82, 83, 88], "union": [8, 16, 31, 36, 37, 49, 53, 55, 56, 59, 66, 67], "none": [8, 12, 16, 23, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 64, 65, 66, 67, 70, 71, 72, 74, 78, 88], "quant_max": [8, 16, 26, 27, 28, 44, 49, 51, 53, 55, 56, 67, 82, 83, 88], "zero_point_domain": [8, 16, 26, 27, 28, 40, 49, 51, 55, 56, 59], "zeropointdomain": [8, 16, 26, 27, 28, 40, 49, 51, 55, 56, 59], "stride": [8, 16, 82, 88], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 89, 91], "tensor": [8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 40, 41, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 67, 68, 69, 72, 74, 79, 81, 83, 84, 86, 91], "subclass": [8, 16, 33, 48, 73, 78, 83, 84, 86], "mean": [8, 18, 44, 49, 53, 55, 67, 68, 81, 82, 83, 86], "quantized_tensor": 8, "float_tensor": [8, 88], "scale": [8, 14, 17, 24, 27, 34, 37, 44, 47, 49, 51, 53, 54, 55, 56, 57, 59, 65, 67, 68, 70, 71, 82, 86, 88], "zero_point": [8, 14, 27, 40, 47, 49, 51, 53, 55, 56, 67, 82, 86, 88], "happen": [8, 16, 48, 82, 88], "dure": [8, 16, 48, 53, 55, 59, 71, 81, 86, 88], "choose_qparam": [8, 82], "dequant": [8, 16, 18, 40, 53, 82, 88], "ao": [8, 16, 86], "three": [8, 48, 74, 78, 82], "choose_qparams_affin": [8, 40, 51, 82], "quantize_affin": [8, 40, 55, 56, 82], "qand": 8, "dequantize_affin": [8, 40, 55, 56], "extern": 8, "regardless": 8, "intern": [8, 21], "represent": [8, 14, 25, 40, 82, 86], "orient": 8, "field": [8, 59], "serv": [8, 14, 88], "gener": [8, 55, 56, 82, 83, 86, 88, 89, 91], "storag": [8, 17, 82, 86], "data": [8, 9, 14, 17, 22, 36, 37, 38, 40, 51, 79, 82, 84, 86, 88], "store": [8, 17, 18, 22, 73, 82, 86], "plain": 8, "int_data": [8, 88], "format": [8, 17, 18, 35, 39, 68, 82, 86], "depend": [8, 39, 48, 84, 86, 88], "kernel": [8, 10, 11, 13, 17, 21, 35, 39, 40, 66, 83, 86], "granular": [8, 36, 37, 39, 40, 41, 46, 49, 53, 55, 59, 67, 81, 82], "element": [8, 20, 22, 48, 49, 53, 55, 67, 86], "share": [8, 49, 53, 55, 67, 86], "qparam": [8, 49, 53, 55, 67], "us": [8, 12, 13, 14, 17, 18, 19, 22, 24, 27, 36, 37, 40, 41, 44, 46, 48, 49, 51, 53, 55, 58, 59, 60, 67, 74, 79, 81, 82, 83, 84, 86, 88], "per": [8, 38, 40, 41, 42, 43, 46, 49, 53, 55, 59, 61, 62, 63, 67, 74, 76, 81, 82, 83, 86], "torch": [8, 17, 18, 22, 24, 31, 33, 36, 37, 38, 40, 46, 48, 49, 52, 53, 54, 55, 57, 59, 61, 62, 63, 66, 67, 69, 70, 71, 78, 81, 82, 83, 84, 86, 88, 91], "origin": [8, 18, 38, 55, 60, 67, 74, 82, 83, 84, 86], "high": [8, 23, 24, 25, 26, 27, 68, 81, 82, 86, 88], "precis": [8, 23, 24, 25, 26, 27, 38, 62, 63, 68, 82, 88], "minimum": [8, 48, 49, 53, 55, 67], "valu": [8, 18, 31, 32, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 53, 55, 56, 67, 70, 74, 82, 86, 88], "specifi": [8, 31, 33, 39, 46, 55, 58, 66, 67, 74, 78, 81, 86], "deriv": [8, 51, 55, 67], "maximum": [8, 49, 53, 55, 67, 70], "domain": [8, 40, 47, 49, 53, 55, 59], "integ": [8, 26, 27, 39, 40, 44, 47, 49, 53, 55, 57, 59, 69], "zero": [8, 20, 40, 49, 53, 55, 59, 65, 74, 86], "ad": [8, 53, 55, 74, 86, 88], "subtract": [8, 18, 55], "unquant": [8, 55], "default": [8, 9, 12, 19, 21, 22, 36, 37, 38, 40, 46, 48, 49, 53, 55, 59, 66, 70, 71, 81, 88], "float32": [8, 24, 53, 54, 55, 59, 61, 63, 67, 68, 84, 86, 88], "given": [8, 16, 29, 81, 86], "return": [8, 16, 17, 18, 33, 48, 56, 57, 59, 66, 69, 70, 71, 78, 81, 82, 83, 84, 88], "classmethod": [8, 16, 88], "from_hp_to_floatx": 8, "input_float": [8, 16, 23, 24, 25, 26, 27, 28, 72], "target_dtyp": [8, 23, 24, 26, 27, 30, 31, 49, 51, 82], "_layout": [8, 16, 23, 24, 25, 26, 27, 28, 82, 83], "layout": [8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 40, 41, 42, 78, 86], "scale_dtyp": [8, 23, 24, 26, 49, 51], "float8": [8, 11, 12, 23, 24, 30, 31, 32, 33, 34, 36, 37, 38, 79, 82], "from_hp_to_floatx_stat": 8, "paramet": [8, 14, 17, 18, 24, 27, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 48, 49, 53, 55, 57, 59, 66, 67, 69, 70, 71, 74, 78, 81, 82, 84, 86, 88], "from_hp_to_fpx": 8, "floatx": [8, 25, 82], "ebit": [8, 25, 35, 50, 54, 68], "mbit": [8, 25, 35, 50, 54, 68], "support": [8, 25, 36, 41, 59, 78, 81, 83, 84, 86, 88], "float1": [8, 25], "float7": [8, 25], "from_hp_to_intx": [8, 16], "mapping_typ": [8, 26, 41, 49, 51, 59], "mappingtyp": [8, 26, 41, 42, 49, 51, 59], "ep": [8, 26, 49, 51, 59], "zero_point_dtyp": [8, 26, 49, 51], "preserve_zero": [8, 26, 40, 49, 51], "bool": [8, 26, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 51, 52, 59, 63, 66, 70, 78], "plainlayout": [8, 26, 27, 41, 42], "use_hqq": [8, 26, 40, 46], "fals": [8, 26, 31, 40, 42, 46, 48, 52, 59, 63, 70, 74, 81, 82, 83, 84, 88], "from_hp_to_intx_stat": 8, "kwarg": [8, 59, 61, 73, 74, 75, 88], "perform": [8, 21, 34, 39, 48, 57, 61, 62, 63, 69, 70, 73, 81, 83, 86, 88], "self": [8, 82, 83, 84, 88], "If": [8, 12, 33, 36, 48, 57, 59, 69, 70, 74, 82, 83, 86, 88], "correct": [8, 17], "otherwis": [8, 58, 59, 82], "desir": [8, 48, 55], "call": [8, 48, 55, 56, 73, 82, 83, 84, 86, 88], "non_block": 8, "memory_format": 8, "preserve_format": 8, "set": [8, 12, 36, 37, 38, 39, 40, 41, 46, 48, 51, 59, 66, 70, 74, 83, 86], "function": [8, 21, 33, 48, 52, 66, 73, 74, 75, 78, 81, 83, 84, 86, 88], "attempt": 8, "asynchron": 8, "respect": [8, 86], "host": 8, "possibl": [8, 86], "behavior": [8, 14, 58], "pin": 8, "pageabl": 8, "howev": [8, 86], "caution": 8, "advis": [8, 82], "featur": [8, 88], "inform": [8, 86], "good": [8, 83, 88], "usag": [8, 34, 48, 58, 59, 60, 81], "pin_memori": 8, "even": [8, 81, 86], "match": [8, 53, 57, 86], "other": [8, 14, 74, 81, 84, 86, 88, 91], "randn": [8, 81, 83, 84, 88], "initi": [8, 65, 82, 84], "float64": 8, "5044": 8, "0005": 8, "3310": 8, "0584": 8, "cuda0": 8, "blocksiz": 9, "64": [9, 29, 40, 46, 52, 84, 88], "block": [9, 18, 74, 86], "matrix": [9, 12, 36, 37, 57, 69, 74, 83, 86], "variabl": [9, 12, 21, 22, 74, 86], "cutlass": [10, 11], "mm_config": [12, 36, 37], "float8mmconfig": [12, 36, 37], "configur": [12, 30, 31, 33, 36, 37, 38, 40, 41, 42, 43, 46, 66, 78, 81, 82, 83], "multipl": [12, 36, 37, 48, 57, 58, 69, 83, 86, 88], "involv": [12, 86], "tinygemm": [13, 40, 66, 82, 83], "_weight_int4pack_mm_for_cpu": [13, 40], "version": [13, 59, 81, 83, 88], "least": 13, "6": [13, 59, 81, 82, 83, 86], "It": [14, 17, 19, 21, 34, 86, 88], "pre": [14, 17, 21, 83, 86], "process": [14, 17, 19, 21, 22, 48, 71, 82, 86, 91], "post": [14, 21, 88], "addit": [14, 19, 48, 56, 81, 86, 88], "design": [14, 17, 20], "extend": [14, 82, 86], "conjunct": 14, "tensorimpl": 14, "custom": [14, 73, 79, 81, 82, 83, 86, 88], "interact": [14, 82], "qqq": [15, 16, 28], "marlinqqq": 16, "inherit": [16, 19, 88], "choose_qparams_and_quantize_affine_qqq": 16, "dequantize_affine_qqq": 16, "handl": [17, 20, 21, 48, 82], "pattern": [17, 20, 82], "ensur": 17, "preprocess": [17, 20], "manag": 17, "pre_process": 17, "1\u00ba": 17, "transpos": [17, 82, 88], "sinc": [17, 73, 82, 84, 86, 88], "layer": [17, 33, 36, 38, 40, 42, 43, 46, 48, 61, 62, 63, 70, 71, 74, 75, 76, 81, 86, 88], "2\u00ba": 17, "inject": 17, "3\u00ba": 17, "again": [17, 18, 86], "becaus": [17, 81, 82, 84, 86, 88], "dim": [17, 88], "tensor_meta": 18, "subclasstensorarg": 18, "n_block": 18, "scaler_block_s": [18, 29], "quantized_scal": 18, "quantization_factor": 18, "scaler_mean": 18, "quantized_data": 18, "nf4": 18, "qlora": 18, "convert_to_norm_float_weight": 18, "normal": [18, 29, 48, 86], "dequantize_scal": 18, "unpack": [18, 68, 82], "doubl": 18, "scaler": 18, "int8": [18, 41, 42, 43, 59, 63, 66, 76, 78, 82, 88], "per_scaler_block": 18, "factor": [18, 57, 71, 81, 86], "inpt_weight": 18, "double_quantize_scal": 18, "achiev": [18, 81, 86, 88], "calcul": [18, 34, 44, 49, 51, 70, 82, 86], "absmax": 18, "find": [18, 86], "posit": 18, "typic": [18, 19, 82, 84], "per_block": 18, "int16": 18, "n_scaler_block": 18, "get_original_weight": 18, "quantize_tensor_nearest": 18, "float16": [18, 52, 55, 67, 86], "nearest": 18, "round": [18, 44, 88], "up": [18, 66, 81, 82, 83, 86], "most": [19, 82, 86], "doe": [19, 40, 82, 86, 88], "metadata": [19, 82, 88], "step": [19, 34, 48, 81, 82, 86], "requir": [19, 21, 81, 82, 86, 88], "semi": [20, 78, 86], "structur": [20, 78, 83, 84, 86, 88], "matric": [20, 86], "where": [20, 44, 46, 51, 61, 62, 63, 68, 82, 86], "everi": [20, 73, 86, 88], "four": 20, "prune": [20, 74], "conform": 20, "inner_k_til": [21, 40, 62, 83], "8": [21, 22, 39, 40, 44, 62, 81, 82, 83], "core": [21, 45, 82], "tile": [21, 82], "fit": [21, 82, 84], "effici": [21, 83, 86], "affect": [21, 86], "matmul": [21, 38, 82, 86, 88], "pack_dim": [22, 46], "uintx": [22, 46, 82], "smaller": [22, 39, 40, 41, 46, 83, 84], "bit": [22, 29, 35, 39, 46, 68, 88], "width": [22, 39], "than": [22, 59, 81, 82, 86, 88], "standard": [22, 82], "byte": [22, 35, 46], "uintxtensor": 22, "determin": [22, 39, 49, 55, 81, 86], "along": [22, 86], "indic": [22, 47, 86], "last": [22, 81], "256": [29, 40, 61, 62, 63], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "tensorwis": [30, 31], "cast": [30, 55, 56], "cast_config_input": 31, "config": [31, 33, 48, 59, 66, 74, 78, 86], "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "nn": [31, 33, 48, 58, 61, 66, 70, 71, 78, 81, 82, 83, 84, 86, 88], "from_recipe_nam": 31, "recipe_nam": [31, 81], "float8linearrecipenam": 31, "str": [31, 33, 52, 59, 66, 71, 72, 74, 78, 81, 88], "string": [31, 59, 74], "recip": [31, 73], "name": [32, 44, 45, 47, 66, 71, 74, 78, 86, 88], "qualnam": [32, 44, 45, 47], "boundari": [32, 44, 45, 47], "module_filter_fn": [33, 81], "callabl": [33, 48, 52, 66, 72, 78], "float8linearconfig": 33, "swap": [33, 61, 81, 82, 86], "float8linear": [33, 81], "pass": [33, 48, 51, 73, 82, 88], "instanc": [33, 66, 73, 78, 84, 88], "fqn": [33, 74, 78, 81], "reduc": [34, 81, 86], "sum": 34, "backward": [34, 81, 86], "set_inductor_config": [35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48], "sub": [35, 46, 86], "expon": [35, 68], "mantissa": [35, 68], "fp6_e3_m2": 35, "fp6_e2_m3": 35, "fp6": 35, "llm": 35, "paper": [35, 86, 91], "arxiv": [35, 74, 86], "org": [35, 48, 74, 82, 83, 86], "ab": [35, 74, 86], "2401": 35, "14112": 35, "repo": 35, "usyd": 35, "fsalab": 35, "fp6_llm": 35, "renam": 35, "fpxtensorcoreaqttensorimpl": 35, "experiment": 35, "merg": 35, "to_affine_quantized_floatx": 35, "activation_dtyp": [36, 37], "float8_e4m3fn": [36, 37, 38, 82], "weight_dtyp": [36, 37, 38], "pertensor": [36, 37], "perrow": [36, 37], "list": [36, 48, 53, 58, 71, 74, 82, 83, 88], "symmetr": [36, 37, 38, 39, 41, 42, 43, 44, 49, 59, 76, 88], "current": [36, 41, 66, 71, 74, 78, 81, 86, 88], "fast": [36, 37, 86], "accumul": [36, 37], "adjust": [36, 37, 38, 39, 40, 41, 46, 48], "torchinductor": [36, 37, 38, 39, 40, 41, 46], "float8_e4m": 37, "channel": [38, 42, 43, 59, 61, 62, 63, 73, 76], "group_siz": [39, 40, 41, 43, 46, 52, 59, 61, 66, 83], "128": [39, 40, 81, 88], "bit_width": 39, "packing_bitwidth": 39, "gemlit": 39, "triton": [39, 82], "its": [39, 86, 88], "associ": 39, "fp16": [39, 49], "asymmetr": [39, 40, 41, 44, 46, 49, 59, 82, 83], "control": [39, 40, 41, 46, 74, 86], "grain": [39, 40, 41, 46, 88], "32": [39, 40, 41, 59, 66, 78, 81, 83, 84, 88], "impact": [39, 48, 81], "hardwar": [39, 82, 86], "contigu": 39, "leav": [39, 59], "best": [39, 86], "choic": [39, 40], "tensorcoretiledlayout": [40, 82, 83], "group": [40, 41, 46, 59, 61, 62, 63, 82, 83], "tensor_core_til": [40, 82], "int4mm": [40, 83], "aten": [40, 82, 88], "_weight_int4pack_mm": [40, 82], "tradit": 40, "instead": [40, 51, 59, 73, 81, 82, 83, 86, 88], "exactli": [40, 88], "chosen": [40, 86], "whether": [40, 46, 47, 48, 49, 59, 88], "hqq": [40, 46, 82], "preserv": [40, 49, 74, 86], "Will": 40, "act_mapping_typ": [41, 42], "token": [41, 42, 59, 63, 76, 81], "produc": 41, "backend": [41, 86], "did": 41, "lower": [41, 82, 86], "flow": [41, 86], "yet": [41, 45, 88], "marlinqqqlayout": 41, "cutlassint4packedlayout": 41, "weight_only_decod": 42, "number": [44, 46, 48, 68, 74, 86, 88], "map": [44, 59, 82, 88], "rang": [44, 81, 86], "sai": [44, 67, 82], "3": [44, 48, 67, 81, 82, 83, 86, 91], "5": [44, 71, 74, 81, 83, 86, 91], "7": [44, 81], "symmetric_no_clipping_err": 44, "variant": [44, 51, 88], "smin": 44, "smax": 44, "min_val_neg": [44, 88], "max_val_po": [44, 88], "By": [44, 86], "individu": [44, 86], "less": [44, 86, 88], "error": [44, 48, 59, 81, 88], "neg": 44, "directli": [44, 51, 82, 86, 88], "placehold": 45, "x": [46, 81, 83, 84, 88, 91], "uint1": [46, 82], "uint7": [46, 82], "enum": 47, "quantized_v": 47, "float_val": 47, "mid_point": 47, "example_input": [48, 65, 83, 84], "qtensor_class_list": 48, "aqdefaultlinearweight": 48, "aqint8weightonlyquantizedlinearweight": 48, "aqint8weightonlyquantizedlinearweight2": 48, "aqint8dynamicallyquantizedlinearweight": 48, "filter_fn": [48, 66, 78], "interpol": 48, "85": 48, "manual": 48, "supress_autoquant_error": 48, "min_sqnr": 48, "aq_kwarg": 48, "autoquant": 48, "identifi": 48, "fastest": 48, "over": [48, 81, 86], "potenti": [48, 86], "qtensor": 48, "prepar": [48, 58, 61, 70, 74, 82, 86], "search": [48, 86], "whose": 48, "exchang": 48, "autoquantizablelinearweight": 48, "calibr": [48, 51], "user": [48, 58, 81, 82, 83, 86, 88, 91], "seen": 48, "record": [48, 82], "so": [48, 81, 82, 83, 84, 86, 88], "final": [48, 56, 66, 82, 83, 86], "benchmark": [48, 70, 81], "member": 48, "pick": 48, "result": [48, 57, 68, 69, 82, 86], "highli": 48, "complet": 48, "simpli": [48, 86, 88], "had": [48, 88], "compil": [48, 66, 69, 81, 82, 83, 88], "them": [48, 73, 82], "onc": [48, 86], "proce": 48, "combin": [48, 59, 86, 88], "finalize_autoqu": 48, "been": [48, 88], "log": [48, 88], "forward": [48, 73, 82, 83, 84, 86, 88], "fulli": [48, 66, 71, 78, 86], "unless": 48, "default_autoquant_class_list": 48, "contain": [48, 70, 71, 86, 88], "second": [48, 57, 81, 82, 91], "stop": 48, "wait": [48, 82], "sever": [48, 81], "automat": [48, 81, 88, 91], "suppress": 48, "accept": 48, "signal": 48, "nois": 48, "ration": 48, "wikipedia": 48, "wiki": 48, "noise_ratio": 48, "v": 48, "non": [48, 82, 86, 88], "caus": [48, 81], "too": 48, "larg": [48, 88], "numer": [48, 81, 86], "resaon": 48, "40": [48, 81], "keyword": 48, "example_input1": 48, "example_input2": 48, "int32": [49, 59, 61, 82, 83], "fp32": [49, 53, 59, 88], "bf16": [49, 82, 83, 86], "optioanl": 49, "param": [49, 51, 56, 74], "request": [49, 53, 67], "min_val": [51, 82, 88], "max_val": [51, 82, 88], "observ": [51, 73, 86], "obtain": 51, "track": [51, 82], "nbit": 52, "axi": [52, 67], "compute_dtyp": 52, "verbos": 52, "raw_output": 52, "optimize_weight": 52, "optimize_weights_proximal_legaci": 52, "input_dtyp": 53, "output_dtyp": [53, 54, 67], "uint8": [53, 67, 82], "quant_dtyp": [55, 56], "fake": [55, 56, 59, 60, 61, 62, 63, 81], "awar": [55, 56, 74, 86, 88], "equival": [55, 56, 59, 71, 86], "without": [55, 56, 60, 82, 86], "valid": 55, "fake_quantize_affin": 56, "consum": 56, "outlier": [56, 81], "mask": [56, 74, 86], "intermedi": 56, "b": 57, "scales1": 57, "multipli": [57, 69, 86], "row": [57, 81, 86], "rais": [57, 69, 81, 88], "assertionerror": [57, 69, 81, 88], "expect": [57, 81, 86, 88], "twostepquant": 58, "compos": [58, 82, 86, 88], "easili": 58, "thei": [58, 81, 82, 86, 88], "constructor": [58, 88], "must": [58, 59, 81, 86], "embed": [58, 61], "undefin": [58, 74], "my_quant": 58, "qatquantizer1": 58, "qatquantizer2": 58, "qatquantizer3": 58, "torchaodtyp": 59, "scale_precis": [59, 61], "zero_point_precis": [59, 61], "is_dynam": 59, "range_learn": 59, "is_symmetr": 59, "simul": [59, 75, 82, 86], "older": 59, "int1": [59, 82], "int7": 59, "pergroup": 59, "per_token": 59, "pertoken": 59, "per_channel": 59, "peraxi": 59, "per_group": [59, 67], "separ": [59, 86], "altern": [59, 82, 88], "empti": [59, 82], "properti": [59, 82], "throw": 59, "els": 59, "fakequantizedlinear": 60, "fakequantizedembed": 60, "back": [60, 88], "correspond": [60, 66, 82, 84, 86, 88], "model_with_fake_quantized_linear": 60, "int4weightonlyqatembed": 61, "int4weightonlyembed": 61, "groupsiz": [62, 63, 67], "scales_precis": [62, 63], "padding_allow": 63, "activation_config": 64, "fakequantizeconfig": 64, "weight_config": 64, "fakequant": 65, "aobaseconfig": [66, 78], "inplac": [66, 74, 83], "workflow": [66, 78, 81, 83, 86], "qualifi": [66, 71, 78, 86], "move": [66, 82], "speed": [66, 86], "predefin": 66, "execut": [66, 85, 88, 90], "path": [66, 69, 83], "customiz": 66, "int8_dynamic_activation_int4_weight": 66, "int8_dynamic_activation_int8_weight": [66, 78], "mm": [66, 88], "int4_weight_onli": [66, 82, 83, 84], "int8_weight_onli": 66, "sequenti": [66, 78, 81], "1024": [66, 78, 83, 84], "tabl": [67, 81, 82, 86], "per_tensor": 67, "per_axi": 67, "low": [68, 86, 88], "00seeemm": 68, "fp6_e3m2": 68, "sign": 68, "mat2": 69, "safe": 69, "consid": [69, 82, 86], "cubla": 69, "fallback": 69, "i": [69, 81, 86], "j": 69, "debug_skip_calibr": 70, "smoothquant": [70, 71], "smoothfakedynamicallyquantizedlinear": [70, 71], "debug": 70, "skip_fqn_list": 71, "cur_fqn": 71, "alpha": 71, "replac": [71, 86], "skip": [71, 74, 86], "being": [71, 81, 82, 86], "input_quant_func": [72, 82], "quant_kwarg": 72, "dict": [72, 74, 88], "l2": [73, 86], "norm": [73, 74, 86], "buffer": 73, "x_orig": 73, "overridden": 73, "although": [73, 88], "within": [73, 86], "afterward": 73, "former": 73, "care": [73, 84, 86], "hook": [73, 82], "while": [73, 74, 86, 88], "latter": 73, "silent": 73, "ignor": [73, 81], "sparsity_level": [74, 86], "semi_structured_block_s": 74, "wanda": 74, "sparsifi": [74, 79, 84, 86], "propos": 74, "2306": 74, "11695": 74, "product": 74, "magnitud": [74, 86], "parametr": 74, "deepcopi": [74, 83, 88], "squash_mask": [74, 86], "params_to_keep": 74, "params_to_keep_per_lay": 74, "squash": 74, "appropri": [74, 82], "sparse_param": 74, "attach": [74, 86], "kei": [74, 86, 91], "save": [74, 81, 83, 84], "xdoctest": 74, "local": [74, 86], "don": [74, 81, 83, 86], "t": [74, 81, 82, 83, 86, 88], "hasattr": 74, "submodule1": 74, "linear1": [74, 83, 84, 88], "foo": 74, "bar": 74, "submodule2": 74, "linear42": 74, "baz": 74, "print": [74, 83, 84, 88, 91], "42": 74, "24": 74, "ones": [74, 82], "update_mask": 74, "tensor_nam": 74, "statist": [74, 82, 86], "retriev": 74, "act_per_input": 74, "Then": [74, 88], "metric": 74, "across": [74, 86, 88], "whole": 74, "dnynam": 76, "alia": 77, "semisparseweightconfig": 77, "sparsify_": 78, "apply_tensor_subclass": [78, 82], "essenti": 78, "semi_sparse_weight": 78, "semisparselayout": 78, "sparsemarlinlayout": 78, "def": [78, 81, 82, 83, 84, 88], "isinst": [78, 81, 86, 88], "sparse_api": 78, "librari": [79, 84], "gradient": [79, 86], "nativ": [79, 81, 88], "readm": [79, 83, 86], "overal": [79, 83], "introduct": [79, 82], "recent": 79, "highlight": [79, 88, 91], "updat": [79, 83, 84, 86], "guid": [79, 82], "contributor": [79, 83], "serial": [79, 82], "write": 79, "advanc": [79, 88], "pretrain": [79, 86], "5x": 81, "512": 81, "gpu": [81, 83, 91], "cluster": 81, "34": 81, "43x": 81, "2k": 81, "h200": 81, "latest": [81, 83], "offic": 81, "framework": 81, "8b": 81, "offici": 81, "popular": [81, 82], "flagship": 81, "common": [81, 82, 86], "form": [81, 82, 86], "distribut": [81, 88], "checkpoint": 81, "quickli": [81, 88], "batteri": 81, "includ": [81, 82, 88], "experi": 81, "commonli": [81, 86], "fork": 81, "build": [81, 82, 86, 88], "top": [81, 82, 88], "re": [81, 84, 88], "readi": [81, 83, 88], "virtual": 81, "environ": 81, "conda": 81, "venv": 81, "instal": [81, 83], "download": [81, 83, 89, 91], "job": 81, "command": [81, 83], "root": 81, "directori": 81, "launch": 81, "ngpu": 81, "config_fil": 81, "train_config": 81, "llama3_8b": 81, "toml": 81, "run_train": 81, "sh": 81, "fsdp2": 81, "hyperparamet": 81, "edit": 81, "line": [81, 86], "flag": 81, "termin": 81, "rank0": 81, "titan": 81, "2025": 81, "06": 81, "04": 81, "08": 81, "51": 81, "48": 81, "074": 81, "info": 81, "loss": [81, 86], "12": 81, "2254": 81, "27": 81, "34gib": 81, "28": 81, "78": 81, "tp": 81, "375": 81, "tflop": 81, "21": 81, "73": 81, "mfu": 81, "20": 81, "58": 81, "557": 81, "7069": 81, "30": [81, 83], "99gib": 81, "62": 81, "034": 81, "407": 81, "35": 81, "41": 81, "19": 81, "52": 81, "224": 81, "9196": 81, "022": 81, "406": 81, "65": 81, "904": 81, "1423": 81, "014": 81, "23": 81, "As": [81, 82], "warmup": 81, "around": [81, 84], "7k": 81, "99gb": 81, "peak": 81, "against": 81, "baselin": 81, "11": 81, "02": 81, "37": 81, "404": 81, "2611": 81, "22gib": 81, "595": 81, "47": 81, "49": 81, "027": 81, "4260": 81, "89gib": 81, "344": 81, "367": 81, "39": 81, "15": [81, 83], "03": 81, "01": 81, "988": 81, "9482": 81, "321": 81, "366": 81, "14": 81, "991": 81, "1183": 81, "300": 81, "364": 81, "89": 81, "36": 81, "013": 81, "4659": 81, "291": 81, "84": 81, "769": 81, "gc": 81, "peform": 81, "period": 81, "collect": [81, 82, 86], "3k": 81, "89gb": 81, "11x": 81, "higher": [81, 82, 88], "throughput": 81, "nearli": 81, "ident": [81, 86], "improv": [81, 86], "performan": 81, "vs": [81, 86], "accuraci": [81, 86], "curv": [81, 86], "omit": 81, "648": 81, "2648": 81, "28gib": 81, "71": 81, "29": 81, "26": 81, "475": 81, "9106": 81, "91gib": 81, "53": 81, "503": 81, "434": 81, "43": 81, "94": 81, "166": 81, "9": 81, "0774": 81, "663": 81, "443": 81, "44": 81, "87": 81, "50": [81, 86], "885": 81, "3233": 81, "643": 81, "442": 81, "66": 81, "76": 81, "613": 81, "6150": 81, "637": 81, "72": 81, "6k": 81, "91gb": 81, "21x": 81, "tl": 81, "dr": 81, "better": [81, 88], "priorit": 81, "accur": [81, 86], "stabil": 81, "come": [81, 82, 86, 87], "cost": 81, "slightli": [81, 88], "limit": [81, 88], "underflow": 81, "8xh100": 81, "box": [81, 86], "toi": [81, 83, 88], "convert_to_float8_train": 81, "recurs": 81, "kind": 81, "gemm": 81, "snippet": 81, "f": [81, 82, 84, 86, 88], "float8_linear_util": 81, "float8_linear": 81, "torch_version_at_least_2_5": [81, 83], "greater": 81, "sampl": [81, 82], "2048": 81, "4096": 81, "adamw": 81, "lr": 81, "1e": 81, "elig": 81, "mod": [81, 86, 88], "divis": 81, "16": 81, "in_featur": [81, 83, 84, 88], "out_featur": [81, 83, 88], "enabl": [81, 82], "competit": 81, "loop": [81, 86], "_": 81, "zero_grad": 81, "label": 81, "demonstr": [81, 82, 83, 88], "purpos": [81, 82, 88], "fake_label": 81, "ones_lik": 81, "mse_loss": 81, "model_state_dict": 81, "state_dict": [81, 84], "optimizer_state_dict": 81, "pth": 81, "lai": 82, "stack": 82, "awq": 82, "gptq": 82, "codebookquantizedtensor": 82, "float3": 82, "compon": [82, 88], "overload": [82, 86], "term": [82, 86], "extra": 82, "dev": 82, "discuss": [82, 88], "1833": 82, "No": [82, 84, 86], "matter": [82, 86], "end": [82, 86, 88, 91], "avail": 82, "later": [82, 88], "float3_e2_m0": 82, "float4_e2_m1": 82, "float4_e3_m0": 82, "float5_e2_m2": 82, "float5_e3_m1": 82, "float6_e2_m3": 82, "float6_e3_m2": 82, "float8_e5m2": 82, "float8_e4m3fnuz": 82, "float8_e5m2fnuz": 82, "plan": 82, "float4": 82, "float6": 82, "becom": 82, "part": [82, 86, 88], "uint2": 82, "117208": 82, "outsid": 82, "mention": 82, "criteria": 82, "wide": 82, "adopt": 82, "fundament": [82, 86], "until": 82, "evid": 82, "hopefulli": 82, "amen": 82, "haven": 82, "enough": 82, "ont": 82, "revisit": 82, "intx": 82, "connect": 82, "int4tensor": 82, "previou": 82, "between": [82, 86, 88], "preicison": 82, "mainli": 82, "There": [82, 88], "accommod": 82, "choose_qparams_affine_with_min_max": 82, "min": [82, 88], "int_matmul": 82, "int_scaled_matmul": 82, "reli": [82, 86, 88], "On": [82, 83], "glue": 82, "everyth": 82, "togeth": 82, "construct": 82, "low_precision_v": 82, "high_precision_v": 82, "procedur": 82, "veri": [82, 86], "straightforward": 82, "try": [82, 86, 88], "high_preicsion_v": 82, "especi": [82, 84, 86], "bitwidth": 82, "codebook": 82, "hardcod": 82, "select": 82, "multi": 82, "dimension": [82, 86], "view": [82, 88], "mkldnn": 82, "coo": [82, 86], "sparse_coo": [82, 86], "sparsetensorimpl": 82, "idea": [82, 86], "nice": [82, 86], "concept": [82, 91], "why": [82, 88, 91], "c": [82, 88], "conflict": 82, "quantized_linear": 82, "semant": 82, "stai": [82, 83, 88], "develop": 82, "tradition": 82, "to_affine_quant": 82, "simplic": 82, "explain": 82, "simplest": [82, 86], "easi": 82, "linear_modul": 82, "to_affine_quantized_intx": 82, "requires_grad": [82, 88], "runtim": 82, "to_linear_activation_quant": 82, "quantized_weight": 82, "activation_and_weight_quant": 82, "encount": 82, "input_qunat_func": 82, "redispatch": 82, "fx": 82, "symbolic_trac": 82, "But": [82, 88], "prefer": [82, 83, 88], "easier": 82, "further": [82, 88], "modif": 82, "figur": [82, 86], "At": [82, 86], "thing": [82, 84, 86, 88], "address": 82, "stat": 82, "averag": 82, "calculate_qparam": 82, "affinequantizedminmaxobserv": 82, "insert_observer_": 82, "observedlinear": 82, "dataset": 82, "complic": [82, 86], "next": 82, "done": [82, 88], "manner": 82, "intend": 82, "autoround": 82, "multitensor": 82, "sure": 82, "describ": [82, 84, 86, 91], "focus": [82, 86], "todai": 82, "low_bit_optim": 82, "similar": [82, 86], "quantized_train": 82, "progress": 82, "lot": [82, 86], "walk": [82, 88, 91], "_convert_weight_to_int4pack": 82, "tensorcoretiledaqttensorimpl": 82, "_quantized_linear_op": 82, "goe": 82, "_aqt_qlinear_dispatch_t": 82, "dispatch": 82, "explan": 82, "wint4": 82, "explor": 83, "stabl": 83, "releas": 83, "pip": 83, "nightli": 83, "index": [83, 86], "url": 83, "whl": 83, "cu121": 83, "major": 83, "instruct": 83, "entri": 83, "mutat": 83, "insert": 83, "logic": [83, 88], "toylinearmodel": [83, 84], "__init__": [83, 84, 88], "super": [83, 84, 88], "linear2": [83, 84, 88], "eval": [83, 84], "faster": [83, 86], "model_bf16": 83, "leverag": [83, 88], "mix": 83, "tensor_impl_dtyp": 83, "verifi": [83, 84, 88], "roughli": [83, 86], "quarter": 83, "os": 83, "tmp": 83, "int4_model": 83, "pt": 83, "bfloat16_model": 83, "int4_model_size_mb": 83, "getsiz": 83, "bfloat16_model_size_mb": 83, "2f": 83, "mb": [83, 84, 85, 90], "25": 83, "00": [83, 85, 90], "much": [83, 86], "benchmark_model": 83, "temporari": 83, "workaround": 83, "num_run": 83, "100": [83, 88], "_dynamo": [83, 88], "reset": 83, "bf16_time": 83, "int4_tim": 83, "time": [83, 86, 88, 91], "3f": 83, "ms": 83, "1fx": 83, "a100": 83, "80gb": 83, "393": 83, "410": 83, "9x": 83, "simpl": [83, 86, 88], "visit": 83, "would": [83, 86, 88], "forget": 83, "tempfil": 84, "get_model_size_in_byt": 84, "batch_siz": 84, "ref": 84, "namedtemporaryfil": 84, "seek": [84, 86], "load": 84, "meta": 84, "m_load": 84, "load_state_dict": 84, "assign": 84, "assert": [84, 88], "equal": [84, 86], "float_weight1": 84, "float_weight2": 84, "quantized_weight1": 84, "quantized_weight2": 84, "go": [84, 88, 91], "techinqu": 84, "reduct": [84, 86, 88], "4x": 84, "0625": 84, "reason": [84, 86], "avoid": [84, 86], "properli": 84, "003": [85, 90, 91], "total": [85, 90, 91], "galleri": [85, 89, 91], "mem": [85, 90], "templat": [85, 89, 90], "tutorials_sourc": 85, "template_tutori": [85, 90, 91], "neural": 86, "network": [86, 88], "overhead": 86, "latenc": 86, "carefulli": 86, "signific": 86, "pai": 86, "price": 86, "qualiti": 86, "f1": 86, "problem": [86, 88], "research": [86, 91], "face": 86, "fragment": 86, "rightfulli": 86, "spent": 86, "compress": 86, "place": 86, "dens": 86, "solv": [86, 88], "focu": [86, 88], "realli": 86, "push": 86, "concret": 86, "hope": 86, "modular": 86, "acceler": 86, "scratch": [86, 91], "minim": 86, "recov": 86, "algorthim": 86, "realiz": 86, "trade": 86, "off": 86, "degrad": 86, "architectur": 86, "theoret": 86, "gain": 86, "2x": 86, "analog": 86, "fix": 86, "unstructur": 86, "One": [86, 88], "close": 86, "relat": 86, "mitig": 86, "retrain": 86, "neglig": 86, "area": 86, "agre": 86, "upon": 86, "consensu": 86, "mind": 86, "thought": 86, "subproblem": 86, "satisfi": 86, "consist": [86, 88], "answer": 86, "independ": 86, "frontend": 86, "arbitrari": 86, "handoff": 86, "piec": 86, "miss": 86, "natur": [86, 88], "present": 86, "clear": 86, "contract": 86, "7x": 86, "advantag": 86, "anticip": 86, "mani": [86, 88], "solut": 86, "third": 86, "parti": 86, "to_sparse_semi_structur": 86, "sparsesemistructuredtensor": 86, "weightnormsparsifi": 86, "half": 86, "subnetwork": 86, "sparse_config": 86, "named_modul": 86, "append": 86, "tensor_fqn": 86, "sparse_block_shap": 86, "zeros_per_block": 86, "fakespars": 86, "manipul": 86, "dictionari": 86, "paramer": 86, "parameter": 86, "necessari": [86, 88], "ve": 86, "suitabl": 86, "fuse": [86, 88], "0s": 86, "spot": 86, "definit": 86, "academia": 86, "industri": 86, "often": [86, 88], "interchang": 86, "confus": 86, "distinct": 86, "behind": 86, "doesn": 86, "itself": [86, 88], "those": [86, 88], "loos": 86, "speak": 86, "tightli": 86, "coupl": [86, 88], "nvidia": 86, "csc": 86, "fbgemm": 86, "qnnpack": 86, "descript": 86, "coordin": 86, "vector": 86, "locat": 86, "bsr": 86, "sparse_bsr": 86, "except": [86, 88], "scalar": 86, "csr": 86, "sparse_csr": 86, "sparse_csc": 86, "column": 86, "compact": 86, "sparse_matrix": 86, "1d": 86, "indexptr": 86, "\u00bd": 86, "bitmask": 86, "2bit": 86, "unprun": 86, "quit": [86, 88], "successfulli": 86, "These": [86, 88], "broken": 86, "down": 86, "Not": 86, "sensit": 86, "effect": [86, 88], "subsequ": [86, 88], "infinit": 86, "lost": 86, "degre": 86, "analysi": 86, "drop": 86, "give": [86, 88], "proxi": 86, "aforement": 86, "smallest": 86, "absolut": 86, "global": [86, 88], "scope": 86, "impli": 86, "pro": 86, "con": 86, "tradeoff": 86, "span": 86, "threshold": 86, "increas": 86, "complex": 86, "constant": [86, 88], "ctr_mobile_fe": 86, "score": 86, "w": 86, "tenosr": 86, "udpat": 86, "cannot": 86, "histori": 86, "regrow": 86, "dw": 86, "via": 86, "backprop": 86, "pat": 86, "unmask": 86, "resid": 86, "salienc": 86, "lowest": 86, "l1": 86, "shown": 86, "abl": [86, 88], "repeat": 86, "shot": 86, "movement": 86, "tune": 86, "2005": 86, "07683": 86, "rank": [86, 88], "wx": 86, "sqx": 86, "q": 86, "usual": 86, "sort": 86, "wise": 86, "reconstruct": 86, "random": 86, "randomli": 86, "tri": 86, "remedi": 86, "item": [86, 91], "ultim": 86, "literatur": 86, "vision": 86, "nlp": [86, 91], "iter": 86, "ctr_feed": 86, "na": 86, "multimask": 86, "pyspeech": 86, "fastna": 86, "approach": [86, 88], "knowledg": [86, 91], "distil": 86, "pdf": 86, "2204": 86, "09656": 86, "arrang": 86, "recal": 86, "counterpart": 86, "slower": 86, "suffici": 86, "flexibl": [86, 88], "98": 86, "benefit": [86, 88], "special": 86, "exhibit": 86, "maintain": 86, "penalti": 86, "expens": [86, 88], "dictat": 86, "characterist": 86, "highest": 86, "wouldn": [86, 88], "visual": 86, "fig": 86, "4x4": 86, "benchmak": 86, "soon": 87, "foundat": 88, "extens": 88, "autograd": 88, "express": 88, "interpos": 88, "namespac": 88, "continu": 88, "seamlessli": 88, "obviou": 88, "int8quantizedlinear": 88, "few": 88, "finer": 88, "intercept": 88, "contrast": 88, "long": 88, "clunki": 88, "distributedlinear": 88, "duplic": 88, "bypass": 88, "offer": 88, "outer": 88, "inner": 88, "allgath": 88, "bandwidth": 88, "rest": 88, "read": 88, "document": 88, "zoo": 88, "podcast": 88, "edward": 88, "yang": 88, "begin": 88, "int8_symmetric_quant": 88, "fp32_tensor": 88, "127": 88, "amin": 88, "keepdim": 88, "amax": 88, "zeros_lik": 88, "clamp": 88, "quantizedlinear": 88, "w_int8": 88, "cl": 88, "new_linear": 88, "left": 88, "toymodel": 88, "float_model": 88, "quantized_model": 88, "child": 88, "named_children": 88, "setattr": 88, "drawback": 88, "won": 88, "suppos": 88, "clean": 88, "eleg": 88, "pretti": 88, "power": 88, "overrid": 88, "almost": 88, "shard": 88, "ragged": 88, "rag": 88, "nestedtensor": 88, "resourc": 88, "who": 88, "link": [88, 91], "googl": 88, "collab": 88, "flopcount": 88, "memorytrack": 88, "With": 88, "bare": 88, "bone": 88, "int8symmetrictensor": 88, "hold": 88, "staticmethod": 88, "disabl": 88, "__new__": 88, "_make_wrapper_subclass": 88, "storage_offset": 88, "ndim": 88, "__tensor_flatten__": 88, "attribut": 88, "pt2": 88, "__tensor_unflatten__": 88, "tensor_data_dict": 88, "extra_metadata": 88, "outer_s": 88, "outer_strid": 88, "undo": 88, "__repr__": 88, "repr": 88, "ahead": 88, "insid": 88, "int8_tensor": 88, "func": 88, "op_implementations_dict": 88, "conveni": 88, "register_op": 88, "_op": 88, "opoverload": 88, "impl_decor": 88, "op_impl": 88, "wrapper": 88, "particular": 88, "largest": 88, "tell": 88, "desugar": 88, "decor": 88, "surfac": 88, "coverag": 88, "though": 88, "brute": 88, "forc": 88, "repeatedli": 88, "loggingtensor": 88, "_python_dispatch": 88, "return_and_correct_alias": 88, "int8_mm": 88, "detach": 88, "int8_view_op": 88, "out_data": 88, "out_scal": 88, "notic": 88, "hit": 88, "background": 88, "decomposit": 88, "live": 88, "decomp": 88, "shrink": 88, "author": [88, 91], "pain": 88, "rather": 88, "underli": 88, "worth": 88, "written": 88, "differenti": 88, "nuanc": 88, "longer": 88, "That": 88, "transposit": 88, "got": 88, "propag": 88, "fact": 88, "themselv": 88, "pointwis": 88, "alwai": 88, "were": 88, "might": 88, "unwrap": 88, "dim0": 88, "dim1": 88, "confirm": 88, "quantized_model_module_swap": 88, "quantized_model_subclass": 88, "subclass_param": 88, "no_grad": 88, "out_module_swap": 88, "allclos": 88, "out_compil": 88, "seri": 88, "wa": 88, "tutorials_python": 89, "zip": [89, 91], "jupyt": [89, 91], "notebook": [89, 91], "tutorials_jupyt": 89, "sphinx": [89, 91], "firstnam": 91, "lastnam": 91, "prerequisit": 91, "v2": 91, "topic": 91, "rand": 91, "4242": 91, "9096": 91, "3368": 91, "0924": 91, "6098": 91, "8688": 91, "9662": 91, "4921": 91, "6789": 91, "4178": 91, "7013": 91, "2599": 91, "4521": 91, "1991": 91, "5131": 91, "practic": 91, "test": 91, "summar": 91, "takeawai": 91, "link1": 91, "link2": 91, "minut": 91, "ipynb": 91}, "objects": {"torchao.dtypes": [[8, 0, 1, "", "AffineQuantizedTensor"], [9, 0, 1, "", "BlockSparseLayout"], [10, 0, 1, "", "CutlassInt4PackedLayout"], [11, 0, 1, "", "CutlassSemiSparseLayout"], [12, 0, 1, "", "Float8Layout"], [13, 0, 1, "", "Int4CPULayout"], [14, 0, 1, "", "Layout"], [15, 0, 1, "", "MarlinQQQLayout"], [16, 0, 1, "", "MarlinQQQTensor"], [17, 0, 1, "", "MarlinSparseLayout"], [18, 0, 1, "", "NF4Tensor"], [19, 0, 1, "", "PlainLayout"], [20, 0, 1, "", "SemiSparseLayout"], [21, 0, 1, "", "TensorCoreTiledLayout"], [22, 0, 1, "", "UintxLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[8, 1, 1, "", "dequantize"], [8, 1, 1, "", "from_hp_to_floatx"], [8, 1, 1, "", "from_hp_to_floatx_static"], [8, 1, 1, "", "from_hp_to_fpx"], [8, 1, 1, "", "from_hp_to_intx"], [8, 1, 1, "", "from_hp_to_intx_static"], [8, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[17, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[18, 1, 1, "", "convert_to_norm_float_weight"], [18, 1, 1, "", "dequantize"], [18, 1, 1, "", "dequantize_scalers"], [18, 1, 1, "", "double_quantize_scalers"], [18, 1, 1, "", "get_original_weight"], [18, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingType"], [33, 2, 1, "", "convert_to_float8_training"], [34, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[35, 0, 1, "", "FPXWeightOnlyConfig"], [36, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [37, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [38, 0, 1, "", "Float8WeightOnlyConfig"], [39, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [40, 0, 1, "", "Int4WeightOnlyConfig"], [41, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [42, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [43, 0, 1, "", "Int8WeightOnlyConfig"], [44, 0, 1, "", "MappingType"], [45, 0, 1, "", "TorchAODType"], [46, 0, 1, "", "UIntXWeightOnlyConfig"], [47, 0, 1, "", "ZeroPointDomain"], [48, 2, 1, "", "autoquant"], [49, 2, 1, "", "choose_qparams_affine"], [50, 2, 1, "", "choose_qparams_affine_floatx"], [51, 2, 1, "", "choose_qparams_affine_with_min_max"], [52, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [53, 2, 1, "", "dequantize_affine"], [54, 2, 1, "", "dequantize_affine_floatx"], [55, 2, 1, "", "fake_quantize_affine"], [56, 2, 1, "", "fake_quantize_affine_cachemask"], [57, 2, 1, "", "int_scaled_matmul"], [66, 2, 1, "", "quantize_"], [67, 2, 1, "", "quantize_affine"], [68, 2, 1, "", "quantize_affine_floatx"], [69, 2, 1, "", "safe_int_mm"], [70, 2, 1, "", "smooth_fq_linear_to_inference"], [71, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [72, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[58, 0, 1, "", "ComposableQATQuantizer"], [59, 0, 1, "", "FakeQuantizeConfig"], [60, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [61, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [62, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [63, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [64, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [65, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizeConfig": [[59, 3, 1, "", "group_size"], [59, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[61, 1, 1, "", "convert"], [61, 1, 1, "", "prepare"]], "torchao": [[5, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[73, 0, 1, "", "PerChannelNormObserver"], [74, 0, 1, "", "WandaSparsifier"], [75, 2, 1, "", "apply_fake_sparsity"], [76, 2, 1, "", "int8_dynamic_activation_int8_semi_sparse_weight"], [77, 5, 1, "", "semi_sparse_weight"], [78, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[73, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[74, 1, 1, "", "prepare"], [74, 1, 1, "", "squash_mask"], [74, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:module", "5": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "module", "Python module"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 79, 81, 82], "dtype": [0, 7, 82], "layout": [0, 6, 14, 82], "tensor": [0, 6, 82, 87, 88], "subclass": [0, 6, 82, 88], "quantiz": [0, 4, 66, 82, 83, 87, 88], "techniqu": 0, "float8": [1, 81], "main": [1, 4], "train": [1, 82], "api": [1, 2, 4, 79, 81], "other": [1, 4, 6, 82], "type": 1, "refer": [2, 79], "python": 2, "kernel": [3, 6, 80, 82], "infer": 4, "quantize_": 4, "qat": 4, "primit": [4, 82], "sparsiti": [5, 86], "contributor": 6, "guid": [6, 83], "gener": 6, "extend": 6, "ad": [6, 82], "effici": [6, 82], "custom": 6, "triton": 6, "hand": 6, "written": 6, "dispatch": 6, "tensorimpl": [6, 82], "flow": [6, 82, 84], "us": 6, "torch": 6, "compil": 6, "perform": [6, 80], "serial": [6, 84], "featur": 6, "support": [6, 82], "function": [6, 82], "compos": 6, "test": 6, "microbenchmark": 6, "model": [6, 81, 82, 84], "benchmark": 6, "eval": 6, "affinequantizedtensor": 8, "blocksparselayout": 9, "cutlassint4packedlayout": 10, "cutlasssemisparselayout": 11, "float8layout": 12, "int4cpulayout": 13, "marlinqqqlayout": 15, "marlinqqqtensor": 16, "marlinsparselayout": 17, "nf4tensor": 18, "plainlayout": 19, "semisparselayout": 20, "tensorcoretiledlayout": 21, "uintxlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalingtyp": 32, "convert_to_float8_train": 33, "precompute_float8_dynamic_scale_for_fsdp": 34, "fpxweightonlyconfig": 35, "float8dynamicactivationfloat8weightconfig": 36, "float8staticactivationfloat8weightconfig": 37, "float8weightonlyconfig": 38, "gemliteuintxweightonlyconfig": 39, "int4weightonlyconfig": 40, "int8dynamicactivationint4weightconfig": 41, "int8dynamicactivationint8weightconfig": 42, "int8weightonlyconfig": 43, "mappingtyp": 44, "torchaodtyp": 45, "uintxweightonlyconfig": 46, "zeropointdomain": 47, "autoqu": 48, "choose_qparams_affin": 49, "choose_qparams_affine_floatx": 50, "choose_qparams_affine_with_min_max": 51, "choose_qparams_and_quantize_affine_hqq": 52, "dequantize_affin": 53, "dequantize_affine_floatx": 54, "fake_quantize_affin": 55, "fake_quantize_affine_cachemask": 56, "int_scaled_matmul": 57, "composableqatquant": 58, "fakequantizeconfig": 59, "fromintxquantizationawaretrainingconfig": 60, "int4weightonlyembeddingqatquant": 61, "int4weightonlyqatquant": 62, "int8dynactint4weightqatquant": 63, "intxquantizationawaretrainingconfig": 64, "initialize_fake_quant": 65, "quantize_affin": 67, "quantize_affine_floatx": 68, "safe_int_mm": 69, "smooth_fq_linear_to_infer": 70, "swap_linear_with_smooth_fq_linear": 71, "to_linear_activation_quant": 72, "perchannelnormobserv": 73, "wandasparsifi": 74, "apply_fake_spars": 75, "int8_dynamic_activation_int8_semi_sparse_weight": 76, "semi_sparse_weight": 77, "sparsifi": 78, "welcom": 79, "document": 79, "get": 79, "start": [79, 83], "develop": 79, "note": [79, 81], "tutori": [79, 91], "pretrain": 81, "torchtitan": 81, "prerequisit": 81, "rowwis": 81, "scale": 81, "tensorwis": 81, "pick": 81, "recip": 81, "import": 81, "directli": 81, "convers": 81, "overview": [82, 86, 91], "basic": 82, "current": 82, "placehold": 82, "pytorch": 82, "implement": [82, 88], "oper": [82, 88], "integr": 82, "nativ": 82, "factori": 82, "op": 82, "deriv": 82, "algorithm": 82, "weight": 82, "onli": 82, "dynam": 82, "activ": 82, "static": 82, "insert": 82, "observ": 82, "how": 82, "defin": 82, "modul": [82, 88], "add": 82, "calibr": 82, "awar": 82, "low": 82, "bit": 82, "optim": [82, 84], "case": 82, "studi": 82, "int4": 82, "work": 82, "dure": 82, "execut": 82, "save": 82, "load": 82, "quick": 83, "first": 83, "exampl": 83, "next": [83, 88], "step": [83, 88, 91], "deseri": 84, "what": [84, 88], "happen": 84, "when": 84, "an": 84, "comput": [85, 90], "time": [85, 90], "goal": 86, "design": 86, "context": 86, "prune": 86, "configur": 86, "criteria": 86, "strategi": 86, "pattern": 86, "write": [87, 88], "your": [87, 88], "own": [87, 88], "advanc": 87, "ar": 88, "swap": 88, "which": 88, "should": 88, "we": 88, "compar": 88, "output": 88, "templat": 91, "option": 91, "addit": 91, "exercis": 91, "conclus": 91, "further": 91, "read": 91}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})