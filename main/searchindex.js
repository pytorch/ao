Search.setIndex({"docnames": ["api_reference/api_ref_float8", "api_reference/api_ref_qat", "api_reference/api_ref_quantization", "api_reference/api_ref_sparsity", "api_reference/api_ref_utils", "api_reference/generated/torchao.float8.CastConfig", "api_reference/generated/torchao.float8.Float8LinearConfig", "api_reference/generated/torchao.float8.Float8LinearRecipeName", "api_reference/generated/torchao.float8.ScalingGranularity", "api_reference/generated/torchao.float8.ScalingType", "api_reference/generated/torchao.float8.convert_to_float8_training", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig", "api_reference/generated/torchao.quantization.FqnToConfig", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer", "api_reference/generated/torchao.quantization.qat.QATConfig", "api_reference/generated/torchao.quantization.qat.QATStep", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "api_reference/generated/torchao.quantization.quantize_", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "api_reference/generated/torchao.sparsity.PerChannelNormObserver", "api_reference/generated/torchao.sparsity.WandaSparsifier", "api_reference/generated/torchao.sparsity.apply_fake_sparsity", "api_reference/generated/torchao.sparsity.semi_sparse_weight", "api_reference/generated/torchao.sparsity.sparsify_", "api_reference/generated/torchao.utils.TorchAOBaseTensor", "api_reference/index", "contributing/benchmarking_api_guide", "contributing/contributor_guide", "contributing/index", "contributing/quantization_overview", "contributing/sparsity", "eager_tutorials/finetuning", "eager_tutorials/first_quantization_example", "eager_tutorials/index", "eager_tutorials/mxfp8_expert_parallel_training", "eager_tutorials/pretraining", "eager_tutorials/serialization", "eager_tutorials/serving", "eager_tutorials/static_quantization", "eager_tutorials/subclass_advanced", "eager_tutorials/subclass_basic", "eager_tutorials/torchao_hf_integration", "eager_tutorials/torchao_vllm_integration", "index", "performant_kernels", "pt2e_quantization/index", "pt2e_quantization/pt2e_quant_openvino_inductor", "pt2e_quantization/pt2e_quant_ptq", "pt2e_quantization/pt2e_quant_qat", "pt2e_quantization/pt2e_quant_x86_inductor", "pt2e_quantization/pt2e_quant_xpu_inductor", "pt2e_quantization/pt2e_quantizer", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "workflows/index", "workflows/inference", "workflows/qat", "workflows/training"], "filenames": ["api_reference/api_ref_float8.rst", "api_reference/api_ref_qat.rst", "api_reference/api_ref_quantization.rst", "api_reference/api_ref_sparsity.rst", "api_reference/api_ref_utils.rst", "api_reference/generated/torchao.float8.CastConfig.rst", "api_reference/generated/torchao.float8.Float8LinearConfig.rst", "api_reference/generated/torchao.float8.Float8LinearRecipeName.rst", "api_reference/generated/torchao.float8.ScalingGranularity.rst", "api_reference/generated/torchao.float8.ScalingType.rst", "api_reference/generated/torchao.float8.convert_to_float8_training.rst", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.FqnToConfig.rst", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.rst", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.rst", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.QATConfig.rst", "api_reference/generated/torchao.quantization.qat.QATStep.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.quantize_.rst", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.rst", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.rst", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "api_reference/generated/torchao.sparsity.PerChannelNormObserver.rst", "api_reference/generated/torchao.sparsity.WandaSparsifier.rst", "api_reference/generated/torchao.sparsity.apply_fake_sparsity.rst", "api_reference/generated/torchao.sparsity.semi_sparse_weight.rst", "api_reference/generated/torchao.sparsity.sparsify_.rst", "api_reference/generated/torchao.utils.TorchAOBaseTensor.rst", "api_reference/index.rst", "contributing/benchmarking_api_guide.md", "contributing/contributor_guide.rst", "contributing/index.rst", "contributing/quantization_overview.rst", "contributing/sparsity.rst", "eager_tutorials/finetuning.rst", "eager_tutorials/first_quantization_example.rst", "eager_tutorials/index.rst", "eager_tutorials/mxfp8_expert_parallel_training.rst", "eager_tutorials/pretraining.rst", "eager_tutorials/serialization.rst", "eager_tutorials/serving.rst", "eager_tutorials/static_quantization.rst", "eager_tutorials/subclass_advanced.rst", "eager_tutorials/subclass_basic.rst", "eager_tutorials/torchao_hf_integration.md", "eager_tutorials/torchao_vllm_integration.md", "index.rst", "performant_kernels.rst", "pt2e_quantization/index.rst", "pt2e_quantization/pt2e_quant_openvino_inductor.rst", "pt2e_quantization/pt2e_quant_ptq.rst", "pt2e_quantization/pt2e_quant_qat.rst", "pt2e_quantization/pt2e_quant_x86_inductor.rst", "pt2e_quantization/pt2e_quant_xpu_inductor.rst", "pt2e_quantization/pt2e_quantizer.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "workflows/index.md", "workflows/inference.md", "workflows/qat.md", "workflows/training.md"], "titles": ["torchao.float8", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "CastConfig", "Float8LinearConfig", "Float8LinearRecipeName", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MXDynamicActivationMXWeightConfig", "NVFP4DynamicActivationNVFP4WeightConfig", "NVFP4WeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt8WeightConfig", "Int8DynamicActivationIntxWeightConfig", "Int8WeightOnlyConfig", "IntxWeightOnlyConfig", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "API Reference", "Benchmarking API Guide", "Contributor Guide", "Contributing", "Quantization Overview", "Sparsity Overview", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "First Quantization Example", "Tutorials", "MXFP8 Expert Parallel Training", "(Part 1) Pre-training with float8", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "Welcome to the torchao Documentation", "Performant Kernels", "PT2E Quantization", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization", "&lt;no title&gt;", "Computation times", "Template Tutorial", "Workflows", "Quantized Inference", "Quantization-Aware Training (QAT)", "Quantized Training"], "terms": {"For": [1, 37, 58, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 90, 91, 92], "full": [1, 58, 65, 72, 75, 79, 80, 82, 88, 91], "exampl": [1, 10, 11, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 32, 36, 37, 39, 43, 48, 49, 54, 57, 58, 60, 61, 63, 64, 65, 67, 70, 71, 72, 74, 77, 79, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92], "how": [1, 16, 20, 37, 49, 50, 58, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 79, 80, 83, 84, 89], "us": [1, 5, 7, 9, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 32, 36, 37, 39, 44, 45, 49, 50, 54, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92], "our": [1, 61, 64, 65, 66, 69, 71, 72, 74, 77, 81, 82, 89, 91], "pleas": [1, 32, 36, 58, 61, 63, 64, 65, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 91, 92], "refer": [1, 39, 45, 60, 64, 65, 68, 69, 71, 72, 74, 75, 76, 80, 81, 82, 83, 90, 91, 92], "readm": [1, 60, 64, 65, 66, 77, 89], "class": [5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 53, 54, 58, 60, 61, 65, 66, 68, 70, 72, 74, 79, 81, 82, 83, 85, 91], "torchao": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 66, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 89, 90, 92], "float8": [5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 29, 30, 31, 52, 59, 67, 71, 72, 77, 89, 90], "scaling_typ": [5, 6], "scalingtyp": [5, 6], "dynam": [5, 6, 7, 9, 11, 13, 15, 16, 20, 21, 29, 35, 37, 45, 57, 61, 65, 68, 71, 72, 74, 75, 81, 82, 83, 90, 91, 92], "scaling_granular": [5, 6], "scalinggranular": [5, 6], "tensorwis": [5, 6, 7, 8, 10, 15, 63, 65], "target_dtyp": [5, 6, 63, 72], "option": [5, 6, 7, 10, 15, 18, 20, 21, 22, 23, 26, 27, 29, 30, 34, 36, 37, 39, 41, 42, 48, 49, 52, 54, 57, 58, 60, 61, 63, 66, 68, 69, 75, 76, 77, 79, 81, 82, 83, 84, 85], "dtype": [5, 10, 12, 15, 17, 21, 23, 26, 27, 29, 30, 33, 34, 35, 37, 41, 42, 44, 45, 52, 57, 60, 61, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 81, 83, 84, 85, 90, 91, 92], "none": [5, 6, 7, 8, 9, 10, 11, 15, 18, 21, 22, 23, 26, 27, 29, 30, 36, 37, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 54, 57, 58, 63, 65, 68, 72, 74, 76, 80, 81, 82, 84, 92], "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 71, 86, 88], "configur": [5, 6, 7, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 48, 57, 63, 65, 69, 71, 75, 83, 84, 85, 90, 91, 92], "cast": [5, 8, 9, 65, 68, 91, 92], "singl": [5, 8, 11, 15, 61, 64, 65, 68, 69, 81, 85, 90, 91, 92], "tensor": [5, 7, 8, 9, 13, 17, 19, 20, 21, 22, 23, 26, 27, 28, 30, 31, 38, 49, 50, 51, 52, 54, 58, 60, 64, 65, 66, 67, 68, 69, 70, 72, 75, 81, 83, 84, 88, 89], "paramet": [5, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 37, 39, 42, 44, 45, 48, 54, 57, 58, 60, 63, 64, 65, 68, 69, 70, 71, 74, 76, 80, 81, 91, 92], "The": [5, 10, 11, 15, 17, 18, 21, 23, 39, 48, 54, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 80, 81, 82, 83, 84, 85, 90, 91, 92], "type": [5, 6, 7, 8, 9, 10, 15, 17, 18, 20, 21, 23, 37, 40, 48, 49, 50, 51, 52, 58, 60, 61, 63, 64, 65, 66, 70, 71, 74, 76, 77, 80, 81, 83, 84, 85, 91], "scale": [5, 7, 8, 9, 11, 13, 15, 21, 23, 29, 30, 37, 42, 43, 44, 45, 52, 61, 63, 64, 68, 72, 74, 76, 85, 91], "see": [5, 21, 23, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 80, 81, 85, 89, 90, 91, 92], "default": [5, 7, 13, 15, 17, 19, 21, 29, 37, 45, 48, 58, 61, 63, 65, 69, 74, 76, 79, 80, 81, 82, 83, 84, 85], "granular": [5, 8, 15, 19, 20, 21, 22, 23, 26, 27, 29, 30, 37, 38, 61, 63, 68, 69, 71, 72, 76, 92], "target": [5, 15, 17, 19, 26, 27, 30, 37, 54, 60, 61, 64, 65, 79, 80, 81, 82, 83, 84, 85, 91], "e": [5, 18, 24, 37, 39, 48, 51, 58, 61, 63, 65, 69, 70, 72, 74, 75, 77, 80, 85, 90, 91], "g": [5, 18, 24, 37, 39, 48, 51, 58, 61, 63, 65, 70, 72, 74, 80, 85, 90, 91], "torch": [5, 6, 10, 12, 15, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 39, 41, 42, 44, 45, 48, 49, 57, 58, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 83, 84, 85, 88, 90, 91, 92], "float8_e4m3fn": [5, 12, 13, 15, 17, 30, 63], "set": [5, 15, 17, 19, 20, 22, 37, 48, 54, 58, 64, 65, 68, 80, 82, 83, 84, 91, 92], "base": [5, 9, 15, 18, 21, 23, 25, 38, 39, 43, 49, 51, 52, 54, 58, 61, 63, 64, 66, 74, 75, 76, 80, 81, 82, 83, 84, 85, 90, 91, 92], "recip": [5, 6, 7, 10, 26, 31, 41, 53, 65, 91, 92], "cast_config_input": 6, "config": [6, 10, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 30, 31, 32, 36, 37, 38, 39, 48, 54, 57, 60, 63, 64, 65, 66, 71, 72, 75, 76, 79, 81, 83, 84, 90, 91, 92], "castconfig": 6, "cast_config_input_for_grad_weight": 6, "cast_config_weight": 6, "cast_config_weight_for_grad_input": 6, "cast_config_grad_output": 6, "cast_config_grad_output_for_grad_weight": 6, "gemm_config_output": 6, "float8gemmconfig": 6, "use_fast_accum": 6, "true": [6, 10, 13, 14, 15, 17, 19, 20, 22, 26, 27, 36, 37, 39, 47, 48, 57, 58, 61, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 79, 80, 81, 82, 83, 85, 92], "gemm_config_grad_input": 6, "fals": [6, 10, 20, 26, 27, 35, 36, 37, 39, 41, 42, 44, 45, 54, 60, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 80, 81, 82, 84, 85, 90, 91, 92], "gemm_config_grad_weight": 6, "enable_fsdp_float8_all_gath": 6, "bool": [6, 10, 13, 14, 15, 17, 19, 20, 22, 26, 27, 35, 37, 41, 42, 44, 45, 47, 48, 57, 65, 72], "pad_inner_dim": 6, "emul": [6, 49], "force_recompute_fp8_weight_in_bwd": 6, "round_scales_to_power_of_2": 6, "convert": [6, 10, 24, 32, 33, 39, 48, 57, 63, 64, 65, 68, 69, 71, 80, 83, 84, 85, 91, 92], "nn": [6, 10, 15, 16, 17, 19, 20, 21, 22, 23, 24, 29, 33, 36, 39, 48, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 79, 81, 82, 83, 85, 90, 91, 92], "linear": [6, 10, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 34, 35, 36, 39, 44, 45, 46, 47, 48, 55, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 79, 80, 81, 82, 83, 85, 90, 91, 92], "modul": [6, 7, 8, 9, 10, 11, 12, 18, 24, 26, 28, 29, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 57, 60, 61, 63, 65, 66, 68, 69, 70, 72, 76, 79, 80, 81, 82, 83, 84, 85, 91, 92], "train": [6, 7, 10, 24, 37, 39, 61, 64, 67, 74, 79, 85], "static": [6, 37, 67, 79, 81, 82, 83, 84, 85, 92], "from_recipe_nam": [6, 10, 92], "recipe_nam": [6, 68, 69], "union": [6, 15, 30, 37, 48], "float8linearrecipenam": 6, "str": [6, 10, 18, 37, 39, 48, 54, 57, 58, 60, 68, 69, 74, 76, 84, 92], "input": [6, 10, 11, 13, 39, 43, 48, 54, 57, 60, 61, 63, 66, 68, 69, 71, 72, 74, 79, 80, 81, 82, 83, 84, 85, 92], "valu": [6, 7, 8, 9, 15, 17, 19, 20, 22, 30, 40, 49, 50, 54, 63, 64, 65, 72, 74, 80, 81, 82, 85, 91], "string": [6, 37, 54, 58, 60], "repres": [6, 25, 37, 50, 54, 61, 63, 70, 74, 81, 82, 91], "output": [6, 61, 63, 64, 65, 66, 69, 71, 75, 79, 80, 81, 82, 83, 84, 85, 88, 91, 92], "implement": [6, 19, 41, 42, 44, 45, 49, 58, 61, 63, 64, 65, 68, 70, 72, 80, 81, 85], "specifi": [6, 10, 18, 21, 22, 23, 24, 26, 27, 28, 31, 38, 39, 45, 48, 49, 54, 57, 61, 63, 64, 65, 69, 80, 81, 82, 85, 91, 92], "name": [7, 8, 9, 10, 18, 40, 48, 49, 50, 54, 57, 58, 60, 61, 63, 64, 68, 71, 74, 76, 80, 81, 82, 85, 92], "qualnam": [7, 8, 9, 40, 49, 50], "start": [7, 8, 9, 18, 40, 49, 50, 61, 63, 64, 65, 66, 68, 69, 71, 72, 74, 76, 80, 81, 82, 83, 84, 85], "1": [7, 8, 9, 10, 15, 17, 18, 19, 20, 21, 22, 23, 30, 40, 49, 50, 52, 54, 58, 61, 63, 64, 66, 67, 68, 70, 72, 74, 77, 79, 81, 82, 88, 89, 90, 91], "boundari": [7, 8, 9, 40, 49, 50], "pre": [7, 64, 65, 67, 68, 71, 77, 85], "made": [7, 85], "common": [7, 39, 49, 50, 51, 52, 59, 61, 63, 64, 69, 92], "per": [7, 13, 16, 17, 20, 21, 22, 29, 33, 34, 35, 37, 41, 42, 44, 45, 54, 61, 63, 64, 65, 69, 72, 84, 91, 92], "cubla": [7, 92], "kernel": [7, 13, 15, 16, 44, 48, 49, 64, 68, 71, 80, 83, 84, 90, 91], "fastest": [7, 61, 92], "rowwis": [7, 8, 10, 15, 29, 63, 89, 90], "cutlass": 7, "e4m3": 7, "activ": [7, 13, 15, 20, 21, 26, 27, 29, 35, 36, 37, 39, 45, 51, 52, 54, 60, 64, 65, 68, 71, 72, 75, 76, 77, 79, 80, 83, 84, 85, 89, 90, 91, 92], "weight": [7, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 33, 34, 35, 37, 39, 41, 42, 44, 45, 48, 51, 54, 57, 61, 64, 65, 69, 70, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 90, 91, 92], "gradient": [7, 64, 77, 91], "ar": [7, 10, 15, 18, 19, 21, 23, 24, 26, 27, 36, 39, 48, 49, 50, 54, 58, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 76, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92], "round": [7, 74, 91], "floor": 7, "nearest": 7, "power": [7, 74, 76], "two": [7, 15, 39, 58, 63, 64, 65, 74, 79, 80, 81, 82, 83, 85, 91, 92], "increas": [7, 64, 65, 68, 81, 92], "accuraci": [7, 64, 65, 66, 68, 69, 71, 72, 77, 80, 82, 83, 89, 91, 92], "rowwise_with_gw_hp": [7, 10], "A": [7, 8, 49, 53, 58, 61, 63, 64, 65, 74, 75, 76, 81, 91, 92], "modif": 7, "grad_weight": 7, "keep": [7, 20, 54, 61, 63, 81], "comput": [7, 8, 9, 11, 13, 17, 26, 31, 41, 49, 53, 54, 61, 63, 64, 68, 72, 74, 75, 81, 82, 83, 84, 90], "high": [7, 30, 39, 63, 64, 65, 69, 71, 72, 74, 80, 81, 83, 84, 90, 92], "precis": [7, 9, 17, 20, 29, 30, 34, 35, 39, 42, 44, 45, 63, 65, 72, 74, 75, 80, 83, 84, 90, 92], "most": [7, 39, 49, 61, 63, 64, 71, 76, 81, 82, 85, 91, 92], "accur": [7, 64, 69, 80, 92], "defin": [8, 9, 26, 31, 41, 53, 54, 58, 60, 61, 63, 64, 68, 72, 74, 76, 79, 80, 83, 84, 85], "strategi": [8, 92], "factor": [8, 9, 64, 68, 69], "entir": [8, 68, 71, 81, 82], "axiswis": 8, "along": [8, 13, 64, 68, 76, 80], "one": [8, 15, 21, 23, 26, 31, 39, 41, 53, 61, 63, 64, 68, 69, 74, 76, 82, 85, 91], "axi": [8, 21, 23, 72], "": [9, 13, 18, 49, 50, 58, 61, 63, 64, 65, 66, 68, 69, 71, 72, 74, 81, 82, 83, 84, 85, 90, 91, 92], "disabl": [9, 46, 74, 82], "skip": [9, 54, 63, 64], "thi": [9, 11, 12, 13, 15, 20, 21, 22, 26, 31, 32, 37, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 80, 81, 82, 83, 84, 85, 88, 89, 91, 92], "leav": [9, 37], "its": [9, 58, 64, 65, 74, 76, 81, 85, 92], "origin": [9, 17, 20, 32, 54, 60, 63, 64, 65, 66, 68, 70, 71, 80, 81, 85], "module_filter_fn": [10, 69, 92], "callabl": [10, 48, 57, 58, 76], "float8linearconfig": [10, 92], "swap": [10, 29, 33, 64, 65, 68, 69, 72, 82, 91], "float8linear": [10, 69, 92], "modifi": [10, 48, 54, 61, 64, 69, 74], "If": [10, 15, 20, 22, 36, 37, 39, 54, 58, 60, 61, 63, 64, 65, 71, 74, 81, 82], "onli": [10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 39, 45, 58, 60, 61, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 80, 81, 83, 84, 85, 90, 91, 92], "subclass": [10, 26, 31, 41, 49, 50, 53, 57, 58, 63, 64, 65, 66, 68, 70, 75], "pass": [10, 20, 26, 27, 31, 39, 41, 53, 58, 60, 63, 68, 72, 74, 76, 82, 85, 92], "filter": [10, 18, 61, 65, 69, 72, 91, 92], "function": [10, 26, 31, 41, 46, 47, 48, 53, 54, 55, 57, 58, 60, 63, 64, 65, 66, 68, 69, 70, 72, 74, 76, 79, 80, 85, 91, 92], "instanc": [10, 26, 31, 41, 48, 53, 57, 58, 70, 74, 81, 83, 84, 85], "fqn": [10, 18, 54, 57, 68, 69, 72, 92], "convers": [10, 61, 65, 91, 92], "return": [10, 37, 48, 57, 58, 60, 61, 63, 65, 66, 68, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 91, 92], "layer": [10, 15, 17, 18, 20, 22, 26, 27, 29, 33, 34, 35, 41, 42, 44, 45, 54, 55, 58, 60, 64, 68, 69, 71, 72, 74, 76, 80, 85, 91, 92], "import": [10, 15, 16, 17, 19, 20, 21, 22, 23, 32, 36, 39, 48, 57, 61, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 80, 83, 84, 88, 91, 92], "from": [10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 32, 36, 39, 48, 49, 57, 58, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 88, 91, 92], "creat": [10, 61, 64, 66, 68, 69, 74, 75, 80, 81, 83, 84, 85, 92], "model": [10, 11, 15, 16, 17, 19, 20, 21, 22, 23, 24, 29, 32, 33, 34, 35, 36, 39, 43, 48, 54, 55, 57, 58, 64, 65, 68, 72, 74, 79, 83, 84, 85, 89, 90, 91], "sampl": [10, 68, 69, 81, 83, 84, 92], "m": [10, 13, 48, 57, 60, 61, 65, 69, 70, 71, 72, 74, 79, 81, 82, 83, 91, 92], "sequenti": [10, 15, 16, 17, 19, 20, 21, 22, 23, 48, 57, 69, 92], "8192": [10, 68, 92], "4096": [10, 65, 69, 90, 91, 92], "bia": [10, 27, 44, 45, 60, 63, 65, 66, 70, 72, 74, 76, 82, 85, 92], "128": [10, 13, 16, 19, 66, 69, 71, 72, 74, 75, 76, 84, 85, 90, 91, 92], "bfloat16": [10, 29, 34, 44, 60, 63, 64, 66, 68, 69, 70, 71, 72, 75, 76, 83, 84, 89, 90, 91, 92], "cuda": [10, 15, 16, 17, 19, 20, 21, 22, 23, 48, 60, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 90, 91, 92], "optim": [10, 11, 21, 48, 61, 64, 65, 68, 69, 74, 80, 82, 83, 84, 91, 92], "sgd": [10, 65, 91, 92], "lr": [10, 65, 69, 91, 92], "0": [10, 13, 18, 21, 23, 26, 37, 41, 42, 54, 58, 60, 61, 63, 64, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 81, 82, 84, 85, 87, 88, 90, 91, 92], "being": [10, 64, 69, 76, 83, 84, 92], "elig": [10, 69, 92], "def": [10, 51, 57, 58, 60, 61, 63, 65, 66, 68, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 91, 92], "mod": [10, 46, 47, 64, 68, 69, 74, 92], "don": [10, 18, 54, 61, 63, 64, 66, 68, 69, 75, 76, 85, 92], "t": [10, 13, 18, 54, 58, 61, 63, 64, 66, 68, 69, 72, 74, 75, 76, 81, 82, 85, 90, 92], "last": [10, 69, 80, 92], "dimens": [10, 13, 60, 61, 63, 68, 69, 74, 76, 81, 82, 92], "divis": [10, 68, 69, 92], "16": [10, 13, 27, 65, 68, 69, 90, 91, 92], "isinst": [10, 57, 64, 68, 69, 72, 74, 76, 82, 85, 91, 92], "in_featur": [10, 27, 44, 45, 66, 69, 70, 72, 74, 92], "out_featur": [10, 27, 44, 45, 69, 72, 74, 92], "valid": [10, 21, 23, 58, 68, 71, 76, 85, 92], "enabl": [10, 47, 58, 60, 61, 63, 66, 68, 69, 71, 76, 83, 92], "compil": [10, 48, 63, 65, 66, 68, 69, 72, 74, 79, 83, 84, 90, 92], "competit": [10, 65, 68, 69, 92], "perform": [10, 11, 20, 21, 22, 26, 31, 33, 34, 35, 41, 53, 64, 65, 66, 68, 69, 72, 74, 75, 76, 80, 82, 83, 84, 91], "loop": [10, 64, 65, 69, 91, 92], "x": [10, 21, 23, 26, 27, 31, 38, 41, 60, 66, 68, 69, 70, 71, 72, 74, 76, 79, 80, 81, 82, 83, 84, 88, 92], "randn": [10, 27, 60, 65, 66, 68, 69, 70, 72, 74, 80, 81, 82, 83, 84, 91, 92], "devic": [10, 15, 16, 17, 19, 20, 21, 22, 23, 41, 44, 45, 48, 60, 61, 65, 66, 68, 69, 70, 71, 72, 74, 76, 80, 81, 82, 83, 84, 90, 92], "_": [10, 58, 61, 63, 66, 68, 69, 72, 76, 80, 81, 82, 83, 91, 92], "rang": [10, 64, 65, 66, 68, 69, 72, 81, 82, 91, 92], "10": [10, 26, 60, 61, 65, 66, 68, 69, 71, 72, 79, 81, 82, 90, 91, 92], "zero_grad": [10, 65, 69, 82, 91, 92], "y": [10, 92], "sum": [10, 11, 68, 81, 82, 92], "backward": [10, 11, 64, 65, 68, 69, 82, 91, 92], "step": [10, 11, 39, 40, 60, 63, 64, 65, 68, 69, 79, 80, 81, 82, 83, 84, 85, 91, 92], "calcul": [11, 15, 30, 63, 64, 68, 81, 85], "all": [11, 18, 26, 29, 31, 33, 41, 43, 53, 54, 55, 58, 61, 63, 64, 66, 70, 71, 72, 74, 76, 79, 80, 81, 83, 85, 86, 90, 92], "should": [11, 18, 26, 31, 32, 39, 41, 53, 54, 58, 61, 64, 65, 68, 69, 76, 80, 81, 85, 91], "run": [11, 12, 26, 27, 31, 41, 48, 49, 53, 61, 63, 64, 65, 69, 71, 74, 79, 80, 81, 82, 83, 84, 85, 88, 90, 91, 92], "after": [11, 61, 63, 64, 65, 69, 70, 75, 80, 81, 82, 83, 84, 85, 89, 91, 92], "It": [11, 64, 74, 79, 85], "reduc": [11, 39, 60, 61, 64, 65, 66, 69, 71, 83], "contain": [11, 51, 52, 60, 64, 74, 82, 85], "prototyp": [12, 13, 14, 37, 43, 58, 63, 68, 85, 89, 92], "mx_format": [12, 13, 14, 92], "block_siz": [12, 63, 72], "int": [12, 15, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 33, 34, 35, 37, 41, 42, 44, 45, 48, 54, 58, 60, 65, 68, 72, 74, 76], "32": [12, 19, 21, 27, 36, 37, 39, 41, 42, 48, 57, 65, 68, 69, 70, 71, 72, 74, 77, 82, 90, 91, 92], "activation_dtyp": [12, 15, 63], "weight_dtyp": [12, 15, 17, 21, 23, 63, 71], "kernel_prefer": [12, 15, 63], "kernelprefer": [12, 15], "auto": [12, 15, 49, 61, 71, 75, 76], "scaling_mod": 12, "scalecalculationmod": 12, "rceil": 12, "mx": [12, 68], "format": [12, 13, 18, 19, 21, 23, 50, 58, 61, 64, 71, 81, 82, 85], "infer": [12, 13, 39, 60, 63, 64, 65, 66, 70, 72, 74, 75, 77, 80, 81, 82, 83, 84, 91], "quantiz": [12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 57, 59, 60, 61, 62, 64, 67, 68, 69, 70, 89], "provid": [12, 24, 43, 58, 61, 63, 64, 65, 66, 69, 71, 74, 76, 81, 82, 84, 85, 89, 91], "support": [12, 15, 16, 18, 19, 21, 29, 36, 37, 39, 49, 51, 52, 57, 58, 60, 63, 64, 65, 66, 68, 69, 70, 71, 74, 80, 81, 82, 83, 84, 85, 89, 90, 91, 92], "requir": [12, 21, 49, 58, 60, 63, 64, 65, 66, 68, 71, 74, 75, 77, 79, 80, 83, 85, 90], "nvidia": [12, 13, 60, 64], "sm100": 12, "hardwar": [12, 15, 49, 50, 61, 64, 66, 71, 75, 79, 90, 92], "blackwel": [12, 65], "newer": [12, 65], "i": [12, 13, 15, 16, 17, 18, 19, 20, 21, 36, 37, 39, 48, 51, 52, 54, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92], "execut": [12, 48, 67, 74, 87], "pytorch": [12, 37, 58, 60, 63, 64, 65, 68, 69, 71, 74, 76, 79, 88, 90, 92], "2": [12, 15, 17, 18, 19, 20, 21, 22, 23, 26, 37, 41, 42, 55, 57, 61, 63, 64, 66, 67, 68, 69, 72, 74, 79, 88, 89, 90, 91], "5": [12, 26, 54, 61, 64, 65, 71, 76, 79, 81, 82, 88, 90, 91, 92], "proper": 12, "serial": [12, 58, 63, 67, 75, 81, 82], "use_triton_kernel": [13, 76], "use_dynamic_per_tensor_scal": [13, 14], "fp4": 13, "nvfp4": [13, 63, 65, 89, 90, 91], "special": [13, 64, 80, 81], "whether": [13, 37, 58, 61, 65, 74], "fuse": [13, 64, 74, 79, 82, 91], "triton": [13, 63, 68, 83, 84], "data": [13, 15, 17, 20, 50, 58, 60, 63, 64, 65, 68, 70, 72, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 89], "float4_e2m1fn_x2": [13, 63], "block": [13, 54, 64, 68, 89], "size": [13, 19, 22, 37, 60, 61, 64, 68, 69, 70, 71, 72, 74, 76, 82, 90, 91, 92], "reduct": [13, 64, 66, 70, 71, 74], "dim": [13, 20, 22, 30, 68, 72, 74, 76, 81, 82], "note": [13, 18, 21, 23, 24, 36, 45, 54, 58, 60, 61, 63, 64, 65, 66, 68, 71, 74, 76, 77, 82, 83, 84, 90, 92], "work": [13, 60, 61, 62, 64, 65, 69, 70, 74, 75, 76, 81, 82, 83], "mode": [13, 60, 61, 66, 67, 68, 72, 80, 82, 83, 84, 85], "ha": [13, 39, 58, 61, 64, 65, 68, 71, 74, 76, 80, 81, 82, 84, 85], "constraint": [13, 81, 82, 85], "must": [13, 18, 21, 23, 24, 37, 39, 45, 64, 68, 69, 75, 76, 82, 84, 85], "satisfi": [13, 64], "k": [13, 60, 61, 70, 72, 74, 81, 82, 92], "64": [13, 19, 29, 70, 71, 72, 74, 76, 90, 91], "Will": 13, "automat": [13, 39, 58, 68, 69, 71, 74, 75, 76, 88, 91], "fallback": [13, 18, 76], "when": [13, 18, 21, 39, 58, 60, 61, 63, 64, 65, 68, 69, 71, 72, 75, 76, 80, 81, 82, 83, 84, 85, 92], "aren": 13, "met": 13, "pertensor": [15, 22, 30, 72, 92], "perrow": [15, 20, 22, 30, 63], "list": [15, 24, 54, 58, 66, 68, 74, 75, 76, 80, 82, 85], "packing_format": [15, 19], "float8packingformat": 15, "plain": [15, 19, 50, 58, 63, 76], "mm_config": 15, "float8mmconfig": 15, "activation_value_lb": 15, "float": [15, 26, 30, 37, 41, 42, 54, 63, 65, 70, 74, 79, 81, 82, 85, 91], "activation_value_ub": 15, "set_inductor_config": [15, 17, 19, 20, 22], "version": [15, 17, 18, 19, 20, 21, 22, 23, 37, 49, 58, 63, 65, 68, 74, 76, 77, 81, 82, 85, 91, 92], "appli": [15, 16, 17, 18, 20, 22, 24, 28, 29, 31, 36, 38, 39, 48, 57, 58, 61, 63, 64, 65, 68, 71, 76, 82, 90, 91], "symmetr": [15, 17, 20, 21, 22, 23, 26, 29, 37, 65, 74, 80, 81, 84, 85, 91], "both": [15, 19, 39, 45, 63, 64, 66, 68, 72, 74, 79, 81, 83, 84, 85, 91, 92], "fp8granular": [15, 30], "can": [15, 24, 37, 48, 49, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 80, 81, 82, 83, 84, 85, 90, 91, 92], "either": [15, 30, 39, 54, 61, 64, 71, 82, 83, 84], "tupl": [15, 43, 54, 58, 68, 74, 76, 81, 82, 85], "current": [15, 19, 29, 30, 39, 48, 54, 57, 60, 63, 64, 68, 69, 74, 75, 76, 79, 81, 82, 84, 91, 92], "need": [15, 26, 31, 41, 50, 51, 52, 53, 54, 58, 60, 61, 63, 64, 65, 68, 70, 71, 74, 76, 81, 82, 83, 85], "same": [15, 19, 21, 45, 57, 58, 63, 64, 65, 69, 72, 74, 82, 84, 85, 91], "And": [15, 74, 83, 85], "matrix": [15, 49, 54, 60, 63, 64, 68, 83, 92], "multipl": [15, 24, 49, 51, 58, 60, 61, 63, 64, 65, 68, 72, 74, 76, 83, 85, 91], "fast": [15, 64], "accumul": [15, 68, 91], "lower": [15, 30, 63, 64, 65, 71, 72, 75, 79, 82, 91], "bound": [15, 30, 61, 64, 71, 76, 92], "upper": [15, 30], "prefer": [15, 63, 65, 74], "op": [15, 48, 49, 58, 61, 64, 65, 68, 74, 76, 79, 81, 82, 83, 85, 91, 92], "like": [15, 21, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 74, 75, 76, 80, 81, 82, 83, 84, 85, 90], "matmul": [15, 17, 63, 64, 74], "group": [15, 16, 22, 29, 33, 34, 35, 37, 41, 42, 44, 45, 49, 60, 61, 65, 91], "etc": [15, 26, 27, 49, 50, 52, 60, 61, 63, 80, 85], "defalut": 15, "chosen": [15, 49, 52, 64], "user": [15, 24, 39, 45, 49, 58, 60, 61, 63, 64, 65, 69, 71, 72, 74, 79, 81, 82, 83, 84, 85, 88, 91], "other": [15, 21, 38, 49, 54, 58, 60, 64, 65, 69, 70, 71, 74, 76, 77, 81, 82, 83, 85, 88], "inform": [15, 58, 60, 63, 64, 71, 76, 80, 81], "adjust": [15, 17, 19, 20, 22, 65, 68], "torchinductor": [15, 17, 19, 20, 22, 83, 84], "recommend": [15, 17, 19, 20, 22, 61, 63, 65, 66, 68, 69, 75, 77, 80, 83, 84, 89], "deprec": [15, 17, 18, 20, 32, 36, 58], "float8tensor": [15, 17, 30, 51, 61, 63, 76], "quantize_": [15, 16, 17, 19, 20, 21, 22, 23, 32, 36, 39, 48, 49, 50, 51, 52, 57, 59, 60, 61, 63, 65, 66, 70, 71, 72, 77, 90, 92], "2048": [15, 16, 17, 19, 20, 21, 22, 23, 65, 68, 69, 90, 91, 92], "int4_packing_format": [16, 19, 77], "int4packingformat": [16, 19], "preshuffl": [16, 63], "row": [16, 60, 61, 63, 64, 69], "int4": [16, 19, 21, 26, 27, 29, 33, 34, 35, 36, 37, 39, 41, 42, 44, 45, 48, 61, 63, 65, 70, 71, 75, 76, 77, 89, 90, 91], "group_siz": [16, 19, 21, 22, 26, 27, 29, 33, 36, 37, 39, 41, 42, 48, 60, 65, 75, 76, 77, 91], "right": [16, 19, 61, 64, 68, 81], "now": [16, 19, 60, 61, 63, 64, 65, 66, 68, 69, 72, 74, 75, 80, 81, 83, 85, 91], "sinc": [16, 18, 26, 31, 41, 53, 58, 63, 64, 70, 71, 72, 74, 81, 82, 83, 84, 85], "underli": [16, 71, 74], "abov": [16, 21, 23, 58, 61, 63, 64, 65, 68, 70, 72, 74, 81, 82, 85, 90, 91, 92], "benefit": [16, 64, 65, 68, 74, 81, 84], "make": [16, 61, 63, 74, 76, 79, 81, 85, 92], "bigger": 16, "pack": [16, 19, 21, 23, 50, 61], "channel": [17, 20, 22, 29, 33, 34, 35, 37, 41, 42, 44, 45, 53, 72, 84], "actual": [17, 39, 49, 63, 65, 68, 72, 74, 76, 81, 82, 85, 90, 91], "fqn_to_config": 18, "ordereddict": 18, "core": [18, 48, 72, 76, 81, 90], "aobaseconfig": [18, 39, 48, 57, 60, 72, 76], "factori": 18, "module_fqn_to_config": 18, "differ": [18, 19, 24, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 81, 82, 83, 85, 89, 91, 92], "fulli": [18, 48, 57, 64, 71, 81], "qualifi": [18, 48, 57, 64], "an": [18, 36, 37, 39, 45, 54, 58, 63, 64, 65, 69, 71, 72, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 89, 90, 92], "order": [18, 24, 58, 61, 64, 68, 74, 85], "dictionari": [18, 64], "regex": [18, 80], "python": [18, 58, 60, 61, 64, 71, 79, 80, 81, 83, 84, 86, 88, 92], "re": [18, 61, 63, 68, 69, 70, 71, 74, 81, 82], "prefix": 18, "3": [18, 26, 63, 64, 67, 68, 69, 75, 77, 79, 81, 82, 88, 90, 91, 92], "_default": [18, 71, 76], "we": [18, 19, 20, 36, 37, 39, 45, 48, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 90, 92], "want": [18, 48, 57, 61, 63, 64, 70, 74, 76, 79, 80, 81, 82, 85, 92], "param": [18, 23, 54, 68, 71], "kei": [18, 54, 64, 68, 88], "preced": [18, 68, 80, 81, 83, 84], "languag": [18, 71], "q_proj": [18, 76, 91], "first": [18, 39, 54, 58, 61, 63, 67, 68, 71, 72, 74, 75, 76, 77, 81, 82, 85, 91, 92], "match": [18, 44, 45, 58, 64, 81], "whichev": 18, "kept": 18, "consist": [18, 60, 64, 71, 74, 83, 84, 85], "previou": [18, 63, 71, 81, 82, 83, 84], "subset": [18, 21, 23, 63], "some": [18, 48, 54, 58, 61, 63, 64, 68, 71, 72, 74, 79, 80, 81, 82, 83, 84, 85], "better": [18, 20, 22, 66, 69, 74, 81, 82, 83, 84, 85, 92], "befor": [18, 39, 48, 61, 63, 64, 65, 68, 70, 71, 72, 74, 81, 82, 85, 91, 92], "hand": [18, 68], "them": [18, 26, 31, 41, 53, 60, 65, 85, 91], "norm": [18, 53, 54, 64], "linear_config": [18, 71], "filter_fn": [18, 48, 57, 91], "To": [18, 45, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 76, 77, 81, 82, 83, 85, 90, 91, 92], "maintain": [18, 58, 64, 71], "bc": [18, 58], "modulefqntoconfig": 18, "later": [18, 58, 63, 65, 68, 74, 81, 82, 84], "pattern": [18, 63, 68, 76, 79, 80, 81], "mai": [18, 37, 50, 61, 63, 68, 70, 72, 75, 81, 82, 83, 84, 85, 90, 91], "matter": [18, 63, 64], "ignor": [18, 26, 31, 41, 53, 69, 81, 82], "replac": [18, 64, 65, 76], "int4_choose_qparams_algorithm": [19, 77], "int4chooseqparamsalgorithm": 19, "tinygemm": [19, 44, 48, 91], "groupwis": [19, 21, 23, 90], "although": [19, 26, 31, 41, 53, 65, 74], "In": [19, 39, 61, 63, 64, 65, 66, 68, 69, 72, 74, 80, 81, 82, 83, 84, 85, 90, 91, 92], "mainli": [19, 63, 80, 83, 85], "distinguish": [19, 63], "arg": [19, 21, 23, 26, 27, 28, 29, 33, 42, 54, 58, 61, 63, 74, 76, 82, 85], "layout": [19, 20, 21, 57, 58, 64, 68], "control": [19, 20, 54, 64, 76, 81], "smaller": [19, 65, 66, 70, 91], "more": [19, 21, 23, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 74, 75, 76, 77, 80, 81, 82, 83, 84, 91, 92], "fine": [19, 64, 67, 68, 69, 71, 91], "grain": [19, 74], "choic": [19, 61], "256": [19, 33, 34, 35, 44, 45, 71, 81, 82, 85, 90], "variant": [19, 74], "choos": [19, 21, 23, 52, 61, 63, 64, 74, 81, 83], "qparam": 19, "algorithm": [19, 21, 23, 61, 64, 71, 80, 89], "hqq": [19, 63, 77, 89], "tile_packed_to_4d": [19, 77], "plainlayout": [20, 58, 72], "act_mapping_typ": [20, 21], "mappingtyp": [20, 21, 23, 37, 72], "weight_only_decod": 20, "int8": [20, 21, 22, 23, 27, 35, 36, 37, 39, 45, 48, 52, 57, 63, 65, 66, 71, 74, 81, 83, 84, 85, 89, 90, 91, 92], "token": [20, 21, 35, 37, 45, 65, 68, 69, 71, 75, 90, 91, 92], "store": [20, 51, 53, 58, 63, 64, 75, 76, 81, 82], "access": [20, 61, 80], "map": [20, 21, 23, 37, 58, 63, 65, 74, 81, 85], "around": [20, 63, 69, 70, 79, 81], "zero": [20, 21, 23, 37, 42, 43, 44, 45, 54, 64, 68, 72, 85, 91], "dure": [20, 37, 39, 64, 65, 68, 69, 71, 72, 74, 79, 80, 82, 91], "forward": [20, 26, 27, 31, 38, 41, 44, 53, 60, 64, 66, 68, 70, 72, 74, 76, 79, 81, 82, 83, 92], "decod": [20, 71, 90], "oper": [20, 61, 63, 65, 71, 79, 80, 81, 82, 83, 84, 91], "scheme": [20, 22, 26, 27, 39, 65, 71, 80], "affinequantizedtensor": [20, 61, 70, 72, 74], "plan": [20, 61, 82, 89], "split": [20, 68, 71, 81, 82], "int8tensor": [20, 63, 66], "weight_granular": [21, 63, 71], "pergroup": [21, 23, 37, 71], "weight_mapping_typ": 21, "weight_scale_dtyp": [21, 71], "asymmetr": [21, 23, 37, 65, 72, 80, 84, 85, 91], "intx_packing_format": [21, 23], "intxpackingformat": [21, 23], "unpacked_to_int8": [21, 23], "intx_choose_qparams_algorithm": [21, 23], "intxchooseqparamsalgorithm": [21, 23], "affin": [21, 23, 63, 68], "intx": [21, 23, 89, 90], "8": [21, 23, 26, 27, 34, 44, 63, 65, 68, 69, 71, 76, 83, 84, 90, 91, 92], "specif": [21, 26, 27, 45, 50, 54, 58, 60, 61, 63, 64, 65, 68, 69, 70, 71, 75, 80, 83, 84, 85, 91, 92], "bit": [21, 23, 38, 60, 65, 71, 74, 75, 76, 81, 83, 84, 90, 91], "channelwis": [21, 23], "manner": [21, 23], "number": [21, 23, 29, 42, 44, 45, 54, 64, 71, 74, 82, 83], "ident": [21, 64, 69], "int8dynamicactivationint4weightconfig": [21, 39, 45, 65, 90, 91], "howev": [21, 64, 68, 75, 76, 82, 85], "gener": [21, 26, 27, 28, 31, 38, 60, 63, 64, 65, 66, 71, 72, 74, 76, 80, 82, 83, 84, 85, 86, 88, 90, 91], "where": [21, 23, 33, 34, 35, 60, 63, 64, 68, 76, 85], "peraxi": [21, 23, 37, 71, 72], "zeropointdomain": [21, 37], "intend": [21, 49, 63, 68, 81], "export": [21, 63, 79], "applic": [21, 71], "executorch": [21, 61, 67, 75, 79, 81, 82], "opaque_torchao_auto": 21, "cpu": [21, 60, 61, 64, 68, 70, 72, 75, 76, 77, 80, 81, 82, 83, 90], "detail": [21, 23, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 74, 77, 80, 81, 82, 83, 89, 90, 91, 92], "otherwis": [22, 24, 37, 82], "mapping_typ": [23, 37], "scale_dtyp": [23, 72], "qat": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 59, 67, 71, 77, 79, 83], "twostepquant": 24, "compos": [24, 63, 64, 65, 74, 81, 82, 85, 92], "easili": [24, 80], "thei": [24, 64, 68, 69, 74, 75, 79, 81, 82, 85], "constructor": [24, 58, 74], "embed": [24, 26, 33, 36, 39, 41, 42, 91], "behavior": [24, 76, 81, 82, 92], "undefin": [24, 54], "usag": [24, 26, 27, 32, 36, 37, 39, 58, 65, 67, 68, 69, 71, 83, 84, 91], "my_quant": 24, "qatquantizer1": 24, "qatquantizer2": 24, "qatquantizer3": 24, "prepar": [24, 29, 33, 39, 54, 64, 65, 80, 83, 84, 85, 91], "fake": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 65, 68, 69, 81, 82, 85, 91, 92], "num_embed": [26, 41, 42], "embedding_dim": [26, 41, 42], "padding_idx": [26, 41, 42], "max_norm": [26, 41, 42], "norm_typ": [26, 41, 42], "scale_grad_by_freq": [26, 41, 42], "spars": [26, 41, 42, 54, 64], "weight_config": [26, 27, 36, 39, 91], "fakequantizeconfigbas": [26, 27, 36, 39], "kwarg": [26, 27, 28, 29, 33, 37, 42, 52, 53, 54, 55, 58, 60, 61, 63, 74, 76], "through": [26, 27, 60, 61, 63, 65, 66, 71, 72, 74, 76, 79, 80, 81, 85, 88, 91, 92], "separ": [26, 27, 37, 64, 65, 76, 81, 85], "intxfakequantizeconfig": [26, 27, 36, 38, 39, 91], "fq_embed": 26, "longtensor": 26, "everi": [26, 31, 41, 53, 64, 74, 81, 82], "call": [26, 31, 41, 53, 58, 61, 63, 64, 65, 70, 72, 74, 76, 82, 84, 91], "overridden": [26, 31, 41, 53], "within": [26, 31, 41, 53, 64, 71, 76, 83, 84], "afterward": [26, 31, 41, 53], "instead": [26, 31, 32, 36, 37, 39, 41, 53, 64, 65, 68, 69, 74, 79, 82, 83, 84, 85], "former": [26, 31, 41, 53], "take": [26, 31, 41, 48, 53, 57, 58, 63, 64, 80, 81, 82, 83, 84, 85], "care": [26, 31, 41, 53, 64, 70, 81], "regist": [26, 31, 41, 53, 58, 61, 63, 74], "hook": [26, 31, 41, 53, 63], "while": [26, 31, 39, 41, 51, 53, 54, 64, 65, 66, 71, 74, 75, 80, 81, 85, 91], "latter": [26, 31, 41, 53, 82], "silent": [26, 31, 41, 53, 83], "activation_config": [27, 36, 39, 91], "per_token": [27, 36, 37, 39, 91], "is_symmetr": [27, 36, 37, 39, 91], "fq_linear": 27, "ani": [28, 29, 33, 43, 54, 61, 63, 64, 74, 80, 82, 84], "scale_precis": [29, 33, 37, 41, 42], "element": [29, 42, 44, 45, 58, 63, 64], "each": [29, 37, 42, 44, 45, 53, 58, 61, 63, 64, 72, 74, 76, 81, 82, 85, 90, 91], "fakequantizedlinear": [29, 32, 46, 47, 65, 91], "hp_value_lb": 30, "hp_value_ub": 30, "point": [30, 37, 42, 43, 44, 45, 63, 64, 66, 69, 70, 72, 74, 79, 81, 85, 91, 92], "float8fakequantizeconfig": 31, "qatconfig": [32, 36, 40, 65, 91], "fakequantizedembed": 32, "back": [32, 68, 74], "correspond": [32, 39, 48, 60, 63, 64, 65, 70, 74, 84, 85, 91], "without": [32, 63, 64, 65, 68, 76, 83, 85, 91], "model_with_fake_quantized_linear": 32, "float32": [33, 35, 37, 41, 42, 45, 64, 65, 70, 71, 72, 74, 83, 84, 85], "zero_point_precis": [33, 37, 41, 42], "int32": [33, 37, 41, 42, 63, 68, 81, 85], "have": [33, 34, 35, 50, 54, 61, 63, 64, 65, 68, 72, 74, 76, 80, 81, 82, 83, 84, 85, 89, 90, 91, 92], "int4weightonlyqatembed": 33, "int4weightonlyembed": 33, "groupsiz": [34, 35, 44, 45, 65, 91], "inner_k_til": [34, 44], "scales_precis": [34, 35, 44, 45], "padding_allow": 35, "rais": [36, 39, 74, 76], "valueerror": [36, 39], "torchaodtyp": 37, "zero_point_domain": 37, "is_dynam": [37, 83, 84, 85], "range_learn": 37, "ep": [37, 68, 72, 82, 84, 85], "integ": [37, 38, 65, 72, 81, 82, 83], "up": [37, 48, 63, 64, 65, 68, 69, 80, 81, 82, 85, 91, 92], "simul": [37, 39, 55, 64, 91], "older": [37, 58], "than": [37, 63, 64, 65, 66, 68, 69, 74, 81, 92], "6": [37, 63, 64, 68, 69, 71, 77, 81, 82, 83, 90], "you": [37, 54, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 80, 81, 82, 83, 84, 85, 88, 90, 91, 92], "int1": [37, 63], "int7": [37, 63], "also": [37, 48, 61, 63, 64, 65, 66, 68, 70, 72, 74, 75, 76, 81, 84, 85, 89, 91], "follow": [37, 39, 58, 61, 63, 64, 65, 68, 69, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92], "equival": [37, 64, 65, 68, 82, 83, 85, 91, 92], "pertoken": 37, "per_channel": 37, "per_group": 37, "combin": [37, 64, 71, 74, 81, 83, 92], "altern": [37, 65, 72, 74, 83, 84, 91], "just": [37, 61, 63, 64, 68, 70, 74, 81, 82, 85], "field": [37, 40, 85], "empti": [37, 63, 68], "fp32": [37, 45, 72, 74, 81, 83], "domain": [37, 65, 69], "learn": [37, 64, 66, 81, 83, 84, 85, 88, 91], "compat": [37, 60, 61, 77, 92], "keyword": [37, 39, 51, 63], "argument": [37, 39, 48, 51, 58, 63, 69, 71, 83], "properti": [37, 38], "throw": 37, "error": [37, 69, 74, 81, 90], "els": [37, 63, 68, 71, 76, 81, 82], "width": [38, 60, 91], "symmetri": 38, "base_config": [39, 65, 91], "qatstep": 39, "awar": [39, 54, 64, 74, 79, 89], "here": [39, 45, 60, 63, 68, 70, 71, 72, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 88, 91], "numer": [39, 44, 45, 49, 64, 65, 68, 69, 81, 82, 83, 91, 92], "arithmet": [39, 65], "bf16": [39, 60, 64, 65, 83, 84, 91, 92], "goal": [39, 65], "eventu": [39, 65, 69], "degrad": [39, 64, 65, 77], "There": [39, 63, 65, 68, 72, 74, 81, 85, 92], "wai": [39, 61, 63, 64, 68, 69, 71, 72, 74, 81, 82, 85, 91, 92], "involv": [39, 64, 65, 68, 91], "post": [39, 63, 66, 68, 74, 79, 82, 85, 91], "ptq": [39, 82, 83, 89, 91], "which": [39, 44, 49, 58, 60, 61, 63, 64, 65, 68, 69, 70, 71, 72, 76, 80, 81, 82, 83, 84, 85, 91], "phase": [39, 85], "case": [39, 49, 60, 61, 64, 71, 74, 76, 80, 81, 85, 90, 91], "train_loop": [39, 65, 91], "int4weightonlyconfig": [39, 48, 70, 75, 76, 77, 90, 91], "second": [39, 58, 63, 68, 69, 85, 88, 90, 92], "directli": [39, 63, 64, 65, 72, 74], "mostli": [39, 79], "experiment": [39, 80, 90, 91], "doe": [39, 49, 50, 58, 61, 63, 64, 65, 68, 74, 81, 83, 84, 91], "exist": [39, 61, 63, 64, 69, 72, 74, 81, 85], "yet": [39, 65, 68, 74, 76, 82, 83, 84], "qat_config": [39, 91], "act_config": 39, "custom": [39, 53, 58, 60, 63, 64, 65, 68, 69, 74, 76, 77, 80, 81, 83, 85, 91], "alwai": [39, 71, 74], "One": [39, 64, 74, 76, 85], "determin": [39, 64, 69, 76], "enum": [40, 49, 58], "output_dtyp": 41, "example_input": [43, 66, 70, 72, 79, 80, 81, 82, 83, 84, 85], "initi": [43, 63, 65, 68, 70, 79, 82], "intxfakequantizerbas": 43, "weightonlyint4linear": 44, "effici": [44, 49, 64, 65, 68, 72, 84, 90, 91], "hardcod": [45, 85, 91], "allow": [45, 61, 63, 64, 74, 79, 80, 81, 82, 83, 85, 91], "get": [45, 58, 61, 63, 64, 65, 66, 69, 71, 76, 79, 80, 81, 82, 83, 85], "exact": [45, 65, 81, 82], "helper": [46, 47, 58, 61], "_is_linear": [48, 72], "inplac": [48, 54, 66], "workflow": [48, 49, 57, 60, 61, 64, 66, 68, 69, 79, 85, 92], "object": [48, 57, 58, 61, 63, 74, 81, 82, 85], "move": [48, 61, 68, 72, 76, 82, 83], "speed": [48, 64, 65, 71, 80], "final": [48, 63, 64, 66, 80, 81, 82, 83, 84, 85, 91], "do": [48, 61, 63, 64, 68, 71, 72, 74, 76, 81, 82, 83, 85, 90], "chang": [48, 61, 64, 66, 69, 70, 71, 72, 74, 80, 81, 82, 84, 85], "predefin": [48, 50, 58, 85], "method": [48, 54, 58, 60, 61, 64, 68, 72, 74, 75, 79, 80, 81, 82, 84, 85], "path": [48, 65, 66, 71, 79, 80, 81, 82, 83, 85, 92], "customiz": [48, 65], "int8dynamicactivationint8weightconfig": [48, 57, 66, 75, 90], "mm": [48, 49, 61, 68, 74, 81], "int8weightonlyconfig": [48, 65, 75, 76, 90], "quant_api": [48, 61, 70, 71, 72, 92], "1024": [48, 57, 60, 66, 70, 83], "affect": [49, 58, 64], "select": [49, 81], "found": [49, 63, 64, 66, 71, 72, 74, 90], "under": [49, 61, 65, 71, 90], "librari": [49, 50, 61, 63, 70, 77], "avail": [49, 50, 60, 61, 63, 71, 80, 81, 82, 83, 84, 89], "gemm_lowp": 49, "b": [49, 58], "gemm_fp32": 49, "dequant": [49, 63, 68, 74, 76, 79, 81, 83, 84, 85, 91], "ci": [49, 90], "product": [49, 54, 66, 71, 76, 83, 85], "logic": [49, 66, 74, 76], "lowp": 49, "gemm": [49, 69, 83, 84, 92], "debug": [49, 61, 68], "issu": [49, 63, 66, 68, 74, 83, 90], "mslk": [49, 61, 63], "nativ": [49, 63, 68, 69, 74, 81, 92], "laid": [50, 63], "out": [50, 54, 60, 61, 63, 64, 65, 66, 68, 69, 71, 74, 79, 80, 81, 82, 83, 90, 92], "opaqu": 50, "decid": [50, 64, 72], "shape": [50, 58, 60, 61, 63, 68, 72, 74, 76, 81, 84, 92], "rest": [50, 60, 74, 82], "system": [50, 60, 61, 71, 92], "understand": [50, 61, 69, 83, 85], "adopt": [50, 63], "creation": [51, 76], "construct": [51, 63, 81, 85], "classmethod": [51, 58, 72, 74, 76], "from_hp": [51, 63], "cl": [51, 58, 72, 74, 76], "quant_kwarg": [51, 52], "quantizetensorkwarg": 52, "given": [52, 64, 68, 69, 76, 85, 92], "deriv": [52, 61], "flexibl": [52, 64, 74, 80, 83, 91], "variou": [52, 89, 90, 92], "sparsiti": [53, 54, 55, 56, 57, 59, 60, 62, 65, 68, 69, 70, 71, 89], "observ": [53, 63, 64, 72, 80, 81, 82, 83, 84, 85, 92], "l2": [53, 64], "buffer": 53, "x_orig": 53, "sparsity_level": [54, 64], "semi_structured_block_s": 54, "wanda": 54, "sparsifi": [54, 64, 70, 77], "prune": 54, "propos": [54, 65], "http": [54, 58, 64, 71, 75, 77, 84, 90, 91], "arxiv": [54, 64], "org": [54, 58, 64, 71, 77, 84], "ab": [54, 64], "2306": 54, "11695": 54, "remov": [54, 61, 64, 68, 69, 76, 81, 82, 91], "magnitud": [54, 64, 92], "three": [54, 57, 83, 84, 89, 92], "variabl": [54, 64], "level": [54, 61, 63, 64, 74, 80, 81, 83, 84], "dict": [54, 58, 74, 76, 84, 85], "ad": [54, 58, 60, 63, 64, 65, 72, 74, 82], "parametr": 54, "preserv": [54, 64, 71, 80], "copi": [54, 61, 64, 66, 70, 72, 74, 82, 83], "deepcopi": [54, 66, 72, 74, 82], "squash_mask": [54, 64], "params_to_keep": 54, "params_to_keep_per_lay": 54, "squash": 54, "mask": [54, 64], "appropri": [54, 68, 80, 81, 82, 83, 84], "sparse_param": 54, "attach": [54, 64, 85], "save": [54, 58, 61, 65, 66, 68, 69, 70, 71, 76, 91], "xdoctest": 54, "local": [54, 64, 68, 71, 92], "hasattr": [54, 76], "submodule1": 54, "linear1": [54, 66, 70, 72, 74], "foo": [54, 81], "bar": [54, 81], "submodule2": 54, "linear42": 54, "baz": 54, "print": [54, 65, 66, 68, 70, 71, 74, 81, 82, 88, 92], "42": [54, 72], "24": [54, 68, 90], "ones": [54, 82], "update_mask": 54, "tensor_nam": [54, 76], "statist": [54, 64, 72, 81, 82], "retriev": 54, "act_per_input": 54, "Then": [54, 74, 84, 85, 91], "metric": [54, 60, 65, 68], "compar": [54, 61, 63, 65, 66, 68, 69, 71, 81, 83, 85, 91], "across": [54, 64, 68, 71, 74, 76, 90], "whole": [54, 85], "4": [55, 57, 63, 64, 65, 66, 68, 70, 71, 74, 75, 81, 82, 89, 90, 91, 92], "alia": [56, 58, 76], "semisparseweightconfig": 56, "sparsify_": 57, "apply_tensor_subclass": 57, "essenti": [57, 76, 80], "put": [57, 61, 68, 83, 85], "semi": [57, 64], "structur": [57, 61, 63, 64, 65, 66, 70, 74, 81], "semi_sparse_weight": 57, "semisparselayout": 57, "sparse_api": 57, "util": [58, 59, 60, 61, 63, 70, 74, 76, 80, 81, 82, 83, 84, 85], "commonli": [58, 64, 69], "new": [58, 60, 63, 65, 68, 69, 72, 74, 81, 82, 83, 85], "inherit": [58, 74, 76, 83, 84], "attribut": [58, 61, 63, 65, 74, 76, 83, 84], "tensor_data_nam": [58, 61], "tensor_data": 58, "__init__": [58, 60, 65, 66, 68, 70, 72, 74, 76, 79, 81, 82, 83], "been": [58, 65, 68, 74, 82, 83, 84, 85, 92], "section": [58, 61, 63, 64, 76, 81, 82, 85], "tensor_attribute_nam": [58, 61], "non": [58, 61, 64, 74, 80, 83, 84], "optional_tensor_data_nam": 58, "addit": [58, 60, 63, 64, 65, 69, 74, 75, 80, 81, 84, 85, 91], "optional_tensor_attribute_nam": 58, "__new__": [58, 74, 76], "exaclti": 58, "present": [58, 64, 68], "includ": [58, 63, 68, 69, 74, 80, 83, 84, 85, 89, 92], "__tensor_flatten__": [58, 74, 76], "flatten": 58, "attribute_nam": 58, "__tensor_unflatten__": [58, 74, 76], "tensor_data_dict": [58, 74, 76], "_apply_fn_to_data": [58, 76], "recreat": 58, "transform": [58, 61, 65, 72, 80, 81, 82, 83, 84, 91], "__repr__": [58, 74], "represent": [58, 64, 76, 81, 85], "_same_metadata": 58, "metadata": [58, 63, 71, 74, 76], "between": [58, 63, 64, 74, 76, 80, 82, 83, 85, 91], "__setstate__": 58, "load": [58, 61, 68, 70, 71, 75, 76], "checkpoint": [58, 65, 69, 71, 76, 90], "old": 58, "add": [58, 61, 68, 74, 75, 83, 85, 88], "__torch_function__": [58, 63, 74], "contigu": [58, 63, 83, 84], "aten": [58, 61, 63, 74, 76, 79, 80, 81, 82, 83, 84], "__torch_dispatch__": [58, 74], "detach": [58, 74, 76], "clone": [58, 71, 76, 92], "copy_": [58, 76], "_to_copi": [58, 76], "parent": 58, "own": [58, 61, 64, 65, 67, 68, 69, 72, 79, 81, 82, 85], "independ": [58, 64], "dispatch": [58, 68], "tabl": [58, 63, 64, 68, 69, 77, 92], "so": [58, 61, 63, 64, 65, 66, 68, 69, 70, 74, 75, 81, 82, 85, 90, 92], "child": [58, 74], "vice": 58, "versa": 58, "overrid": [58, 74], "childclass": 58, "c": [58, 74, 79, 83, 84], "mro": 58, "resolut": 58, "prioriti": 58, "qdata": [58, 61, 63], "attr": [58, 76], "r": [58, 81, 82, 91], "_make_wrapper_subclass": [58, 74, 76], "self": [58, 60, 65, 66, 68, 70, 72, 74, 76, 79, 81, 82, 83], "cat": [58, 75, 85], "parent_cat": 58, "func": [58, 61, 63, 68, 74, 76], "child_cat": 58, "safetensor": [58, 65, 75], "decompos": [58, 81], "constitu": 58, "plu": 58, "json": [58, 60, 71, 76], "reconstruct": [58, 64, 76], "alreadi": [58, 61, 68, 74, 85], "safetensors_util": 58, "py": [58, 60, 61, 68, 83, 84, 87, 88, 90, 92], "allowed_tensors_subclass": 58, "classnam": 58, "entri": [58, 66], "allowed_class": 58, "dataclass": [58, 72, 76, 85], "those": [58, 64, 68, 71, 72, 74], "well": [58, 61, 63, 64, 68, 79, 81, 82, 85], "onc": [58, 64, 65, 91], "hug": [58, 67, 71], "face": [58, 63, 64, 67, 71, 81], "save_pretrain": [58, 61, 71, 75], "push_to_hub": [58, 61, 71, 75, 76], "safe_seri": [58, 71, 75, 76], "doc": [58, 61, 63, 68, 69, 71, 74, 75, 79, 92], "ao": [58, 64, 68, 76, 90], "main": [58, 63, 64, 66, 68, 71, 72, 74, 75, 81, 85, 89, 91], "eager_tutori": 58, "torchao_hf_integr": 58, "html": 58, "end": [58, 63, 64, 65, 68, 69, 71, 74, 75, 76, 82, 85], "mytensor": [58, 61], "d": [58, 61, 71, 82], "f": [58, 63, 64, 66, 68, 69, 70, 71, 72, 74, 76, 81, 82, 92], "h": [58, 68, 71], "get_layout": 58, "15": [58, 60, 68, 69, 71, 90], "part": [58, 64, 67, 68, 74, 75, 82], "develop": [58, 61, 68, 77, 79, 81, 82, 85], "stack": [58, 63, 71], "about": [58, 60, 61, 63, 64, 65, 66, 70, 71, 81, 82, 83, 85, 91, 92], "dev": [58, 68, 75], "check": [58, 60, 61, 63, 65, 66, 70, 71, 74, 79, 80, 82, 85], "quantization_overview": 58, "contributor_guid": 58, "get_tensor_impl_constructor": 58, "layout_class": 58, "tensorimpl": 58, "tensorimplclass": 58, "from_plain": 58, "tensor_class": 58, "mean": [58, 63, 64, 65, 69, 81, 82, 85], "impl": 58, "aten_op": 58, "decor": [58, 74, 76], "callback": 58, "implements_torch_funct": 58, "torch_fn": 58, "register_layout": 58, "registr": 58, "aqt": 58, "comprehens": [59, 60, 66, 76, 83], "document": [59, 62, 65, 74, 76, 80, 81, 83, 89, 90, 91], "tutori": [60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91], "framework": [60, 61, 65, 68, 69, 71, 80, 92], "architectur": [60, 64, 67, 71, 80, 81, 83, 84], "micro": 60, "sparsity_": 60, "string_to_config": 60, "microbenchmark": [60, 92], "code": [60, 61, 63, 64, 66, 68, 69, 71, 72, 74, 81, 82, 83, 84, 85, 86, 88, 90], "elif": [60, 76, 77], "my_new_quant": 60, "process": [60, 63, 64, 65, 68, 80, 84, 88, 91], "mynewquantizationconfig": 60, "my_new_spars": 60, "mynewsparsityconfig": 60, "throughout": 60, "append": [60, 64, 81, 82], "gemliteuintxweightonlyconfig": 60, "gemlitewo": 60, "bit_width": 60, "model_architectur": 60, "your": [60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 75, 77, 81, 82, 83, 84, 85, 90, 91, 92], "mycustommodel": 60, "input_dim": [60, 66], "output_dim": [60, 66], "super": [60, 65, 66, 68, 70, 72, 74, 79, 81, 82, 83], "layer1": 60, "512": [60, 68, 69, 92], "relu": [60, 79, 80, 85], "layer2": 60, "updat": [60, 64, 66, 70, 77, 81, 82, 85], "create_model_and_input_data": 60, "handl": [60, 61, 68, 92], "model_typ": [60, 65, 76, 80], "n": [60, 61, 65, 70, 72, 74, 81, 82, 85, 92], "high_precision_dtyp": 60, "my_custom_model": 60, "input_data": 60, "ensur": [60, 68, 71, 82], "convent": 60, "batch": [60, 71, 72, 82, 91, 92], "sequenc": [60, 92], "length": [60, 92], "featur": [60, 65, 68, 74, 80, 83, 84, 89], "typic": [60, 63, 65, 70, 72, 76, 79, 85, 91], "come": [60, 63, 64, 68, 69, 71, 72, 73, 75, 82, 83, 84, 91], "soon": [60, 71, 73, 82, 91], "file": [60, 61, 66, 69, 71, 74, 76, 81, 82, 87], "microbenchmark_quantization_config": 60, "yml": 60, "benchmark_mod": 60, "quantization_config_recipe_nam": 60, "int8wo": [60, 75], "int8dq": 60, "float8dq": [60, 71], "float8wo": 60, "output_dir": [60, 75], "result": [60, 63, 64, 65, 66, 68, 72, 75, 81, 82, 83, 84, 85], "model_param": 60, "small_bf16_linear": 60, "matrix_shap": 60, "small_sweep": 60, "min_pow": 60, "max_pow": 60, "torch_compile_mod": 60, "max": [60, 61, 63, 66, 72, 74, 81, 82, 85], "autotun": [60, 61, 66, 72], "runner": 60, "oss": 60, "databas": 60, "ci_microbenchmark_runn": 60, "benchmark_result": 60, "extra_info": 60, "arch": 60, "a100": [60, 65, 75, 89], "sxm4": 60, "80gb": 60, "speedup": [60, 61, 63, 64, 65, 68, 69, 71, 92], "wrt": 60, "benchmark_valu": 60, "25": [60, 68, 92], "target_valu": 60, "depend": [60, 64, 70, 74, 77, 81, 82, 84, 92], "github": [60, 66, 71, 75, 90, 91], "action": [60, 76, 81, 82], "upload": 60, "verifi": [60, 66, 70, 74], "setup": [60, 71], "suit": [60, 61, 81, 83], "unittest": 60, "discov": 60, "memori": [60, 61, 63, 64, 65, 68, 69, 74, 75, 77, 83, 84, 90, 91, 92], "miss": [60, 64], "properli": [60, 70], "instal": [60, 61, 63, 68, 69, 71, 75, 81, 84, 92], "Not": [60, 64], "driver": 60, "basic": [60, 61, 72, 74], "analysi": [60, 64], "profil": [60, 61], "overhead": [60, 64, 66, 68, 75, 76, 83, 92], "possibl": [60, 63, 64, 81, 82, 83, 85], "reproduc": [60, 71, 90, 92], "compon": [60, 63, 68, 74, 76], "directori": [60, 68, 69, 92], "read": [61, 74, 91], "overview": [61, 62, 66, 76], "page": [61, 66, 83, 89], "contribut": [61, 64, 66], "api": [61, 62, 63, 64, 66, 72, 74, 79, 80, 81, 82, 83, 84, 90], "trainabl": [61, 63, 65, 74], "parallel": [61, 67, 69, 74, 76], "primit": [61, 68, 74, 81], "slight": [61, 64], "variat": [61, 63], "quant_primit": [61, 72], "mp": 61, "csrc": 61, "concept": [61, 63, 81, 83, 84, 85, 88], "could": [61, 63, 68, 74, 80, 81, 83, 84, 85], "context": [61, 83, 84], "write": [61, 67, 79, 80, 81, 82], "torchaobasetensor": [61, 76], "help": [61, 63, 65, 69, 71, 76, 80, 81], "With": [61, 68, 74, 81, 83, 85, 92], "ll": [61, 63, 68, 69, 74, 81, 82, 85], "mani": [61, 63, 64, 74], "still": [61, 63, 64, 65, 66, 68, 81, 85, 91], "awai": 61, "abstract": [61, 63], "easier": [61, 85], "peopl": [61, 63, 70, 76, 85], "my_custom_op": 61, "my_mm_for_mp": 61, "input_tensor": [61, 63, 76], "weight_tensor": [61, 63, 76], "group_mm": 61, "whatev": 61, "think": [61, 76], "condit": 61, "worri": 61, "purpos": [61, 63, 68, 69, 74, 81, 91, 92], "h100": [61, 63, 75, 89, 91], "sm89": 61, "sm90": 61, "_choose_scale_float8": [61, 63], "_quantize_affine_float8": [61, 63], "_scaled_mm": [61, 63], "kerenel": 61, "f8f8bf16_rowwis": [61, 63], "reus": [61, 74], "quant": [61, 63, 71, 76, 81, 84, 85], "aim": [61, 64, 84], "fullgraph": [61, 66], "unnecessari": 61, "graph": [61, 79, 81, 82, 85], "break": [61, 68], "torch_log": 61, "output_cod": 61, "script": [61, 66, 71, 72, 74, 82, 83, 84, 88, 92], "inductor": [61, 79, 80, 81], "relev": [61, 63, 88], "safe": 61, "global": [61, 64, 74], "add_safe_glob": 61, "quantizetensortofloat8kwarg": [61, 63], "checkout": [61, 63, 77], "integr": [61, 64, 67, 68, 69, 70, 71, 74, 83, 85, 92], "huggingfac": [61, 75], "deseri": [61, 81, 82], "from_pretrain": [61, 65, 71, 75, 76, 91], "diffus": [61, 71], "talk": [61, 63, 71], "fsdp": [61, 63, 68, 92], "mydtypetensor": 61, "developer_api_guid": 61, "folder": [61, 71, 81, 82, 89], "cover": [61, 81, 84, 85, 88], "torchchat": 61, "dtensor": [61, 68, 74, 92], "past": [61, 64], "adapt": [61, 69, 72], "intens": 61, "sens": [61, 63, 74], "benchmark_aq": 61, "quick": 61, "interest": [61, 64, 68, 74], "print_op_and_shap": 61, "torch_func": 61, "built": [61, 69, 74], "_c": 61, "tensorbas": 61, "benchmark_your_kernel": 61, "feel": [61, 63, 64, 74, 76], "free": [61, 63, 74], "probabl": 61, "futur": [61, 68, 72, 75, 76, 81, 82, 83, 85, 92], "llama": [61, 65, 71, 75, 76, 77, 80, 90, 91], "llama2": 61, "llama3": [61, 65, 69, 75, 91, 92], "sam": 61, "friendli": 61, "techniqu": [61, 64, 65, 68, 69, 70, 71, 72, 74, 76, 89], "profile_path": 61, "chrome": 61, "trace": 61, "let": [61, 63, 64, 66, 68, 72, 74, 85], "u": [61, 64, 80], "know": [61, 74, 92], "technic": 62, "contributor": [62, 63, 66], "guid": [62, 63, 66, 67, 71, 80, 92], "benchmark": [62, 66, 68, 69, 75, 79, 80, 83, 84], "lai": 63, "awq": [63, 89], "gptq": [63, 90], "int4tensor": 63, "int4preshuffledtensor": 63, "uint1": 63, "uint7": 63, "float3": 63, "overload": [63, 64], "term": [63, 64, 81, 85], "extra": [63, 71], "No": [63, 64, 65, 68, 70], "what": [63, 64, 65, 68, 69, 71, 72, 76, 81, 85, 88], "float8_e4m3fnuz": 63, "float8_e5m2": 63, "float8_e5m2fnuz": 63, "float8_e8m0fnu": 63, "placehold": [63, 84], "real": [63, 65, 68, 79, 81, 85], "pr": 63, "shell": 63, "limit": [63, 65, 69, 74, 76, 81, 92], "offici": [63, 68, 69], "dervi": 63, "mxfp8": [63, 67, 89, 90, 92], "mxfp4": [63, 65, 89], "preicison": 63, "choose_qparam": 63, "zero_point": [63, 64, 72, 74, 85], "mention": [63, 81], "accommod": 63, "choose_qparams_affine_with_min_max": 63, "min": [63, 72, 74, 81, 85], "raw": 63, "quantize_fp8_row": 63, "int_matmul": 63, "int_scaled_matmul": 63, "reli": [63, 64, 72, 74, 79], "handwritten": 63, "On": [63, 92], "top": [63, 69, 74, 80, 81, 82, 83, 84], "glue": 63, "everyth": 63, "togeth": [63, 68, 71, 81, 83, 85], "build": [63, 64, 68, 69, 74, 76, 77, 81], "anoth": [63, 64, 74, 81, 85], "side": [63, 68], "uint8": [63, 72, 85], "swizzl": 63, "dtpype": 63, "float8rowwisetensor": 63, "float8blockwisetensor": 63, "confus": [63, 64, 81], "close": [63, 64], "low_precision_v": 63, "high_precision_v": 63, "procedur": 63, "especi": [63, 64, 70, 83, 84], "bitwidth": [63, 85], "codebook": 63, "look": [63, 64, 69, 80, 81, 82, 83, 84], "index": [63, 64, 71, 77, 84], "vector": [63, 64, 83], "kmean": 63, "cluster": [63, 68, 69], "tradition": 63, "demonstr": [63, 65, 66, 68, 69, 71, 74, 80, 82, 92], "sai": [63, 75, 76, 85], "below": [63, 64, 68, 69, 74, 75, 76, 80, 88, 90, 92], "explain": [63, 80, 83], "introduct": [63, 71, 77], "simplest": [63, 64], "form": [63, 64, 68, 69], "easi": [63, 71], "linear_modul": 63, "requires_grad": [63, 65, 72, 74, 76], "runtim": [63, 66, 81], "question": [63, 64, 70, 74, 85, 92], "activation_granular": 63, "act_quant_kwarg": 63, "quantized_weight": [63, 76], "float8_dtyp": 63, "instruct": [63, 65, 71, 81, 82, 83, 91], "haven": 63, "seen": [63, 68], "pt2": [63, 74, 83], "fit": [63, 65, 70, 91], "autoround": 63, "multitensor": 63, "sure": [63, 71, 85], "open": [63, 64], "describ": [63, 64, 70, 81, 82, 88], "advis": 63, "focus": [63, 64, 65, 69, 71], "finetun": [63, 71], "quantized_train": [63, 92], "extend": [63, 64, 83], "progress": [63, 75, 76], "lot": [63, 64], "connect": [63, 68, 85], "walk": [63, 72, 74, 80, 83, 88], "float8dynamicactivationfloat8weightconfig": [63, 75, 90, 92], "happen": [63, 68, 74, 81, 83], "len": [63, 71, 76, 81, 82, 85], "_choose_quant_func_and_quantize_tensor": 63, "omit": [63, 69, 81, 82, 83], "relat": [63, 64], "xq": 63, "reshap": [63, 81, 82], "wq": 63, "x_scale": [63, 81], "w_scale": 63, "out_shap": 63, "neural": [64, 80, 83], "network": [64, 68, 74, 80, 83], "latenc": 64, "By": 64, "carefulli": 64, "achiev": [64, 65, 66, 68, 69, 72, 74, 82, 83], "signific": [64, 71, 90], "pai": 64, "reason": [64, 70, 91], "low": [64, 68, 74, 75, 80], "price": 64, "qualiti": [64, 65, 75], "f1": 64, "problem": [64, 74], "research": [64, 88, 91], "fragment": 64, "rightfulli": 64, "show": [64, 68, 69, 71, 76, 79, 81, 82], "time": [64, 66, 74, 75, 80, 81, 82, 88, 92], "spent": [64, 92], "figur": [64, 81], "compress": [64, 80], "place": [64, 80, 81, 82, 83, 84], "dens": [64, 68, 89], "solv": [64, 71, 74], "focu": [64, 74], "realli": 64, "push": [64, 71, 75, 76], "concret": [64, 85], "hope": 64, "modular": 64, "acceler": [64, 71, 75, 92], "nice": 64, "scratch": [64, 88], "minim": [64, 80, 83, 84], "loss": [64, 65, 68, 69, 81, 82, 91, 92], "recov": [64, 65, 77, 82, 91], "algorthim": 64, "realiz": 64, "improv": [64, 65, 68, 69, 71, 81, 84, 85, 89], "trade": [64, 68, 71, 92], "off": [64, 68, 71, 92], "theoret": 64, "gain": [64, 71, 84], "float16": [64, 89], "yield": [64, 65], "2x": [64, 66, 68, 71, 92], "analog": 64, "would": [64, 66, 68, 74, 82, 84], "fix": [64, 72], "50": [64, 69, 72, 80, 81, 83, 84], "expect": [64, 69, 74, 80, 81, 83, 84, 85], "matric": [64, 65], "unstructur": 64, "share": 64, "mitig": [64, 65], "retrain": 64, "neglig": 64, "even": [64, 65, 69, 85], "area": 64, "agre": 64, "upon": 64, "consensu": 64, "mind": 64, "thought": 64, "subproblem": 64, "find": [64, 65, 81, 85], "my": [64, 82], "answer": 64, "frontend": [64, 83], "arbitrari": 64, "backend": [64, 68, 71, 79, 85, 90], "collect": [64, 68, 69], "handoff": 64, "piec": 64, "natur": [64, 74, 81, 85], "becaus": [64, 65, 66, 68, 69, 70, 74, 82, 85], "clear": 64, "contract": 64, "7x": 64, "advantag": 64, "anticip": 64, "solut": 64, "third": [64, 90], "parti": [64, 90], "to_sparse_semi_structur": 64, "sparsesemistructuredtensor": 64, "weightnormsparsifi": 64, "half": 64, "subnetwork": 64, "sparse_config": 64, "named_modul": 64, "tensor_fqn": 64, "sparse_block_shap": 64, "zeros_per_block": 64, "fakespars": 64, "fundament": [64, 82], "flow": [64, 65, 69, 71, 72, 80, 81, 82, 83, 84], "manipul": 64, "paramer": 64, "parameter": 64, "necessari": [64, 72, 74, 80, 81, 82, 83, 84, 90], "ve": [64, 71], "suitabl": [64, 83], "spot": 64, "definit": [64, 76], "academia": 64, "industri": 64, "often": [64, 74], "interchang": 64, "thing": [64, 70, 74, 81], "distinct": 64, "pretrain": [64, 71, 80, 81, 82, 83, 92], "avoid": [64, 68, 70], "try": [64, 65, 74, 81, 90], "roughli": 64, "idea": 64, "behind": 64, "doesn": [64, 82, 85], "box": [64, 69, 83], "itself": [64, 68, 74], "multipli": [64, 92], "loos": 64, "speak": 64, "tightli": 64, "coupl": [64, 74], "csc": 64, "fbgemm": 64, "qnnpack": 64, "descript": [64, 80], "coo": 64, "sparse_coo": 64, "coordin": 64, "locat": [64, 68], "bsr": 64, "sparse_bsr": 64, "veri": [64, 76, 82], "similar": [64, 65, 68, 72, 82, 83, 92], "except": [64, 74, 85], "individu": 64, "scalar": [64, 81], "dimension": 64, "csr": 64, "sparse_csr": 64, "sparse_csc": 64, "column": 64, "indic": [64, 68, 85], "compact": 64, "sparse_matrix": 64, "1d": 64, "indexptr": 64, "storag": 64, "\u00bd": 64, "bitmask": 64, "2bit": 64, "unprun": 64, "quit": [64, 74], "simpl": [64, 66, 72, 74, 80, 83, 84], "successfulli": [64, 65], "These": [64, 65, 68, 74, 80, 81, 82, 85, 90], "broken": 64, "down": [64, 68], "equal": [64, 70], "sensit": 64, "effect": [64, 72, 74, 83, 84, 85], "best": [64, 66, 83], "subsequ": [64, 74, 83, 84], "infinit": 64, "lost": 64, "degre": 64, "drop": 64, "give": [64, 71, 74], "curv": [64, 69, 92], "proxi": 64, "much": [64, 65, 68, 85], "aforement": 64, "less": [64, 74, 77, 81], "smallest": 64, "absolut": 64, "consid": 64, "v": [64, 69, 81, 85, 92], "scope": 64, "impli": 64, "respect": [64, 82], "pro": [64, 71, 90, 91], "con": 64, "potenti": [64, 72, 80, 81, 83, 84], "sub": 64, "tradeoff": [64, 65, 75], "span": 64, "over": [64, 68, 69, 81, 82, 92], "threshold": 64, "normal": [64, 81, 82], "complex": 64, "constant": [64, 74, 81], "ctr_mobile_fe": 64, "paper": [64, 65, 88], "score": [64, 68], "w": [64, 76], "tenosr": 64, "udpat": 64, "cannot": [64, 72, 76], "histori": 64, "regrow": 64, "dw": 64, "via": [64, 68, 80, 92], "backprop": 64, "pat": 64, "unmask": 64, "resid": 64, "salienc": 64, "lowest": 64, "l1": 64, "shown": [64, 65, 68, 71, 82, 85, 90, 91, 92], "abl": [64, 74, 76, 81, 85], "repeat": [64, 81, 82], "shot": [64, 65], "movement": 64, "tune": [64, 67, 69, 71, 80, 91], "2005": 64, "07683": 64, "rank": [64, 68, 74], "wx": 64, "sqx": 64, "q": [64, 81], "usual": 64, "sort": 64, "wise": 64, "seek": [64, 70], "random": [64, 71, 81, 82], "randomli": 64, "tri": 64, "remedi": 64, "line": [64, 69, 75], "sometim": 64, "item": [64, 88], "ultim": [64, 72], "complic": [64, 81], "literatur": 64, "vision": 64, "nlp": [64, 83, 88], "simpli": [64, 65, 72, 74], "again": [64, 81, 85], "iter": [64, 81, 82], "ctr_feed": 64, "na": [64, 90], "multimask": 64, "search": 64, "pyspeech": 64, "fastna": 64, "approach": [64, 68, 74, 80, 83, 84, 92], "knowledg": [64, 88], "distil": 64, "pdf": 64, "2204": 64, "09656": 64, "arrang": [64, 68], "recal": 64, "faster": [64, 66, 68, 77, 91, 92], "counterpart": 64, "slower": 64, "suffici": 64, "At": [64, 81], "98": [64, 90], "exhibit": [64, 91], "penalti": 64, "expens": [64, 68, 74], "dictat": 64, "characterist": [64, 68], "highest": 64, "wouldn": [64, 74], "visual": 64, "fig": 64, "4x4": 64, "benchmak": 64, "serv": [65, 66, 67, 69, 74, 75, 84, 92], "leverag": [65, 69, 71, 74, 83, 84, 91], "partner": [65, 69, 71], "showcas": [65, 69, 71], "blog": [65, 91], "resourc": [65, 74], "introduc": [65, 68, 80, 81, 83, 84, 85], "small": [65, 66, 92], "freez": [65, 82, 83, 84], "inevit": 65, "presum": 65, "recent": [65, 77], "releas": [65, 83], "1b": [65, 75, 76], "3b": [65, 91], "llamaguard": 65, "8b": [65, 66, 69, 75, 77, 90, 91, 92], "distribut": [65, 68, 69, 72, 74, 76, 80, 91, 92], "command": [65, 68, 69, 90, 91, 92], "regular": [65, 68, 80, 83, 84], "nnode": [65, 91], "nproc_per_nod": [65, 68, 91], "full_finetune_distribut": 65, "llama3_2": 65, "3b_full": 65, "batch_siz": [65, 66, 68, 70, 71, 72, 81, 82], "_component_": 65, "qat_distribut": [65, 91], "3b_qat_ful": 65, "evalu": [65, 66, 68, 82], "wa": [65, 74, 82, 90, 91, 92], "llama3_2_3b": 65, "fullmodelhfcheckpoint": 65, "checkpoint_fil": 65, "00001": 65, "00002": 65, "int8dynactint4weightquant": 65, "hellaswag": [65, 71], "wikitext": [65, 90, 91], "eleuther_ev": 65, "eleuther_evalu": 65, "task": [65, 71, 91], "fullmodeltorchtunecheckpoint": 65, "8da4w": [65, 71], "ckpt": 65, "llama3_token": 65, "tmp": 65, "meta": [65, 70, 75, 76, 85, 90], "stderr": 65, "acc": [65, 81, 82], "5021": 65, "0050": 65, "acc_norm": 65, "6797": 65, "0047": 65, "bits_per_byt": 65, "6965": 65, "byte_perplex": 65, "6206": [65, 88], "word_perplex": 65, "13": [65, 68, 90, 91, 92], "2199": 65, "openassist": 65, "oasst1": 65, "dataset": [65, 69, 71, 80, 83, 84, 91], "higher": [65, 69, 74, 75, 80, 81, 83, 84, 91], "69": [65, 72], "overal": [65, 66, 77, 81, 85], "vanilla": [65, 91], "lora": [65, 91], "89x": [65, 77, 91], "36": [65, 69, 71, 90, 91], "qat_lora_finetune_distribut": [65, 91], "3b_qat_lora": 65, "fsdp2": [65, 69, 91, 92], "yaml": [65, 91], "complet": [65, 71, 80, 84, 91], "qat_out": [65, 91], "quatiz": [65, 91], "hood": [65, 90], "mini": [65, 71], "gpu": [65, 66, 68, 69, 75, 76, 79, 80, 88, 90, 91], "accordingli": 65, "get_model": [65, 91], "vocab_s": [65, 91], "num_lay": [65, 91], "num_head": [65, 91], "num_kv_head": [65, 91], "embed_dim": [65, 91], "max_seq_len": [65, 91], "001": [65, 91], "momentum": [65, 82, 91], "9": [65, 68, 69, 77, 90, 91, 92], "weight_decai": [65, 91], "1e": [65, 69, 91, 92], "loss_fn": [65, 91], "crossentropyloss": [65, 81, 82, 91], "randint": [65, 91], "next": [65, 68, 69, 72, 81, 82, 83, 84], "attun": 65, "benefici": 65, "readi": [65, 66, 68, 69, 71, 72, 74, 82], "did": 65, "legaci": [65, 91], "offer": [65, 66, 74, 81], "unlik": [65, 72], "int8dynactint4weightqatquant": [65, 91], "qat_quant": [65, 91], "insert": [65, 66, 72, 79, 80, 81, 82, 83, 84, 85, 91], "int8dynactint4weightqatlinear": [65, 91], "int8dynactint4weightlinear": [65, 91], "fraction": 65, "therebi": [65, 91], "significantli": [65, 66, 80, 81, 83, 84], "footprint": 65, "extens": [65, 74, 81, 83], "addition": [65, 83, 84, 91], "frozen": 65, "further": [65, 74, 80, 81, 82, 83], "nf4": 65, "express": [65, 74, 79, 80, 81, 82, 85], "nf4tensor": 65, "cleanli": 65, "to_nf4": 65, "frozennf4linear": 65, "in_dim": 65, "out_dim": 65, "quantization_kwarg": 65, "requires_grad_": 65, "nf4_weight": 65, "though": [65, 74], "baselin": [65, 69, 71, 81, 90, 91, 92], "reap": 65, "vari": [65, 66, 81, 82, 83, 84], "incorpor": 65, "loralinear": 65, "lora_finetune_single_devic": 65, "3b_qlora_single_devic": 65, "invok": [65, 83], "loraconfig": 65, "get_peft_model": [65, 91], "automodelforcausallm": [65, 71, 75, 76], "torchaoconfig": [65, 71, 75, 76], "base_model": 65, "quantization_config": [65, 71, 75, 76, 84], "peft_config": 65, "throughput": [65, 66, 69, 71, 90, 92], "torchtitan": [65, 92], "enable_fp8_train": 65, "fp8_recipe_nam": 65, "experi": [65, 69, 84, 91], "saw": 65, "experiment_nam": 65, "tok": [65, 90], "peak_mem_reserv": 65, "6502": 65, "143": 65, "000": 65, "30": [65, 68, 69, 81], "090": 65, "fp8_nonam": 65, "7205": 65, "386": 65, "816": 65, "010": 65, "266": 65, "fp8_tensorwis": 65, "7222": [65, 91], "198": 65, "11": [65, 68, 69, 90], "074": [65, 69], "fp8_rowwis": [65, 92], "6387": 65, "968": 65, "756": 65, "29": [65, 68, 69], "158": 65, "096": 65, "fp8_rowwise_with_gw_hp": 65, "7573": 65, "698": 65, "480": 65, "516": 65, "908": 65, "hellaswag_acc": 65, "wikitext_word_perplex": 65, "533": [65, 90], "12": [65, 68, 69, 77, 84, 85, 91], "407": [65, 69], "414": 65, "007": 65, "412": 65, "005": 65, "420": [65, 91], "013": [65, 69], "534": 65, "416": 65, "009": 65, "mutat": 66, "toylinearmodel": [66, 70, 72], "hidden_dim": [66, 68], "has_bia": 66, "linear2": [66, 70, 72, 74], "eval": [66, 70, 71, 72, 79, 80, 82, 83, 84, 90, 91], "model_w16a16": 66, "model_w8a8": 66, "chapter": 66, "remain": [66, 83, 84], "unchang": 66, "__name__": [66, 68], "approxim": 66, "disk": 66, "o": [66, 68, 81, 82], "state_dict": [66, 69, 70, 81, 82, 92], "pth": [66, 69, 81, 82, 92], "original_s": 66, "getsiz": [66, 81, 82], "quantized_s": 66, "2f": [66, 81, 82], "mb": [66, 70, 81, 82, 87], "00x": 66, "00mb": 66, "warmup": [66, 69], "synchron": 66, "100": [66, 74, 81, 82, 92], "original_tim": 66, "quantized_tim": 66, "03x": 66, "larger": [66, 68, 92], "enough": 66, "toi": [66, 69, 72, 74, 83, 92], "address": [66, 81], "vllm": [66, 67, 75, 90], "lm": [66, 71, 90], "visit": 66, "forget": 66, "good": [66, 68, 74, 85], "eager": [67, 80, 81, 82, 83, 84, 85], "qlora": [67, 71], "sglang": [67, 75], "advanc": [67, 72, 74, 80, 83, 84], "expert": 67, "mixtur": 68, "moe": [68, 89, 92], "microsc": 68, "fp8": [68, 71, 90], "larg": [68, 71, 74, 83, 92], "shard": [68, 74, 76], "commun": 68, "deepseekv3": 68, "16b": 68, "node": [68, 80, 82, 83, 84, 85, 92], "8xb200": 68, "nvlink": 68, "intra": 68, "inter": 68, "multi": 68, "b200": [68, 89, 91], "ib": 68, "moe_train": [68, 92], "differenti": [68, 74], "autograd": [68, 74, 85, 92], "chain": [68, 85], "a2a_dispatch_mxfp8_fwd_hp_bwd": 68, "permute_mxfp8_fwd_hp_bwd": 68, "permut": 68, "pad": 68, "_to_mxfp8_then_scaled_grouped_mm": 68, "rout": 68, "accept": [68, 71, 85, 91], "produc": [68, 79, 80, 81, 82, 83, 84, 91], "unpermute_hp_fwd_mxfp8_bwd": 68, "unpermut": 68, "a2a_combine_hp_fwd_mxfp8_bwd": 68, "aggreg": 68, "all2al": 68, "immediatlei": 68, "deepseek": 68, "v3": 68, "virtual": [68, 69], "environ": [68, 69, 71], "conda": [68, 69], "venv": [68, 69], "nightli": [68, 71, 77], "download": [68, 69, 71, 77, 81, 82, 84, 86, 88, 92], "job": [68, 69], "root": [68, 69, 71], "launch": [68, 69], "config_fil": [68, 69], "home": 68, "deepseek_v3": 68, "train_config": [68, 69], "deepseek_v3_16b": 68, "toml": [68, 69], "run_train": [68, 69], "sh": [68, 69, 71, 90, 92], "log_freq": 68, "1500": 68, "data_parallel_shard_degre": 68, "expert_parallel_degre": 68, "tensor_parallel_degre": 68, "expert_tensor_parallel_degre": 68, "seq_len": 68, "activation_checkpoint": 68, "print_after_convers": 68, "local_batch_s": 68, "mxfp8_dim0_cast_kernel_choic": 68, "mxfp8_dim1_cast_kernel_choic": 68, "grouped_mm": 68, "mxfp8_wgrad_with_hp": 68, "moe_force_load_bal": 68, "forc": [68, 74], "balanc": 68, "termin": [68, 69], "rank0": [68, 69], "titan": [68, 69], "2026": 68, "01": [68, 69, 90], "145": 68, "info": [68, 69], "8432": 68, "45": [68, 91], "23gib": 68, "47": [68, 69, 92], "65": [68, 69, 90, 92], "tp": [68, 69, 76, 92], "267": 68, "3421": 68, "48": [68, 69], "91gib": [68, 69], "51": [68, 69], "52": [68, 69], "21": [68, 69], "734": 68, "58": [68, 69, 77], "891": 68, "20": [68, 69, 71, 82], "7": [68, 69, 71, 83, 84, 89, 90, 92], "8234": 68, "902": 68, "523": [68, 91], "9123": 68, "511": 68, "reader": 68, "why": [68, 74, 88], "1x32": 68, "transpos": [68, 74], "wgrad": 68, "grad_out": 68, "operand": 68, "thu": [68, 81], "32x1": 68, "requant": 68, "impact": [68, 69, 71, 76], "v0": 68, "stick": 68, "wgrad_with_hp": 68, "trend": 68, "toward": 68, "difficult": 68, "attent": 68, "ffn": 68, "pipelin": [68, 71], "pipeline_parallel_degre": 68, "lbalanc": 68, "critic": 68, "workload": [68, 81], "simplifi": [68, 80, 81, 83, 84], "router": 68, "3d": [68, 81, 85], "scaled_grouped_mm": 68, "groupedexpert": 68, "num_expert": 68, "w1": 68, "w2": 68, "w3": 68, "num_tokens_per_expert": 68, "to_loc": 68, "offset": 68, "cumsum": 68, "mxtensor": 68, "prior": [68, 81], "mxfp8_gmm": 68, "silu": 68, "type_a": 68, "simplifiedmo": 68, "routed_input": 68, "parallelstyl": 68, "mxfp8expertparallel": 68, "input_split": 68, "output_split": 68, "input_shap": 68, "permuted_indic": 68, "_partition_fn": 68, "device_mesh": 68, "devicemesh": 68, "param_nam": 68, "named_paramet": 68, "recurs": [68, 69], "dist_param": 68, "distribute_tensor": 68, "register_paramet": 68, "_token_dispatch": 68, "correct": [68, 81, 82], "count": [68, 81, 82, 92], "ep_degre": 68, "num_local_expert": 68, "no_grad": [68, 74, 79, 80, 81, 82, 83, 84], "num_tokens_per_expert_group": 68, "all_to_all_singl": 68, "get_group": 68, "wait": 68, "async": [68, 92], "_c10d_function": 68, "wait_tensor": 68, "view": [68, 74, 81, 82], "non_block": 68, "tolist": 68, "consum": [68, 85], "send": 68, "byte": 68, "incom": 68, "upstream": 68, "came": 68, "group_nam": 68, "_token_combin": 68, "routed_output": 68, "reorder": 68, "revers": 68, "receiv": 68, "opportun": 68, "big": 68, "immedi": 68, "net": 68, "perf": [68, 90], "pair": [68, 83, 84], "lossless": 68, "implic": 68, "stai": [68, 74, 92], "earlier": 68, "due": [68, 76, 80, 85], "comm": 68, "_appli": 68, "style": 68, "distribute_modul": 68, "partition_fn": 68, "input_fn": 68, "output_fn": 68, "apply_mxfp8_expert_parallel": 68, "moe_lay": 68, "ep_mesh": 68, "experts_plan": 68, "parallelize_modul": 68, "parallelize_plan": 68, "usr": 68, "bin": [68, 71], "env": 68, "python3": 68, "standalon": 68, "torchrun": 68, "mxfp8_expert_parallel_exampl": 68, "init_process_group": 68, "destroy_process_group": 68, "_functional_collect": 68, "nccl": 68, "local_rank": 68, "world_siz": 68, "set_devic": 68, "7168": 68, "mesh": 68, "mesh_dim_nam": 68, "practic": [68, 88], "num_token": 68, "int64": 68, "grad_output": 68, "randn_lik": 68, "done": [68, 74, 91], "__main__": 68, "world": [68, 75, 76], "fwd_bf16_m": 68, "fwd_mxfp8_m": 68, "fwd_speedup": 68, "bwd_bf16_m": 68, "bwd_mxfp8_m": 68, "bwd_speedup": 68, "total_speedup": 68, "131072": 68, "5120": 68, "18": [68, 90], "037": 68, "49x": 68, "485": [68, 81, 82, 90], "839": 68, "40x": 68, "43x": [68, 69], "394": 68, "424": 68, "46x": 68, "762": 68, "306": 68, "34x": 68, "38x": 68, "1408": 68, "368": 68, "952": 68, "14x": [68, 71], "982": 68, "877": 68, "29x": 68, "22x": 68, "22": 68, "total": [68, 87, 88], "largest": [68, 74], "nvl8": 68, "14": [68, 69, 92], "28": [68, 69], "348": 68, "16x": [68, 71], "812": 68, "897": 68, "13x": 68, "283": 68, "548": 68, "299": 68, "25x": [68, 92], "278": 68, "913": 68, "934": 68, "881": [68, 91], "27x": 68, "21x": [68, 69, 71], "As": [68, 69, 81, 85], "versu": 68, "conclus": 68, "5x": [69, 77, 92], "34": 69, "2k": [69, 92], "h200": 69, "latest": [69, 77], "offic": 69, "sever": [69, 76, 80, 85], "popular": 69, "flagship": 69, "quickli": [69, 74], "batteri": 69, "fork": 69, "ngpu": 69, "llama3_8b": 69, "hyperparamet": 69, "edit": [69, 71], "flag": [69, 77, 82], "2025": 69, "06": 69, "04": 69, "08": 69, "2254": 69, "27": 69, "34gib": 69, "78": 69, "375": 69, "tflop": 69, "73": [69, 72, 90], "mfu": 69, "557": 69, "7069": 69, "99gib": 69, "62": [69, 90], "034": 69, "35": [69, 71, 72, 90], "41": [69, 71], "19": [69, 90], "224": [69, 72, 80, 81, 82, 83, 84], "9196": 69, "022": 69, "406": [69, 81, 82], "904": 69, "1423": 69, "014": 69, "23": [69, 72, 90], "7k": 69, "99gb": 69, "peak": [69, 71, 75, 90, 92], "against": 69, "02": 69, "37": 69, "404": 69, "2611": 69, "22gib": 69, "595": 69, "49": [69, 72], "027": 69, "4260": 69, "89gib": 69, "344": 69, "367": 69, "39": [69, 91, 92], "03": [69, 90, 92], "988": 69, "9482": 69, "321": 69, "366": 69, "991": 69, "1183": 69, "300": 69, "364": 69, "89": 69, "40": [69, 91], "4659": 69, "291": 69, "84": 69, "769": 69, "gc": 69, "peform": 69, "period": 69, "3k": 69, "89gb": 69, "11x": 69, "nearli": 69, "performan": 69, "648": 69, "2648": 69, "28gib": 69, "71": [69, 90], "26": [69, 91], "475": 69, "9106": 69, "53": [69, 71], "503": 69, "434": 69, "43": 69, "94": [69, 81, 90], "166": 69, "0774": 69, "663": 69, "443": 69, "44": [69, 72], "87": 69, "885": 69, "3233": 69, "643": 69, "442": 69, "66": [69, 71, 72, 91], "76": 69, "613": 69, "6150": [69, 92], "637": 69, "72": [69, 71], "6k": 69, "91gb": 69, "tl": 69, "dr": 69, "priorit": 69, "stabil": 69, "cost": [69, 72], "slightli": [69, 74], "outlier": [69, 92], "caus": 69, "underflow": 69, "8xh100": [69, 92], "convert_to_float8_train": [69, 92], "kind": [69, 81], "snippet": [69, 81, 82], "float8_linear_util": [69, 92], "float8_linear": [69, 92], "adamw": [69, 92], "label": [69, 92], "fake_label": [69, 92], "ones_lik": [69, 92], "mse_loss": [69, 92], "model_state_dict": [69, 92], "optimizer_state_dict": [69, 92], "explor": [69, 84], "few": [69, 74, 81, 82, 91], "tempfil": [70, 75], "get_model_size_in_byt": 70, "ref": [70, 81], "namedtemporaryfil": 70, "m_load": 70, "load_state_dict": [70, 81, 82, 92], "assign": 70, "assert": [70, 72, 74, 76, 85], "float_weight1": 70, "float_weight2": 70, "quantized_weight1": 70, "quantized_weight2": 70, "go": [70, 74, 85], "techinqu": 70, "4x": [70, 71], "0625": 70, "affine_quantized_tensor": 70, "deploi": 71, "engin": 71, "seamlessli": [71, 74, 83, 84], "seamless": [71, 83, 92], "hf": [71, 75], "pip": [71, 75, 77, 80, 81], "url": [71, 77, 84], "whl": [71, 77, 84], "cu128": [71, 77], "hub": [71, 75, 76], "server": [71, 76], "phi": 71, "microsoft": 71, "o3": 71, "client": 71, "curl": 71, "localhost": 71, "8000": 71, "v1": 71, "chat": 71, "content": 71, "messag": 71, "role": 71, "me": 71, "short": 71, "temperatur": 71, "top_p": 71, "95": [71, 90], "top_k": 71, "max_token": 71, "32768": 71, "vram": 71, "15x": 71, "littl": [71, 76], "packag": [71, 75], "git": [71, 75], "com": [71, 75, 90, 91], "autotoken": [71, 75], "manual_se": [71, 81, 82], "model_path": 71, "device_map": [71, 75, 76], "trust_remote_cod": 71, "ai": 71, "assist": 71, "eat": 71, "banana": 71, "dragonfruit": 71, "smoothi": 71, "blend": 71, "milk": 71, "honei": 71, "salad": 71, "mix": [71, 80, 83, 84], "slice": [71, 76], "lemon": 71, "juic": 71, "equat": 71, "pipe": [71, 75], "text": 71, "generation_arg": 71, "max_new_token": 71, "500": 71, "return_full_text": 71, "do_sampl": 71, "generated_text": 71, "design": [71, 76, 80, 81, 85], "lm_head": 71, "ti": 71, "autoprocessor": 71, "modeling_util": 71, "find_tied_paramet": 71, "model_id": [71, 75], "untied_model": 71, "getattr": [71, 76], "get_text_config": 71, "tie_word_embed": 71, "setattr": [71, 74], "_tied_weights_kei": 71, "user_id": 71, "your_user_id": 71, "model_nam": [71, 80, 83, 84], "save_to": [71, 75], "save_to_local_path": 71, "int8dynamicactivationintxweightconfig": [71, 75], "intxweightonlyconfig": [71, 75, 90], "fqntoconfig": [71, 76], "untied_model_id": 71, "untied_model_local_path": 71, "embedding_config": 71, "quant_config": 71, "embed_token": 71, "quant_typ": [71, 75, 76], "include_embed": 71, "untie_embedding_weight": 71, "modules_to_not_convert": 71, "quantized_model": [71, 74, 75, 80, 81, 82], "pte": 71, "cd": 71, "install_requir": 71, "phi_4_mini": 71, "convert_weight": 71, "pytorch_model": 71, "pytorch_model_convert": 71, "export_llama": 71, "kv": 71, "use_sdpa_with_kv_cach": 71, "get_bos_id": 71, "199999": 71, "get_eos_id": 71, "200020": 71, "max_seq_length": 71, "max_context_length": 71, "output_nam": 71, "phi4": 71, "phone": 71, "io": 71, "2gb": 71, "iphon": 71, "17": [71, 90, 91], "sec": 71, "test": [71, 75, 81, 83, 88], "har": 71, "eleutherai": 71, "lm_eval": 71, "model_arg": 71, "reset_peak_memory_stat": 71, "prompt": [71, 75], "hei": 71, "consciou": 71, "templated_prompt": 71, "apply_chat_templ": 71, "add_generation_prompt": 71, "templat": [71, 86, 87], "return_tensor": 71, "pt": 71, "generated_id": 71, "output_text": 71, "batch_decod": 71, "skip_special_token": 71, "clean_up_tokenization_spac": 71, "respons": 71, "mem": 71, "max_memory_reserv": 71, "1e9": 71, "02f": 71, "gb": [71, 90, 92], "hello": [71, 75], "ye": 71, "am": 71, "digit": 71, "todai": 71, "70": [71, 72, 90], "bench": [71, 90], "vllm_disable_compile_cach": 71, "project": 71, "vllm_use_precompil": 71, "sharegpt": 71, "wget": 71, "co": 71, "anon8231489123": 71, "sharegpt_vicuna_unfilt": 71, "resolv": 71, "sharegpt_v3_unfiltered_cleaned_split": 71, "tree": 71, "num": 71, "benchmark_serv": 71, "num_prompt": [71, 90], "req": 71, "57": [71, 72, 92], "1000": [71, 83], "68": [71, 92], "80": 71, "ml": 71, "eas": 71, "fly": [72, 75], "affinequantizedminmaxobserv": 72, "record": 72, "welcom": 72, "desir": 72, "averag": [72, 81, 82], "histogram": [72, 81], "act_ob": 72, "finfo": 72, "zero_point_dtyp": 72, "weight_ob": 72, "observedlinear": 72, "observed_input": 72, "observed_weight": 72, "from_float": [72, 74], "float_linear": 72, "observed_linear": 72, "_replace_with_custom_fn_if_matches_filt": 72, "insert_observers_": 72, "lambda": [72, 76, 91], "replacement_fn": 72, "copied_act_ob": 72, "copied_weight_ob": 72, "popul": 72, "feed": 72, "simpler": [72, 81], "quantizedlinear": [72, 74], "isn": 72, "strictli": 72, "to_affine_quantized_intx_stat": 72, "act_scal": [72, 85], "act_zero_point": 72, "calculate_qparam": [72, 85], "weight_scal": [72, 81, 85], "weight_zero_point": [72, 81], "qweight": 72, "qinput": 72, "from_observ": 72, "quantized_linear": [72, 81], "begin": [72, 74], "transform_modul": [72, 76], "register_quantize_module_handl": [72, 76], "staticquantconfig": 72, "_apply_static_qu": 72, "associ": 72, "identifi": [72, 85], "is_observed_linear": 72, "optimizedmodul": 72, "_orig_mod": 72, "0237": 72, "tensor_impl": 72, "plainaqttensorimpl": 72, "142": 72, "31": [72, 85], "113": 72, "157": 72, "59": [72, 90], "160": 72, "150": 72, "67": [72, 77], "241": 72, "238": 72, "235": 72, "228": 72, "255": [72, 85], "201": 72, "114": 72, "236": 72, "88": [72, 81], "83": 72, "109": 72, "209": 72, "92": 72, "184": 72, "141": 72, "110": 72, "0009": 72, "0010": 72, "130": 72, "122": 72, "132": 72, "125": 72, "126": 72, "129": 72, "127": [72, 74, 84, 85], "133": 72, "124": 72, "131": 72, "135": 72, "136": 72, "_layout": 72, "foundat": 74, "highlight": [74, 77, 88], "interpos": 74, "namespac": 74, "continu": [74, 75, 82, 83, 84, 85], "obviou": 74, "int8quantizedlinear": 74, "finer": 74, "intercept": 74, "contrast": [74, 91], "long": [74, 81], "clunki": 74, "distributedlinear": 74, "duplic": 74, "bypass": 74, "wrap": [74, 83, 84], "outer": 74, "inner": 74, "allgath": 74, "bandwidth": [74, 90, 92], "exactli": [74, 91], "zoo": 74, "podcast": 74, "edward": 74, "yang": 74, "int8_symmetric_quant": 74, "fp32_tensor": 74, "quant_min": [74, 84, 85], "quant_max": [74, 84, 85], "min_val": 74, "amin": 74, "keepdim": [74, 81, 82], "max_val": 74, "amax": 74, "min_val_neg": 74, "zeros_lik": 74, "max_val_po": 74, "clamp": [74, 81, 91], "w_int8": 74, "new_linear": 74, "left": [74, 85], "toymodel": 74, "float_model": [74, 79, 80, 81, 82, 83, 84], "named_children": 74, "drawback": 74, "won": 74, "suppos": 74, "clean": [74, 91], "eleg": 74, "pretti": 74, "almost": 74, "ragged": 74, "rag": 74, "nestedtensor": 74, "who": 74, "link": [74, 88, 89], "googl": [74, 91], "collab": 74, "flopcount": 74, "memorytrack": 74, "bare": 74, "bone": 74, "int8symmetrictensor": 74, "hold": [74, 75], "int_data": 74, "staticmethod": 74, "_dynamo": 74, "stride": 74, "storage_offset": 74, "ndim": 74, "extra_metadata": 74, "outer_s": [74, 76], "outer_strid": [74, 76], "undo": 74, "repr": 74, "float_tensor": 74, "ahead": 74, "insid": 74, "int8_tensor": 74, "op_implementations_dict": 74, "assertionerror": 74, "conveni": 74, "register_op": 74, "_op": 74, "opoverload": 74, "impl_decor": 74, "op_impl": 74, "wrapper": [74, 79, 83], "particular": 74, "tell": 74, "desugar": 74, "surfac": 74, "coverag": [74, 80, 81, 83, 84], "brute": 74, "repeatedli": 74, "log": 74, "loggingtensor": 74, "_python_dispatch": [74, 76], "return_and_correct_alias": [74, 76], "int8_mm": 74, "int8_view_op": 74, "out_data": 74, "out_scal": [74, 81], "notic": 74, "hit": 74, "background": 74, "decomposit": 74, "live": 74, "decomp": 74, "shrink": 74, "author": [74, 80, 81, 82, 83, 84, 85, 88], "But": [74, 76, 85], "pain": 74, "rather": 74, "worth": 74, "written": 74, "nuanc": 74, "longer": [74, 81, 82], "had": [74, 81], "That": 74, "transposit": 74, "got": [74, 81, 85], "propag": [74, 81, 83, 84], "fact": 74, "themselv": [74, 81], "pointwis": [74, 83, 84], "were": [74, 90], "might": [74, 76, 81, 85], "unwrap": 74, "dim0": 74, "dim1": 74, "confirm": 74, "quantized_model_module_swap": 74, "quantized_model_subclass": 74, "subclass_param": 74, "out_module_swap": 74, "allclos": 74, "out_compil": 74, "seri": 74, "discuss": 74, "float8dynamicactivationint4weightconfig": [75, 90], "use_hqq": [75, 76], "torch_dtyp": 75, "fluxpipelin": 75, "fluxtransformer2dmodel": 75, "black": 75, "forest": 75, "lab": 75, "flux": 75, "subfold": 75, "sign": [75, 84], "imag": [75, 79, 80, 81, 82, 83, 84], "num_inference_step": 75, "guidance_scal": 75, "png": 75, "temporarydirectori": 75, "tmp_dir": 75, "uncom": 75, "usernam": [75, 76], "statu": [75, 76, 90], "becom": [75, 81], "stabl": [75, 77, 89, 92], "int4wo": 75, "team": [75, 76], "track": [75, 76], "retain": 75, "thoroughli": 75, "e2": 76, "_type": 76, "_data": 76, "capabl": [76, 81, 83, 90], "self_attn": 76, "k_proj": [76, 91], "mlp": 76, "gate_proj": [76, 91], "narrow": 76, "host": 76, "state": 76, "chunk": 76, "heavi": 76, "codebas": [76, 92], "fn": 76, "ctx": 76, "new_tensor": 76, "__class__": 76, "principl": 76, "mynewquantconfig": 76, "classvar": 76, "myquantizedtensor": 76, "tensor_data_attr": 76, "quantized_data": 76, "tensor_attribut": 76, "fill_default": 76, "notimplementederror": 76, "_my_quant_transform": 76, "my_quantization_funct": 76, "use_cutlass_kernel": 76, "my_cutlass_linear": 76, "my_triton_linear": 76, "standard": 76, "disappear": 76, "unless": 76, "extrem": 76, "sole": 76, "explicitli": [76, 85], "spooki": 76, "distanc": 76, "workaround": 76, "2338": 76, "detect": 76, "illustr": 76, "70b": 77, "gemma3": [77, 91], "4b": [77, 91], "is_avail": 77, "xpu": [77, 79, 84], "plain_int32": 77, "cu126": 77, "cu129": 77, "isol": 77, "use_cuda": 77, "use_xpu": 77, "use_cpp": 77, "tba": 78, "recogn": [79, 85], "decis": 79, "deleg": [79, 81], "x86inductorquant": [79, 83], "quantize_pt2": [79, 80, 81, 82, 83, 84], "prepare_pt2": [79, 80, 81, 83, 84], "x86_inductor_quant": [79, 83], "get_default_x86_inductor_quantization_config": [79, 83], "calibr": [79, 80, 82, 83, 84], "data_load": [79, 81, 82, 83, 84], "program": [79, 81, 82, 83, 85], "captur": [79, 81, 82, 85], "expos": [79, 81, 82], "set_glob": [79, 81, 82, 83, 84], "xiq": [79, 83], "prepare_qat_pt2": [79, 82, 83], "sample_inference_data": 79, "convert_pt2": [79, 80, 81, 82, 83, 84], "_inductor": [79, 83], "cpp_wrapper": [79, 83], "optimized_model": [79, 80, 83, 84], "converted_model": [79, 83, 84], "x86": 79, "openvino": 79, "intel": [79, 80, 83], "daniil": 80, "lyakhov": 80, "aamir": 80, "nazir": 80, "alexand": 80, "suslov": 80, "yamini": 80, "nimmagadda": 80, "kozlov": 80, "subject": [80, 82], "openvinoquant": 80, "unlock": 80, "placement": 80, "ux": [80, 81, 83], "torchdynamo": [80, 83, 84, 85], "four": 80, "mechan": [80, 83, 84], "torchvis": [80, 81, 82, 83, 84, 85], "resnet18": [80, 81, 82, 83, 84], "pt2e": [80, 81, 82, 83, 84], "__dict__": [80, 81, 82, 83, 84], "dummi": [80, 83, 84], "traced_b": [80, 83, 84], "exported_model": [80, 81, 82, 83, 84], "preset": 80, "elu": 80, "prelu": 80, "gelu": 80, "quantizationpreset": 80, "bert": [80, 83], "modeltyp": 80, "ignored_scop": 80, "exclud": 80, "layer_1": 80, "layer_2": 80, "layer_3": 80, "ignoredscop": 80, "conv2d": [80, 81, 82, 83, 84, 85], "layer_": 80, "subgraph": [80, 82], "target_devic": 80, "taken": 80, "account": [80, 92], "cpu_spr": 80, "npu": [80, 90], "targetdevic": 80, "fold": [80, 81, 83, 84], "batchnorm": [80, 81, 82, 83, 84], "prepared_model": [80, 81, 82, 83, 84], "fold_quant": 80, "finish": [80, 83], "comparison": 80, "smoothquant": 80, "biascorrect": 80, "discrep": 80, "calibration_load": 80, "dataload": [80, 81, 82], "transform_fn": 80, "data_item": 80, "calibration_dataset": 80, "smooth_quant": 80, "fast_bias_correct": 80, "deploy": [80, 83], "jerri": [81, 83, 85], "zhang": [81, 83, 84, 85], "_export": [81, 82], "fx": [81, 85], "14k": 81, "programm": [81, 83, 84], "prerequisit": [81, 88], "db": 81, "xnnpack": [81, 82, 85], "xnnpack_quant": [81, 82], "get_symmetric_quantization_config": [81, 82], "xnnpackquant": [81, 82, 85], "qconfigmap": [81, 85], "backendconfig": [81, 85], "rel": 81, "intent": [81, 85], "qconfig": [81, 85], "incompat": 81, "great": 81, "ideal": 81, "fake_qu": 81, "hidden": 81, "summari": 81, "interact": 81, "queri": [81, 85], "previous": 81, "embedding_byt": 81, "executorchquant": 81, "concaten": 81, "prone": 81, "cleaner": 81, "composed_quant": 81, "quantization_cap": 81, "concern": 81, "decoupl": 81, "minmax": 81, "freed": 81, "identitc": 81, "imagenet": [81, 82], "unzip": [81, 82], "data_path": [81, 82], "renam": [81, 82], "resnet18_pretrained_float": [81, 82], "sy": [81, 82], "numpi": [81, 82], "np": [81, 82], "resnet": [81, 82, 83], "warn": [81, 82], "filterwarn": [81, 82], "categori": [81, 82], "deprecationwarn": [81, 82], "seed": [81, 82], "191009": [81, 82], "averagemet": [81, 82], "fmt": [81, 82], "reset": [81, 82], "val": [81, 82], "avg": [81, 82], "__str__": [81, 82], "fmtstr": [81, 82], "topk": [81, 82], "predict": [81, 82], "maxk": [81, 82], "pred": [81, 82], "eq": [81, 82], "expand_a": [81, 82], "correct_k": [81, 82], "mul_": [81, 82], "criterion": [81, 82], "top1": [81, 82], "top5": [81, 82], "cnt": [81, 82], "acc1": [81, 82], "acc5": [81, 82], "load_model": [81, 82], "model_fil": [81, 82], "weights_onli": [81, 82, 92], "print_size_of_model": [81, 82], "temp": [81, 82], "p": [81, 82], "1e6": [81, 82], "prepare_data_load": [81, 82], "456": [81, 82], "std": [81, 82], "229": [81, 82], "225": [81, 82], "randomresizedcrop": [81, 82], "randomhorizontalflip": [81, 82], "totensor": [81, 82], "dataset_test": [81, 82], "resiz": [81, 82], "centercrop": [81, 82], "train_sampl": [81, 82], "randomsampl": [81, 82], "test_sampl": [81, 82], "sequentialsampl": [81, 82], "train_batch_s": [81, 82], "sampler": [81, 82], "data_loader_test": [81, 82, 83, 84], "eval_batch_s": [81, 82], "saved_model_dir": [81, 82], "float_model_fil": [81, 82], "model_to_quant": [81, 82], "rand": [81, 82, 88], "capture_pre_autograd_graph": [81, 82], "dynamic_shap": [81, 82], "dynamic_dim": [81, 82], "qconfig_opt": 81, "set_object_typ": 81, "set_module_nam": 81, "themodel": 81, "feedback": 81, "dq": 81, "fp32_op": 81, "qauntiz": 81, "x_int8": 81, "x_zero_point": 81, "weight_int8": 81, "bias_fp32": 81, "output_scal": 81, "output_zero_point": 81, "x_fp32": 81, "quantized_decompos": 81, "dequantize_per_tensor": 81, "x_i8": 81, "x_quant_min": 81, "x_quant_max": 81, "weight_fp32": 81, "weight_i8": 81, "weight_quant_min": 81, "weight_quant_max": 81, "weight_permut": 81, "permute_copi": 81, "out_fp32": 81, "addmm": 81, "out_i8": 81, "quantize_per_tensor": 81, "out_zero_point": 81, "out_quant_min": 81, "out_quant_max": 81, "float32_op": 81, "use_reference_represent": 81, "x_int16": 81, "int16": 81, "weight_int16": 81, "acc_int32": 81, "out_dtyp": 81, "bias_scal": 81, "bias_int32": 81, "div": 81, "mul": 81, "out_int8": 81, "qmin": [81, 91], "qmax": [81, 91], "date": 81, "unus": 81, "serila": 81, "consult": 81, "exportedprogram": 81, "pt2e_quantized_model_file_path": 81, "resnet18_pt2e_quant": 81, "quantized_ep": 81, "loaded_quantized_ep": 81, "loaded_quantized_model": 81, "diff": 81, "79": [81, 92], "82": 81, "55": 81, "edg": [81, 85], "went": 81, "andrew": 82, "Or": [82, 92], "move_exported_model_to_ev": [82, 83], "correctli": 82, "certain": 82, "dropout": 82, "move_exported_model_to_train": 82, "jit": 82, "recursivescriptmodul": 82, "train_one_epoch": 82, "ntrain_batch": 82, "avgloss": 82, "5f": 82, "start_tim": 82, "3f": 82, "global_avg": 82, "is_qat": [82, 83], "fusion": 82, "batchnorm2d": 82, "_native_batch_norm_legit": 82, "cudnn_batch_norm": 82, "mobilenetv2": 82, "manual": 82, "recompil": 82, "consolid": 82, "epoch": 82, "far": 82, "num_epoch": 82, "num_train_batch": 82, "num_eval_batch": 82, "num_observer_update_epoch": 82, "num_batch_norm_update_epoch": 82, "num_epochs_between_ev": 82, "nepoch": 82, "stat": 82, "subseq": 82, "disable_observ": 82, "bn": 82, "running_mean": 82, "running_var": 82, "new_arg": 82, "wish": 82, "prepared_model_copi": 82, "neval_batch": 82, "paus": 82, "resum": 82, "fail": [82, 85], "machin": [82, 92], "checkpoint_path": 82, "checkpoint_": 82, "behav": 82, "incorrectli": 82, "lesli": [83, 85], "fang": [83, 85], "weiwen": [83, 85], "xia": [83, 85], "jiong": [83, 85], "gong": [83, 85], "cnn": 83, "rnn": 83, "outstand": 83, "fourth": 83, "spr": 83, "xeon": 83, "processor": 83, "boost": 83, "memory_format": [83, 84], "channels_last": [83, 84], "onednn": [83, 84], "assum": [83, 85, 92], "word": 83, "satur": 83, "extern": [83, 90], "pure": 83, "dedic": 83, "scenario": [83, 84], "plai": [83, 84], "convolut": [83, 84, 85], "absenc": [83, 84], "enhanc": [83, 84], "mirror": [83, 84], "autocast": [83, 84], "device_typ": [83, 84], "turn": [83, 84], "cpp": 83, "qconvolut": [83, 84], "qlinear": [83, 84], "presenc": [83, 84], "conting": [83, 84], "qmaxpool2d": [83, 84], "torchinductor_freez": [83, 84], "example_x86inductorquantizer_pytorch_2_1": 83, "torchbench": 83, "measur": [83, 92], "proven": 83, "depth": 83, "example_x86inductorquantizer_qat": 83, "yan": 84, "zhiwei": 84, "wang": 84, "eikan": 84, "liangang": 84, "liu": 84, "river": 84, "cui": 84, "yifeng": 84, "xpuinductorquant": 84, "pip3": 84, "torchaudio": 84, "xpu_inductor_quantizer_exampl": 84, "xpu_inductor_quant": 84, "xpuiq": 84, "resnet18_weight": 84, "get_default_xpu_inductor_quantization_config": 84, "wherea": 84, "histogramobserv": [84, 85], "perchannelminmaxobserv": 84, "quantizationspec": [84, 85], "quantizationconfig": [84, 85], "type_check": 84, "observerorfakequantizeconstructor": 84, "get_xpu_inductor_symm_quantization_config": 84, "extra_arg": 84, "act_observer_or_fake_quant_ctr": 84, "act_quantization_spec": [84, 85], "qscheme": [84, 85], "per_tensor_symmetr": [84, 85], "observer_or_fake_quant_ctr": [84, 85], "with_arg": [84, 85], "weight_observer_or_fake_quant_ctr": 84, "weight_quantization_spec": [84, 85], "per_channel_symmetr": 84, "ch_axi": 84, "oc": 84, "ic": 84, "kh": 84, "kw": 84, "conv": [84, 85], "bias_quantization_spec": 84, "amp": 84, "indcutor": 84, "kimish": 85, "patel": 85, "explicit": 85, "quantiat": 85, "encod": 85, "convei": 85, "quantizationannot": 85, "furthermor": 85, "minmaxobserv": 85, "input_qspec_map": 85, "output_qspec": 85, "_annot": 85, "conclud": 85, "matcher": 85, "get_source_partit": 85, "add_partit": 85, "gm": 85, "itertool": 85, "add_nod": 85, "output_nod": 85, "per_tensor_affin": 85, "input_act_qspec": 85, "output_act_qspec": 85, "input_act0": 85, "input_act1": 85, "quantization_annot": 85, "substitut": 85, "among": 85, "sharedquantizationspec": 85, "maxpool": 85, "average_pool": 85, "concat": 85, "whose": 85, "edgeornod": 85, "transit": 85, "spec": 85, "conv1": 85, "conv2": 85, "fed": 85, "conv1_out": 85, "conv2_out": 85, "qspec1": 85, "cat_input0": 85, "cat_input1": 85, "implicitli": 85, "therefor": 85, "ob": 85, "rewrit": 85, "share_qparams_with_input_act0_qspec": 85, "known": 85, "beforehand": 85, "sigmoid": 85, "fixedqparamsquantizationspec": 85, "act_qspec": 85, "sigmoid_nod": 85, "input_act": 85, "derivedquantizationspec": 85, "derive_qparams_fn": 85, "observerorfakequant": 85, "observerbas": 85, "fakequantizebas": 85, "heurist": 85, "obejct": 85, "obs_or_fq": 85, "fq": 85, "act_obs_or_fq": 85, "weight_obs_or_fq": 85, "act_zp": 85, "weight_zp": 85, "bias_qspec": 85, "derived_from": 85, "backendquant": 85, "get_input_act_qspec": 85, "get_output_act_qspec": 85, "get_weight_qspec": 85, "get_bias_qspec": 85, "intermedi": 85, "straightforward": 85, "call_funct": 85, "relu_": 85, "relu_nod": 85, "maybe_conv_nod": 85, "conv1d": 85, "unexpect": 85, "recognz": 85, "unquant": 85, "subgraphmatch": 85, "conv_relu_pattern": 85, "name_node_map": 85, "input_nod": 85, "weight_nod": 85, "bias_nod": 85, "caveat": 85, "exhaust": 85, "2d": 85, "4d": 85, "symbol": 85, "outcom": 85, "tutorials_python": 86, "zip": 86, "jupyt": [86, 88], "notebook": [86, 88, 91], "tutorials_jupyt": 86, "galleri": [86, 88], "sphinx": [86, 88], "00": 87, "004": [87, 88], "template_tutori": [87, 88], "click": 88, "firstnam": 88, "lastnam": 88, "v2": 88, "topic": 88, "7802": 88, "1951": 88, "4925": 88, "8583": 88, "4958": 88, "1510": 88, "6621": 88, "7015": 88, "2061": 88, "4123": 88, "4336": 88, "7109": 88, "7913": 88, "1957": 88, "summar": 88, "takeawai": 88, "link1": 88, "link2": 88, "minut": 88, "ipynb": [88, 91], "128x128": 89, "blockwis": 89, "1x128": 89, "mi350x": 89, "bmg": 89, "md": 89, "funtion": 90, "pseudocod": [90, 92], "output_bf16": [90, 92], "input_bf16": [90, 92], "weight_bf16": [90, 92], "to_fp8": [90, 92], "weight_fp8": 90, "weight_int4": 90, "float8weightonlyconfig": 90, "incur": 90, "fairli": 90, "obtain": 90, "usabl": 90, "greater": 90, "ascend": 90, "torch_npu": 90, "perplex": [90, 91], "winogrand": 90, "3315": 90, "7380": 90, "float8_rowwis": 90, "4197": 90, "7388": 90, "int8_rowwis": 90, "3451": 90, "7340": 90, "4535": 90, "7285": 90, "6034": 90, "7316": 90, "4459": 90, "7135": 90, "05": [90, 92], "skip_vllm": 90, "measure_accuracy_and_perform": 90, "prefil": 90, "prefill_speedup": 90, "decode_speedup": 90, "59099": 90, "14380": 90, "todo": 90, "3549": 90, "102786": 90, "15218": 90, "739": 90, "058": 90, "69313": 90, "15984": 90, "173": 90, "112": 90, "30946": 90, "6612": 90, "45312": 90, "8025": 90, "464": 90, "214": 90, "int8_rowwwis": 90, "28231": 90, "4309": 90, "912": 90, "652": 90, "3550": 90, "skip_lm_ev": 90, "input_len": 90, "output_len": 90, "max_model_len": 90, "4128": 90, "2080": 90, "uintx": 90, "arm": 90, "mac": 90, "appl": 90, "silicon": 90, "m1": 90, "32gb": 90, "ram": 90, "int8_dynamic_activation_intx_weight": 90, "81": 90, "97": 90, "alongsid": 90, "_model": 90, "a6000": 90, "590": 90, "713": 90, "482": 90, "095": 90, "63": 90, "codebookweightonlyconfig": 90, "x_q": 91, "zp": 91, "x_float": 91, "x_fq": 91, "proce": 91, "torchtun": 91, "int8dynactint4qatquant": 91, "int4weightonlyqatquant": 91, "int4weightonlyembeddingqatquant": 91, "composableqatquant": 91, "fastlanguagemodel": 91, "qwen3": 91, "2507": 91, "load_in_4bit": 91, "full_finetun": 91, "target_modul": 91, "v_proj": 91, "o_proj": 91, "up_proj": 91, "down_proj": 91, "lora_alpha": 91, "qat_schem": 91, "colab": 91, "unslothai": 91, "blob": 91, "nb": 91, "qwen3_": 91, "14b": 91, "8b_qat_ful": 91, "earli": 91, "8b_qat_lora": 91, "mlabonn": 91, "finetom": 91, "100k": 91, "rate": 91, "2e": 91, "12b": 91, "1477": 91, "7745": 91, "5631": 91, "33": 91, "727": 91, "bbh": 91, "8079": 91, "7624": 91, "7831": 91, "495": 91, "1155": 91, "247": 91, "797": 91, "770": 91, "7074": 91, "6415": 91, "6666": 91, "38": 91, "088": 91, "gpqa": 91, "3232": 91, "3081": 91, "3182": 91, "887": 91, "mmlu": 91, "4909": 91, "4328": 91, "4524": 91, "735": 91, "1322": 91, "3459": 91, "8796": 91, "5483": 91, "4967": 91, "5174": 91, "116": 91, "3333": 91, "2879": 91, "303": 91, "260": 91, "2771": 91, "2562": 91, "2629": 91, "057": 91, "8x": 91, "yahma": 91, "alpaca": 91, "7527": 91, "7068": 91, "551": 91, "4074": 91, "3621": 91, "3702": 91, "7771": 91, "7262": 91, "7397": 91, "4929": 91, "4519": 91, "4686": 91, "732": 91, "_grouped_mm": 92, "grad_input_bf16": 92, "grad_output_bf16": 92, "grad_weight_bf16": 92, "405b": 92, "strive": 92, "hackabl": 92, "debugg": 92, "tool": 92, "gather": 92, "ac": 92, "\u2139": 92, "tracker": 92, "upcom": 92, "sac": 92, "0a0": 92, "gitb98af95": 92, "git890e0ac8": 92, "median": 92, "77": 92, "7689": 92, "6768": 92, "8xmi300x": 92, "dev20250811": 92, "rocm6": 92, "git4fc4068d6": 92, "commit": 92, "2c8b5947991239913d67e2f7d22a255c3e2a9694": 92, "09": 92, "5376": 92, "07": 92, "6166": 92, "6100": 92, "46": 92, "5891": 92, "torchtitan_root": 92, "float8_recipe_with_best_set": 92, "sp": 92, "repositori": 92, "estim": 92, "reproduct": 92, "float8_rooflin": 92, "your_output_filenam": 92, "csv": 92, "shape_gen_nam": 92, "sweep": 92, "float8_recipe_nam": 92, "max_ab": 92, "bf16_gemm_tim": 92, "fp8_gemm_tim": 92, "fp8_overhead_tim": 92, "formula": 92, "lh": 92, "rh": 92, "lead": 92, "medium": 92, "unit": 92, "pytest": 92, "test_bas": 92, "test_compil": 92, "test_numerics_integr": 92, "test_fsdp": 92, "test_dtensor": 92, "test_fsdp2": 92, "test_everyth": 92, "benchmrk": 92, "inference_mod": 92}, "objects": {"torchao.float8": [[5, 0, 1, "", "CastConfig"], [6, 0, 1, "", "Float8LinearConfig"], [7, 0, 1, "", "Float8LinearRecipeName"], [8, 0, 1, "", "ScalingGranularity"], [9, 0, 1, "", "ScalingType"], [10, 2, 1, "", "convert_to_float8_training"], [11, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[6, 1, 1, "", "from_recipe_name"]], "torchao.prototype.mx_formats": [[12, 0, 1, "", "MXDynamicActivationMXWeightConfig"], [13, 0, 1, "", "NVFP4DynamicActivationNVFP4WeightConfig"], [14, 0, 1, "", "NVFP4WeightOnlyConfig"]], "torchao.quantization": [[15, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [16, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [17, 0, 1, "", "Float8WeightOnlyConfig"], [18, 0, 1, "", "FqnToConfig"], [19, 0, 1, "", "Int4WeightOnlyConfig"], [20, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [21, 0, 1, "", "Int8DynamicActivationIntxWeightConfig"], [22, 0, 1, "", "Int8WeightOnlyConfig"], [23, 0, 1, "", "IntxWeightOnlyConfig"], [48, 2, 1, "", "quantize_"]], "torchao.quantization.qat": [[24, 0, 1, "", "ComposableQATQuantizer"], [25, 0, 1, "", "FakeQuantizeConfigBase"], [26, 0, 1, "", "FakeQuantizedEmbedding"], [27, 0, 1, "", "FakeQuantizedLinear"], [28, 0, 1, "", "FakeQuantizerBase"], [29, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [30, 0, 1, "", "Float8FakeQuantizeConfig"], [31, 0, 1, "", "Float8FakeQuantizer"], [32, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [33, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [34, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [35, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [36, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [37, 0, 1, "", "IntxFakeQuantizeConfig"], [38, 0, 1, "", "IntxFakeQuantizer"], [39, 0, 1, "", "QATConfig"], [40, 0, 1, "", "QATStep"], [43, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[26, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[27, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[29, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[31, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[33, 1, 1, "", "convert"], [33, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[37, 3, 1, "", "group_size"], [37, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[38, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[41, 0, 1, "", "Int4WeightOnlyEmbedding"], [42, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[41, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[44, 0, 1, "", "Int4WeightOnlyQATLinear"], [45, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [46, 2, 1, "", "disable_linear_fake_quant"], [47, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[49, 0, 1, "", "KernelPreference"], [50, 0, 1, "", "PackingFormat"], [51, 0, 1, "", "QuantizeTensorKwargs"], [52, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[49, 4, 1, "", "AUTO"], [49, 4, 1, "", "EMULATED"], [49, 4, 1, "", "MSLK"], [49, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[50, 4, 1, "", "PLAIN"]], "torchao": [[3, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[53, 0, 1, "", "PerChannelNormObserver"], [54, 0, 1, "", "WandaSparsifier"], [55, 2, 1, "", "apply_fake_sparsity"], [56, 4, 1, "", "semi_sparse_weight"], [57, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[53, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[54, 1, 1, "", "prepare"], [54, 1, 1, "", "squash_mask"], [54, 1, 1, "", "update_mask"]], "torchao.utils": [[58, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[58, 1, 1, "", "get_layout"], [58, 1, 1, "", "get_tensor_impl_constructor"], [58, 1, 1, "", "implements"], [58, 1, 1, "", "implements_torch_function"], [58, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 61, 63, 65, 68, 69, 76, 77, 91], "float8": [0, 2, 63, 65, 69, 92], "main": [0, 1, 2], "train": [0, 63, 65, 68, 69, 71, 77, 80, 81, 82, 83, 84, 89, 91, 92], "api": [0, 1, 2, 4, 59, 60, 65, 68, 69, 77, 85, 91, 92], "other": [0, 61, 63, 68, 89, 90], "type": [0, 75], "quantiz": [1, 2, 4, 48, 63, 65, 66, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92], "qat": [1, 65, 82, 89, 91], "config": [1, 2], "quantize_": [1, 4, 91], "custom": [1, 61], "legaci": 1, "prototyp": [1, 2], "workflow": [2, 77, 89], "weight": [2, 63, 66, 68, 71], "int8": 2, "int4": 2, "intx": 2, "mx": 2, "nvfp4": 2, "sparsiti": [3, 64], "util": 4, "tensor": [4, 61, 63, 73, 74, 76, 85], "subclass": [4, 61, 74, 76], "common": [4, 60, 85], "castconfig": 5, "float8linearconfig": 6, "float8linearrecipenam": 7, "scalinggranular": 8, "scalingtyp": 9, "convert_to_float8_train": 10, "precompute_float8_dynamic_scale_for_fsdp": 11, "mxdynamicactivationmxweightconfig": 12, "nvfp4dynamicactivationnvfp4weightconfig": 13, "nvfp4weightonlyconfig": 14, "float8dynamicactivationfloat8weightconfig": 15, "float8dynamicactivationint4weightconfig": 16, "float8weightonlyconfig": 17, "fqntoconfig": 18, "int4weightonlyconfig": 19, "int8dynamicactivationint8weightconfig": 20, "int8dynamicactivationintxweightconfig": [21, 90], "int8weightonlyconfig": 22, "intxweightonlyconfig": 23, "composableqatquant": 24, "fakequantizeconfigbas": 25, "fakequantizedembed": 26, "fakequantizedlinear": 27, "fakequantizerbas": 28, "float8actint4weightqatquant": 29, "float8fakequantizeconfig": 30, "float8fakequant": 31, "fromintxquantizationawaretrainingconfig": 32, "int4weightonlyembeddingqatquant": 33, "int4weightonlyqatquant": 34, "int8dynactint4weightqatquant": 35, "intxquantizationawaretrainingconfig": 36, "intxfakequantizeconfig": 37, "intxfakequant": 38, "qatconfig": 39, "qatstep": 40, "int4weightonlyembed": 41, "int4weightonlyqatembed": 42, "initialize_fake_quant": 43, "int4weightonlyqatlinear": 44, "int8dynactint4weightqatlinear": 45, "disable_linear_fake_qu": 46, "enable_linear_fake_qu": 47, "kernelprefer": [49, 61], "packingformat": 50, "quantizetensorkwarg": 51, "_choose_quant_func_and_quantize_tensor": 52, "perchannelnormobserv": 53, "wandasparsifi": 54, "apply_fake_spars": 55, "semi_sparse_weight": 56, "sparsifi": 57, "torchaobasetensor": 58, "refer": [59, 77], "benchmark": [60, 61, 71, 90, 92], "guid": [60, 61, 76], "add": [60, 76], "an": [60, 70], "recip": [60, 68, 69], "model": [60, 61, 63, 66, 69, 70, 71, 75, 76, 77, 80, 81, 82, 92], "design": [60, 64], "consider": 60, "hf": 60, "ci": 60, "dashboard": 60, "1": [60, 65, 69, 71, 75, 76, 80, 83, 84, 85, 92], "modifi": 60, "exist": 60, "configur": [60, 64, 68, 76, 81, 82], "2": [60, 65, 71, 75, 76, 80, 81, 82, 83, 84, 85, 92], "run": [60, 68], "3": [60, 65, 71, 76, 80, 83, 84, 85], "output": [60, 68, 74], "format": [60, 63], "4": [60, 80, 85], "integr": [60, 65, 75, 76, 91], "pipelin": 60, "troubleshoot": 60, "test": [60, 61, 92], "issu": 60, "best": 60, "practic": 60, "contributor": 61, "gener": 61, "extend": 61, "ad": [61, 76], "new": [61, 76], "effici": [61, 63], "kernel": [61, 63, 76, 78], "triton": 61, "hand": 61, "written": 61, "us": [61, 85], "flow": [61, 63, 70, 76, 85, 92], "torch": [61, 80, 81, 82], "compil": [61, 76, 80], "perform": [61, 71, 78, 81, 90, 92], "serial": [61, 70, 76], "featur": [61, 92], "support": [61, 75, 76], "function": [61, 81, 82], "compos": 61, "microbenchmark": [61, 68], "eval": [61, 81], "contribut": [62, 77], "overview": [63, 64, 88, 89], "basic": 63, "dtype": [63, 89], "primit": 63, "op": 63, "deriv": [63, 85, 92], "pack": 63, "algorithm": 63, "onli": 63, "dynam": [63, 66], "activ": [63, 66], "static": [63, 72], "awar": [63, 65, 82, 83, 91], "low": [63, 65], "bit": [63, 66], "optim": [63, 70, 71, 77], "case": 63, "studi": 63, "how": [63, 81, 82, 85], "work": 63, "dure": 63, "execut": 63, "save": [63, 75, 81, 82, 92], "load": [63, 81, 82, 92], "goal": 64, "context": 64, "prune": 64, "criteria": 64, "strategi": [64, 68], "pattern": [64, 85], "part": [65, 69, 71], "fine": 65, "tune": 65, "qlora": 65, "option": [65, 71, 80, 88, 92], "torchtun": 65, "axolotl": [65, 91], "rank": 65, "adapt": 65, "huggingfac": [65, 71, 76], "peft": 65, "first": 66, "exampl": [66, 68, 75, 76, 85], "set": [66, 81], "up": 66, "w8a8": 66, "int": 66, "8": 66, "size": [66, 81], "comparison": [66, 68], "speedup": 66, "next": [66, 74], "step": [66, 71, 74, 76, 88], "tutori": [67, 77, 88], "mxfp8": 68, "expert": 68, "parallel": 68, "torchtitan": [68, 69], "prerequisit": [68, 69, 80, 83, 84, 85], "understand": 68, "expect": 68, "select": 68, "gradient": 68, "high": [68, 76], "precis": 68, "combin": 68, "directli": [68, 69, 85], "complet": 68, "against": 68, "full": 68, "bf16": 68, "baselin": 68, "all": 68, "group": 68, "gemm": 68, "pre": 69, "rowwis": [69, 92], "scale": [69, 92], "tensorwis": [69, 92], "pick": 69, "import": [69, 81, 82], "note": [69, 85], "convers": 69, "deseri": 70, "what": [70, 74], "happen": 70, "when": 70, "serv": [71, 76, 77], "vllm": [71, 76], "sglang": 71, "executorch": 71, "post": [71, 80, 81, 83, 84], "infer": [71, 89, 90, 92], "transform": [71, 75, 76], "mobil": 71, "deploy": 71, "unti": 71, "embed": 71, "creat": [71, 76], "export": [71, 80, 81, 82, 83, 84, 85], "characterist": 71, "evalu": [71, 81, 91], "qualiti": 71, "assess": 71, "memori": 71, "latenc": 71, "result": [71, 91], "h100": [71, 90, 92], "machin": 71, "conclus": [71, 80, 81, 82, 83, 84, 85, 88], "calibr": [72, 81], "phase": 72, "write": [73, 74, 85], "your": [73, 74, 76], "own": [73, 74], "advanc": 73, "ar": 74, "modul": 74, "swap": 74, "which": 74, "oper": [74, 76, 85], "should": 74, "we": 74, "implement": [74, 76], "compar": 74, "hug": 75, "face": 75, "quick": [75, 77, 79, 92], "start": [75, 77, 79, 92], "usag": [75, 76], "diffus": 75, "architectur": 76, "system": 76, "class": 76, "fqn": 76, "method": 76, "minim": 76, "requir": 76, "compat": 76, "why": 76, "regist": 76, "": 76, "kei": [76, 92], "detail": 76, "hardwar": [76, 89], "specif": [76, 81, 82], "linear": 76, "benefit": 76, "trade": 76, "off": 76, "share": [76, 85], "safetensor": 76, "diagram": 76, "level": 76, "point": 76, "dispatch": 76, "bring": 76, "extern": 76, "welcom": 77, "document": 77, "pytorch": [77, 80, 81, 82, 83, 84, 85], "nativ": 77, "instal": [77, 80], "pt2e": [77, 79, 85], "openvino": 80, "backend": [80, 81, 82, 83, 84], "introduct": [80, 83, 84, 85], "nncf": 80, "captur": [80, 83, 84], "fx": [80, 83, 84], "graph": [80, 83, 84], "appli": [80, 83, 84, 92], "lower": [80, 81, 83, 84], "represent": 80, "improv": 80, "metric": 80, "motiv": [81, 85], "defin": [81, 82], "helper": [81, 82], "prepar": [81, 82], "dataset": [81, 82], "mode": 81, "convert": [81, 82], "check": 81, "accuraci": [81, 90], "debug": 81, "loop": 82, "checkpoint": [82, 92], "x86": 83, "through": [83, 84], "inductor": [83, 84], "intel": [84, 89], "gpu": [84, 92], "annot": 85, "param": 85, "fix": 85, "paramet": 85, "5": 85, "A": 85, "toi": 85, "resnet18": 85, "ir": 85, "problem": 85, "match": 85, "aten": 85, "recommend": [85, 91], "subgraphmatcherwithnamenodemap": 85, "comput": 87, "time": 87, "templat": 88, "addit": 88, "exercis": 88, "further": 88, "read": 88, "statu": 89, "nvidia": [89, 90, 92], "cuda": 89, "edg": 89, "rocm": 89, "techniqu": 90, "b200": 90, "avail": 90, "codebook": 90, "unsloth": 91, "e2": 92, "amd": 92, "mi300x": 92, "multi": 92, "user": 92, "rowwise_with_gw_hp": 92}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao.quantization.qat": [[1, "torchao-quantization-qat"]], "Main Config for quantize_": [[1, "main-config-for-quantize"]], "Custom QAT APIs": [[1, "custom-qat-apis"]], "Legacy QAT APIs": [[1, "legacy-qat-apis"]], "Prototype": [[1, "prototype"]], "torchao.quantization": [[2, "torchao-quantization"]], "Main Quantization APIs": [[2, "main-quantization-apis"]], "Workflow Configs": [[2, "workflow-configs"]], "float8 weight configs": [[2, "float8-weight-configs"]], "int8 weight configs": [[2, "int8-weight-configs"]], "int4 weight configs": [[2, "int4-weight-configs"]], "intx weight configs": [[2, "intx-weight-configs"]], "mx weight configs (prototype)": [[2, "mx-weight-configs-prototype"]], "nvfp4 weight configs (prototype)": [[2, "nvfp4-weight-configs-prototype"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "torchao.utils": [[4, "torchao-utils"]], "Tensor Subclass Utils": [[4, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[4, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[4, "quantize-api-common-utils"]], "CastConfig": [[5, "castconfig"]], "Float8LinearConfig": [[6, "float8linearconfig"]], "Float8LinearRecipeName": [[7, "float8linearrecipename"]], "ScalingGranularity": [[8, "scalinggranularity"]], "ScalingType": [[9, "scalingtype"]], "convert_to_float8_training": [[10, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[11, "precompute-float8-dynamic-scale-for-fsdp"]], "MXDynamicActivationMXWeightConfig": [[12, "mxdynamicactivationmxweightconfig"]], "NVFP4DynamicActivationNVFP4WeightConfig": [[13, "nvfp4dynamicactivationnvfp4weightconfig"]], "NVFP4WeightOnlyConfig": [[14, "nvfp4weightonlyconfig"]], "Float8DynamicActivationFloat8WeightConfig": [[15, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[16, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[17, "float8weightonlyconfig"]], "FqnToConfig": [[18, "fqntoconfig"]], "Int4WeightOnlyConfig": [[19, "int4weightonlyconfig"]], "Int8DynamicActivationInt8WeightConfig": [[20, "int8dynamicactivationint8weightconfig"]], "Int8DynamicActivationIntxWeightConfig": [[21, "int8dynamicactivationintxweightconfig"]], "Int8WeightOnlyConfig": [[22, "int8weightonlyconfig"]], "IntxWeightOnlyConfig": [[23, "intxweightonlyconfig"]], "ComposableQATQuantizer": [[24, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[25, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[26, "fakequantizedembedding"]], "FakeQuantizedLinear": [[27, "fakequantizedlinear"]], "FakeQuantizerBase": [[28, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[29, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[30, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[31, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[32, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[33, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[34, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[35, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[36, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[37, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[38, "intxfakequantizer"]], "QATConfig": [[39, "qatconfig"]], "QATStep": [[40, "qatstep"]], "Int4WeightOnlyEmbedding": [[41, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[42, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[43, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[44, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[45, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[46, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[47, "enable-linear-fake-quant"]], "quantize": [[48, "quantize"]], "KernelPreference": [[49, "kernelpreference"], [61, "kernelpreference"]], "PackingFormat": [[50, "packingformat"]], "QuantizeTensorKwargs": [[51, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[52, "choose-quant-func-and-quantize-tensor"]], "PerChannelNormObserver": [[53, "perchannelnormobserver"]], "WandaSparsifier": [[54, "wandasparsifier"]], "apply_fake_sparsity": [[55, "apply-fake-sparsity"]], "semi_sparse_weight": [[56, "semi-sparse-weight"]], "sparsify": [[57, "sparsify"]], "TorchAOBaseTensor": [[58, "torchaobasetensor"]], "API Reference": [[59, "api-reference"], [77, null]], "Benchmarking API Guide": [[60, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[60, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[60, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[60, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[60, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[60, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[60, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[60, "run-ci-benchmarks"]], "3. CI Output Format": [[60, "ci-output-format"]], "4. Integration with CI Pipeline": [[60, "integration-with-ci-pipeline"]], "Troubleshooting": [[60, "troubleshooting"]], "Running Tests": [[60, "running-tests"]], "Common Issues": [[60, "common-issues"]], "Best Practices": [[60, "best-practices"]], "Contributor Guide": [[61, "contributor-guide"]], "General Guide on Extending torchao": [[61, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[61, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[61, "adding-efficient-kernels"]], "Custom triton kernels": [[61, "custom-triton-kernels"]], "Custom hand written kernels": [[61, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[61, "using-hand-written-kernels-in-tensor-subclasses"]], "Flow": [[61, "flow"]], "Using torch.compile for Performance": [[61, "using-torch-compile-for-performance"]], "Serialization": [[61, "serialization"], [70, "serialization"]], "Other Feature Support": [[61, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[61, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[61, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[61, "model-benchmarks-and-eval"]], "Contributing": [[62, "contributing"], [77, null]], "Quantization Overview": [[63, "quantization-overview"]], "Basic DTypes": [[63, "basic-dtypes"]], "Quantization Primitive Ops": [[63, "quantization-primitive-ops"]], "Efficient kernels": [[63, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[63, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[63, "quantization-algorithms-flows"]], "Weight Only Quantization": [[63, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[63, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[63, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[63, "other-quantization-flows"]], "Training": [[63, "training"]], "Quantization Aware Training": [[63, "quantization-aware-training"], [83, "quantization-aware-training"]], "Low Bit Optimizers": [[63, "low-bit-optimizers"]], "Quantized Training": [[63, "quantized-training"], [92, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[63, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[63, "during-quantization"]], "During Model Execution": [[63, "during-model-execution"]], "During Save/Load": [[63, "during-save-load"]], "Sparsity Overview": [[64, "sparsity-overview"]], "Goal": [[64, "goal"]], "Design": [[64, "design"]], "Context": [[64, "context"]], "Pruning Configuration": [[64, "pruning-configuration"]], "Pruning Criteria": [[64, "pruning-criteria"]], "Pruning Strategy": [[64, "pruning-strategy"]], "Sparsity Pattern": [[64, "sparsity-pattern"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[65, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[65, "quantization-aware-training-qat"], [91, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[65, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[65, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[65, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[65, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[65, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[65, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[65, "float8-quantized-fine-tuning"]], "First Quantization Example": [[66, "first-quantization-example"]], "Setting Up the Model": [[66, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[66, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[66, "model-size-comparison"]], "Speedup Comparison": [[66, "speedup-comparison"]], "Next Steps": [[66, "next-steps"], [74, "next-steps"]], "Tutorials": [[67, "tutorials"], [77, null]], "MXFP8 Expert Parallel Training": [[68, "mxfp8-expert-parallel-training"], [68, "id1"]], "MXFP8 Expert Parallel APIs": [[68, "mxfp8-expert-parallel-apis"]], "Training with torchtitan": [[68, "training-with-torchtitan"]], "Prerequisites": [[68, "prerequisites"], [68, "id2"], [69, "prerequisites"], [69, "id1"], [80, "prerequisites"], [83, "prerequisites"], [84, "prerequisites"]], "Understanding the Configuration": [[68, "understanding-the-configuration"]], "Expected Output": [[68, "expected-output"]], "Recipe Selection: MXFP8 Weight Gradient with High Precision": [[68, "recipe-selection-mxfp8-weight-gradient-with-high-precision"]], "Combining with Other Parallelism Strategies": [[68, "combining-with-other-parallelism-strategies"]], "Training with torchao directly": [[68, "training-with-torchao-directly"]], "Complete Example": [[68, "complete-example"]], "Running the Example": [[68, "running-the-example"]], "Microbenchmarks": [[68, "microbenchmarks"]], "Comparison Against Full BF16 Baseline": [[68, "comparison-against-full-bf16-baseline"]], "Comparison Against BF16 All-to-Alls + MXFP8 Grouped GEMM": [[68, "comparison-against-bf16-all-to-alls-mxfp8-grouped-gemm"]], "(Part 1) Pre-training with float8": [[69, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[69, "pre-training-with-torchtitan"]], "Rowwise scaling": [[69, "rowwise-scaling"]], "Tensorwise scaling": [[69, "tensorwise-scaling"]], "Picking a recipe": [[69, "picking-a-recipe"]], "Important notes": [[69, "important-notes"]], "Pre-training with torchao directly": [[69, "pre-training-with-torchao-directly"]], "Model conversion API": [[69, "model-conversion-api"]], "Serialization and deserialization flow": [[70, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[70, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[70, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[71, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[71, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[71, "serving-and-inference"]], "Serving and Inference with vLLM": [[71, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[71, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[71, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[71, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[71, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[71, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[71, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[71, "mobile-performance-characteristics"]], "Evaluation": [[71, "evaluation"]], "Model Quality Assessment": [[71, "model-quality-assessment"]], "Memory Benchmarking": [[71, "memory-benchmarking"]], "Performance Benchmarking": [[71, "performance-benchmarking"]], "Latency Benchmarking": [[71, "latency-benchmarking"]], "Serving Benchmarking": [[71, "serving-benchmarking"]], "Results (H100 machine)": [[71, "results-h100-machine"]], "Conclusion": [[71, "conclusion"], [80, "conclusion"], [81, "conclusion"], [82, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [88, "conclusion"]], "Static Quantization": [[72, "static-quantization"]], "Calibration Phase": [[72, "calibration-phase"]], "Quantization Phase": [[72, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[73, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[74, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[74, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[74, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[74, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[74, "which-operators-should-we-implement"]], "Comparing the Outputs": [[74, "comparing-the-outputs"]], "Hugging Face Integration": [[75, "hugging-face-integration"]], "Quick Start: Usage Example": [[75, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[75, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[75, "quantizing-models-with-diffusers"]], "Saving the Model": [[75, "saving-the-model"]], "Supported Quantization Types": [[75, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[76, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[76, "configuration-system"]], "1. HuggingFace Model Configuration": [[76, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[76, "torchao-configuration-classes"]], "3. FQN Configuration": [[76, "fqn-configuration"]], "Usage Examples": [[76, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[76, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[76, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[76, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[76, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[76, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[76, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[76, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[76, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[76, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[76, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[76, "hardware-specific-linear-operations"]], "Compilation Benefits": [[76, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[76, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[76, "serialization-and-model-sharing"]], "SafeTensors Support": [[76, "safetensors-support"]], "Integration Architecture Diagrams": [[76, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[76, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[76, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[76, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Welcome to the torchao Documentation": [[77, "welcome-to-the-torchao-documentation"]], "PyTorch-Native Training-to-Serving Model Optimization": [[77, "pytorch-native-training-to-serving-model-optimization"]], "Quick Start": [[77, "quick-start"], [79, "quick-start"], [92, "quick-start"]], "Installation": [[77, "installation"]], "Workflows": [[77, null], [89, "workflows"]], "PT2E Quantization": [[77, null], [79, "pt2e-quantization"]], "Performant Kernels": [[78, "performant-kernels"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[80, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[80, "introduction"], [83, "introduction"], [84, "introduction"], [85, "introduction"]], "Post Training Quantization": [[80, "post-training-quantization"], [83, "post-training-quantization"], [84, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[80, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[80, "capture-fx-graph"], [83, "capture-fx-graph"], [84, "capture-fx-graph"]], "2. Apply Quantization": [[80, "apply-quantization"], [83, "apply-quantization"], [84, "apply-quantization"]], "3. Lower into OpenVINO representation": [[80, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[80, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[81, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[81, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[81, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[81, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[81, "export-the-model-with-torch-export"], [82, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[81, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [82, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[81, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[81, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[81, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[81, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[81, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[81, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[81, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[82, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[82, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[82, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[82, "training-loop"]], "Saving and Loading Model Checkpoints": [[82, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[82, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[83, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[83, "lower-into-inductor"], [84, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[84, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[85, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[85, "prerequisites"]], "Annotation API": [[85, "annotation-api"]], "1. Annotate Common Operator Patterns": [[85, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[85, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[85, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[85, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[85, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[85, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[85, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[85, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]], "Computation times": [[87, "computation-times"]], "Template Tutorial": [[88, "template-tutorial"]], "Overview": [[88, "overview"]], "Steps": [[88, "steps"]], "(Optional) Additional Exercises": [[88, "optional-additional-exercises"]], "Further Reading": [[88, "further-reading"]], "Workflow overview by training/QAT/inference": [[89, "workflow-overview-by-training-qat-inference"]], "Workflows status by dtype + hardware": [[89, "workflows-status-by-dtype-hardware"]], "NVIDIA CUDA": [[89, "nvidia-cuda"]], "Edge": [[89, "edge"]], "ROCM": [[89, "rocm"]], "Intel": [[89, "intel"]], "Other": [[89, "other"]], "Quantized Inference": [[90, "quantized-inference"]], "Quantization Techniques": [[90, "quantization-techniques"]], "Accuracy benchmarks": [[90, "accuracy-benchmarks"]], "Performance benchmarks": [[90, "performance-benchmarks"]], "NVIDIA B200": [[90, "nvidia-b200"]], "NVIDIA H100": [[90, "nvidia-h100"], [92, "nvidia-h100"]], "Other Available Quantization Techniques": [[90, "other-available-quantization-techniques"]], "Int8DynamicActivationIntxWeightConfig Quantization": [[90, "int8dynamicactivationintxweightconfig-quantization"]], "Codebook Quantization": [[90, "codebook-quantization"]], "torchao APIs": [[91, "torchao-apis"]], "quantize_ API (recommended)": [[91, "quantize-api-recommended"]], "Axolotl integration": [[91, "axolotl-integration"]], "Unsloth integration": [[91, "unsloth-integration"]], "Evaluation Results": [[91, "evaluation-results"]], "float8": [[92, "float8"]], "Key features": [[92, "key-features"]], "e2e training benchmarks": [[92, "e2e-training-benchmarks"]], "AMD MI300x": [[92, "amd-mi300x"]], "Multi GPU User API": [[92, "multi-gpu-user-api"]], "Performance": [[92, "performance"]], "tensorwise scaling": [[92, "tensorwise-scaling"]], "rowwise scaling": [[92, "rowwise-scaling"]], "rowwise_with_gw_hp scaling": [[92, "rowwise-with-gw-hp-scaling"]], "Derivation": [[92, "derivation"]], "Testing": [[92, "testing"]], "E2E training + inference flow": [[92, "e2e-training-inference-flow"]], "1. Train model and save checkpoint": [[92, "train-model-and-save-checkpoint"]], "2. Load checkpoint and optionally apply inference quantization": [[92, "load-checkpoint-and-optionally-apply-inference-quantization"]]}, "indexentries": {"module": [[3, "module-torchao.sparsity"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[5, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[6, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[6, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "float8linearrecipename (class in torchao.float8)": [[7, "torchao.float8.Float8LinearRecipeName"]], "scalinggranularity (class in torchao.float8)": [[8, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[9, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[10, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[11, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "mxdynamicactivationmxweightconfig (class in torchao.prototype.mx_formats)": [[12, "torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig"]], "nvfp4dynamicactivationnvfp4weightconfig (class in torchao.prototype.mx_formats)": [[13, "torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig"]], "nvfp4weightonlyconfig (class in torchao.prototype.mx_formats)": [[14, "torchao.prototype.mx_formats.NVFP4WeightOnlyConfig"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[15, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[16, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[17, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[18, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[19, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[20, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8dynamicactivationintxweightconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int8DynamicActivationIntxWeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8WeightOnlyConfig"]], "intxweightonlyconfig (class in torchao.quantization)": [[23, "torchao.quantization.IntxWeightOnlyConfig"]], "composableqatquantizer (class in torchao.quantization.qat)": [[24, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[25, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[26, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[26, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[27, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[27, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[28, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[29, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[29, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[30, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[31, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[33, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[33, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[37, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[37, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[38, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[41, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[41, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[42, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[43, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[44, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[45, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[46, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[47, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[48, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[49, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "emulated (torchao.quantization.quantize_.common.kernelpreference attribute)": [[49, "torchao.quantization.quantize_.common.KernelPreference.EMULATED"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[49, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[49, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[49, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[50, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[50, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[51, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[52, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "perchannelnormobserver (class in torchao.sparsity)": [[53, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[53, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[54, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[54, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[54, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[54, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[55, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[56, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[57, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[58, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[58, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[58, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[58, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[58, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[58, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})