Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.prototype.dtypes.FloatxTensorCoreLayout", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout", "generated/torchao.prototype.dtypes.MarlinQQQLayout", "generated/torchao.prototype.dtypes.MarlinQQQTensor", "generated/torchao.prototype.dtypes.UintxLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.prototype.dtypes.FloatxTensorCoreLayout.rst", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQLayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQTensor.rst", "generated/torchao.prototype.dtypes.UintxLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "FloatxTensorCoreLayout", "Int8DynamicActInt4WeightCPULayout", "MarlinQQQLayout", "MarlinQQQTensor", "UintxLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 18, 19, 20, 21, 35, 38, 42, 43, 46, 47, 48, 49, 50, 52, 53, 54, 58, 63, 64, 69, 71, 73, 74, 76, 77, 80, 83, 84, 85, 87, 88, 89, 91, 92, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115], "section": [2, 10, 96, 101, 106, 111, 112, 115], "introduc": [2, 12, 110, 111, 113, 114, 115], "dive": 2, "detail": [2, 8, 10, 12, 46, 95, 96, 97, 99, 101, 102, 104, 110, 111, 112, 113], "how": [2, 4, 10, 12, 13, 17, 42, 44, 48, 50, 52, 69, 81, 82, 85, 93, 95, 97, 98, 99, 101, 102, 104, 105, 106, 110, 113, 114], "integr": [2, 10, 93, 95, 98, 99, 101, 104, 113, 115], "pytorch": [2, 8, 12, 13, 16, 41, 51, 69, 93, 95, 96, 99, 101, 104, 106, 109], "optim": [2, 10, 12, 18, 35, 38, 80, 93, 95, 101, 104, 110, 112, 113, 114], "your": [2, 8, 10, 12, 93, 95, 96, 97, 99, 101, 105, 111, 112, 113, 114, 115], "machin": [2, 112], "learn": [2, 69, 97, 101, 109, 111, 113, 114, 115], "model": [2, 12, 35, 47, 56, 61, 64, 65, 66, 67, 68, 71, 75, 80, 88, 89, 91, 97, 101, 102, 104, 113, 114, 115], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 40, 41, 42, 43, 45, 51, 52, 53, 54, 58, 59, 61, 62, 65, 66, 67, 69, 73, 74, 76, 77, 84, 85, 91, 93, 95, 97, 98, 99, 102, 104, 105, 106, 111, 113, 114, 115], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 28, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 91, 95, 98, 101], "sparsiti": [2, 8, 12, 14, 18, 21, 87, 88, 89, 90, 91, 93, 95, 98, 99], "tba": [3, 11, 94], "For": [4, 8, 10, 12, 13, 46, 69, 96, 97, 98, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "full": [4, 12, 97, 102, 105, 109, 110, 112], "exampl": [4, 8, 10, 12, 13, 35, 50, 56, 58, 59, 64, 68, 69, 71, 75, 80, 81, 88, 91, 92, 96, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114], "us": [4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 61, 64, 68, 69, 71, 76, 77, 81, 82, 85, 88, 92, 93, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114], "our": [4, 10, 12, 19, 95, 97, 99, 101, 102, 104, 111, 112], "pleas": [4, 9, 10, 12, 13, 41, 64, 68, 93, 96, 97, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "refer": [4, 8, 12, 13, 71, 77, 95, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113], "readm": [4, 8, 12, 93, 97, 101], "tutori": [8, 10, 12, 13, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115], "you": [8, 9, 10, 12, 69, 88, 92, 95, 96, 97, 98, 99, 101, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115], "through": [8, 10, 12, 53, 58, 59, 93, 96, 97, 99, 102, 104, 106, 109, 110, 111, 115], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 97, 98, 99, 101, 102, 104, 105, 110, 111, 112, 113, 114], "framework": [8, 10, 12, 95, 99, 110], "The": [8, 10, 12, 13, 17, 18, 34, 36, 42, 43, 45, 55, 71, 80, 86, 88, 95, 96, 97, 98, 99, 101, 104, 105, 106, 110, 111, 112, 113, 114, 115], "contain": [8, 83, 84, 101, 104, 112, 115], "new": [8, 12, 13, 92, 95, 96, 102, 104, 111, 112, 113, 115], "architectur": [8, 93, 99, 101, 110, 111, 113, 114], "micro": 8, "current": [8, 43, 46, 47, 61, 62, 71, 80, 88, 91, 95, 96, 97, 101, 104, 105, 106, 111, 112, 114], "support": [8, 12, 13, 25, 43, 44, 46, 47, 61, 68, 69, 71, 83, 84, 91, 95, 96, 97, 98, 99, 101, 104, 110, 111, 112, 113, 114, 115], "which": [8, 10, 12, 41, 42, 71, 76, 95, 96, 98, 99, 101, 102, 106, 110, 111, 112, 113, 114, 115], "can": [8, 10, 12, 13, 22, 43, 50, 56, 69, 80, 81, 85, 92, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "quantize_": [8, 10, 12, 64, 68, 71, 80, 81, 82, 83, 84, 91, 93, 96, 97, 98, 99, 102], "sparsity_": 8, "function": [8, 12, 13, 22, 34, 58, 63, 73, 78, 79, 80, 87, 88, 89, 91, 92, 95, 96, 97, 98, 101, 102, 104, 106, 110, 115], "To": [8, 10, 12, 13, 41, 77, 95, 96, 97, 98, 99, 101, 102, 106, 111, 112, 113, 115], "correspond": [8, 12, 64, 71, 80, 96, 98, 101, 104, 114, 115], "string": [8, 31, 69, 88, 92], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 92, 93, 96, 97, 98, 104, 106, 110, 111, 112, 113, 114, 115], "py": [8, 10, 13, 41, 92, 100, 108, 109, 113, 114], "def": [8, 10, 12, 83, 91, 92, 95, 96, 97, 98, 102, 104, 106, 110, 111, 112, 113, 114, 115], "option": [8, 10, 13, 15, 23, 26, 27, 28, 30, 31, 34, 41, 43, 46, 48, 49, 52, 53, 54, 58, 59, 61, 62, 66, 68, 69, 71, 73, 74, 80, 81, 85, 88, 91, 92, 95, 96, 97, 105, 106, 111, 112, 113, 114, 115], "str": [8, 31, 34, 69, 71, 80, 88, 91, 92, 95, 104, 106, 114], "kwarg": [8, 10, 13, 58, 59, 60, 61, 65, 69, 74, 84, 87, 88, 89, 92, 96, 104, 106], "aobaseconfig": [8, 71, 80, 91, 102, 106], "code": [8, 10, 95, 96, 97, 99, 101, 102, 104, 107, 109, 111, 112, 113, 114, 115], "elif": [8, 106], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 34, 43, 48, 49, 55, 68, 69, 71, 86, 88, 92, 96, 99, 101, 104, 111, 112], "addit": [8, 12, 17, 20, 92, 95, 96, 101, 104, 105, 110, 111, 114, 115], "inform": [8, 13, 43, 96, 99, 101, 106, 110, 111], "need": [8, 10, 12, 43, 58, 63, 73, 82, 83, 84, 87, 88, 92, 96, 98, 99, 101, 104, 106, 111, 112, 113, 115], "pass": [8, 34, 48, 53, 58, 59, 63, 71, 73, 87, 92, 96, 102, 104, 106, 112, 115], "process": [8, 12, 17, 18, 20, 22, 42, 96, 101, 109, 110, 114], "here": [8, 9, 13, 71, 77, 85, 96, 97, 98, 99, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "return": [8, 10, 12, 13, 18, 19, 34, 41, 55, 69, 80, 86, 91, 92, 95, 96, 97, 98, 102, 104, 106, 110, 111, 112, 113, 114, 115], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 82, 104, 112], "now": [8, 10, 12, 44, 46, 47, 52, 95, 96, 97, 101, 102, 104, 110, 111, 113, 115], "we": [8, 10, 12, 13, 19, 43, 45, 46, 50, 52, 53, 54, 68, 69, 71, 77, 80, 85, 91, 92, 95, 96, 97, 98, 99, 101, 102, 105, 106, 110, 111, 112, 113, 114, 115], "throughout": 8, "note": [8, 10, 12, 46, 56, 68, 77, 88, 92, 96, 97, 99, 101, 104, 106, 112, 113, 114], "input": [8, 10, 13, 18, 19, 21, 31, 34, 35, 52, 53, 54, 55, 71, 75, 80, 85, 86, 88, 91, 95, 96, 97, 99, 102, 104, 110, 111, 112, 113, 114, 115], "paramet": [8, 12, 13, 17, 18, 19, 24, 27, 34, 35, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 61, 62, 69, 71, 74, 76, 77, 80, 85, 86, 88, 91, 92, 95, 96, 98, 99, 101, 104, 106, 110, 111], "like": [8, 10, 12, 17, 43, 95, 96, 97, 98, 101, 104, 105, 106, 110, 111, 112, 113, 114, 115], "bit": [8, 12, 29, 38, 42, 70, 99, 104, 105, 106, 111, 113, 114], "width": [8, 42, 70], "group": [8, 10, 12, 43, 44, 47, 49, 61, 65, 66, 67, 69, 73, 74, 76, 77, 81, 97], "size": [8, 10, 13, 19, 36, 41, 46, 47, 49, 52, 54, 69, 85, 95, 97, 98, 99, 101, 102, 104, 106, 112], "etc": [8, 10, 43, 58, 59, 82, 84, 96, 110, 115], "them": [8, 12, 58, 63, 73, 87, 115], "append": [8, 101, 111, 112], "config": [8, 12, 31, 34, 43, 45, 46, 57, 58, 59, 60, 62, 63, 64, 68, 69, 70, 71, 80, 88, 91, 96, 97, 99, 101, 102, 106, 111, 113, 114], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 44, 46, 47, 49, 58, 59, 61, 65, 68, 69, 71, 73, 74, 80, 97, 105, 106], "system": [8, 10, 82, 99], "model_architectur": 8, "type": [8, 10, 12, 13, 18, 19, 31, 32, 33, 34, 42, 43, 45, 46, 47, 48, 50, 51, 55, 69, 72, 80, 81, 82, 83, 84, 85, 86, 92, 93, 96, 98, 99, 101, 104, 106, 110, 111, 113, 114, 115], "defin": [8, 10, 17, 32, 38, 42, 58, 63, 73, 87, 88, 92, 96, 97, 101, 102, 104, 106, 110, 113, 114, 115], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 81, 82, 83, 87, 88, 92, 97, 98, 102, 104, 111, 112, 113, 115], "mycustommodel": 8, "torch": [8, 12, 13, 18, 19, 24, 31, 34, 42, 43, 45, 52, 54, 55, 58, 59, 61, 62, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 80, 81, 85, 86, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 109, 113, 114, 115], "nn": [8, 10, 12, 31, 34, 56, 61, 65, 68, 71, 80, 91, 92, 95, 96, 97, 98, 99, 101, 102, 104, 106, 111, 112, 113, 115], "modul": [8, 10, 12, 31, 32, 33, 34, 35, 50, 51, 56, 58, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 87, 88, 91, 95, 96, 97, 98, 102, 106, 110, 111, 112, 113, 114, 115], "__init__": [8, 12, 92, 97, 98, 102, 104, 106, 111, 112, 113], "self": [8, 12, 13, 92, 97, 98, 102, 104, 106, 111, 112, 113], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 19, 61, 66, 76, 85, 95, 96, 97, 98, 99, 101, 102, 105, 106, 113, 114], "super": [8, 12, 97, 98, 102, 104, 111, 112, 113], "layer1": 8, "linear": [8, 10, 12, 18, 31, 34, 43, 44, 45, 47, 48, 49, 56, 59, 61, 66, 67, 68, 71, 76, 77, 78, 79, 80, 89, 91, 92, 95, 96, 97, 98, 99, 101, 102, 104, 110, 111, 112, 113, 115], "512": [8, 95], "bia": [8, 12, 59, 76, 77, 96, 97, 98, 102, 104, 106, 112, 115], "fals": [8, 12, 13, 26, 31, 46, 48, 58, 59, 67, 68, 69, 71, 73, 74, 76, 77, 88, 95, 96, 97, 98, 99, 102, 104, 105, 106, 110, 111, 112, 114, 115], "activ": [8, 12, 43, 47, 48, 58, 59, 61, 67, 68, 69, 71, 77, 83, 84, 88, 93, 97, 99, 101, 102, 105, 106, 110, 113, 114, 115], "relu": [8, 97, 110, 115], "layer2": 8, "forward": [8, 48, 58, 59, 63, 70, 73, 76, 87, 97, 98, 101, 102, 104, 106, 111, 112, 113], "x": [8, 58, 59, 63, 70, 73, 95, 97, 98, 99, 102, 104, 106, 109, 110, 111, 112, 113, 114], "updat": [8, 93, 97, 98, 101, 111, 112, 115], "create_model_and_input_data": 8, "handl": [8, 10, 18, 21, 22], "model_typ": [8, 12, 106, 110], "m": [8, 10, 12, 80, 91, 95, 97, 98, 99, 102, 104, 111, 112, 113], "int": [8, 12, 13, 19, 22, 23, 24, 26, 27, 28, 29, 36, 38, 41, 42, 43, 45, 46, 47, 49, 52, 53, 54, 58, 59, 61, 65, 66, 67, 69, 73, 74, 76, 77, 80, 85, 88, 92, 97, 102, 104, 106], "k": [8, 10, 86, 97, 98, 102, 104, 111, 112], "n": [8, 10, 12, 97, 98, 102, 104, 111, 112, 115], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 73, 76, 77, 80, 86, 95, 97, 98, 99, 102, 104, 106, 110, 111, 112, 113, 114], "cuda": [8, 10, 12, 13, 80, 95, 97, 98, 99, 101, 102, 104, 105, 112], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 59, 95, 97, 98, 102, 104, 110, 111, 112, 113, 114], "when": [8, 10, 12, 13, 20, 52, 54, 71, 85, 92, 95, 96, 99, 101, 102, 105, 106, 110, 111, 112, 113, 114, 115], "ad": [8, 12, 13, 54, 88, 92, 96, 101, 102, 104, 112], "dimens": [8, 10, 13, 42, 52, 54, 55, 85, 95, 96, 104, 106, 111, 112], "ensur": [8, 18, 99, 112], "convent": 8, "where": [8, 21, 50, 53, 65, 66, 67, 96, 101, 106, 115], "batch": [8, 99, 102, 112], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 104, 110, 113, 114], "data": [8, 12, 13, 17, 18, 36, 38, 42, 43, 45, 46, 48, 53, 82, 92, 93, 96, 98, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "typic": [8, 12, 19, 20, 96, 97, 98, 102, 106, 115], "compat": [8, 10, 18, 69, 97], "work": [8, 10, 12, 21, 95, 98, 101, 104, 105, 106, 111, 112, 113], "cpu": [8, 10, 13, 16, 39, 98, 101, 102, 105, 106, 110, 111, 112, 113], "other": [8, 12, 13, 17, 43, 46, 70, 81, 88, 95, 98, 99, 101, 104, 106, 109, 111, 112, 113, 115], "target": [8, 10, 12, 13, 43, 45, 46, 52, 58, 59, 62, 69, 88, 97, 101, 110, 111, 112, 113, 114, 115], "method": [8, 10, 17, 18, 21, 22, 80, 88, 97, 101, 102, 104, 105, 110, 111, 112, 114, 115], "come": [8, 9, 95, 96, 99, 101, 102, 103, 105, 112, 113, 114], "soon": [8, 9, 99, 103, 112], "file": [8, 10, 95, 99, 100, 104, 106, 108, 111, 112], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 71, 93, 96, 97, 98, 101, 102, 104, 105, 110, 111, 112, 113, 114], "quantization_config_recipe_nam": 8, "int8wo": [8, 105], "int8dq": 8, "float8dq": [8, 99], "tensor": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 39, 41, 42, 45, 46, 47, 48, 52, 53, 54, 55, 58, 59, 60, 62, 63, 70, 81, 82, 83, 84, 85, 86, 88, 92, 93, 95, 97, 98, 101, 102, 105, 109, 111, 113, 114], "row": [8, 10, 44, 55, 95, 96, 101], "float8wo": 8, "output_dir": [8, 105], "result": [8, 12, 13, 55, 86, 96, 101, 102, 105, 111, 112, 113, 114, 115], "model_param": 8, "name": [8, 10, 32, 33, 50, 51, 72, 80, 81, 82, 88, 91, 92, 96, 99, 101, 104, 106, 110, 111, 112, 115], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 50, 58, 85, 95, 97, 99, 102, 111, 112], "max_pow": 8, "15": [8, 46, 95, 97, 99], "torch_compile_mod": 8, "max": [8, 10, 50, 96, 97, 102, 104, 111, 112, 115], "autotun": [8, 10, 97, 102], "runner": 8, "gener": [8, 12, 13, 58, 59, 60, 63, 70, 96, 97, 99, 101, 102, 104, 106, 107, 109, 110, 112, 113, 114, 115], "oss": 8, "databas": 8, "python": [8, 10, 97, 99, 101, 107, 109, 110, 111, 113, 114], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 99, 106], "specif": [8, 10, 12, 17, 18, 20, 21, 38, 58, 59, 77, 82, 88, 95, 96, 97, 98, 99, 101, 105, 110, 113, 114, 115], "requir": [8, 12, 13, 20, 22, 81, 92, 96, 97, 99, 101, 104, 105, 110, 113, 115], "mode": [8, 10, 46, 97, 102, 110, 112, 113, 114, 115], "extra_info": 8, "arch": 8, "nvidia": [8, 101], "a100": [8, 12, 97, 105], "sxm4": 8, "80gb": [8, 97], "1024": [8, 80, 91, 97, 98, 113], "custom": [8, 12, 17, 71, 87, 93, 95, 96, 97, 101, 104, 106, 110, 111, 113, 115], "layer": [8, 18, 34, 43, 45, 48, 49, 58, 59, 61, 65, 66, 67, 73, 74, 76, 77, 88, 89, 95, 99, 101, 102, 104, 106, 110, 115], "origin": [8, 12, 13, 19, 45, 48, 64, 85, 88, 96, 97, 98, 99, 101, 110, 111, 115], "metric": [8, 12, 88], "speedup": [8, 10, 12, 95, 96, 97, 99, 101], "wrt": 8, "bf16": [8, 12, 52, 71, 97, 101, 113, 114], "benchmark_valu": 8, "25": [8, 97], "target_valu": 8, "0": [8, 10, 12, 13, 46, 58, 69, 73, 74, 85, 88, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 108, 109, 111, 112, 114, 115], "depend": [8, 13, 98, 101, 104, 111, 112, 114], "step": [8, 12, 20, 35, 71, 72, 95, 96, 101, 110, 111, 112, 113, 114, 115], "workflow": [8, 10, 80, 81, 91, 95, 97, 101, 115], "github": [8, 13, 41, 97, 99, 105], "action": [8, 106, 111, 112], "upload": 8, "verifi": [8, 97, 98, 104], "setup": [8, 99], "suit": [8, 10, 111, 113], "unittest": 8, "discov": 8, "out": [8, 10, 12, 21, 50, 82, 88, 95, 96, 97, 99, 101, 104, 110, 111, 112, 113], "memori": [8, 10, 12, 13, 95, 96, 97, 101, 104, 105, 113, 114], "reduc": [8, 10, 12, 35, 71, 95, 99, 101, 113], "matrix": [8, 15, 36, 43, 55, 81, 86, 88, 96, 97, 101, 113], "miss": [8, 101], "properli": [8, 98], "instal": [8, 10, 95, 96, 97, 99, 105, 111, 114], "Not": [8, 101], "avail": [8, 10, 82, 96, 99, 110, 111, 112, 113, 114], "check": [8, 10, 12, 13, 41, 96, 97, 98, 99, 104, 110, 112, 115], "driver": 8, "basic": [8, 10, 20, 97, 102, 104], "shape": [8, 10, 13, 41, 55, 82, 86, 96, 97, 102, 104, 106, 111, 114], "comprehens": [8, 106, 113], "analysi": [8, 101], "enabl": [8, 10, 79, 92, 95, 96, 99, 105, 106, 113], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 34, 43, 44, 45, 46, 47, 48, 49, 61, 71, 77, 91, 95, 97, 98, 99, 101, 104, 105, 106, 110, 111, 113, 114, 115], "overhead": [8, 101, 105, 106, 113], "multipl": [8, 10, 12, 15, 43, 55, 56, 81, 83, 86, 96, 97, 101, 102, 104, 106, 113, 115], "possibl": [8, 13, 96, 101, 111, 112, 113, 115], "consist": [8, 99, 101, 104, 113, 114, 115], "reproduc": [8, 99], "differ": [8, 10, 12, 17, 46, 53, 56, 85, 86, 95, 96, 97, 98, 99, 101, 104, 105, 106, 111, 112, 113, 115], "case": [8, 9, 10, 71, 86, 99, 101, 104, 106, 110, 111, 115], "user": [8, 10, 12, 43, 56, 71, 77, 93, 95, 96, 97, 99, 101, 102, 104, 109, 111, 112, 113, 114, 115], "more": [8, 10, 12, 13, 46, 47, 95, 96, 97, 99, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114], "about": [8, 10, 12, 96, 97, 98, 99, 101, 111, 112, 113, 115], "compon": [8, 96, 104, 106], "see": [8, 10, 12, 13, 41, 46, 92, 95, 96, 97, 98, 101, 102, 104, 105, 106, 110, 111, 115], "directori": [8, 95], "intend": [9, 96, 111], "provid": [9, 10, 12, 17, 18, 21, 22, 52, 56, 75, 92, 95, 96, 99, 101, 104, 106, 111, 112, 114, 115], "instruct": [9, 12, 96, 99, 111, 112, 113], "most": [9, 10, 20, 71, 96, 99, 101, 106, 111, 112, 115], "fequent": 9, "have": [9, 10, 12, 50, 65, 66, 67, 82, 85, 88, 92, 96, 101, 102, 104, 106, 110, 111, 112, 113, 114, 115], "ani": [9, 10, 20, 61, 65, 75, 88, 96, 101, 104, 110, 112, 114], "answer": [9, 101], "creat": [9, 10, 13, 24, 25, 27, 95, 101, 104, 105, 110, 111, 113, 114, 115], "an": [9, 12, 13, 22, 26, 27, 68, 69, 71, 77, 88, 93, 95, 96, 97, 99, 101, 102, 104, 105, 110, 111, 112, 113, 114, 115], "issu": [9, 96, 97, 104, 113], "start": [10, 12, 32, 33, 50, 51, 72, 81, 82, 95, 96, 99, 101, 102, 104, 106, 110, 111, 112, 113, 114, 115], "read": [10, 104], "overview": [10, 93, 97, 106], "page": [10, 97, 113], "first": [10, 19, 55, 71, 88, 92, 96, 99, 102, 104, 105, 106, 111, 112, 115], "contribut": [10, 97, 101], "exist": [10, 51, 71, 95, 96, 101, 102, 104, 111, 115], "base": [10, 17, 20, 43, 50, 57, 70, 71, 75, 83, 84, 88, 92, 96, 97, 101, 104, 105, 106, 110, 111, 112, 113, 114, 115], "api": [10, 96, 97, 101, 102, 104, 110, 111, 112, 113, 114], "quant_api": [10, 80, 98, 99, 102], "float8tensor": [10, 43, 45, 62, 83, 96, 106], "e": [10, 12, 13, 50, 52, 54, 56, 69, 71, 80, 83, 85, 92, 95, 96, 98, 102, 104, 105, 110, 115], "g": [10, 12, 13, 50, 52, 54, 56, 69, 71, 80, 83, 85, 92, 96, 98, 102, 104, 110, 115], "oper": [10, 12, 13, 15, 17, 18, 38, 48, 53, 96, 97, 99, 110, 111, 112, 113, 114], "make": [10, 44, 46, 96, 97, 104, 106, 111, 115], "trainabl": [10, 12, 96, 104], "add": [10, 20, 92, 104, 109, 113, 115], "parallel": [10, 95, 104, 106], "primit": [10, 13, 41, 104, 111], "op": [10, 12, 13, 41, 43, 80, 81, 92, 97, 101, 104, 106, 111, 112, 113, 115], "slight": [10, 101], "variat": [10, 96], "quant_primit": [10, 13, 41, 102], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 21, 34, 42, 43, 46, 52, 54, 56, 58, 59, 68, 71, 80, 82, 85, 86, 88, 92, 95, 96, 97, 98, 99, 101, 102, 106, 110, 111, 112, 113, 114, 115], "structur": [10, 12, 21, 91, 96, 97, 98, 101, 104, 111], "deriv": [10, 13, 53, 84, 85], "pack": [10, 13, 22, 37, 38, 42, 44, 46, 82], "format": [10, 13, 18, 19, 46, 82, 99, 101, 111, 112, 115], "understand": [10, 82, 95, 113, 115], "concept": [10, 96, 109, 111, 113, 114, 115], "i": [10, 12, 86, 95, 96, 99, 101, 105, 110, 111, 112], "doe": [10, 12, 20, 71, 82, 96, 101, 104, 111, 113, 114], "alreadi": [10, 13, 104, 115], "could": [10, 96, 104, 110, 111, 113, 114, 115], "context": [10, 38, 113, 114], "also": [10, 12, 69, 80, 96, 97, 98, 101, 102, 104, 105, 106, 111, 114, 115], "write": [10, 93, 97, 110, 111, 112], "own": [10, 12, 93, 95, 97, 101, 102, 111, 112, 115], "torchaobasetensor": [10, 106], "help": [10, 12, 95, 96, 99, 106, 110, 111], "common": [10, 71, 81, 82, 83, 84, 93, 95, 96, 101], "specifi": [10, 12, 13, 31, 34, 49, 56, 58, 59, 60, 63, 70, 71, 77, 80, 81, 85, 88, 91, 95, 96, 101, 110, 111, 112, 115], "non": [10, 92, 101, 104, 110, 113, 114], "attribut": [10, 12, 92, 96, 104, 106, 113, 114], "mytensor": [10, 92], "tensor_data_nam": [10, 92], "qdata": [10, 96], "scale": [10, 13, 17, 18, 24, 27, 32, 35, 43, 50, 52, 53, 54, 55, 61, 62, 69, 74, 75, 76, 77, 85, 92, 96, 101, 102, 104, 106, 115], "tensor_attribute_nam": [10, 92], "With": [10, 104, 111, 113, 115], "abov": [10, 12, 44, 46, 50, 96, 98, 101, 102, 104, 111, 112, 115], "ll": [10, 50, 95, 96, 104, 111, 112, 115], "doc": [10, 95, 96, 97, 99, 104, 105], "mani": [10, 96, 101, 104], "still": [10, 12, 96, 101, 111, 115], "affinequantizedtensor": [10, 24, 25, 27, 41, 43, 45, 97, 98, 102, 104], "plan": [10, 43, 45, 46, 112], "move": [10, 80, 102, 106, 112, 113], "awai": 10, "from": [10, 12, 13, 19, 20, 24, 25, 27, 47, 53, 64, 68, 71, 80, 81, 85, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115], "abstract": [10, 96], "easier": [10, 115], "peopl": [10, 96, 98, 106, 115], "implement": [10, 12, 31, 46, 73, 74, 76, 77, 81, 92, 96, 98, 101, 102, 110, 111, 115], "regist": [10, 58, 63, 73, 87, 92, 96, 104], "mai": [10, 13, 53, 69, 82, 96, 98, 102, 105, 111, 112, 113, 114, 115], "well": [10, 17, 96, 97, 101, 111, 112, 115], "int4": [10, 12, 16, 37, 44, 46, 47, 50, 58, 59, 61, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 80, 91, 96, 97, 98, 99, 105, 106], "access": [10, 48, 110], "my_custom_op": 10, "call": [10, 12, 13, 58, 63, 73, 87, 96, 97, 98, 101, 102, 104, 106, 112, 114], "want": [10, 80, 91, 96, 97, 98, 101, 104, 106, 110, 111, 112, 115], "my_mm_for_mp": 10, "aten": [10, 92, 96, 97, 104, 106, 110, 111, 112, 113, 114], "default": [10, 12, 13, 15, 20, 22, 36, 42, 43, 45, 46, 52, 54, 61, 69, 77, 80, 92, 95, 96, 97, 104, 106, 110, 111, 112, 113, 114, 115], "_": [10, 92, 95, 96, 102, 106, 110, 111, 112, 113], "func": [10, 92, 96, 104, 106], "arg": [10, 13, 46, 58, 59, 60, 61, 65, 74, 88, 92, 96, 104, 106, 112, 115], "re": [10, 95, 96, 98, 99, 104, 111, 112], "input_tensor": [10, 19, 96, 106], "weight_tensor": [10, 96, 106], "some": [10, 80, 88, 92, 96, 97, 99, 101, 102, 104, 110, 111, 112, 113, 114, 115], "choic": [10, 46], "mm": [10, 80, 81, 104, 111], "recommend": [10, 12, 43, 45, 46, 47, 48, 49, 95, 96, 105, 110, 113, 114], "wai": [10, 13, 71, 95, 96, 99, 101, 102, 104, 111, 112, 115], "repres": [10, 13, 15, 17, 25, 31, 36, 57, 69, 82, 85, 88, 96, 98, 104, 111, 112], "group_mm": 10, "auto": [10, 43, 81, 99, 105, 106], "develop": [10, 97, 111, 112, 115], "choos": [10, 46, 84, 96, 101, 104, 111, 113], "whatev": 10, "think": [10, 106], "fastest": 10, "under": [10, 12, 81, 99], "condit": 10, "so": [10, 12, 95, 96, 97, 98, 101, 104, 105, 111, 112, 115], "don": [10, 88, 95, 96, 97, 101, 105, 106, 115], "t": [10, 88, 92, 95, 96, 97, 101, 102, 104, 105, 106, 111, 112, 115], "worri": 10, "debug": 10, "purpos": [10, 95, 96, 104, 111], "ha": [10, 12, 13, 71, 99, 101, 104, 106, 110, 111, 112, 114, 115], "hardwar": [10, 43, 82, 97, 99, 101, 105], "h100": [10, 96, 105], "sm89": 10, "sm90": 10, "librari": [10, 81, 82, 93, 96, 98], "whether": [10, 12, 46, 52, 69, 92, 104], "fbgemm_gpu_genai": [10, 81, 96], "granular": [10, 13, 32, 43, 46, 47, 49, 52, 54, 58, 59, 61, 62, 69, 70, 85, 95, 96, 99, 102, 106], "per": [10, 12, 13, 44, 45, 47, 48, 49, 52, 54, 61, 65, 66, 67, 69, 73, 74, 76, 77, 85, 88, 95, 96, 97, 101, 102, 114], "_choose_scale_float8": [10, 96], "_quantize_affine_float8": [10, 96], "_scaled_mm": [10, 96], "kerenel": 10, "fbgemm": [10, 96, 101], "f8f8bf16_rowwis": [10, 96], "level": [10, 88, 96, 101, 104, 110, 111, 113, 114], "reus": [10, 104], "allow": [10, 77, 96, 97, 101, 104, 110, 111, 112, 113, 115], "appli": [10, 12, 13, 43, 44, 45, 47, 48, 49, 56, 60, 61, 63, 68, 70, 71, 80, 91, 92, 96, 97, 99, 101, 106, 112], "convers": [10, 12, 13, 34], "weight": [10, 12, 18, 19, 35, 43, 44, 45, 46, 47, 48, 49, 58, 59, 61, 65, 66, 67, 69, 71, 73, 74, 76, 77, 80, 83, 88, 91, 93, 95, 97, 98, 101, 102, 104, 105, 106, 110, 111, 112, 113, 114, 115], "filter": [10, 12, 34, 95, 102], "should": [10, 12, 13, 35, 54, 58, 63, 64, 71, 73, 87, 88, 92, 95, 101, 106, 110, 111, 115], "algorithm": [10, 46, 99, 101, 110], "dynam": [10, 12, 30, 31, 35, 43, 44, 47, 48, 61, 67, 69, 77, 91, 99, 102, 104, 105, 111, 112, 113], "quant": [10, 13, 41, 96, 99, 106, 111, 114, 115], "In": [10, 12, 46, 71, 95, 96, 97, 101, 102, 104, 110, 111, 112, 113, 114, 115], "order": [10, 56, 92, 101, 104, 115], "aim": [10, 101, 114], "run": [10, 12, 35, 58, 59, 63, 73, 80, 87, 95, 96, 97, 99, 101, 104, 109, 110, 111, 112, 113, 114, 115], "fullgraph": [10, 97], "true": [10, 12, 13, 26, 31, 43, 45, 46, 47, 48, 49, 52, 53, 58, 59, 68, 69, 71, 79, 80, 91, 95, 97, 98, 99, 102, 104, 105, 106, 110, 111, 112, 113, 115], "remov": [10, 52, 88, 95, 101, 106, 111, 112], "unnecessari": 10, "graph": [10, 97, 111, 112, 115], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 97, 99, 102, 104, 109, 112, 113, 114], "inductor": [10, 93, 97, 110, 111], "save": [10, 12, 88, 92, 95, 97, 98, 99, 106], "load": [10, 92, 98, 99, 105, 106], "relev": [10, 96, 109], "object": [10, 42, 80, 91, 96, 104, 111, 112, 115], "safe": [10, 86], "global": [10, 101, 104], "after": [10, 12, 35, 95, 96, 98, 101, 105, 110, 111, 112, 113, 114, 115], "2": [10, 13, 14, 16, 18, 21, 43, 45, 46, 50, 58, 69, 73, 74, 85, 89, 91, 93, 95, 96, 101, 102, 104, 109], "5": [10, 12, 50, 58, 88, 97, 99, 101, 106, 109, 111, 112], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 96], "checkout": [10, 13, 41, 93, 96], "huggingfac": [10, 105], "transform": [10, 12, 13, 92, 102, 110, 111, 112, 113, 114], "deseri": [10, 111, 112], "save_pretrain": [10, 99, 105], "push_to_hub": [10, 99, 105, 106], "from_pretrain": [10, 12, 99, 105, 106], "diffus": [10, 99], "just": [10, 50, 69, 96, 98, 101, 104, 111, 112, 115], "talk": [10, 96, 99], "train": [10, 31, 56, 69, 71, 93, 97, 101, 104, 115], "fsdp": [10, 96], "mydtypetensor": 10, "put": [10, 91, 113, 115], "developer_api_guid": 10, "folder": [10, 99, 111, 112], "cover": [10, 109, 111, 114, 115], "follow": [10, 12, 69, 71, 92, 95, 96, 97, 99, 101, 102, 104, 105, 110, 111, 112, 113, 114, 115], "executorch": [10, 47, 80, 93, 97, 105, 111, 112], "torchchat": 10, "dtensor": [10, 104], "copi": [10, 13, 88, 97, 98, 101, 102, 104, 112, 113], "past": [10, 101], "adapt": [10, 95, 102], "befor": [10, 12, 71, 80, 96, 98, 99, 101, 102, 104, 111, 112, 115], "do": [10, 51, 55, 80, 96, 99, 101, 102, 104, 106, 111, 112, 113, 115], "singl": [10, 12, 30, 35, 43, 53, 95, 96, 97, 101, 111, 115], "comput": [10, 18, 22, 35, 45, 58, 63, 73, 81, 87, 88, 96, 101, 102, 104, 105, 111, 112, 113, 114], "intens": 10, "get": [10, 12, 19, 77, 92, 95, 96, 97, 99, 101, 106, 110, 111, 112, 113, 115], "sens": [10, 96, 104], "d": [10, 92, 99, 112], "benchmark_aq": 10, "s": [10, 12, 13, 50, 52, 54, 81, 82, 85, 92, 95, 96, 97, 99, 101, 102, 104, 111, 112, 113, 114, 115], "import": [10, 12, 64, 68, 71, 80, 91, 97, 98, 99, 101, 102, 104, 105, 106, 109, 110, 113, 114], "A": [10, 12, 13, 42, 53, 87, 92, 96, 101, 104, 105, 106, 111], "quick": [10, 93], "chang": [10, 80, 95, 97, 98, 99, 101, 102, 104, 110, 111, 112, 114, 115], "interest": [10, 101, 104], "print_op_and_shap": 10, "output": [10, 12, 31, 52, 54, 85, 95, 96, 97, 99, 101, 105, 109, 110, 111, 112, 113, 114, 115], "torch_func": 10, "built": [10, 95, 104], "_c": 10, "tensorbas": 10, "all": [10, 35, 46, 50, 53, 58, 61, 63, 65, 73, 75, 87, 88, 89, 92, 96, 97, 98, 99, 100, 101, 102, 104, 106, 107, 110, 111, 113, 115], "benchmark_your_kernel": 10, "helper": [10, 78, 79, 92], "right": [10, 44, 46, 101, 111], "1": [10, 18, 32, 33, 42, 43, 45, 46, 50, 51, 62, 72, 80, 81, 82, 84, 85, 88, 93, 96, 97, 98, 100, 101, 102, 104, 108, 109, 111, 112], "feel": [10, 96, 101, 104, 106], "free": [10, 96, 104], "either": [10, 13, 43, 62, 71, 88, 99, 101, 112, 113, 114], "one": [10, 43, 53, 58, 63, 71, 73, 87, 95, 96, 101, 104, 106, 112, 115], "probabl": 10, "keep": [10, 18, 48, 88, 96, 111], "futur": [10, 102, 105, 106, 111, 112, 113, 115], "llama": [10, 12, 99, 105, 106, 110], "llama2": 10, "llama3": [10, 12, 95, 105], "sam": 10, "modifi": [10, 34, 80, 88, 95, 101, 104], "friendli": 10, "compar": [10, 12, 88, 95, 96, 99, 111, 113, 115], "techniqu": [10, 12, 95, 98, 99, 101, 102, 104, 106], "bound": [10, 43, 62, 99, 101, 106], "each": [10, 19, 61, 69, 74, 76, 77, 87, 92, 96, 101, 102, 104, 106, 111, 112, 115], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 50, 85, 96, 97, 101, 102, 104, 115], "know": [10, 104], "end": [12, 95, 96, 99, 101, 104, 105, 106, 109, 112, 115], "pre": [12, 17, 18, 22, 93, 99, 101, 115], "serv": [12, 13, 17, 93, 95, 104, 105, 114], "flow": [12, 47, 95, 99, 101, 102, 110, 111, 112, 113, 114], "leverag": [12, 95, 97, 99, 104, 113, 114], "partner": [12, 95, 99], "showcas": [12, 95, 99], "focus": [12, 95, 96, 99, 101], "domain": [12, 13, 52, 54, 69, 95], "demonstr": [12, 95, 96, 97, 99, 104, 110, 112], "dure": [12, 13, 41, 48, 54, 69, 71, 95, 97, 99, 101, 102, 104, 110, 112], "numer": [12, 71, 76, 77, 95, 101, 111, 112, 113], "goal": [12, 71], "mitig": [12, 101], "degrad": [12, 71, 101], "eventu": [12, 71, 95], "blog": 12, "resourc": [12, 104], "small": 12, "matric": [12, 21, 101], "freez": [12, 112, 113, 114], "checkpoint": [12, 92, 95, 99, 106], "effici": [12, 22, 76, 97, 101, 102, 114], "paper": [12, 101, 109], "speed": [12, 80, 99, 101, 110], "up": [12, 19, 69, 80, 95, 96, 97, 101, 110, 111, 112, 115], "high": [12, 13, 23, 24, 25, 26, 27, 62, 71, 95, 96, 99, 101, 102, 104, 110, 111, 113, 114], "precis": [12, 13, 23, 24, 25, 26, 27, 45, 48, 61, 62, 66, 67, 71, 74, 76, 77, 96, 102, 104, 105, 110, 113, 114], "similar": [12, 101, 102, 112, 113], "inevit": 12, "actual": [12, 45, 71, 96, 102, 104, 106, 111, 112, 115], "presum": 12, "been": [12, 92, 104, 112, 113, 114, 115], "successfulli": [12, 101], "recent": [12, 93], "releas": [12, 113], "1b": [12, 105, 106], "3b": 12, "llamaguard": 12, "8b": [12, 95, 105], "improv": [12, 95, 99, 101, 111, 114, 115], "qualiti": [12, 101, 105], "involv": [12, 15, 71, 101], "two": [12, 21, 41, 43, 71, 92, 96, 97, 101, 104, 110, 111, 112, 113, 115], "separ": [12, 58, 59, 69, 101, 106, 111, 115], "prepar": [12, 56, 61, 65, 71, 88, 101, 110, 113, 114, 115], "convert": [12, 13, 19, 23, 26, 28, 29, 31, 41, 56, 64, 65, 71, 80, 91, 95, 96, 99, 101, 110, 113, 114, 115], "fake": [12, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 95, 111, 112, 115], "mean": [12, 13, 19, 50, 52, 54, 85, 92, 95, 96, 97, 101, 111, 112, 115], "valu": [12, 13, 19, 31, 32, 33, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 62, 72, 81, 82, 85, 88, 96, 101, 102, 104, 110, 111, 112, 115], "map": [12, 48, 50, 69, 92, 96, 104, 111, 115], "without": [12, 64, 96, 101, 106, 113, 115], "cast": [12, 13, 30, 32], "lower": [12, 43, 47, 62, 96, 97, 99, 101, 102, 105, 112], "replac": [12, 101, 106], "real": [12, 96, 97, 111, 115], "perform": [12, 13, 22, 35, 48, 49, 55, 58, 63, 65, 66, 67, 73, 86, 87, 95, 97, 101, 102, 104, 105, 106, 110, 112, 113, 114], "There": [12, 71, 96, 102, 104, 111, 115], "directli": [12, 50, 53, 71, 96, 101, 102, 104], "loop": [12, 95, 101], "distribut": [12, 95, 102, 104, 106, 110], "recip": [12, 31, 58, 63, 73, 87], "instead": [12, 53, 58, 63, 64, 68, 69, 71, 73, 87, 95, 97, 101, 104, 112, 113, 114, 115], "command": [12, 95], "regular": [12, 110, 113, 114], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 18, 21, 29, 89, 91, 96, 97, 98, 99, 101, 104, 105, 111, 112], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 98, 99, 102, 111, 112], "16": [12, 59, 95], "equival": [12, 69, 101, 112, 113, 115], "asymmetr": [12, 47, 50, 52, 69, 97, 102, 110, 114, 115], "token": [12, 47, 48, 67, 69, 77, 95, 99, 105], "int8": [12, 19, 47, 48, 49, 59, 67, 68, 69, 71, 77, 80, 84, 91, 96, 99, 104, 111, 113, 114, 115], "symmetr": [12, 43, 45, 47, 48, 49, 50, 52, 58, 61, 69, 104, 110, 111, 114, 115], "configur": [12, 15, 30, 31, 34, 43, 44, 45, 46, 47, 48, 49, 80, 91, 95, 96, 97, 99, 105, 113, 114, 115], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 112], "same": [12, 13, 43, 46, 52, 53, 54, 77, 85, 86, 91, 92, 95, 96, 101, 102, 104, 112, 114, 115], "wa": [12, 104, 112], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 105], "int8dynactint4weightquant": 12, "groupsiz": [12, 66, 67, 76, 77, 85], "32": [12, 46, 47, 59, 68, 69, 71, 73, 74, 80, 91, 95, 97, 98, 99, 102, 104, 112], "hellaswag": [12, 99], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 99], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 99], "ckpt": 12, "llama3_token": 12, "path": [12, 80, 86, 97, 99, 110, 111, 112, 113, 115], "tmp": [12, 97], "meta": [12, 98, 105, 106, 115], "print": [12, 88, 97, 98, 99, 104, 109, 111, 112], "version": [12, 16, 43, 45, 46, 69, 80, 96, 98, 104, 106, 111, 112, 115], "shot": [12, 101], "stderr": 12, "none": [12, 13, 15, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 41, 43, 46, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 68, 69, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 85, 88, 91, 92, 96, 102, 104, 106, 110, 111, 112, 114], "acc": [12, 111, 112], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 97, 101, 115], "openassist": 12, "oasst1": 12, "dataset": [12, 95, 99, 110, 113, 114], "find": [12, 19, 101, 111, 115], "achiev": [12, 19, 95, 101, 102, 104, 112, 113], "higher": [12, 95, 104, 105, 110, 111, 113, 114], "accuraci": [12, 95, 99, 101, 102, 110, 112, 113], "than": [12, 42, 69, 95, 96, 101, 104, 111], "recov": [12, 101, 112], "69": [12, 102], "8": [12, 22, 42, 46, 50, 58, 59, 66, 76, 95, 96, 97, 99, 106, 113, 114], "overal": [12, 93, 97, 111, 115], "vanilla": 12, "compos": [12, 56, 96, 101, 104, 111, 112, 115], "lora": 12, "yield": [12, 101], "89x": 12, "usag": [12, 13, 35, 56, 58, 59, 64, 68, 69, 71, 92, 93, 95, 99, 113, 114], "36": [12, 95, 99], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 43, 45, 46, 47, 48, 49, 53, 69, 80, 88, 92, 97, 101, 110, 112, 113, 114], "try": [12, 101, 104, 111], "fsdp2": [12, 95], "yaml": 12, "onc": [12, 101], "complet": [12, 99, 110, 114], "qat_out": 12, "quatiz": 12, "document": [12, 104, 106, 110, 111, 113], "prefer": [12, 43, 96, 104], "These": [12, 101, 104, 110, 111, 112, 115], "what": [12, 13, 41, 95, 96, 97, 99, 101, 102, 106, 109, 111, 115], "hood": 12, "mini": [12, 99], "gpu": [12, 93, 95, 97, 105, 106, 109, 110], "smaller": [12, 42, 46, 47, 97, 98], "fit": [12, 13, 22, 96, 98], "adjust": [12, 43, 45, 46, 47, 48, 49], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 95], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 95], "max_seq_len": 12, "train_loop": [12, 71], "sgd": 12, "lr": [12, 95], "001": 12, "momentum": [12, 112], "9": [12, 95], "weight_decai": 12, "1e": [12, 95], "loss_fn": 12, "crossentropyloss": [12, 111, 112], "rang": [12, 50, 95, 101, 102, 111, 112], "randint": 12, "loss": [12, 95, 101, 111, 112], "backward": [12, 35, 95, 101, 112], "zero_grad": [12, 95, 112], "next": [12, 95, 102, 111, 112, 113, 114], "scheme": [12, 48, 49, 58, 59, 71, 99, 110], "although": [12, 46, 58, 63, 73, 87, 104], "integ": [12, 13, 26, 27, 50, 52, 54, 55, 69, 70, 86, 102, 111, 112, 113], "arithmet": [12, 71], "float": [12, 13, 19, 26, 28, 29, 41, 43, 46, 50, 52, 53, 54, 58, 62, 69, 73, 74, 85, 88, 96, 97, 98, 104, 111, 112, 115], "float32": [12, 13, 24, 54, 65, 67, 69, 73, 74, 77, 85, 98, 99, 101, 102, 104, 113, 114, 115], "becaus": [12, 13, 18, 95, 98, 101, 104, 112, 115], "int8dynamicactivationint4weightconfig": [12, 71, 77, 80], "qatconfig": [12, 64, 68, 72], "swap": [12, 34, 61, 65, 95, 101, 102, 112], "fakequantizedlinear": [12, 61, 64, 78, 79], "base_config": [12, 71], "exact": [12, 77, 111, 112], "attun": 12, "benefici": 12, "later": [12, 96, 104, 111, 112, 114], "readi": [12, 95, 97, 99, 102, 104, 112], "did": [12, 47], "altern": [12, 69, 102, 104, 113, 114], "legaci": [12, 46], "offer": [12, 104, 111], "customiz": [12, 80], "unlik": [12, 102], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 97, 102, 110, 111, 112, 113, 114, 115], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 110, 111, 113, 114], "footprint": 12, "extens": [12, 104, 111, 113], "addition": [12, 113, 114], "frozen": 12, "further": [12, 104, 110, 111, 112, 113], "nf4": [12, 19], "propos": [12, 88], "express": [12, 97, 104, 110, 111, 112, 115], "subclass": [12, 13, 34, 41, 58, 63, 73, 81, 82, 87, 91, 92, 97, 98, 101, 105], "nf4tensor": 12, "cleanli": 12, "compil": [12, 80, 86, 93, 95, 96, 97, 102, 104, 113, 114], "simpli": [12, 101, 102, 104], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 26, 31, 34, 43, 45, 46, 47, 48, 49, 52, 53, 58, 59, 67, 69, 73, 74, 76, 77, 79, 80, 91, 102], "quantization_kwarg": 12, "No": [12, 96, 98, 101], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 96, 102, 104, 106], "though": [12, 104], "shown": [12, 99, 101, 112, 115], "competit": [12, 95], "baselin": [12, 95, 99, 111], "while": [12, 58, 63, 71, 73, 83, 87, 88, 99, 101, 104, 105, 110, 111, 115], "even": [12, 13, 95, 101, 115], "newer": 12, "mxfp4": [12, 96], "nvfp4": [12, 96], "blackwel": 12, "reap": 12, "benefit": [12, 44, 101, 104, 111, 114], "vari": [12, 13, 111, 112, 113, 114], "tradeoff": [12, 101, 105], "incorpor": 12, "its": [12, 101, 104, 106, 111, 115], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 95, 96, 104, 105, 106, 111], "yet": [12, 47, 51, 71, 104, 105, 106, 112, 113, 114], "invok": [12, 113], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 99, 105, 106], "torchaoconfig": [12, 99, 105, 106], "int8weightonlyconfig": [12, 80, 106], "base_model": 12, "quantization_config": [12, 99, 105, 106, 114], "peft_config": 12, "throughput": [12, 95, 99], "increas": [12, 101, 111], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 30, 31, 96], "initi": [12, 13, 75, 96, 97, 98, 112], "experi": [12, 95, 114], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 95, 97, 111], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 95], "074": [12, 95], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 95], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 95, 114, 115], "407": [12, 95], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 95], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 41, 92, 102], "aqttensorimpl": [13, 41], "block_siz": [13, 17, 19, 23, 24, 26, 27, 28, 29, 41, 52, 53, 54, 85, 96, 97, 102], "tupl": [13, 19, 23, 24, 26, 27, 28, 41, 43, 52, 53, 54, 75, 85, 88, 92, 104, 106, 111, 112, 115], "quant_min": [13, 26, 27, 28, 41, 50, 52, 53, 54, 85, 97, 104, 114, 115], "union": [13, 31, 41, 43, 52, 54, 62, 69, 80, 85], "quant_max": [13, 26, 27, 28, 41, 50, 52, 53, 54, 85, 97, 104, 114, 115], "zero_point_domain": [13, 26, 27, 28, 41, 46, 52, 53, 69], "zeropointdomain": [13, 26, 27, 28, 41, 46, 52, 53, 69], "stride": [13, 41, 104], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 99, 107, 109], "affin": [13, 14, 15, 16, 18, 21, 22, 26, 37, 39, 54, 85, 96], "point": [13, 28, 41, 46, 50, 54, 62, 69, 74, 75, 76, 77, 95, 96, 97, 98, 101, 102, 104, 111, 115], "quantized_tensor": 13, "float_tensor": [13, 104], "zero_point": [13, 17, 27, 52, 53, 54, 85, 92, 96, 101, 102, 104, 115], "happen": [13, 41, 96, 104, 111, 113], "choose_qparam": [13, 96], "dequant": [13, 19, 41, 54, 96, 97, 104, 106, 111, 113, 114, 115], "http": [13, 41, 88, 99, 101, 105, 114], "com": [13, 41, 99, 105], "ao": [13, 41, 101, 106], "blob": [13, 41], "main": [13, 41, 96, 97, 99, 101, 102, 104, 105, 111, 115], "three": [13, 88, 91, 113, 114], "choose_qparams_affin": [13, 53], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 95, 96, 101, 110, 111, 112, 113, 114], "extern": [13, 113], "regardless": 13, "intern": [13, 22], "represent": [13, 17, 25, 92, 101, 106, 111, 115], "orient": 13, "field": [13, 69, 72, 92, 115], "impl": [13, 92], "storag": [13, 18, 101], "store": [13, 18, 19, 42, 48, 83, 87, 96, 101, 105, 106, 111, 112], "plain": [13, 46, 82, 96, 106], "int_data": [13, 104], "kernel": [13, 14, 16, 18, 22, 37, 43, 44, 76, 80, 81, 97, 99, 101, 110, 113, 114], "element": [13, 21, 42, 52, 54, 61, 74, 76, 77, 85, 92, 96, 101], "share": [13, 52, 54, 85, 101], "qparam": [13, 46, 52, 54, 85], "minimum": [13, 52, 54, 85], "maximum": [13, 52, 54, 85], "zero": [13, 21, 46, 48, 52, 54, 69, 74, 75, 76, 77, 88, 101, 102, 115], "subtract": [13, 19], "unquant": [13, 115], "given": [13, 29, 41, 84, 95, 101, 106, 115], "classmethod": [13, 41, 83, 92, 102, 104, 106], "from_hp_to_floatx": 13, "input_float": [13, 23, 24, 25, 26, 27, 28, 41], "target_dtyp": [13, 23, 24, 26, 27, 30, 31, 52, 53, 96, 102], "_layout": [13, 23, 24, 25, 26, 27, 28, 41, 92, 97, 102], "layout": [13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 91, 92, 101], "scale_dtyp": [13, 23, 24, 26, 52, 53, 102], "float8": [13, 14, 15, 23, 24, 30, 31, 32, 33, 34, 35, 43, 44, 45, 61, 62, 63, 84, 93, 99, 102], "from_hp_to_floatx_stat": 13, "static": [13, 17, 19, 24, 27, 31, 53, 69, 93, 97, 111, 112, 113, 114, 115], "from_hp_to_fpx": 13, "floatx": [13, 25], "ebit": [13, 25, 38], "mbit": [13, 25, 38], "float1": [13, 25], "float7": [13, 25], "from_hp_to_intx": [13, 41], "mapping_typ": [13, 26, 47, 52, 53, 69], "mappingtyp": [13, 26, 47, 48, 52, 53, 69, 102], "ep": [13, 26, 52, 53, 69, 102, 112, 114, 115], "zero_point_dtyp": [13, 26, 52, 53, 102], "preserve_zero": [13, 26, 46, 52, 53], "plainlayout": [13, 26, 27, 47, 48, 92, 102], "use_hqq": [13, 26, 46, 105, 106], "custom_scal": [13, 26], "custom_zero_point": [13, 26], "from_hp_to_intx_stat": 13, "argument": [13, 22, 54, 69, 71, 80, 83, 92, 95, 96, 99, 113], "correct": [13, 18, 111, 112], "otherwis": [13, 49, 56, 69, 112], "desir": [13, 102], "gradient": [13, 93, 101], "implicitli": [13, 115], "complex": [13, 101], "non_block": 13, "memory_format": [13, 113, 114], "preserve_format": 13, "accord": 13, "c": [13, 92, 97, 104, 113, 114], "rule": 13, "truncat": 13, "part": [13, 93, 101, 104, 105, 112], "cannot": [13, 101, 102, 105, 106], "inf": 13, "long": [13, 104, 111], "behavior": [13, 17, 56, 106, 111, 112], "undefin": [13, 56, 88], "across": [13, 88, 99, 101, 104, 106], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 101, 112], "host": [13, 106], "both": [13, 43, 46, 71, 77, 96, 97, 101, 102, 104, 111, 113, 114, 115], "pin": 13, "pageabl": 13, "howev": [13, 101, 105, 106, 112, 115], "caution": 13, "advis": [13, 96], "good": [13, 97, 104, 115], "pin_memori": 13, "match": [13, 54, 55, 76, 77, 92, 101, 111], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 37], "mm_config": [15, 43], "float8mmconfig": [15, 43], "variabl": [15, 22, 36, 42, 88, 92, 101], "tinygemm": [16, 46, 76, 80, 97], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 69, 95, 96, 97, 99, 101, 111, 112, 113], "It": [17, 18, 20, 22, 35, 97, 101, 104, 115], "post": [17, 22, 71, 93, 96, 97, 104, 112, 115], "design": [17, 18, 21, 99, 106, 110, 111, 115], "extend": [17, 96, 101, 113], "conjunct": 17, "tensorimpl": [17, 92], "interact": [17, 111], "spars": [18, 21, 36, 58, 73, 74, 88, 101], "marlin": [18, 28, 40, 41], "pattern": [18, 21, 96, 97, 106, 110, 111], "preprocess": [18, 21], "manag": 18, "pre_process": 18, "1\u00ba": 18, "transpos": [18, 104], "sinc": [18, 44, 58, 63, 73, 87, 96, 98, 99, 101, 102, 104, 111, 112, 113, 114, 115], "2\u00ba": 18, "inject": 18, "3\u00ba": 18, "again": [18, 19, 101, 111, 115], "dim": [18, 62, 102, 104, 106, 111, 112], "tensor_meta": 19, "subclasstensorarg": 19, "n_block": 19, "scaler_block_s": [19, 29], "quantized_scal": 19, "quantization_factor": 19, "scaler_mean": 19, "quantized_data": [19, 106], "qlora": [19, 93, 99], "convert_to_norm_float_weight": 19, "normal": [19, 29, 101, 111, 112], "dequantize_scal": 19, "unpack": 19, "doubl": 19, "scaler": 19, "per_scaler_block": 19, "factor": [19, 55, 95, 101], "inpt_weight": 19, "block": [19, 36, 88, 101], "double_quantize_scal": 19, "take": [19, 58, 63, 73, 80, 87, 91, 92, 96, 101, 110, 111, 112, 113, 114, 115], "calcul": [19, 35, 43, 50, 52, 53, 62, 96, 101, 111, 115], "absmax": 19, "posit": 19, "And": [19, 43, 104, 113, 115], "per_block": 19, "int16": [19, 111], "n_scaler_block": 19, "get_original_weight": 19, "quantize_tensor_nearest": 19, "float16": [19, 85, 101], "nearest": 19, "round": [19, 50, 104], "inherit": [20, 41, 92, 104, 106, 113, 114], "metadata": [20, 92, 96, 99, 104, 106], "semi": [21, 91, 101], "everi": [21, 58, 63, 73, 87, 101, 104, 111, 112], "four": [21, 110], "prune": [21, 88], "conform": 21, "inner_k_til": [22, 46, 66, 76, 97], "core": [22, 51, 80, 102, 106, 111], "tile": 22, "affect": [22, 81, 101], "matmul": [22, 43, 45, 96, 101, 104], "qqq": [28, 40, 41], "64": [29, 36, 46, 61, 98, 99, 102, 104, 106], "256": [29, 46, 65, 66, 67, 76, 77, 99, 111, 112, 115], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "mayb": 30, "cast_config_input": 31, "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "from_recipe_nam": 31, "recipe_nam": [31, 95], "float8linearrecipenam": 31, "qualnam": [32, 33, 50, 51, 72, 81, 82], "boundari": [32, 33, 50, 51, 72, 81, 82], "strategi": 32, "module_filter_fn": [34, 95], "callabl": [34, 80, 91, 92, 106], "float8linearconfig": 34, "float8linear": [34, 95], "instanc": [34, 58, 63, 73, 80, 87, 91, 92, 98, 104, 111, 113, 114, 115], "fqn": [34, 88, 91, 95, 102], "sum": [35, 111, 112], "prototyp": [36, 37, 38, 39, 40, 41, 42, 69, 75, 96, 115], "blocksiz": 36, "number": [38, 50, 61, 74, 76, 77, 88, 99, 101, 104, 112, 113], "expon": 38, "mantissa": 38, "tensorcor": 38, "da8w4": 39, "marlinqqq": 41, "_choose_qparams_and_quantize_affine_qqq": 41, "_dequantize_affine_qqq": 41, "pack_dim": 42, "uintx": 42, "standard": [42, 106], "byte": 42, "uintxtensor": 42, "determin": [42, 52, 71, 95, 101, 106], "along": [42, 101, 106, 110], "indic": [42, 101, 115], "last": [42, 95, 110], "activation_dtyp": [43, 96], "float8_e4m3fn": [43, 45, 62, 96], "weight_dtyp": [43, 45, 96, 99], "pertensor": [43, 62, 102], "perrow": [43, 62, 96], "list": [43, 54, 56, 88, 92, 97, 104, 106, 110, 112, 115], "activation_value_lb": 43, "activation_value_ub": 43, "kernel_prefer": [43, 96], "kernelprefer": 43, "set_inductor_config": [43, 45, 46, 47, 48, 49], "fp8granular": [43, 62], "fast": [43, 101], "accumul": 43, "upper": [43, 62], "defalut": 43, "chosen": [43, 84, 101], "torchinductor": [43, 45, 46, 47, 48, 49, 113, 114], "deprec": [43, 45, 46, 64, 68], "split": [43, 45, 99, 111, 112], "int4_packing_format": [44, 46, 97], "int4packingformat": [44, 46], "preshuffl": [44, 96], "128": [44, 46, 95, 99, 102, 104, 105, 106, 114, 115], "underli": [44, 99, 104], "bigger": 44, "channel": [45, 48, 49, 61, 65, 66, 67, 69, 73, 74, 76, 77, 87, 102, 114], "tensorcoretiledlayout": [46, 97], "int4_choose_qparams_algorithm": [46, 97], "int4chooseqparamsalgorithm": 46, "groupwis": 46, "mainli": [46, 96, 110, 113, 115], "distinguish": [46, 96], "packing_format": 46, "control": [46, 47, 48, 49, 88, 101, 106, 111], "fine": [46, 47, 93, 95, 99, 101], "grain": [46, 47, 104], "variant": [46, 50, 53, 104], "hqq": [46, 96, 97], "preserv": [46, 52, 88, 99, 101, 110], "Will": 46, "subset": [46, 96], "valid": [46, 92, 99, 106, 115], "state": [46, 106], "v1": [46, 99], "v2": [46, 109], "ignor": [46, 58, 63, 73, 87, 95, 111, 112], "less": [46, 50, 101, 104, 111], "confus": [46, 96, 101, 111], "act_mapping_typ": [47, 48], "produc": [47, 97, 110, 111, 112, 113, 114], "backend": [47, 93, 97, 99, 101, 115], "marlinqqqlayout": 47, "cutlassint4packedlayout": 47, "weight_only_decod": 48, "around": [48, 95, 96, 97, 98, 111], "decod": [48, 99], "better": [48, 49, 95, 104, 111, 112, 113, 114, 115], "sai": [50, 85, 96, 105, 106, 115], "3": [50, 58, 85, 93, 95, 96, 97, 101, 105, 109, 111, 112], "7": [50, 95, 99, 113, 114], "symmetric_no_clipping_err": 50, "smin": 50, "smax": 50, "min_val_neg": [50, 104], "max_val_po": [50, 104], "By": [50, 101], "individu": [50, 101], "error": [50, 69, 95, 104, 111], "neg": 50, "placehold": [51, 96, 114], "int32": [52, 65, 69, 73, 74, 96, 97, 111, 115], "fp32": [52, 54, 69, 77, 102, 104, 111, 113], "fp16": 52, "optioanl": 52, "param": [52, 53, 88, 99], "request": [52, 54, 85], "min_val": [53, 104], "max_val": [53, 104], "observ": [53, 87, 96, 101, 102, 110, 111, 112, 113, 114, 115], "obtain": 53, "track": [53, 105, 106], "calibr": [53, 97, 110, 112, 113, 114], "mostli": [53, 71, 97], "input_dtyp": 54, "output_dtyp": [54, 73, 85], "uint8": [54, 85, 96, 102, 115], "b": [55, 92], "scales1": 55, "multipli": [55, 86, 101], "second": [55, 71, 92, 95, 96, 109, 115], "rais": [55, 68, 71, 86, 104, 106], "assertionerror": [55, 86, 104], "expect": [55, 95, 101, 104, 110, 111, 113, 114, 115], "qat": [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 93, 99, 113], "twostepquant": 56, "easili": [56, 110], "thei": [56, 95, 97, 101, 104, 111, 112, 115], "constructor": [56, 92, 104], "must": [56, 69, 71, 77, 95, 101, 105, 106, 112, 114, 115], "embed": [56, 58, 65, 68, 71, 73, 74], "my_quant": 56, "qatquantizer1": 56, "qatquantizer2": 56, "qatquantizer3": 56, "num_embed": [58, 73, 74], "embedding_dim": [58, 73, 74], "padding_idx": [58, 73, 74], "max_norm": [58, 73, 74], "norm_typ": [58, 73, 74], "scale_grad_by_freq": [58, 73, 74], "weight_config": [58, 59, 68, 71], "fakequantizeconfigbas": [58, 59, 68, 71], "intxfakequantizeconfig": [58, 59, 68, 70, 71], "fq_embed": 58, "longtensor": 58, "overridden": [58, 63, 73, 87], "within": [58, 63, 73, 87, 99, 101, 106, 113, 114], "afterward": [58, 63, 73, 87], "former": [58, 63, 73, 87], "care": [58, 63, 73, 87, 98, 101, 111], "hook": [58, 63, 73, 87, 96], "latter": [58, 63, 73, 87, 112], "silent": [58, 63, 73, 87, 113], "in_featur": [59, 76, 77, 95, 97, 98, 102, 104], "out_featur": [59, 76, 77, 95, 97, 102, 104], "activation_config": [59, 68, 71], "per_token": [59, 68, 69, 71], "is_symmetr": [59, 68, 69, 71], "fq_linear": 59, "scale_precis": [61, 65, 69, 73, 74], "rowwis": [61, 96], "hp_value_lb": 62, "hp_value_ub": 62, "float8fakequantizeconfig": 63, "fakequantizedembed": 64, "back": [64, 104], "model_with_fake_quantized_linear": 64, "zero_point_precis": [65, 69, 73, 74], "int4weightonlyqatembed": 65, "int4weightonlyembed": 65, "scales_precis": [66, 67, 76, 77], "padding_allow": 67, "valueerror": [68, 71], "torchaodtyp": 69, "is_dynam": [69, 113, 114, 115], "range_learn": 69, "simul": [69, 71, 89, 101], "older": 69, "int1": [69, 96], "int7": [69, 96], "pergroup": [69, 99], "pertoken": 69, "per_channel": 69, "peraxi": [69, 99, 102], "per_group": [69, 85], "combin": [69, 99, 101, 104, 111, 113], "leav": 69, "empti": [69, 96], "keyword": [69, 71, 83, 96], "properti": [69, 70], "throw": 69, "els": [69, 96, 99, 106, 111, 112], "symmetri": 70, "qatstep": 71, "awar": [71, 88, 93, 97, 101, 104], "ptq": [71, 112, 113], "automat": [71, 95, 99, 104, 105, 106, 109], "phase": [71, 115], "int4weightonlyconfig": [71, 80, 97, 98, 106], "experiment": [71, 110], "qat_config": 71, "act_config": 71, "alwai": [71, 99, 104], "One": [71, 101, 104, 106, 115], "enum": [72, 81], "example_input": [75, 97, 98, 102, 110, 111, 112, 113, 114, 115], "intxfakequantizerbas": 75, "weightonlyint4linear": 76, "hardcod": [77, 115], "mod": [78, 79, 95, 101, 104], "disabl": [78, 104, 112], "filter_fn": [80, 91], "_is_linear": [80, 102], "inplac": [80, 88, 97], "fulli": [80, 91, 99, 101, 111], "qualifi": [80, 91, 101], "final": [80, 96, 97, 101, 110, 111, 112, 113, 114, 115], "predefin": [80, 82, 115], "execut": [80, 100, 104, 108], "int8dynamicactivationint8weightconfig": [80, 91], "int4_weight_onli": 80, "sequenti": [80, 91, 95], "select": [81, 111], "found": [81, 96, 97, 99, 101, 102, 104], "nativ": [81, 93, 95, 96, 104, 111], "laid": [82, 96], "opaqu": 82, "decid": [82, 101, 102], "adopt": [82, 96], "creation": [83, 106], "construct": [83, 96, 111, 115], "from_hp": [83, 96], "cl": [83, 92, 102, 104, 106], "quant_kwarg": [83, 84], "quantizetensorkwarg": 84, "flexibl": [84, 101, 104, 110, 113], "variou": 84, "tabl": [85, 92, 95, 96, 101], "show": [85, 95, 97, 99, 101, 106, 111, 112], "per_tensor": 85, "per_axi": 85, "axi": [85, 102], "mat2": 86, "consid": [86, 101], "cubla": 86, "fallback": [86, 106], "j": 86, "l2": [87, 101], "norm": [87, 88, 101], "buffer": 87, "x_orig": 87, "sparsity_level": [88, 101], "semi_structured_block_s": 88, "wanda": 88, "sparsifi": [88, 93, 98, 101], "arxiv": [88, 101], "org": [88, 99, 101, 114], "ab": [88, 101], "2306": 88, "11695": 88, "product": [88, 99, 105, 106, 113, 115], "magnitud": [88, 101], "dict": [88, 92, 104, 106, 114, 115], "parametr": 88, "deepcopi": [88, 97, 102, 104, 112], "squash_mask": [88, 101], "params_to_keep": 88, "params_to_keep_per_lay": 88, "squash": 88, "mask": [88, 101], "appropri": [88, 110, 111, 112, 113, 114], "sparse_param": 88, "attach": [88, 101, 115], "kei": [88, 101, 109], "xdoctest": 88, "skip": [88, 96, 101], "local": [88, 99, 101], "hasattr": [88, 106], "submodule1": 88, "linear1": [88, 97, 98, 102, 104], "foo": [88, 111], "bar": [88, 111], "submodule2": 88, "linear42": 88, "baz": 88, "42": [88, 102], "24": 88, "ones": [88, 112], "update_mask": 88, "tensor_nam": [88, 106], "statist": [88, 101, 102, 111, 112], "retriev": 88, "act_per_input": 88, "Then": [88, 104, 114, 115], "whole": [88, 115], "alia": [90, 92, 106], "semisparseweightconfig": 90, "sparsify_": 91, "apply_tensor_subclass": 91, "essenti": [91, 106, 110], "semi_sparse_weight": 91, "semisparselayout": 91, "sparsemarlinlayout": 91, "isinst": [91, 95, 101, 102, 104, 106, 112, 115], "sparse_api": 91, "commonli": [92, 95, 101], "includ": [92, 95, 96, 104, 110, 113, 114, 115], "_get_to_kwarg": 92, "register_layout": 92, "plainaqttensorimpl": [92, 102], "get_tensor_impl_constructor": 92, "tensor_impl_ctr": 92, "simplifi": [92, 110, 111, 113, 114], "implment": 92, "tensor_data": 92, "optional_tensor_data_nam": 92, "boilerpl": 92, "optional_tensor_attribute_nam": 92, "__new__": [92, 104, 106], "exaclti": 92, "present": [92, 101], "__tensor_flatten__": [92, 104, 106], "flatten": 92, "attribute_nam": 92, "__tensor_unflatten__": [92, 104, 106], "tensor_data_dict": [92, 104, 106], "_apply_fn_to_data": [92, 106], "recreat": 92, "__repr__": [92, 104], "_same_metadata": 92, "between": [92, 96, 101, 104, 106, 110, 112, 113, 115], "__setstate__": 92, "serial": [92, 93, 96, 105, 111, 112], "old": 92, "maintain": [92, 99, 101], "bc": 92, "contigu": [92, 96, 113, 114], "detach": [92, 104, 106], "clone": [92, 99, 106], "copy_": [92, 106], "_to_copi": [92, 106], "f": [92, 95, 96, 98, 99, 101, 102, 104, 106, 111, 112], "h": [92, 99], "layout_class": 92, "tensorimplclass": 92, "from_plain": 92, "tensor_class": 92, "aten_op": 92, "decor": [92, 104, 106], "__torch_dispatch__": [92, 104], "implements_torch_funct": 92, "torch_fn": 92, "__torch_function__": [92, 96, 104], "registr": 92, "aqt": 92, "introduct": [93, 96, 99], "highlight": [93, 104, 109], "guid": [93, 96, 99, 110], "contributor": [93, 96, 97], "benchmark": [93, 95, 97, 105, 110, 113, 114], "tune": [93, 95, 99, 101, 110], "vllm": [93, 105], "sglang": [93, 105], "hug": [93, 99], "face": [93, 96, 99, 101, 111], "advanc": [93, 102, 104, 110, 113, 114], "export": [93, 96], "x86": [93, 97], "intel": [93, 110, 113], "openvino": [93, 97], "5x": 95, "cluster": [95, 96], "34": 95, "43x": 95, "2k": 95, "h200": 95, "latest": 95, "offic": 95, "offici": [95, 96], "sever": [95, 106, 110, 115], "popular": 95, "flagship": 95, "form": [95, 96, 101], "quickli": [95, 104], "batteri": 95, "fork": 95, "build": [95, 96, 101, 104, 106, 111], "top": [95, 96, 104, 110, 111, 112, 113, 114], "virtual": 95, "environ": [95, 99], "conda": 95, "venv": 95, "download": [95, 99, 107, 109, 111, 112, 114], "job": 95, "below": [95, 96, 101, 104, 105, 106, 109, 110], "root": [95, 99], "launch": 95, "ngpu": 95, "config_fil": 95, "train_config": 95, "llama3_8b": 95, "toml": 95, "run_train": 95, "sh": [95, 99], "hyperparamet": 95, "edit": [95, 99], "line": [95, 101, 105], "flag": [95, 112], "termin": 95, "rank0": 95, "titan": 95, "2025": [95, 109], "06": 95, "04": 95, "08": 95, "51": 95, "48": 95, "info": 95, "2254": 95, "27": 95, "34gib": 95, "28": 95, "78": 95, "tp": [95, 106], "375": 95, "tflop": 95, "21": 95, "73": [95, 102], "mfu": 95, "20": [95, 99, 112], "58": 95, "557": 95, "7069": 95, "99gib": 95, "62": 95, "034": 95, "35": [95, 99, 102], "41": [95, 99], "19": 95, "52": 95, "224": [95, 102, 110, 111, 112, 113, 114], "9196": 95, "022": 95, "406": [95, 111, 112], "65": 95, "904": 95, "1423": 95, "014": 95, "23": [95, 102], "As": [95, 111, 115], "warmup": 95, "7k": 95, "99gb": 95, "peak": [95, 99, 105], "against": 95, "02": 95, "37": 95, "404": 95, "2611": 95, "22gib": 95, "595": 95, "47": 95, "49": [95, 102], "027": 95, "4260": 95, "89gib": 95, "344": 95, "367": 95, "39": 95, "03": 95, "01": 95, "988": 95, "9482": 95, "321": 95, "366": 95, "14": 95, "991": 95, "1183": 95, "300": 95, "364": 95, "89": 95, "40": 95, "4659": 95, "291": 95, "84": 95, "769": 95, "gc": 95, "peform": 95, "period": 95, "collect": [95, 101], "3k": 95, "89gb": 95, "11x": 95, "nearli": 95, "ident": [95, 101], "performan": 95, "vs": [95, 101, 111, 115], "curv": [95, 101], "omit": [95, 96, 111, 112, 113], "648": 95, "2648": 95, "28gib": 95, "71": 95, "26": 95, "475": 95, "9106": 95, "91gib": 95, "53": [95, 99], "503": 95, "434": 95, "43": 95, "94": [95, 111], "166": 95, "0774": 95, "663": 95, "443": 95, "44": [95, 102], "87": 95, "50": [95, 101, 102, 110, 111, 113, 114], "885": 95, "3233": 95, "643": 95, "442": 95, "66": [95, 99, 102], "76": 95, "613": 95, "6150": 95, "637": 95, "72": [95, 99], "6k": 95, "91gb": 95, "21x": [95, 99], "tl": 95, "dr": 95, "priorit": 95, "accur": [95, 101, 110], "stabil": 95, "cost": [95, 102], "slightli": [95, 104], "impact": [95, 99, 106], "outlier": 95, "caus": 95, "underflow": 95, "8xh100": 95, "box": [95, 101, 113], "toi": [95, 97, 102, 104, 113], "convert_to_float8_train": 95, "recurs": 95, "kind": [95, 111], "over": [95, 101, 111, 112], "gemm": [95, 113, 114], "snippet": [95, 111, 112], "float8_linear_util": 95, "float8_linear": 95, "sampl": [95, 111, 113, 114], "adamw": 95, "being": [95, 101, 106, 113, 114], "elig": 95, "divis": 95, "label": 95, "fake_label": 95, "ones_lik": 95, "mse_loss": 95, "model_state_dict": 95, "state_dict": [95, 98, 111, 112], "optimizer_state_dict": 95, "pth": [95, 111, 112], "explor": [95, 97, 114], "few": [95, 104, 111, 112], "lai": 96, "stack": [96, 99], "awq": 96, "gptq": 96, "int4tensor": 96, "int4preshuffledtensor": 96, "uint1": 96, "uint7": 96, "float3": 96, "triton": [96, 113, 114], "overload": [96, 101], "term": [96, 101, 111, 115], "extra": [96, 99], "matter": [96, 101], "float4_e2m1fn_x2": 96, "float8_e4m3fnuz": 96, "float8_e5m2": 96, "float8_e5m2fnuz": 96, "float8_e8m0fnu": 96, "pr": 96, "shell": 96, "dervi": 96, "mxfp8": 96, "preicison": 96, "mention": [96, 111], "previou": [96, 99, 111, 112, 113, 114], "accommod": 96, "choose_qparams_affine_with_min_max": 96, "min": [96, 102, 104, 111, 115], "raw": 96, "quantize_fp8_row": 96, "int_matmul": 96, "int_scaled_matmul": 96, "reli": [96, 97, 101, 102, 104], "handwritten": 96, "On": [96, 97], "glue": 96, "everyth": 96, "togeth": [96, 99, 111, 113, 115], "anoth": [96, 101, 104, 111, 115], "side": 96, "swizzl": 96, "dtpype": 96, "act": 96, "adjac": 96, "special": [96, 101, 110, 111], "float8rowwisetensor": 96, "float8blockwisetensor": 96, "close": [96, 101], "low_precision_v": 96, "high_precision_v": 96, "procedur": 96, "especi": [96, 98, 101, 113, 114], "bitwidth": [96, 115], "codebook": 96, "index": [96, 99, 101, 114], "vector": [96, 101, 113], "kmean": 96, "tradition": 96, "explain": [96, 110, 113], "simplest": [96, 101], "easi": [96, 99], "linear_modul": 96, "runtim": [96, 111], "question": [96, 98, 101, 104, 115], "activation_granular": 96, "act_quant_kwarg": 96, "weight_granular": [96, 99], "quantized_weight": [96, 106], "float8_dtyp": 96, "haven": 96, "seen": 96, "pt2": [96, 104, 113], "autoround": 96, "multitensor": 96, "sure": [96, 99, 115], "open": [96, 101], "describ": [96, 98, 101, 109, 111, 112], "finetun": [96, 99], "quantized_train": 96, "progress": [96, 105, 106], "lot": [96, 101], "connect": [96, 115], "walk": [96, 102, 104, 109, 110, 113], "float8dynamicactivationfloat8weightconfig": 96, "len": [96, 99, 106, 111, 112, 115], "_choose_quant_func_and_quantize_tensor": 96, "relat": [96, 101], "xq": 96, "reshap": [96, 111, 112], "wq": 96, "x_scale": [96, 111], "w_scale": 96, "out_shap": 96, "entri": 97, "mutat": 97, "logic": [97, 104, 106], "toylinearmodel": [97, 98, 102], "linear2": [97, 98, 102, 104], "eval": [97, 98, 99, 102, 110, 112, 113, 114], "faster": [97, 101], "model_bf16": 97, "uint4": 97, "int4mm": 97, "mix": [97, 99, 110, 113, 114], "tile_packed_to_4d": 97, "stai": [97, 104], "tensor_impl_dtyp": 97, "roughli": [97, 101], "quarter": 97, "os": [97, 111, 112], "int4_model": 97, "pt": [97, 99], "bfloat16_model": 97, "int4_model_size_mb": 97, "getsiz": [97, 111, 112], "bfloat16_model_size_mb": 97, "2f": [97, 111, 112], "mb": [97, 98, 100, 108, 111, 112], "00": [97, 100, 108], "benchmark_model": 97, "unwrap_tensor_subclass": 97, "num_run": 97, "100": [97, 104, 111, 112], "_dynamo": [97, 104], "reset": [97, 111, 112], "bf16_time": 97, "int4_tim": 97, "time": [97, 101, 104, 105, 109, 110, 111, 112], "3f": [97, 112], "ms": 97, "1fx": 97, "393": 97, "410": 97, "9x": 97, "recogn": [97, 115], "decis": 97, "pt2e": [97, 110, 111, 112, 113, 114], "fuse": [97, 101, 104, 112], "deleg": [97, 111], "x86inductorquant": [97, 113], "quantize_pt2": [97, 110, 111, 112, 113, 114], "prepare_pt2": [97, 110, 111, 113, 114], "x86_inductor_quant": [97, 113], "get_default_x86_inductor_quantization_config": [97, 113], "float_model": [97, 104, 110, 111, 112, 113, 114], "data_load": [97, 111, 112, 113, 114], "no_grad": [97, 104, 110, 111, 112, 113, 114], "imag": [97, 105, 110, 111, 112, 113, 114], "program": [97, 111, 112, 113, 115], "captur": [97, 111, 112, 115], "expos": [97, 111, 112], "set_glob": [97, 111, 112, 113, 114], "xiq": [97, 113], "prepare_qat_pt2": [97, 112, 113], "sample_inference_data": 97, "convert_pt2": [97, 110, 111, 112, 113, 114], "wrapper": [97, 104, 113], "_inductor": [97, 113], "cpp_wrapper": [97, 113], "optimized_model": [97, 110, 113, 114], "converted_model": [97, 113, 114], "xpu": [97, 114], "simpl": [97, 101, 102, 104, 110, 113, 114], "visit": 97, "would": [97, 101, 104, 112, 114], "forget": 97, "tempfil": [98, 105], "get_model_size_in_byt": 98, "ref": [98, 111], "namedtemporaryfil": 98, "seek": [98, 101], "m_load": 98, "load_state_dict": [98, 111, 112], "assign": 98, "assert": [98, 102, 104, 106, 115], "equal": [98, 101], "thing": [98, 101, 104, 111], "float_weight1": 98, "float_weight2": 98, "quantized_weight1": 98, "quantized_weight2": 98, "go": [98, 104, 109, 115], "techinqu": 98, "reduct": [98, 99, 101, 104], "4x": [98, 99], "0625": 98, "reason": [98, 101], "avoid": [98, 101], "affine_quantized_tensor": 98, "deploi": 99, "engin": 99, "seamlessli": [99, 104, 113, 114], "seamless": [99, 113], "hf": [99, 105], "signific": [99, 101], "pip": [99, 105, 110, 111], "url": [99, 114], "whl": [99, 114], "nightli": 99, "cu128": 99, "push": [99, 101, 105, 106], "hub": [99, 105, 106], "server": [99, 106], "phi": 99, "fp8": 99, "microsoft": 99, "o3": 99, "client": 99, "curl": 99, "localhost": 99, "8000": 99, "chat": 99, "content": 99, "applic": 99, "messag": 99, "role": 99, "give": [99, 101, 104], "me": 99, "short": 99, "larg": [99, 104, 113], "languag": 99, "temperatur": 99, "top_p": 99, "95": 99, "top_k": 99, "max_token": 99, "32768": 99, "vram": 99, "15x": 99, "2x": [99, 101], "littl": [99, 106], "packag": [99, 105], "git": [99, 105], "acceler": [99, 101, 105], "autotoken": [99, 105], "pipelin": 99, "random": [99, 101, 111, 112], "manual_se": [99, 111, 112], "model_path": 99, "device_map": [99, 105, 106], "trust_remote_cod": 99, "ai": 99, "assist": 99, "eat": 99, "banana": 99, "dragonfruit": 99, "smoothi": 99, "blend": 99, "milk": 99, "honei": 99, "salad": 99, "slice": [99, 106], "lemon": 99, "juic": 99, "solv": [99, 101, 104], "equat": 99, "pipe": [99, 105], "text": 99, "generation_arg": 99, "max_new_token": 99, "500": 99, "return_full_text": 99, "do_sampl": 99, "generated_text": 99, "lm_head": 99, "those": [99, 101, 102, 104], "ti": 99, "autoprocessor": 99, "modeling_util": 99, "find_tied_paramet": 99, "model_id": [99, 105], "untied_model": 99, "getattr": [99, 106], "get_text_config": 99, "tie_word_embed": 99, "setattr": [99, 104], "_tied_weights_kei": 99, "user_id": 99, "your_user_id": 99, "model_nam": [99, 110, 113, 114], "save_to": [99, 105], "save_to_local_path": 99, "int8dynamicactivationintxweightconfig": 99, "ve": [99, 101], "intxweightonlyconfig": 99, "fqntoconfig": [99, 106], "untied_model_id": 99, "untied_model_local_path": 99, "embedding_config": 99, "linear_config": 99, "weight_scale_dtyp": 99, "quant_config": 99, "_default": [99, 106], "embed_token": 99, "quant_typ": [99, 105, 106], "include_embed": 99, "untie_embedding_weight": 99, "modules_to_not_convert": 99, "quantized_model": [99, 104, 105, 110, 111, 112], "safe_seri": [99, 105, 106], "pte": 99, "cd": 99, "install_requir": 99, "phi_4_mini": 99, "convert_weight": 99, "pytorch_model": 99, "bin": 99, "pytorch_model_convert": 99, "export_llama": 99, "kv": 99, "use_sdpa_with_kv_cach": 99, "get_bos_id": 99, "199999": 99, "get_eos_id": 99, "200020": 99, "max_seq_length": 99, "max_context_length": 99, "output_nam": 99, "phi4": 99, "phone": 99, "io": 99, "2gb": 99, "iphon": 99, "pro": [99, 101], "17": 99, "sec": 99, "test": [99, 105, 109, 111, 113], "lm": 99, "har": 99, "eleutherai": 99, "lm_eval": 99, "model_arg": 99, "pretrain": [99, 101, 110, 111, 112, 113], "reset_peak_memory_stat": 99, "prompt": [99, 105], "hei": 99, "consciou": 99, "templated_prompt": 99, "apply_chat_templ": 99, "add_generation_prompt": 99, "templat": [99, 100, 107, 108], "return_tensor": 99, "generated_id": 99, "output_text": 99, "batch_decod": 99, "skip_special_token": 99, "clean_up_tokenization_spac": 99, "respons": 99, "mem": [99, 100, 108], "max_memory_reserv": 99, "1e9": 99, "02f": 99, "gb": 99, "hello": [99, 105], "ye": 99, "am": 99, "digit": 99, "todai": 99, "70": [99, 102], "bench": 99, "vllm_disable_compile_cach": 99, "project": 99, "vllm_use_precompil": 99, "sharegpt": 99, "wget": 99, "co": 99, "anon8231489123": 99, "sharegpt_vicuna_unfilt": 99, "resolv": 99, "sharegpt_v3_unfiltered_cleaned_split": 99, "tree": 99, "num": 99, "benchmark_serv": 99, "16x": 99, "1s": 99, "14x": 99, "num_prompt": 99, "req": 99, "57": [99, 102], "1000": [99, 113], "68": 99, "80": 99, "entir": [99, 111, 112], "ml": 99, "gain": [99, 101, 114], "eas": 99, "accept": [99, 115], "trade": [99, 101], "off": [99, 101], "004": [100, 108, 109], "total": [100, 108, 109], "galleri": [100, 107, 109], "tutorials_sourc": 100, "template_tutori": [100, 108, 109], "neural": [101, 110, 113], "network": [101, 104, 110, 113], "latenc": 101, "carefulli": 101, "pai": 101, "low": [101, 104, 105, 110], "price": 101, "f1": 101, "problem": [101, 104], "research": [101, 109], "fragment": 101, "rightfulli": 101, "spent": 101, "figur": [101, 111], "compress": [101, 110], "place": [101, 110, 111, 112, 113, 114], "dens": 101, "focu": [101, 104], "realli": 101, "concret": [101, 115], "hope": 101, "modular": 101, "nice": 101, "scratch": [101, 109], "minim": [101, 110, 113, 114], "algorthim": 101, "realiz": 101, "theoret": 101, "analog": 101, "fix": [101, 102], "unstructur": 101, "retrain": 101, "neglig": 101, "area": 101, "agre": 101, "upon": 101, "consensu": 101, "mind": 101, "thought": 101, "subproblem": 101, "satisfi": 101, "my": [101, 112], "independ": 101, "frontend": [101, 113], "arbitrari": 101, "handoff": 101, "piec": 101, "natur": [101, 104, 111, 115], "clear": 101, "contract": 101, "7x": 101, "advantag": 101, "anticip": 101, "solut": 101, "third": 101, "parti": 101, "to_sparse_semi_structur": 101, "sparsesemistructuredtensor": 101, "weightnormsparsifi": 101, "half": 101, "subnetwork": 101, "sparse_config": 101, "named_modul": 101, "tensor_fqn": 101, "sparse_block_shap": 101, "zeros_per_block": 101, "fakespars": 101, "fundament": [101, 112], "manipul": 101, "dictionari": 101, "paramer": 101, "parameter": 101, "necessari": [101, 102, 104, 110, 111, 112, 113, 114], "suitabl": [101, 113], "0s": 101, "spot": 101, "definit": [101, 106], "academia": 101, "industri": 101, "often": [101, 104], "interchang": 101, "distinct": 101, "idea": 101, "behind": 101, "doesn": [101, 112, 115], "itself": [101, 104], "loos": 101, "speak": 101, "tightli": 101, "coupl": [101, 104], "csc": 101, "qnnpack": 101, "descript": [101, 110], "coo": 101, "sparse_coo": 101, "coordin": 101, "locat": 101, "bsr": 101, "sparse_bsr": 101, "veri": [101, 106, 112], "except": [101, 104, 115], "scalar": [101, 111], "dimension": 101, "csr": 101, "sparse_csr": 101, "sparse_csc": 101, "column": 101, "compact": 101, "sparse_matrix": 101, "1d": 101, "indexptr": 101, "\u00bd": 101, "bitmask": 101, "2bit": 101, "unprun": 101, "quit": [101, 104], "broken": 101, "down": 101, "sensit": 101, "effect": [101, 102, 104, 113, 114, 115], "best": [101, 113], "subsequ": [101, 104, 113, 114], "infinit": 101, "lost": 101, "degre": 101, "drop": 101, "proxi": 101, "aforement": 101, "smallest": 101, "absolut": 101, "scope": 101, "impli": 101, "con": 101, "potenti": [101, 102, 110, 111, 113, 114], "sub": 101, "span": 101, "threshold": 101, "constant": [101, 104, 111], "ctr_mobile_fe": 101, "score": 101, "w": [101, 106], "tenosr": 101, "udpat": 101, "histori": 101, "regrow": 101, "dw": 101, "via": [101, 110], "backprop": 101, "pat": 101, "unmask": 101, "resid": 101, "salienc": 101, "lowest": 101, "l1": 101, "abl": [101, 104, 106, 111, 115], "repeat": [101, 111, 112], "movement": 101, "2005": 101, "07683": 101, "rank": [101, 104], "wx": 101, "sqx": 101, "q": [101, 111], "usual": 101, "sort": 101, "wise": 101, "reconstruct": [101, 106], "randomli": 101, "tri": 101, "remedi": 101, "sometim": 101, "item": [101, 109], "ultim": [101, 102], "complic": [101, 111], "literatur": 101, "vision": 101, "nlp": [101, 109, 113], "iter": [101, 111, 112], "ctr_feed": 101, "na": 101, "multimask": 101, "search": 101, "pyspeech": 101, "fastna": 101, "approach": [101, 104, 110, 113, 114], "knowledg": [101, 109], "distil": 101, "pdf": 101, "2204": 101, "09656": 101, "arrang": 101, "recal": 101, "counterpart": 101, "slower": 101, "suffici": 101, "At": [101, 111], "98": 101, "exhibit": 101, "penalti": 101, "expens": [101, 104], "dictat": 101, "characterist": 101, "highest": 101, "wouldn": [101, 104], "visual": 101, "fig": 101, "4x4": 101, "benchmak": 101, "fly": [102, 105], "affinequantizedminmaxobserv": 102, "record": 102, "welcom": 102, "averag": [102, 111, 112], "histogram": [102, 111], "act_ob": 102, "finfo": 102, "weight_ob": 102, "observedlinear": 102, "observed_input": 102, "observed_weight": 102, "from_float": [102, 104], "float_linear": 102, "observed_linear": 102, "_replace_with_custom_fn_if_matches_filt": 102, "insert_observers_": 102, "lambda": [102, 106], "replacement_fn": 102, "copied_act_ob": 102, "copied_weight_ob": 102, "popul": 102, "feed": 102, "simpler": [102, 111], "quantizedlinear": [102, 104], "isn": 102, "strictli": 102, "to_affine_quantized_intx_stat": 102, "act_scal": [102, 115], "act_zero_point": 102, "calculate_qparam": [102, 115], "weight_scal": [102, 111, 115], "weight_zero_point": [102, 111], "qweight": 102, "qinput": 102, "from_observ": 102, "quantized_linear": [102, 111], "begin": [102, 104], "dataclass": [102, 106, 115], "transform_modul": [102, 106], "register_quantize_module_handl": [102, 106], "staticquantconfig": 102, "_apply_static_qu": 102, "associ": 102, "identifi": [102, 115], "is_observed_linear": 102, "optimizedmodul": 102, "_orig_mod": 102, "0237": 102, "142": 102, "31": [102, 115], "113": 102, "157": 102, "59": 102, "160": 102, "150": 102, "67": 102, "241": 102, "238": 102, "235": 102, "228": 102, "255": [102, 115], "201": 102, "114": 102, "236": 102, "88": [102, 111], "83": 102, "109": 102, "209": 102, "92": 102, "184": 102, "141": 102, "110": 102, "0009": 102, "0010": 102, "130": 102, "122": 102, "132": 102, "125": 102, "126": 102, "129": 102, "127": [102, 104, 114, 115], "133": 102, "124": 102, "131": 102, "135": 102, "136": 102, "foundat": 104, "autograd": [104, 115], "interpos": 104, "namespac": 104, "continu": [104, 112, 113, 114, 115], "obviou": 104, "int8quantizedlinear": 104, "finer": 104, "intercept": 104, "contrast": 104, "clunki": 104, "distributedlinear": 104, "duplic": 104, "bypass": 104, "wrap": [104, 113, 114], "outer": 104, "inner": 104, "allgath": 104, "bandwidth": 104, "exactli": 104, "zoo": 104, "podcast": 104, "edward": 104, "yang": 104, "int8_symmetric_quant": 104, "fp32_tensor": 104, "amin": 104, "keepdim": [104, 111, 112], "amax": 104, "zeros_lik": 104, "view": [104, 111, 112], "clamp": [104, 111], "w_int8": 104, "new_linear": 104, "left": [104, 115], "toymodel": 104, "child": 104, "named_children": 104, "drawback": 104, "won": 104, "suppos": 104, "clean": 104, "eleg": 104, "pretti": 104, "power": [104, 106], "overrid": 104, "almost": 104, "shard": [104, 106], "ragged": 104, "rag": 104, "nestedtensor": 104, "who": 104, "link": [104, 109], "why": [104, 109], "googl": 104, "collab": 104, "flopcount": 104, "memorytrack": 104, "bare": 104, "bone": 104, "int8symmetrictensor": 104, "hold": [104, 105], "staticmethod": 104, "_make_wrapper_subclass": [104, 106], "storage_offset": 104, "ndim": 104, "extra_metadata": 104, "outer_s": [104, 106], "outer_strid": [104, 106], "undo": 104, "repr": 104, "ahead": 104, "insid": 104, "int8_tensor": 104, "op_implementations_dict": 104, "conveni": 104, "register_op": 104, "_op": 104, "opoverload": 104, "impl_decor": 104, "op_impl": 104, "done": 104, "particular": 104, "largest": 104, "tell": 104, "desugar": 104, "surfac": 104, "coverag": [104, 110, 111, 113, 114], "brute": 104, "forc": 104, "repeatedli": 104, "log": 104, "loggingtensor": 104, "_python_dispatch": [104, 106], "return_and_correct_alias": [104, 106], "int8_mm": 104, "int8_view_op": 104, "out_data": 104, "out_scal": [104, 111], "notic": 104, "hit": 104, "background": 104, "decomposit": 104, "live": 104, "decomp": 104, "shrink": 104, "author": [104, 109, 110, 111, 112, 113, 114, 115], "But": [104, 106, 115], "pain": 104, "rather": 104, "worth": 104, "written": 104, "differenti": 104, "nuanc": 104, "longer": [104, 111, 112], "had": [104, 111], "That": 104, "transposit": 104, "got": [104, 111, 115], "propag": [104, 111, 113, 114], "fact": 104, "themselv": [104, 111], "pointwis": [104, 113, 114], "were": 104, "might": [104, 106, 111, 115], "unwrap": 104, "dim0": 104, "dim1": 104, "confirm": 104, "quantized_model_module_swap": 104, "quantized_model_subclass": 104, "subclass_param": 104, "out_module_swap": 104, "allclos": 104, "out_compil": 104, "seri": 104, "discuss": 104, "float8dynamicactivationint4weightconfig": 105, "torch_dtyp": 105, "fluxpipelin": 105, "fluxtransformer2dmodel": 105, "black": 105, "forest": 105, "lab": 105, "flux": 105, "dev": 105, "subfold": 105, "cat": [105, 115], "sign": [105, 114], "world": [105, 106], "num_inference_step": 105, "guidance_scal": 105, "png": 105, "temporarydirectori": 105, "tmp_dir": 105, "uncom": 105, "usernam": [105, 106], "statu": [105, 106], "due": [105, 106, 110, 115], "int4wo": 105, "workaround": [105, 106], "team": [105, 106], "retain": 105, "thoroughli": 105, "e2": 106, "_type": 106, "_data": 106, "capabl": [106, 111, 113], "self_attn": 106, "q_proj": 106, "k_proj": 106, "mlp": 106, "gate_proj": 106, "narrow": 106, "chunk": 106, "heavi": 106, "codebas": 106, "fn": 106, "ctx": 106, "new_tensor": 106, "__class__": 106, "principl": 106, "mynewquantconfig": 106, "classvar": 106, "myquantizedtensor": 106, "tensor_data_attr": 106, "tensor_attribut": 106, "attr": 106, "fill_default": 106, "notimplementederror": 106, "_my_quant_transform": 106, "my_quantization_funct": 106, "use_cutlass_kernel": 106, "my_cutlass_linear": 106, "use_triton_kernel": 106, "my_triton_linear": 106, "disappear": 106, "unless": 106, "extrem": 106, "sole": 106, "explicitli": [106, 115], "spooki": 106, "distanc": 106, "2338": 106, "detect": 106, "illustr": 106, "tutorials_python": 107, "zip": [107, 109], "jupyt": [107, 109], "notebook": [107, 109], "tutorials_jupyt": 107, "sphinx": [107, 109], "firstnam": 109, "lastnam": 109, "prerequisit": [109, 111], "topic": 109, "rand": [109, 111, 112], "4107": 109, "5992": 109, "3504": 109, "0972": 109, "1066": 109, "0691": 109, "5280": 109, "3168": 109, "8431": 109, "4022": 109, "7917": 109, "4243": 109, "4515": 109, "2046": 109, "practic": 109, "summar": 109, "takeawai": 109, "link1": 109, "link2": 109, "minut": 109, "ipynb": 109, "daniil": 110, "lyakhov": 110, "aamir": 110, "nazir": 110, "alexand": 110, "suslov": 110, "yamini": 110, "nimmagadda": 110, "kozlov": 110, "subject": [110, 112], "openvinoquant": 110, "unlock": 110, "placement": 110, "ux": [110, 111, 113], "torchdynamo": [110, 113, 114, 115], "eager": [110, 111, 112, 113, 114, 115], "mechan": [110, 113, 114], "torchvis": [110, 111, 112, 113, 114, 115], "resnet18": [110, 111, 112, 113, 114], "u": 110, "__dict__": [110, 111, 112, 113, 114], "dummi": [110, 113, 114], "traced_b": [110, 113, 114], "exported_model": [110, 111, 112, 113, 114], "preset": 110, "elu": 110, "prelu": 110, "gelu": 110, "quantizationpreset": 110, "bert": [110, 113], "modeltyp": 110, "ignored_scop": 110, "exclud": 110, "layer_1": 110, "layer_2": 110, "layer_3": 110, "ignoredscop": 110, "conv2d": [110, 111, 112, 113, 114, 115], "regex": 110, "layer_": 110, "subgraph": [110, 112], "node": [110, 112, 113, 114, 115], "target_devic": 110, "taken": 110, "account": 110, "cpu_spr": 110, "npu": 110, "targetdevic": 110, "fold": [110, 111, 113, 114], "batchnorm": [110, 111, 112, 113, 114], "preced": [110, 111, 113, 114], "prepared_model": [110, 111, 112, 113, 114], "fold_quant": 110, "finish": [110, 113], "comparison": 110, "smoothquant": 110, "biascorrect": 110, "discrep": 110, "calibration_load": 110, "dataload": [110, 111, 112], "transform_fn": 110, "data_item": 110, "calibration_dataset": 110, "smooth_quant": 110, "fast_bias_correct": 110, "deploy": [110, 113], "jerri": [111, 113, 115], "zhang": [111, 113, 114, 115], "_export": [111, 112], "fx": [111, 115], "14k": 111, "programm": [111, 113, 114], "db": 111, "xnnpack": [111, 112, 115], "xnnpack_quant": [111, 112], "get_symmetric_quantization_config": [111, 112], "xnnpackquant": [111, 112, 115], "prior": 111, "qconfigmap": [111, 115], "backendconfig": [111, 115], "rel": 111, "intent": [111, 115], "qconfig": [111, 115], "3d": [111, 115], "incompat": 111, "great": 111, "ideal": 111, "fake_qu": 111, "hidden": 111, "summari": 111, "address": 111, "thu": 111, "queri": [111, 115], "becom": 111, "previous": 111, "embedding_byt": 111, "executorchquant": 111, "concaten": 111, "prone": 111, "cleaner": 111, "composed_quant": 111, "quantization_cap": 111, "concern": 111, "decoupl": 111, "minmax": 111, "freed": 111, "identitc": 111, "imagenet": [111, 112], "unzip": [111, 112], "data_path": [111, 112], "renam": [111, 112], "resnet18_pretrained_float": [111, 112], "sy": [111, 112], "numpi": [111, 112], "np": [111, 112], "resnet": [111, 112, 113], "warn": [111, 112], "filterwarn": [111, 112], "categori": [111, 112], "deprecationwarn": [111, 112], "r": [111, 112], "seed": [111, 112], "191009": [111, 112], "averagemet": [111, 112], "fmt": [111, 112], "val": [111, 112], "avg": [111, 112], "count": [111, 112], "__str__": [111, 112], "fmtstr": [111, 112], "topk": [111, 112], "predict": [111, 112], "maxk": [111, 112], "pred": [111, 112], "eq": [111, 112], "expand_a": [111, 112], "correct_k": [111, 112], "mul_": [111, 112], "criterion": [111, 112], "top1": [111, 112], "top5": [111, 112], "cnt": [111, 112], "acc1": [111, 112], "acc5": [111, 112], "load_model": [111, 112], "model_fil": [111, 112], "weights_onli": [111, 112], "print_size_of_model": [111, 112], "temp": [111, 112], "p": [111, 112], "1e6": [111, 112], "prepare_data_load": [111, 112], "485": [111, 112], "456": [111, 112], "std": [111, 112], "229": [111, 112], "225": [111, 112], "randomresizedcrop": [111, 112], "randomhorizontalflip": [111, 112], "totensor": [111, 112], "dataset_test": [111, 112], "resiz": [111, 112], "centercrop": [111, 112], "train_sampl": [111, 112], "randomsampl": [111, 112], "test_sampl": [111, 112], "sequentialsampl": [111, 112], "train_batch_s": [111, 112], "sampler": [111, 112], "data_loader_test": [111, 112, 113, 114], "eval_batch_s": [111, 112], "saved_model_dir": [111, 112], "float_model_fil": [111, 112], "model_to_quant": [111, 112], "capture_pre_autograd_graph": [111, 112], "dynamic_shap": [111, 112], "dynamic_dim": [111, 112], "constraint": [111, 112, 115], "qconfig_opt": 111, "set_object_typ": 111, "set_module_nam": 111, "workload": 111, "themodel": 111, "feedback": 111, "dq": 111, "fp32_op": 111, "qauntiz": 111, "x_int8": 111, "x_zero_point": 111, "weight_int8": 111, "bias_fp32": 111, "output_scal": 111, "output_zero_point": 111, "x_fp32": 111, "quantized_decompos": 111, "dequantize_per_tensor": 111, "x_i8": 111, "x_quant_min": 111, "x_quant_max": 111, "weight_fp32": 111, "weight_i8": 111, "weight_quant_min": 111, "weight_quant_max": 111, "weight_permut": 111, "permute_copi": 111, "out_fp32": 111, "addmm": 111, "out_i8": 111, "quantize_per_tensor": 111, "out_zero_point": 111, "out_quant_min": 111, "out_quant_max": 111, "float32_op": 111, "decompos": 111, "use_reference_represent": 111, "x_int16": 111, "weight_int16": 111, "acc_int32": 111, "out_dtyp": 111, "bias_scal": 111, "bias_int32": 111, "div": 111, "mul": 111, "out_int8": 111, "qmin": 111, "qmax": 111, "date": 111, "unus": 111, "serila": 111, "consult": 111, "exportedprogram": 111, "pt2e_quantized_model_file_path": 111, "resnet18_pt2e_quant": 111, "quantized_ep": 111, "loaded_quantized_ep": 111, "loaded_quantized_model": 111, "diff": 111, "79": 111, "82": 111, "55": 111, "edg": [111, 115], "went": 111, "andrew": 112, "Or": 112, "move_exported_model_to_ev": [112, 113], "correctli": 112, "certain": 112, "dropout": 112, "move_exported_model_to_train": 112, "jit": 112, "recursivescriptmodul": 112, "train_one_epoch": 112, "ntrain_batch": 112, "avgloss": 112, "5f": 112, "start_tim": 112, "global_avg": 112, "is_qat": [112, 113], "fusion": 112, "batchnorm2d": 112, "_native_batch_norm_legit": 112, "cudnn_batch_norm": 112, "mobilenetv2": 112, "manual": 112, "recompil": 112, "consolid": 112, "epoch": 112, "far": 112, "num_epoch": 112, "num_train_batch": 112, "num_eval_batch": 112, "num_observer_update_epoch": 112, "num_batch_norm_update_epoch": 112, "num_epochs_between_ev": 112, "nepoch": 112, "stat": 112, "subseq": 112, "disable_observ": 112, "bn": 112, "running_mean": 112, "running_var": 112, "new_arg": 112, "wish": 112, "prepared_model_copi": 112, "neval_batch": 112, "paus": 112, "resum": 112, "fail": [112, 115], "checkpoint_path": 112, "checkpoint_": 112, "behav": 112, "incorrectli": 112, "lesli": [113, 115], "fang": [113, 115], "weiwen": [113, 115], "xia": [113, 115], "jiong": [113, 115], "gong": [113, 115], "cnn": 113, "rnn": 113, "outstand": 113, "fourth": 113, "spr": 113, "xeon": 113, "processor": 113, "boost": 113, "channels_last": [113, 114], "onednn": [113, 114], "assum": [113, 115], "word": 113, "satur": 113, "pure": 113, "dedic": 113, "scenario": [113, 114], "plai": [113, 114], "convolut": [113, 114, 115], "absenc": [113, 114], "enhanc": [113, 114], "mirror": [113, 114], "autocast": [113, 114], "device_typ": [113, 114], "turn": [113, 114], "cpp": 113, "qconvolut": [113, 114], "qlinear": [113, 114], "presenc": [113, 114], "pair": [113, 114], "remain": [113, 114], "conting": [113, 114], "qmaxpool2d": [113, 114], "torchinductor_freez": [113, 114], "example_x86inductorquantizer_pytorch_2_1": 113, "torchbench": 113, "measur": 113, "proven": 113, "depth": 113, "example_x86inductorquantizer_qat": 113, "yan": 114, "zhiwei": 114, "wang": 114, "eikan": 114, "liangang": 114, "liu": 114, "river": 114, "cui": 114, "yifeng": 114, "xpuinductorquant": 114, "pip3": 114, "torchaudio": 114, "xpu_inductor_quantizer_exampl": 114, "xpu_inductor_quant": 114, "xpuiq": 114, "resnet18_weight": 114, "get_default_xpu_inductor_quantization_config": 114, "wherea": 114, "histogramobserv": [114, 115], "perchannelminmaxobserv": 114, "quantizationspec": [114, 115], "quantizationconfig": [114, 115], "type_check": 114, "observerorfakequantizeconstructor": 114, "get_xpu_inductor_symm_quantization_config": 114, "extra_arg": 114, "act_observer_or_fake_quant_ctr": 114, "act_quantization_spec": [114, 115], "qscheme": [114, 115], "per_tensor_symmetr": [114, 115], "observer_or_fake_quant_ctr": [114, 115], "with_arg": [114, 115], "weight_observer_or_fake_quant_ctr": 114, "weight_quantization_spec": [114, 115], "per_channel_symmetr": 114, "ch_axi": 114, "oc": 114, "ic": 114, "kh": 114, "kw": 114, "conv": [114, 115], "bias_quantization_spec": 114, "amp": 114, "indcutor": 114, "kimish": 115, "patel": 115, "made": 115, "explicit": 115, "quantiat": 115, "encod": 115, "convei": 115, "quantizationannot": 115, "furthermor": 115, "minmaxobserv": 115, "input_qspec_map": 115, "output_qspec": 115, "_annot": 115, "conclud": 115, "matcher": 115, "get_source_partit": 115, "add_partit": 115, "gm": 115, "itertool": 115, "chain": 115, "add_nod": 115, "output_nod": 115, "per_tensor_affin": 115, "input_act_qspec": 115, "output_act_qspec": 115, "input_act0": 115, "input_act1": 115, "quantization_annot": 115, "substitut": 115, "among": 115, "sharedquantizationspec": 115, "maxpool": 115, "average_pool": 115, "concat": 115, "whose": 115, "edgeornod": 115, "transit": 115, "spec": 115, "conv1": 115, "conv2": 115, "fed": 115, "conv1_out": 115, "conv2_out": 115, "qspec1": 115, "cat_input0": 115, "cat_input1": 115, "therefor": 115, "ob": 115, "consum": 115, "rewrit": 115, "share_qparams_with_input_act0_qspec": 115, "known": 115, "beforehand": 115, "sigmoid": 115, "fixedqparamsquantizationspec": 115, "act_qspec": 115, "sigmoid_nod": 115, "input_act": 115, "derivedquantizationspec": 115, "derive_qparams_fn": 115, "observerorfakequant": 115, "observerbas": 115, "fakequantizebas": 115, "heurist": 115, "obejct": 115, "obs_or_fq": 115, "fq": 115, "act_obs_or_fq": 115, "weight_obs_or_fq": 115, "act_zp": 115, "weight_zp": 115, "bias_qspec": 115, "derived_from": 115, "backendquant": 115, "get_input_act_qspec": 115, "get_output_act_qspec": 115, "get_weight_qspec": 115, "get_bias_qspec": 115, "intermedi": 115, "straightforward": 115, "call_funct": 115, "relu_": 115, "relu_nod": 115, "maybe_conv_nod": 115, "conv1d": 115, "unexpect": 115, "recognz": 115, "subgraphmatch": 115, "conv_relu_pattern": 115, "name_node_map": 115, "input_nod": 115, "weight_nod": 115, "bias_nod": 115, "caveat": 115, "exhaust": 115, "2d": 115, "4d": 115, "v": 115, "symbol": 115, "outcom": 115}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "MarlinSparseLayout"], [19, 0, 1, "", "NF4Tensor"], [20, 0, 1, "", "PlainLayout"], [21, 0, 1, "", "SemiSparseLayout"], [22, 0, 1, "", "TensorCoreTiledLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinSparseLayout": [[18, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[19, 1, 1, "", "convert_to_norm_float_weight"], [19, 1, 1, "", "dequantize"], [19, 1, 1, "", "dequantize_scalers"], [19, 1, 1, "", "double_quantize_scalers"], [19, 1, 1, "", "get_original_weight"], [19, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingGranularity"], [33, 0, 1, "", "ScalingType"], [34, 2, 1, "", "convert_to_float8_training"], [35, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[36, 0, 1, "", "BlockSparseLayout"], [37, 0, 1, "", "CutlassInt4PackedLayout"], [38, 0, 1, "", "FloatxTensorCoreLayout"], [39, 0, 1, "", "Int8DynamicActInt4WeightCPULayout"], [40, 0, 1, "", "MarlinQQQLayout"], [41, 0, 1, "", "MarlinQQQTensor"], [42, 0, 1, "", "UintxLayout"]], "torchao.prototype.dtypes.MarlinQQQTensor": [[41, 1, 1, "", "dequantize"], [41, 1, 1, "", "from_hp_to_intx"]], "torchao.quantization": [[43, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [44, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [45, 0, 1, "", "Float8WeightOnlyConfig"], [46, 0, 1, "", "Int4WeightOnlyConfig"], [47, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [48, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [49, 0, 1, "", "Int8WeightOnlyConfig"], [50, 0, 1, "", "MappingType"], [51, 0, 1, "", "TorchAODType"], [52, 2, 1, "", "choose_qparams_affine"], [53, 2, 1, "", "choose_qparams_affine_with_min_max"], [54, 2, 1, "", "dequantize_affine"], [55, 2, 1, "", "int_scaled_matmul"], [80, 2, 1, "", "quantize_"], [85, 2, 1, "", "quantize_affine"], [86, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[56, 0, 1, "", "ComposableQATQuantizer"], [57, 0, 1, "", "FakeQuantizeConfigBase"], [58, 0, 1, "", "FakeQuantizedEmbedding"], [59, 0, 1, "", "FakeQuantizedLinear"], [60, 0, 1, "", "FakeQuantizerBase"], [61, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [62, 0, 1, "", "Float8FakeQuantizeConfig"], [63, 0, 1, "", "Float8FakeQuantizer"], [64, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [65, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [66, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [67, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [68, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [69, 0, 1, "", "IntxFakeQuantizeConfig"], [70, 0, 1, "", "IntxFakeQuantizer"], [71, 0, 1, "", "QATConfig"], [72, 0, 1, "", "QATStep"], [75, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[58, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[59, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[61, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[63, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[65, 1, 1, "", "convert"], [65, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[69, 3, 1, "", "group_size"], [69, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[70, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[73, 0, 1, "", "Int4WeightOnlyEmbedding"], [74, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[73, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[76, 0, 1, "", "Int4WeightOnlyQATLinear"], [77, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [78, 2, 1, "", "disable_linear_fake_quant"], [79, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[81, 0, 1, "", "KernelPreference"], [82, 0, 1, "", "PackingFormat"], [83, 0, 1, "", "QuantizeTensorKwargs"], [84, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[81, 4, 1, "", "AUTO"], [81, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[82, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[87, 0, 1, "", "PerChannelNormObserver"], [88, 0, 1, "", "WandaSparsifier"], [89, 2, 1, "", "apply_fake_sparsity"], [90, 4, 1, "", "semi_sparse_weight"], [91, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[87, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[88, 1, 1, "", "prepare"], [88, 1, 1, "", "squash_mask"], [88, 1, 1, "", "update_mask"]], "torchao.utils": [[92, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[92, 1, 1, "", "get_tensor_impl_constructor"], [92, 1, 1, "", "implements"], [92, 1, 1, "", "implements_torch_function"], [92, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 93, 95, 96, 106], "dtype": [0, 11, 96], "layout": [0, 17], "tensor": [0, 7, 10, 96, 103, 104, 106, 115], "subclass": [0, 7, 10, 96, 104, 106], "quantiz": [0, 4, 5, 7, 12, 80, 93, 96, 97, 99, 102, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 95, 96], "main": [1, 4, 5], "train": [1, 12, 95, 96, 99, 110, 111, 112, 113, 114], "api": [1, 2, 4, 5, 7, 8, 12, 93, 95, 115], "other": [1, 10, 96], "type": [1, 105], "refer": [2, 93], "python": 2, "kernel": [3, 10, 94, 96, 106], "qat": [4, 12, 112], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 99], "primit": [5, 96], "sparsiti": [6, 101], "util": 7, "common": [7, 8, 115], "benchmark": [8, 9, 10, 99], "guid": [8, 9, 10, 97, 106], "add": [8, 106], "an": [8, 98], "recip": [8, 95], "model": [8, 10, 95, 96, 98, 99, 105, 106, 110, 111, 112], "design": [8, 101], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 95, 99, 105, 106, 110, 113, 114, 115], "modifi": 8, "exist": 8, "configur": [8, 101, 106, 111, 112], "2": [8, 12, 97, 99, 105, 106, 110, 111, 112, 113, 114, 115], "run": 8, "3": [8, 12, 99, 106, 110, 113, 114, 115], "output": [8, 104], "format": [8, 96], "4": [8, 110, 115], "integr": [8, 12, 105, 106], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 106], "new": [10, 106], "effici": [10, 96], "triton": 10, "hand": 10, "written": 10, "us": [10, 115], "kernelprefer": [10, 81], "flow": [10, 96, 98, 106, 115], "torch": [10, 110, 111, 112], "compil": [10, 106, 110], "perform": [10, 94, 99, 111], "serial": [10, 98, 106], "featur": 10, "support": [10, 105, 106], "function": [10, 111, 112], "compos": 10, "microbenchmark": 10, "eval": [10, 111], "part": [12, 95, 99], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 96, 112, 113], "option": [12, 99, 109, 110], "torchtun": 12, "axolotl": 12, "low": [12, 96], "rank": 12, "adapt": 12, "huggingfac": [12, 99, 106], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "marlinsparselayout": 18, "nf4tensor": 19, "plainlayout": 20, "semisparselayout": 21, "tensorcoretiledlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalinggranular": 32, "scalingtyp": 33, "convert_to_float8_train": 34, "precompute_float8_dynamic_scale_for_fsdp": 35, "blocksparselayout": 36, "cutlassint4packedlayout": 37, "floatxtensorcorelayout": 38, "int8dynamicactint4weightcpulayout": 39, "marlinqqqlayout": 40, "marlinqqqtensor": 41, "uintxlayout": 42, "float8dynamicactivationfloat8weightconfig": 43, "float8dynamicactivationint4weightconfig": 44, "float8weightonlyconfig": 45, "int4weightonlyconfig": 46, "int8dynamicactivationint4weightconfig": 47, "int8dynamicactivationint8weightconfig": 48, "int8weightonlyconfig": 49, "mappingtyp": 50, "torchaodtyp": 51, "choose_qparams_affin": 52, "choose_qparams_affine_with_min_max": 53, "dequantize_affin": 54, "int_scaled_matmul": 55, "composableqatquant": 56, "fakequantizeconfigbas": 57, "fakequantizedembed": 58, "fakequantizedlinear": 59, "fakequantizerbas": 60, "float8actint4weightqatquant": 61, "float8fakequantizeconfig": 62, "float8fakequant": 63, "fromintxquantizationawaretrainingconfig": 64, "int4weightonlyembeddingqatquant": 65, "int4weightonlyqatquant": 66, "int8dynactint4weightqatquant": 67, "intxquantizationawaretrainingconfig": 68, "intxfakequantizeconfig": 69, "intxfakequant": 70, "qatconfig": 71, "qatstep": 72, "int4weightonlyembed": 73, "int4weightonlyqatembed": 74, "initialize_fake_quant": 75, "int4weightonlyqatlinear": 76, "int8dynactint4weightqatlinear": 77, "disable_linear_fake_qu": 78, "enable_linear_fake_qu": 79, "packingformat": 82, "quantizetensorkwarg": 83, "_choose_quant_func_and_quantize_tensor": 84, "quantize_affin": 85, "safe_int_mm": 86, "perchannelnormobserv": 87, "wandasparsifi": 88, "apply_fake_spars": 89, "semi_sparse_weight": 90, "sparsifi": 91, "torchaobasetensor": 92, "welcom": 93, "document": 93, "get": 93, "start": [93, 97, 105], "develop": 93, "note": [93, 95, 115], "eager": 93, "tutori": [93, 109], "pt2e": [93, 115], "pre": 95, "torchtitan": 95, "prerequisit": [95, 110, 113, 114, 115], "rowwis": 95, "scale": 95, "tensorwis": 95, "pick": 95, "import": [95, 111, 112], "directli": [95, 115], "convers": 95, "overview": [96, 101, 109], "basic": 96, "op": 96, "deriv": [96, 115], "pack": 96, "algorithm": 96, "weight": [96, 99], "onli": 96, "dynam": 96, "activ": 96, "static": [96, 102], "bit": 96, "optim": [96, 98, 99], "case": 96, "studi": 96, "how": [96, 111, 112, 115], "work": 96, "dure": 96, "execut": 96, "save": [96, 105, 111, 112], "load": [96, 111, 112], "quick": [97, 105], "first": 97, "exampl": [97, 105, 106, 115], "pytorch": [97, 110, 111, 112, 113, 114, 115], "export": [97, 99, 110, 111, 112, 113, 114, 115], "next": [97, 104], "step": [97, 99, 104, 106, 109], "deseri": 98, "what": [98, 104], "happen": 98, "when": 98, "serv": [99, 106], "vllm": [99, 106], "sglang": 99, "executorch": 99, "post": [99, 110, 111, 113, 114], "transform": [99, 105, 106], "mobil": 99, "deploy": 99, "unti": 99, "embed": 99, "creat": [99, 106], "characterist": 99, "evalu": [99, 111], "qualiti": 99, "assess": 99, "memori": 99, "latenc": 99, "result": 99, "h100": 99, "machin": 99, "conclus": [99, 109, 110, 111, 112, 113, 114, 115], "comput": [100, 108], "time": [100, 108], "goal": 101, "context": 101, "prune": 101, "criteria": 101, "strategi": 101, "pattern": [101, 115], "calibr": [102, 111], "phase": 102, "write": [103, 104, 115], "your": [103, 104, 106], "own": [103, 104], "advanc": 103, "ar": 104, "modul": 104, "swap": 104, "which": 104, "oper": [104, 106, 115], "should": 104, "we": 104, "implement": [104, 106], "compar": 104, "hug": 105, "face": 105, "usag": [105, 106], "diffus": 105, "architectur": 106, "system": 106, "class": 106, "fqn": 106, "method": 106, "minim": 106, "requir": 106, "compat": 106, "why": 106, "regist": 106, "s": 106, "kei": 106, "detail": 106, "hardwar": 106, "specif": [106, 111, 112], "linear": 106, "benefit": 106, "trade": 106, "off": 106, "share": [106, 115], "safetensor": 106, "diagram": 106, "high": 106, "level": 106, "point": 106, "dispatch": 106, "bring": 106, "extern": 106, "templat": 109, "addit": 109, "exercis": 109, "further": 109, "read": 109, "openvino": 110, "backend": [110, 111, 112, 113, 114], "introduct": [110, 113, 114, 115], "nncf": 110, "instal": 110, "captur": [110, 113, 114], "fx": [110, 113, 114], "graph": [110, 113, 114], "appli": [110, 113, 114], "lower": [110, 111, 113, 114], "represent": 110, "improv": 110, "metric": 110, "motiv": [111, 115], "defin": [111, 112], "helper": [111, 112], "prepar": [111, 112], "dataset": [111, 112], "set": 111, "mode": 111, "convert": [111, 112], "check": 111, "size": 111, "accuraci": 111, "debug": 111, "loop": 112, "checkpoint": 112, "x86": 113, "through": [113, 114], "inductor": [113, 114], "intel": 114, "gpu": 114, "annot": 115, "param": 115, "fix": 115, "paramet": 115, "5": 115, "A": 115, "toi": 115, "resnet18": 115, "ir": 115, "problem": 115, "match": 115, "aten": 115, "recommend": 115, "subgraphmatcherwithnamenodemap": 115}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})