Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout", "generated/torchao.prototype.dtypes.MarlinQQQLayout", "generated/torchao.prototype.dtypes.MarlinQQQTensor", "generated/torchao.prototype.dtypes.UintxLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQLayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQTensor.rst", "generated/torchao.prototype.dtypes.UintxLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "Int8DynamicActInt4WeightCPULayout", "MarlinQQQLayout", "MarlinQQQTensor", "UintxLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 18, 19, 20, 21, 35, 41, 42, 45, 46, 47, 48, 49, 51, 52, 53, 57, 62, 63, 68, 70, 72, 73, 75, 76, 79, 82, 83, 84, 86, 87, 88, 90, 91, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "section": [2, 10, 95, 100, 105, 110, 111, 114], "introduc": [2, 12, 109, 110, 112, 113, 114], "dive": 2, "detail": [2, 8, 10, 12, 45, 94, 95, 96, 98, 100, 101, 103, 109, 110, 111, 112], "how": [2, 4, 10, 12, 13, 17, 41, 43, 47, 49, 51, 68, 80, 81, 84, 92, 94, 96, 97, 98, 100, 101, 103, 104, 105, 109, 112, 113], "integr": [2, 10, 92, 94, 97, 98, 100, 103, 112, 114], "pytorch": [2, 8, 12, 13, 16, 40, 50, 68, 92, 94, 95, 98, 100, 103, 105, 108], "optim": [2, 10, 12, 18, 35, 79, 92, 94, 100, 103, 109, 111, 112, 113], "your": [2, 8, 10, 12, 92, 94, 95, 96, 98, 100, 104, 110, 111, 112, 113, 114], "machin": [2, 111], "learn": [2, 68, 96, 100, 108, 110, 112, 113, 114], "model": [2, 12, 35, 46, 55, 60, 63, 64, 65, 66, 67, 70, 74, 79, 87, 88, 90, 96, 100, 101, 103, 112, 113, 114], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 40, 41, 42, 44, 50, 51, 52, 53, 57, 58, 60, 61, 64, 65, 66, 68, 72, 73, 75, 76, 83, 84, 90, 92, 94, 96, 97, 98, 101, 103, 104, 105, 110, 112, 113, 114], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 28, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 90, 94, 97, 100], "sparsiti": [2, 8, 12, 14, 18, 21, 86, 87, 88, 89, 90, 92, 94, 97, 98], "tba": [3, 11, 93], "For": [4, 8, 10, 12, 13, 45, 68, 95, 96, 97, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "full": [4, 12, 96, 101, 104, 108, 109, 111], "exampl": [4, 8, 10, 12, 13, 35, 49, 55, 57, 58, 63, 67, 68, 70, 74, 79, 80, 87, 90, 91, 95, 97, 98, 99, 100, 101, 103, 106, 107, 108, 109, 110, 111, 112, 113], "us": [4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 60, 63, 67, 68, 70, 75, 76, 80, 81, 84, 87, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113], "our": [4, 10, 12, 19, 94, 96, 98, 100, 101, 103, 110, 111], "pleas": [4, 9, 10, 12, 13, 40, 63, 67, 92, 95, 96, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "refer": [4, 8, 12, 13, 70, 76, 94, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112], "readm": [4, 8, 12, 92, 96, 100], "tutori": [8, 10, 12, 13, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114], "you": [8, 9, 10, 12, 68, 87, 91, 94, 95, 96, 97, 98, 100, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114], "through": [8, 10, 12, 52, 57, 58, 92, 95, 96, 98, 101, 103, 105, 108, 109, 110, 114], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 97, 98, 100, 101, 103, 104, 109, 110, 111, 112, 113], "framework": [8, 10, 12, 94, 98, 109], "The": [8, 10, 12, 13, 17, 18, 34, 36, 41, 42, 44, 54, 70, 79, 85, 87, 94, 95, 96, 97, 98, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "contain": [8, 82, 83, 100, 103, 111, 114], "new": [8, 12, 13, 91, 94, 95, 101, 103, 110, 111, 112, 114], "architectur": [8, 92, 98, 100, 109, 110, 112, 113], "micro": 8, "current": [8, 42, 45, 46, 60, 61, 70, 79, 87, 90, 94, 95, 96, 100, 103, 104, 105, 110, 111, 113], "support": [8, 12, 13, 25, 42, 43, 45, 46, 60, 67, 68, 70, 82, 83, 90, 94, 95, 96, 97, 98, 100, 103, 109, 110, 111, 112, 113, 114], "which": [8, 10, 12, 40, 41, 70, 75, 94, 95, 97, 98, 100, 101, 105, 109, 110, 111, 112, 113, 114], "can": [8, 10, 12, 13, 22, 42, 49, 55, 68, 79, 80, 84, 91, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "quantize_": [8, 10, 12, 63, 67, 70, 79, 80, 81, 82, 83, 90, 92, 95, 96, 97, 98, 101], "sparsity_": 8, "function": [8, 12, 13, 22, 34, 57, 62, 72, 77, 78, 79, 86, 87, 88, 90, 91, 94, 95, 96, 97, 100, 101, 103, 105, 109, 114], "To": [8, 10, 12, 13, 40, 76, 94, 95, 96, 97, 98, 100, 101, 105, 110, 111, 112, 114], "correspond": [8, 12, 63, 70, 79, 95, 97, 100, 103, 113, 114], "string": [8, 31, 68, 87, 91], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 91, 92, 95, 96, 97, 103, 105, 109, 110, 111, 112, 113, 114], "py": [8, 10, 13, 40, 91, 99, 107, 108, 112, 113], "def": [8, 10, 12, 82, 90, 91, 94, 95, 96, 97, 101, 103, 105, 109, 110, 111, 112, 113, 114], "option": [8, 10, 13, 15, 23, 26, 27, 28, 30, 31, 34, 40, 42, 45, 47, 48, 51, 52, 53, 57, 58, 60, 61, 65, 67, 68, 70, 72, 73, 79, 80, 84, 87, 90, 91, 94, 95, 96, 104, 105, 110, 111, 112, 113, 114], "str": [8, 31, 34, 68, 70, 79, 87, 90, 91, 94, 103, 105, 113], "kwarg": [8, 10, 13, 57, 58, 59, 60, 64, 68, 73, 83, 86, 87, 88, 91, 95, 103, 105], "aobaseconfig": [8, 70, 79, 90, 101, 105], "code": [8, 10, 94, 95, 96, 98, 100, 101, 103, 106, 108, 110, 111, 112, 113, 114], "elif": [8, 105], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 34, 42, 47, 48, 54, 67, 68, 70, 85, 87, 91, 95, 98, 100, 103, 110, 111], "addit": [8, 12, 17, 20, 91, 94, 95, 100, 103, 104, 109, 110, 113, 114], "inform": [8, 13, 42, 95, 98, 100, 105, 109, 110], "need": [8, 10, 12, 42, 57, 62, 72, 81, 82, 83, 86, 87, 91, 95, 97, 98, 100, 103, 105, 110, 111, 112, 114], "pass": [8, 34, 47, 52, 57, 58, 62, 70, 72, 86, 91, 95, 101, 103, 105, 111, 114], "process": [8, 12, 17, 18, 20, 22, 41, 95, 100, 108, 109, 113], "here": [8, 9, 13, 70, 76, 84, 95, 96, 97, 98, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "return": [8, 10, 12, 13, 18, 19, 34, 40, 54, 68, 79, 85, 90, 91, 94, 95, 96, 97, 101, 103, 105, 109, 110, 111, 112, 113, 114], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 81, 103, 111], "now": [8, 10, 12, 43, 45, 46, 51, 94, 95, 96, 100, 101, 103, 109, 110, 112, 114], "we": [8, 10, 12, 13, 19, 42, 44, 45, 49, 51, 52, 53, 67, 68, 70, 76, 79, 84, 90, 91, 94, 95, 96, 97, 98, 100, 101, 104, 105, 109, 110, 111, 112, 113, 114], "throughout": 8, "note": [8, 10, 12, 45, 55, 67, 76, 87, 91, 95, 96, 98, 100, 103, 105, 111, 112, 113], "input": [8, 10, 13, 18, 19, 21, 31, 34, 35, 51, 52, 53, 54, 70, 74, 79, 84, 85, 87, 90, 94, 95, 96, 98, 101, 103, 109, 110, 111, 112, 113, 114], "paramet": [8, 12, 13, 17, 18, 19, 24, 27, 34, 35, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 60, 61, 68, 70, 73, 75, 76, 79, 84, 85, 87, 90, 91, 94, 95, 97, 98, 100, 103, 105, 109, 110], "like": [8, 10, 12, 17, 42, 94, 95, 96, 97, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "bit": [8, 12, 29, 41, 69, 98, 103, 104, 105, 110, 112, 113], "width": [8, 41, 69], "group": [8, 10, 12, 42, 43, 46, 48, 60, 64, 65, 66, 68, 72, 73, 75, 76, 80, 96], "size": [8, 10, 13, 19, 36, 40, 45, 46, 48, 51, 53, 68, 84, 94, 96, 97, 98, 100, 101, 103, 105, 111], "etc": [8, 10, 42, 57, 58, 81, 83, 95, 109, 114], "them": [8, 12, 57, 62, 72, 86, 114], "append": [8, 100, 110, 111], "config": [8, 12, 31, 34, 42, 44, 45, 56, 57, 58, 59, 61, 62, 63, 67, 68, 69, 70, 79, 87, 90, 95, 96, 98, 100, 101, 105, 110, 112, 113], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 43, 45, 46, 48, 57, 58, 60, 64, 67, 68, 70, 72, 73, 79, 96, 104, 105], "system": [8, 10, 81, 98], "model_architectur": 8, "type": [8, 10, 12, 13, 18, 19, 31, 32, 33, 34, 41, 42, 44, 45, 46, 47, 49, 50, 54, 68, 71, 79, 80, 81, 82, 83, 84, 85, 91, 92, 95, 97, 98, 100, 103, 105, 109, 110, 112, 113, 114], "defin": [8, 10, 17, 32, 41, 57, 62, 72, 86, 87, 91, 95, 96, 100, 101, 103, 105, 109, 112, 113, 114], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 80, 81, 82, 86, 87, 91, 96, 97, 101, 103, 110, 111, 112, 114], "mycustommodel": 8, "torch": [8, 12, 13, 18, 19, 24, 31, 34, 41, 42, 44, 51, 53, 54, 57, 58, 60, 61, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 79, 80, 84, 85, 90, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 108, 112, 113, 114], "nn": [8, 10, 12, 31, 34, 55, 60, 64, 67, 70, 79, 90, 91, 94, 95, 96, 97, 98, 100, 101, 103, 105, 110, 111, 112, 114], "modul": [8, 10, 12, 31, 32, 33, 34, 35, 49, 50, 55, 57, 59, 60, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86, 87, 90, 94, 95, 96, 97, 101, 105, 109, 110, 111, 112, 113, 114], "__init__": [8, 12, 91, 96, 97, 101, 103, 105, 110, 111, 112], "self": [8, 12, 13, 91, 96, 97, 101, 103, 105, 110, 111, 112], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 19, 60, 65, 75, 84, 94, 95, 96, 97, 98, 100, 101, 104, 105, 112, 113], "super": [8, 12, 96, 97, 101, 103, 110, 111, 112], "layer1": 8, "linear": [8, 10, 12, 18, 31, 34, 42, 43, 44, 46, 47, 48, 55, 58, 60, 65, 66, 67, 70, 75, 76, 77, 78, 79, 88, 90, 91, 94, 95, 96, 97, 98, 100, 101, 103, 109, 110, 111, 112, 114], "512": [8, 94], "bia": [8, 12, 58, 75, 76, 95, 96, 97, 101, 103, 105, 111, 114], "fals": [8, 12, 13, 26, 31, 45, 47, 57, 58, 66, 67, 68, 70, 72, 73, 75, 76, 87, 94, 95, 96, 97, 98, 101, 103, 104, 105, 109, 110, 111, 113, 114], "activ": [8, 12, 42, 46, 47, 57, 58, 60, 66, 67, 68, 70, 76, 82, 83, 87, 92, 96, 98, 100, 101, 104, 105, 109, 112, 113, 114], "relu": [8, 96, 109, 114], "layer2": 8, "forward": [8, 47, 57, 58, 62, 69, 72, 75, 86, 96, 97, 100, 101, 103, 105, 110, 111, 112], "x": [8, 57, 58, 62, 69, 72, 94, 96, 97, 98, 101, 103, 105, 108, 109, 110, 111, 112, 113], "updat": [8, 92, 96, 97, 100, 110, 111, 114], "create_model_and_input_data": 8, "handl": [8, 10, 18, 21, 22], "model_typ": [8, 12, 105, 109], "m": [8, 10, 12, 79, 90, 94, 96, 97, 98, 101, 103, 110, 111, 112], "int": [8, 12, 13, 19, 22, 23, 24, 26, 27, 28, 29, 36, 40, 41, 42, 44, 45, 46, 48, 51, 52, 53, 57, 58, 60, 64, 65, 66, 68, 72, 73, 75, 76, 79, 84, 87, 91, 96, 101, 103, 105], "k": [8, 10, 85, 96, 97, 101, 103, 110, 111], "n": [8, 10, 12, 96, 97, 101, 103, 110, 111, 114], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 72, 75, 76, 79, 85, 94, 96, 97, 98, 101, 103, 105, 109, 110, 111, 112, 113], "cuda": [8, 10, 12, 13, 79, 94, 96, 97, 98, 100, 101, 103, 104, 111], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 58, 94, 96, 97, 101, 103, 109, 110, 111, 112, 113], "when": [8, 10, 12, 13, 20, 51, 53, 70, 84, 91, 94, 95, 98, 100, 101, 104, 105, 109, 110, 111, 112, 113, 114], "ad": [8, 12, 13, 53, 87, 91, 95, 100, 101, 103, 111], "dimens": [8, 10, 13, 41, 51, 53, 54, 84, 94, 95, 103, 105, 110, 111], "ensur": [8, 18, 98, 111], "convent": 8, "where": [8, 21, 49, 52, 64, 65, 66, 95, 100, 105, 114], "batch": [8, 98, 101, 111], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 103, 109, 112, 113], "data": [8, 12, 13, 17, 18, 36, 41, 42, 44, 45, 47, 52, 81, 91, 92, 95, 97, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "typic": [8, 12, 19, 20, 95, 96, 97, 101, 105, 114], "compat": [8, 10, 18, 68, 96], "work": [8, 10, 12, 21, 94, 97, 100, 103, 104, 105, 110, 111, 112], "cpu": [8, 10, 13, 16, 38, 97, 100, 101, 104, 105, 109, 110, 111, 112], "other": [8, 12, 13, 17, 42, 45, 69, 80, 87, 94, 97, 98, 100, 103, 105, 108, 110, 111, 112, 114], "target": [8, 10, 12, 13, 42, 44, 45, 51, 57, 58, 61, 68, 87, 96, 100, 109, 110, 111, 112, 113, 114], "method": [8, 10, 17, 18, 21, 22, 79, 87, 96, 100, 101, 103, 104, 109, 110, 111, 113, 114], "come": [8, 9, 94, 95, 98, 100, 101, 102, 104, 111, 112, 113], "soon": [8, 9, 98, 102, 111], "file": [8, 10, 94, 98, 99, 103, 105, 107, 110, 111], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 70, 92, 95, 96, 97, 100, 101, 103, 104, 109, 110, 111, 112, 113], "quantization_config_recipe_nam": 8, "int8wo": [8, 104], "int8dq": 8, "float8dq": [8, 98], "tensor": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 40, 41, 44, 45, 46, 47, 51, 52, 53, 54, 57, 58, 59, 61, 62, 69, 80, 81, 82, 83, 84, 85, 87, 91, 92, 94, 96, 97, 100, 101, 104, 108, 110, 112, 113], "row": [8, 10, 43, 54, 94, 95, 100], "float8wo": 8, "output_dir": [8, 104], "result": [8, 12, 13, 54, 85, 95, 100, 101, 104, 110, 111, 112, 113, 114], "model_param": 8, "name": [8, 10, 32, 33, 49, 50, 71, 79, 80, 81, 87, 90, 91, 95, 98, 100, 103, 105, 109, 110, 111, 114], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 49, 57, 84, 94, 96, 98, 101, 110, 111], "max_pow": 8, "15": [8, 45, 94, 96, 98], "torch_compile_mod": 8, "max": [8, 10, 49, 95, 96, 101, 103, 110, 111, 114], "autotun": [8, 10, 96, 101], "runner": 8, "gener": [8, 12, 13, 57, 58, 59, 62, 69, 95, 96, 98, 100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114], "oss": 8, "databas": 8, "python": [8, 10, 96, 98, 100, 106, 108, 109, 110, 112, 113], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 98, 105], "specif": [8, 10, 12, 17, 18, 20, 21, 57, 58, 76, 81, 87, 94, 95, 96, 97, 98, 100, 104, 109, 112, 113, 114], "requir": [8, 12, 13, 20, 22, 80, 91, 95, 96, 98, 100, 103, 104, 109, 112, 114], "mode": [8, 10, 45, 96, 101, 109, 111, 112, 113, 114], "extra_info": 8, "arch": 8, "nvidia": [8, 100], "a100": [8, 12, 96, 104], "sxm4": 8, "80gb": [8, 96], "1024": [8, 79, 90, 96, 97, 112], "custom": [8, 12, 17, 70, 86, 92, 94, 95, 96, 100, 103, 105, 109, 110, 112, 114], "layer": [8, 18, 34, 42, 44, 47, 48, 57, 58, 60, 64, 65, 66, 72, 73, 75, 76, 87, 88, 94, 98, 100, 101, 103, 105, 109, 114], "origin": [8, 12, 13, 19, 44, 47, 63, 84, 87, 95, 96, 97, 98, 100, 109, 110, 114], "metric": [8, 12, 87], "speedup": [8, 10, 12, 94, 95, 96, 98, 100], "wrt": 8, "bf16": [8, 12, 51, 70, 96, 100, 112, 113], "benchmark_valu": 8, "25": [8, 96], "target_valu": 8, "0": [8, 10, 12, 13, 45, 57, 68, 72, 73, 84, 87, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 108, 110, 111, 113, 114], "depend": [8, 13, 97, 100, 103, 110, 111, 113], "step": [8, 12, 20, 35, 70, 71, 94, 95, 100, 109, 110, 111, 112, 113, 114], "workflow": [8, 10, 79, 80, 90, 94, 96, 100, 114], "github": [8, 13, 40, 96, 98, 104], "action": [8, 105, 110, 111], "upload": 8, "verifi": [8, 96, 97, 103], "setup": [8, 98], "suit": [8, 10, 110, 112], "unittest": 8, "discov": 8, "out": [8, 10, 12, 21, 49, 81, 87, 94, 95, 96, 98, 100, 103, 109, 110, 111, 112], "memori": [8, 10, 12, 13, 94, 95, 96, 100, 103, 104, 112, 113], "reduc": [8, 10, 12, 35, 70, 94, 98, 100, 112], "matrix": [8, 15, 36, 42, 54, 80, 85, 87, 95, 96, 100, 112], "miss": [8, 100], "properli": [8, 97], "instal": [8, 10, 94, 95, 96, 98, 104, 110, 113], "Not": [8, 100], "avail": [8, 10, 81, 95, 98, 109, 110, 111, 112, 113], "check": [8, 10, 12, 13, 40, 95, 96, 97, 98, 103, 109, 111, 114], "driver": 8, "basic": [8, 10, 20, 96, 101, 103], "shape": [8, 10, 13, 40, 54, 81, 85, 95, 96, 101, 103, 105, 110, 113], "comprehens": [8, 105, 112], "analysi": [8, 100], "enabl": [8, 10, 78, 91, 94, 95, 98, 104, 105, 112], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 34, 42, 43, 44, 45, 46, 47, 48, 60, 70, 76, 90, 94, 96, 97, 98, 100, 103, 104, 105, 109, 110, 112, 113, 114], "overhead": [8, 100, 104, 105, 112], "multipl": [8, 10, 12, 15, 42, 54, 55, 80, 82, 85, 95, 96, 100, 101, 103, 105, 112, 114], "possibl": [8, 13, 95, 100, 110, 111, 112, 114], "consist": [8, 98, 100, 103, 112, 113, 114], "reproduc": [8, 98], "differ": [8, 10, 12, 17, 45, 52, 55, 84, 85, 94, 95, 96, 97, 98, 100, 103, 104, 105, 110, 111, 112, 114], "case": [8, 9, 10, 70, 85, 98, 100, 103, 105, 109, 110, 114], "user": [8, 10, 12, 42, 55, 70, 76, 92, 94, 95, 96, 98, 100, 101, 103, 108, 110, 111, 112, 113, 114], "more": [8, 10, 12, 13, 45, 46, 94, 95, 96, 98, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113], "about": [8, 10, 12, 95, 96, 97, 98, 100, 110, 111, 112, 114], "compon": [8, 95, 103, 105], "see": [8, 10, 12, 13, 40, 45, 91, 94, 95, 96, 97, 100, 101, 103, 104, 105, 109, 110, 114], "directori": [8, 94], "intend": [9, 95, 110], "provid": [9, 10, 12, 17, 18, 21, 22, 51, 55, 74, 91, 94, 95, 98, 100, 103, 105, 110, 111, 113, 114], "instruct": [9, 12, 95, 98, 110, 111, 112], "most": [9, 10, 20, 70, 95, 98, 100, 105, 110, 111, 114], "fequent": 9, "have": [9, 10, 12, 49, 64, 65, 66, 81, 84, 87, 91, 95, 100, 101, 103, 105, 109, 110, 111, 112, 113, 114], "ani": [9, 10, 20, 60, 64, 74, 87, 95, 100, 103, 109, 111, 113], "answer": [9, 100], "creat": [9, 10, 13, 24, 25, 27, 94, 100, 103, 104, 109, 110, 112, 113, 114], "an": [9, 12, 13, 22, 26, 27, 67, 68, 70, 76, 87, 92, 94, 95, 96, 98, 100, 101, 103, 104, 109, 110, 111, 112, 113, 114], "issu": [9, 95, 96, 103, 112], "start": [10, 12, 32, 33, 49, 50, 71, 80, 81, 94, 95, 98, 100, 101, 103, 105, 109, 110, 111, 112, 113, 114], "read": [10, 103], "overview": [10, 92, 96, 105], "page": [10, 96, 112], "first": [10, 19, 54, 70, 87, 91, 95, 98, 101, 103, 104, 105, 110, 111, 114], "contribut": [10, 96, 100], "exist": [10, 50, 70, 94, 95, 100, 101, 103, 110, 114], "base": [10, 17, 20, 42, 49, 56, 69, 70, 74, 82, 83, 87, 91, 95, 96, 100, 103, 104, 105, 109, 110, 111, 112, 113, 114], "api": [10, 95, 96, 100, 101, 103, 109, 110, 111, 112, 113], "quant_api": [10, 79, 97, 98, 101], "float8tensor": [10, 42, 44, 61, 82, 95, 105], "e": [10, 12, 13, 49, 51, 53, 55, 68, 70, 79, 82, 84, 91, 94, 95, 97, 101, 103, 104, 109, 114], "g": [10, 12, 13, 49, 51, 53, 55, 68, 70, 79, 82, 84, 91, 95, 97, 101, 103, 109, 114], "oper": [10, 12, 13, 15, 17, 18, 47, 52, 95, 96, 98, 109, 110, 111, 112, 113], "make": [10, 43, 45, 95, 96, 103, 105, 110, 114], "trainabl": [10, 12, 95, 103], "add": [10, 20, 91, 103, 108, 112, 114], "parallel": [10, 94, 103, 105], "primit": [10, 13, 40, 103, 110], "op": [10, 12, 13, 40, 42, 79, 80, 91, 96, 100, 103, 105, 110, 111, 112, 114], "slight": [10, 100], "variat": [10, 95], "quant_primit": [10, 13, 40, 101], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 21, 34, 41, 42, 45, 51, 53, 55, 57, 58, 67, 70, 79, 81, 84, 85, 87, 91, 94, 95, 96, 97, 98, 100, 101, 105, 109, 110, 111, 112, 113, 114], "structur": [10, 12, 21, 90, 95, 96, 97, 100, 103, 110], "deriv": [10, 13, 52, 83, 84], "pack": [10, 13, 22, 37, 41, 43, 45, 81], "format": [10, 13, 18, 19, 45, 81, 98, 100, 110, 111, 114], "understand": [10, 81, 94, 112, 114], "concept": [10, 95, 108, 110, 112, 113, 114], "i": [10, 12, 85, 94, 95, 98, 100, 104, 109, 110, 111], "doe": [10, 12, 20, 70, 81, 95, 100, 103, 110, 112, 113], "alreadi": [10, 13, 103, 114], "could": [10, 95, 103, 109, 110, 112, 113, 114], "context": [10, 112, 113], "also": [10, 12, 68, 79, 95, 96, 97, 100, 101, 103, 104, 105, 110, 113, 114], "write": [10, 92, 96, 109, 110, 111], "own": [10, 12, 92, 94, 96, 100, 101, 110, 111, 114], "torchaobasetensor": [10, 105], "help": [10, 12, 94, 95, 98, 105, 109, 110], "common": [10, 70, 80, 81, 82, 83, 92, 94, 95, 100], "specifi": [10, 12, 13, 31, 34, 48, 55, 57, 58, 59, 62, 69, 70, 76, 79, 80, 84, 87, 90, 94, 95, 100, 109, 110, 111, 114], "non": [10, 91, 100, 103, 109, 112, 113], "attribut": [10, 12, 91, 95, 103, 105, 112, 113], "mytensor": [10, 91], "tensor_data_nam": [10, 91], "qdata": [10, 95], "scale": [10, 13, 17, 18, 24, 27, 32, 35, 42, 49, 51, 52, 53, 54, 60, 61, 68, 73, 74, 75, 76, 84, 91, 95, 100, 101, 103, 105, 114], "tensor_attribute_nam": [10, 91], "With": [10, 103, 110, 112, 114], "abov": [10, 12, 43, 45, 49, 95, 97, 100, 101, 103, 110, 111, 114], "ll": [10, 49, 94, 95, 103, 110, 111, 114], "doc": [10, 94, 95, 96, 98, 103, 104], "mani": [10, 95, 100, 103], "still": [10, 12, 95, 100, 110, 114], "affinequantizedtensor": [10, 24, 25, 27, 40, 42, 44, 96, 97, 101, 103], "plan": [10, 42, 44, 45, 111], "move": [10, 79, 101, 105, 111, 112], "awai": 10, "from": [10, 12, 13, 19, 20, 24, 25, 27, 46, 52, 63, 67, 70, 79, 80, 84, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114], "abstract": [10, 95], "easier": [10, 114], "peopl": [10, 95, 97, 105, 114], "implement": [10, 12, 31, 45, 72, 73, 75, 76, 80, 91, 95, 97, 100, 101, 109, 110, 114], "regist": [10, 57, 62, 72, 86, 91, 95, 103], "mai": [10, 13, 52, 68, 81, 95, 97, 101, 104, 110, 111, 112, 113, 114], "well": [10, 17, 95, 96, 100, 110, 111, 114], "int4": [10, 12, 16, 37, 43, 45, 46, 49, 57, 58, 60, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 79, 90, 95, 96, 97, 98, 104, 105], "access": [10, 47, 109], "my_custom_op": 10, "call": [10, 12, 13, 57, 62, 72, 86, 95, 96, 97, 100, 101, 103, 105, 111, 113], "want": [10, 79, 90, 95, 96, 97, 100, 103, 105, 109, 110, 111, 114], "my_mm_for_mp": 10, "aten": [10, 91, 95, 96, 103, 105, 109, 110, 111, 112, 113], "default": [10, 12, 13, 15, 20, 22, 36, 41, 42, 44, 45, 51, 53, 60, 68, 76, 79, 91, 94, 95, 96, 103, 105, 109, 110, 111, 112, 113, 114], "_": [10, 91, 94, 95, 101, 105, 109, 110, 111, 112], "func": [10, 91, 95, 103, 105], "arg": [10, 13, 45, 57, 58, 59, 60, 64, 73, 87, 91, 95, 103, 105, 111, 114], "re": [10, 94, 95, 97, 98, 103, 110, 111], "input_tensor": [10, 19, 95, 105], "weight_tensor": [10, 95, 105], "some": [10, 79, 87, 91, 95, 96, 98, 100, 101, 103, 109, 110, 111, 112, 113, 114], "choic": [10, 45], "mm": [10, 79, 80, 103, 110], "recommend": [10, 12, 42, 44, 45, 46, 47, 48, 94, 95, 104, 109, 112, 113], "wai": [10, 13, 70, 94, 95, 98, 100, 101, 103, 110, 111, 114], "repres": [10, 13, 15, 17, 25, 31, 36, 56, 68, 81, 84, 87, 95, 97, 103, 110, 111], "group_mm": 10, "auto": [10, 42, 80, 98, 104, 105], "develop": [10, 96, 110, 111, 114], "choos": [10, 45, 83, 95, 100, 103, 110, 112], "whatev": 10, "think": [10, 105], "fastest": 10, "under": [10, 12, 80, 98], "condit": 10, "so": [10, 12, 94, 95, 96, 97, 100, 103, 104, 110, 111, 114], "don": [10, 87, 94, 95, 96, 100, 104, 105, 114], "t": [10, 87, 91, 94, 95, 96, 100, 101, 103, 104, 105, 110, 111, 114], "worri": 10, "debug": 10, "purpos": [10, 94, 95, 103, 110], "ha": [10, 12, 13, 70, 98, 100, 103, 105, 109, 110, 111, 113, 114], "hardwar": [10, 42, 81, 96, 98, 100, 104], "h100": [10, 95, 104], "sm89": 10, "sm90": 10, "librari": [10, 80, 81, 92, 95, 97], "whether": [10, 12, 45, 51, 68, 91, 103], "fbgemm_gpu_genai": [10, 80, 95], "granular": [10, 13, 32, 42, 45, 46, 48, 51, 53, 57, 58, 60, 61, 68, 69, 84, 94, 95, 98, 101, 105], "per": [10, 12, 13, 43, 44, 46, 47, 48, 51, 53, 60, 64, 65, 66, 68, 72, 73, 75, 76, 84, 87, 94, 95, 96, 100, 101, 113], "_choose_scale_float8": [10, 95], "_quantize_affine_float8": [10, 95], "_scaled_mm": [10, 95], "kerenel": 10, "fbgemm": [10, 95, 100], "f8f8bf16_rowwis": [10, 95], "level": [10, 87, 95, 100, 103, 109, 110, 112, 113], "reus": [10, 103], "allow": [10, 76, 95, 96, 100, 103, 109, 110, 111, 112, 114], "appli": [10, 12, 13, 42, 43, 44, 46, 47, 48, 55, 59, 60, 62, 67, 69, 70, 79, 90, 91, 95, 96, 98, 100, 105, 111], "convers": [10, 12, 13, 34], "weight": [10, 12, 18, 19, 35, 42, 43, 44, 45, 46, 47, 48, 57, 58, 60, 64, 65, 66, 68, 70, 72, 73, 75, 76, 79, 82, 87, 90, 92, 94, 96, 97, 100, 101, 103, 104, 105, 109, 110, 111, 112, 113, 114], "filter": [10, 12, 34, 94, 101], "should": [10, 12, 13, 35, 53, 57, 62, 63, 70, 72, 86, 87, 91, 94, 100, 105, 109, 110, 114], "algorithm": [10, 45, 98, 100, 109], "dynam": [10, 12, 30, 31, 35, 42, 43, 46, 47, 60, 66, 68, 76, 90, 98, 101, 103, 104, 110, 111, 112], "quant": [10, 13, 40, 95, 98, 105, 110, 113, 114], "In": [10, 12, 45, 70, 94, 95, 96, 100, 101, 103, 109, 110, 111, 112, 113, 114], "order": [10, 55, 91, 100, 103, 114], "aim": [10, 100, 113], "run": [10, 12, 35, 57, 58, 62, 72, 79, 86, 94, 95, 96, 98, 100, 103, 108, 109, 110, 111, 112, 113, 114], "fullgraph": [10, 96], "true": [10, 12, 13, 26, 31, 42, 44, 45, 46, 47, 48, 51, 52, 57, 58, 67, 68, 70, 78, 79, 90, 94, 96, 97, 98, 101, 103, 104, 105, 109, 110, 111, 112, 114], "remov": [10, 51, 87, 94, 100, 105, 110, 111], "unnecessari": 10, "graph": [10, 96, 110, 111, 114], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 96, 98, 101, 103, 108, 111, 112, 113], "inductor": [10, 92, 96, 109, 110], "save": [10, 12, 87, 91, 94, 96, 97, 98, 105], "load": [10, 91, 97, 98, 104, 105], "relev": [10, 95, 108], "object": [10, 41, 79, 90, 95, 103, 110, 111, 114], "safe": [10, 85], "global": [10, 100, 103], "after": [10, 12, 35, 94, 95, 97, 100, 104, 109, 110, 111, 112, 113, 114], "2": [10, 13, 14, 16, 18, 21, 42, 44, 45, 49, 57, 68, 72, 73, 84, 88, 90, 92, 94, 95, 100, 101, 103, 108], "5": [10, 12, 49, 57, 87, 96, 98, 100, 105, 108, 110, 111], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 95], "checkout": [10, 13, 40, 92, 95], "huggingfac": [10, 104], "transform": [10, 12, 13, 91, 101, 109, 110, 111, 112, 113], "deseri": [10, 110, 111], "save_pretrain": [10, 98, 104], "push_to_hub": [10, 98, 104, 105], "from_pretrain": [10, 12, 98, 104, 105], "diffus": [10, 98], "just": [10, 49, 68, 95, 97, 100, 103, 110, 111, 114], "talk": [10, 95, 98], "train": [10, 31, 55, 68, 70, 92, 96, 100, 103, 114], "fsdp": [10, 95], "mydtypetensor": 10, "put": [10, 90, 112, 114], "developer_api_guid": 10, "folder": [10, 98, 110, 111], "cover": [10, 108, 110, 113, 114], "follow": [10, 12, 68, 70, 91, 94, 95, 96, 98, 100, 101, 103, 104, 109, 110, 111, 112, 113, 114], "executorch": [10, 46, 79, 92, 96, 104, 110, 111], "torchchat": 10, "dtensor": [10, 103], "copi": [10, 13, 87, 96, 97, 100, 101, 103, 111, 112], "past": [10, 100], "adapt": [10, 94, 101], "befor": [10, 12, 70, 79, 95, 97, 98, 100, 101, 103, 110, 111, 114], "do": [10, 50, 54, 79, 95, 98, 100, 101, 103, 105, 110, 111, 112, 114], "singl": [10, 12, 30, 35, 42, 52, 94, 95, 96, 100, 110, 114], "comput": [10, 18, 22, 35, 44, 57, 62, 72, 80, 86, 87, 95, 100, 101, 103, 104, 110, 111, 112, 113], "intens": 10, "get": [10, 12, 19, 76, 91, 94, 95, 96, 98, 100, 105, 109, 110, 111, 112, 114], "sens": [10, 95, 103], "d": [10, 91, 98, 111], "benchmark_aq": 10, "s": [10, 12, 13, 49, 51, 53, 80, 81, 84, 91, 94, 95, 96, 98, 100, 101, 103, 110, 111, 112, 113, 114], "import": [10, 12, 63, 67, 70, 79, 90, 96, 97, 98, 100, 101, 103, 104, 105, 108, 109, 112, 113], "A": [10, 12, 13, 41, 52, 86, 91, 95, 100, 103, 104, 105, 110], "quick": [10, 92], "chang": [10, 79, 94, 96, 97, 98, 100, 101, 103, 109, 110, 111, 113, 114], "interest": [10, 100, 103], "print_op_and_shap": 10, "output": [10, 12, 31, 51, 53, 84, 94, 95, 96, 98, 100, 104, 108, 109, 110, 111, 112, 113, 114], "torch_func": 10, "built": [10, 94, 103], "_c": 10, "tensorbas": 10, "all": [10, 35, 45, 49, 52, 57, 60, 62, 64, 72, 74, 86, 87, 88, 91, 95, 96, 97, 98, 99, 100, 101, 103, 105, 106, 109, 110, 112, 114], "benchmark_your_kernel": 10, "helper": [10, 77, 78, 91], "right": [10, 43, 45, 100, 110], "1": [10, 18, 32, 33, 41, 42, 44, 45, 49, 50, 61, 71, 79, 80, 81, 83, 84, 87, 92, 95, 96, 97, 99, 100, 101, 103, 107, 108, 110, 111], "feel": [10, 95, 100, 103, 105], "free": [10, 95, 103], "either": [10, 13, 42, 61, 70, 87, 98, 100, 111, 112, 113], "one": [10, 42, 52, 57, 62, 70, 72, 86, 94, 95, 100, 103, 105, 111, 114], "probabl": 10, "keep": [10, 18, 47, 87, 95, 110], "futur": [10, 101, 104, 105, 110, 111, 112, 114], "llama": [10, 12, 98, 104, 105, 109], "llama2": 10, "llama3": [10, 12, 94, 104], "sam": 10, "modifi": [10, 34, 79, 87, 94, 100, 103], "friendli": 10, "compar": [10, 12, 87, 94, 95, 98, 110, 112, 114], "techniqu": [10, 12, 94, 97, 98, 100, 101, 103, 105], "bound": [10, 42, 61, 98, 100, 105], "each": [10, 19, 60, 68, 73, 75, 76, 86, 91, 95, 100, 101, 103, 105, 110, 111, 114], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 49, 84, 95, 96, 100, 101, 103, 114], "know": [10, 103], "end": [12, 94, 95, 98, 100, 103, 104, 105, 108, 111, 114], "pre": [12, 17, 18, 22, 92, 98, 100, 114], "serv": [12, 13, 17, 92, 94, 103, 104, 113], "flow": [12, 46, 94, 98, 100, 101, 109, 110, 111, 112, 113], "leverag": [12, 94, 96, 98, 103, 112, 113], "partner": [12, 94, 98], "showcas": [12, 94, 98], "focus": [12, 94, 95, 98, 100], "domain": [12, 13, 51, 53, 68, 94], "demonstr": [12, 94, 95, 96, 98, 103, 109, 111], "dure": [12, 13, 40, 47, 53, 68, 70, 94, 96, 98, 100, 101, 103, 109, 111], "numer": [12, 70, 75, 76, 94, 100, 110, 111, 112], "goal": [12, 70], "mitig": [12, 100], "degrad": [12, 70, 100], "eventu": [12, 70, 94], "blog": 12, "resourc": [12, 103], "small": 12, "matric": [12, 21, 100], "freez": [12, 111, 112, 113], "checkpoint": [12, 91, 94, 98, 105], "effici": [12, 22, 75, 96, 100, 101, 113], "paper": [12, 100, 108], "speed": [12, 79, 98, 100, 109], "up": [12, 19, 68, 79, 94, 95, 96, 100, 109, 110, 111, 114], "high": [12, 13, 23, 24, 25, 26, 27, 61, 70, 94, 95, 98, 100, 101, 103, 109, 110, 112, 113], "precis": [12, 13, 23, 24, 25, 26, 27, 44, 47, 60, 61, 65, 66, 70, 73, 75, 76, 95, 101, 103, 104, 109, 112, 113], "similar": [12, 100, 101, 111, 112], "inevit": 12, "actual": [12, 44, 70, 95, 101, 103, 105, 110, 111, 114], "presum": 12, "been": [12, 91, 103, 111, 112, 113, 114], "successfulli": [12, 100], "recent": [12, 92], "releas": [12, 112], "1b": [12, 104, 105], "3b": 12, "llamaguard": 12, "8b": [12, 94, 104], "improv": [12, 94, 98, 100, 110, 113, 114], "qualiti": [12, 100, 104], "involv": [12, 15, 70, 100], "two": [12, 21, 40, 42, 70, 91, 95, 96, 100, 103, 109, 110, 111, 112, 114], "separ": [12, 57, 58, 68, 100, 105, 110, 114], "prepar": [12, 55, 60, 64, 70, 87, 100, 109, 112, 113, 114], "convert": [12, 13, 19, 23, 26, 28, 29, 31, 40, 55, 63, 64, 70, 79, 90, 94, 95, 98, 100, 109, 112, 113, 114], "fake": [12, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 94, 110, 111, 114], "mean": [12, 13, 19, 49, 51, 53, 84, 91, 94, 95, 96, 100, 110, 111, 114], "valu": [12, 13, 19, 31, 32, 33, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 61, 71, 80, 81, 84, 87, 95, 100, 101, 103, 109, 110, 111, 114], "map": [12, 47, 49, 68, 91, 95, 103, 110, 114], "without": [12, 63, 95, 100, 105, 112, 114], "cast": [12, 13, 30, 32], "lower": [12, 42, 46, 61, 95, 96, 98, 100, 101, 104, 111], "replac": [12, 100, 105], "real": [12, 95, 96, 110, 114], "perform": [12, 13, 22, 35, 47, 48, 54, 57, 62, 64, 65, 66, 72, 85, 86, 94, 96, 100, 101, 103, 104, 105, 109, 111, 112, 113], "There": [12, 70, 95, 101, 103, 110, 114], "directli": [12, 49, 52, 70, 95, 100, 101, 103], "loop": [12, 94, 100], "distribut": [12, 94, 101, 103, 105, 109], "recip": [12, 31, 57, 62, 72, 86], "instead": [12, 52, 57, 62, 63, 67, 68, 70, 72, 86, 94, 96, 100, 103, 111, 112, 113, 114], "command": [12, 94], "regular": [12, 109, 112, 113], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 18, 21, 29, 88, 90, 95, 96, 97, 98, 100, 103, 104, 110, 111], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 97, 98, 101, 110, 111], "16": [12, 58, 94], "equival": [12, 68, 100, 111, 112, 114], "asymmetr": [12, 46, 49, 51, 68, 96, 101, 109, 113, 114], "token": [12, 46, 47, 66, 68, 76, 94, 98, 104], "int8": [12, 19, 46, 47, 48, 58, 66, 67, 68, 70, 76, 79, 83, 90, 95, 98, 103, 110, 112, 113, 114], "symmetr": [12, 42, 44, 46, 47, 48, 49, 51, 57, 60, 68, 103, 109, 110, 113, 114], "configur": [12, 15, 30, 31, 34, 42, 43, 44, 45, 46, 47, 48, 79, 90, 94, 95, 96, 98, 104, 112, 113, 114], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 111], "same": [12, 13, 42, 45, 51, 52, 53, 76, 84, 85, 90, 91, 94, 95, 100, 101, 103, 111, 113, 114], "wa": [12, 103, 111], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 104], "int8dynactint4weightquant": 12, "groupsiz": [12, 65, 66, 75, 76, 84], "32": [12, 45, 46, 58, 67, 68, 70, 72, 73, 79, 90, 94, 96, 97, 98, 101, 103, 111], "hellaswag": [12, 98], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 98], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 98], "ckpt": 12, "llama3_token": 12, "path": [12, 79, 85, 96, 98, 109, 110, 111, 112, 114], "tmp": [12, 96], "meta": [12, 97, 104, 105, 114], "print": [12, 87, 96, 97, 98, 103, 108, 110, 111], "version": [12, 16, 42, 44, 45, 68, 79, 95, 97, 103, 105, 110, 111, 114], "shot": [12, 100], "stderr": 12, "none": [12, 13, 15, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 40, 42, 45, 48, 49, 50, 51, 52, 53, 57, 58, 60, 61, 67, 68, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 84, 87, 90, 91, 95, 101, 103, 105, 109, 110, 111, 113], "acc": [12, 110, 111], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 96, 100, 114], "openassist": 12, "oasst1": 12, "dataset": [12, 94, 98, 109, 112, 113], "find": [12, 19, 100, 110, 114], "achiev": [12, 19, 94, 100, 101, 103, 111, 112], "higher": [12, 94, 103, 104, 109, 110, 112, 113], "accuraci": [12, 94, 98, 100, 101, 109, 111, 112], "than": [12, 41, 68, 94, 95, 100, 103, 110], "recov": [12, 100, 111], "69": [12, 101], "8": [12, 22, 41, 45, 49, 57, 58, 65, 75, 94, 95, 96, 98, 105, 112, 113], "overal": [12, 92, 96, 110, 114], "vanilla": 12, "compos": [12, 55, 95, 100, 103, 110, 111, 114], "lora": 12, "yield": [12, 100], "89x": 12, "usag": [12, 13, 35, 55, 57, 58, 63, 67, 68, 70, 91, 92, 94, 98, 112, 113], "36": [12, 94, 98], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 42, 44, 45, 46, 47, 48, 52, 68, 79, 87, 91, 96, 100, 109, 111, 112, 113], "try": [12, 100, 103, 110], "fsdp2": [12, 94], "yaml": 12, "onc": [12, 100], "complet": [12, 98, 109, 113], "qat_out": 12, "quatiz": 12, "document": [12, 103, 105, 109, 110, 112], "prefer": [12, 42, 95, 103], "These": [12, 100, 103, 109, 110, 111, 114], "what": [12, 13, 40, 94, 95, 96, 98, 100, 101, 105, 108, 110, 114], "hood": 12, "mini": [12, 98], "gpu": [12, 92, 94, 96, 104, 105, 108, 109], "smaller": [12, 41, 45, 46, 96, 97], "fit": [12, 13, 22, 95, 97], "adjust": [12, 42, 44, 45, 46, 47, 48], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 94], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 94], "max_seq_len": 12, "train_loop": [12, 70], "sgd": 12, "lr": [12, 94], "001": 12, "momentum": [12, 111], "9": [12, 94], "weight_decai": 12, "1e": [12, 94], "loss_fn": 12, "crossentropyloss": [12, 110, 111], "rang": [12, 49, 94, 100, 101, 110, 111], "randint": 12, "loss": [12, 94, 100, 110, 111], "backward": [12, 35, 94, 100, 111], "zero_grad": [12, 94, 111], "next": [12, 94, 101, 110, 111, 112, 113], "scheme": [12, 47, 48, 57, 58, 70, 98, 109], "although": [12, 45, 57, 62, 72, 86, 103], "integ": [12, 13, 26, 27, 49, 51, 53, 54, 68, 69, 85, 101, 110, 111, 112], "arithmet": [12, 70], "float": [12, 13, 19, 26, 28, 29, 40, 42, 45, 49, 51, 52, 53, 57, 61, 68, 72, 73, 84, 87, 95, 96, 97, 103, 110, 111, 114], "float32": [12, 13, 24, 53, 64, 66, 68, 72, 73, 76, 84, 97, 98, 100, 101, 103, 112, 113, 114], "becaus": [12, 13, 18, 94, 97, 100, 103, 111, 114], "int8dynamicactivationint4weightconfig": [12, 70, 76, 79], "qatconfig": [12, 63, 67, 71], "swap": [12, 34, 60, 64, 94, 100, 101, 111], "fakequantizedlinear": [12, 60, 63, 77, 78], "base_config": [12, 70], "exact": [12, 76, 110, 111], "attun": 12, "benefici": 12, "later": [12, 95, 103, 110, 111, 113], "readi": [12, 94, 96, 98, 101, 103, 111], "did": [12, 46], "altern": [12, 68, 101, 103, 112, 113], "legaci": [12, 45], "offer": [12, 103, 110], "customiz": [12, 79], "unlik": [12, 101], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 96, 101, 109, 110, 111, 112, 113, 114], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 109, 110, 112, 113], "footprint": 12, "extens": [12, 103, 110, 112], "addition": [12, 112, 113], "frozen": 12, "further": [12, 103, 109, 110, 111, 112], "nf4": [12, 19], "propos": [12, 87], "express": [12, 96, 103, 109, 110, 111, 114], "subclass": [12, 13, 34, 40, 57, 62, 72, 80, 81, 86, 90, 91, 96, 97, 100, 104], "nf4tensor": 12, "cleanli": 12, "compil": [12, 79, 85, 92, 94, 95, 96, 101, 103, 112, 113], "simpli": [12, 100, 101, 103], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 26, 31, 34, 42, 44, 45, 46, 47, 48, 51, 52, 57, 58, 66, 68, 72, 73, 75, 76, 78, 79, 90, 101], "quantization_kwarg": 12, "No": [12, 95, 97, 100], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 95, 101, 103, 105], "though": [12, 103], "shown": [12, 98, 100, 111, 114], "competit": [12, 94], "baselin": [12, 94, 98, 110], "while": [12, 57, 62, 70, 72, 82, 86, 87, 98, 100, 103, 104, 109, 110, 114], "even": [12, 13, 94, 100, 114], "newer": 12, "mxfp4": [12, 95], "nvfp4": [12, 95], "blackwel": 12, "reap": 12, "benefit": [12, 43, 100, 103, 110, 113], "vari": [12, 13, 110, 111, 112, 113], "tradeoff": [12, 100, 104], "incorpor": 12, "its": [12, 100, 103, 105, 110, 114], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 94, 95, 103, 104, 105, 110], "yet": [12, 46, 50, 70, 103, 104, 105, 111, 112, 113], "invok": [12, 112], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 98, 104, 105], "torchaoconfig": [12, 98, 104, 105], "int8weightonlyconfig": [12, 79, 105], "base_model": 12, "quantization_config": [12, 98, 104, 105, 113], "peft_config": 12, "throughput": [12, 94, 98], "increas": [12, 100, 110], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 30, 31, 95], "initi": [12, 13, 74, 95, 96, 97, 111], "experi": [12, 94, 113], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 94, 96, 110], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 94], "074": [12, 94], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 94], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 94, 113, 114], "407": [12, 94], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 94], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 40, 91, 101], "aqttensorimpl": [13, 40], "block_siz": [13, 17, 19, 23, 24, 26, 27, 28, 29, 40, 51, 52, 53, 84, 95, 96, 101], "tupl": [13, 19, 23, 24, 26, 27, 28, 40, 42, 51, 52, 53, 74, 84, 87, 91, 103, 105, 110, 111, 114], "quant_min": [13, 26, 27, 28, 40, 49, 51, 52, 53, 84, 96, 103, 113, 114], "union": [13, 31, 40, 42, 51, 53, 61, 68, 79, 84], "quant_max": [13, 26, 27, 28, 40, 49, 51, 52, 53, 84, 96, 103, 113, 114], "zero_point_domain": [13, 26, 27, 28, 40, 45, 51, 52, 68], "zeropointdomain": [13, 26, 27, 28, 40, 45, 51, 52, 68], "stride": [13, 40, 103], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 98, 106, 108], "affin": [13, 14, 15, 16, 18, 21, 22, 26, 37, 38, 53, 84, 95], "point": [13, 28, 40, 45, 49, 53, 61, 68, 73, 74, 75, 76, 94, 95, 96, 97, 100, 101, 103, 110, 114], "quantized_tensor": 13, "float_tensor": [13, 103], "zero_point": [13, 17, 27, 51, 52, 53, 84, 91, 95, 100, 101, 103, 114], "happen": [13, 40, 95, 103, 110, 112], "choose_qparam": [13, 95], "dequant": [13, 19, 40, 53, 95, 96, 103, 105, 110, 112, 113, 114], "http": [13, 40, 87, 98, 100, 104, 113], "com": [13, 40, 98, 104], "ao": [13, 40, 100, 105], "blob": [13, 40], "main": [13, 40, 95, 96, 98, 100, 101, 103, 104, 110, 114], "three": [13, 87, 90, 112, 113], "choose_qparams_affin": [13, 52], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 94, 95, 100, 109, 110, 111, 112, 113], "extern": [13, 112], "regardless": 13, "intern": [13, 22], "represent": [13, 17, 25, 91, 100, 105, 110, 114], "orient": 13, "field": [13, 68, 71, 91, 114], "impl": [13, 91], "storag": [13, 18, 100], "store": [13, 18, 19, 41, 47, 82, 86, 95, 100, 104, 105, 110, 111], "plain": [13, 45, 81, 95, 105], "int_data": [13, 103], "kernel": [13, 14, 16, 18, 22, 37, 42, 43, 75, 79, 80, 96, 98, 100, 109, 112, 113], "element": [13, 21, 41, 51, 53, 60, 73, 75, 76, 84, 91, 95, 100], "share": [13, 51, 53, 84, 100], "qparam": [13, 45, 51, 53, 84], "minimum": [13, 51, 53, 84], "maximum": [13, 51, 53, 84], "zero": [13, 21, 45, 47, 51, 53, 68, 73, 74, 75, 76, 87, 100, 101, 114], "subtract": [13, 19], "unquant": [13, 114], "given": [13, 29, 40, 83, 94, 100, 105, 114], "classmethod": [13, 40, 82, 91, 101, 103, 105], "from_hp_to_floatx": 13, "input_float": [13, 23, 24, 25, 26, 27, 28, 40], "target_dtyp": [13, 23, 24, 26, 27, 30, 31, 51, 52, 95, 101], "_layout": [13, 23, 24, 25, 26, 27, 28, 40, 91, 96, 101], "layout": [13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 38, 39, 40, 41, 45, 46, 47, 90, 91, 100], "scale_dtyp": [13, 23, 24, 26, 51, 52, 101], "float8": [13, 14, 15, 23, 24, 30, 31, 32, 33, 34, 35, 42, 43, 44, 60, 61, 62, 83, 92, 98, 101], "from_hp_to_floatx_stat": 13, "static": [13, 17, 19, 24, 27, 31, 52, 68, 92, 96, 110, 111, 112, 113, 114], "from_hp_to_fpx": 13, "floatx": [13, 25], "ebit": [13, 25], "mbit": [13, 25], "float1": [13, 25], "float7": [13, 25], "from_hp_to_intx": [13, 40], "mapping_typ": [13, 26, 46, 51, 52, 68], "mappingtyp": [13, 26, 46, 47, 51, 52, 68, 101], "ep": [13, 26, 51, 52, 68, 101, 111, 113, 114], "zero_point_dtyp": [13, 26, 51, 52, 101], "preserve_zero": [13, 26, 45, 51, 52], "plainlayout": [13, 26, 27, 46, 47, 91, 101], "use_hqq": [13, 26, 45, 104, 105], "custom_scal": [13, 26], "custom_zero_point": [13, 26], "from_hp_to_intx_stat": 13, "argument": [13, 22, 53, 68, 70, 79, 82, 91, 94, 95, 98, 112], "correct": [13, 18, 110, 111], "otherwis": [13, 48, 55, 68, 111], "desir": [13, 101], "gradient": [13, 92, 100], "implicitli": [13, 114], "complex": [13, 100], "non_block": 13, "memory_format": [13, 112, 113], "preserve_format": 13, "accord": 13, "c": [13, 91, 96, 103, 112, 113], "rule": 13, "truncat": 13, "part": [13, 92, 100, 103, 104, 111], "cannot": [13, 100, 101, 104, 105], "inf": 13, "long": [13, 103, 110], "behavior": [13, 17, 55, 105, 110, 111], "undefin": [13, 55, 87], "across": [13, 87, 98, 100, 103, 105], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 100, 111], "host": [13, 105], "both": [13, 42, 45, 70, 76, 95, 96, 100, 101, 103, 110, 112, 113, 114], "pin": 13, "pageabl": 13, "howev": [13, 100, 104, 105, 111, 114], "caution": 13, "advis": [13, 95], "good": [13, 96, 103, 114], "pin_memori": 13, "match": [13, 53, 54, 75, 76, 91, 100, 110], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 37], "mm_config": [15, 42], "float8mmconfig": [15, 42], "variabl": [15, 22, 36, 41, 87, 91, 100], "tinygemm": [16, 45, 75, 79, 96], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 68, 94, 95, 96, 98, 100, 110, 111, 112], "It": [17, 18, 20, 22, 35, 96, 100, 103, 114], "post": [17, 22, 70, 92, 95, 96, 103, 111, 114], "design": [17, 18, 21, 98, 105, 109, 110, 114], "extend": [17, 95, 100, 112], "conjunct": 17, "tensorimpl": [17, 91], "interact": [17, 110], "spars": [18, 21, 36, 57, 72, 73, 87, 100], "marlin": [18, 28, 39, 40], "pattern": [18, 21, 95, 96, 105, 109, 110], "preprocess": [18, 21], "manag": 18, "pre_process": 18, "1\u00ba": 18, "transpos": [18, 103], "sinc": [18, 43, 57, 62, 72, 86, 95, 97, 98, 100, 101, 103, 110, 111, 112, 113, 114], "2\u00ba": 18, "inject": 18, "3\u00ba": 18, "again": [18, 19, 100, 110, 114], "dim": [18, 61, 101, 103, 105, 110, 111], "tensor_meta": 19, "subclasstensorarg": 19, "n_block": 19, "scaler_block_s": [19, 29], "quantized_scal": 19, "quantization_factor": 19, "scaler_mean": 19, "quantized_data": [19, 105], "qlora": [19, 92, 98], "convert_to_norm_float_weight": 19, "normal": [19, 29, 100, 110, 111], "dequantize_scal": 19, "unpack": 19, "doubl": 19, "scaler": 19, "per_scaler_block": 19, "factor": [19, 54, 94, 100], "inpt_weight": 19, "block": [19, 36, 87, 100], "double_quantize_scal": 19, "take": [19, 57, 62, 72, 79, 86, 90, 91, 95, 100, 109, 110, 111, 112, 113, 114], "calcul": [19, 35, 42, 49, 51, 52, 61, 95, 100, 110, 114], "absmax": 19, "posit": 19, "And": [19, 42, 103, 112, 114], "per_block": 19, "int16": [19, 110], "n_scaler_block": 19, "get_original_weight": 19, "quantize_tensor_nearest": 19, "float16": [19, 84, 100], "nearest": 19, "round": [19, 49, 103], "inherit": [20, 40, 91, 103, 105, 112, 113], "metadata": [20, 91, 95, 98, 103, 105], "semi": [21, 90, 100], "everi": [21, 57, 62, 72, 86, 100, 103, 110, 111], "four": [21, 109], "prune": [21, 87], "conform": 21, "inner_k_til": [22, 45, 65, 75, 96], "core": [22, 50, 79, 101, 105, 110], "tile": 22, "affect": [22, 80, 100], "matmul": [22, 42, 44, 95, 100, 103], "qqq": [28, 39, 40], "64": [29, 36, 45, 60, 97, 98, 101, 103, 105], "256": [29, 45, 64, 65, 66, 75, 76, 98, 110, 111, 114], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "mayb": 30, "cast_config_input": 31, "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "from_recipe_nam": 31, "recipe_nam": [31, 94], "float8linearrecipenam": 31, "qualnam": [32, 33, 49, 50, 71, 80, 81], "boundari": [32, 33, 49, 50, 71, 80, 81], "strategi": 32, "module_filter_fn": [34, 94], "callabl": [34, 79, 90, 91, 105], "float8linearconfig": 34, "float8linear": [34, 94], "instanc": [34, 57, 62, 72, 79, 86, 90, 91, 97, 103, 110, 112, 113, 114], "fqn": [34, 87, 90, 94, 101], "sum": [35, 110, 111], "prototyp": [36, 37, 38, 39, 40, 41, 68, 74, 95, 114], "blocksiz": 36, "da8w4": 38, "marlinqqq": 40, "_choose_qparams_and_quantize_affine_qqq": 40, "_dequantize_affine_qqq": 40, "pack_dim": 41, "uintx": 41, "standard": [41, 105], "byte": 41, "uintxtensor": 41, "determin": [41, 51, 70, 94, 100, 105], "along": [41, 100, 105, 109], "indic": [41, 100, 114], "last": [41, 94, 109], "activation_dtyp": [42, 95], "float8_e4m3fn": [42, 44, 61, 95], "weight_dtyp": [42, 44, 95, 98], "pertensor": [42, 61, 101], "perrow": [42, 61, 95], "list": [42, 53, 55, 87, 91, 96, 103, 105, 109, 111, 114], "activation_value_lb": 42, "activation_value_ub": 42, "kernel_prefer": [42, 95], "kernelprefer": 42, "set_inductor_config": [42, 44, 45, 46, 47, 48], "fp8granular": [42, 61], "fast": [42, 100], "accumul": 42, "upper": [42, 61], "defalut": 42, "chosen": [42, 83, 100], "torchinductor": [42, 44, 45, 46, 47, 48, 112, 113], "deprec": [42, 44, 45, 63, 67], "split": [42, 44, 98, 110, 111], "int4_packing_format": [43, 45, 96], "int4packingformat": [43, 45], "preshuffl": [43, 95], "128": [43, 45, 94, 98, 101, 103, 104, 105, 113, 114], "underli": [43, 98, 103], "bigger": 43, "channel": [44, 47, 48, 60, 64, 65, 66, 68, 72, 73, 75, 76, 86, 101, 113], "tensorcoretiledlayout": [45, 96], "int4_choose_qparams_algorithm": [45, 96], "int4chooseqparamsalgorithm": 45, "groupwis": 45, "mainli": [45, 95, 109, 112, 114], "distinguish": [45, 95], "packing_format": 45, "control": [45, 46, 47, 48, 87, 100, 105, 110], "fine": [45, 46, 92, 94, 98, 100], "grain": [45, 46, 103], "variant": [45, 49, 52, 103], "hqq": [45, 95, 96], "preserv": [45, 51, 87, 98, 100, 109], "Will": 45, "subset": [45, 95], "valid": [45, 91, 98, 105, 114], "state": [45, 105], "v1": [45, 98], "v2": [45, 108], "ignor": [45, 57, 62, 72, 86, 94, 110, 111], "less": [45, 49, 100, 103, 110], "confus": [45, 95, 100, 110], "act_mapping_typ": [46, 47], "produc": [46, 96, 109, 110, 111, 112, 113], "backend": [46, 92, 96, 98, 100, 114], "marlinqqqlayout": 46, "cutlassint4packedlayout": 46, "weight_only_decod": 47, "around": [47, 94, 95, 96, 97, 110], "decod": [47, 98], "better": [47, 48, 94, 103, 110, 111, 112, 113, 114], "number": [49, 60, 73, 75, 76, 87, 98, 100, 103, 111, 112], "sai": [49, 84, 95, 104, 105, 114], "3": [49, 57, 84, 92, 94, 95, 96, 100, 104, 108, 110, 111], "7": [49, 94, 98, 112, 113], "symmetric_no_clipping_err": 49, "smin": 49, "smax": 49, "min_val_neg": [49, 103], "max_val_po": [49, 103], "By": [49, 100], "individu": [49, 100], "error": [49, 68, 94, 103, 110], "neg": 49, "placehold": [50, 95, 113], "int32": [51, 64, 68, 72, 73, 95, 96, 110, 114], "fp32": [51, 53, 68, 76, 101, 103, 110, 112], "fp16": 51, "optioanl": 51, "param": [51, 52, 87, 98], "request": [51, 53, 84], "min_val": [52, 103], "max_val": [52, 103], "observ": [52, 86, 95, 100, 101, 109, 110, 111, 112, 113, 114], "obtain": 52, "track": [52, 104, 105], "calibr": [52, 96, 109, 111, 112, 113], "mostli": [52, 70, 96], "input_dtyp": 53, "output_dtyp": [53, 72, 84], "uint8": [53, 84, 95, 101, 114], "b": [54, 91], "scales1": 54, "multipli": [54, 85, 100], "second": [54, 70, 91, 94, 95, 108, 114], "rais": [54, 67, 70, 85, 103, 105], "assertionerror": [54, 85, 103], "expect": [54, 94, 100, 103, 109, 110, 112, 113, 114], "qat": [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 92, 98, 112], "twostepquant": 55, "easili": [55, 109], "thei": [55, 94, 96, 100, 103, 110, 111, 114], "constructor": [55, 91, 103], "must": [55, 68, 70, 76, 94, 100, 104, 105, 111, 113, 114], "embed": [55, 57, 64, 67, 70, 72, 73], "my_quant": 55, "qatquantizer1": 55, "qatquantizer2": 55, "qatquantizer3": 55, "num_embed": [57, 72, 73], "embedding_dim": [57, 72, 73], "padding_idx": [57, 72, 73], "max_norm": [57, 72, 73], "norm_typ": [57, 72, 73], "scale_grad_by_freq": [57, 72, 73], "weight_config": [57, 58, 67, 70], "fakequantizeconfigbas": [57, 58, 67, 70], "intxfakequantizeconfig": [57, 58, 67, 69, 70], "fq_embed": 57, "longtensor": 57, "overridden": [57, 62, 72, 86], "within": [57, 62, 72, 86, 98, 100, 105, 112, 113], "afterward": [57, 62, 72, 86], "former": [57, 62, 72, 86], "care": [57, 62, 72, 86, 97, 100, 110], "hook": [57, 62, 72, 86, 95], "latter": [57, 62, 72, 86, 111], "silent": [57, 62, 72, 86, 112], "in_featur": [58, 75, 76, 94, 96, 97, 101, 103], "out_featur": [58, 75, 76, 94, 96, 101, 103], "activation_config": [58, 67, 70], "per_token": [58, 67, 68, 70], "is_symmetr": [58, 67, 68, 70], "fq_linear": 58, "scale_precis": [60, 64, 68, 72, 73], "rowwis": [60, 95], "hp_value_lb": 61, "hp_value_ub": 61, "float8fakequantizeconfig": 62, "fakequantizedembed": 63, "back": [63, 103], "model_with_fake_quantized_linear": 63, "zero_point_precis": [64, 68, 72, 73], "int4weightonlyqatembed": 64, "int4weightonlyembed": 64, "scales_precis": [65, 66, 75, 76], "padding_allow": 66, "valueerror": [67, 70], "torchaodtyp": 68, "is_dynam": [68, 112, 113, 114], "range_learn": 68, "simul": [68, 70, 88, 100], "older": 68, "int1": [68, 95], "int7": [68, 95], "pergroup": [68, 98], "pertoken": 68, "per_channel": 68, "peraxi": [68, 98, 101], "per_group": [68, 84], "combin": [68, 98, 100, 103, 110, 112], "leav": 68, "empti": [68, 95], "keyword": [68, 70, 82, 95], "properti": [68, 69], "throw": 68, "els": [68, 95, 98, 105, 110, 111], "symmetri": 69, "qatstep": 70, "awar": [70, 87, 92, 96, 100, 103], "ptq": [70, 111, 112], "automat": [70, 94, 98, 103, 104, 105, 108], "phase": [70, 114], "int4weightonlyconfig": [70, 79, 96, 97, 105], "experiment": [70, 109], "qat_config": 70, "act_config": 70, "alwai": [70, 98, 103], "One": [70, 100, 103, 105, 114], "enum": [71, 80], "example_input": [74, 96, 97, 101, 109, 110, 111, 112, 113, 114], "intxfakequantizerbas": 74, "weightonlyint4linear": 75, "hardcod": [76, 114], "mod": [77, 78, 94, 100, 103], "disabl": [77, 103, 111], "filter_fn": [79, 90], "_is_linear": [79, 101], "inplac": [79, 87, 96], "fulli": [79, 90, 98, 100, 110], "qualifi": [79, 90, 100], "final": [79, 95, 96, 100, 109, 110, 111, 112, 113, 114], "predefin": [79, 81, 114], "execut": [79, 99, 103, 107], "int8dynamicactivationint8weightconfig": [79, 90], "int4_weight_onli": 79, "sequenti": [79, 90, 94], "select": [80, 110], "found": [80, 95, 96, 98, 100, 101, 103], "nativ": [80, 92, 94, 95, 103, 110], "laid": [81, 95], "opaqu": 81, "decid": [81, 100, 101], "adopt": [81, 95], "creation": [82, 105], "construct": [82, 95, 110, 114], "from_hp": [82, 95], "cl": [82, 91, 101, 103, 105], "quant_kwarg": [82, 83], "quantizetensorkwarg": 83, "flexibl": [83, 100, 103, 109, 112], "variou": 83, "tabl": [84, 91, 94, 95, 100], "show": [84, 94, 96, 98, 100, 105, 110, 111], "per_tensor": 84, "per_axi": 84, "axi": [84, 101], "mat2": 85, "consid": [85, 100], "cubla": 85, "fallback": [85, 105], "j": 85, "l2": [86, 100], "norm": [86, 87, 100], "buffer": 86, "x_orig": 86, "sparsity_level": [87, 100], "semi_structured_block_s": 87, "wanda": 87, "sparsifi": [87, 92, 97, 100], "arxiv": [87, 100], "org": [87, 98, 100, 113], "ab": [87, 100], "2306": 87, "11695": 87, "product": [87, 98, 104, 105, 112, 114], "magnitud": [87, 100], "dict": [87, 91, 103, 105, 113, 114], "parametr": 87, "deepcopi": [87, 96, 101, 103, 111], "squash_mask": [87, 100], "params_to_keep": 87, "params_to_keep_per_lay": 87, "squash": 87, "mask": [87, 100], "appropri": [87, 109, 110, 111, 112, 113], "sparse_param": 87, "attach": [87, 100, 114], "kei": [87, 100, 108], "xdoctest": 87, "skip": [87, 95, 100], "local": [87, 98, 100], "hasattr": [87, 105], "submodule1": 87, "linear1": [87, 96, 97, 101, 103], "foo": [87, 110], "bar": [87, 110], "submodule2": 87, "linear42": 87, "baz": 87, "42": [87, 101], "24": 87, "ones": [87, 111], "update_mask": 87, "tensor_nam": [87, 105], "statist": [87, 100, 101, 110, 111], "retriev": 87, "act_per_input": 87, "Then": [87, 103, 113, 114], "whole": [87, 114], "alia": [89, 91, 105], "semisparseweightconfig": 89, "sparsify_": 90, "apply_tensor_subclass": 90, "essenti": [90, 105, 109], "semi_sparse_weight": 90, "semisparselayout": 90, "sparsemarlinlayout": 90, "isinst": [90, 94, 100, 101, 103, 105, 111, 114], "sparse_api": 90, "commonli": [91, 94, 100], "includ": [91, 94, 95, 103, 109, 112, 113, 114], "_get_to_kwarg": 91, "register_layout": 91, "plainaqttensorimpl": [91, 101], "get_tensor_impl_constructor": 91, "tensor_impl_ctr": 91, "simplifi": [91, 109, 110, 112, 113], "implment": 91, "tensor_data": 91, "optional_tensor_data_nam": 91, "boilerpl": 91, "optional_tensor_attribute_nam": 91, "__new__": [91, 103, 105], "exaclti": 91, "present": [91, 100], "__tensor_flatten__": [91, 103, 105], "flatten": 91, "attribute_nam": 91, "__tensor_unflatten__": [91, 103, 105], "tensor_data_dict": [91, 103, 105], "_apply_fn_to_data": [91, 105], "recreat": 91, "__repr__": [91, 103], "_same_metadata": 91, "between": [91, 95, 100, 103, 105, 109, 111, 112, 114], "__setstate__": 91, "serial": [91, 92, 95, 104, 110, 111], "old": 91, "maintain": [91, 98, 100], "bc": 91, "contigu": [91, 95, 112, 113], "detach": [91, 103, 105], "clone": [91, 98, 105], "copy_": [91, 105], "_to_copi": [91, 105], "f": [91, 94, 95, 97, 98, 100, 101, 103, 105, 110, 111], "h": [91, 98], "layout_class": 91, "tensorimplclass": 91, "from_plain": 91, "tensor_class": 91, "aten_op": 91, "decor": [91, 103, 105], "__torch_dispatch__": [91, 103], "implements_torch_funct": 91, "torch_fn": 91, "__torch_function__": [91, 95, 103], "registr": 91, "aqt": 91, "introduct": [92, 95, 98], "highlight": [92, 103, 108], "guid": [92, 95, 98, 109], "contributor": [92, 95, 96], "benchmark": [92, 94, 96, 104, 109, 112, 113], "tune": [92, 94, 98, 100, 109], "vllm": [92, 104], "sglang": [92, 104], "hug": [92, 98], "face": [92, 95, 98, 100, 110], "advanc": [92, 101, 103, 109, 112, 113], "export": [92, 95], "x86": [92, 96], "intel": [92, 109, 112], "openvino": [92, 96], "5x": 94, "cluster": [94, 95], "34": 94, "43x": 94, "2k": 94, "h200": 94, "latest": 94, "offic": 94, "offici": [94, 95], "sever": [94, 105, 109, 114], "popular": 94, "flagship": 94, "form": [94, 95, 100], "quickli": [94, 103], "batteri": 94, "fork": 94, "build": [94, 95, 100, 103, 105, 110], "top": [94, 95, 103, 109, 110, 111, 112, 113], "virtual": 94, "environ": [94, 98], "conda": 94, "venv": 94, "download": [94, 98, 106, 108, 110, 111, 113], "job": 94, "below": [94, 95, 100, 103, 104, 105, 108, 109], "root": [94, 98], "launch": 94, "ngpu": 94, "config_fil": 94, "train_config": 94, "llama3_8b": 94, "toml": 94, "run_train": 94, "sh": [94, 98], "hyperparamet": 94, "edit": [94, 98], "line": [94, 100, 104], "flag": [94, 111], "termin": 94, "rank0": 94, "titan": 94, "2025": 94, "06": 94, "04": 94, "08": 94, "51": 94, "48": 94, "info": 94, "2254": 94, "27": 94, "34gib": 94, "28": 94, "78": 94, "tp": [94, 105], "375": 94, "tflop": 94, "21": 94, "73": [94, 101], "mfu": 94, "20": [94, 98, 111], "58": 94, "557": 94, "7069": 94, "99gib": 94, "62": 94, "034": 94, "35": [94, 98, 101], "41": [94, 98], "19": 94, "52": 94, "224": [94, 101, 109, 110, 111, 112, 113], "9196": 94, "022": 94, "406": [94, 110, 111], "65": 94, "904": 94, "1423": 94, "014": 94, "23": [94, 101], "As": [94, 110, 114], "warmup": 94, "7k": 94, "99gb": 94, "peak": [94, 98, 104], "against": 94, "02": 94, "37": 94, "404": 94, "2611": 94, "22gib": 94, "595": 94, "47": 94, "49": [94, 101], "027": 94, "4260": 94, "89gib": 94, "344": 94, "367": 94, "39": 94, "03": 94, "01": 94, "988": 94, "9482": 94, "321": 94, "366": 94, "14": 94, "991": 94, "1183": 94, "300": 94, "364": 94, "89": 94, "40": 94, "4659": 94, "291": 94, "84": 94, "769": 94, "gc": 94, "peform": 94, "period": 94, "collect": [94, 100], "3k": 94, "89gb": 94, "11x": 94, "nearli": 94, "ident": [94, 100], "performan": 94, "vs": [94, 100, 110, 114], "curv": [94, 100], "omit": [94, 95, 110, 111, 112], "648": 94, "2648": 94, "28gib": 94, "71": 94, "26": 94, "475": 94, "9106": 94, "91gib": 94, "53": [94, 98], "503": 94, "434": 94, "43": 94, "94": [94, 110], "166": 94, "0774": 94, "663": 94, "443": 94, "44": [94, 101], "87": 94, "50": [94, 100, 101, 109, 110, 112, 113], "885": 94, "3233": 94, "643": 94, "442": 94, "66": [94, 98, 101], "76": 94, "613": 94, "6150": 94, "637": 94, "72": [94, 98], "6k": 94, "91gb": 94, "21x": [94, 98], "tl": 94, "dr": 94, "priorit": 94, "accur": [94, 100, 109], "stabil": 94, "cost": [94, 101], "slightli": [94, 103], "impact": [94, 98, 105], "outlier": 94, "caus": 94, "underflow": 94, "8xh100": 94, "box": [94, 100, 112], "toi": [94, 96, 101, 103, 112], "convert_to_float8_train": 94, "recurs": 94, "kind": [94, 110], "over": [94, 100, 110, 111], "gemm": [94, 112, 113], "snippet": [94, 110, 111], "float8_linear_util": 94, "float8_linear": 94, "sampl": [94, 110, 112, 113], "adamw": 94, "being": [94, 100, 105, 112, 113], "elig": 94, "divis": 94, "label": 94, "fake_label": 94, "ones_lik": 94, "mse_loss": 94, "model_state_dict": 94, "state_dict": [94, 97, 110, 111], "optimizer_state_dict": 94, "pth": [94, 110, 111], "explor": [94, 96, 113], "few": [94, 103, 110, 111], "lai": 95, "stack": [95, 98], "awq": 95, "gptq": 95, "int4tensor": 95, "int4preshuffledtensor": 95, "uint1": 95, "uint7": 95, "float3": 95, "triton": [95, 112, 113], "overload": [95, 100], "term": [95, 100, 110, 114], "extra": [95, 98], "matter": [95, 100], "float4_e2m1fn_x2": 95, "float8_e4m3fnuz": 95, "float8_e5m2": 95, "float8_e5m2fnuz": 95, "float8_e8m0fnu": 95, "pr": 95, "shell": 95, "dervi": 95, "mxfp8": 95, "preicison": 95, "mention": [95, 110], "previou": [95, 98, 110, 111, 112, 113], "accommod": 95, "choose_qparams_affine_with_min_max": 95, "min": [95, 101, 103, 110, 114], "raw": 95, "quantize_fp8_row": 95, "int_matmul": 95, "int_scaled_matmul": 95, "reli": [95, 96, 100, 101, 103], "handwritten": 95, "On": [95, 96], "glue": 95, "everyth": 95, "togeth": [95, 98, 110, 112, 114], "anoth": [95, 100, 103, 110, 114], "side": 95, "swizzl": 95, "dtpype": 95, "act": 95, "adjac": 95, "special": [95, 100, 109, 110], "float8rowwisetensor": 95, "float8blockwisetensor": 95, "close": [95, 100], "low_precision_v": 95, "high_precision_v": 95, "procedur": 95, "especi": [95, 97, 100, 112, 113], "bitwidth": [95, 114], "codebook": 95, "index": [95, 98, 100, 113], "vector": [95, 100, 112], "kmean": 95, "tradition": 95, "explain": [95, 109, 112], "simplest": [95, 100], "easi": [95, 98], "linear_modul": 95, "runtim": [95, 110], "question": [95, 97, 100, 103, 114], "activation_granular": 95, "act_quant_kwarg": 95, "weight_granular": [95, 98], "quantized_weight": [95, 105], "float8_dtyp": 95, "haven": 95, "seen": 95, "pt2": [95, 103, 112], "autoround": 95, "multitensor": 95, "sure": [95, 98, 114], "open": [95, 100], "describ": [95, 97, 100, 108, 110, 111], "finetun": [95, 98], "quantized_train": 95, "progress": [95, 104, 105], "lot": [95, 100], "connect": [95, 114], "walk": [95, 101, 103, 108, 109, 112], "float8dynamicactivationfloat8weightconfig": 95, "len": [95, 98, 105, 110, 111, 114], "_choose_quant_func_and_quantize_tensor": 95, "relat": [95, 100], "xq": 95, "reshap": [95, 110, 111], "wq": 95, "x_scale": [95, 110], "w_scale": 95, "out_shap": 95, "entri": 96, "mutat": 96, "logic": [96, 103, 105], "toylinearmodel": [96, 97, 101], "linear2": [96, 97, 101, 103], "eval": [96, 97, 98, 101, 109, 111, 112, 113], "faster": [96, 100], "model_bf16": 96, "uint4": 96, "int4mm": 96, "mix": [96, 98, 109, 112, 113], "tile_packed_to_4d": 96, "stai": [96, 103], "tensor_impl_dtyp": 96, "roughli": [96, 100], "quarter": 96, "os": [96, 110, 111], "int4_model": 96, "pt": [96, 98], "bfloat16_model": 96, "int4_model_size_mb": 96, "getsiz": [96, 110, 111], "bfloat16_model_size_mb": 96, "2f": [96, 110, 111], "mb": [96, 97, 99, 107, 110, 111], "00": [96, 99, 107], "benchmark_model": 96, "unwrap_tensor_subclass": 96, "num_run": 96, "100": [96, 103, 110, 111], "_dynamo": [96, 103], "reset": [96, 110, 111], "bf16_time": 96, "int4_tim": 96, "time": [96, 100, 103, 104, 108, 109, 110, 111], "3f": [96, 111], "ms": 96, "1fx": 96, "393": 96, "410": 96, "9x": 96, "recogn": [96, 114], "decis": 96, "pt2e": [96, 109, 110, 111, 112, 113], "fuse": [96, 100, 103, 111], "deleg": [96, 110], "x86inductorquant": [96, 112], "quantize_pt2": [96, 109, 110, 111, 112, 113], "prepare_pt2": [96, 109, 110, 112, 113], "x86_inductor_quant": [96, 112], "get_default_x86_inductor_quantization_config": [96, 112], "float_model": [96, 103, 109, 110, 111, 112, 113], "data_load": [96, 110, 111, 112, 113], "no_grad": [96, 103, 109, 110, 111, 112, 113], "imag": [96, 104, 109, 110, 111, 112, 113], "program": [96, 110, 111, 112, 114], "captur": [96, 110, 111, 114], "expos": [96, 110, 111], "set_glob": [96, 110, 111, 112, 113], "xiq": [96, 112], "prepare_qat_pt2": [96, 111, 112], "sample_inference_data": 96, "convert_pt2": [96, 109, 110, 111, 112, 113], "wrapper": [96, 103, 112], "_inductor": [96, 112], "cpp_wrapper": [96, 112], "optimized_model": [96, 109, 112, 113], "converted_model": [96, 112, 113], "xpu": [96, 113], "simpl": [96, 100, 101, 103, 109, 112, 113], "visit": 96, "would": [96, 100, 103, 111, 113], "forget": 96, "tempfil": [97, 104], "get_model_size_in_byt": 97, "ref": [97, 110], "namedtemporaryfil": 97, "seek": [97, 100], "m_load": 97, "load_state_dict": [97, 110, 111], "assign": 97, "assert": [97, 101, 103, 105, 114], "equal": [97, 100], "thing": [97, 100, 103, 110], "float_weight1": 97, "float_weight2": 97, "quantized_weight1": 97, "quantized_weight2": 97, "go": [97, 103, 108, 114], "techinqu": 97, "reduct": [97, 98, 100, 103], "4x": [97, 98], "0625": 97, "reason": [97, 100], "avoid": [97, 100], "affine_quantized_tensor": 97, "deploi": 98, "engin": 98, "seamlessli": [98, 103, 112, 113], "seamless": [98, 112], "hf": [98, 104], "signific": [98, 100], "pip": [98, 104, 109, 110], "url": [98, 113], "whl": [98, 113], "nightli": 98, "cu128": 98, "push": [98, 100, 104, 105], "hub": [98, 104, 105], "server": [98, 105], "phi": 98, "fp8": 98, "microsoft": 98, "o3": 98, "client": 98, "curl": 98, "localhost": 98, "8000": 98, "chat": 98, "content": 98, "applic": 98, "messag": 98, "role": 98, "give": [98, 100, 103], "me": 98, "short": 98, "larg": [98, 103, 112], "languag": 98, "temperatur": 98, "top_p": 98, "95": 98, "top_k": 98, "max_token": 98, "32768": 98, "vram": 98, "15x": 98, "2x": [98, 100], "littl": [98, 105], "packag": [98, 104], "git": [98, 104], "acceler": [98, 100, 104], "autotoken": [98, 104], "pipelin": 98, "random": [98, 100, 110, 111], "manual_se": [98, 110, 111], "model_path": 98, "device_map": [98, 104, 105], "trust_remote_cod": 98, "ai": 98, "assist": 98, "eat": 98, "banana": 98, "dragonfruit": 98, "smoothi": 98, "blend": 98, "milk": 98, "honei": 98, "salad": 98, "slice": [98, 105], "lemon": 98, "juic": 98, "solv": [98, 100, 103], "equat": 98, "pipe": [98, 104], "text": 98, "generation_arg": 98, "max_new_token": 98, "500": 98, "return_full_text": 98, "do_sampl": 98, "generated_text": 98, "lm_head": 98, "those": [98, 100, 101, 103], "ti": 98, "autoprocessor": 98, "modeling_util": 98, "find_tied_paramet": 98, "model_id": [98, 104], "untied_model": 98, "getattr": [98, 105], "get_text_config": 98, "tie_word_embed": 98, "setattr": [98, 103], "_tied_weights_kei": 98, "user_id": 98, "your_user_id": 98, "model_nam": [98, 109, 112, 113], "save_to": [98, 104], "save_to_local_path": 98, "int8dynamicactivationintxweightconfig": 98, "ve": [98, 100], "intxweightonlyconfig": 98, "fqntoconfig": [98, 105], "untied_model_id": 98, "untied_model_local_path": 98, "embedding_config": 98, "linear_config": 98, "weight_scale_dtyp": 98, "quant_config": 98, "_default": [98, 105], "embed_token": 98, "quant_typ": [98, 104, 105], "include_embed": 98, "untie_embedding_weight": 98, "modules_to_not_convert": 98, "quantized_model": [98, 103, 104, 109, 110, 111], "safe_seri": [98, 104, 105], "pte": 98, "cd": 98, "install_requir": 98, "phi_4_mini": 98, "convert_weight": 98, "pytorch_model": 98, "bin": 98, "pytorch_model_convert": 98, "export_llama": 98, "kv": 98, "use_sdpa_with_kv_cach": 98, "get_bos_id": 98, "199999": 98, "get_eos_id": 98, "200020": 98, "max_seq_length": 98, "max_context_length": 98, "output_nam": 98, "phi4": 98, "phone": 98, "io": 98, "2gb": 98, "iphon": 98, "pro": [98, 100], "17": 98, "sec": 98, "test": [98, 104, 108, 110, 112], "lm": 98, "har": 98, "eleutherai": 98, "lm_eval": 98, "model_arg": 98, "pretrain": [98, 100, 109, 110, 111, 112], "reset_peak_memory_stat": 98, "prompt": [98, 104], "hei": 98, "consciou": 98, "templated_prompt": 98, "apply_chat_templ": 98, "add_generation_prompt": 98, "templat": [98, 99, 106, 107], "return_tensor": 98, "generated_id": 98, "output_text": 98, "batch_decod": 98, "skip_special_token": 98, "clean_up_tokenization_spac": 98, "respons": 98, "mem": [98, 99, 107], "max_memory_reserv": 98, "1e9": 98, "02f": 98, "gb": 98, "hello": [98, 104], "ye": 98, "am": 98, "digit": 98, "todai": 98, "70": [98, 101], "bench": 98, "vllm_disable_compile_cach": 98, "project": 98, "vllm_use_precompil": 98, "sharegpt": 98, "wget": 98, "co": 98, "anon8231489123": 98, "sharegpt_vicuna_unfilt": 98, "resolv": 98, "sharegpt_v3_unfiltered_cleaned_split": 98, "tree": 98, "num": 98, "benchmark_serv": 98, "16x": 98, "1s": 98, "14x": 98, "num_prompt": 98, "req": 98, "57": [98, 101], "1000": [98, 112], "68": 98, "80": 98, "entir": [98, 110, 111], "ml": 98, "gain": [98, 100, 113], "eas": 98, "accept": [98, 114], "trade": [98, 100], "off": [98, 100], "004": [99, 107, 108], "total": [99, 107, 108], "galleri": [99, 106, 108], "tutorials_sourc": 99, "template_tutori": [99, 107, 108], "neural": [100, 109, 112], "network": [100, 103, 109, 112], "latenc": 100, "carefulli": 100, "pai": 100, "low": [100, 103, 104, 109], "price": 100, "f1": 100, "problem": [100, 103], "research": [100, 108], "fragment": 100, "rightfulli": 100, "spent": 100, "figur": [100, 110], "compress": [100, 109], "place": [100, 109, 110, 111, 112, 113], "dens": 100, "focu": [100, 103], "realli": 100, "concret": [100, 114], "hope": 100, "modular": 100, "nice": 100, "scratch": [100, 108], "minim": [100, 109, 112, 113], "algorthim": 100, "realiz": 100, "theoret": 100, "analog": 100, "fix": [100, 101], "unstructur": 100, "retrain": 100, "neglig": 100, "area": 100, "agre": 100, "upon": 100, "consensu": 100, "mind": 100, "thought": 100, "subproblem": 100, "satisfi": 100, "my": [100, 111], "independ": 100, "frontend": [100, 112], "arbitrari": 100, "handoff": 100, "piec": 100, "natur": [100, 103, 110, 114], "clear": 100, "contract": 100, "7x": 100, "advantag": 100, "anticip": 100, "solut": 100, "third": 100, "parti": 100, "to_sparse_semi_structur": 100, "sparsesemistructuredtensor": 100, "weightnormsparsifi": 100, "half": 100, "subnetwork": 100, "sparse_config": 100, "named_modul": 100, "tensor_fqn": 100, "sparse_block_shap": 100, "zeros_per_block": 100, "fakespars": 100, "fundament": [100, 111], "manipul": 100, "dictionari": 100, "paramer": 100, "parameter": 100, "necessari": [100, 101, 103, 109, 110, 111, 112, 113], "suitabl": [100, 112], "0s": 100, "spot": 100, "definit": [100, 105], "academia": 100, "industri": 100, "often": [100, 103], "interchang": 100, "distinct": 100, "idea": 100, "behind": 100, "doesn": [100, 111, 114], "itself": [100, 103], "loos": 100, "speak": 100, "tightli": 100, "coupl": [100, 103], "csc": 100, "qnnpack": 100, "descript": [100, 109], "coo": 100, "sparse_coo": 100, "coordin": 100, "locat": 100, "bsr": 100, "sparse_bsr": 100, "veri": [100, 105, 111], "except": [100, 103, 114], "scalar": [100, 110], "dimension": 100, "csr": 100, "sparse_csr": 100, "sparse_csc": 100, "column": 100, "compact": 100, "sparse_matrix": 100, "1d": 100, "indexptr": 100, "\u00bd": 100, "bitmask": 100, "2bit": 100, "unprun": 100, "quit": [100, 103], "broken": 100, "down": 100, "sensit": 100, "effect": [100, 101, 103, 112, 113, 114], "best": [100, 112], "subsequ": [100, 103, 112, 113], "infinit": 100, "lost": 100, "degre": 100, "drop": 100, "proxi": 100, "aforement": 100, "smallest": 100, "absolut": 100, "scope": 100, "impli": 100, "con": 100, "potenti": [100, 101, 109, 110, 112, 113], "sub": 100, "span": 100, "threshold": 100, "constant": [100, 103, 110], "ctr_mobile_fe": 100, "score": 100, "w": [100, 105], "tenosr": 100, "udpat": 100, "histori": 100, "regrow": 100, "dw": 100, "via": [100, 109], "backprop": 100, "pat": 100, "unmask": 100, "resid": 100, "salienc": 100, "lowest": 100, "l1": 100, "abl": [100, 103, 105, 110, 114], "repeat": [100, 110, 111], "movement": 100, "2005": 100, "07683": 100, "rank": [100, 103], "wx": 100, "sqx": 100, "q": [100, 110], "usual": 100, "sort": 100, "wise": 100, "reconstruct": [100, 105], "randomli": 100, "tri": 100, "remedi": 100, "sometim": 100, "item": [100, 108], "ultim": [100, 101], "complic": [100, 110], "literatur": 100, "vision": 100, "nlp": [100, 108, 112], "iter": [100, 110, 111], "ctr_feed": 100, "na": 100, "multimask": 100, "search": 100, "pyspeech": 100, "fastna": 100, "approach": [100, 103, 109, 112, 113], "knowledg": [100, 108], "distil": 100, "pdf": 100, "2204": 100, "09656": 100, "arrang": 100, "recal": 100, "counterpart": 100, "slower": 100, "suffici": 100, "At": [100, 110], "98": 100, "exhibit": 100, "penalti": 100, "expens": [100, 103], "dictat": 100, "characterist": 100, "highest": 100, "wouldn": [100, 103], "visual": 100, "fig": 100, "4x4": 100, "benchmak": 100, "fly": [101, 104], "affinequantizedminmaxobserv": 101, "record": 101, "welcom": 101, "averag": [101, 110, 111], "histogram": [101, 110], "act_ob": 101, "finfo": 101, "weight_ob": 101, "observedlinear": 101, "observed_input": 101, "observed_weight": 101, "from_float": [101, 103], "float_linear": 101, "observed_linear": 101, "_replace_with_custom_fn_if_matches_filt": 101, "insert_observers_": 101, "lambda": [101, 105], "replacement_fn": 101, "copied_act_ob": 101, "copied_weight_ob": 101, "popul": 101, "feed": 101, "simpler": [101, 110], "quantizedlinear": [101, 103], "isn": 101, "strictli": 101, "to_affine_quantized_intx_stat": 101, "act_scal": [101, 114], "act_zero_point": 101, "calculate_qparam": [101, 114], "weight_scal": [101, 110, 114], "weight_zero_point": [101, 110], "qweight": 101, "qinput": 101, "from_observ": 101, "quantized_linear": [101, 110], "begin": [101, 103], "dataclass": [101, 105, 114], "transform_modul": [101, 105], "register_quantize_module_handl": [101, 105], "staticquantconfig": 101, "_apply_static_qu": 101, "associ": 101, "identifi": [101, 114], "is_observed_linear": 101, "optimizedmodul": 101, "_orig_mod": 101, "0237": 101, "142": 101, "31": [101, 114], "113": 101, "157": 101, "59": 101, "160": 101, "150": 101, "67": 101, "241": 101, "238": 101, "235": 101, "228": 101, "255": [101, 114], "201": 101, "114": 101, "236": 101, "88": [101, 110], "83": 101, "109": 101, "209": 101, "92": 101, "184": 101, "141": 101, "110": 101, "0009": 101, "0010": 101, "130": 101, "122": 101, "132": 101, "125": 101, "126": 101, "129": 101, "127": [101, 103, 113, 114], "133": 101, "124": 101, "131": 101, "135": 101, "136": 101, "foundat": 103, "autograd": [103, 114], "interpos": 103, "namespac": 103, "continu": [103, 111, 112, 113, 114], "obviou": 103, "int8quantizedlinear": 103, "finer": 103, "intercept": 103, "contrast": 103, "clunki": 103, "distributedlinear": 103, "duplic": 103, "bypass": 103, "wrap": [103, 112, 113], "outer": 103, "inner": 103, "allgath": 103, "bandwidth": 103, "exactli": 103, "zoo": 103, "podcast": 103, "edward": 103, "yang": 103, "int8_symmetric_quant": 103, "fp32_tensor": 103, "amin": 103, "keepdim": [103, 110, 111], "amax": 103, "zeros_lik": 103, "view": [103, 110, 111], "clamp": [103, 110], "w_int8": 103, "new_linear": 103, "left": [103, 114], "toymodel": 103, "child": 103, "named_children": 103, "drawback": 103, "won": 103, "suppos": 103, "clean": 103, "eleg": 103, "pretti": 103, "power": [103, 105], "overrid": 103, "almost": 103, "shard": [103, 105], "ragged": 103, "rag": 103, "nestedtensor": 103, "who": 103, "link": [103, 108], "why": [103, 108], "googl": 103, "collab": 103, "flopcount": 103, "memorytrack": 103, "bare": 103, "bone": 103, "int8symmetrictensor": 103, "hold": [103, 104], "staticmethod": 103, "_make_wrapper_subclass": [103, 105], "storage_offset": 103, "ndim": 103, "extra_metadata": 103, "outer_s": [103, 105], "outer_strid": [103, 105], "undo": 103, "repr": 103, "ahead": 103, "insid": 103, "int8_tensor": 103, "op_implementations_dict": 103, "conveni": 103, "register_op": 103, "_op": 103, "opoverload": 103, "impl_decor": 103, "op_impl": 103, "done": 103, "particular": 103, "largest": 103, "tell": 103, "desugar": 103, "surfac": 103, "coverag": [103, 109, 110, 112, 113], "brute": 103, "forc": 103, "repeatedli": 103, "log": 103, "loggingtensor": 103, "_python_dispatch": [103, 105], "return_and_correct_alias": [103, 105], "int8_mm": 103, "int8_view_op": 103, "out_data": 103, "out_scal": [103, 110], "notic": 103, "hit": 103, "background": 103, "decomposit": 103, "live": 103, "decomp": 103, "shrink": 103, "author": [103, 108, 109, 110, 111, 112, 113, 114], "But": [103, 105, 114], "pain": 103, "rather": 103, "worth": 103, "written": 103, "differenti": 103, "nuanc": 103, "longer": [103, 110, 111], "had": [103, 110], "That": 103, "transposit": 103, "got": [103, 110, 114], "propag": [103, 110, 112, 113], "fact": 103, "themselv": [103, 110], "pointwis": [103, 112, 113], "were": 103, "might": [103, 105, 110, 114], "unwrap": 103, "dim0": 103, "dim1": 103, "confirm": 103, "quantized_model_module_swap": 103, "quantized_model_subclass": 103, "subclass_param": 103, "out_module_swap": 103, "allclos": 103, "out_compil": 103, "seri": 103, "discuss": 103, "float8dynamicactivationint4weightconfig": 104, "torch_dtyp": 104, "fluxpipelin": 104, "fluxtransformer2dmodel": 104, "black": 104, "forest": 104, "lab": 104, "flux": 104, "dev": 104, "subfold": 104, "cat": [104, 114], "sign": [104, 113], "world": [104, 105], "num_inference_step": 104, "guidance_scal": 104, "png": 104, "temporarydirectori": 104, "tmp_dir": 104, "uncom": 104, "usernam": [104, 105], "statu": [104, 105], "due": [104, 105, 109, 114], "int4wo": 104, "workaround": [104, 105], "team": [104, 105], "retain": 104, "thoroughli": 104, "e2": 105, "_type": 105, "_data": 105, "capabl": [105, 110, 112], "self_attn": 105, "q_proj": 105, "k_proj": 105, "mlp": 105, "gate_proj": 105, "narrow": 105, "chunk": 105, "heavi": 105, "codebas": 105, "fn": 105, "ctx": 105, "new_tensor": 105, "__class__": 105, "principl": 105, "mynewquantconfig": 105, "classvar": 105, "myquantizedtensor": 105, "tensor_data_attr": 105, "tensor_attribut": 105, "attr": 105, "fill_default": 105, "notimplementederror": 105, "_my_quant_transform": 105, "my_quantization_funct": 105, "use_cutlass_kernel": 105, "my_cutlass_linear": 105, "use_triton_kernel": 105, "my_triton_linear": 105, "disappear": 105, "unless": 105, "extrem": 105, "sole": 105, "explicitli": [105, 114], "spooki": 105, "distanc": 105, "2338": 105, "detect": 105, "illustr": 105, "tutorials_python": 106, "zip": [106, 108], "jupyt": [106, 108], "notebook": [106, 108], "tutorials_jupyt": 106, "sphinx": [106, 108], "firstnam": 108, "lastnam": 108, "prerequisit": [108, 110], "topic": 108, "rand": [108, 110, 111], "6182": 108, "1716": 108, "9053": 108, "5090": 108, "6990": 108, "6738": 108, "8353": 108, "0871": 108, "8555": 108, "0674": 108, "0573": 108, "0353": 108, "3694": 108, "9370": 108, "6976": 108, "practic": 108, "summar": 108, "takeawai": 108, "link1": 108, "link2": 108, "minut": 108, "ipynb": 108, "daniil": 109, "lyakhov": 109, "aamir": 109, "nazir": 109, "alexand": 109, "suslov": 109, "yamini": 109, "nimmagadda": 109, "kozlov": 109, "subject": [109, 111], "openvinoquant": 109, "unlock": 109, "placement": 109, "ux": [109, 110, 112], "torchdynamo": [109, 112, 113, 114], "eager": [109, 110, 111, 112, 113, 114], "mechan": [109, 112, 113], "torchvis": [109, 110, 111, 112, 113, 114], "resnet18": [109, 110, 111, 112, 113], "u": 109, "__dict__": [109, 110, 111, 112, 113], "dummi": [109, 112, 113], "traced_b": [109, 112, 113], "exported_model": [109, 110, 111, 112, 113], "preset": 109, "elu": 109, "prelu": 109, "gelu": 109, "quantizationpreset": 109, "bert": [109, 112], "modeltyp": 109, "ignored_scop": 109, "exclud": 109, "layer_1": 109, "layer_2": 109, "layer_3": 109, "ignoredscop": 109, "conv2d": [109, 110, 111, 112, 113, 114], "regex": 109, "layer_": 109, "subgraph": [109, 111], "node": [109, 111, 112, 113, 114], "target_devic": 109, "taken": 109, "account": 109, "cpu_spr": 109, "npu": 109, "targetdevic": 109, "fold": [109, 110, 112, 113], "batchnorm": [109, 110, 111, 112, 113], "preced": [109, 110, 112, 113], "prepared_model": [109, 110, 111, 112, 113], "fold_quant": 109, "finish": [109, 112], "comparison": 109, "smoothquant": 109, "biascorrect": 109, "discrep": 109, "calibration_load": 109, "dataload": [109, 110, 111], "transform_fn": 109, "data_item": 109, "calibration_dataset": 109, "smooth_quant": 109, "fast_bias_correct": 109, "deploy": [109, 112], "jerri": [110, 112, 114], "zhang": [110, 112, 113, 114], "_export": [110, 111], "fx": [110, 114], "14k": 110, "programm": [110, 112, 113], "db": 110, "xnnpack": [110, 111, 114], "xnnpack_quant": [110, 111], "get_symmetric_quantization_config": [110, 111], "xnnpackquant": [110, 111, 114], "prior": 110, "qconfigmap": [110, 114], "backendconfig": [110, 114], "rel": 110, "intent": [110, 114], "qconfig": [110, 114], "3d": [110, 114], "incompat": 110, "great": 110, "ideal": 110, "fake_qu": 110, "hidden": 110, "summari": 110, "address": 110, "thu": 110, "queri": [110, 114], "becom": 110, "previous": 110, "embedding_byt": 110, "executorchquant": 110, "concaten": 110, "prone": 110, "cleaner": 110, "composed_quant": 110, "quantization_cap": 110, "concern": 110, "decoupl": 110, "minmax": 110, "freed": 110, "identitc": 110, "imagenet": [110, 111], "unzip": [110, 111], "data_path": [110, 111], "renam": [110, 111], "resnet18_pretrained_float": [110, 111], "sy": [110, 111], "numpi": [110, 111], "np": [110, 111], "resnet": [110, 111, 112], "warn": [110, 111], "filterwarn": [110, 111], "categori": [110, 111], "deprecationwarn": [110, 111], "r": [110, 111], "seed": [110, 111], "191009": [110, 111], "averagemet": [110, 111], "fmt": [110, 111], "val": [110, 111], "avg": [110, 111], "count": [110, 111], "__str__": [110, 111], "fmtstr": [110, 111], "topk": [110, 111], "predict": [110, 111], "maxk": [110, 111], "pred": [110, 111], "eq": [110, 111], "expand_a": [110, 111], "correct_k": [110, 111], "mul_": [110, 111], "criterion": [110, 111], "top1": [110, 111], "top5": [110, 111], "cnt": [110, 111], "acc1": [110, 111], "acc5": [110, 111], "load_model": [110, 111], "model_fil": [110, 111], "weights_onli": [110, 111], "print_size_of_model": [110, 111], "temp": [110, 111], "p": [110, 111], "1e6": [110, 111], "prepare_data_load": [110, 111], "485": [110, 111], "456": [110, 111], "std": [110, 111], "229": [110, 111], "225": [110, 111], "randomresizedcrop": [110, 111], "randomhorizontalflip": [110, 111], "totensor": [110, 111], "dataset_test": [110, 111], "resiz": [110, 111], "centercrop": [110, 111], "train_sampl": [110, 111], "randomsampl": [110, 111], "test_sampl": [110, 111], "sequentialsampl": [110, 111], "train_batch_s": [110, 111], "sampler": [110, 111], "data_loader_test": [110, 111, 112, 113], "eval_batch_s": [110, 111], "saved_model_dir": [110, 111], "float_model_fil": [110, 111], "model_to_quant": [110, 111], "capture_pre_autograd_graph": [110, 111], "dynamic_shap": [110, 111], "dynamic_dim": [110, 111], "constraint": [110, 111, 114], "qconfig_opt": 110, "set_object_typ": 110, "set_module_nam": 110, "workload": 110, "themodel": 110, "feedback": 110, "dq": 110, "fp32_op": 110, "qauntiz": 110, "x_int8": 110, "x_zero_point": 110, "weight_int8": 110, "bias_fp32": 110, "output_scal": 110, "output_zero_point": 110, "x_fp32": 110, "quantized_decompos": 110, "dequantize_per_tensor": 110, "x_i8": 110, "x_quant_min": 110, "x_quant_max": 110, "weight_fp32": 110, "weight_i8": 110, "weight_quant_min": 110, "weight_quant_max": 110, "weight_permut": 110, "permute_copi": 110, "out_fp32": 110, "addmm": 110, "out_i8": 110, "quantize_per_tensor": 110, "out_zero_point": 110, "out_quant_min": 110, "out_quant_max": 110, "float32_op": 110, "decompos": 110, "use_reference_represent": 110, "x_int16": 110, "weight_int16": 110, "acc_int32": 110, "out_dtyp": 110, "bias_scal": 110, "bias_int32": 110, "div": 110, "mul": 110, "out_int8": 110, "qmin": 110, "qmax": 110, "date": 110, "unus": 110, "serila": 110, "consult": 110, "exportedprogram": 110, "pt2e_quantized_model_file_path": 110, "resnet18_pt2e_quant": 110, "quantized_ep": 110, "loaded_quantized_ep": 110, "loaded_quantized_model": 110, "diff": 110, "79": 110, "82": 110, "55": 110, "edg": [110, 114], "went": 110, "andrew": 111, "Or": 111, "move_exported_model_to_ev": [111, 112], "correctli": 111, "certain": 111, "dropout": 111, "move_exported_model_to_train": 111, "jit": 111, "recursivescriptmodul": 111, "train_one_epoch": 111, "ntrain_batch": 111, "avgloss": 111, "5f": 111, "start_tim": 111, "global_avg": 111, "is_qat": [111, 112], "fusion": 111, "batchnorm2d": 111, "_native_batch_norm_legit": 111, "cudnn_batch_norm": 111, "mobilenetv2": 111, "manual": 111, "recompil": 111, "consolid": 111, "epoch": 111, "far": 111, "num_epoch": 111, "num_train_batch": 111, "num_eval_batch": 111, "num_observer_update_epoch": 111, "num_batch_norm_update_epoch": 111, "num_epochs_between_ev": 111, "nepoch": 111, "stat": 111, "subseq": 111, "disable_observ": 111, "bn": 111, "running_mean": 111, "running_var": 111, "new_arg": 111, "wish": 111, "prepared_model_copi": 111, "neval_batch": 111, "paus": 111, "resum": 111, "fail": [111, 114], "checkpoint_path": 111, "checkpoint_": 111, "behav": 111, "incorrectli": 111, "lesli": [112, 114], "fang": [112, 114], "weiwen": [112, 114], "xia": [112, 114], "jiong": [112, 114], "gong": [112, 114], "cnn": 112, "rnn": 112, "outstand": 112, "fourth": 112, "spr": 112, "xeon": 112, "processor": 112, "boost": 112, "channels_last": [112, 113], "onednn": [112, 113], "assum": [112, 114], "word": 112, "satur": 112, "pure": 112, "dedic": 112, "scenario": [112, 113], "plai": [112, 113], "convolut": [112, 113, 114], "absenc": [112, 113], "enhanc": [112, 113], "mirror": [112, 113], "autocast": [112, 113], "device_typ": [112, 113], "turn": [112, 113], "cpp": 112, "qconvolut": [112, 113], "qlinear": [112, 113], "presenc": [112, 113], "pair": [112, 113], "remain": [112, 113], "conting": [112, 113], "qmaxpool2d": [112, 113], "torchinductor_freez": [112, 113], "example_x86inductorquantizer_pytorch_2_1": 112, "torchbench": 112, "measur": 112, "proven": 112, "depth": 112, "example_x86inductorquantizer_qat": 112, "yan": 113, "zhiwei": 113, "wang": 113, "eikan": 113, "liangang": 113, "liu": 113, "river": 113, "cui": 113, "yifeng": 113, "xpuinductorquant": 113, "pip3": 113, "torchaudio": 113, "xpu_inductor_quantizer_exampl": 113, "xpu_inductor_quant": 113, "xpuiq": 113, "resnet18_weight": 113, "get_default_xpu_inductor_quantization_config": 113, "wherea": 113, "histogramobserv": [113, 114], "perchannelminmaxobserv": 113, "quantizationspec": [113, 114], "quantizationconfig": [113, 114], "type_check": 113, "observerorfakequantizeconstructor": 113, "get_xpu_inductor_symm_quantization_config": 113, "extra_arg": 113, "act_observer_or_fake_quant_ctr": 113, "act_quantization_spec": [113, 114], "qscheme": [113, 114], "per_tensor_symmetr": [113, 114], "observer_or_fake_quant_ctr": [113, 114], "with_arg": [113, 114], "weight_observer_or_fake_quant_ctr": 113, "weight_quantization_spec": [113, 114], "per_channel_symmetr": 113, "ch_axi": 113, "oc": 113, "ic": 113, "kh": 113, "kw": 113, "conv": [113, 114], "bias_quantization_spec": 113, "amp": 113, "indcutor": 113, "kimish": 114, "patel": 114, "made": 114, "explicit": 114, "quantiat": 114, "encod": 114, "convei": 114, "quantizationannot": 114, "furthermor": 114, "minmaxobserv": 114, "input_qspec_map": 114, "output_qspec": 114, "_annot": 114, "conclud": 114, "matcher": 114, "get_source_partit": 114, "add_partit": 114, "gm": 114, "itertool": 114, "chain": 114, "add_nod": 114, "output_nod": 114, "per_tensor_affin": 114, "input_act_qspec": 114, "output_act_qspec": 114, "input_act0": 114, "input_act1": 114, "quantization_annot": 114, "substitut": 114, "among": 114, "sharedquantizationspec": 114, "maxpool": 114, "average_pool": 114, "concat": 114, "whose": 114, "edgeornod": 114, "transit": 114, "spec": 114, "conv1": 114, "conv2": 114, "fed": 114, "conv1_out": 114, "conv2_out": 114, "qspec1": 114, "cat_input0": 114, "cat_input1": 114, "therefor": 114, "ob": 114, "consum": 114, "rewrit": 114, "share_qparams_with_input_act0_qspec": 114, "known": 114, "beforehand": 114, "sigmoid": 114, "fixedqparamsquantizationspec": 114, "act_qspec": 114, "sigmoid_nod": 114, "input_act": 114, "derivedquantizationspec": 114, "derive_qparams_fn": 114, "observerorfakequant": 114, "observerbas": 114, "fakequantizebas": 114, "heurist": 114, "obejct": 114, "obs_or_fq": 114, "fq": 114, "act_obs_or_fq": 114, "weight_obs_or_fq": 114, "act_zp": 114, "weight_zp": 114, "bias_qspec": 114, "derived_from": 114, "backendquant": 114, "get_input_act_qspec": 114, "get_output_act_qspec": 114, "get_weight_qspec": 114, "get_bias_qspec": 114, "intermedi": 114, "straightforward": 114, "call_funct": 114, "relu_": 114, "relu_nod": 114, "maybe_conv_nod": 114, "conv1d": 114, "unexpect": 114, "recognz": 114, "subgraphmatch": 114, "conv_relu_pattern": 114, "name_node_map": 114, "input_nod": 114, "weight_nod": 114, "bias_nod": 114, "caveat": 114, "exhaust": 114, "2d": 114, "4d": 114, "v": 114, "symbol": 114, "outcom": 114}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "MarlinSparseLayout"], [19, 0, 1, "", "NF4Tensor"], [20, 0, 1, "", "PlainLayout"], [21, 0, 1, "", "SemiSparseLayout"], [22, 0, 1, "", "TensorCoreTiledLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinSparseLayout": [[18, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[19, 1, 1, "", "convert_to_norm_float_weight"], [19, 1, 1, "", "dequantize"], [19, 1, 1, "", "dequantize_scalers"], [19, 1, 1, "", "double_quantize_scalers"], [19, 1, 1, "", "get_original_weight"], [19, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingGranularity"], [33, 0, 1, "", "ScalingType"], [34, 2, 1, "", "convert_to_float8_training"], [35, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[36, 0, 1, "", "BlockSparseLayout"], [37, 0, 1, "", "CutlassInt4PackedLayout"], [38, 0, 1, "", "Int8DynamicActInt4WeightCPULayout"], [39, 0, 1, "", "MarlinQQQLayout"], [40, 0, 1, "", "MarlinQQQTensor"], [41, 0, 1, "", "UintxLayout"]], "torchao.prototype.dtypes.MarlinQQQTensor": [[40, 1, 1, "", "dequantize"], [40, 1, 1, "", "from_hp_to_intx"]], "torchao.quantization": [[42, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [43, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [44, 0, 1, "", "Float8WeightOnlyConfig"], [45, 0, 1, "", "Int4WeightOnlyConfig"], [46, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [47, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [48, 0, 1, "", "Int8WeightOnlyConfig"], [49, 0, 1, "", "MappingType"], [50, 0, 1, "", "TorchAODType"], [51, 2, 1, "", "choose_qparams_affine"], [52, 2, 1, "", "choose_qparams_affine_with_min_max"], [53, 2, 1, "", "dequantize_affine"], [54, 2, 1, "", "int_scaled_matmul"], [79, 2, 1, "", "quantize_"], [84, 2, 1, "", "quantize_affine"], [85, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[55, 0, 1, "", "ComposableQATQuantizer"], [56, 0, 1, "", "FakeQuantizeConfigBase"], [57, 0, 1, "", "FakeQuantizedEmbedding"], [58, 0, 1, "", "FakeQuantizedLinear"], [59, 0, 1, "", "FakeQuantizerBase"], [60, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [61, 0, 1, "", "Float8FakeQuantizeConfig"], [62, 0, 1, "", "Float8FakeQuantizer"], [63, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [64, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [65, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [66, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [67, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [68, 0, 1, "", "IntxFakeQuantizeConfig"], [69, 0, 1, "", "IntxFakeQuantizer"], [70, 0, 1, "", "QATConfig"], [71, 0, 1, "", "QATStep"], [74, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[57, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[58, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[60, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[62, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[64, 1, 1, "", "convert"], [64, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[68, 3, 1, "", "group_size"], [68, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[69, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[72, 0, 1, "", "Int4WeightOnlyEmbedding"], [73, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[72, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[75, 0, 1, "", "Int4WeightOnlyQATLinear"], [76, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [77, 2, 1, "", "disable_linear_fake_quant"], [78, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[80, 0, 1, "", "KernelPreference"], [81, 0, 1, "", "PackingFormat"], [82, 0, 1, "", "QuantizeTensorKwargs"], [83, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[80, 4, 1, "", "AUTO"], [80, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[81, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[86, 0, 1, "", "PerChannelNormObserver"], [87, 0, 1, "", "WandaSparsifier"], [88, 2, 1, "", "apply_fake_sparsity"], [89, 4, 1, "", "semi_sparse_weight"], [90, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[86, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[87, 1, 1, "", "prepare"], [87, 1, 1, "", "squash_mask"], [87, 1, 1, "", "update_mask"]], "torchao.utils": [[91, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[91, 1, 1, "", "get_tensor_impl_constructor"], [91, 1, 1, "", "implements"], [91, 1, 1, "", "implements_torch_function"], [91, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 92, 94, 95, 105], "dtype": [0, 11, 95], "layout": [0, 17], "tensor": [0, 7, 10, 95, 102, 103, 105, 114], "subclass": [0, 7, 10, 95, 103, 105], "quantiz": [0, 4, 5, 7, 12, 79, 92, 95, 96, 98, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 94, 95], "main": [1, 4, 5], "train": [1, 12, 94, 95, 98, 109, 110, 111, 112, 113], "api": [1, 2, 4, 5, 7, 8, 12, 92, 94, 114], "other": [1, 10, 95], "type": [1, 104], "refer": [2, 92], "python": 2, "kernel": [3, 10, 93, 95, 105], "qat": [4, 12, 111], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 98], "primit": [5, 95], "sparsiti": [6, 100], "util": 7, "common": [7, 8, 114], "benchmark": [8, 9, 10, 98], "guid": [8, 9, 10, 96, 105], "add": [8, 105], "an": [8, 97], "recip": [8, 94], "model": [8, 10, 94, 95, 97, 98, 104, 105, 109, 110, 111], "design": [8, 100], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 94, 98, 104, 105, 109, 112, 113, 114], "modifi": 8, "exist": 8, "configur": [8, 100, 105, 110, 111], "2": [8, 12, 96, 98, 104, 105, 109, 110, 111, 112, 113, 114], "run": 8, "3": [8, 12, 98, 105, 109, 112, 113, 114], "output": [8, 103], "format": [8, 95], "4": [8, 109, 114], "integr": [8, 12, 104, 105], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 105], "new": [10, 105], "effici": [10, 95], "triton": 10, "hand": 10, "written": 10, "us": [10, 114], "kernelprefer": [10, 80], "flow": [10, 95, 97, 105, 114], "torch": [10, 109, 110, 111], "compil": [10, 105, 109], "perform": [10, 93, 98, 110], "serial": [10, 97, 105], "featur": 10, "support": [10, 104, 105], "function": [10, 110, 111], "compos": 10, "microbenchmark": 10, "eval": [10, 110], "part": [12, 94, 98], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 95, 111, 112], "option": [12, 98, 108, 109], "torchtun": 12, "axolotl": 12, "low": [12, 95], "rank": 12, "adapt": 12, "huggingfac": [12, 98, 105], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "marlinsparselayout": 18, "nf4tensor": 19, "plainlayout": 20, "semisparselayout": 21, "tensorcoretiledlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalinggranular": 32, "scalingtyp": 33, "convert_to_float8_train": 34, "precompute_float8_dynamic_scale_for_fsdp": 35, "blocksparselayout": 36, "cutlassint4packedlayout": 37, "int8dynamicactint4weightcpulayout": 38, "marlinqqqlayout": 39, "marlinqqqtensor": 40, "uintxlayout": 41, "float8dynamicactivationfloat8weightconfig": 42, "float8dynamicactivationint4weightconfig": 43, "float8weightonlyconfig": 44, "int4weightonlyconfig": 45, "int8dynamicactivationint4weightconfig": 46, "int8dynamicactivationint8weightconfig": 47, "int8weightonlyconfig": 48, "mappingtyp": 49, "torchaodtyp": 50, "choose_qparams_affin": 51, "choose_qparams_affine_with_min_max": 52, "dequantize_affin": 53, "int_scaled_matmul": 54, "composableqatquant": 55, "fakequantizeconfigbas": 56, "fakequantizedembed": 57, "fakequantizedlinear": 58, "fakequantizerbas": 59, "float8actint4weightqatquant": 60, "float8fakequantizeconfig": 61, "float8fakequant": 62, "fromintxquantizationawaretrainingconfig": 63, "int4weightonlyembeddingqatquant": 64, "int4weightonlyqatquant": 65, "int8dynactint4weightqatquant": 66, "intxquantizationawaretrainingconfig": 67, "intxfakequantizeconfig": 68, "intxfakequant": 69, "qatconfig": 70, "qatstep": 71, "int4weightonlyembed": 72, "int4weightonlyqatembed": 73, "initialize_fake_quant": 74, "int4weightonlyqatlinear": 75, "int8dynactint4weightqatlinear": 76, "disable_linear_fake_qu": 77, "enable_linear_fake_qu": 78, "packingformat": 81, "quantizetensorkwarg": 82, "_choose_quant_func_and_quantize_tensor": 83, "quantize_affin": 84, "safe_int_mm": 85, "perchannelnormobserv": 86, "wandasparsifi": 87, "apply_fake_spars": 88, "semi_sparse_weight": 89, "sparsifi": 90, "torchaobasetensor": 91, "welcom": 92, "document": 92, "get": 92, "start": [92, 96, 104], "develop": 92, "note": [92, 94, 114], "eager": 92, "tutori": [92, 108], "pt2e": [92, 114], "pre": 94, "torchtitan": 94, "prerequisit": [94, 109, 112, 113, 114], "rowwis": 94, "scale": 94, "tensorwis": 94, "pick": 94, "import": [94, 110, 111], "directli": [94, 114], "convers": 94, "overview": [95, 100, 108], "basic": 95, "op": 95, "deriv": [95, 114], "pack": 95, "algorithm": 95, "weight": [95, 98], "onli": 95, "dynam": 95, "activ": 95, "static": [95, 101], "bit": 95, "optim": [95, 97, 98], "case": 95, "studi": 95, "how": [95, 110, 111, 114], "work": 95, "dure": 95, "execut": 95, "save": [95, 104, 110, 111], "load": [95, 110, 111], "quick": [96, 104], "first": 96, "exampl": [96, 104, 105, 114], "pytorch": [96, 109, 110, 111, 112, 113, 114], "export": [96, 98, 109, 110, 111, 112, 113, 114], "next": [96, 103], "step": [96, 98, 103, 105, 108], "deseri": 97, "what": [97, 103], "happen": 97, "when": 97, "serv": [98, 105], "vllm": [98, 105], "sglang": 98, "executorch": 98, "post": [98, 109, 110, 112, 113], "transform": [98, 104, 105], "mobil": 98, "deploy": 98, "unti": 98, "embed": 98, "creat": [98, 105], "characterist": 98, "evalu": [98, 110], "qualiti": 98, "assess": 98, "memori": 98, "latenc": 98, "result": 98, "h100": 98, "machin": 98, "conclus": [98, 108, 109, 110, 111, 112, 113, 114], "comput": [99, 107], "time": [99, 107], "goal": 100, "context": 100, "prune": 100, "criteria": 100, "strategi": 100, "pattern": [100, 114], "calibr": [101, 110], "phase": 101, "write": [102, 103, 114], "your": [102, 103, 105], "own": [102, 103], "advanc": 102, "ar": 103, "modul": 103, "swap": 103, "which": 103, "oper": [103, 105, 114], "should": 103, "we": 103, "implement": [103, 105], "compar": 103, "hug": 104, "face": 104, "usag": [104, 105], "diffus": 104, "architectur": 105, "system": 105, "class": 105, "fqn": 105, "method": 105, "minim": 105, "requir": 105, "compat": 105, "why": 105, "regist": 105, "s": 105, "kei": 105, "detail": 105, "hardwar": 105, "specif": [105, 110, 111], "linear": 105, "benefit": 105, "trade": 105, "off": 105, "share": [105, 114], "safetensor": 105, "diagram": 105, "high": 105, "level": 105, "point": 105, "dispatch": 105, "bring": 105, "extern": 105, "templat": 108, "addit": 108, "exercis": 108, "further": 108, "read": 108, "openvino": 109, "backend": [109, 110, 111, 112, 113], "introduct": [109, 112, 113, 114], "nncf": 109, "instal": 109, "captur": [109, 112, 113], "fx": [109, 112, 113], "graph": [109, 112, 113], "appli": [109, 112, 113], "lower": [109, 110, 112, 113], "represent": 109, "improv": 109, "metric": 109, "motiv": [110, 114], "defin": [110, 111], "helper": [110, 111], "prepar": [110, 111], "dataset": [110, 111], "set": 110, "mode": 110, "convert": [110, 111], "check": 110, "size": 110, "accuraci": 110, "debug": 110, "loop": 111, "checkpoint": 111, "x86": 112, "through": [112, 113], "inductor": [112, 113], "intel": 113, "gpu": 113, "annot": 114, "param": 114, "fix": 114, "paramet": 114, "5": 114, "A": 114, "toi": 114, "resnet18": 114, "ir": 114, "problem": 114, "match": 114, "aten": 114, "recommend": 114, "subgraphmatcherwithnamenodemap": 114}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})