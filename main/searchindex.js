Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.float8_dynamic_activation_float8_weight", "generated/torchao.quantization.float8_static_activation_float8_weight", "generated/torchao.quantization.float8_weight_only", "generated/torchao.quantization.fpx_weight_only", "generated/torchao.quantization.gemlite_uintx_weight_only", "generated/torchao.quantization.int4_weight_only", "generated/torchao.quantization.int8_dynamic_activation_int4_weight", "generated/torchao.quantization.int8_dynamic_activation_int8_weight", "generated/torchao.quantization.int8_weight_only", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.intx_quantization_aware_training", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.quantization.uintx_weight_only", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "subclass_advanced", "subclass_basic", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.float8_dynamic_activation_float8_weight.rst", "generated/torchao.quantization.float8_static_activation_float8_weight.rst", "generated/torchao.quantization.float8_weight_only.rst", "generated/torchao.quantization.fpx_weight_only.rst", "generated/torchao.quantization.gemlite_uintx_weight_only.rst", "generated/torchao.quantization.int4_weight_only.rst", "generated/torchao.quantization.int8_dynamic_activation_int4_weight.rst", "generated/torchao.quantization.int8_dynamic_activation_int8_weight.rst", "generated/torchao.quantization.int8_weight_only.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.intx_quantization_aware_training.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.quantization.uintx_weight_only.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "subclass_advanced.rst", "subclass_basic.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MappingType", "TorchAODType", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "float8_dynamic_activation_float8_weight", "float8_static_activation_float8_weight", "float8_weight_only", "fpx_weight_only", "gemlite_uintx_weight_only", "int4_weight_only", "int8_dynamic_activation_int4_weight", "int8_dynamic_activation_int8_weight", "int8_weight_only", "int_scaled_matmul", "intx_quantization_aware_training", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "uintx_weight_only", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "int8_dynamic_activation_int8_semi_sparse_weight", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Pretraining with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [2, 6, 8, 17, 18, 19, 20, 22, 34, 35, 38, 39, 41, 43, 45, 46, 58, 59, 66, 67, 68, 71, 74, 75, 76, 77, 79, 81, 84], "section": [2, 6, 75, 79], "introduc": 2, "dive": 2, "detail": [2, 6, 38, 74, 75, 76, 79, 81], "how": [2, 6, 8, 14, 22, 35, 39, 59, 74, 76, 77, 79, 81], "integr": [2, 6, 74, 77, 79, 81], "pytorch": [2, 6, 8, 13, 16, 36, 72, 74, 76, 79, 81, 84], "optim": [2, 6, 17, 34, 38, 42, 58, 72, 74, 79, 81], "your": [2, 6, 72, 74, 75, 76, 79], "machin": 2, "learn": [2, 76, 79, 84], "model": [2, 34, 38, 58, 62, 63, 67, 68, 71, 76, 79, 81], "dtype": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 38, 39, 41, 42, 43, 44, 45, 46, 59, 71, 72, 74, 76, 77, 81], "quantiz": [2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 26, 28, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 69, 71, 72, 74, 77, 79], "sparsiti": [2, 11, 17, 20, 66, 67, 68, 69, 70, 71, 72, 75, 77], "tba": [3, 7, 73], "For": [6, 8, 75, 76, 77, 79, 81], "new": [6, 8, 74, 75, 81], "case": [6, 38, 61, 79, 81], "exampl": [6, 8, 34, 35, 38, 58, 67, 71, 75, 77, 78, 79, 81, 82, 83, 84], "train": [6, 31, 45, 46, 72, 74, 79, 81], "like": [6, 14, 38, 74, 75, 76, 77, 79, 81], "fp4": 6, "s": [6, 8, 35, 38, 39, 43, 45, 59, 60, 74, 75, 76, 79, 81], "fine": [6, 79], "start": [6, 32, 35, 36, 37, 38, 74, 75, 79, 81], "prototyp": [6, 75], "folder": 6, "you": [6, 67, 74, 75, 76, 77, 79, 81, 84], "could": [6, 75, 81], "also": [6, 38, 58, 75, 76, 77, 79, 81], "take": [6, 18, 58, 66, 71, 75, 79], "look": [6, 8, 74, 75, 79], "affinequantizedtensor": [6, 16, 24, 25, 27, 75, 76, 77, 81], "what": [6, 8, 16, 38, 74, 75, 76, 79, 84], "want": [6, 58, 71, 75, 77, 79, 81], "do": [6, 36, 38, 56, 58, 75, 79, 81], "mostli": [6, 41], "e": [6, 8, 35, 38, 39, 43, 45, 58, 59, 60, 74, 75, 77, 81], "g": [6, 8, 35, 38, 39, 43, 45, 58, 59, 75, 77, 81], "int3": 6, "exact": 6, "same": [6, 8, 39, 41, 43, 45, 46, 59, 61, 71, 74, 75, 79, 81], "affin": [6, 8, 10, 11, 12, 13, 17, 20, 21, 26, 43, 45, 59, 75], "pleas": [6, 8, 16, 72, 75, 79, 81], "feel": [6, 75, 79, 81], "free": [6, 75, 81], "open": [6, 75, 79], "an": [6, 8, 21, 26, 27, 38, 46, 67, 72, 75, 79, 81], "issu": [6, 75, 76, 81], "have": [6, 35, 38, 59, 67, 75, 79, 81], "question": [6, 75, 77, 79, 81], "specif": [6, 14, 17, 19, 20, 67, 75, 76, 77, 79], "more": [6, 8, 38, 46, 74, 75, 76, 79, 81], "refer": [6, 8, 74, 79, 81], "our": [6, 18, 74, 76, 79, 81], "overview": [6, 72, 76], "page": [6, 76], "To": [6, 8, 16, 38, 74, 75, 76, 77, 79], "contribut": [6, 76, 79], "exist": [6, 36, 74, 75, 79, 81], "code": [6, 74, 75, 76, 79, 81, 82, 84], "base": [6, 14, 19, 35, 67, 75, 76, 79, 81], "make": [6, 75, 81], "trainabl": [6, 75, 81], "add": [6, 19, 81, 84], "parallel": [6, 74, 81], "etc": [6, 75], "affine_quantized_tensor": [6, 77], "py": [6, 8, 16, 78, 83, 84], "api": [6, 38, 75, 76, 79, 81], "quant_api": [6, 58, 77], "primit": [6, 8, 16, 81], "op": [6, 8, 16, 38, 45, 46, 58, 79, 81], "slight": [6, 79], "variat": [6, 75], "quant_primit": [6, 8, 16], "autotun": [6, 76], "cpu": [6, 8, 13, 77, 79], "cuda": [6, 8, 42, 58, 74, 76, 77, 79, 81], "mp": 6, "csrc": 6, "mayb": [6, 30], "well": [6, 14, 38, 75, 79], "spars": [6, 9, 17, 20, 67, 75, 79], "marlin": [6, 15, 16, 17, 28], "aqt": 6, "621": 6, "we": [6, 8, 18, 35, 38, 39, 41, 43, 45, 58, 59, 71, 74, 75, 76, 77, 79], "ar": [6, 8, 12, 20, 22, 33, 38, 39, 43, 45, 58, 59, 61, 67, 74, 75, 76, 77, 79], "still": [6, 75, 79], "decid": [6, 75, 79], "split": 6, "can": [6, 21, 35, 38, 58, 59, 74, 75, 76, 77, 79, 81], "implement": [6, 31, 77, 79], "regist": [6, 66, 81], "mai": [6, 41, 75, 77], "need": [6, 66, 67, 75, 76, 77, 79, 81], "defin": [6, 14, 22, 66, 67, 79, 81], "own": [6, 72, 74, 79], "through": [6, 41, 75, 76, 81, 84], "int4": [6, 10, 13, 35, 58, 71, 76, 77], "access": 6, "my_custom_op": 6, "devic": [6, 8, 42, 58, 61, 74, 76, 77, 81], "check": [6, 8, 16, 75, 76, 77, 81], "condit": [6, 75], "__torch_function__": [6, 75, 81], "__torch_dispatch__": [6, 81], "target": [6, 39, 67, 79], "oper": [6, 8, 12, 14, 17, 41], "bfloat16": [6, 18, 45, 59, 74, 75, 76, 77, 79], "activ": [6, 38, 62, 67, 69, 72, 79], "uint4": [6, 75, 76], "weight": [6, 17, 18, 34, 38, 58, 67, 69, 71, 72, 74, 76, 77, 79, 81], "found": [6, 75, 76, 79, 81], "here": [6, 8, 59, 75, 77, 81], "allow": [6, 79, 81], "peopl": [6, 75, 77], "linear": [6, 17, 31, 33, 38, 58, 63, 68, 69, 71, 74, 75, 76, 77, 79, 81], "two": [6, 16, 20, 75, 79, 81], "dispatch_condit": [6, 75], "impl": [6, 8, 75], "actual": [6, 75, 81], "bia": [6, 75, 76, 77, 81], "run": [6, 34, 38, 58, 62, 66, 74, 75, 79, 81, 84], "both": [6, 8, 75, 79, 81], "input_tensor": [6, 18, 75], "weight_tensor": [6, 75], "argument": [6, 8, 21, 38, 43, 58, 74, 75], "register_aqt_quantized_linear_dispatch": 6, "show": [6, 59, 74, 75, 79], "work": [6, 20, 74, 77, 79, 81], "sometim": [6, 79], "ha": [6, 8, 75, 79, 81], "pack": [6, 8, 10, 21, 22, 75], "order": [6, 38, 75, 79, 81], "yield": [6, 79], "And": [6, 18, 75, 81], "abstract": [6, 75], "see": [6, 8, 16, 74, 75, 76, 77, 79, 81], "full": [6, 84], "after": [6, 34, 38, 75, 77, 79], "wrap": [6, 38, 81], "factori": 6, "convert": [6, 8, 16, 18, 23, 26, 28, 29, 31, 58, 60, 71, 74, 75, 79], "from": [6, 8, 18, 19, 24, 25, 27, 41, 45, 58, 59, 71, 74, 75, 76, 77, 78, 79, 81, 83, 84], "float": [6, 8, 16, 18, 26, 28, 29, 35, 37, 38, 39, 41, 42, 43, 45, 46, 59, 60, 63, 67, 75, 77, 81], "point": [6, 8, 16, 28, 35, 37, 43, 45, 60, 74, 75, 76, 77, 79, 81], "my": [6, 79], "to_my_dtyp": 6, "mydtypetensor": 6, "from_float": [6, 81], "level": [6, 67, 75, 79, 81], "reus": [6, 75, 81], "quantize_": [6, 58, 71, 75, 76, 77], "appli": [6, 8, 38, 58, 69, 71, 75, 76, 79], "convers": [6, 8, 33, 75], "filter": [6, 33, 38, 74], "choos": [6, 75, 79, 81], "which": [6, 16, 22, 38, 74, 75, 76, 77, 79], "modul": [6, 31, 32, 33, 34, 35, 36, 37, 38, 58, 62, 63, 66, 67, 71, 74, 76, 77], "should": [6, 8, 34, 43, 45, 66, 67, 74, 75, 79], "algorithm": [6, 79], "onli": [6, 13, 33, 71, 74, 76, 77, 79, 81], "dynam": [6, 30, 31, 34, 71, 81], "quant": [6, 8, 16, 75], "static": [6, 8, 14, 18, 24, 27, 31, 41], "type": [6, 8, 17, 18, 22, 31, 32, 33, 35, 36, 37, 38, 42, 56, 59, 61, 72, 75, 77, 79, 81], "note": [6, 46, 67, 75, 76, 79, 81], "2": [6, 8, 11, 13, 17, 20, 35, 38, 46, 59, 68, 69, 71, 74, 75, 76, 79, 81, 84], "4": [6, 11, 17, 20, 29, 42, 68, 69, 71, 75, 76, 77, 79, 81], "below": [6, 74, 75, 79, 81, 84], "follow": [6, 74, 75, 76, 79, 81], "util": [6, 74, 75, 76, 77, 81], "import": [6, 58, 71, 76, 77, 79, 81, 84], "unwrap_tensor_subclass": [6, 76], "m_unwrap": 6, "m": [6, 58, 60, 71, 74, 76, 77, 81], "In": [6, 74, 75, 76, 79, 81], "compat": [6, 17, 76], "aim": [6, 75, 79], "fullgraph": [6, 76], "true": [6, 8, 26, 31, 38, 39, 41, 42, 58, 62, 71, 74, 76, 77, 81], "first": [6, 18, 38, 56, 67, 75, 81], "remov": [6, 39, 67, 74, 79], "ani": [6, 19, 38, 64, 67, 75, 79, 81], "unnecessari": 6, "graph": 6, "break": 6, "torch_log": 6, "output_cod": 6, "when": [6, 8, 19, 39, 43, 45, 59, 74, 75, 79], "script": [6, 76, 81, 84], "inductor": [6, 38], "python": [6, 75, 79, 82, 84], "mode": [6, 38, 76], "max": [6, 35, 75, 76, 81], "checkout": [6, 8, 16, 72, 75], "doc": [6, 74, 75, 81], "huggingfac": 6, "transform": [6, 8, 75], "deseri": [6, 75], "save_pretrain": 6, "push_to_hub": 6, "from_pretrain": 6, "http": [6, 8, 16, 38, 67, 76, 79], "co": 6, "main": [6, 8, 16, 75, 76, 79, 81], "en": [6, 38], "anoth": [6, 75, 79, 81], "diffus": 6, "github": [6, 8, 16, 76], "com": [6, 8, 16], "sayakpaul": 6, "blob": [6, 8, 16], "infer": [6, 8, 62, 72, 75, 76, 77, 79, 81], "serialization_and_load": 6, "md": 6, "The": [6, 8, 9, 14, 17, 22, 33, 38, 56, 58, 61, 62, 63, 67, 74, 75, 76, 77, 79, 81], "abov": [6, 35, 75, 77, 79, 81], "just": [6, 35, 75, 77, 79, 81], "talk": [6, 75], "about": [6, 75, 76, 77, 79], "basic": [6, 19, 76, 81], "provid": [6, 14, 17, 20, 21, 38, 39, 74, 75, 79, 81], "fsdp": [6, 75], "ll": [6, 35, 74, 75, 81], "put": [6, 71], "developer_api_guid": 6, "cover": [6, 75, 84], "executorch": [6, 58], "torchchat": 6, "todo": [6, 75], "qat": [6, 45, 46], "suit": 6, "out": [6, 20, 35, 38, 67, 74, 75, 76, 79, 81], "differ": [6, 14, 41, 59, 61, 74, 75, 76, 77, 79, 81], "system": 6, "dtensor": [6, 81], "recommend": [6, 38, 74], "copi": [6, 8, 67, 76, 77, 79, 81], "past": [6, 79], "adapt": 6, "now": [6, 39, 74, 75, 76, 79, 81], "befor": [6, 58, 75, 77, 79, 81], "some": [6, 38, 58, 67, 75, 79, 81], "singl": [6, 30, 34, 38, 41, 74, 76, 79], "comput": [6, 17, 21, 34, 66, 67, 79, 81], "intens": 6, "memori": [6, 8, 46, 74, 76, 79, 81], "input": [6, 8, 17, 18, 20, 31, 33, 34, 38, 39, 41, 43, 45, 46, 56, 58, 59, 61, 67, 71, 74, 75, 81], "dimens": [6, 8, 22, 39, 43, 45, 56, 59, 74, 81], "get": [6, 18, 74, 75, 79], "sens": [6, 75, 81], "speedup": [6, 74, 75, 76, 79], "d": [6, 75], "creat": [6, 8, 24, 25, 27, 74, 75, 79, 81], "file": [6, 74, 78, 81, 83], "benchmark_aq": 6, "shape": [6, 8, 16, 38, 56, 61, 76, 81], "A": [6, 8, 22, 38, 41, 46, 66, 79, 81], "quick": [6, 72], "wai": [6, 8, 38, 74, 75, 79, 81], "relev": [6, 75, 84], "chang": [6, 58, 74, 75, 76, 77, 79, 81], "interest": [6, 75, 79, 81], "tutori": [6, 8, 74, 75, 78, 79, 81, 82, 83], "print_op_and_shap": 6, "output": [6, 31, 38, 39, 43, 45, 59, 74, 75, 79, 84], "torch_func": 6, "built": [6, 74, 81], "k": [6, 61, 76, 77, 81], "n": [6, 76, 77, 81], "10": [6, 35, 59, 74], "method": [6, 14, 17, 20, 21, 38, 58, 67, 79, 81], "_c": 6, "tensorbas": 6, "object": [6, 22, 58, 71, 81], "arg": [6, 8, 67, 81], "0": [6, 8, 38, 59, 63, 67, 74, 76, 77, 78, 79, 81, 83, 84], "size": [6, 8, 9, 16, 18, 39, 43, 45, 59, 74, 76, 77, 79, 81], "all": [6, 34, 35, 38, 41, 66, 67, 68, 75, 76, 77, 78, 79, 81, 82], "under": 6, "benchmark_your_kernel": 6, "helper": 6, "right": [6, 75, 79], "1": [6, 17, 22, 32, 35, 36, 37, 38, 42, 59, 67, 74, 75, 76, 77, 78, 79, 81, 83, 84], "either": [6, 8, 45, 67, 79], "one": [6, 38, 41, 66, 74, 75, 79, 81], "probabl": 6, "keep": [6, 17, 67], "futur": 6, "llama": 6, "llama2": 6, "llama3": [6, 74], "sam": 6, "alreadi": [6, 8, 38, 81], "modifi": [6, 33, 58, 67, 74, 75, 79, 81], "friendli": [6, 75], "compar": [6, 46, 67, 74, 75], "techniqu": [6, 77, 79, 81], "repres": [6, 8, 9, 12, 14, 25, 31, 59, 67, 75, 77, 81], "bound": [6, 79], "help": [6, 74, 75], "option": [6, 8, 12, 16, 23, 26, 27, 28, 30, 31, 33, 38, 39, 41, 43, 45, 46, 58, 59, 62, 63, 64, 67, 71, 74, 76], "each": [6, 18, 38, 62, 66, 75, 79, 81], "understand": [6, 74], "profil": 6, "profile_path": 6, "chrome": 6, "trace": [6, 75], "let": [6, 35, 59, 75, 76, 79, 81], "know": [6, 38, 81], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 35, 36, 37, 38, 66, 67, 75, 76, 77, 81], "torchao": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 79, 81], "tensor_impl": [8, 16, 75], "aqttensorimpl": [8, 16], "block_siz": [8, 14, 16, 18, 23, 24, 26, 27, 28, 29, 39, 41, 43, 45, 46, 59, 76], "tupl": [8, 16, 18, 23, 24, 26, 27, 28, 39, 41, 42, 43, 45, 46, 59, 67, 81], "int": [8, 9, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 39, 40, 41, 42, 43, 44, 45, 46, 58, 59, 60, 67, 76, 81], "quant_min": [8, 16, 26, 27, 28, 35, 39, 41, 43, 45, 46, 59, 75, 76, 81], "union": [8, 16, 31, 39, 43, 45, 46, 58, 59], "none": [8, 12, 16, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 58, 59, 62, 63, 64, 67, 71, 81], "quant_max": [8, 16, 26, 27, 28, 35, 39, 41, 43, 45, 46, 59, 75, 76, 81], "zero_point_domain": [8, 16, 26, 27, 28, 39, 41, 45, 46], "zeropointdomain": [8, 16, 26, 27, 28, 39, 41, 45, 46], "stride": [8, 16, 75, 81], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 56, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 71, 82, 84], "tensor": [8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 38, 39, 40, 41, 42, 43, 44, 45, 46, 56, 59, 60, 61, 64, 67, 72, 74, 76, 77, 79, 84], "subclass": [8, 16, 33, 38, 66, 71, 76, 77, 79], "mean": [8, 18, 35, 39, 43, 45, 59, 60, 74, 75, 76, 79], "quantized_tensor": 8, "float_tensor": [8, 81], "scale": [8, 14, 17, 24, 27, 34, 35, 37, 39, 41, 43, 44, 45, 46, 56, 59, 60, 62, 63, 75, 79, 81], "zero_point": [8, 14, 27, 37, 39, 41, 43, 45, 46, 59, 75, 79, 81], "happen": [8, 16, 38, 75, 81], "dure": [8, 16, 38, 43, 45, 63, 74, 79, 81], "choose_qparam": [8, 75], "dequant": [8, 16, 18, 43, 75, 81], "ao": [8, 16, 79], "three": [8, 38, 67, 71, 75], "choose_qparams_affin": [8, 41, 75], "quantize_affin": [8, 45, 46, 75], "qand": 8, "dequantize_affin": [8, 45, 46], "extern": 8, "regardless": 8, "intern": [8, 21], "represent": [8, 14, 25, 75, 79], "orient": 8, "field": 8, "serv": [8, 14, 81], "gener": [8, 45, 46, 75, 76, 79, 81, 82, 84], "storag": [8, 17, 75, 79], "data": [8, 9, 14, 17, 22, 41, 72, 75, 77, 79, 81], "store": [8, 17, 18, 22, 66, 75, 79], "plain": 8, "int_data": [8, 81], "format": [8, 17, 18, 60, 75, 79], "depend": [8, 38, 77, 79, 81], "kernel": [8, 10, 11, 13, 17, 21, 58, 76, 79], "granular": [8, 39, 43, 45, 59, 74, 75], "element": [8, 20, 22, 38, 39, 43, 45, 59, 79], "share": [8, 39, 43, 45, 59, 79], "qparam": [8, 39, 43, 45, 59], "us": [8, 12, 13, 14, 17, 18, 19, 22, 24, 27, 35, 38, 39, 41, 43, 45, 59, 67, 72, 74, 75, 76, 77, 79, 81], "per": [8, 39, 43, 45, 59, 67, 69, 74, 75, 76, 79], "torch": [8, 17, 18, 22, 24, 31, 33, 38, 39, 42, 43, 44, 45, 56, 58, 59, 61, 62, 63, 71, 74, 75, 76, 77, 79, 81, 84], "origin": [8, 18, 45, 59, 67, 75, 76, 77, 79], "high": [8, 23, 24, 25, 26, 27, 60, 74, 75, 79, 81], "precis": [8, 23, 24, 25, 26, 27, 60, 75, 81], "minimum": [8, 38, 39, 43, 45, 59], "valu": [8, 18, 31, 32, 35, 36, 37, 38, 39, 43, 45, 46, 59, 62, 67, 75, 79, 81], "specifi": [8, 31, 33, 45, 58, 59, 67, 71, 74, 79], "deriv": [8, 41, 45, 59], "maximum": [8, 39, 43, 45, 59, 62], "domain": [8, 37, 39, 43, 45], "integ": [8, 26, 27, 35, 37, 39, 43, 45, 56, 61], "zero": [8, 20, 39, 43, 45, 67, 79], "ad": [8, 43, 45, 67, 79, 81], "subtract": [8, 18, 45], "unquant": [8, 45], "default": [8, 9, 12, 19, 21, 22, 38, 39, 43, 45, 58, 62, 63, 74, 81], "float32": [8, 24, 43, 44, 45, 59, 60, 77, 79, 81], "given": [8, 16, 29, 74, 79], "return": [8, 16, 17, 18, 33, 38, 46, 56, 58, 61, 62, 63, 71, 74, 75, 76, 77, 81], "classmethod": [8, 16, 81], "from_hp_to_floatx": 8, "input_float": [8, 16, 23, 24, 25, 26, 27, 28, 64], "target_dtyp": [8, 23, 24, 26, 27, 30, 31, 39, 41, 75], "_layout": [8, 16, 23, 24, 25, 26, 27, 28, 75, 76], "layout": [8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 71, 79], "scale_dtyp": [8, 23, 24, 26, 39, 41], "float8": [8, 11, 12, 23, 24, 30, 31, 32, 33, 34, 72, 75], "from_hp_to_floatx_stat": 8, "paramet": [8, 14, 17, 18, 24, 27, 33, 34, 35, 38, 39, 43, 45, 56, 58, 59, 61, 62, 63, 67, 71, 74, 75, 77, 79, 81], "from_hp_to_fpx": 8, "floatx": [8, 25, 75], "ebit": [8, 25, 40, 44, 60], "mbit": [8, 25, 40, 44, 60], "support": [8, 25, 71, 74, 76, 77, 79, 81], "float1": [8, 25], "float7": [8, 25], "from_hp_to_intx": [8, 16], "mapping_typ": [8, 26, 39, 41], "mappingtyp": [8, 26, 39, 41], "ep": [8, 26, 39, 41], "zero_point_dtyp": [8, 26, 39, 41], "preserve_zero": [8, 26, 39, 41], "bool": [8, 26, 31, 33, 38, 39, 41, 42, 58, 62, 71], "plainlayout": [8, 26, 27], "use_hqq": [8, 26], "fals": [8, 26, 31, 38, 42, 62, 67, 74, 75, 76, 77, 81], "from_hp_to_intx_stat": 8, "kwarg": [8, 66, 67, 68, 81], "perform": [8, 21, 34, 38, 56, 61, 62, 66, 74, 76, 79, 81], "self": [8, 75, 76, 77, 81], "If": [8, 12, 33, 38, 56, 61, 62, 67, 75, 76, 79, 81], "correct": [8, 17], "otherwis": [8, 75], "desir": [8, 38, 45], "call": [8, 38, 45, 46, 66, 75, 76, 77, 79, 81], "non_block": 8, "memory_format": 8, "preserve_format": 8, "set": [8, 12, 38, 41, 58, 62, 67, 76, 79], "function": [8, 21, 33, 38, 42, 58, 66, 67, 68, 71, 74, 76, 77, 79, 81], "attempt": 8, "asynchron": 8, "respect": [8, 79], "host": 8, "possibl": [8, 79], "behavior": [8, 14], "pin": 8, "pageabl": 8, "howev": [8, 79], "caution": 8, "advis": [8, 75], "featur": [8, 81], "inform": [8, 79], "good": [8, 76, 81], "usag": [8, 34, 38, 74], "pin_memori": 8, "even": [8, 74, 79], "match": [8, 43, 56, 79], "other": [8, 14, 67, 74, 77, 79, 81, 84], "randn": [8, 74, 76, 77, 81], "initi": [8, 75, 77], "float64": 8, "5044": 8, "0005": 8, "3310": 8, "0584": 8, "cuda0": 8, "blocksiz": 9, "64": [9, 29, 42, 77, 81], "block": [9, 18, 67, 79], "matrix": [9, 12, 56, 61, 67, 76, 79], "variabl": [9, 12, 21, 22, 67, 79], "cutlass": [10, 11], "mm_config": 12, "float8mmconfig": 12, "configur": [12, 30, 31, 33, 58, 71, 74, 75, 76], "multipl": [12, 38, 56, 61, 76, 79, 81], "involv": [12, 79], "tinygemm": [13, 58, 75, 76], "_weight_int4pack_mm_for_cpu": 13, "version": [13, 74, 76, 81], "least": 13, "6": [13, 74, 75, 76, 79], "It": [14, 17, 19, 21, 34, 79, 81], "pre": [14, 17, 21, 76, 79], "process": [14, 17, 19, 21, 22, 38, 63, 75, 79, 84], "post": [14, 21, 81], "addit": [14, 19, 38, 46, 74, 79, 81], "design": [14, 17, 20], "extend": [14, 75, 79], "conjunct": 14, "tensorimpl": 14, "custom": [14, 66, 72, 74, 75, 76, 79, 81], "interact": [14, 75], "qqq": [15, 16, 28], "marlinqqq": 16, "inherit": [16, 19, 81], "choose_qparams_and_quantize_affine_qqq": 16, "dequantize_affine_qqq": 16, "handl": [17, 20, 21, 38, 75], "pattern": [17, 20, 75], "ensur": 17, "preprocess": [17, 20], "manag": 17, "pre_process": 17, "1\u00ba": 17, "transpos": [17, 75, 81], "sinc": [17, 66, 75, 77, 79, 81], "layer": [17, 33, 38, 62, 63, 67, 68, 69, 74, 79, 81], "2\u00ba": 17, "inject": 17, "3\u00ba": 17, "again": [17, 18, 79], "becaus": [17, 74, 75, 77, 79, 81], "dim": [17, 81], "tensor_meta": 18, "subclasstensorarg": 18, "n_block": 18, "scaler_block_s": [18, 29], "quantized_scal": 18, "quantization_factor": 18, "scaler_mean": 18, "quantized_data": 18, "nf4": 18, "qlora": 18, "convert_to_norm_float_weight": 18, "normal": [18, 29, 38, 79], "dequantize_scal": 18, "unpack": [18, 60, 75], "doubl": 18, "scaler": 18, "int8": [18, 58, 69, 71, 75, 81], "per_scaler_block": 18, "factor": [18, 56, 63, 74, 79], "inpt_weight": 18, "double_quantize_scal": 18, "achiev": [18, 74, 79, 81], "calcul": [18, 34, 35, 39, 41, 62, 75, 79], "absmax": 18, "find": [18, 79], "posit": 18, "typic": [18, 19, 75, 77], "per_block": 18, "int16": 18, "n_scaler_block": 18, "get_original_weight": 18, "quantize_tensor_nearest": 18, "float16": [18, 42, 45, 59, 79], "nearest": 18, "round": [18, 35, 81], "up": [18, 58, 74, 75, 76, 79], "most": [19, 75, 79], "doe": [19, 75, 79, 81], "metadata": [19, 75, 81], "step": [19, 34, 38, 74, 75, 79], "requir": [19, 21, 74, 75, 79, 81], "semi": [20, 71, 79], "structur": [20, 71, 76, 77, 79, 81], "matric": [20, 79], "where": [20, 35, 41, 60, 75, 79], "everi": [20, 66, 79, 81], "four": 20, "prune": [20, 67], "conform": 20, "inner_k_til": [21, 76], "8": [21, 22, 35, 74, 75, 76], "core": [21, 36, 75], "tile": [21, 75], "fit": [21, 75, 77], "effici": [21, 76, 79], "affect": [21, 79], "matmul": [21, 75, 79, 81], "pack_dim": 22, "uintx": [22, 75], "smaller": [22, 76, 77], "bit": [22, 29, 60, 81], "width": 22, "than": [22, 74, 75, 79, 81], "standard": [22, 75], "byte": 22, "uintxtensor": 22, "determin": [22, 39, 45, 74, 79], "along": [22, 79], "indic": [22, 37, 79], "last": [22, 74], "256": 29, "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "tensorwis": [30, 31], "cast": [30, 45, 46], "cast_config_input": 31, "config": [31, 33, 38, 58, 67, 71, 79], "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "nn": [31, 33, 38, 58, 62, 63, 71, 74, 75, 76, 77, 79, 81], "from_recipe_nam": 31, "recipe_nam": [31, 74], "float8linearrecipenam": 31, "str": [31, 33, 42, 58, 63, 64, 67, 71, 74, 81], "string": [31, 67], "recip": [31, 66], "name": [32, 35, 36, 37, 58, 63, 67, 71, 79, 81], "qualnam": [32, 35, 36, 37], "boundari": [32, 35, 36, 37], "module_filter_fn": [33, 74], "callabl": [33, 38, 42, 58, 64, 71], "float8linearconfig": 33, "swap": [33, 74, 75, 79], "float8linear": [33, 74], "pass": [33, 38, 41, 66, 75, 81], "instanc": [33, 58, 66, 71, 77, 81], "fqn": [33, 67, 71, 74], "reduc": [34, 74, 79], "sum": 34, "backward": [34, 74, 79], "number": [35, 38, 60, 67, 79, 81], "map": [35, 75, 81], "symmetr": [35, 39, 69, 81], "rang": [35, 74, 79], "sai": [35, 59, 75], "3": [35, 38, 59, 74, 75, 76, 79, 84], "5": [35, 63, 67, 74, 76, 79, 84], "7": [35, 74], "symmetric_no_clipping_err": 35, "variant": [35, 41, 81], "smin": 35, "smax": 35, "min_val_neg": [35, 81], "max_val_po": [35, 81], "By": [35, 79], "individu": [35, 79], "less": [35, 79, 81], "error": [35, 38, 74, 81], "neg": 35, "asymmetr": [35, 39, 75, 76], "directli": [35, 41, 75, 79, 81], "placehold": 36, "yet": [36, 81], "enum": 37, "whether": [37, 38, 39, 81], "quantized_v": 37, "float_val": 37, "mid_point": 37, "example_input": [38, 76, 77], "qtensor_class_list": 38, "aqdefaultlinearweight": 38, "aqint8weightonlyquantizedlinearweight": 38, "aqint8weightonlyquantizedlinearweight2": 38, "aqint8dynamicallyquantizedlinearweight": 38, "filter_fn": [38, 58, 71], "interpol": 38, "85": 38, "manual": 38, "set_inductor_config": 38, "supress_autoquant_error": 38, "min_sqnr": 38, "aq_kwarg": 38, "autoquant": 38, "identifi": 38, "fastest": 38, "over": [38, 74, 79], "potenti": [38, 79], "qtensor": 38, "prepar": [38, 62, 67, 75, 79], "search": [38, 79], "whose": 38, "exchang": 38, "autoquantizablelinearweight": 38, "calibr": [38, 41], "user": [38, 74, 75, 76, 79, 81, 84], "seen": 38, "record": [38, 75], "so": [38, 74, 75, 76, 77, 79, 81], "final": [38, 46, 58, 75, 76, 79], "benchmark": [38, 62, 74], "member": 38, "pick": 38, "result": [38, 56, 60, 61, 75, 79], "highli": 38, "complet": 38, "simpli": [38, 79, 81], "had": [38, 81], "compil": [38, 58, 61, 74, 75, 76, 81], "them": [38, 66, 75], "onc": [38, 79], "proce": 38, "combin": [38, 79, 81], "finalize_autoqu": 38, "been": [38, 81], "log": [38, 81], "forward": [38, 66, 75, 76, 77, 79, 81], "fulli": [38, 58, 63, 71, 79], "unless": 38, "list": [38, 43, 63, 67, 75, 76, 81], "default_autoquant_class_list": 38, "contain": [38, 62, 63, 79, 81], "second": [38, 56, 74, 75, 84], "stop": 38, "wait": [38, 75], "sever": [38, 74], "automat": [38, 74, 81, 84], "suppress": 38, "accept": 38, "signal": 38, "nois": 38, "ration": 38, "wikipedia": 38, "org": [38, 67, 75, 76, 79], "wiki": 38, "noise_ratio": 38, "v": 38, "non": [38, 75, 79, 81], "impact": [38, 74], "caus": [38, 74], "too": 38, "larg": [38, 81], "numer": [38, 74, 79], "resaon": 38, "40": [38, 74], "adjust": 38, "keyword": 38, "example_input1": 38, "example_input2": 38, "int32": [39, 75, 76], "fp32": [39, 43, 81], "bf16": [39, 75, 76, 79], "fp16": 39, "optioanl": 39, "param": [39, 41, 46, 67], "preserv": [39, 67, 79], "request": [39, 43, 59], "min_val": [41, 75, 81], "max_val": [41, 75, 81], "instead": [41, 66, 74, 75, 76, 79, 81], "observ": [41, 66, 79], "obtain": 41, "track": [41, 75], "nbit": 42, "group_siz": [42, 58, 76], "axi": [42, 59], "compute_dtyp": 42, "verbos": 42, "raw_output": 42, "optimize_weight": 42, "optimize_weights_proximal_legaci": 42, "input_dtyp": 43, "output_dtyp": [43, 44, 59], "uint8": [43, 59, 75], "quant_dtyp": [45, 46], "fake": [45, 46, 74], "awar": [45, 46, 67, 79, 81], "equival": [45, 46, 63, 79], "without": [45, 46, 75, 79], "valid": 45, "fake_quantize_affin": 46, "consum": 46, "outlier": [46, 74], "mask": [46, 67, 79], "intermedi": 46, "alia": [47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 65, 70], "float8dynamicactivationfloat8weightconfig": 47, "float8staticactivationfloat8weightconfig": 48, "float8weightonlyconfig": 49, "fpxweightonlyconfig": 50, "gemliteuintxweightonlyconfig": 51, "int4weightonlyconfig": 52, "int8dynamicactivationint4weightconfig": 53, "int8dynamicactivationint8weightconfig": 54, "int8weightonlyconfig": 55, "b": 56, "scales1": 56, "multipli": [56, 61, 79], "row": [56, 74, 79], "rais": [56, 61, 74, 81], "assertionerror": [56, 61, 74, 81], "expect": [56, 74, 79, 81], "intxquantizationawaretrainingconfig": 57, "aobaseconfig": [58, 71], "inplac": [58, 67, 76], "workflow": [58, 71, 74, 76, 79], "qualifi": [58, 63, 71, 79], "move": [58, 75], "speed": [58, 79], "predefin": 58, "correspond": [58, 75, 77, 79, 81], "execut": [58, 78, 81, 83], "path": [58, 61, 76], "customiz": 58, "current": [58, 63, 67, 71, 74, 79, 81], "int8_dynamic_activation_int4_weight": 58, "int8_dynamic_activation_int8_weight": [58, 71], "mm": [58, 81], "int4_weight_onli": [58, 75, 76, 77], "int8_weight_onli": 58, "sequenti": [58, 71, 74], "32": [58, 71, 74, 76, 77, 81], "1024": [58, 71, 76, 77], "tabl": [59, 74, 75, 79], "per_tensor": 59, "per_axi": 59, "per_group": 59, "groupsiz": 59, "low": [60, 79, 81], "00seeemm": 60, "fp6_e3m2": 60, "sign": 60, "expon": 60, "mantissa": 60, "mat2": 61, "safe": 61, "consid": [61, 75, 79], "cubla": 61, "fallback": 61, "i": [61, 74, 79], "j": 61, "debug_skip_calibr": 62, "smoothquant": [62, 63], "smoothfakedynamicallyquantizedlinear": [62, 63], "debug": 62, "skip_fqn_list": 63, "cur_fqn": 63, "alpha": 63, "replac": [63, 79], "skip": [63, 67, 79], "being": [63, 74, 75, 79], "input_quant_func": [64, 75], "quant_kwarg": 64, "dict": [64, 67, 81], "uintxweightonlyconfig": 65, "l2": [66, 79], "norm": [66, 67, 79], "channel": [66, 69], "buffer": 66, "x_orig": 66, "overridden": 66, "although": [66, 81], "within": [66, 79], "afterward": 66, "former": 66, "care": [66, 77, 79], "hook": [66, 75], "while": [66, 67, 79, 81], "latter": 66, "silent": 66, "ignor": [66, 74], "sparsity_level": [67, 79], "semi_structured_block_s": 67, "wanda": 67, "sparsifi": [67, 72, 77, 79], "propos": 67, "arxiv": [67, 79], "ab": [67, 79], "2306": 67, "11695": 67, "product": 67, "magnitud": [67, 79], "control": [67, 79], "parametr": 67, "deepcopi": [67, 76, 81], "squash_mask": [67, 79], "params_to_keep": 67, "params_to_keep_per_lay": 67, "squash": 67, "appropri": [67, 75], "sparse_param": 67, "attach": [67, 79], "kei": [67, 79, 84], "save": [67, 74, 76, 77], "xdoctest": 67, "local": [67, 79], "undefin": 67, "don": [67, 74, 76, 79], "t": [67, 74, 75, 76, 79, 81], "hasattr": 67, "submodule1": 67, "linear1": [67, 76, 77, 81], "foo": 67, "bar": 67, "submodule2": 67, "linear42": 67, "baz": 67, "print": [67, 76, 77, 81, 84], "42": 67, "24": 67, "ones": [67, 75], "update_mask": 67, "tensor_nam": 67, "statist": [67, 75, 79], "retriev": 67, "act_per_input": 67, "Then": [67, 81], "metric": 67, "across": [67, 79, 81], "whole": 67, "simul": [68, 75, 79], "dnynam": 69, "token": [69, 74], "semisparseweightconfig": 70, "sparsify_": 71, "apply_tensor_subclass": [71, 75], "essenti": 71, "semi_sparse_weight": 71, "semisparselayout": 71, "sparsemarlinlayout": 71, "def": [71, 74, 75, 76, 77, 81], "isinst": [71, 74, 79, 81], "sparse_api": 71, "librari": [72, 77], "gradient": [72, 79], "nativ": [72, 74, 81], "readm": [72, 76, 79], "overal": [72, 76], "introduct": [72, 75], "recent": 72, "highlight": [72, 81, 84], "updat": [72, 76, 77, 79], "guid": [72, 75], "contributor": [72, 76], "serial": [72, 75], "write": 72, "advanc": [72, 81], "pretrain": [72, 79], "5x": 74, "512": 74, "gpu": [74, 76, 84], "cluster": 74, "34": 74, "43x": 74, "2k": 74, "h200": 74, "latest": [74, 76], "offic": 74, "framework": 74, "8b": 74, "offici": 74, "popular": [74, 75], "flagship": 74, "common": [74, 75, 79], "form": [74, 75, 79], "distribut": [74, 81], "checkpoint": 74, "quickli": [74, 81], "batteri": 74, "includ": [74, 75, 81], "experi": 74, "commonli": [74, 79], "fork": 74, "build": [74, 75, 79, 81], "top": [74, 75, 81], "thei": [74, 75, 79, 81], "re": [74, 77, 81], "readi": [74, 76, 81], "virtual": 74, "environ": 74, "conda": 74, "venv": 74, "instal": [74, 76], "download": [74, 76, 82, 84], "job": 74, "command": [74, 76], "root": 74, "directori": 74, "launch": 74, "ngpu": 74, "config_fil": 74, "train_config": 74, "llama3_8b": 74, "toml": 74, "run_train": 74, "sh": 74, "fsdp2": 74, "hyperparamet": 74, "edit": 74, "line": [74, 79], "flag": 74, "termin": 74, "rank0": 74, "titan": 74, "2025": 74, "06": 74, "04": 74, "08": 74, "51": 74, "48": 74, "074": 74, "info": 74, "loss": [74, 79], "12": 74, "2254": 74, "27": 74, "34gib": 74, "28": 74, "78": 74, "tp": 74, "375": 74, "tflop": 74, "21": 74, "73": 74, "mfu": 74, "20": 74, "58": 74, "557": 74, "7069": 74, "30": [74, 76], "99gib": 74, "62": 74, "034": 74, "407": 74, "35": 74, "41": 74, "19": 74, "52": 74, "224": 74, "9196": 74, "022": 74, "406": 74, "65": 74, "904": 74, "1423": 74, "014": 74, "23": 74, "As": [74, 75], "warmup": 74, "around": [74, 77], "7k": 74, "99gb": 74, "peak": 74, "against": 74, "baselin": 74, "11": 74, "02": 74, "37": 74, "404": 74, "2611": 74, "22gib": 74, "595": 74, "47": 74, "49": 74, "027": 74, "4260": 74, "89gib": 74, "344": 74, "367": 74, "39": 74, "15": [74, 76], "03": 74, "01": 74, "988": 74, "9482": 74, "321": 74, "366": 74, "14": 74, "991": 74, "1183": 74, "300": 74, "364": 74, "89": 74, "36": 74, "013": 74, "4659": 74, "291": 74, "84": 74, "769": 74, "gc": 74, "peform": 74, "period": 74, "collect": [74, 75, 79], "3k": 74, "89gb": 74, "11x": 74, "higher": [74, 75, 81], "throughput": 74, "nearli": 74, "ident": [74, 79], "improv": [74, 79], "performan": 74, "vs": [74, 79], "accuraci": [74, 79], "curv": [74, 79], "omit": 74, "648": 74, "2648": 74, "28gib": 74, "71": 74, "29": 74, "26": 74, "475": 74, "9106": 74, "91gib": 74, "53": 74, "503": 74, "434": 74, "43": 74, "94": 74, "166": 74, "9": 74, "0774": 74, "663": 74, "443": 74, "44": 74, "87": 74, "50": [74, 79], "885": 74, "3233": 74, "643": 74, "442": 74, "66": 74, "76": 74, "613": 74, "6150": 74, "637": 74, "72": 74, "6k": 74, "91gb": 74, "21x": 74, "tl": 74, "dr": 74, "better": [74, 81], "priorit": 74, "accur": [74, 79], "stabil": 74, "come": [74, 75, 79, 80], "cost": 74, "slightli": [74, 81], "limit": [74, 81], "underflow": 74, "8xh100": 74, "must": [74, 79], "box": [74, 79], "toi": [74, 76, 81], "convert_to_float8_train": 74, "recurs": 74, "kind": 74, "gemm": 74, "snippet": 74, "f": [74, 75, 77, 79, 81], "float8_linear_util": 74, "float8_linear": 74, "torch_version_at_least_2_5": [74, 76], "greater": 74, "sampl": [74, 75], "2048": 74, "4096": 74, "128": [74, 81], "x": [74, 76, 77, 81, 84], "adamw": 74, "lr": 74, "1e": 74, "elig": 74, "mod": [74, 79, 81], "divis": 74, "16": 74, "in_featur": [74, 76, 77, 81], "out_featur": [74, 76, 81], "enabl": [74, 75], "competit": 74, "loop": [74, 79], "_": 74, "zero_grad": 74, "label": 74, "demonstr": [74, 75, 76, 81], "purpos": [74, 75, 81], "fake_label": 74, "ones_lik": 74, "mse_loss": 74, "model_state_dict": 74, "state_dict": [74, 77], "optimizer_state_dict": 74, "pth": 74, "lai": 75, "stack": 75, "hqq": 75, "awq": 75, "gptq": 75, "codebookquantizedtensor": 75, "uint1": 75, "uint7": 75, "int1": 75, "float3": 75, "compon": [75, 81], "tensorcoretiledlayout": [75, 76], "compos": [75, 79, 81], "overload": [75, 79], "term": [75, 79], "extra": 75, "empti": 75, "dev": 75, "discuss": [75, 81], "1833": 75, "No": [75, 77, 79], "matter": [75, 79], "end": [75, 79, 81, 84], "avail": 75, "later": [75, 81], "float3_e2_m0": 75, "float4_e2_m1": 75, "float4_e3_m0": 75, "float5_e2_m2": 75, "float5_e3_m1": 75, "float6_e2_m3": 75, "float6_e3_m2": 75, "float8_e4m3fn": 75, "float8_e5m2": 75, "float8_e4m3fnuz": 75, "float8_e5m2fnuz": 75, "plan": 75, "float4": 75, "float6": 75, "becom": 75, "hardwar": [75, 79], "part": [75, 79, 81], "uint2": 75, "117208": 75, "outsid": 75, "mention": 75, "criteria": 75, "wide": 75, "adopt": 75, "fundament": [75, 79], "until": 75, "evid": 75, "hopefulli": 75, "amen": 75, "haven": 75, "enough": 75, "ont": 75, "revisit": 75, "intx": 75, "connect": 75, "int4tensor": 75, "previou": 75, "between": [75, 79, 81], "preicison": 75, "mainli": 75, "There": [75, 81], "accommod": 75, "choose_qparams_affine_with_min_max": 75, "min": [75, 81], "_weight_int4pack_mm": 75, "int_matmul": 75, "int_scaled_matmul": 75, "reli": [75, 79, 81], "triton": 75, "On": [75, 76], "glue": 75, "everyth": 75, "togeth": 75, "construct": 75, "low_precision_v": 75, "high_precision_v": 75, "procedur": 75, "veri": [75, 79], "straightforward": 75, "try": [75, 79, 81], "lower": [75, 79], "high_preicsion_v": 75, "especi": [75, 77, 79], "bitwidth": 75, "codebook": 75, "hardcod": 75, "select": 75, "multi": 75, "dimension": [75, 79], "view": [75, 81], "mkldnn": 75, "coo": [75, 79], "sparse_coo": [75, 79], "sparsetensorimpl": 75, "idea": [75, 79], "nice": [75, 79], "concept": [75, 84], "why": [75, 81, 84], "c": [75, 81], "conflict": 75, "properti": 75, "quantized_linear": 75, "semant": 75, "stai": [75, 76, 81], "develop": 75, "tradition": 75, "to_affine_quant": 75, "simplic": 75, "explain": 75, "simplest": [75, 79], "easi": 75, "linear_modul": 75, "to_affine_quantized_intx": 75, "requires_grad": [75, 81], "runtim": 75, "to_linear_activation_quant": 75, "quantized_weight": 75, "activation_and_weight_quant": 75, "encount": 75, "input_qunat_func": 75, "redispatch": 75, "fx": 75, "symbolic_trac": 75, "But": [75, 81], "prefer": [75, 76, 81], "easier": 75, "further": [75, 81], "modif": 75, "figur": [75, 79], "At": [75, 79], "thing": [75, 77, 79, 81], "address": 75, "stat": 75, "averag": 75, "calculate_qparam": 75, "affinequantizedminmaxobserv": 75, "insert_observer_": 75, "altern": [75, 81], "observedlinear": 75, "dataset": 75, "complic": [75, 79], "next": 75, "done": [75, 81], "manner": 75, "intend": 75, "autoround": 75, "multitensor": 75, "sure": 75, "describ": [75, 77, 79, 84], "focus": [75, 79], "todai": 75, "low_bit_optim": 75, "similar": [75, 79], "quantized_train": 75, "progress": 75, "lot": [75, 79], "walk": [75, 81, 84], "_convert_weight_to_int4pack": 75, "aten": [75, 81], "group": [75, 76], "tensor_core_til": 75, "tensorcoretiledaqttensorimpl": 75, "_quantized_linear_op": 75, "goe": 75, "_aqt_qlinear_dispatch_t": 75, "dispatch": 75, "explan": 75, "wint4": 75, "explor": 76, "stabl": 76, "releas": 76, "pip": 76, "nightli": 76, "index": [76, 79], "url": 76, "whl": 76, "cu121": 76, "major": 76, "instruct": 76, "entri": 76, "mutat": 76, "insert": 76, "logic": [76, 81], "toylinearmodel": [76, 77], "__init__": [76, 77, 81], "super": [76, 77, 81], "linear2": [76, 77, 81], "eval": [76, 77], "faster": [76, 79], "model_bf16": 76, "leverag": [76, 81], "int4mm": 76, "mix": 76, "tensor_impl_dtyp": 76, "verifi": [76, 77, 81], "roughli": [76, 79], "quarter": 76, "os": 76, "tmp": 76, "int4_model": 76, "pt": 76, "bfloat16_model": 76, "int4_model_size_mb": 76, "getsiz": 76, "bfloat16_model_size_mb": 76, "2f": 76, "mb": [76, 77, 78, 83], "25": 76, "00": [76, 78, 83], "much": [76, 79], "benchmark_model": 76, "temporari": 76, "workaround": 76, "num_run": 76, "100": [76, 81], "_dynamo": [76, 81], "reset": 76, "bf16_time": 76, "int4_tim": 76, "time": [76, 79, 81, 84], "3f": 76, "ms": 76, "1fx": 76, "a100": 76, "80gb": 76, "393": 76, "410": 76, "9x": 76, "simpl": [76, 79, 81], "visit": 76, "would": [76, 79, 81], "forget": 76, "tempfil": 77, "get_model_size_in_byt": 77, "batch_siz": 77, "ref": 77, "namedtemporaryfil": 77, "seek": [77, 79], "load": 77, "meta": 77, "m_load": 77, "load_state_dict": 77, "assign": 77, "assert": [77, 81], "equal": [77, 79], "float_weight1": 77, "float_weight2": 77, "quantized_weight1": 77, "quantized_weight2": 77, "go": [77, 81, 84], "techinqu": 77, "reduct": [77, 79, 81], "4x": 77, "0625": 77, "reason": [77, 79], "avoid": [77, 79], "properli": 77, "004": [78, 83, 84], "total": [78, 83, 84], "galleri": [78, 82, 84], "mem": [78, 83], "templat": [78, 82, 83], "tutorials_sourc": 78, "template_tutori": [78, 83, 84], "neural": 79, "network": [79, 81], "its": [79, 81], "overhead": 79, "latenc": 79, "carefulli": 79, "signific": 79, "pai": 79, "price": 79, "qualiti": 79, "f1": 79, "problem": [79, 81], "research": [79, 84], "face": 79, "fragment": 79, "rightfulli": 79, "spent": 79, "compress": 79, "place": 79, "dens": 79, "solv": [79, 81], "focu": [79, 81], "realli": 79, "push": 79, "concret": 79, "hope": 79, "modular": 79, "acceler": 79, "scratch": [79, 84], "minim": 79, "recov": 79, "algorthim": 79, "realiz": 79, "trade": 79, "off": 79, "degrad": 79, "architectur": 79, "theoret": 79, "gain": 79, "2x": 79, "analog": 79, "fix": 79, "unstructur": 79, "One": [79, 81], "chosen": 79, "close": 79, "relat": 79, "mitig": 79, "retrain": 79, "neglig": 79, "area": 79, "agre": 79, "upon": 79, "consensu": 79, "mind": 79, "thought": 79, "separ": 79, "subproblem": 79, "satisfi": 79, "consist": [79, 81], "answer": 79, "independ": 79, "frontend": 79, "arbitrari": 79, "backend": 79, "handoff": 79, "piec": 79, "miss": 79, "natur": [79, 81], "present": 79, "clear": 79, "contract": 79, "7x": 79, "advantag": 79, "fast": 79, "anticip": 79, "mani": [79, 81], "solut": 79, "third": 79, "parti": 79, "to_sparse_semi_structur": 79, "sparsesemistructuredtensor": 79, "weightnormsparsifi": 79, "half": 79, "subnetwork": 79, "sparse_config": 79, "named_modul": 79, "append": 79, "tensor_fqn": 79, "sparse_block_shap": 79, "zeros_per_block": 79, "fakespars": 79, "flow": 79, "manipul": 79, "dictionari": 79, "paramer": 79, "parameter": 79, "necessari": [79, 81], "ve": 79, "suitabl": 79, "fuse": [79, 81], "0s": 79, "spot": 79, "definit": 79, "academia": 79, "industri": 79, "often": [79, 81], "interchang": 79, "confus": 79, "distinct": 79, "behind": 79, "doesn": 79, "itself": [79, 81], "those": [79, 81], "loos": 79, "speak": 79, "tightli": 79, "coupl": [79, 81], "nvidia": 79, "csc": 79, "fbgemm": 79, "qnnpack": 79, "descript": 79, "coordin": 79, "vector": 79, "locat": 79, "bsr": 79, "sparse_bsr": 79, "except": [79, 81], "scalar": 79, "csr": 79, "sparse_csr": 79, "sparse_csc": 79, "column": 79, "compact": 79, "sparse_matrix": 79, "1d": 79, "indexptr": 79, "\u00bd": 79, "bitmask": 79, "2bit": 79, "unprun": 79, "quit": [79, 81], "successfulli": 79, "These": [79, 81], "broken": 79, "down": 79, "Not": 79, "sensit": 79, "effect": [79, 81], "best": 79, "subsequ": [79, 81], "infinit": 79, "lost": 79, "degre": 79, "analysi": 79, "drop": 79, "give": [79, 81], "proxi": 79, "aforement": 79, "smallest": 79, "absolut": 79, "global": [79, 81], "scope": 79, "impli": 79, "pro": 79, "con": 79, "sub": 79, "tradeoff": 79, "span": 79, "threshold": 79, "increas": 79, "complex": 79, "constant": [79, 81], "ctr_mobile_fe": 79, "paper": [79, 84], "score": 79, "w": 79, "tenosr": 79, "udpat": 79, "cannot": 79, "histori": 79, "regrow": 79, "dw": 79, "via": 79, "backprop": 79, "pat": 79, "unmask": 79, "resid": 79, "salienc": 79, "lowest": 79, "l1": 79, "shown": 79, "abl": [79, 81], "repeat": 79, "shot": 79, "movement": 79, "tune": 79, "2005": 79, "07683": 79, "rank": [79, 81], "wx": 79, "sqx": 79, "q": 79, "usual": 79, "sort": 79, "wise": 79, "reconstruct": 79, "random": 79, "randomli": 79, "tri": 79, "remedi": 79, "item": [79, 84], "ultim": 79, "literatur": 79, "vision": 79, "nlp": [79, 84], "iter": 79, "ctr_feed": 79, "na": 79, "multimask": 79, "pyspeech": 79, "fastna": 79, "approach": [79, 81], "knowledg": [79, 84], "distil": 79, "pdf": 79, "2204": 79, "09656": 79, "arrang": 79, "recal": 79, "counterpart": 79, "slower": 79, "suffici": 79, "flexibl": [79, 81], "98": 79, "benefit": [79, 81], "special": 79, "exhibit": 79, "maintain": 79, "penalti": 79, "expens": [79, 81], "dictat": 79, "characterist": 79, "highest": 79, "wouldn": [79, 81], "visual": 79, "fig": 79, "4x4": 79, "benchmak": 79, "soon": 80, "foundat": 81, "extens": 81, "autograd": 81, "express": 81, "interpos": 81, "namespac": 81, "continu": 81, "seamlessli": 81, "obviou": 81, "int8quantizedlinear": 81, "few": 81, "finer": 81, "grain": 81, "intercept": 81, "contrast": 81, "long": 81, "clunki": 81, "distributedlinear": 81, "duplic": 81, "bypass": 81, "offer": 81, "outer": 81, "inner": 81, "allgath": 81, "bandwidth": 81, "exactli": 81, "rest": 81, "read": 81, "document": 81, "zoo": 81, "podcast": 81, "edward": 81, "yang": 81, "begin": 81, "int8_symmetric_quant": 81, "fp32_tensor": 81, "127": 81, "amin": 81, "keepdim": 81, "amax": 81, "zeros_lik": 81, "clamp": 81, "quantizedlinear": 81, "w_int8": 81, "cl": 81, "new_linear": 81, "left": 81, "toymodel": 81, "float_model": 81, "quantized_model": 81, "child": 81, "named_children": 81, "setattr": 81, "drawback": 81, "won": 81, "suppos": 81, "clean": 81, "eleg": 81, "pretti": 81, "power": 81, "overrid": 81, "almost": 81, "shard": 81, "ragged": 81, "rag": 81, "nestedtensor": 81, "resourc": 81, "who": 81, "link": [81, 84], "googl": 81, "collab": 81, "flopcount": 81, "memorytrack": 81, "With": 81, "bare": 81, "bone": 81, "int8symmetrictensor": 81, "hold": 81, "staticmethod": 81, "disabl": 81, "__new__": 81, "_make_wrapper_subclass": 81, "storage_offset": 81, "ndim": 81, "__tensor_flatten__": 81, "attribut": 81, "pt2": 81, "__tensor_unflatten__": 81, "tensor_data_dict": 81, "extra_metadata": 81, "outer_s": 81, "outer_strid": 81, "undo": 81, "back": 81, "__repr__": 81, "repr": 81, "ahead": 81, "insid": 81, "int8_tensor": 81, "func": 81, "op_implementations_dict": 81, "conveni": 81, "register_op": 81, "_op": 81, "opoverload": 81, "impl_decor": 81, "op_impl": 81, "wrapper": 81, "particular": 81, "largest": 81, "tell": 81, "desugar": 81, "decor": 81, "constructor": 81, "surfac": 81, "coverag": 81, "though": 81, "brute": 81, "forc": 81, "repeatedli": 81, "loggingtensor": 81, "_python_dispatch": 81, "return_and_correct_alias": 81, "int8_mm": 81, "detach": 81, "int8_view_op": 81, "out_data": 81, "out_scal": 81, "notic": 81, "hit": 81, "background": 81, "decomposit": 81, "live": 81, "decomp": 81, "shrink": 81, "author": [81, 84], "pain": 81, "rather": 81, "underli": 81, "worth": 81, "written": 81, "differenti": 81, "nuanc": 81, "longer": 81, "That": 81, "transposit": 81, "got": 81, "propag": 81, "fact": 81, "themselv": 81, "pointwis": 81, "alwai": 81, "were": 81, "might": 81, "unwrap": 81, "dim0": 81, "dim1": 81, "confirm": 81, "quantized_model_module_swap": 81, "quantized_model_subclass": 81, "subclass_param": 81, "no_grad": 81, "out_module_swap": 81, "allclos": 81, "out_compil": 81, "seri": 81, "wa": 81, "tutorials_python": 82, "zip": [82, 84], "jupyt": [82, 84], "notebook": [82, 84], "tutorials_jupyt": 82, "sphinx": [82, 84], "firstnam": 84, "lastnam": 84, "prerequisit": 84, "v2": 84, "topic": 84, "rand": 84, "7978": 84, "8348": 84, "4247": 84, "9210": 84, "1879": 84, "2612": 84, "5829": 84, "7558": 84, "7620": 84, "6253": 84, "8814": 84, "9536": 84, "3416": 84, "2123": 84, "6714": 84, "practic": 84, "test": 84, "summar": 84, "takeawai": 84, "link1": 84, "link2": 84, "minut": 84, "ipynb": 84}, "objects": {"torchao.dtypes": [[8, 0, 1, "", "AffineQuantizedTensor"], [9, 0, 1, "", "BlockSparseLayout"], [10, 0, 1, "", "CutlassInt4PackedLayout"], [11, 0, 1, "", "CutlassSemiSparseLayout"], [12, 0, 1, "", "Float8Layout"], [13, 0, 1, "", "Int4CPULayout"], [14, 0, 1, "", "Layout"], [15, 0, 1, "", "MarlinQQQLayout"], [16, 0, 1, "", "MarlinQQQTensor"], [17, 0, 1, "", "MarlinSparseLayout"], [18, 0, 1, "", "NF4Tensor"], [19, 0, 1, "", "PlainLayout"], [20, 0, 1, "", "SemiSparseLayout"], [21, 0, 1, "", "TensorCoreTiledLayout"], [22, 0, 1, "", "UintxLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[8, 1, 1, "", "dequantize"], [8, 1, 1, "", "from_hp_to_floatx"], [8, 1, 1, "", "from_hp_to_floatx_static"], [8, 1, 1, "", "from_hp_to_fpx"], [8, 1, 1, "", "from_hp_to_intx"], [8, 1, 1, "", "from_hp_to_intx_static"], [8, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[17, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[18, 1, 1, "", "convert_to_norm_float_weight"], [18, 1, 1, "", "dequantize"], [18, 1, 1, "", "dequantize_scalers"], [18, 1, 1, "", "double_quantize_scalers"], [18, 1, 1, "", "get_original_weight"], [18, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingType"], [33, 2, 1, "", "convert_to_float8_training"], [34, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[35, 0, 1, "", "MappingType"], [36, 0, 1, "", "TorchAODType"], [37, 0, 1, "", "ZeroPointDomain"], [38, 2, 1, "", "autoquant"], [39, 2, 1, "", "choose_qparams_affine"], [40, 2, 1, "", "choose_qparams_affine_floatx"], [41, 2, 1, "", "choose_qparams_affine_with_min_max"], [42, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [43, 2, 1, "", "dequantize_affine"], [44, 2, 1, "", "dequantize_affine_floatx"], [45, 2, 1, "", "fake_quantize_affine"], [46, 2, 1, "", "fake_quantize_affine_cachemask"], [47, 3, 1, "", "float8_dynamic_activation_float8_weight"], [48, 3, 1, "", "float8_static_activation_float8_weight"], [49, 3, 1, "", "float8_weight_only"], [50, 3, 1, "", "fpx_weight_only"], [51, 3, 1, "", "gemlite_uintx_weight_only"], [52, 3, 1, "", "int4_weight_only"], [53, 3, 1, "", "int8_dynamic_activation_int4_weight"], [54, 3, 1, "", "int8_dynamic_activation_int8_weight"], [55, 3, 1, "", "int8_weight_only"], [56, 2, 1, "", "int_scaled_matmul"], [57, 3, 1, "", "intx_quantization_aware_training"], [58, 2, 1, "", "quantize_"], [59, 2, 1, "", "quantize_affine"], [60, 2, 1, "", "quantize_affine_floatx"], [61, 2, 1, "", "safe_int_mm"], [62, 2, 1, "", "smooth_fq_linear_to_inference"], [63, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [64, 2, 1, "", "to_linear_activation_quantized"], [65, 3, 1, "", "uintx_weight_only"]], "torchao": [[5, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[66, 0, 1, "", "PerChannelNormObserver"], [67, 0, 1, "", "WandaSparsifier"], [68, 2, 1, "", "apply_fake_sparsity"], [69, 2, 1, "", "int8_dynamic_activation_int8_semi_sparse_weight"], [70, 3, 1, "", "semi_sparse_weight"], [71, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[66, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[67, 1, 1, "", "prepare"], [67, 1, 1, "", "squash_mask"], [67, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:attribute", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 72, 74, 75], "dtype": [0, 7, 75], "layout": [0, 6, 14, 75], "tensor": [0, 6, 75, 80, 81], "subclass": [0, 6, 75, 81], "quantiz": [0, 4, 58, 75, 76, 80, 81], "techniqu": 0, "float8": [1, 74], "main": [1, 4], "train": [1, 75], "api": [1, 2, 4, 72, 74], "other": [1, 4, 6, 75], "type": 1, "refer": [2, 72], "python": 2, "kernel": [3, 6, 73, 75], "quantize_": 4, "primit": [4, 75], "sparsiti": [5, 79], "contributor": 6, "guid": [6, 76], "gener": 6, "extend": 6, "ad": [6, 75], "effici": [6, 75], "custom": 6, "triton": 6, "hand": 6, "written": 6, "dispatch": 6, "tensorimpl": [6, 75], "flow": [6, 75, 77], "us": 6, "torch": 6, "compil": 6, "perform": [6, 73], "serial": [6, 77], "featur": 6, "support": [6, 75], "function": [6, 75], "compos": 6, "test": 6, "microbenchmark": 6, "model": [6, 74, 75, 77], "benchmark": 6, "eval": 6, "affinequantizedtensor": 8, "blocksparselayout": 9, "cutlassint4packedlayout": 10, "cutlasssemisparselayout": 11, "float8layout": 12, "int4cpulayout": 13, "marlinqqqlayout": 15, "marlinqqqtensor": 16, "marlinsparselayout": 17, "nf4tensor": 18, "plainlayout": 19, "semisparselayout": 20, "tensorcoretiledlayout": 21, "uintxlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalingtyp": 32, "convert_to_float8_train": 33, "precompute_float8_dynamic_scale_for_fsdp": 34, "mappingtyp": 35, "torchaodtyp": 36, "zeropointdomain": 37, "autoqu": 38, "choose_qparams_affin": 39, "choose_qparams_affine_floatx": 40, "choose_qparams_affine_with_min_max": 41, "choose_qparams_and_quantize_affine_hqq": 42, "dequantize_affin": 43, "dequantize_affine_floatx": 44, "fake_quantize_affin": 45, "fake_quantize_affine_cachemask": 46, "float8_dynamic_activation_float8_weight": 47, "float8_static_activation_float8_weight": 48, "float8_weight_onli": 49, "fpx_weight_onli": 50, "gemlite_uintx_weight_onli": 51, "int4_weight_onli": 52, "int8_dynamic_activation_int4_weight": 53, "int8_dynamic_activation_int8_weight": 54, "int8_weight_onli": 55, "int_scaled_matmul": 56, "intx_quantization_aware_train": 57, "quantize_affin": 59, "quantize_affine_floatx": 60, "safe_int_mm": 61, "smooth_fq_linear_to_infer": 62, "swap_linear_with_smooth_fq_linear": 63, "to_linear_activation_quant": 64, "uintx_weight_onli": 65, "perchannelnormobserv": 66, "wandasparsifi": 67, "apply_fake_spars": 68, "int8_dynamic_activation_int8_semi_sparse_weight": 69, "semi_sparse_weight": 70, "sparsifi": 71, "welcom": 72, "document": 72, "get": 72, "start": [72, 76], "develop": 72, "note": [72, 74], "tutori": [72, 84], "pretrain": 74, "torchtitan": 74, "prerequisit": 74, "rowwis": 74, "scale": 74, "tensorwis": 74, "pick": 74, "recip": 74, "import": 74, "directli": 74, "convers": 74, "overview": [75, 79, 84], "basic": 75, "current": 75, "placehold": 75, "pytorch": 75, "implement": [75, 81], "oper": [75, 81], "integr": 75, "nativ": 75, "factori": 75, "op": 75, "deriv": 75, "algorithm": 75, "weight": 75, "onli": 75, "dynam": 75, "activ": 75, "static": 75, "insert": 75, "observ": 75, "how": 75, "defin": 75, "modul": [75, 81], "add": 75, "calibr": 75, "awar": 75, "low": 75, "bit": 75, "optim": [75, 77], "case": 75, "studi": 75, "int4": 75, "work": 75, "dure": 75, "execut": 75, "save": 75, "load": 75, "quick": 76, "first": 76, "exampl": 76, "next": [76, 81], "step": [76, 81, 84], "deseri": 77, "what": [77, 81], "happen": 77, "when": 77, "an": 77, "comput": [78, 83], "time": [78, 83], "goal": 79, "design": 79, "context": 79, "prune": 79, "configur": 79, "criteria": 79, "strategi": 79, "pattern": 79, "write": [80, 81], "your": [80, 81], "own": [80, 81], "advanc": 80, "ar": 81, "swap": 81, "which": 81, "should": 81, "we": 81, "compar": 81, "output": 81, "templat": 84, "option": 84, "addit": 84, "exercis": 84, "conclus": 84, "further": 84, "read": 84}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})