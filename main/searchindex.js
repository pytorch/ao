Search.setIndex({"docnames": ["api_reference/api_ref_float8", "api_reference/api_ref_qat", "api_reference/api_ref_quantization", "api_reference/api_ref_sparsity", "api_reference/api_ref_utils", "api_reference/generated/torchao.float8.CastConfig", "api_reference/generated/torchao.float8.Float8LinearConfig", "api_reference/generated/torchao.float8.Float8LinearRecipeName", "api_reference/generated/torchao.float8.ScalingGranularity", "api_reference/generated/torchao.float8.ScalingType", "api_reference/generated/torchao.float8.convert_to_float8_training", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig", "api_reference/generated/torchao.quantization.FqnToConfig", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer", "api_reference/generated/torchao.quantization.qat.QATConfig", "api_reference/generated/torchao.quantization.qat.QATStep", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "api_reference/generated/torchao.quantization.quantize_", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "api_reference/generated/torchao.sparsity.PerChannelNormObserver", "api_reference/generated/torchao.sparsity.WandaSparsifier", "api_reference/generated/torchao.sparsity.apply_fake_sparsity", "api_reference/generated/torchao.sparsity.semi_sparse_weight", "api_reference/generated/torchao.sparsity.sparsify_", "api_reference/generated/torchao.utils.TorchAOBaseTensor", "api_reference/index", "contributing/benchmarking_api_guide", "contributing/contributor_guide", "contributing/index", "contributing/quantization_overview", "contributing/sparsity", "eager_tutorials/finetuning", "eager_tutorials/first_quantization_example", "eager_tutorials/index", "eager_tutorials/pretraining", "eager_tutorials/serialization", "eager_tutorials/serving", "eager_tutorials/static_quantization", "eager_tutorials/subclass_advanced", "eager_tutorials/subclass_basic", "eager_tutorials/torchao_hf_integration", "eager_tutorials/torchao_vllm_integration", "index", "performant_kernels", "pt2e_quantization/index", "pt2e_quantization/pt2e_quant_openvino_inductor", "pt2e_quantization/pt2e_quant_ptq", "pt2e_quantization/pt2e_quant_qat", "pt2e_quantization/pt2e_quant_x86_inductor", "pt2e_quantization/pt2e_quant_xpu_inductor", "pt2e_quantization/pt2e_quantizer", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "workflows/index", "workflows/inference", "workflows/qat", "workflows/training"], "filenames": ["api_reference/api_ref_float8.rst", "api_reference/api_ref_qat.rst", "api_reference/api_ref_quantization.rst", "api_reference/api_ref_sparsity.rst", "api_reference/api_ref_utils.rst", "api_reference/generated/torchao.float8.CastConfig.rst", "api_reference/generated/torchao.float8.Float8LinearConfig.rst", "api_reference/generated/torchao.float8.Float8LinearRecipeName.rst", "api_reference/generated/torchao.float8.ScalingGranularity.rst", "api_reference/generated/torchao.float8.ScalingType.rst", "api_reference/generated/torchao.float8.convert_to_float8_training.rst", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.FqnToConfig.rst", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.rst", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.rst", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.QATConfig.rst", "api_reference/generated/torchao.quantization.qat.QATStep.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.quantize_.rst", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.rst", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.rst", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "api_reference/generated/torchao.sparsity.PerChannelNormObserver.rst", "api_reference/generated/torchao.sparsity.WandaSparsifier.rst", "api_reference/generated/torchao.sparsity.apply_fake_sparsity.rst", "api_reference/generated/torchao.sparsity.semi_sparse_weight.rst", "api_reference/generated/torchao.sparsity.sparsify_.rst", "api_reference/generated/torchao.utils.TorchAOBaseTensor.rst", "api_reference/index.rst", "contributing/benchmarking_api_guide.md", "contributing/contributor_guide.rst", "contributing/index.rst", "contributing/quantization_overview.rst", "contributing/sparsity.rst", "eager_tutorials/finetuning.rst", "eager_tutorials/first_quantization_example.rst", "eager_tutorials/index.rst", "eager_tutorials/pretraining.rst", "eager_tutorials/serialization.rst", "eager_tutorials/serving.rst", "eager_tutorials/static_quantization.rst", "eager_tutorials/subclass_advanced.rst", "eager_tutorials/subclass_basic.rst", "eager_tutorials/torchao_hf_integration.md", "eager_tutorials/torchao_vllm_integration.md", "index.rst", "performant_kernels.rst", "pt2e_quantization/index.rst", "pt2e_quantization/pt2e_quant_openvino_inductor.rst", "pt2e_quantization/pt2e_quant_ptq.rst", "pt2e_quantization/pt2e_quant_qat.rst", "pt2e_quantization/pt2e_quant_x86_inductor.rst", "pt2e_quantization/pt2e_quant_xpu_inductor.rst", "pt2e_quantization/pt2e_quantizer.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "workflows/index.md", "workflows/inference.md", "workflows/qat.md", "workflows/training.md"], "titles": ["torchao.float8", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "CastConfig", "Float8LinearConfig", "Float8LinearRecipeName", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MXDynamicActivationMXWeightConfig", "NVFP4DynamicActivationNVFP4WeightConfig", "NVFP4WeightOnlyConfig", "Float8DynamicActivationFloat8SemiSparseWeightConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8DynamicActivationIntxWeightConfig", "Int8WeightOnlyConfig", "IntxWeightOnlyConfig", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "API Reference", "Benchmarking API Guide", "Contributor Guide", "Contributing", "Quantization Overview", "Sparsity Overview", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "First Quantization Example", "Tutorials", "(Part 1) Pre-training with float8", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "Welcome to the torchao Documentation", "Performant Kernels", "PT2E Quantization", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization", "&lt;no title&gt;", "Computation times", "Template Tutorial", "Workflows", "Quantized Inference", "Quantization-Aware Training (QAT)", "Quantized Training"], "terms": {"For": [1, 39, 62, 63, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 84, 85, 86, 91, 92, 93], "full": [1, 67, 73, 76, 80, 81, 83, 89, 92], "exampl": [1, 10, 11, 16, 18, 20, 22, 24, 26, 28, 29, 34, 38, 39, 41, 45, 50, 51, 56, 59, 60, 62, 63, 65, 66, 67, 69, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 87, 89, 92, 93], "how": [1, 17, 22, 39, 51, 52, 63, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 80, 81, 84, 85, 90, 91], "us": [1, 5, 7, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 31, 34, 38, 39, 41, 46, 47, 51, 52, 56, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93], "our": [1, 63, 66, 67, 68, 70, 72, 73, 75, 78, 82, 83, 90, 91, 92], "pleas": [1, 34, 38, 60, 63, 65, 66, 67, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 92, 93], "refer": [1, 41, 47, 62, 66, 67, 70, 72, 73, 75, 76, 77, 81, 82, 83, 84, 91, 92, 93], "readm": [1, 62, 66, 67, 68, 78, 90], "class": [5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 51, 52, 53, 55, 56, 60, 62, 63, 67, 68, 71, 73, 75, 80, 82, 83, 84, 86, 91, 92], "torchao": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 71, 72, 73, 75, 76, 80, 81, 82, 83, 84, 85, 90, 91, 93], "float8": [5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 31, 32, 33, 54, 61, 69, 72, 73, 78, 90, 91], "scaling_typ": [5, 6], "scalingtyp": [5, 6], "dynam": [5, 6, 7, 9, 11, 13, 15, 16, 17, 21, 22, 23, 31, 37, 39, 47, 59, 63, 67, 72, 73, 75, 76, 82, 83, 84, 91, 92, 93], "scaling_granular": [5, 6], "scalinggranular": [5, 6], "tensorwis": [5, 6, 7, 8, 10, 16, 65, 67], "target_dtyp": [5, 6, 65, 73], "option": [5, 6, 7, 10, 16, 19, 22, 23, 24, 25, 28, 29, 31, 32, 36, 38, 39, 41, 43, 44, 50, 51, 54, 56, 59, 60, 62, 63, 65, 68, 70, 76, 77, 78, 80, 82, 83, 84, 85, 86, 91], "dtype": [5, 10, 12, 15, 16, 18, 23, 25, 28, 29, 31, 32, 35, 36, 37, 39, 43, 44, 46, 47, 54, 59, 62, 63, 67, 68, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 86, 91, 92, 93], "none": [5, 6, 7, 8, 9, 10, 11, 16, 19, 23, 24, 25, 28, 29, 31, 32, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 56, 59, 60, 65, 67, 73, 75, 77, 81, 82, 83, 85, 91, 93], "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 72, 87, 89], "configur": [5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 50, 59, 65, 67, 70, 72, 76, 84, 85, 86, 92, 93], "cast": [5, 8, 9, 67, 92, 93], "singl": [5, 8, 11, 16, 63, 66, 67, 70, 82, 86, 91, 92, 93], "tensor": [5, 7, 8, 9, 13, 15, 18, 20, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 40, 51, 52, 53, 54, 56, 60, 62, 66, 67, 68, 69, 70, 71, 73, 76, 82, 84, 85, 89, 90], "paramet": [5, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 31, 32, 39, 41, 44, 46, 47, 50, 56, 59, 60, 62, 65, 66, 67, 70, 71, 72, 75, 77, 81, 82, 91, 92, 93], "The": [5, 10, 11, 16, 18, 19, 23, 25, 41, 50, 56, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75, 76, 77, 81, 82, 83, 84, 85, 86, 91, 92, 93], "type": [5, 6, 7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 25, 39, 42, 50, 51, 52, 53, 54, 60, 62, 63, 65, 66, 67, 68, 71, 72, 75, 77, 78, 81, 82, 84, 85, 86, 91, 92], "scale": [5, 7, 8, 9, 11, 13, 16, 23, 25, 31, 32, 39, 44, 45, 46, 47, 54, 63, 65, 66, 73, 75, 77, 86, 91, 92], "see": [5, 23, 25, 60, 62, 63, 65, 66, 67, 68, 70, 71, 73, 75, 76, 77, 78, 81, 82, 86, 90, 91, 92, 93], "default": [5, 7, 13, 16, 18, 20, 23, 31, 39, 47, 50, 60, 63, 65, 67, 70, 75, 77, 80, 81, 82, 83, 84, 85, 86, 91], "granular": [5, 8, 16, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 39, 40, 63, 65, 70, 72, 73, 77, 91, 93], "target": [5, 16, 18, 20, 28, 29, 32, 39, 56, 62, 63, 66, 67, 80, 81, 82, 83, 84, 85, 86, 91, 92], "e": [5, 19, 26, 39, 41, 50, 53, 60, 63, 65, 67, 70, 71, 73, 75, 76, 78, 81, 86, 91, 92], "g": [5, 19, 26, 39, 41, 50, 53, 60, 63, 65, 67, 71, 73, 75, 81, 86, 91, 92], "torch": [5, 6, 10, 12, 15, 16, 18, 20, 23, 25, 28, 29, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 51, 59, 60, 62, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 84, 85, 86, 89, 91, 92, 93], "float8_e4m3fn": [5, 12, 13, 15, 16, 18, 32, 65], "set": [5, 16, 18, 20, 21, 22, 24, 39, 50, 56, 60, 66, 67, 81, 83, 84, 85, 91, 92, 93], "base": [5, 9, 16, 19, 23, 25, 27, 40, 41, 45, 51, 53, 54, 56, 60, 63, 65, 66, 68, 75, 76, 77, 81, 82, 83, 84, 85, 86, 91, 92, 93], "recip": [5, 6, 7, 10, 28, 33, 43, 55, 67, 92, 93], "cast_config_input": 6, "config": [6, 10, 16, 18, 19, 20, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 38, 39, 40, 41, 50, 56, 59, 62, 65, 66, 67, 68, 72, 73, 76, 77, 80, 82, 84, 85, 91, 92, 93], "castconfig": 6, "cast_config_input_for_grad_weight": 6, "cast_config_weight": 6, "cast_config_weight_for_grad_input": 6, "cast_config_grad_output": 6, "cast_config_grad_output_for_grad_weight": 6, "gemm_config_output": 6, "float8gemmconfig": 6, "use_fast_accum": 6, "true": [6, 10, 13, 14, 16, 18, 20, 21, 22, 24, 28, 29, 38, 39, 41, 49, 50, 59, 63, 67, 68, 70, 71, 72, 73, 75, 76, 77, 80, 81, 82, 83, 84, 86, 91, 93], "gemm_config_grad_input": 6, "fals": [6, 10, 22, 28, 29, 37, 38, 39, 41, 43, 44, 46, 47, 56, 62, 65, 67, 68, 70, 71, 72, 73, 75, 76, 77, 81, 82, 83, 85, 86, 91, 92, 93], "gemm_config_grad_weight": 6, "enable_fsdp_float8_all_gath": 6, "bool": [6, 10, 13, 14, 16, 18, 20, 21, 22, 24, 28, 29, 37, 39, 43, 44, 46, 47, 49, 50, 59, 67, 73], "pad_inner_dim": 6, "emul": [6, 51], "force_recompute_fp8_weight_in_bwd": 6, "round_scales_to_power_of_2": 6, "convert": [6, 10, 26, 34, 35, 41, 50, 59, 65, 66, 67, 70, 72, 81, 84, 85, 86, 92, 93], "nn": [6, 10, 26, 31, 35, 38, 41, 50, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 77, 80, 82, 83, 84, 86, 91, 92, 93], "linear": [6, 10, 15, 16, 17, 18, 21, 22, 24, 26, 29, 31, 36, 37, 38, 41, 46, 47, 48, 49, 50, 57, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 80, 81, 82, 83, 84, 86, 91, 92, 93], "modul": [6, 7, 8, 9, 10, 11, 12, 19, 26, 28, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 59, 62, 63, 65, 67, 68, 70, 71, 73, 77, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "train": [6, 7, 10, 26, 39, 41, 63, 66, 69, 75, 80, 86], "static": [6, 39, 69, 80, 82, 83, 84, 85, 86, 93], "from_recipe_nam": [6, 10, 93], "recipe_nam": [6, 70], "union": [6, 16, 32, 39, 50], "float8linearrecipenam": 6, "str": [6, 10, 19, 39, 41, 50, 56, 59, 60, 62, 70, 75, 77, 85, 93], "input": [6, 10, 11, 13, 41, 45, 50, 56, 59, 62, 63, 65, 68, 70, 72, 73, 75, 80, 81, 82, 83, 84, 85, 86, 91, 93], "valu": [6, 7, 8, 9, 16, 18, 20, 21, 22, 24, 32, 42, 51, 52, 56, 65, 66, 67, 73, 75, 81, 82, 83, 86, 92], "string": [6, 39, 56, 60, 62], "repres": [6, 27, 39, 52, 56, 63, 65, 71, 75, 82, 83, 91, 92], "output": [6, 63, 65, 66, 67, 68, 70, 72, 76, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93], "implement": [6, 20, 43, 44, 46, 47, 51, 60, 63, 65, 66, 67, 71, 73, 81, 82, 86, 91], "specifi": [6, 10, 19, 23, 24, 25, 26, 28, 29, 30, 33, 40, 41, 47, 50, 51, 56, 59, 63, 65, 66, 67, 70, 81, 82, 83, 86, 91, 92, 93], "name": [7, 8, 9, 10, 19, 42, 50, 51, 52, 56, 59, 60, 62, 63, 65, 66, 72, 75, 77, 81, 82, 83, 86, 91, 93], "qualnam": [7, 8, 9, 42, 51, 52], "start": [7, 8, 9, 19, 42, 51, 52, 63, 65, 66, 67, 68, 70, 72, 73, 75, 77, 81, 82, 83, 84, 85, 86], "1": [7, 8, 9, 10, 16, 18, 19, 20, 22, 23, 24, 25, 32, 42, 51, 52, 54, 56, 60, 63, 65, 66, 68, 69, 71, 73, 75, 78, 80, 82, 83, 89, 90, 91, 92], "boundari": [7, 8, 9, 42, 51, 52], "pre": [7, 66, 67, 69, 72, 78, 86], "made": [7, 86, 91], "common": [7, 41, 51, 52, 53, 54, 61, 63, 65, 66, 70, 93], "per": [7, 13, 17, 18, 21, 22, 23, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 56, 63, 65, 66, 67, 70, 73, 85, 91, 92, 93], "cubla": [7, 93], "kernel": [7, 13, 16, 17, 46, 50, 51, 66, 72, 81, 84, 85, 91, 92], "fastest": [7, 63, 91, 93], "rowwis": [7, 8, 10, 16, 31, 65, 90], "cutlass": 7, "e4m3": 7, "activ": [7, 13, 15, 16, 21, 22, 23, 28, 29, 31, 37, 38, 39, 41, 47, 53, 54, 56, 62, 66, 67, 72, 73, 76, 77, 78, 80, 81, 84, 85, 86, 90, 91, 92, 93], "weight": [7, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 41, 43, 44, 46, 47, 50, 53, 56, 59, 63, 66, 67, 70, 71, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93], "gradient": [7, 66, 78, 92], "ar": [7, 10, 16, 19, 20, 23, 25, 26, 28, 29, 38, 41, 50, 51, 52, 56, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 77, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "round": [7, 75, 92], "floor": 7, "nearest": 7, "power": [7, 75, 77], "two": [7, 16, 41, 60, 65, 66, 67, 75, 80, 81, 82, 83, 84, 86, 91, 92, 93], "increas": [7, 66, 67, 82, 93], "accuraci": [7, 66, 67, 68, 70, 72, 73, 78, 81, 83, 84, 90, 92, 93], "rowwise_with_gw_hp": [7, 10], "A": [7, 8, 51, 55, 60, 63, 65, 66, 67, 75, 76, 77, 82, 92, 93], "modif": 7, "grad_weight": 7, "keep": [7, 22, 56, 63, 65, 82, 91], "comput": [7, 8, 9, 11, 13, 18, 28, 33, 43, 51, 55, 56, 63, 65, 66, 73, 75, 76, 82, 83, 84, 85, 91], "high": [7, 32, 41, 65, 66, 67, 70, 72, 73, 75, 81, 82, 84, 85, 91, 93], "precis": [7, 9, 18, 22, 31, 32, 36, 37, 41, 44, 46, 47, 65, 67, 73, 75, 76, 81, 84, 85, 91], "most": [7, 41, 51, 63, 65, 66, 72, 77, 82, 83, 86, 91, 92, 93], "accur": [7, 66, 70, 81, 93], "defin": [8, 9, 28, 33, 43, 55, 56, 60, 62, 63, 65, 66, 73, 75, 77, 80, 81, 84, 85, 86], "strategi": [8, 93], "factor": [8, 9, 66, 70], "entir": [8, 72, 82, 83], "axiswis": 8, "along": [8, 13, 66, 77, 81], "one": [8, 16, 23, 25, 28, 33, 41, 43, 55, 63, 65, 66, 70, 75, 77, 83, 86, 91, 92], "axi": [8, 23, 25, 73], "": [9, 13, 19, 51, 52, 60, 63, 65, 66, 67, 68, 70, 72, 73, 75, 82, 83, 84, 85, 86, 91, 92, 93], "disabl": [9, 48, 75, 83, 91], "skip": [9, 56, 65, 66], "thi": [9, 11, 12, 13, 16, 21, 22, 23, 24, 28, 33, 34, 39, 41, 43, 44, 46, 47, 50, 53, 54, 55, 56, 57, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93], "leav": [9, 39, 91], "its": [9, 66, 67, 75, 77, 82, 86, 91], "origin": [9, 18, 22, 34, 56, 62, 65, 66, 67, 68, 71, 72, 81, 82, 86], "module_filter_fn": [10, 70, 93], "callabl": [10, 50, 59, 60, 77], "float8linearconfig": [10, 93], "swap": [10, 31, 35, 66, 67, 70, 73, 83, 91, 92], "float8linear": [10, 70, 93], "modifi": [10, 50, 56, 63, 66, 70, 75, 91], "If": [10, 16, 22, 24, 38, 39, 41, 56, 60, 62, 63, 65, 66, 67, 72, 75, 82, 83, 91], "onli": [10, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 31, 41, 47, 62, 63, 66, 67, 68, 70, 71, 72, 75, 76, 77, 78, 81, 82, 84, 85, 86, 91, 92, 93], "subclass": [10, 28, 33, 43, 51, 52, 55, 59, 60, 65, 66, 67, 68, 71, 76], "pass": [10, 22, 28, 29, 33, 41, 43, 55, 60, 62, 65, 73, 75, 77, 83, 86, 91, 93], "filter": [10, 19, 63, 67, 70, 73, 91, 92, 93], "function": [10, 28, 33, 43, 48, 49, 50, 55, 56, 57, 59, 60, 62, 65, 66, 67, 68, 70, 71, 73, 75, 77, 80, 81, 86, 91, 92, 93], "instanc": [10, 28, 33, 43, 50, 55, 59, 60, 71, 75, 82, 84, 85, 86, 91], "fqn": [10, 19, 56, 59, 70, 73, 93], "convers": [10, 63, 67, 92, 93], "return": [10, 39, 50, 59, 60, 62, 63, 65, 67, 68, 70, 71, 73, 75, 77, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "layer": [10, 15, 16, 18, 19, 22, 24, 28, 29, 31, 35, 36, 37, 43, 44, 46, 47, 56, 57, 62, 66, 70, 72, 73, 75, 77, 81, 86, 91, 92], "import": [10, 16, 18, 20, 22, 24, 34, 38, 41, 50, 59, 63, 66, 67, 68, 71, 72, 73, 75, 76, 77, 78, 80, 81, 84, 85, 89, 91, 92, 93], "from": [10, 16, 18, 19, 20, 21, 22, 24, 34, 38, 41, 50, 51, 59, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93], "creat": [10, 63, 66, 68, 70, 75, 76, 81, 82, 84, 85, 86, 93], "model": [10, 11, 16, 18, 20, 21, 22, 24, 26, 31, 34, 35, 36, 37, 38, 41, 45, 50, 56, 57, 59, 66, 67, 73, 75, 80, 84, 85, 86, 90, 91, 92], "sampl": [10, 70, 82, 84, 85, 93], "m": [10, 13, 50, 59, 62, 63, 67, 70, 71, 72, 73, 75, 80, 82, 83, 84, 91, 92, 93], "sequenti": [10, 50, 59, 70, 91, 93], "8192": [10, 93], "4096": [10, 67, 70, 91, 92, 93], "bia": [10, 29, 46, 47, 62, 65, 67, 68, 71, 73, 75, 77, 83, 86, 91, 93], "128": [10, 13, 17, 20, 68, 70, 72, 73, 75, 76, 77, 85, 86, 91, 92, 93], "bfloat16": [10, 31, 36, 46, 62, 65, 66, 68, 70, 71, 72, 73, 76, 77, 84, 85, 90, 91, 92, 93], "cuda": [10, 20, 50, 62, 63, 66, 67, 68, 70, 71, 72, 73, 75, 76, 78, 83, 91, 92, 93], "optim": [10, 11, 20, 23, 50, 63, 66, 67, 70, 75, 81, 83, 84, 85, 91, 92, 93], "sgd": [10, 67, 92, 93], "lr": [10, 67, 70, 92, 93], "0": [10, 13, 19, 23, 25, 28, 39, 43, 44, 56, 60, 62, 63, 65, 66, 67, 70, 71, 72, 73, 75, 76, 77, 78, 82, 83, 85, 86, 88, 89, 91, 92, 93], "being": [10, 66, 70, 77, 84, 85, 91, 93], "elig": [10, 70, 93], "def": [10, 53, 59, 60, 62, 63, 65, 67, 68, 70, 71, 73, 75, 77, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "mod": [10, 48, 49, 66, 70, 75, 93], "don": [10, 19, 56, 63, 65, 66, 68, 70, 76, 77, 86, 93], "t": [10, 13, 19, 56, 60, 63, 65, 66, 68, 70, 73, 75, 76, 77, 82, 83, 86, 91, 93], "last": [10, 70, 81, 93], "dimens": [10, 13, 62, 63, 65, 70, 75, 77, 82, 83, 93], "divis": [10, 70, 93], "16": [10, 13, 29, 67, 70, 91, 92, 93], "isinst": [10, 59, 66, 70, 73, 75, 77, 83, 86, 91, 92, 93], "in_featur": [10, 29, 46, 47, 68, 70, 71, 73, 75, 91, 93], "out_featur": [10, 29, 46, 47, 70, 73, 75, 93], "valid": [10, 23, 25, 60, 72, 77, 86, 93], "enabl": [10, 49, 60, 62, 63, 65, 68, 70, 72, 77, 84, 91, 93], "compil": [10, 50, 65, 67, 68, 70, 73, 75, 80, 84, 85, 91, 93], "competit": [10, 67, 70, 93], "perform": [10, 11, 22, 23, 24, 28, 33, 35, 36, 37, 43, 55, 66, 67, 68, 70, 73, 75, 76, 77, 81, 83, 84, 85, 92], "loop": [10, 66, 67, 70, 92, 93], "x": [10, 23, 25, 28, 29, 33, 40, 43, 62, 68, 70, 71, 72, 73, 75, 77, 80, 81, 82, 83, 84, 85, 89, 91, 93], "randn": [10, 29, 62, 67, 68, 70, 71, 73, 75, 81, 82, 83, 84, 85, 91, 92, 93], "devic": [10, 43, 46, 47, 50, 62, 63, 67, 68, 70, 71, 72, 73, 75, 77, 81, 82, 83, 84, 85, 91, 93], "_": [10, 60, 63, 65, 68, 70, 73, 77, 81, 82, 83, 84, 92, 93], "rang": [10, 66, 67, 68, 70, 73, 82, 83, 92, 93], "10": [10, 28, 62, 63, 67, 68, 70, 72, 73, 80, 82, 83, 91, 92, 93], "zero_grad": [10, 67, 70, 83, 92, 93], "y": [10, 93], "sum": [10, 11, 82, 83, 93], "backward": [10, 11, 66, 67, 70, 83, 92, 93], "step": [10, 11, 41, 42, 62, 65, 66, 67, 70, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "calcul": [11, 16, 32, 65, 66, 82, 86], "all": [11, 19, 28, 31, 33, 35, 43, 45, 55, 56, 57, 60, 63, 65, 66, 68, 71, 72, 73, 75, 77, 80, 81, 82, 84, 86, 87, 91, 93], "should": [11, 19, 28, 33, 34, 41, 43, 55, 56, 60, 63, 66, 67, 70, 77, 81, 82, 86, 91, 92], "run": [11, 12, 28, 29, 33, 43, 50, 51, 55, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93], "after": [11, 63, 65, 66, 67, 70, 71, 76, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93], "It": [11, 66, 75, 80, 86], "reduc": [11, 41, 62, 63, 66, 67, 68, 70, 72, 84, 91], "contain": [11, 53, 54, 62, 66, 75, 83, 86], "prototyp": [12, 13, 14, 39, 45, 65, 86, 90], "mx_format": [12, 13, 14], "block_siz": [12, 65, 73, 91], "int": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 43, 44, 46, 47, 50, 56, 60, 62, 67, 73, 75, 77, 91], "32": [12, 20, 21, 23, 29, 38, 39, 41, 43, 44, 50, 59, 67, 70, 71, 72, 73, 75, 78, 83, 91, 92, 93], "activation_dtyp": [12, 15, 16, 65], "weight_dtyp": [12, 15, 16, 18, 23, 25, 65, 72], "kernel_prefer": [12, 16, 65], "kernelprefer": [12, 16], "auto": [12, 16, 51, 63, 72, 76, 77], "scaling_mod": 12, "scalecalculationmod": 12, "rceil": 12, "mx": 12, "format": [12, 13, 19, 20, 23, 25, 52, 63, 66, 72, 82, 83, 86, 91], "infer": [12, 13, 41, 62, 65, 66, 67, 68, 71, 73, 75, 76, 78, 81, 82, 83, 84, 85, 92], "quantiz": [12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 59, 61, 62, 63, 64, 66, 69, 70, 71, 90], "provid": [12, 26, 45, 60, 63, 65, 66, 67, 68, 70, 72, 75, 77, 82, 83, 85, 86, 90, 92], "support": [12, 15, 16, 17, 19, 20, 21, 23, 31, 38, 39, 41, 51, 53, 54, 59, 60, 62, 65, 66, 67, 68, 70, 71, 72, 75, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93], "requir": [12, 23, 51, 60, 62, 65, 66, 67, 68, 72, 75, 76, 78, 80, 81, 84, 86, 91], "nvidia": [12, 13, 62, 66], "sm100": 12, "hardwar": [12, 16, 51, 52, 63, 66, 68, 72, 76, 80, 91, 93], "blackwel": [12, 67], "newer": [12, 67], "i": [12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 38, 39, 41, 50, 53, 54, 56, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93], "execut": [12, 50, 69, 75, 88], "pytorch": [12, 39, 60, 62, 65, 66, 67, 70, 72, 75, 77, 80, 89, 91, 93], "2": [12, 16, 18, 19, 20, 22, 23, 24, 25, 28, 39, 43, 44, 57, 59, 63, 65, 66, 68, 69, 70, 73, 75, 80, 89, 90, 91, 92], "5": [12, 16, 18, 28, 56, 63, 66, 67, 72, 77, 80, 82, 83, 89, 91, 92, 93], "proper": 12, "serial": [12, 60, 65, 69, 76, 82, 83], "use_triton_kernel": [13, 77], "use_dynamic_per_tensor_scal": [13, 14], "fp4": 13, "nvfp4": [13, 65, 67, 90, 91, 92], "special": [13, 66, 81, 82], "whether": [13, 39, 60, 63, 67, 75, 91], "fuse": [13, 66, 75, 80, 83, 92], "triton": [13, 65, 84, 85], "data": [13, 15, 16, 18, 22, 52, 60, 62, 65, 66, 67, 71, 73, 75, 76, 77, 78, 81, 82, 83, 84, 85, 86, 90, 91], "float4_e2m1fn_x2": [13, 65], "block": [13, 56, 66, 90], "size": [13, 20, 21, 24, 39, 62, 63, 66, 70, 71, 72, 73, 75, 77, 83, 91, 92, 93], "reduct": [13, 66, 68, 71, 72, 75], "dim": [13, 22, 24, 32, 73, 75, 77, 82, 83], "note": [13, 19, 20, 23, 25, 26, 38, 47, 56, 60, 62, 63, 65, 66, 67, 68, 72, 75, 77, 78, 83, 84, 85, 93], "work": [13, 62, 63, 64, 66, 67, 70, 71, 75, 76, 77, 82, 83, 84, 91], "mode": [13, 62, 63, 68, 69, 73, 81, 83, 84, 85, 86, 91], "ha": [13, 41, 63, 66, 67, 72, 75, 77, 81, 82, 83, 85, 86], "constraint": [13, 82, 83, 86], "must": [13, 19, 23, 25, 26, 39, 41, 47, 66, 70, 76, 77, 83, 85, 86], "satisfi": [13, 66], "k": [13, 62, 63, 71, 73, 75, 82, 83, 91, 93], "64": [13, 20, 31, 71, 72, 73, 75, 77, 91, 92], "Will": 13, "automat": [13, 41, 70, 72, 75, 76, 77, 89, 92], "fallback": [13, 19, 77], "when": [13, 19, 23, 41, 60, 62, 63, 65, 66, 67, 70, 72, 73, 76, 77, 81, 82, 83, 84, 85, 86, 91, 93], "aren": 13, "met": 13, "layout": [15, 20, 21, 22, 23, 59, 60, 66], "cutlasssemisparselayout": 15, "float8_e5m2": [15, 65], "appli": [15, 16, 17, 18, 19, 21, 22, 24, 26, 30, 31, 33, 38, 40, 41, 50, 59, 60, 63, 65, 66, 67, 72, 77, 83, 91, 92], "follow": [15, 39, 41, 60, 63, 65, 66, 67, 70, 72, 73, 75, 76, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "compress": [15, 66, 81], "spars": [15, 28, 43, 44, 56, 66], "semi": [15, 59, 66], "structur": [15, 59, 63, 65, 66, 67, 68, 71, 75, 82], "moment": 15, "pertensor": [16, 24, 32, 73, 93], "perrow": [16, 22, 24, 32, 65], "list": [16, 26, 56, 60, 68, 75, 76, 77, 81, 83, 86], "packing_format": [16, 20], "float8packingformat": 16, "plain": [16, 20, 52, 65, 77, 91], "mm_config": 16, "float8mmconfig": 16, "activation_value_lb": 16, "float": [16, 28, 32, 39, 43, 44, 56, 65, 67, 71, 75, 80, 82, 83, 86, 91, 92], "activation_value_ub": 16, "set_inductor_config": [16, 18, 20, 21, 22, 24, 91], "version": [16, 18, 19, 20, 22, 23, 24, 25, 39, 51, 60, 65, 67, 75, 77, 78, 82, 83, 86, 91, 92, 93], "symmetr": [16, 18, 21, 22, 23, 24, 25, 28, 31, 39, 67, 75, 81, 82, 85, 86, 91, 92], "both": [16, 20, 41, 47, 65, 66, 68, 73, 75, 80, 82, 84, 85, 86, 92, 93], "fp8granular": [16, 32], "can": [16, 26, 39, 50, 51, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 81, 82, 83, 84, 85, 86, 91, 92, 93], "either": [16, 32, 41, 56, 63, 66, 72, 83, 84, 85], "tupl": [16, 45, 56, 60, 75, 77, 82, 83, 86], "current": [16, 20, 21, 31, 32, 41, 50, 56, 59, 62, 65, 66, 70, 75, 76, 77, 80, 82, 83, 85, 91, 92], "need": [16, 28, 33, 43, 52, 53, 54, 55, 56, 60, 62, 63, 65, 66, 67, 71, 72, 75, 77, 82, 83, 84, 86, 91], "same": [16, 20, 23, 47, 59, 60, 65, 66, 67, 70, 73, 75, 83, 85, 86, 91, 92], "And": [16, 75, 84, 86], "matrix": [16, 51, 56, 62, 65, 66, 84, 91], "multipl": [16, 26, 51, 53, 62, 63, 65, 66, 67, 73, 75, 77, 84, 86, 92], "fast": [16, 66], "accumul": [16, 92], "lower": [16, 21, 32, 65, 66, 67, 72, 73, 76, 80, 83, 92], "bound": [16, 32, 63, 66, 72, 77, 91, 93], "upper": [16, 32], "prefer": [16, 65, 67, 75, 91], "op": [16, 50, 51, 60, 63, 66, 67, 75, 77, 80, 82, 83, 84, 86, 91, 92, 93], "like": [16, 23, 60, 62, 63, 65, 66, 67, 68, 70, 71, 75, 76, 77, 81, 82, 83, 84, 85, 86, 91], "matmul": [16, 18, 65, 66, 75, 91], "group": [16, 17, 21, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 51, 62, 63, 67, 92], "etc": [16, 28, 29, 51, 52, 54, 62, 63, 65, 81, 86, 91], "defalut": 16, "chosen": [16, 51, 54, 66], "user": [16, 26, 41, 47, 51, 62, 63, 65, 66, 67, 70, 72, 73, 75, 80, 82, 83, 84, 85, 86, 89, 92], "other": [16, 23, 40, 51, 56, 62, 66, 67, 70, 71, 72, 75, 77, 78, 82, 83, 84, 86, 89], "inform": [16, 60, 62, 65, 66, 72, 77, 81, 82], "adjust": [16, 18, 20, 21, 22, 24, 67], "torchinductor": [16, 18, 20, 21, 22, 24, 84, 85], "recommend": [16, 18, 20, 21, 22, 24, 63, 65, 67, 68, 70, 76, 78, 81, 84, 85, 90, 91], "deprec": [16, 18, 19, 22, 34, 38, 60], "float8tensor": [16, 18, 32, 53, 63, 65, 77], "quantize_": [16, 18, 20, 22, 24, 34, 38, 41, 50, 51, 52, 53, 54, 59, 61, 62, 63, 65, 67, 68, 71, 72, 73, 78, 91, 93], "int4_packing_format": [17, 20, 78, 91], "int4packingformat": [17, 20], "preshuffl": [17, 65], "row": [17, 62, 63, 65, 66, 70], "int4": [17, 20, 21, 23, 28, 29, 31, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 63, 65, 67, 71, 72, 76, 77, 78, 90, 91, 92], "group_siz": [17, 20, 21, 23, 24, 28, 29, 31, 35, 38, 39, 41, 43, 44, 50, 62, 67, 76, 77, 78, 91, 92], "right": [17, 20, 63, 66, 82], "now": [17, 20, 62, 63, 65, 66, 67, 68, 70, 73, 75, 76, 81, 82, 84, 86, 91, 92], "sinc": [17, 19, 28, 33, 43, 55, 60, 65, 66, 71, 72, 73, 75, 82, 83, 84, 85, 86, 91], "underli": [17, 72, 75, 91], "abov": [17, 23, 25, 63, 65, 66, 67, 71, 73, 75, 82, 83, 86, 91, 92, 93], "benefit": [17, 66, 67, 75, 82, 85], "make": [17, 63, 65, 75, 77, 80, 82, 86, 93], "bigger": 17, "pack": [17, 20, 23, 25, 52, 63, 91], "channel": [18, 22, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 55, 73, 85, 91], "actual": [18, 41, 51, 65, 67, 73, 75, 77, 82, 83, 86, 91, 92], "fqn_to_config": 19, "ordereddict": 19, "core": [19, 50, 73, 77, 82, 91], "aobaseconfig": [19, 41, 50, 59, 62, 73, 77], "factori": 19, "module_fqn_to_config": 19, "differ": [19, 20, 26, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75, 76, 77, 78, 82, 83, 84, 86, 90, 91, 92, 93], "fulli": [19, 50, 59, 66, 72, 82], "qualifi": [19, 50, 59, 66, 91], "an": [19, 38, 39, 41, 47, 56, 65, 66, 67, 70, 72, 73, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 90, 91, 93], "order": [19, 26, 60, 63, 66, 75, 86, 91], "dictionari": [19, 66, 91], "regex": [19, 81], "python": [19, 62, 63, 66, 72, 80, 81, 82, 84, 85, 87, 89, 93], "re": [19, 63, 65, 70, 71, 72, 75, 82, 83, 91], "prefix": 19, "3": [19, 28, 65, 66, 69, 70, 76, 78, 80, 82, 83, 89, 91, 92, 93], "_default": [19, 72, 77], "we": [19, 20, 22, 38, 39, 41, 47, 50, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 90, 91, 93], "want": [19, 50, 59, 63, 65, 66, 71, 75, 77, 80, 81, 82, 83, 86, 93], "param": [19, 25, 56, 72], "kei": [19, 56, 66, 89, 91], "preced": [19, 81, 82, 84, 85], "languag": [19, 72], "q_proj": [19, 77, 92], "first": [19, 41, 56, 60, 63, 65, 69, 72, 73, 75, 76, 77, 78, 82, 83, 86, 91, 92, 93], "match": [19, 46, 47, 60, 66, 82], "whichev": 19, "kept": 19, "consist": [19, 62, 66, 72, 75, 84, 85, 86], "previou": [19, 65, 72, 82, 83, 84, 85, 91], "subset": [19, 23, 25, 65], "some": [19, 50, 56, 60, 63, 65, 66, 72, 73, 75, 80, 81, 82, 83, 84, 85, 86, 91], "better": [19, 22, 24, 68, 70, 75, 82, 83, 84, 85, 86, 93], "befor": [19, 41, 50, 63, 65, 66, 67, 71, 72, 73, 75, 82, 83, 86, 91, 92, 93], "hand": 19, "them": [19, 28, 33, 43, 55, 62, 67, 86, 91, 92], "norm": [19, 55, 56, 66], "linear_config": [19, 72], "filter_fn": [19, 50, 59, 92], "To": [19, 47, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 77, 78, 82, 83, 84, 86, 91, 92, 93], "maintain": [19, 60, 66, 72], "bc": [19, 60], "modulefqntoconfig": 19, "later": [19, 65, 67, 75, 82, 83, 85, 91], "pattern": [19, 65, 77, 80, 81, 82], "mai": [19, 39, 52, 63, 65, 71, 73, 76, 82, 83, 84, 85, 86, 91, 92], "matter": [19, 65, 66], "ignor": [19, 28, 33, 43, 55, 70, 82, 83], "replac": [19, 66, 67, 77], "int4_choose_qparams_algorithm": [20, 78], "int4chooseqparamsalgorithm": 20, "tinygemm": [20, 46, 50, 91, 92], "groupwis": [20, 23, 25, 91], "although": [20, 28, 33, 43, 55, 67, 75], "In": [20, 41, 63, 65, 66, 67, 68, 70, 73, 75, 81, 82, 83, 84, 85, 86, 91, 92, 93], "mainli": [20, 65, 81, 84, 86], "distinguish": [20, 65, 91], "arg": [20, 23, 25, 28, 29, 30, 31, 35, 44, 56, 60, 63, 65, 75, 77, 83, 86], "control": [20, 21, 22, 56, 66, 77, 82, 91], "smaller": [20, 21, 67, 68, 71, 92], "more": [20, 21, 23, 25, 62, 63, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 78, 81, 82, 83, 84, 85, 91, 92, 93], "fine": [20, 21, 66, 69, 70, 72, 92], "grain": [20, 21, 75], "choic": [20, 63], "256": [20, 35, 36, 37, 46, 47, 72, 82, 83, 86, 91], "variant": [20, 75], "choos": [20, 23, 25, 54, 63, 65, 66, 75, 82, 84, 91], "qparam": 20, "algorithm": [20, 23, 25, 63, 66, 72, 81, 90, 91], "hqq": [20, 65, 78, 90, 91], "vari": [20, 67, 68, 82, 83, 84, 85], "backend": [20, 21, 66, 72, 80, 86, 91], "is_avail": [20, 78], "tile": 20, "tile_packed_to_4d": [20, 78, 91], "elif": [20, 62, 77, 78, 91], "xpu": [20, 78, 80, 85], "plain_int32": [20, 78], "plainlayout": [21, 22, 60, 73], "mapping_typ": [21, 25, 39], "mappingtyp": [21, 22, 23, 25, 39, 73, 91], "act_mapping_typ": [21, 22, 23], "asymmetr": [21, 23, 25, 39, 67, 73, 81, 85, 86, 91, 92], "int8": [21, 22, 23, 24, 25, 29, 37, 38, 39, 41, 47, 50, 54, 59, 65, 67, 68, 72, 75, 82, 84, 85, 86, 90, 91, 92], "token": [21, 22, 23, 37, 39, 47, 67, 70, 72, 76, 91, 92, 93], "produc": [21, 80, 81, 82, 83, 84, 85, 92], "executorch": [21, 23, 63, 69, 76, 80, 82, 83], "did": [21, 67], "flow": [21, 66, 67, 70, 72, 73, 81, 82, 83, 84, 85], "yet": [21, 41, 67, 75, 77, 83, 84, 85], "weight_only_decod": 22, "store": [22, 53, 55, 65, 66, 76, 77, 82, 83], "access": [22, 63, 81], "map": [22, 23, 25, 39, 60, 65, 67, 75, 82, 86, 91], "around": [22, 65, 70, 71, 80, 82], "zero": [22, 23, 25, 39, 44, 45, 46, 47, 56, 66, 73, 86, 92], "dure": [22, 39, 41, 66, 67, 70, 72, 73, 75, 80, 81, 83, 92], "forward": [22, 28, 29, 33, 40, 43, 46, 55, 62, 66, 68, 71, 73, 75, 77, 80, 82, 83, 84, 91, 93], "decod": [22, 72, 91], "oper": [22, 63, 65, 67, 72, 80, 81, 82, 83, 84, 85, 91, 92], "scheme": [22, 24, 28, 29, 41, 67, 72, 81, 91], "affinequantizedtensor": [22, 63, 71, 73, 75, 91], "plan": [22, 63, 83, 90, 91], "split": [22, 72, 82, 83], "int8tensor": [22, 65, 68], "weight_granular": [23, 65, 72], "pergroup": [23, 25, 39, 72], "weight_mapping_typ": 23, "weight_scale_dtyp": [23, 72], "intx_packing_format": [23, 25], "intxpackingformat": [23, 25], "unpacked_to_int8": [23, 25], "intx_choose_qparams_algorithm": [23, 25], "intxchooseqparamsalgorithm": [23, 25], "affin": [23, 25, 65], "intx": [23, 25, 90, 91], "8": [23, 25, 28, 29, 36, 46, 65, 67, 70, 72, 77, 84, 85, 91, 92, 93], "specif": [23, 28, 29, 47, 52, 56, 62, 63, 65, 66, 67, 70, 71, 72, 76, 81, 84, 85, 86, 92], "bit": [23, 25, 40, 62, 67, 72, 75, 76, 77, 82, 84, 85, 91, 92], "channelwis": [23, 25], "manner": [23, 25], "number": [23, 25, 31, 44, 46, 47, 56, 66, 72, 75, 83, 84, 91], "ident": [23, 66, 70], "int8dynamicactivationint4weightconfig": [23, 41, 47, 67, 91, 92], "howev": [23, 66, 76, 77, 83, 86], "gener": [23, 28, 29, 30, 33, 40, 62, 65, 66, 67, 68, 72, 73, 75, 77, 81, 83, 84, 85, 86, 87, 89, 91, 92], "where": [23, 25, 35, 36, 37, 62, 65, 66, 77, 86, 91], "peraxi": [23, 25, 39, 72, 73], "zeropointdomain": [23, 39, 91], "intend": [23, 51, 65, 82], "export": [23, 65, 80], "applic": [23, 72], "opaque_torchao_auto": 23, "cpu": [23, 62, 63, 66, 71, 73, 76, 77, 78, 81, 82, 83, 84, 91], "detail": [23, 25, 62, 63, 65, 66, 67, 68, 70, 72, 73, 75, 78, 81, 82, 83, 84, 90, 92, 93], "otherwis": [24, 26, 39, 83], "scale_dtyp": [25, 73], "qat": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 61, 69, 72, 78, 80, 84], "twostepquant": 26, "compos": [26, 65, 66, 67, 75, 82, 83, 86, 91, 93], "easili": [26, 81], "thei": [26, 66, 70, 75, 76, 80, 82, 83, 86, 91], "constructor": [26, 60, 75, 91], "embed": [26, 28, 35, 38, 41, 43, 44, 92], "behavior": [26, 77, 82, 83, 93], "undefin": [26, 56], "usag": [26, 28, 29, 34, 38, 39, 41, 60, 67, 69, 70, 72, 84, 85, 92], "my_quant": 26, "qatquantizer1": 26, "qatquantizer2": 26, "qatquantizer3": 26, "prepar": [26, 31, 35, 41, 56, 66, 67, 81, 84, 85, 86, 92], "fake": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 67, 70, 82, 83, 86, 92, 93], "num_embed": [28, 43, 44], "embedding_dim": [28, 43, 44], "padding_idx": [28, 43, 44], "max_norm": [28, 43, 44], "norm_typ": [28, 43, 44], "scale_grad_by_freq": [28, 43, 44], "weight_config": [28, 29, 38, 41, 92], "fakequantizeconfigbas": [28, 29, 38, 41], "kwarg": [28, 29, 30, 31, 35, 39, 44, 54, 55, 56, 57, 60, 62, 63, 65, 75, 77], "through": [28, 29, 62, 63, 65, 67, 68, 72, 73, 75, 77, 80, 81, 82, 86, 89, 92, 93], "separ": [28, 29, 39, 66, 67, 77, 82, 86], "intxfakequantizeconfig": [28, 29, 38, 40, 41, 92], "fq_embed": 28, "longtensor": 28, "everi": [28, 33, 43, 55, 66, 75, 82, 83], "call": [28, 33, 43, 55, 60, 63, 65, 66, 67, 71, 73, 75, 77, 83, 85, 91, 92], "overridden": [28, 33, 43, 55], "within": [28, 33, 43, 55, 66, 72, 77, 84, 85], "afterward": [28, 33, 43, 55], "instead": [28, 33, 34, 38, 39, 41, 43, 55, 66, 67, 70, 75, 80, 83, 84, 85, 86], "former": [28, 33, 43, 55], "take": [28, 33, 43, 50, 55, 59, 60, 65, 66, 81, 82, 83, 84, 85, 86, 91], "care": [28, 33, 43, 55, 66, 71, 82, 91], "regist": [28, 33, 43, 55, 60, 63, 65, 75], "hook": [28, 33, 43, 55, 65], "while": [28, 33, 41, 43, 53, 55, 56, 66, 67, 68, 72, 75, 76, 81, 82, 86, 91, 92], "latter": [28, 33, 43, 55, 83], "silent": [28, 33, 43, 55, 84], "activation_config": [29, 38, 41, 92], "per_token": [29, 38, 39, 41, 92], "is_symmetr": [29, 38, 39, 41, 92], "fq_linear": 29, "ani": [30, 31, 35, 45, 56, 63, 65, 66, 75, 81, 83, 85, 91], "scale_precis": [31, 35, 39, 43, 44], "element": [31, 44, 46, 47, 60, 65, 66], "each": [31, 39, 44, 46, 47, 55, 60, 63, 65, 66, 73, 75, 77, 82, 83, 86, 91, 92], "fakequantizedlinear": [31, 34, 48, 49, 67, 92], "hp_value_lb": 32, "hp_value_ub": 32, "point": [32, 39, 44, 45, 46, 47, 65, 66, 68, 70, 71, 73, 75, 80, 82, 86, 92, 93], "float8fakequantizeconfig": 33, "qatconfig": [34, 38, 42, 67, 92], "fakequantizedembed": 34, "back": [34, 75, 91], "correspond": [34, 41, 50, 62, 65, 66, 67, 71, 75, 85, 86, 92], "without": [34, 65, 66, 67, 77, 84, 86, 92], "model_with_fake_quantized_linear": 34, "float32": [35, 37, 39, 43, 44, 47, 66, 67, 71, 72, 73, 75, 84, 85, 86, 91], "zero_point_precis": [35, 39, 43, 44], "int32": [35, 39, 43, 44, 65, 82, 86], "have": [35, 36, 37, 52, 56, 63, 65, 66, 67, 73, 75, 77, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93], "int4weightonlyqatembed": 35, "int4weightonlyembed": 35, "groupsiz": [36, 37, 46, 47, 67, 92], "inner_k_til": [36, 46], "scales_precis": [36, 37, 46, 47], "padding_allow": 37, "rais": [38, 41, 75, 77], "valueerror": [38, 41], "torchaodtyp": 39, "zero_point_domain": 39, "is_dynam": [39, 84, 85, 86], "range_learn": 39, "ep": [39, 73, 83, 85, 86, 91], "integ": [39, 40, 67, 73, 82, 83, 84, 91], "up": [39, 50, 65, 66, 67, 70, 81, 82, 83, 86, 91, 92, 93], "simul": [39, 41, 57, 66, 92], "older": [39, 60, 91], "than": [39, 65, 66, 67, 68, 70, 75, 82, 93], "6": [39, 65, 66, 70, 72, 78, 82, 83, 84, 91], "you": [39, 56, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75, 76, 77, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93], "int1": [39, 65], "int7": [39, 65], "also": [39, 50, 63, 65, 66, 67, 68, 71, 73, 75, 76, 77, 82, 85, 86, 90, 91, 92], "equival": [39, 66, 67, 83, 84, 86, 92, 93], "pertoken": 39, "per_channel": 39, "per_group": 39, "combin": [39, 66, 72, 75, 82, 84, 93], "altern": [39, 67, 73, 75, 84, 85, 91, 92], "just": [39, 63, 65, 66, 71, 75, 82, 83, 86], "field": [39, 42, 86], "empti": [39, 65], "fp32": [39, 47, 73, 75, 82, 84], "domain": [39, 67, 70], "learn": [39, 66, 68, 82, 84, 85, 86, 89, 92], "compat": [39, 62, 63, 78, 91, 93], "keyword": [39, 41, 53, 65], "argument": [39, 41, 50, 53, 60, 65, 70, 72, 84, 91], "properti": [39, 40], "throw": 39, "error": [39, 70, 75, 82, 91], "els": [39, 65, 72, 77, 82, 83], "width": [40, 62, 92], "symmetri": 40, "base_config": [41, 67, 92], "qatstep": 41, "awar": [41, 56, 66, 75, 80, 90], "here": [41, 47, 62, 65, 71, 72, 73, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92], "numer": [41, 46, 47, 51, 66, 67, 70, 82, 83, 84, 92, 93], "arithmet": [41, 67], "bf16": [41, 62, 66, 67, 84, 85, 91, 92, 93], "goal": [41, 67], "eventu": [41, 67, 70], "degrad": [41, 66, 67, 78], "There": [41, 65, 67, 73, 75, 82, 86, 93], "wai": [41, 63, 65, 66, 70, 72, 73, 75, 82, 83, 86, 91, 92], "involv": [41, 66, 67, 92], "post": [41, 65, 68, 75, 80, 83, 86, 92], "ptq": [41, 83, 84, 90, 92], "which": [41, 46, 51, 62, 63, 65, 66, 67, 70, 71, 72, 73, 77, 81, 82, 83, 84, 85, 86, 91, 92], "phase": [41, 86], "case": [41, 51, 62, 63, 66, 72, 75, 77, 81, 82, 86, 91, 92], "train_loop": [41, 67, 92], "int4weightonlyconfig": [41, 50, 71, 76, 77, 78, 91, 92], "second": [41, 60, 65, 70, 86, 89, 91, 93], "directli": [41, 65, 66, 67, 73, 75], "mostli": [41, 80], "experiment": [41, 81, 91, 92], "doe": [41, 51, 52, 63, 65, 66, 67, 75, 82, 84, 85, 91, 92], "exist": [41, 63, 65, 66, 70, 73, 75, 82, 86, 91], "qat_config": [41, 92], "act_config": 41, "custom": [41, 55, 62, 65, 66, 67, 70, 75, 77, 78, 81, 82, 84, 86, 92], "alwai": [41, 72, 75], "One": [41, 66, 75, 77, 86], "determin": [41, 66, 70, 77, 91], "enum": [42, 51], "output_dtyp": 43, "example_input": [45, 68, 71, 73, 80, 81, 82, 83, 84, 85, 86, 91], "initi": [45, 65, 67, 71, 80, 83], "intxfakequantizerbas": 45, "weightonlyint4linear": 46, "effici": [46, 51, 66, 67, 73, 85, 91, 92], "hardcod": [47, 86, 92], "allow": [47, 63, 65, 66, 75, 80, 81, 82, 83, 84, 86, 91, 92], "get": [47, 60, 63, 65, 66, 67, 68, 70, 72, 77, 80, 81, 82, 83, 84, 86, 91], "exact": [47, 67, 82, 83, 91], "helper": [48, 49, 60, 63], "_is_linear": [50, 73], "inplac": [50, 56, 68], "workflow": [50, 51, 59, 62, 63, 66, 68, 70, 80, 86, 91, 93], "object": [50, 59, 63, 65, 75, 82, 83, 86], "move": [50, 63, 73, 77, 83, 84], "speed": [50, 66, 67, 72, 81], "final": [50, 65, 66, 68, 81, 82, 83, 84, 85, 86, 91, 92], "do": [50, 63, 65, 66, 72, 73, 75, 77, 82, 83, 84, 86, 91], "chang": [50, 63, 66, 68, 70, 71, 72, 73, 75, 81, 82, 83, 85, 86, 91], "predefin": [50, 52, 86], "method": [50, 56, 60, 62, 63, 66, 73, 75, 76, 80, 81, 82, 83, 85, 86, 91], "path": [50, 67, 68, 72, 80, 81, 82, 83, 84, 86, 93], "customiz": [50, 67], "int8dynamicactivationint8weightconfig": [50, 59, 68, 76, 91], "mm": [50, 51, 63, 75, 82, 91], "int8weightonlyconfig": [50, 67, 76, 77, 91], "quant_api": [50, 63, 71, 72, 73, 91, 93], "1024": [50, 59, 62, 68, 71, 84, 91], "affect": [51, 66], "select": [51, 82], "found": [51, 65, 66, 68, 72, 73, 75, 91], "under": [51, 63, 67, 72, 91], "librari": [51, 52, 63, 65, 71, 78], "avail": [51, 52, 62, 63, 65, 72, 81, 82, 83, 84, 85, 90], "gemm_lowp": 51, "b": [51, 60], "gemm_fp32": 51, "dequant": [51, 65, 75, 77, 80, 82, 84, 85, 86, 91, 92], "ci": [51, 91], "product": [51, 56, 68, 72, 77, 84, 86], "logic": [51, 68, 75, 77], "lowp": 51, "gemm": [51, 70, 84, 85, 93], "debug": [51, 63], "issu": [51, 65, 68, 75, 84, 91], "mslk": [51, 63, 65], "nativ": [51, 65, 70, 75, 82, 93], "laid": [52, 65], "out": [52, 56, 62, 63, 65, 66, 67, 68, 70, 72, 75, 80, 81, 82, 83, 84, 91, 93], "opaqu": 52, "decid": [52, 66, 73], "shape": [52, 62, 63, 65, 73, 75, 77, 82, 85, 91, 93], "rest": [52, 62, 75, 83], "system": [52, 62, 63, 72, 93], "understand": [52, 63, 70, 84, 86], "adopt": [52, 65], "creation": [53, 77], "construct": [53, 65, 82, 86], "classmethod": [53, 60, 73, 75, 77], "from_hp": [53, 65], "cl": [53, 60, 73, 75, 77], "quant_kwarg": [53, 54], "quantizetensorkwarg": 54, "given": [54, 66, 70, 77, 86, 93], "deriv": [54, 63], "flexibl": [54, 66, 75, 81, 84, 91, 92], "variou": [54, 90], "sparsiti": [55, 56, 57, 58, 59, 61, 62, 64, 67, 70, 71, 72, 90], "observ": [55, 65, 66, 73, 81, 82, 83, 84, 85, 86, 93], "l2": [55, 66], "buffer": 55, "x_orig": 55, "sparsity_level": [56, 66], "semi_structured_block_s": 56, "wanda": 56, "sparsifi": [56, 66, 71, 78], "prune": 56, "propos": [56, 67], "http": [56, 60, 66, 72, 76, 78, 85, 91, 92], "arxiv": [56, 66], "org": [56, 60, 66, 72, 78, 85], "ab": [56, 66], "2306": 56, "11695": 56, "remov": [56, 63, 66, 70, 77, 82, 83, 92], "magnitud": [56, 66, 93], "three": [56, 59, 84, 85, 90, 93], "variabl": [56, 66], "level": [56, 63, 65, 66, 75, 81, 82, 84, 85, 91], "dict": [56, 60, 75, 77, 85, 86], "ad": [56, 60, 62, 65, 66, 67, 73, 75, 83, 91], "parametr": 56, "preserv": [56, 66, 72, 81], "copi": [56, 63, 66, 68, 71, 73, 75, 83, 84, 91], "deepcopi": [56, 68, 73, 75, 83, 91], "squash_mask": [56, 66], "params_to_keep": 56, "params_to_keep_per_lay": 56, "squash": 56, "mask": [56, 66], "appropri": [56, 81, 82, 83, 84, 85], "sparse_param": 56, "attach": [56, 66, 86], "save": [56, 60, 63, 67, 68, 70, 71, 72, 77, 91, 92], "xdoctest": 56, "local": [56, 66, 72, 93], "hasattr": [56, 77], "submodule1": 56, "linear1": [56, 68, 71, 73, 75, 91], "foo": [56, 82], "bar": [56, 82], "submodule2": 56, "linear42": 56, "baz": 56, "print": [56, 67, 68, 71, 72, 75, 82, 83, 89, 91, 93], "42": [56, 73, 91], "24": [56, 91], "ones": [56, 83], "update_mask": 56, "tensor_nam": [56, 77], "statist": [56, 66, 73, 82, 83], "retriev": 56, "act_per_input": 56, "Then": [56, 75, 85, 86, 92], "metric": [56, 62, 67], "compar": [56, 63, 65, 67, 68, 70, 72, 82, 84, 86, 91, 92], "across": [56, 66, 72, 75, 77], "whole": [56, 86], "4": [57, 59, 65, 66, 67, 68, 71, 72, 75, 76, 82, 83, 90, 91, 92, 93], "alia": [58, 60, 77], "semisparseweightconfig": 58, "sparsify_": 59, "apply_tensor_subclass": 59, "essenti": [59, 77, 81], "put": [59, 63, 84, 86], "semi_sparse_weight": 59, "semisparselayout": 59, "sparse_api": 59, "util": [60, 61, 62, 63, 65, 71, 75, 77, 81, 82, 83, 84, 85, 86, 91], "commonli": [60, 66, 70], "new": [60, 62, 65, 67, 70, 73, 75, 82, 83, 84, 86], "inherit": [60, 75, 77, 84, 85], "attribut": [60, 63, 65, 67, 75, 77, 84, 85], "tensor_data_nam": [60, 63], "tensor_data": 60, "__init__": [60, 62, 67, 68, 71, 73, 75, 77, 80, 82, 83, 84, 91], "been": [60, 67, 75, 83, 84, 85, 86, 91, 93], "section": [60, 63, 65, 66, 77, 82, 83, 86, 91], "tensor_attribute_nam": [60, 63], "non": [60, 63, 66, 75, 81, 84, 85, 91], "optional_tensor_data_nam": 60, "addit": [60, 62, 65, 66, 67, 70, 75, 76, 81, 82, 85, 86, 91, 92], "optional_tensor_attribute_nam": 60, "__new__": [60, 75, 77], "exaclti": 60, "present": [60, 66], "includ": [60, 65, 70, 75, 81, 84, 85, 86, 90, 93], "__tensor_flatten__": [60, 75, 77], "flatten": 60, "attribute_nam": 60, "__tensor_unflatten__": [60, 75, 77], "tensor_data_dict": [60, 75, 77], "_apply_fn_to_data": [60, 77], "recreat": 60, "transform": [60, 63, 67, 73, 81, 82, 83, 84, 85, 91, 92], "__repr__": [60, 75], "represent": [60, 66, 77, 82, 86], "_same_metadata": 60, "metadata": [60, 65, 72, 75, 77], "between": [60, 65, 66, 75, 77, 81, 83, 84, 86, 91, 92], "__setstate__": 60, "load": [60, 63, 71, 72, 76, 77, 91], "checkpoint": [60, 67, 70, 72, 77, 91], "old": 60, "add": [60, 63, 75, 76, 84, 86, 89, 91], "__torch_function__": [60, 65, 75], "contigu": [60, 65, 84, 85], "aten": [60, 63, 65, 75, 77, 80, 81, 82, 83, 84, 85, 91], "__torch_dispatch__": [60, 75], "detach": [60, 75, 77], "clone": [60, 72, 77, 93], "copy_": [60, 77], "_to_copi": [60, 77], "mytensor": [60, 63], "c": [60, 75, 80, 84, 85], "d": [60, 63, 72, 83, 91], "f": [60, 65, 66, 68, 70, 71, 72, 73, 75, 77, 82, 83, 91, 93], "h": [60, 72], "self": [60, 62, 67, 68, 71, 73, 75, 77, 80, 82, 83, 84, 91], "get_layout": 60, "15": [60, 62, 70, 72, 91], "part": [60, 66, 69, 75, 76, 83], "develop": [60, 63, 78, 80, 82, 83, 86, 91], "stack": [60, 65, 72], "about": [60, 62, 63, 65, 66, 67, 68, 71, 72, 82, 83, 84, 86, 91, 92, 93], "dev": [60, 76], "check": [60, 62, 63, 65, 67, 68, 71, 72, 75, 80, 81, 83, 86, 91], "doc": [60, 63, 65, 70, 72, 75, 76, 80, 93], "ao": [60, 66, 77, 91], "main": [60, 65, 66, 68, 72, 73, 75, 76, 82, 86, 90, 92], "quantization_overview": 60, "html": 60, "contributor_guid": 60, "get_tensor_impl_constructor": 60, "layout_class": 60, "tensorimpl": 60, "tensorimplclass": 60, "from_plain": 60, "tensor_class": 60, "mean": [60, 65, 66, 67, 70, 82, 83, 86, 91], "impl": 60, "aten_op": 60, "decor": [60, 75, 77], "callback": 60, "func": [60, 63, 65, 75, 77], "implements_torch_funct": 60, "torch_fn": 60, "register_layout": 60, "registr": 60, "aqt": 60, "py": [60, 62, 63, 84, 85, 88, 89, 91, 93], "tabl": [60, 65, 66, 70, 78, 93], "comprehens": [61, 62, 68, 77, 84], "document": [61, 64, 67, 75, 77, 81, 82, 84, 90, 91, 92], "tutori": [62, 63, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92], "framework": [62, 63, 67, 70, 72, 81, 93], "architectur": [62, 66, 69, 72, 81, 82, 84, 85], "micro": 62, "sparsity_": 62, "string_to_config": 62, "microbenchmark": [62, 93], "code": [62, 63, 65, 66, 68, 70, 72, 73, 75, 82, 83, 84, 85, 86, 87, 89, 91], "my_new_quant": 62, "process": [62, 65, 66, 67, 81, 85, 89, 91, 92], "mynewquantizationconfig": 62, "my_new_spars": 62, "mynewsparsityconfig": 62, "throughout": 62, "append": [62, 66, 82, 83], "gemliteuintxweightonlyconfig": [62, 91], "gemlitewo": 62, "bit_width": 62, "model_architectur": 62, "your": [62, 63, 65, 66, 67, 68, 69, 70, 72, 76, 78, 82, 83, 84, 85, 86, 91, 92, 93], "mycustommodel": 62, "input_dim": [62, 68], "output_dim": [62, 68], "super": [62, 67, 68, 71, 73, 75, 80, 82, 83, 84, 91], "layer1": 62, "512": [62, 70, 93], "relu": [62, 80, 81, 86], "layer2": 62, "updat": [62, 66, 68, 71, 78, 82, 83, 86, 91], "create_model_and_input_data": 62, "handl": [62, 63, 93], "model_typ": [62, 67, 77, 81], "n": [62, 63, 67, 71, 73, 75, 82, 83, 86, 91, 93], "high_precision_dtyp": 62, "my_custom_model": 62, "input_data": 62, "ensur": [62, 72, 83], "convent": 62, "batch": [62, 72, 73, 83, 92, 93], "sequenc": [62, 93], "length": [62, 91, 93], "featur": [62, 67, 75, 81, 84, 85, 90, 91], "typic": [62, 65, 67, 71, 73, 77, 80, 86, 91, 92], "come": [62, 65, 66, 70, 72, 73, 74, 76, 83, 84, 85, 92], "soon": [62, 72, 74, 83, 92], "file": [62, 63, 68, 70, 72, 75, 77, 82, 83, 88], "microbenchmark_quantization_config": 62, "yml": 62, "benchmark_mod": 62, "quantization_config_recipe_nam": 62, "int8wo": [62, 76], "int8dq": 62, "float8dq": [62, 72], "float8wo": 62, "output_dir": [62, 76], "result": [62, 65, 66, 67, 68, 73, 76, 82, 83, 84, 85, 86, 91], "model_param": 62, "small_bf16_linear": 62, "matrix_shap": 62, "small_sweep": 62, "min_pow": 62, "max_pow": 62, "torch_compile_mod": 62, "max": [62, 63, 65, 68, 73, 75, 82, 83, 86, 91], "autotun": [62, 63, 68, 73, 91], "runner": 62, "oss": 62, "databas": 62, "ci_microbenchmark_runn": 62, "benchmark_result": 62, "json": [62, 72, 77], "extra_info": 62, "arch": 62, "a100": [62, 67, 76, 90, 91], "sxm4": 62, "80gb": 62, "speedup": [62, 63, 65, 66, 67, 70, 72, 91, 93], "wrt": 62, "benchmark_valu": 62, "25": [62, 91, 93], "target_valu": 62, "depend": [62, 66, 71, 75, 78, 82, 83, 85, 93], "github": [62, 68, 72, 76, 91, 92], "action": [62, 77, 82, 83], "upload": 62, "verifi": [62, 68, 71, 75], "setup": [62, 72], "suit": [62, 63, 82, 84], "unittest": 62, "discov": 62, "memori": [62, 63, 65, 66, 67, 70, 75, 76, 78, 84, 85, 91, 92, 93], "miss": [62, 66], "properli": [62, 71], "instal": [62, 63, 65, 70, 72, 76, 82, 85, 93], "Not": [62, 66], "driver": 62, "basic": [62, 63, 73, 75], "analysi": [62, 66], "profil": [62, 63], "overhead": [62, 66, 68, 76, 77, 84, 91, 93], "possibl": [62, 65, 66, 82, 83, 84, 86, 91], "reproduc": [62, 72, 91, 93], "compon": [62, 65, 75, 77], "directori": [62, 70, 93], "read": [63, 75, 92], "overview": [63, 64, 68, 77], "page": [63, 68, 84, 90], "contribut": [63, 66, 68], "api": [63, 64, 65, 66, 68, 73, 75, 80, 81, 82, 83, 84, 85, 91], "trainabl": [63, 65, 67, 75], "parallel": [63, 70, 75, 77], "primit": [63, 75, 82], "slight": [63, 66], "variat": [63, 65], "quant_primit": [63, 73, 91], "mp": 63, "csrc": 63, "concept": [63, 65, 82, 84, 85, 86, 89, 91], "alreadi": [63, 75, 86], "could": [63, 65, 75, 81, 82, 84, 85, 86, 91], "context": [63, 84, 85, 91], "write": [63, 69, 80, 81, 82, 83], "own": [63, 66, 67, 69, 70, 73, 80, 82, 83, 86, 91], "torchaobasetensor": [63, 77], "help": [63, 65, 67, 70, 72, 77, 81, 82], "qdata": [63, 65], "With": [63, 75, 82, 84, 86, 93], "ll": [63, 65, 70, 75, 82, 83, 86], "mani": [63, 65, 66, 75], "still": [63, 65, 66, 67, 68, 82, 86, 92], "awai": 63, "abstract": [63, 65], "easier": [63, 86], "peopl": [63, 65, 71, 77, 86], "well": [63, 65, 66, 80, 82, 83, 86], "my_custom_op": 63, "my_mm_for_mp": 63, "input_tensor": [63, 65, 77], "weight_tensor": [63, 65, 77], "group_mm": 63, "whatev": 63, "think": [63, 77], "condit": 63, "so": [63, 65, 66, 67, 68, 70, 71, 75, 76, 82, 83, 86, 91, 93], "worri": 63, "purpos": [63, 65, 70, 75, 82, 92, 93], "h100": [63, 65, 76, 90, 92], "sm89": 63, "sm90": 63, "_choose_scale_float8": [63, 65], "_quantize_affine_float8": [63, 65], "_scaled_mm": [63, 65], "kerenel": 63, "f8f8bf16_rowwis": [63, 65], "reus": [63, 75, 91], "quant": [63, 65, 72, 77, 82, 85, 86, 91], "aim": [63, 66, 85], "fullgraph": [63, 68], "unnecessari": 63, "graph": [63, 80, 82, 83, 86, 91], "break": 63, "torch_log": 63, "output_cod": 63, "script": [63, 68, 72, 73, 75, 83, 84, 85, 89, 93], "inductor": [63, 80, 81, 82], "relev": [63, 65, 89], "safe": 63, "global": [63, 66, 75], "add_safe_glob": 63, "quantizetensortofloat8kwarg": [63, 65], "checkout": [63, 65, 78], "integr": [63, 66, 69, 70, 71, 72, 75, 84, 86, 93], "huggingfac": [63, 76], "deseri": [63, 82, 83], "save_pretrain": [63, 72, 76], "push_to_hub": [63, 72, 76, 77], "from_pretrain": [63, 67, 72, 76, 77, 92], "diffus": [63, 72], "talk": [63, 65, 72], "fsdp": [63, 65, 93], "mydtypetensor": 63, "developer_api_guid": 63, "folder": [63, 72, 82, 83, 90], "cover": [63, 82, 85, 86, 89], "torchchat": 63, "dtensor": [63, 75, 93], "past": [63, 66], "adapt": [63, 70, 73], "intens": 63, "sens": [63, 65, 75], "benchmark_aq": 63, "quick": 63, "interest": [63, 66, 75], "print_op_and_shap": 63, "torch_func": 63, "built": [63, 70, 75], "_c": 63, "tensorbas": 63, "benchmark_your_kernel": 63, "feel": [63, 65, 66, 75, 77], "free": [63, 65, 75], "probabl": 63, "futur": [63, 73, 76, 77, 82, 83, 84, 86, 91], "llama": [63, 67, 72, 76, 77, 78, 81, 91, 92], "llama2": 63, "llama3": [63, 67, 70, 76, 91, 92, 93], "sam": 63, "friendli": 63, "techniqu": [63, 66, 67, 70, 71, 72, 73, 75, 77, 90], "profile_path": 63, "chrome": 63, "trace": 63, "let": [63, 65, 66, 68, 73, 75, 86, 91], "u": [63, 66, 81, 91], "know": [63, 75, 93], "technic": 64, "contributor": [64, 65, 68], "guid": [64, 65, 68, 69, 72, 81, 93], "benchmark": [64, 68, 70, 76, 80, 81, 84, 85], "lai": 65, "awq": [65, 90], "gptq": [65, 91], "int4tensor": 65, "int4preshuffledtensor": 65, "uint1": 65, "uint7": 65, "float3": 65, "overload": [65, 66], "term": [65, 66, 82, 86], "extra": [65, 72], "No": [65, 66, 67, 71, 91], "what": [65, 66, 67, 70, 72, 73, 77, 82, 86, 89, 91], "end": [65, 66, 67, 70, 72, 75, 76, 77, 83, 86, 91], "float8_e4m3fnuz": 65, "float8_e5m2fnuz": 65, "float8_e8m0fnu": 65, "placehold": [65, 85], "real": [65, 67, 80, 82, 86], "pr": 65, "shell": 65, "limit": [65, 67, 70, 75, 77, 82, 93], "offici": [65, 70], "dervi": 65, "mxfp8": [65, 90, 91], "mxfp4": [65, 67, 90], "preicison": 65, "choose_qparam": [65, 91], "zero_point": [65, 66, 73, 75, 86, 91], "mention": [65, 82], "accommod": 65, "choose_qparams_affine_with_min_max": 65, "min": [65, 73, 75, 82, 86], "raw": 65, "quantize_fp8_row": 65, "int_matmul": 65, "int_scaled_matmul": 65, "reli": [65, 66, 73, 75, 80], "handwritten": 65, "On": [65, 91, 93], "top": [65, 70, 75, 81, 82, 83, 84, 85, 91], "glue": 65, "everyth": 65, "togeth": [65, 72, 82, 84, 86], "build": [65, 66, 70, 75, 77, 78, 82], "anoth": [65, 66, 75, 82, 86], "side": 65, "uint8": [65, 73, 86], "swizzl": 65, "dtpype": 65, "float8rowwisetensor": 65, "float8blockwisetensor": 65, "confus": [65, 66, 82], "close": [65, 66], "low_precision_v": 65, "high_precision_v": 65, "procedur": 65, "especi": [65, 66, 71, 84, 85], "bitwidth": [65, 86], "codebook": 65, "look": [65, 66, 70, 81, 82, 83, 84, 85], "index": [65, 66, 72, 78, 85], "vector": [65, 66, 84], "kmean": 65, "cluster": [65, 70], "tradition": 65, "demonstr": [65, 67, 68, 70, 72, 75, 81, 83, 93], "sai": [65, 76, 77, 86], "below": [65, 66, 70, 75, 76, 77, 81, 89, 91, 93], "explain": [65, 81, 84], "introduct": [65, 72, 78], "simplest": [65, 66], "form": [65, 66, 70], "easi": [65, 72], "linear_modul": 65, "requires_grad": [65, 67, 73, 75, 77], "runtim": [65, 68, 82], "question": [65, 66, 71, 75, 86, 93], "activation_granular": 65, "act_quant_kwarg": 65, "quantized_weight": [65, 77], "float8_dtyp": 65, "instruct": [65, 67, 72, 82, 83, 84, 92], "haven": 65, "seen": 65, "pt2": [65, 75, 84], "fit": [65, 67, 71, 92], "autoround": 65, "multitensor": 65, "sure": [65, 72, 86], "open": [65, 66, 91], "describ": [65, 66, 71, 82, 83, 89], "advis": 65, "focus": [65, 66, 67, 70, 72], "face": [65, 66, 69, 72, 82], "finetun": [65, 72], "quantized_train": 65, "extend": [65, 66, 84, 91], "progress": [65, 76, 77], "lot": [65, 66], "connect": [65, 86], "walk": [65, 73, 75, 81, 84, 89], "float8dynamicactivationfloat8weightconfig": [65, 76, 91, 93], "happen": [65, 75, 82, 84], "len": [65, 72, 77, 82, 83, 86], "_choose_quant_func_and_quantize_tensor": 65, "omit": [65, 70, 82, 83, 84], "relat": [65, 66], "xq": 65, "reshap": [65, 82, 83], "wq": 65, "x_scale": [65, 82], "w_scale": 65, "out_shap": 65, "neural": [66, 81, 84], "network": [66, 75, 81, 84], "latenc": 66, "By": [66, 91], "carefulli": 66, "achiev": [66, 67, 68, 70, 73, 75, 83, 84], "signific": [66, 72, 91], "pai": 66, "reason": [66, 71, 92], "low": [66, 75, 76, 81, 91], "price": 66, "qualiti": [66, 67, 76], "f1": 66, "problem": [66, 75], "research": [66, 89, 92], "fragment": 66, "rightfulli": 66, "show": [66, 70, 72, 77, 80, 82, 83], "time": [66, 68, 75, 76, 81, 82, 83, 89, 91, 93], "spent": [66, 93], "figur": [66, 82], "place": [66, 81, 82, 83, 84, 85], "dens": [66, 90], "solv": [66, 72, 75], "onc": [66, 67, 91, 92], "focu": [66, 75], "realli": 66, "push": [66, 72, 76, 77], "concret": [66, 86], "hope": [66, 91], "modular": 66, "acceler": [66, 72, 76, 93], "nice": 66, "scratch": [66, 89], "minim": [66, 81, 84, 85], "loss": [66, 67, 70, 82, 83, 92, 93], "recov": [66, 67, 78, 83, 92], "algorthim": 66, "realiz": 66, "improv": [66, 67, 70, 72, 82, 85, 86, 90, 91], "trade": [66, 72, 93], "off": [66, 72, 93], "theoret": 66, "gain": [66, 72, 85], "float16": [66, 90], "yield": [66, 67], "2x": [66, 68, 72, 93], "analog": 66, "would": [66, 68, 75, 83, 85], "fix": [66, 73], "50": [66, 70, 73, 81, 82, 84, 85, 91], "expect": [66, 70, 75, 81, 82, 84, 85, 86], "matric": [66, 67], "unstructur": 66, "share": 66, "mitig": [66, 67], "retrain": 66, "neglig": 66, "even": [66, 67, 70, 86], "area": 66, "agre": 66, "upon": 66, "consensu": 66, "mind": 66, "thought": 66, "subproblem": 66, "find": [66, 67, 82, 86], "my": [66, 83], "answer": 66, "independ": 66, "frontend": [66, 84], "arbitrari": 66, "collect": [66, 70], "handoff": 66, "piec": 66, "natur": [66, 75, 82, 86], "becaus": [66, 67, 68, 70, 71, 75, 83, 86, 91], "clear": 66, "contract": 66, "7x": 66, "advantag": 66, "anticip": 66, "solut": 66, "third": [66, 91], "parti": [66, 91], "to_sparse_semi_structur": 66, "sparsesemistructuredtensor": 66, "weightnormsparsifi": 66, "half": 66, "subnetwork": 66, "sparse_config": 66, "named_modul": [66, 91], "tensor_fqn": 66, "sparse_block_shap": 66, "zeros_per_block": 66, "fakespars": 66, "fundament": [66, 83], "manipul": 66, "paramer": 66, "parameter": 66, "necessari": [66, 73, 75, 81, 82, 83, 84, 85, 91], "ve": [66, 72, 91], "suitabl": [66, 84], "spot": 66, "definit": [66, 77], "academia": 66, "industri": 66, "often": [66, 75], "interchang": 66, "thing": [66, 71, 75, 82], "distinct": 66, "pretrain": [66, 72, 81, 82, 83, 84, 93], "avoid": [66, 71, 91], "try": [66, 67, 75, 82, 91], "roughli": [66, 91], "idea": 66, "behind": 66, "doesn": [66, 83, 86, 91], "box": [66, 70, 84], "itself": [66, 75], "those": [66, 72, 73, 75, 91], "multipli": 66, "loos": 66, "speak": 66, "tightli": 66, "coupl": [66, 75], "csc": 66, "fbgemm": 66, "qnnpack": 66, "descript": [66, 81], "coo": 66, "sparse_coo": 66, "coordin": 66, "locat": 66, "bsr": 66, "sparse_bsr": 66, "veri": [66, 77, 83, 91], "similar": [66, 67, 73, 83, 84, 93], "except": [66, 75, 86], "individu": [66, 91], "scalar": [66, 82], "dimension": 66, "csr": 66, "sparse_csr": 66, "sparse_csc": 66, "column": 66, "indic": [66, 86], "compact": 66, "sparse_matrix": 66, "1d": 66, "indexptr": 66, "storag": 66, "\u00bd": 66, "bitmask": 66, "2bit": 66, "unprun": 66, "quit": [66, 75], "simpl": [66, 68, 73, 75, 81, 84, 85], "successfulli": [66, 67], "These": [66, 67, 75, 81, 82, 83, 86, 91], "broken": 66, "down": 66, "equal": [66, 71], "sensit": 66, "effect": [66, 73, 75, 84, 85, 86], "best": [66, 68, 84, 91], "subsequ": [66, 75, 84, 85], "infinit": 66, "lost": 66, "degre": 66, "drop": 66, "give": [66, 72, 75], "curv": [66, 70, 93], "proxi": 66, "much": [66, 67, 86], "aforement": 66, "less": [66, 75, 78, 82], "smallest": 66, "absolut": 66, "consid": 66, "v": [66, 70, 82, 86, 93], "scope": 66, "impli": 66, "respect": [66, 83], "pro": [66, 72, 91, 92], "con": 66, "potenti": [66, 73, 81, 82, 84, 85], "sub": 66, "tradeoff": [66, 67, 76], "span": 66, "over": [66, 70, 82, 83, 91, 93], "threshold": 66, "normal": [66, 82, 83, 91], "complex": 66, "constant": [66, 75, 82], "ctr_mobile_fe": 66, "paper": [66, 67, 89], "score": 66, "w": [66, 77], "tenosr": 66, "udpat": 66, "cannot": [66, 73, 77], "histori": 66, "regrow": 66, "dw": 66, "via": [66, 81, 93], "backprop": 66, "pat": 66, "unmask": 66, "resid": 66, "salienc": 66, "lowest": 66, "l1": 66, "shown": [66, 67, 72, 83, 86, 92], "abl": [66, 75, 77, 82, 86, 91], "repeat": [66, 82, 83], "shot": [66, 67], "movement": 66, "tune": [66, 69, 70, 72, 81, 92], "2005": 66, "07683": 66, "rank": [66, 75], "wx": 66, "sqx": 66, "q": [66, 82], "usual": 66, "sort": 66, "wise": 66, "reconstruct": [66, 77], "seek": [66, 71], "random": [66, 72, 82, 83], "randomli": 66, "tri": 66, "remedi": 66, "line": [66, 70, 76, 91], "sometim": [66, 91], "item": [66, 89], "ultim": [66, 73], "complic": [66, 82], "literatur": 66, "vision": 66, "nlp": [66, 84, 89], "simpli": [66, 67, 73, 75], "again": [66, 82, 86], "iter": [66, 82, 83, 91], "ctr_feed": 66, "na": [66, 91], "multimask": 66, "search": 66, "pyspeech": 66, "fastna": 66, "approach": [66, 75, 81, 84, 85, 93], "knowledg": [66, 89], "distil": 66, "pdf": 66, "2204": 66, "09656": 66, "arrang": 66, "recal": 66, "faster": [66, 68, 78, 91, 92, 93], "counterpart": 66, "slower": 66, "suffici": 66, "At": [66, 82], "98": [66, 91], "exhibit": [66, 92], "penalti": 66, "expens": [66, 75], "dictat": 66, "characterist": 66, "highest": 66, "wouldn": [66, 75], "visual": 66, "fig": 66, "4x4": 66, "benchmak": 66, "serv": [67, 68, 69, 70, 75, 76, 85, 93], "leverag": [67, 70, 72, 75, 84, 85, 91, 92], "partner": [67, 70, 72], "showcas": [67, 70, 72], "blog": [67, 92], "resourc": [67, 75], "introduc": [67, 81, 82, 84, 85, 86], "small": [67, 68, 91, 93], "freez": [67, 83, 84, 85], "inevit": 67, "presum": 67, "recent": [67, 78, 91], "releas": [67, 84, 91], "1b": [67, 76, 77], "3b": [67, 92], "llamaguard": 67, "8b": [67, 68, 70, 76, 78, 91, 92, 93], "distribut": [67, 70, 73, 75, 77, 81, 92, 93], "command": [67, 70, 91, 92, 93], "regular": [67, 81, 84, 85], "nnode": [67, 92], "nproc_per_nod": [67, 92], "full_finetune_distribut": 67, "llama3_2": 67, "3b_full": 67, "batch_siz": [67, 68, 71, 72, 73, 82, 83, 91], "_component_": 67, "qat_distribut": [67, 92], "3b_qat_ful": 67, "evalu": [67, 68, 83], "wa": [67, 75, 83, 91, 92, 93], "llama3_2_3b": 67, "fullmodelhfcheckpoint": 67, "checkpoint_fil": 67, "00001": 67, "00002": 67, "safetensor": [67, 76], "int8dynactint4weightquant": 67, "hellaswag": [67, 72], "wikitext": [67, 91, 92], "eleuther_ev": 67, "eleuther_evalu": 67, "task": [67, 72, 92], "fullmodeltorchtunecheckpoint": 67, "8da4w": [67, 72], "ckpt": 67, "llama3_token": 67, "tmp": 67, "meta": [67, 71, 76, 77, 86, 91], "stderr": 67, "acc": [67, 82, 83], "5021": 67, "0050": 67, "acc_norm": 67, "6797": 67, "0047": 67, "bits_per_byt": 67, "6965": 67, "byte_perplex": 67, "6206": 67, "word_perplex": 67, "13": [67, 91, 92, 93], "2199": 67, "openassist": 67, "oasst1": 67, "dataset": [67, 70, 72, 81, 84, 85, 92], "higher": [67, 70, 75, 76, 81, 82, 84, 85, 92], "69": [67, 73], "overal": [67, 68, 78, 82, 86], "vanilla": [67, 92], "lora": [67, 92], "89x": [67, 78, 92], "36": [67, 70, 72, 91, 92], "qat_lora_finetune_distribut": [67, 92], "3b_qat_lora": 67, "fsdp2": [67, 70, 92, 93], "yaml": [67, 92], "complet": [67, 72, 81, 85, 91, 92], "qat_out": [67, 92], "quatiz": [67, 92], "hood": [67, 91], "mini": [67, 72], "gpu": [67, 68, 70, 76, 77, 80, 81, 89, 91, 92], "accordingli": 67, "get_model": [67, 92], "vocab_s": [67, 92], "num_lay": [67, 92], "num_head": [67, 92], "num_kv_head": [67, 92], "embed_dim": [67, 92], "2048": [67, 70, 91, 92, 93], "max_seq_len": [67, 92], "001": [67, 92], "momentum": [67, 83, 92], "9": [67, 70, 78, 91, 92, 93], "weight_decai": [67, 92], "1e": [67, 70, 92, 93], "loss_fn": [67, 92], "crossentropyloss": [67, 82, 83, 92], "randint": [67, 92], "next": [67, 70, 73, 82, 83, 84, 85, 91], "attun": 67, "benefici": 67, "readi": [67, 68, 70, 72, 73, 75, 83], "legaci": [67, 92], "offer": [67, 68, 75, 82], "unlik": [67, 73, 91], "int8dynactint4weightqatquant": [67, 92], "qat_quant": [67, 92], "insert": [67, 68, 73, 80, 81, 82, 83, 84, 85, 86, 92], "int8dynactint4weightqatlinear": [67, 92], "int8dynactint4weightlinear": [67, 92], "fraction": 67, "therebi": [67, 92], "significantli": [67, 68, 81, 82, 84, 85], "footprint": 67, "extens": [67, 75, 82, 84], "addition": [67, 84, 85, 92], "frozen": 67, "further": [67, 75, 81, 82, 83, 84], "nf4": 67, "express": [67, 75, 80, 81, 82, 83, 86, 91], "nf4tensor": 67, "cleanli": 67, "to_nf4": 67, "frozennf4linear": 67, "in_dim": 67, "out_dim": 67, "quantization_kwarg": 67, "requires_grad_": 67, "nf4_weight": 67, "though": [67, 75, 91], "baselin": [67, 70, 72, 82, 92, 93], "reap": 67, "incorpor": 67, "loralinear": 67, "lora_finetune_single_devic": 67, "3b_qlora_single_devic": 67, "invok": [67, 84], "loraconfig": 67, "get_peft_model": [67, 92], "automodelforcausallm": [67, 72, 76, 77], "torchaoconfig": [67, 72, 76, 77], "base_model": 67, "quantization_config": [67, 72, 76, 77, 85], "peft_config": 67, "throughput": [67, 68, 70, 72, 91, 93], "torchtitan": [67, 93], "enable_fp8_train": 67, "fp8_recipe_nam": 67, "experi": [67, 70, 85, 91, 92], "saw": 67, "experiment_nam": 67, "tok": [67, 91], "peak_mem_reserv": 67, "6502": 67, "143": 67, "000": 67, "30": [67, 70, 82], "090": 67, "fp8_nonam": 67, "7205": 67, "386": 67, "816": 67, "010": 67, "266": 67, "fp8_tensorwis": 67, "7222": [67, 92], "198": 67, "11": [67, 70, 91], "074": [67, 70], "fp8_rowwis": 67, "6387": 67, "968": 67, "756": 67, "29": [67, 70, 91], "158": 67, "096": 67, "fp8_rowwise_with_gw_hp": 67, "7573": 67, "698": 67, "480": 67, "516": 67, "908": 67, "hellaswag_acc": 67, "wikitext_word_perplex": 67, "533": [67, 91], "12": [67, 70, 78, 85, 86, 91, 92], "407": [67, 70], "414": 67, "007": 67, "412": 67, "005": 67, "420": [67, 92], "013": [67, 70], "534": 67, "416": 67, "009": 67, "entri": 68, "mutat": 68, "toylinearmodel": [68, 71, 73, 91], "hidden_dim": 68, "has_bia": 68, "linear2": [68, 71, 73, 75, 91], "eval": [68, 71, 72, 73, 80, 81, 83, 84, 85, 91, 92], "model_w16a16": 68, "model_w8a8": 68, "chapter": 68, "remain": [68, 84, 85], "unchang": 68, "__name__": 68, "approxim": 68, "disk": 68, "o": [68, 82, 83], "state_dict": [68, 70, 71, 82, 83, 93], "pth": [68, 70, 82, 83, 93], "original_s": 68, "getsiz": [68, 82, 83], "quantized_s": 68, "2f": [68, 82, 83], "mb": [68, 71, 82, 83, 88], "00x": 68, "00mb": 68, "warmup": [68, 70], "synchron": 68, "100": [68, 75, 82, 83, 91, 93], "original_tim": 68, "quantized_tim": 68, "03x": 68, "larger": [68, 93], "enough": [68, 91], "toi": [68, 70, 73, 75, 84, 93], "address": [68, 82], "vllm": [68, 69, 76, 91], "lm": [68, 72, 91], "visit": 68, "forget": 68, "good": [68, 75, 86], "eager": [69, 81, 82, 83, 84, 85, 86], "qlora": [69, 72], "sglang": [69, 76], "hug": [69, 72], "advanc": [69, 73, 75, 81, 84, 85], "5x": [70, 78, 93], "34": [70, 91], "43x": 70, "2k": [70, 93], "h200": 70, "latest": [70, 78, 91], "offic": 70, "sever": [70, 77, 81, 86], "popular": 70, "flagship": 70, "quickli": [70, 75], "batteri": 70, "fork": 70, "virtual": 70, "environ": [70, 72], "conda": 70, "venv": 70, "download": [70, 72, 78, 82, 83, 85, 87, 89, 93], "job": 70, "root": [70, 72], "launch": 70, "ngpu": 70, "config_fil": 70, "train_config": 70, "llama3_8b": 70, "toml": 70, "run_train": 70, "sh": [70, 72, 91, 93], "hyperparamet": 70, "edit": [70, 72], "flag": [70, 78, 83], "termin": 70, "rank0": 70, "titan": 70, "2025": 70, "06": 70, "04": 70, "08": [70, 91], "51": [70, 91], "48": 70, "info": 70, "2254": 70, "27": 70, "34gib": 70, "28": 70, "78": 70, "tp": [70, 77, 93], "375": 70, "tflop": 70, "21": [70, 91], "73": [70, 73, 91], "mfu": 70, "20": [70, 72, 83], "58": [70, 78], "557": 70, "7069": 70, "99gib": 70, "62": [70, 91], "7": [70, 72, 84, 85, 90, 91, 93], "034": 70, "35": [70, 72, 73, 91], "41": [70, 72], "19": [70, 91], "52": 70, "224": [70, 73, 81, 82, 83, 84, 85], "9196": 70, "022": 70, "406": [70, 82, 83], "65": [70, 91, 93], "904": 70, "1423": 70, "014": 70, "23": [70, 73, 91], "As": [70, 82, 86], "7k": 70, "99gb": 70, "peak": [70, 72, 76, 91, 93], "against": 70, "02": 70, "37": 70, "404": 70, "2611": 70, "22gib": 70, "595": 70, "47": [70, 91, 93], "49": [70, 73], "027": 70, "4260": 70, "89gib": 70, "344": 70, "367": 70, "39": [70, 91, 92, 93], "03": [70, 91, 93], "01": [70, 91], "988": 70, "9482": 70, "321": 70, "366": 70, "14": [70, 91, 93], "991": 70, "1183": 70, "300": 70, "364": 70, "89": 70, "40": [70, 91, 92], "4659": 70, "291": 70, "84": 70, "769": 70, "gc": 70, "peform": 70, "period": 70, "3k": 70, "89gb": 70, "11x": 70, "nearli": 70, "performan": 70, "648": 70, "2648": 70, "28gib": 70, "71": [70, 91], "26": [70, 92], "475": 70, "9106": [70, 89], "91gib": 70, "53": [70, 72], "503": 70, "434": 70, "43": [70, 91], "94": [70, 82, 91], "166": 70, "0774": 70, "663": 70, "443": 70, "44": [70, 73], "87": 70, "885": 70, "3233": 70, "643": 70, "442": 70, "66": [70, 72, 73, 92], "76": 70, "613": 70, "6150": [70, 93], "637": 70, "72": [70, 72], "6k": 70, "91gb": 70, "21x": [70, 72], "tl": 70, "dr": 70, "priorit": 70, "stabil": 70, "cost": [70, 73], "slightli": [70, 75], "impact": [70, 72, 77], "outlier": [70, 93], "caus": [70, 91], "underflow": 70, "8xh100": [70, 93], "convert_to_float8_train": [70, 93], "recurs": 70, "kind": [70, 82], "snippet": [70, 82, 83], "float8_linear_util": [70, 93], "float8_linear": [70, 93], "adamw": [70, 93], "label": [70, 93], "fake_label": [70, 93], "ones_lik": [70, 93], "mse_loss": [70, 93], "model_state_dict": [70, 93], "optimizer_state_dict": [70, 93], "explor": [70, 85], "few": [70, 75, 82, 83, 92], "tempfil": [71, 76], "get_model_size_in_byt": 71, "ref": [71, 82], "namedtemporaryfil": 71, "m_load": 71, "load_state_dict": [71, 82, 83, 93], "assign": [71, 91], "assert": [71, 73, 75, 77, 86], "float_weight1": 71, "float_weight2": 71, "quantized_weight1": 71, "quantized_weight2": 71, "go": [71, 75, 86], "techinqu": 71, "4x": [71, 72], "0625": 71, "affine_quantized_tensor": 71, "deploi": 72, "engin": 72, "seamlessli": [72, 75, 84, 85], "seamless": [72, 84, 93], "hf": [72, 76], "pip": [72, 76, 78, 81, 82], "url": [72, 78, 85], "whl": [72, 78, 85], "nightli": [72, 78, 91], "cu128": [72, 78], "hub": [72, 76, 77], "server": [72, 77], "phi": 72, "fp8": 72, "microsoft": 72, "o3": 72, "client": 72, "curl": 72, "localhost": 72, "8000": 72, "v1": 72, "chat": 72, "content": 72, "messag": 72, "role": 72, "me": 72, "short": 72, "larg": [72, 75, 84, 93], "temperatur": 72, "top_p": 72, "95": [72, 91], "top_k": 72, "max_token": 72, "32768": 72, "vram": 72, "15x": 72, "littl": [72, 77], "packag": [72, 76], "git": [72, 76], "com": [72, 76, 91, 92], "autotoken": [72, 76], "pipelin": 72, "manual_se": [72, 82, 83], "model_path": 72, "device_map": [72, 76, 77], "trust_remote_cod": 72, "ai": 72, "assist": 72, "eat": 72, "banana": 72, "dragonfruit": 72, "smoothi": 72, "blend": 72, "milk": 72, "honei": 72, "salad": 72, "mix": [72, 81, 84, 85], "slice": [72, 77], "lemon": 72, "juic": 72, "equat": 72, "pipe": [72, 76], "text": 72, "generation_arg": 72, "max_new_token": 72, "500": [72, 91], "return_full_text": 72, "do_sampl": 72, "generated_text": 72, "design": [72, 77, 81, 82, 86, 91], "lm_head": 72, "ti": 72, "autoprocessor": 72, "modeling_util": 72, "find_tied_paramet": 72, "model_id": [72, 76], "untied_model": 72, "getattr": [72, 77], "get_text_config": 72, "tie_word_embed": 72, "setattr": [72, 75], "_tied_weights_kei": 72, "user_id": 72, "your_user_id": 72, "model_nam": [72, 81, 84, 85], "save_to": [72, 76], "save_to_local_path": 72, "int8dynamicactivationintxweightconfig": [72, 76], "intxweightonlyconfig": [72, 76, 91], "fqntoconfig": [72, 77], "untied_model_id": 72, "untied_model_local_path": 72, "embedding_config": 72, "quant_config": 72, "embed_token": 72, "quant_typ": [72, 76, 77], "include_embed": 72, "untie_embedding_weight": 72, "modules_to_not_convert": 72, "quantized_model": [72, 75, 76, 81, 82, 83], "safe_seri": [72, 76, 77], "pte": 72, "cd": 72, "install_requir": 72, "phi_4_mini": 72, "convert_weight": 72, "pytorch_model": 72, "bin": 72, "pytorch_model_convert": 72, "export_llama": 72, "kv": 72, "use_sdpa_with_kv_cach": 72, "get_bos_id": 72, "199999": 72, "get_eos_id": 72, "200020": 72, "max_seq_length": 72, "max_context_length": 72, "output_nam": 72, "phi4": 72, "phone": 72, "io": 72, "2gb": 72, "iphon": 72, "17": [72, 91, 92], "sec": 72, "test": [72, 76, 82, 84, 89, 91], "har": 72, "eleutherai": 72, "lm_eval": 72, "model_arg": 72, "reset_peak_memory_stat": 72, "prompt": [72, 76], "hei": 72, "consciou": 72, "templated_prompt": 72, "apply_chat_templ": 72, "add_generation_prompt": 72, "templat": [72, 87, 88], "return_tensor": 72, "pt": 72, "generated_id": 72, "output_text": 72, "batch_decod": 72, "skip_special_token": 72, "clean_up_tokenization_spac": 72, "respons": 72, "mem": 72, "max_memory_reserv": 72, "1e9": 72, "02f": 72, "gb": [72, 91, 93], "hello": [72, 76], "ye": [72, 91], "am": 72, "digit": 72, "todai": 72, "70": [72, 73, 91], "bench": [72, 91], "vllm_disable_compile_cach": 72, "project": 72, "vllm_use_precompil": 72, "sharegpt": 72, "wget": 72, "co": 72, "anon8231489123": 72, "sharegpt_vicuna_unfilt": 72, "resolv": 72, "sharegpt_v3_unfiltered_cleaned_split": 72, "tree": 72, "num": 72, "benchmark_serv": 72, "16x": 72, "14x": 72, "num_prompt": [72, 91], "req": 72, "57": [72, 73, 93], "1000": [72, 84], "68": [72, 93], "80": 72, "ml": 72, "eas": 72, "accept": [72, 86, 92], "fly": [73, 76], "affinequantizedminmaxobserv": 73, "record": 73, "welcom": 73, "desir": [73, 91], "averag": [73, 82, 83], "histogram": [73, 82], "act_ob": 73, "finfo": [73, 91], "zero_point_dtyp": [73, 91], "weight_ob": 73, "observedlinear": 73, "observed_input": 73, "observed_weight": 73, "from_float": [73, 75], "float_linear": 73, "observed_linear": 73, "_replace_with_custom_fn_if_matches_filt": 73, "insert_observers_": 73, "lambda": [73, 77, 92], "replacement_fn": 73, "copied_act_ob": 73, "copied_weight_ob": 73, "popul": 73, "feed": 73, "simpler": [73, 82], "quantizedlinear": [73, 75], "isn": [73, 91], "strictli": 73, "to_affine_quantized_intx_stat": 73, "act_scal": [73, 86], "act_zero_point": 73, "calculate_qparam": [73, 86], "weight_scal": [73, 82, 86], "weight_zero_point": [73, 82], "qweight": 73, "qinput": 73, "from_observ": 73, "quantized_linear": [73, 82], "begin": [73, 75], "dataclass": [73, 77, 86], "transform_modul": [73, 77], "register_quantize_module_handl": [73, 77], "staticquantconfig": 73, "_apply_static_qu": 73, "associ": 73, "identifi": [73, 86], "is_observed_linear": 73, "optimizedmodul": 73, "_orig_mod": 73, "0237": 73, "tensor_impl": 73, "plainaqttensorimpl": 73, "142": 73, "31": [73, 86, 91], "113": 73, "157": 73, "59": [73, 91], "160": 73, "150": 73, "67": [73, 78], "241": 73, "238": 73, "235": 73, "228": 73, "255": [73, 86], "201": 73, "114": 73, "236": 73, "88": [73, 82, 91], "83": [73, 91], "109": 73, "209": 73, "92": [73, 91], "184": 73, "141": 73, "110": 73, "0009": 73, "0010": 73, "130": 73, "122": 73, "132": 73, "125": 73, "126": 73, "129": 73, "127": [73, 75, 85, 86], "133": 73, "124": [73, 91], "131": 73, "135": 73, "136": 73, "_layout": 73, "foundat": 75, "autograd": [75, 86, 93], "highlight": [75, 78, 89], "interpos": 75, "namespac": 75, "continu": [75, 76, 83, 84, 85, 86, 91], "obviou": 75, "int8quantizedlinear": 75, "finer": 75, "intercept": 75, "contrast": [75, 92], "long": [75, 82, 91], "clunki": 75, "distributedlinear": 75, "duplic": 75, "bypass": 75, "wrap": [75, 84, 85], "outer": 75, "inner": 75, "allgath": 75, "bandwidth": [75, 91, 93], "stai": [75, 93], "exactli": [75, 92], "zoo": 75, "podcast": 75, "edward": 75, "yang": 75, "int8_symmetric_quant": 75, "fp32_tensor": 75, "quant_min": [75, 85, 86], "quant_max": [75, 85, 86], "min_val": 75, "amin": 75, "keepdim": [75, 82, 83], "max_val": 75, "amax": 75, "min_val_neg": 75, "zeros_lik": 75, "max_val_po": 75, "view": [75, 82, 83], "clamp": [75, 82, 92], "w_int8": 75, "new_linear": 75, "left": [75, 86], "toymodel": 75, "float_model": [75, 80, 81, 82, 83, 84, 85], "child": 75, "named_children": 75, "drawback": 75, "won": 75, "suppos": 75, "clean": [75, 92], "eleg": 75, "pretti": 75, "overrid": 75, "almost": 75, "shard": [75, 77], "ragged": 75, "rag": 75, "nestedtensor": 75, "who": 75, "link": [75, 89, 90], "why": [75, 89], "googl": [75, 92], "collab": 75, "flopcount": 75, "memorytrack": 75, "bare": 75, "bone": 75, "int8symmetrictensor": 75, "hold": [75, 76, 91], "int_data": 75, "staticmethod": 75, "_dynamo": [75, 91], "_make_wrapper_subclass": [75, 77], "stride": 75, "storage_offset": 75, "ndim": 75, "extra_metadata": 75, "outer_s": [75, 77], "outer_strid": [75, 77], "undo": 75, "repr": 75, "float_tensor": 75, "ahead": 75, "insid": 75, "int8_tensor": 75, "op_implementations_dict": 75, "assertionerror": 75, "conveni": 75, "register_op": 75, "_op": 75, "opoverload": 75, "impl_decor": 75, "op_impl": 75, "done": [75, 91, 92], "wrapper": [75, 80, 84], "particular": 75, "largest": 75, "tell": 75, "desugar": 75, "surfac": 75, "coverag": [75, 81, 82, 84, 85], "brute": 75, "forc": 75, "repeatedli": 75, "log": 75, "loggingtensor": 75, "_python_dispatch": [75, 77], "return_and_correct_alias": [75, 77], "int8_mm": 75, "int8_view_op": 75, "out_data": 75, "out_scal": [75, 82], "notic": 75, "hit": 75, "background": 75, "decomposit": 75, "live": 75, "decomp": 75, "shrink": 75, "author": [75, 81, 82, 83, 84, 85, 86, 89], "But": [75, 77, 86, 91], "pain": 75, "rather": 75, "worth": 75, "written": 75, "differenti": 75, "nuanc": 75, "longer": [75, 82, 83], "had": [75, 82], "transpos": 75, "That": 75, "transposit": 75, "got": [75, 82, 86], "propag": [75, 82, 84, 85], "fact": 75, "themselv": [75, 82], "pointwis": [75, 84, 85], "were": [75, 91], "might": [75, 77, 82, 86], "unwrap": 75, "dim0": 75, "dim1": 75, "confirm": 75, "quantized_model_module_swap": 75, "quantized_model_subclass": 75, "subclass_param": 75, "no_grad": [75, 80, 81, 82, 83, 84, 85], "out_module_swap": 75, "allclos": 75, "out_compil": 75, "seri": 75, "discuss": 75, "float8dynamicactivationint4weightconfig": [76, 91], "use_hqq": [76, 77], "torch_dtyp": 76, "fluxpipelin": 76, "fluxtransformer2dmodel": 76, "black": 76, "forest": 76, "lab": 76, "flux": 76, "subfold": 76, "cat": [76, 86], "sign": [76, 85], "world": [76, 77], "imag": [76, 80, 81, 82, 83, 84, 85], "num_inference_step": 76, "guidance_scal": 76, "png": 76, "temporarydirectori": 76, "tmp_dir": 76, "uncom": 76, "usernam": [76, 77], "statu": [76, 77, 91], "becom": [76, 82], "stabl": [76, 78, 90, 91], "int4wo": 76, "team": [76, 77], "track": [76, 77, 91], "retain": 76, "thoroughli": 76, "e2": 77, "_type": 77, "_data": 77, "capabl": [77, 82, 84, 91], "self_attn": 77, "k_proj": [77, 92], "mlp": 77, "gate_proj": [77, 92], "narrow": 77, "host": 77, "state": 77, "chunk": 77, "heavi": 77, "codebas": [77, 93], "fn": 77, "ctx": 77, "new_tensor": 77, "__class__": 77, "principl": 77, "mynewquantconfig": 77, "classvar": 77, "myquantizedtensor": 77, "tensor_data_attr": 77, "quantized_data": 77, "tensor_attribut": 77, "attr": 77, "fill_default": 77, "notimplementederror": 77, "_my_quant_transform": 77, "my_quantization_funct": 77, "use_cutlass_kernel": 77, "my_cutlass_linear": 77, "my_triton_linear": 77, "standard": 77, "disappear": 77, "unless": 77, "extrem": 77, "sole": 77, "explicitli": [77, 86], "spooki": 77, "distanc": 77, "due": [77, 81, 86], "workaround": 77, "2338": 77, "detect": 77, "illustr": [77, 91], "70b": 78, "gemma3": [78, 92], "4b": [78, 92], "cu126": 78, "cu129": 78, "isol": 78, "use_cuda": 78, "use_xpu": 78, "use_cpp": 78, "tba": 79, "recogn": [80, 86], "decis": 80, "deleg": [80, 82], "x86inductorquant": [80, 84], "quantize_pt2": [80, 81, 82, 83, 84, 85], "prepare_pt2": [80, 81, 82, 84, 85], "x86_inductor_quant": [80, 84], "get_default_x86_inductor_quantization_config": [80, 84], "calibr": [80, 81, 83, 84, 85], "data_load": [80, 82, 83, 84, 85], "program": [80, 82, 83, 84, 86], "captur": [80, 82, 83, 86], "expos": [80, 82, 83], "set_glob": [80, 82, 83, 84, 85], "xiq": [80, 84], "prepare_qat_pt2": [80, 83, 84], "sample_inference_data": 80, "convert_pt2": [80, 81, 82, 83, 84, 85], "_inductor": [80, 84], "cpp_wrapper": [80, 84], "optimized_model": [80, 81, 84, 85], "converted_model": [80, 84, 85], "x86": 80, "openvino": 80, "intel": [80, 81, 84], "daniil": 81, "lyakhov": 81, "aamir": 81, "nazir": 81, "alexand": 81, "suslov": 81, "yamini": 81, "nimmagadda": 81, "kozlov": 81, "subject": [81, 83], "openvinoquant": 81, "unlock": 81, "placement": 81, "simplifi": [81, 82, 84, 85], "ux": [81, 82, 84], "torchdynamo": [81, 84, 85, 86], "four": 81, "mechan": [81, 84, 85], "torchvis": [81, 82, 83, 84, 85, 86], "resnet18": [81, 82, 83, 84, 85], "pt2e": [81, 82, 83, 84, 85], "__dict__": [81, 82, 83, 84, 85], "dummi": [81, 84, 85], "traced_b": [81, 84, 85], "exported_model": [81, 82, 83, 84, 85], "preset": 81, "elu": 81, "prelu": 81, "gelu": 81, "quantizationpreset": 81, "bert": [81, 84], "modeltyp": 81, "ignored_scop": 81, "exclud": 81, "layer_1": 81, "layer_2": 81, "layer_3": 81, "ignoredscop": 81, "conv2d": [81, 82, 83, 84, 85, 86], "layer_": 81, "subgraph": [81, 83], "node": [81, 83, 84, 85, 86, 93], "target_devic": 81, "taken": 81, "account": [81, 91, 93], "cpu_spr": 81, "npu": [81, 91], "targetdevic": 81, "fold": [81, 82, 84, 85], "batchnorm": [81, 82, 83, 84, 85], "prepared_model": [81, 82, 83, 84, 85], "fold_quant": 81, "finish": [81, 84], "comparison": 81, "smoothquant": 81, "biascorrect": 81, "discrep": 81, "calibration_load": 81, "dataload": [81, 82, 83], "transform_fn": 81, "data_item": 81, "calibration_dataset": 81, "smooth_quant": 81, "fast_bias_correct": 81, "deploy": [81, 84], "jerri": [82, 84, 86], "zhang": [82, 84, 85, 86], "_export": [82, 83], "fx": [82, 86], "14k": 82, "programm": [82, 84, 85], "prerequisit": [82, 89], "db": 82, "xnnpack": [82, 83, 86], "xnnpack_quant": [82, 83], "get_symmetric_quantization_config": [82, 83], "xnnpackquant": [82, 83, 86], "prior": 82, "qconfigmap": [82, 86], "backendconfig": [82, 86], "rel": 82, "intent": [82, 86], "qconfig": [82, 86], "3d": [82, 86], "incompat": 82, "great": 82, "ideal": [82, 91], "fake_qu": 82, "hidden": 82, "summari": 82, "interact": 82, "thu": 82, "queri": [82, 86], "previous": 82, "embedding_byt": 82, "executorchquant": 82, "concaten": 82, "prone": 82, "cleaner": 82, "composed_quant": 82, "quantization_cap": 82, "concern": 82, "decoupl": 82, "minmax": 82, "freed": 82, "identitc": 82, "imagenet": [82, 83], "unzip": [82, 83], "data_path": [82, 83], "renam": [82, 83], "resnet18_pretrained_float": [82, 83], "sy": [82, 83], "numpi": [82, 83], "np": [82, 83], "resnet": [82, 83, 84], "warn": [82, 83, 91], "filterwarn": [82, 83], "categori": [82, 83], "deprecationwarn": [82, 83], "r": [82, 83, 92], "seed": [82, 83], "191009": [82, 83], "averagemet": [82, 83], "fmt": [82, 83], "reset": [82, 83, 91], "val": [82, 83], "avg": [82, 83], "count": [82, 83, 93], "__str__": [82, 83], "fmtstr": [82, 83], "topk": [82, 83], "predict": [82, 83], "maxk": [82, 83], "pred": [82, 83], "correct": [82, 83], "eq": [82, 83], "expand_a": [82, 83], "correct_k": [82, 83], "mul_": [82, 83], "criterion": [82, 83], "top1": [82, 83], "top5": [82, 83], "cnt": [82, 83], "acc1": [82, 83], "acc5": [82, 83], "load_model": [82, 83], "model_fil": [82, 83], "weights_onli": [82, 83, 93], "print_size_of_model": [82, 83], "temp": [82, 83], "p": [82, 83], "1e6": [82, 83], "prepare_data_load": [82, 83], "485": [82, 83, 91], "456": [82, 83], "std": [82, 83], "229": [82, 83], "225": [82, 83], "randomresizedcrop": [82, 83], "randomhorizontalflip": [82, 83], "totensor": [82, 83], "dataset_test": [82, 83], "resiz": [82, 83], "centercrop": [82, 83], "train_sampl": [82, 83], "randomsampl": [82, 83], "test_sampl": [82, 83], "sequentialsampl": [82, 83], "train_batch_s": [82, 83], "sampler": [82, 83], "data_loader_test": [82, 83, 84, 85], "eval_batch_s": [82, 83], "saved_model_dir": [82, 83], "float_model_fil": [82, 83], "model_to_quant": [82, 83], "rand": [82, 83, 89], "capture_pre_autograd_graph": [82, 83], "dynamic_shap": [82, 83], "dynamic_dim": [82, 83], "qconfig_opt": 82, "set_object_typ": 82, "set_module_nam": 82, "workload": 82, "themodel": 82, "feedback": 82, "dq": 82, "fp32_op": 82, "qauntiz": 82, "x_int8": 82, "x_zero_point": 82, "weight_int8": 82, "bias_fp32": 82, "output_scal": 82, "output_zero_point": 82, "x_fp32": 82, "quantized_decompos": 82, "dequantize_per_tensor": 82, "x_i8": 82, "x_quant_min": 82, "x_quant_max": 82, "weight_fp32": 82, "weight_i8": 82, "weight_quant_min": 82, "weight_quant_max": 82, "weight_permut": 82, "permute_copi": 82, "out_fp32": 82, "addmm": [82, 91], "out_i8": 82, "quantize_per_tensor": 82, "out_zero_point": 82, "out_quant_min": 82, "out_quant_max": 82, "float32_op": 82, "decompos": 82, "use_reference_represent": 82, "x_int16": 82, "int16": 82, "weight_int16": 82, "acc_int32": 82, "out_dtyp": 82, "bias_scal": 82, "bias_int32": 82, "div": 82, "mul": 82, "out_int8": 82, "qmin": [82, 92], "qmax": [82, 92], "date": 82, "unus": 82, "serila": 82, "consult": 82, "exportedprogram": 82, "pt2e_quantized_model_file_path": 82, "resnet18_pt2e_quant": 82, "quantized_ep": 82, "loaded_quantized_ep": 82, "loaded_quantized_model": 82, "diff": 82, "79": [82, 93], "82": 82, "55": [82, 91], "edg": [82, 86], "went": 82, "andrew": 83, "Or": [83, 93], "move_exported_model_to_ev": [83, 84], "correctli": 83, "certain": [83, 91], "dropout": 83, "move_exported_model_to_train": 83, "jit": 83, "recursivescriptmodul": 83, "train_one_epoch": 83, "ntrain_batch": 83, "avgloss": 83, "5f": 83, "start_tim": 83, "3f": 83, "global_avg": 83, "is_qat": [83, 84], "fusion": [83, 91], "batchnorm2d": 83, "_native_batch_norm_legit": 83, "cudnn_batch_norm": 83, "mobilenetv2": 83, "manual": [83, 91], "recompil": 83, "consolid": 83, "epoch": 83, "far": 83, "num_epoch": 83, "num_train_batch": 83, "num_eval_batch": 83, "num_observer_update_epoch": 83, "num_batch_norm_update_epoch": 83, "num_epochs_between_ev": 83, "nepoch": 83, "stat": 83, "subseq": 83, "disable_observ": 83, "bn": 83, "running_mean": 83, "running_var": 83, "new_arg": 83, "wish": [83, 91], "prepared_model_copi": 83, "neval_batch": 83, "paus": 83, "resum": 83, "fail": [83, 86], "machin": [83, 91, 93], "checkpoint_path": 83, "checkpoint_": 83, "behav": 83, "incorrectli": 83, "lesli": [84, 86], "fang": [84, 86], "weiwen": [84, 86], "xia": [84, 86], "jiong": [84, 86], "gong": [84, 86], "cnn": 84, "rnn": 84, "outstand": 84, "fourth": 84, "spr": 84, "xeon": 84, "processor": 84, "boost": 84, "memory_format": [84, 85], "channels_last": [84, 85], "onednn": [84, 85], "assum": [84, 86, 93], "word": [84, 91], "satur": 84, "extern": [84, 91], "pure": 84, "dedic": 84, "scenario": [84, 85], "plai": [84, 85], "convolut": [84, 85, 86], "absenc": [84, 85], "enhanc": [84, 85], "mirror": [84, 85], "autocast": [84, 85], "device_typ": [84, 85], "turn": [84, 85], "cpp": 84, "qconvolut": [84, 85], "qlinear": [84, 85], "presenc": [84, 85], "pair": [84, 85], "conting": [84, 85], "qmaxpool2d": [84, 85], "torchinductor_freez": [84, 85], "example_x86inductorquantizer_pytorch_2_1": 84, "torchbench": 84, "measur": [84, 93], "proven": 84, "depth": 84, "example_x86inductorquantizer_qat": 84, "yan": 85, "zhiwei": 85, "wang": 85, "eikan": 85, "liangang": 85, "liu": 85, "river": 85, "cui": 85, "yifeng": 85, "xpuinductorquant": 85, "pip3": 85, "torchaudio": 85, "xpu_inductor_quantizer_exampl": 85, "xpu_inductor_quant": 85, "xpuiq": 85, "resnet18_weight": 85, "get_default_xpu_inductor_quantization_config": 85, "wherea": 85, "histogramobserv": [85, 86], "perchannelminmaxobserv": 85, "quantizationspec": [85, 86], "quantizationconfig": [85, 86], "type_check": 85, "observerorfakequantizeconstructor": 85, "get_xpu_inductor_symm_quantization_config": 85, "extra_arg": 85, "act_observer_or_fake_quant_ctr": 85, "act_quantization_spec": [85, 86], "qscheme": [85, 86], "per_tensor_symmetr": [85, 86], "observer_or_fake_quant_ctr": [85, 86], "with_arg": [85, 86], "weight_observer_or_fake_quant_ctr": 85, "weight_quantization_spec": [85, 86], "per_channel_symmetr": 85, "ch_axi": 85, "oc": 85, "ic": 85, "kh": 85, "kw": 85, "conv": [85, 86], "bias_quantization_spec": 85, "amp": 85, "indcutor": 85, "kimish": 86, "patel": 86, "explicit": 86, "quantiat": 86, "encod": 86, "convei": 86, "quantizationannot": 86, "furthermor": 86, "minmaxobserv": 86, "input_qspec_map": 86, "output_qspec": 86, "_annot": 86, "conclud": 86, "matcher": 86, "get_source_partit": 86, "add_partit": 86, "gm": 86, "itertool": 86, "chain": 86, "add_nod": 86, "output_nod": 86, "per_tensor_affin": 86, "input_act_qspec": 86, "output_act_qspec": 86, "input_act0": 86, "input_act1": 86, "quantization_annot": 86, "substitut": 86, "among": 86, "sharedquantizationspec": 86, "maxpool": 86, "average_pool": 86, "concat": 86, "whose": 86, "edgeornod": 86, "transit": 86, "spec": 86, "conv1": 86, "conv2": 86, "fed": 86, "conv1_out": 86, "conv2_out": 86, "qspec1": 86, "cat_input0": 86, "cat_input1": 86, "implicitli": 86, "therefor": 86, "ob": 86, "consum": 86, "rewrit": 86, "share_qparams_with_input_act0_qspec": 86, "known": 86, "beforehand": 86, "sigmoid": 86, "fixedqparamsquantizationspec": 86, "act_qspec": 86, "sigmoid_nod": 86, "input_act": 86, "derivedquantizationspec": 86, "derive_qparams_fn": 86, "observerorfakequant": 86, "observerbas": 86, "fakequantizebas": 86, "heurist": 86, "obejct": 86, "obs_or_fq": 86, "fq": 86, "act_obs_or_fq": 86, "weight_obs_or_fq": 86, "act_zp": 86, "weight_zp": 86, "bias_qspec": 86, "derived_from": 86, "backendquant": 86, "get_input_act_qspec": 86, "get_output_act_qspec": 86, "get_weight_qspec": 86, "get_bias_qspec": 86, "intermedi": 86, "straightforward": 86, "call_funct": 86, "relu_": 86, "relu_nod": 86, "maybe_conv_nod": 86, "conv1d": 86, "unexpect": 86, "recognz": 86, "unquant": 86, "subgraphmatch": 86, "conv_relu_pattern": 86, "name_node_map": 86, "input_nod": 86, "weight_nod": 86, "bias_nod": 86, "caveat": 86, "exhaust": 86, "2d": 86, "4d": 86, "symbol": 86, "outcom": 86, "tutorials_python": 87, "zip": 87, "jupyt": [87, 89], "notebook": [87, 89, 92], "tutorials_jupyt": 87, "galleri": [87, 89], "sphinx": [87, 89], "00": 88, "004": [88, 89], "total": [88, 89], "template_tutori": [88, 89], "click": 89, "firstnam": 89, "lastnam": 89, "v2": 89, "topic": 89, "2117": 89, "7090": 89, "6592": 89, "2963": 89, "5452": 89, "6069": 89, "5132": 89, "5618": 89, "9622": 89, "8804": 89, "8706": 89, "9108": 89, "7753": 89, "8382": 89, "practic": [89, 91], "summar": 89, "takeawai": 89, "link1": 89, "link2": 89, "minut": 89, "ipynb": [89, 92], "moe": 90, "b200": [90, 92], "128x128": 90, "blockwis": 90, "1x128": 90, "mi350x": 90, "bmg": 90, "md": 90, "a16w8": 91, "whera": 91, "perplex": [91, 92], "winogrand": 91, "3315": 91, "7380": 91, "float8_rowwis": 91, "4197": 91, "7388": 91, "int8_rowwis": 91, "3451": 91, "7340": 91, "4535": 91, "7285": 91, "6034": 91, "7316": 91, "4459": 91, "7135": 91, "05": [91, 93], "skip_vllm": 91, "measure_accuracy_and_perform": 91, "prefil": 91, "prefill_speedup": 91, "decode_speedup": 91, "59099": 91, "14380": 91, "todo": 91, "3549": 91, "102786": 91, "15218": 91, "739": 91, "058": 91, "69313": 91, "15984": 91, "173": 91, "112": 91, "30946": 91, "6612": 91, "45312": 91, "8025": 91, "464": 91, "214": 91, "int8_rowwwis": 91, "28231": 91, "4309": 91, "912": 91, "652": 91, "3550": 91, "skip_lm_ev": 91, "input_len": 91, "output_len": 91, "max_model_len": 91, "4128": 91, "2080": 91, "float8weightonlyconfig": 91, "incur": 91, "fairli": 91, "obtain": 91, "usabl": 91, "greater": 91, "ascend": 91, "torch_npu": 91, "arm": 91, "mac": 91, "appl": 91, "silicon": 91, "m1": 91, "perf": 91, "32gb": 91, "ram": 91, "18": 91, "int8_dynamic_activation_intx_weight": 91, "81": 91, "97": 91, "alongsid": 91, "_model": 91, "a6000": 91, "590": 91, "713": 91, "482": 91, "095": 91, "63": 91, "codebookweightonlyconfig": 91, "migrat": 91, "1715": 91, "autoqu": 91, "sete": 91, "mimic": 91, "recommended_inductor_config_sett": 91, "replic": 91, "prevent": 91, "overwrit": 91, "overwritten": 91, "referenc": 91, "varieti": 91, "outdat": 91, "expand": 91, "tool": [91, 93], "default_int4_autoquant_class_list": 91, "plug": 91, "use_autoquant_default": 91, "qtensor_class_list": 91, "pick": 91, "heavili": 91, "preliminari": 91, "attempt": 91, "occur": 91, "maximum": 91, "regress": 91, "regim": 91, "slow": 91, "came": 91, "_autoquant_cach": 91, "restor": 91, "pickl": 91, "pkl": 91, "wb": 91, "dump": 91, "rb": 91, "quantized_v": 91, "high_precision_float_v": 91, "unifi": 91, "choose_qparams_affin": 91, "quantize_affin": 91, "dequantize_affin": 91, "channel_group": 91, "docstr": 91, "dispatch": 91, "int4mm": 91, "tensor_core_til": 91, "relationship": 91, "tensorcoretiledlayout": 91, "int4cpulayout": 91, "to_affine_quantized_intx": 91, "m_bf16": 91, "benchmark_model": 91, "num_run": 91, "bf16_time": 91, "int4_tim": 91, "1xa100": 91, "457685546875": 91, "4580908203125": 91, "2715200981216173": 91, "int8wo_qu": 91, "int64": 91, "input_quant_func": 91, "to_linear_activation_quant": 91, "necessarili": 91, "130k": 91, "7b": 91, "212": 91, "107": 91, "38": [91, 92], "1418": 91, "93": 91, "775": 91, "99": 91, "200": 91, "265": 91, "61": 91, "441": 91, "1435": 91, "54": 91, "85": 91, "213": 91, "46": [91, 93], "605": 91, "261": 91, "uintxweightonlyconfig": 91, "t4": 91, "colab": [91, 92], "opposit": 91, "hopefulli": 91, "bottleneck": 91, "x_q": 92, "zp": 92, "x_float": 92, "x_fq": 92, "proce": 92, "torchtun": 92, "int8dynactint4qatquant": 92, "int4weightonlyqatquant": 92, "int4weightonlyembeddingqatquant": 92, "composableqatquant": 92, "fastlanguagemodel": 92, "qwen3": 92, "2507": 92, "load_in_4bit": 92, "full_finetun": 92, "target_modul": 92, "v_proj": 92, "o_proj": 92, "up_proj": 92, "down_proj": 92, "lora_alpha": 92, "qat_schem": 92, "unslothai": 92, "blob": 92, "nb": 92, "qwen3_": 92, "14b": 92, "8b_qat_ful": 92, "earli": 92, "8b_qat_lora": 92, "mlabonn": 92, "finetom": 92, "100k": 92, "rate": 92, "2e": 92, "12b": 92, "1477": 92, "7745": 92, "5631": 92, "33": 92, "727": 92, "bbh": 92, "8079": 92, "7624": 92, "7831": 92, "45": 92, "495": 92, "1155": 92, "247": 92, "797": 92, "770": 92, "7074": 92, "6415": 92, "6666": 92, "088": 92, "gpqa": 92, "3232": 92, "3081": 92, "3182": 92, "887": 92, "mmlu": 92, "4909": 92, "4328": 92, "4524": 92, "735": 92, "1322": 92, "3459": 92, "8796": 92, "5483": 92, "4967": 92, "5174": 92, "116": 92, "3333": 92, "2879": 92, "303": 92, "260": 92, "2771": 92, "2562": 92, "2629": 92, "057": 92, "8x": 92, "yahma": 92, "alpaca": 92, "7527": 92, "7068": 92, "551": 92, "4074": 92, "3621": 92, "3702": 92, "881": 92, "7771": 92, "7262": 92, "7397": 92, "523": 92, "4929": 92, "4519": 92, "4686": 92, "732": 92, "405b": 93, "25x": 93, "strive": 93, "hackabl": 93, "debugg": 93, "gather": 93, "async": 93, "ac": 93, "\u2139": 93, "tracker": 93, "upcom": 93, "sac": 93, "0a0": 93, "gitb98af95": 93, "git890e0ac8": 93, "median": 93, "77": 93, "7689": 93, "6768": 93, "8xmi300x": 93, "dev20250811": 93, "rocm6": 93, "git4fc4068d6": 93, "commit": 93, "2c8b5947991239913d67e2f7d22a255c3e2a9694": 93, "09": 93, "5376": 93, "07": 93, "6166": 93, "6100": 93, "5891": 93, "torchtitan_root": 93, "float8_recipe_with_best_set": 93, "sp": 93, "repositori": 93, "estim": 93, "reproduct": 93, "float8_rooflin": 93, "your_output_filenam": 93, "csv": 93, "shape_gen_nam": 93, "sweep": 93, "float8_recipe_nam": 93, "max_ab": 93, "bf16_gemm_tim": 93, "fp8_gemm_tim": 93, "fp8_overhead_tim": 93, "formula": 93, "lh": 93, "rh": 93, "lead": 93, "medium": 93, "unit": 93, "pytest": 93, "test_bas": 93, "test_compil": 93, "test_numerics_integr": 93, "test_fsdp": 93, "test_dtensor": 93, "test_fsdp2": 93, "test_everyth": 93, "benchmrk": 93, "inference_mod": 93}, "objects": {"torchao.float8": [[5, 0, 1, "", "CastConfig"], [6, 0, 1, "", "Float8LinearConfig"], [7, 0, 1, "", "Float8LinearRecipeName"], [8, 0, 1, "", "ScalingGranularity"], [9, 0, 1, "", "ScalingType"], [10, 2, 1, "", "convert_to_float8_training"], [11, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[6, 1, 1, "", "from_recipe_name"]], "torchao.prototype.mx_formats": [[12, 0, 1, "", "MXDynamicActivationMXWeightConfig"], [13, 0, 1, "", "NVFP4DynamicActivationNVFP4WeightConfig"], [14, 0, 1, "", "NVFP4WeightOnlyConfig"]], "torchao.quantization": [[15, 0, 1, "", "Float8DynamicActivationFloat8SemiSparseWeightConfig"], [16, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [17, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [18, 0, 1, "", "Float8WeightOnlyConfig"], [19, 0, 1, "", "FqnToConfig"], [20, 0, 1, "", "Int4WeightOnlyConfig"], [21, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [22, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [23, 0, 1, "", "Int8DynamicActivationIntxWeightConfig"], [24, 0, 1, "", "Int8WeightOnlyConfig"], [25, 0, 1, "", "IntxWeightOnlyConfig"], [50, 2, 1, "", "quantize_"]], "torchao.quantization.qat": [[26, 0, 1, "", "ComposableQATQuantizer"], [27, 0, 1, "", "FakeQuantizeConfigBase"], [28, 0, 1, "", "FakeQuantizedEmbedding"], [29, 0, 1, "", "FakeQuantizedLinear"], [30, 0, 1, "", "FakeQuantizerBase"], [31, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [32, 0, 1, "", "Float8FakeQuantizeConfig"], [33, 0, 1, "", "Float8FakeQuantizer"], [34, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [35, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [36, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [37, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [38, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [39, 0, 1, "", "IntxFakeQuantizeConfig"], [40, 0, 1, "", "IntxFakeQuantizer"], [41, 0, 1, "", "QATConfig"], [42, 0, 1, "", "QATStep"], [45, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[28, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[29, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[31, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[33, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[35, 1, 1, "", "convert"], [35, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[39, 3, 1, "", "group_size"], [39, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[40, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[43, 0, 1, "", "Int4WeightOnlyEmbedding"], [44, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[43, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[46, 0, 1, "", "Int4WeightOnlyQATLinear"], [47, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [48, 2, 1, "", "disable_linear_fake_quant"], [49, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[51, 0, 1, "", "KernelPreference"], [52, 0, 1, "", "PackingFormat"], [53, 0, 1, "", "QuantizeTensorKwargs"], [54, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[51, 4, 1, "", "AUTO"], [51, 4, 1, "", "EMULATED"], [51, 4, 1, "", "MSLK"], [51, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[52, 4, 1, "", "PLAIN"]], "torchao": [[3, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[55, 0, 1, "", "PerChannelNormObserver"], [56, 0, 1, "", "WandaSparsifier"], [57, 2, 1, "", "apply_fake_sparsity"], [58, 4, 1, "", "semi_sparse_weight"], [59, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[55, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[56, 1, 1, "", "prepare"], [56, 1, 1, "", "squash_mask"], [56, 1, 1, "", "update_mask"]], "torchao.utils": [[60, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[60, 1, 1, "", "get_layout"], [60, 1, 1, "", "get_tensor_impl_constructor"], [60, 1, 1, "", "implements"], [60, 1, 1, "", "implements_torch_function"], [60, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 63, 65, 67, 70, 77, 78, 92], "float8": [0, 2, 65, 67, 70, 93], "main": [0, 1, 2], "train": [0, 65, 67, 70, 72, 78, 81, 82, 83, 84, 85, 90, 92, 93], "api": [0, 1, 2, 4, 61, 62, 67, 70, 78, 86, 92, 93], "other": [0, 63, 65, 90, 91], "type": [0, 76], "quantiz": [1, 2, 4, 50, 65, 67, 68, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93], "qat": [1, 67, 83, 90, 92], "config": [1, 2], "quantize_": [1, 4, 92], "custom": [1, 63], "legaci": 1, "prototyp": [1, 2], "workflow": [2, 78, 90], "weight": [2, 65, 68, 72], "int8": 2, "int4": 2, "intx": 2, "mx": 2, "nvfp4": 2, "sparsiti": [3, 66], "util": 4, "tensor": [4, 63, 65, 74, 75, 77, 86, 91], "subclass": [4, 63, 75, 77, 91], "common": [4, 62, 86], "castconfig": 5, "float8linearconfig": 6, "float8linearrecipenam": 7, "scalinggranular": 8, "scalingtyp": 9, "convert_to_float8_train": 10, "precompute_float8_dynamic_scale_for_fsdp": 11, "mxdynamicactivationmxweightconfig": 12, "nvfp4dynamicactivationnvfp4weightconfig": 13, "nvfp4weightonlyconfig": 14, "float8dynamicactivationfloat8semisparseweightconfig": 15, "float8dynamicactivationfloat8weightconfig": 16, "float8dynamicactivationint4weightconfig": 17, "float8weightonlyconfig": 18, "fqntoconfig": 19, "int4weightonlyconfig": 20, "int8dynamicactivationint4weightconfig": 21, "int8dynamicactivationint8weightconfig": 22, "int8dynamicactivationintxweightconfig": [23, 91], "int8weightonlyconfig": 24, "intxweightonlyconfig": 25, "composableqatquant": 26, "fakequantizeconfigbas": 27, "fakequantizedembed": 28, "fakequantizedlinear": 29, "fakequantizerbas": 30, "float8actint4weightqatquant": 31, "float8fakequantizeconfig": 32, "float8fakequant": 33, "fromintxquantizationawaretrainingconfig": 34, "int4weightonlyembeddingqatquant": 35, "int4weightonlyqatquant": 36, "int8dynactint4weightqatquant": 37, "intxquantizationawaretrainingconfig": 38, "intxfakequantizeconfig": 39, "intxfakequant": 40, "qatconfig": 41, "qatstep": 42, "int4weightonlyembed": 43, "int4weightonlyqatembed": 44, "initialize_fake_quant": 45, "int4weightonlyqatlinear": 46, "int8dynactint4weightqatlinear": 47, "disable_linear_fake_qu": 48, "enable_linear_fake_qu": 49, "kernelprefer": [51, 63], "packingformat": 52, "quantizetensorkwarg": 53, "_choose_quant_func_and_quantize_tensor": 54, "perchannelnormobserv": 55, "wandasparsifi": 56, "apply_fake_spars": 57, "semi_sparse_weight": 58, "sparsifi": 59, "torchaobasetensor": 60, "refer": [61, 78], "benchmark": [62, 63, 72, 91, 93], "guid": [62, 63, 77], "add": [62, 77], "an": [62, 71], "recip": [62, 70], "model": [62, 63, 65, 68, 70, 71, 72, 76, 77, 78, 81, 82, 83, 93], "design": [62, 66], "consider": 62, "hf": 62, "ci": 62, "dashboard": 62, "1": [62, 67, 70, 72, 76, 77, 81, 84, 85, 86, 93], "modifi": 62, "exist": 62, "configur": [62, 66, 77, 82, 83, 91], "2": [62, 67, 72, 76, 77, 81, 82, 83, 84, 85, 86, 93], "run": 62, "3": [62, 67, 72, 77, 81, 84, 85, 86], "output": [62, 75], "format": [62, 65], "4": [62, 81, 86], "integr": [62, 67, 76, 77, 92], "pipelin": 62, "troubleshoot": 62, "test": [62, 63, 93], "issu": 62, "best": 62, "practic": 62, "contributor": 63, "gener": 63, "extend": 63, "ad": [63, 77], "new": [63, 77], "effici": [63, 65], "kernel": [63, 65, 77, 79], "triton": [63, 91], "hand": 63, "written": 63, "us": [63, 86], "flow": [63, 65, 71, 77, 86, 91, 93], "torch": [63, 81, 82, 83], "compil": [63, 77, 81], "perform": [63, 72, 79, 82, 91, 93], "serial": [63, 71, 77], "featur": [63, 93], "support": [63, 76, 77], "function": [63, 82, 83], "compos": 63, "microbenchmark": 63, "eval": [63, 82], "contribut": [64, 78], "overview": [65, 66, 89, 90], "basic": 65, "dtype": [65, 90], "primit": [65, 91], "op": 65, "deriv": [65, 86, 93], "pack": 65, "algorithm": 65, "onli": 65, "dynam": [65, 68], "activ": [65, 68], "static": [65, 73], "awar": [65, 67, 83, 84, 92], "low": [65, 67], "bit": [65, 68], "optim": [65, 71, 72, 78], "case": 65, "studi": 65, "how": [65, 82, 83, 86], "work": 65, "dure": 65, "execut": 65, "save": [65, 76, 82, 83, 93], "load": [65, 82, 83, 93], "goal": 66, "context": 66, "prune": 66, "criteria": 66, "strategi": 66, "pattern": [66, 86], "part": [67, 70, 72], "fine": 67, "tune": 67, "qlora": 67, "option": [67, 72, 81, 89, 93], "torchtun": 67, "axolotl": [67, 92], "rank": 67, "adapt": 67, "huggingfac": [67, 72, 77], "peft": 67, "first": 68, "exampl": [68, 76, 77, 86, 91], "set": [68, 82], "up": 68, "w8a8": 68, "int": 68, "8": 68, "size": [68, 82], "comparison": 68, "speedup": 68, "next": [68, 75], "step": [68, 72, 75, 77, 89], "tutori": [69, 78, 89], "pre": 70, "torchtitan": 70, "prerequisit": [70, 81, 84, 85, 86], "rowwis": [70, 93], "scale": [70, 93], "tensorwis": [70, 93], "pick": 70, "import": [70, 82, 83], "note": [70, 86, 91], "directli": [70, 86], "convers": 70, "deseri": 71, "what": [71, 75], "happen": 71, "when": 71, "serv": [72, 77, 78], "vllm": [72, 77], "sglang": 72, "executorch": 72, "post": [72, 81, 82, 84, 85], "infer": [72, 90, 91, 93], "transform": [72, 76, 77], "mobil": 72, "deploy": 72, "unti": 72, "embed": 72, "creat": [72, 77], "export": [72, 81, 82, 83, 84, 85, 86], "characterist": 72, "evalu": [72, 82, 92], "qualiti": 72, "assess": 72, "memori": 72, "latenc": 72, "result": [72, 92], "h100": [72, 91, 93], "machin": 72, "conclus": [72, 81, 82, 83, 84, 85, 86, 89], "calibr": [73, 82], "phase": 73, "write": [74, 75, 86], "your": [74, 75, 77], "own": [74, 75], "advanc": 74, "ar": 75, "modul": 75, "swap": 75, "which": 75, "oper": [75, 77, 86], "should": 75, "we": 75, "implement": [75, 77], "compar": 75, "hug": 76, "face": 76, "quick": [76, 78, 80, 93], "start": [76, 78, 80, 93], "usag": [76, 77], "diffus": 76, "architectur": 77, "system": 77, "class": 77, "fqn": 77, "method": 77, "minim": 77, "requir": 77, "compat": 77, "why": 77, "regist": 77, "": 77, "kei": [77, 93], "detail": [77, 91], "hardwar": [77, 90], "specif": [77, 82, 83], "linear": 77, "benefit": 77, "trade": 77, "off": 77, "share": [77, 86], "safetensor": 77, "diagram": 77, "high": 77, "level": 77, "point": [77, 91], "dispatch": 77, "bring": 77, "extern": 77, "welcom": 78, "document": 78, "pytorch": [78, 81, 82, 83, 84, 85, 86], "nativ": 78, "instal": [78, 81], "pt2e": [78, 80, 86], "openvino": 81, "backend": [81, 82, 83, 84, 85], "introduct": [81, 84, 85, 86], "nncf": 81, "captur": [81, 84, 85], "fx": [81, 84, 85], "graph": [81, 84, 85], "appli": [81, 84, 85, 93], "lower": [81, 82, 84, 85], "represent": 81, "improv": 81, "metric": 81, "motiv": [82, 86], "defin": [82, 83], "helper": [82, 83], "prepar": [82, 83], "dataset": [82, 83], "mode": 82, "convert": [82, 83], "check": 82, "accuraci": [82, 91], "debug": 82, "loop": 83, "checkpoint": [83, 93], "x86": 84, "through": [84, 85], "inductor": [84, 85, 91], "intel": [85, 90], "gpu": [85, 93], "annot": 86, "param": 86, "fix": 86, "paramet": 86, "5": 86, "A": 86, "toi": 86, "resnet18": 86, "ir": 86, "problem": 86, "match": 86, "aten": 86, "recommend": [86, 92], "subgraphmatcherwithnamenodemap": 86, "comput": 88, "time": 88, "templat": 89, "addit": 89, "exercis": 89, "further": 89, "read": 89, "statu": 90, "nvidia": [90, 91, 93], "cuda": 90, "edg": 90, "rocm": 90, "b200": 91, "techniqu": 91, "avail": 91, "codebook": 91, "automat": 91, "autoquant": 91, "affin": 91, "layout": 91, "zero": 91, "domain": 91, "full": 91, "kv": 91, "cach": 91, "gemlit": 91, "uintx": 91, "unsloth": 92, "e2": 93, "amd": 93, "mi300x": 93, "multi": 93, "user": 93, "rowwise_with_gw_hp": 93}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao.quantization.qat": [[1, "torchao-quantization-qat"]], "Main Config for quantize_": [[1, "main-config-for-quantize"]], "Custom QAT APIs": [[1, "custom-qat-apis"]], "Legacy QAT APIs": [[1, "legacy-qat-apis"]], "Prototype": [[1, "prototype"]], "torchao.quantization": [[2, "torchao-quantization"]], "Main Quantization APIs": [[2, "main-quantization-apis"]], "Workflow Configs": [[2, "workflow-configs"]], "float8 weight configs": [[2, "float8-weight-configs"]], "int8 weight configs": [[2, "int8-weight-configs"]], "int4 weight configs": [[2, "int4-weight-configs"]], "intx weight configs": [[2, "intx-weight-configs"]], "mx weight configs (prototype)": [[2, "mx-weight-configs-prototype"]], "nvfp4 weight configs (prototype)": [[2, "nvfp4-weight-configs-prototype"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "torchao.utils": [[4, "torchao-utils"]], "Tensor Subclass Utils": [[4, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[4, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[4, "quantize-api-common-utils"]], "CastConfig": [[5, "castconfig"]], "Float8LinearConfig": [[6, "float8linearconfig"]], "Float8LinearRecipeName": [[7, "float8linearrecipename"]], "ScalingGranularity": [[8, "scalinggranularity"]], "ScalingType": [[9, "scalingtype"]], "convert_to_float8_training": [[10, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[11, "precompute-float8-dynamic-scale-for-fsdp"]], "MXDynamicActivationMXWeightConfig": [[12, "mxdynamicactivationmxweightconfig"]], "NVFP4DynamicActivationNVFP4WeightConfig": [[13, "nvfp4dynamicactivationnvfp4weightconfig"]], "NVFP4WeightOnlyConfig": [[14, "nvfp4weightonlyconfig"]], "Float8DynamicActivationFloat8SemiSparseWeightConfig": [[15, "float8dynamicactivationfloat8semisparseweightconfig"]], "Float8DynamicActivationFloat8WeightConfig": [[16, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[17, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[18, "float8weightonlyconfig"]], "FqnToConfig": [[19, "fqntoconfig"]], "Int4WeightOnlyConfig": [[20, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[21, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[22, "int8dynamicactivationint8weightconfig"]], "Int8DynamicActivationIntxWeightConfig": [[23, "int8dynamicactivationintxweightconfig"]], "Int8WeightOnlyConfig": [[24, "int8weightonlyconfig"]], "IntxWeightOnlyConfig": [[25, "intxweightonlyconfig"]], "ComposableQATQuantizer": [[26, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[27, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[28, "fakequantizedembedding"]], "FakeQuantizedLinear": [[29, "fakequantizedlinear"]], "FakeQuantizerBase": [[30, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[31, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[32, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[33, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[34, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[35, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[36, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[37, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[38, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[39, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[40, "intxfakequantizer"]], "QATConfig": [[41, "qatconfig"]], "QATStep": [[42, "qatstep"]], "Int4WeightOnlyEmbedding": [[43, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[44, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[45, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[46, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[47, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[48, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[49, "enable-linear-fake-quant"]], "quantize": [[50, "quantize"]], "KernelPreference": [[51, "kernelpreference"], [63, "kernelpreference"]], "PackingFormat": [[52, "packingformat"]], "QuantizeTensorKwargs": [[53, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[54, "choose-quant-func-and-quantize-tensor"]], "PerChannelNormObserver": [[55, "perchannelnormobserver"]], "WandaSparsifier": [[56, "wandasparsifier"]], "apply_fake_sparsity": [[57, "apply-fake-sparsity"]], "semi_sparse_weight": [[58, "semi-sparse-weight"]], "sparsify": [[59, "sparsify"]], "TorchAOBaseTensor": [[60, "torchaobasetensor"]], "API Reference": [[61, "api-reference"], [78, null]], "Benchmarking API Guide": [[62, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[62, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[62, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[62, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[62, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[62, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[62, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[62, "run-ci-benchmarks"]], "3. CI Output Format": [[62, "ci-output-format"]], "4. Integration with CI Pipeline": [[62, "integration-with-ci-pipeline"]], "Troubleshooting": [[62, "troubleshooting"]], "Running Tests": [[62, "running-tests"]], "Common Issues": [[62, "common-issues"]], "Best Practices": [[62, "best-practices"]], "Contributor Guide": [[63, "contributor-guide"]], "General Guide on Extending torchao": [[63, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[63, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[63, "adding-efficient-kernels"]], "Custom triton kernels": [[63, "custom-triton-kernels"]], "Custom hand written kernels": [[63, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[63, "using-hand-written-kernels-in-tensor-subclasses"]], "Flow": [[63, "flow"]], "Using torch.compile for Performance": [[63, "using-torch-compile-for-performance"]], "Serialization": [[63, "serialization"], [71, "serialization"]], "Other Feature Support": [[63, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[63, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[63, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[63, "model-benchmarks-and-eval"]], "Contributing": [[64, "contributing"], [78, null]], "Quantization Overview": [[65, "quantization-overview"]], "Basic DTypes": [[65, "basic-dtypes"]], "Quantization Primitive Ops": [[65, "quantization-primitive-ops"]], "Efficient kernels": [[65, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[65, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[65, "quantization-algorithms-flows"]], "Weight Only Quantization": [[65, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[65, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[65, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[65, "other-quantization-flows"]], "Training": [[65, "training"]], "Quantization Aware Training": [[65, "quantization-aware-training"], [84, "quantization-aware-training"]], "Low Bit Optimizers": [[65, "low-bit-optimizers"]], "Quantized Training": [[65, "quantized-training"], [93, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[65, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[65, "during-quantization"]], "During Model Execution": [[65, "during-model-execution"]], "During Save/Load": [[65, "during-save-load"]], "Sparsity Overview": [[66, "sparsity-overview"]], "Goal": [[66, "goal"]], "Design": [[66, "design"]], "Context": [[66, "context"]], "Pruning Configuration": [[66, "pruning-configuration"]], "Pruning Criteria": [[66, "pruning-criteria"]], "Pruning Strategy": [[66, "pruning-strategy"]], "Sparsity Pattern": [[66, "sparsity-pattern"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[67, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[67, "quantization-aware-training-qat"], [92, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[67, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[67, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[67, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[67, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[67, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[67, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[67, "float8-quantized-fine-tuning"]], "First Quantization Example": [[68, "first-quantization-example"]], "Setting Up the Model": [[68, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[68, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[68, "model-size-comparison"]], "Speedup Comparison": [[68, "speedup-comparison"]], "Next Steps": [[68, "next-steps"], [75, "next-steps"]], "Tutorials": [[69, "tutorials"], [78, null]], "(Part 1) Pre-training with float8": [[70, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[70, "pre-training-with-torchtitan"]], "Prerequisites": [[70, "prerequisites"], [70, "id1"], [81, "prerequisites"], [84, "prerequisites"], [85, "prerequisites"]], "Rowwise scaling": [[70, "rowwise-scaling"]], "Tensorwise scaling": [[70, "tensorwise-scaling"]], "Picking a recipe": [[70, "picking-a-recipe"]], "Important notes": [[70, "important-notes"]], "Pre-training with torchao directly": [[70, "pre-training-with-torchao-directly"]], "Model conversion API": [[70, "model-conversion-api"]], "Serialization and deserialization flow": [[71, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[71, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[71, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[72, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[72, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[72, "serving-and-inference"]], "Serving and Inference with vLLM": [[72, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[72, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[72, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[72, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[72, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[72, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[72, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[72, "mobile-performance-characteristics"]], "Evaluation": [[72, "evaluation"]], "Model Quality Assessment": [[72, "model-quality-assessment"]], "Memory Benchmarking": [[72, "memory-benchmarking"]], "Performance Benchmarking": [[72, "performance-benchmarking"]], "Latency Benchmarking": [[72, "latency-benchmarking"]], "Serving Benchmarking": [[72, "serving-benchmarking"]], "Results (H100 machine)": [[72, "results-h100-machine"]], "Conclusion": [[72, "conclusion"], [81, "conclusion"], [82, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [89, "conclusion"]], "Static Quantization": [[73, "static-quantization"]], "Calibration Phase": [[73, "calibration-phase"]], "Quantization Phase": [[73, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[74, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[75, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[75, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[75, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[75, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[75, "which-operators-should-we-implement"]], "Comparing the Outputs": [[75, "comparing-the-outputs"]], "Hugging Face Integration": [[76, "hugging-face-integration"]], "Quick Start: Usage Example": [[76, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[76, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[76, "quantizing-models-with-diffusers"]], "Saving the Model": [[76, "saving-the-model"]], "Supported Quantization Types": [[76, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[77, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[77, "configuration-system"]], "1. HuggingFace Model Configuration": [[77, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[77, "torchao-configuration-classes"]], "3. FQN Configuration": [[77, "fqn-configuration"]], "Usage Examples": [[77, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[77, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[77, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[77, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[77, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[77, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[77, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[77, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[77, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[77, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[77, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[77, "hardware-specific-linear-operations"]], "Compilation Benefits": [[77, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[77, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[77, "serialization-and-model-sharing"]], "SafeTensors Support": [[77, "safetensors-support"]], "Integration Architecture Diagrams": [[77, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[77, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[77, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[77, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Welcome to the torchao Documentation": [[78, "welcome-to-the-torchao-documentation"]], "PyTorch-Native Training-to-Serving Model Optimization": [[78, "pytorch-native-training-to-serving-model-optimization"]], "Quick Start": [[78, "quick-start"], [80, "quick-start"], [93, "quick-start"]], "Installation": [[78, "installation"]], "Workflows": [[78, null], [90, "workflows"]], "PT2E Quantization": [[78, null], [80, "pt2e-quantization"]], "Performant Kernels": [[79, "performant-kernels"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[81, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[81, "introduction"], [84, "introduction"], [85, "introduction"], [86, "introduction"]], "Post Training Quantization": [[81, "post-training-quantization"], [84, "post-training-quantization"], [85, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[81, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[81, "capture-fx-graph"], [84, "capture-fx-graph"], [85, "capture-fx-graph"]], "2. Apply Quantization": [[81, "apply-quantization"], [84, "apply-quantization"], [85, "apply-quantization"]], "3. Lower into OpenVINO representation": [[81, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[81, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[82, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[82, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[82, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[82, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[82, "export-the-model-with-torch-export"], [83, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[82, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [83, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[82, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[82, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[82, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[82, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[82, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[82, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[82, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[83, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[83, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[83, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[83, "training-loop"]], "Saving and Loading Model Checkpoints": [[83, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[83, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[84, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[84, "lower-into-inductor"], [85, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[85, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[86, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[86, "prerequisites"]], "Annotation API": [[86, "annotation-api"]], "1. Annotate Common Operator Patterns": [[86, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[86, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[86, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[86, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[86, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[86, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[86, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[86, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]], "Computation times": [[88, "computation-times"]], "Template Tutorial": [[89, "template-tutorial"]], "Overview": [[89, "overview"]], "Steps": [[89, "steps"]], "(Optional) Additional Exercises": [[89, "optional-additional-exercises"]], "Further Reading": [[89, "further-reading"]], "Workflow overview by training/QAT/inference": [[90, "workflow-overview-by-training-qat-inference"]], "Workflows status by dtype + hardware": [[90, "workflows-status-by-dtype-hardware"]], "NVIDIA CUDA": [[90, "nvidia-cuda"]], "Edge": [[90, "edge"]], "ROCM": [[90, "rocm"]], "Intel": [[90, "intel"]], "Other": [[90, "other"]], "Quantized Inference": [[91, "quantized-inference"]], "Accuracy benchmarks": [[91, "accuracy-benchmarks"]], "Performance benchmarks": [[91, "performance-benchmarks"]], "NVIDIA B200": [[91, "nvidia-b200"]], "NVIDIA H100": [[91, "nvidia-h100"], [93, "nvidia-h100"]], "Quantization Techniques": [[91, "quantization-techniques"]], "Other Available Quantization Techniques": [[91, "other-available-quantization-techniques"]], "Int8DynamicActivationIntxWeightConfig Quantization": [[91, "int8dynamicactivationintxweightconfig-quantization"]], "Codebook Quantization": [[91, "codebook-quantization"]], "Automatic Inductor Configuration": [[91, "automatic-inductor-configuration"]], "Autoquantization": [[91, "autoquantization"]], "Affine Quantization Details": [[91, "affine-quantization-details"]], "Quantization Primitives": [[91, "quantization-primitives"]], "Quantized Tensor Subclass": [[91, "quantized-tensor-subclass"]], "Layouts": [[91, "layouts"]], "Zero Point Domains": [[91, "zero-point-domains"]], "Full Affine Quantization Flow Example": [[91, "full-affine-quantization-flow-example"]], "KV Cache Quantization": [[91, "kv-cache-quantization"]], "Gemlite Triton": [[91, "gemlite-triton"]], "UINTx Quantization": [[91, "uintx-quantization"]], "Notes": [[91, "notes"]], "torchao APIs": [[92, "torchao-apis"]], "quantize_ API (recommended)": [[92, "quantize-api-recommended"]], "Axolotl integration": [[92, "axolotl-integration"]], "Unsloth integration": [[92, "unsloth-integration"]], "Evaluation Results": [[92, "evaluation-results"]], "float8": [[93, "float8"]], "Key features": [[93, "key-features"]], "e2e training benchmarks": [[93, "e2e-training-benchmarks"]], "AMD MI300x": [[93, "amd-mi300x"]], "Multi GPU User API": [[93, "multi-gpu-user-api"]], "Performance": [[93, "performance"]], "tensorwise scaling": [[93, "tensorwise-scaling"]], "rowwise scaling": [[93, "rowwise-scaling"]], "rowwise_with_gw_hp scaling": [[93, "rowwise-with-gw-hp-scaling"]], "Derivation": [[93, "derivation"]], "Testing": [[93, "testing"]], "E2E training + inference flow": [[93, "e2e-training-inference-flow"]], "1. Train model and save checkpoint": [[93, "train-model-and-save-checkpoint"]], "2. Load checkpoint and optionally apply inference quantization": [[93, "load-checkpoint-and-optionally-apply-inference-quantization"]]}, "indexentries": {"module": [[3, "module-torchao.sparsity"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[5, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[6, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[6, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "float8linearrecipename (class in torchao.float8)": [[7, "torchao.float8.Float8LinearRecipeName"]], "scalinggranularity (class in torchao.float8)": [[8, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[9, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[10, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[11, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "mxdynamicactivationmxweightconfig (class in torchao.prototype.mx_formats)": [[12, "torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig"]], "nvfp4dynamicactivationnvfp4weightconfig (class in torchao.prototype.mx_formats)": [[13, "torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig"]], "nvfp4weightonlyconfig (class in torchao.prototype.mx_formats)": [[14, "torchao.prototype.mx_formats.NVFP4WeightOnlyConfig"]], "float8dynamicactivationfloat8semisparseweightconfig (class in torchao.quantization)": [[15, "torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[16, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[17, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[19, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[20, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8dynamicactivationintxweightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationIntxWeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8WeightOnlyConfig"]], "intxweightonlyconfig (class in torchao.quantization)": [[25, "torchao.quantization.IntxWeightOnlyConfig"]], "composableqatquantizer (class in torchao.quantization.qat)": [[26, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[27, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[29, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[29, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[30, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[33, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[40, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[44, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[45, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[46, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[47, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[48, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[49, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[50, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "emulated (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.EMULATED"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[51, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[52, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[52, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[53, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[54, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "perchannelnormobserver (class in torchao.sparsity)": [[55, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[55, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[56, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[57, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[58, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[59, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[60, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[60, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})