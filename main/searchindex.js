Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizer", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizer.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizer", "Float8ActInt4WeightQATQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "quantize_affine", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 7, 8, 9, 11, 12, 21, 22, 23, 24, 26, 39, 40, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56, 60, 61, 64, 69, 70, 72, 73, 75, 76, 79, 80, 85, 86, 87, 89, 92, 93, 94, 95, 96, 98, 99, 101, 102, 105, 106, 107, 108, 109, 110, 111], "section": [2, 9, 93, 98, 102, 107, 108, 111], "introduc": [2, 11, 106, 107, 109, 110, 111], "dive": 2, "detail": [2, 7, 9, 11, 40, 53, 92, 93, 94, 96, 98, 99, 101, 106, 107, 108, 109], "how": [2, 4, 9, 11, 12, 18, 26, 45, 47, 49, 54, 69, 80, 90, 92, 94, 95, 96, 98, 99, 101, 102, 106, 109, 110], "integr": [2, 9, 90, 92, 95, 96, 98, 101, 109, 111], "pytorch": [2, 7, 9, 11, 12, 17, 20, 50, 69, 90, 92, 96, 98, 101, 102, 105], "optim": [2, 9, 11, 21, 39, 53, 79, 90, 92, 98, 101, 106, 108, 109, 110], "your": [2, 7, 9, 11, 90, 92, 93, 94, 96, 98, 107, 108, 109, 110, 111], "machin": [2, 108], "learn": [2, 45, 69, 94, 98, 105, 107, 109, 110, 111], "model": [2, 11, 39, 44, 46, 53, 58, 63, 64, 65, 66, 67, 68, 70, 74, 79, 82, 83, 86, 87, 89, 94, 98, 99, 101, 109, 110, 111], "dtype": [2, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 43, 50, 51, 53, 54, 55, 56, 60, 61, 63, 65, 66, 67, 69, 72, 73, 75, 76, 80, 89, 90, 92, 94, 95, 99, 101, 102, 107, 109, 110, 111], "quantiz": [2, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 30, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 89, 92, 95, 98], "sparsiti": [2, 7, 11, 15, 21, 24, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96], "tba": [3, 10, 91], "For": [4, 7, 9, 11, 12, 40, 69, 93, 94, 95, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "full": [4, 9, 11, 94, 99, 105, 106, 108], "exampl": [4, 7, 9, 11, 12, 39, 49, 53, 58, 60, 61, 64, 68, 69, 70, 74, 79, 86, 89, 93, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110], "us": [4, 7, 8, 11, 12, 16, 17, 18, 21, 22, 23, 26, 28, 31, 41, 42, 45, 46, 47, 49, 51, 53, 54, 55, 56, 58, 63, 64, 68, 69, 70, 75, 76, 80, 86, 90, 92, 93, 94, 95, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110], "our": [4, 9, 11, 22, 92, 94, 96, 98, 99, 101, 107, 108], "pleas": [4, 8, 9, 11, 12, 20, 40, 45, 90, 93, 94, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "refer": [4, 7, 9, 11, 12, 70, 76, 92, 96, 98, 99, 101, 102, 106, 107, 108, 109], "readm": [4, 7, 11, 90, 94, 98], "tutori": [7, 9, 11, 12, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111], "you": [7, 8, 9, 11, 69, 86, 92, 93, 94, 95, 96, 98, 101, 102, 105, 106, 107, 108, 109, 110, 111], "through": [7, 9, 11, 55, 60, 61, 90, 93, 94, 96, 99, 101, 102, 105, 106, 107, 111], "torchao": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 101, 106, 107, 108, 109, 110], "framework": [7, 11, 92, 96, 106], "The": [7, 9, 11, 12, 13, 18, 21, 26, 38, 40, 41, 42, 43, 53, 57, 70, 79, 81, 82, 83, 86, 92, 93, 94, 95, 96, 98, 101, 102, 106, 107, 108, 109, 110, 111], "contain": [7, 53, 82, 83, 98, 101, 108, 111], "new": [7, 9, 11, 12, 92, 93, 99, 101, 107, 108, 109, 111], "architectur": [7, 90, 96, 98, 106, 107, 109, 110], "micro": 7, "current": [7, 41, 46, 63, 70, 79, 83, 86, 89, 92, 94, 98, 101, 102, 107, 108, 110], "support": [7, 11, 12, 29, 41, 46, 63, 68, 69, 70, 89, 92, 94, 95, 96, 98, 101, 106, 107, 108, 109, 110, 111], "which": [7, 9, 11, 20, 26, 53, 70, 75, 92, 93, 94, 95, 96, 98, 99, 102, 106, 107, 108, 109, 110, 111], "can": [7, 9, 11, 25, 41, 44, 49, 53, 58, 69, 79, 80, 92, 93, 94, 95, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "quantize_": [7, 9, 11, 64, 68, 70, 79, 89, 93, 94, 95, 96, 99], "sparsity_": 7, "function": [7, 11, 12, 25, 38, 53, 60, 61, 72, 77, 78, 79, 85, 86, 87, 89, 92, 94, 95, 98, 99, 101, 102, 106, 111], "To": [7, 9, 11, 12, 20, 53, 76, 92, 93, 94, 95, 96, 98, 99, 102, 107, 108, 109, 111], "correspond": [7, 11, 64, 70, 79, 93, 95, 98, 101, 110, 111], "string": [7, 35, 69, 86], "string_to_config": 7, "microbenchmark": 7, "util": [7, 9, 44, 92, 93, 94, 95, 101, 102, 106, 107, 108, 109, 110, 111], "py": [7, 9, 12, 20, 96, 97, 104, 105, 109, 110], "def": [7, 11, 89, 92, 93, 94, 95, 99, 101, 102, 106, 107, 108, 109, 110, 111], "option": [7, 9, 12, 16, 20, 27, 30, 31, 32, 34, 35, 38, 41, 42, 44, 45, 47, 48, 53, 54, 55, 56, 60, 61, 63, 66, 68, 69, 70, 72, 73, 79, 80, 82, 83, 84, 86, 89, 92, 94, 102, 107, 108, 109, 110, 111], "str": [7, 35, 38, 44, 69, 70, 79, 83, 84, 86, 89, 92, 101, 102, 110], "kwarg": [7, 12, 60, 61, 63, 65, 69, 73, 85, 86, 87, 101, 102], "aobaseconfig": [7, 70, 79, 89, 99, 102], "code": [7, 9, 45, 92, 93, 94, 96, 98, 99, 101, 103, 105, 107, 108, 109, 110, 111], "elif": [7, 102], "my_new_quant": 7, "If": [7, 8, 11, 12, 16, 38, 41, 47, 48, 53, 57, 68, 69, 70, 81, 82, 86, 93, 94, 96, 98, 101, 107, 108], "addit": [7, 11, 18, 23, 53, 92, 98, 101, 106, 107, 110, 111], "inform": [7, 12, 96, 98, 102, 106, 107], "need": [7, 9, 11, 41, 60, 61, 72, 85, 86, 93, 94, 95, 96, 98, 101, 102, 107, 108, 109, 111], "pass": [7, 38, 47, 53, 55, 60, 61, 70, 72, 85, 93, 99, 101, 102, 108, 111], "process": [7, 11, 18, 21, 23, 25, 26, 53, 83, 93, 98, 105, 106, 110], "here": [7, 8, 9, 12, 70, 76, 80, 93, 94, 95, 96, 99, 101, 102, 106, 107, 108, 109, 110, 111], "return": [7, 11, 12, 20, 21, 22, 38, 53, 57, 69, 79, 81, 82, 83, 89, 92, 93, 94, 95, 99, 101, 102, 106, 107, 108, 109, 110, 111], "mynewquantizationconfig": 7, "my_new_spars": 7, "mynewsparsityconfig": 7, "rest": [7, 101, 108], "now": [7, 9, 11, 40, 46, 54, 92, 93, 94, 98, 99, 101, 106, 107, 109, 111], "we": [7, 9, 11, 12, 22, 49, 51, 53, 54, 55, 56, 68, 69, 70, 76, 79, 80, 89, 92, 93, 94, 95, 96, 98, 99, 102, 106, 107, 108, 109, 110, 111], "throughout": 7, "note": [7, 9, 11, 58, 68, 76, 86, 93, 94, 96, 98, 101, 102, 108, 109, 110], "input": [7, 9, 12, 21, 22, 24, 35, 38, 39, 53, 54, 55, 56, 57, 70, 74, 79, 80, 81, 86, 89, 92, 93, 94, 96, 99, 101, 106, 107, 108, 109, 110, 111], "paramet": [7, 11, 12, 18, 21, 22, 28, 31, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56, 57, 63, 69, 70, 73, 75, 76, 79, 80, 81, 82, 83, 86, 89, 92, 93, 95, 96, 98, 101, 102, 106, 107], "like": [7, 9, 11, 18, 53, 92, 93, 94, 95, 98, 101, 102, 106, 107, 108, 109, 110, 111], "bit": [7, 11, 26, 33, 40, 44, 51, 62, 96, 101, 102, 107, 109, 110], "width": [7, 26, 44, 62], "group": [7, 11, 45, 46, 48, 51, 63, 65, 66, 67, 69, 72, 73, 75, 76, 93, 94], "size": [7, 9, 12, 13, 20, 22, 44, 45, 46, 48, 51, 54, 56, 69, 80, 92, 94, 95, 96, 98, 99, 101, 102, 108], "etc": [7, 9, 60, 61, 93, 106, 111], "them": [7, 11, 53, 60, 61, 72, 85, 93, 111], "append": [7, 98, 107, 108], "config": [7, 11, 35, 38, 53, 59, 60, 61, 62, 64, 68, 69, 70, 79, 86, 89, 94, 96, 98, 99, 102, 107, 109, 110], "gemliteuintxweightonlyconfig": 7, "gemlitewo": 7, "bit_width": [7, 44], "group_siz": [7, 11, 44, 45, 46, 48, 51, 60, 61, 63, 65, 68, 69, 70, 72, 73, 79, 94, 102], "system": [7, 9, 96], "model_architectur": 7, "type": [7, 9, 11, 12, 21, 22, 26, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 50, 52, 53, 57, 69, 71, 80, 81, 90, 93, 95, 96, 98, 101, 102, 106, 107, 109, 110, 111], "defin": [7, 9, 18, 26, 36, 40, 60, 61, 72, 85, 86, 94, 98, 99, 101, 102, 106, 109, 110, 111], "class": [7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 85, 86, 93, 94, 95, 99, 101, 107, 108, 109, 111], "mycustommodel": 7, "torch": [7, 11, 12, 21, 22, 26, 28, 35, 38, 41, 42, 43, 45, 51, 53, 54, 56, 57, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 79, 80, 81, 82, 83, 89, 90, 92, 93, 94, 95, 96, 98, 99, 101, 102, 105, 109, 110, 111], "nn": [7, 11, 35, 38, 53, 58, 63, 65, 68, 70, 79, 82, 83, 89, 92, 93, 94, 95, 96, 98, 99, 101, 102, 107, 108, 109, 111], "modul": [7, 9, 11, 35, 36, 37, 38, 39, 49, 50, 52, 53, 58, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 85, 86, 89, 92, 94, 95, 99, 106, 107, 108, 109, 110, 111], "__init__": [7, 11, 94, 95, 99, 101, 102, 107, 108, 109], "self": [7, 11, 12, 93, 94, 95, 99, 101, 102, 107, 108, 109], "input_dim": 7, "output_dim": 7, "bfloat16": [7, 9, 22, 63, 66, 75, 80, 92, 93, 94, 95, 96, 98, 99, 102, 109, 110], "super": [7, 11, 94, 95, 99, 101, 107, 108, 109], "layer1": 7, "linear": [7, 9, 11, 21, 35, 38, 41, 43, 45, 46, 47, 48, 51, 53, 58, 61, 63, 66, 67, 68, 70, 75, 76, 77, 78, 79, 83, 87, 89, 92, 93, 94, 95, 96, 98, 99, 101, 106, 107, 108, 109, 111], "512": [7, 92], "bia": [7, 9, 11, 61, 75, 76, 93, 94, 95, 99, 101, 102, 108, 111], "fals": [7, 11, 12, 30, 35, 45, 47, 51, 53, 60, 61, 67, 68, 69, 70, 72, 73, 75, 76, 82, 86, 92, 93, 94, 95, 96, 99, 101, 102, 106, 107, 108, 110, 111], "activ": [7, 9, 11, 41, 42, 44, 46, 47, 53, 60, 61, 63, 67, 68, 69, 70, 76, 82, 86, 90, 94, 96, 98, 99, 102, 106, 109, 110, 111], "relu": [7, 94, 106, 111], "layer2": 7, "forward": [7, 47, 53, 60, 61, 62, 72, 75, 85, 93, 94, 95, 98, 99, 101, 102, 107, 108, 109], "x": [7, 51, 60, 61, 62, 72, 92, 94, 95, 96, 99, 101, 102, 105, 106, 107, 108, 109, 110], "updat": [7, 90, 94, 95, 98, 107, 108, 109, 111], "create_model_and_input_data": 7, "handl": [7, 21, 24, 25, 53, 93], "model_typ": [7, 11, 102, 106], "m": [7, 9, 11, 79, 89, 92, 94, 95, 96, 99, 101, 107, 108, 109], "int": [7, 11, 12, 13, 20, 22, 25, 26, 27, 28, 30, 31, 32, 33, 40, 44, 45, 46, 48, 51, 54, 55, 56, 60, 61, 63, 65, 66, 67, 69, 72, 73, 75, 76, 79, 80, 86, 94, 99, 101, 102], "k": [7, 9, 81, 94, 95, 99, 101, 107, 108], "n": [7, 9, 11, 94, 95, 99, 101, 107, 108, 111], "high_precision_dtyp": 7, "devic": [7, 9, 11, 12, 72, 75, 76, 79, 81, 92, 94, 95, 96, 99, 101, 102, 106, 107, 108, 109, 110], "cuda": [7, 9, 11, 12, 79, 92, 94, 95, 96, 98, 99, 101, 108], "my_custom_model": 7, "input_data": 7, "randn": [7, 11, 12, 61, 92, 94, 95, 99, 101, 106, 107, 108, 109, 110], "when": [7, 9, 11, 12, 23, 54, 56, 70, 80, 92, 93, 96, 98, 99, 102, 106, 107, 108, 109, 110, 111], "ad": [7, 11, 12, 56, 86, 98, 99, 101, 108], "dimens": [7, 9, 12, 26, 51, 54, 56, 57, 80, 92, 101, 102, 107, 108], "ensur": [7, 21, 96, 108], "convent": 7, "where": [7, 24, 49, 51, 55, 65, 66, 67, 93, 98, 102, 111], "batch": [7, 96, 99, 108], "sequenc": 7, "length": 7, "featur": [7, 11, 12, 101, 106, 109, 110], "data": [7, 11, 12, 13, 18, 21, 26, 41, 42, 43, 45, 47, 55, 90, 93, 95, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "typic": [7, 11, 22, 23, 93, 94, 95, 99, 102, 111], "compat": [7, 9, 21, 69, 94], "work": [7, 9, 11, 24, 44, 92, 95, 98, 101, 102, 107, 108, 109], "cpu": [7, 9, 12, 17, 95, 98, 99, 102, 106, 107, 108, 109], "other": [7, 11, 12, 18, 62, 86, 92, 95, 96, 98, 101, 102, 105, 107, 108, 109, 111], "target": [7, 9, 11, 41, 42, 43, 45, 54, 60, 61, 69, 86, 94, 98, 106, 107, 108, 109, 110, 111], "method": [7, 9, 18, 21, 24, 25, 53, 79, 86, 94, 98, 99, 101, 106, 107, 108, 110, 111], "come": [7, 8, 92, 93, 96, 98, 99, 100, 108, 109, 110], "soon": [7, 8, 64, 68, 96, 100, 108], "file": [7, 9, 92, 96, 97, 101, 102, 104, 107, 108], "microbenchmark_quantization_config": 7, "yml": 7, "benchmark_mod": 7, "infer": [7, 9, 11, 12, 70, 82, 90, 93, 94, 95, 98, 99, 101, 106, 107, 108, 109, 110], "quantization_config_recipe_nam": 7, "int8wo": 7, "int8dq": 7, "float8dq": [7, 96], "tensor": [7, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 43, 45, 46, 47, 53, 54, 55, 56, 57, 60, 61, 62, 80, 81, 84, 86, 90, 92, 94, 95, 98, 99, 105, 107, 109, 110], "row": [7, 57, 92, 98], "float8wo": 7, "output_dir": 7, "result": [7, 11, 53, 57, 81, 93, 98, 99, 107, 108, 109, 110, 111], "model_param": 7, "name": [7, 36, 37, 49, 50, 52, 71, 79, 83, 86, 89, 96, 98, 101, 102, 106, 107, 108, 111], "small_bf16_linear": 7, "matrix_shap": 7, "small_sweep": 7, "min_pow": 7, "10": [7, 9, 11, 49, 60, 80, 92, 94, 96, 99, 107, 108], "max_pow": 7, "15": [7, 92, 94, 96], "use_torch_compil": 7, "true": [7, 9, 11, 12, 30, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 60, 61, 68, 69, 70, 78, 79, 82, 89, 92, 94, 95, 96, 99, 101, 102, 106, 107, 108, 109, 111], "torch_compile_mod": 7, "max": [7, 9, 49, 93, 94, 99, 101, 107, 108, 111], "autotun": [7, 9, 94, 99], "runner": 7, "gener": [7, 11, 12, 60, 61, 62, 93, 94, 96, 98, 99, 101, 102, 103, 105, 106, 108, 109, 110, 111], "oss": 7, "databas": 7, "python": [7, 9, 93, 94, 96, 98, 103, 105, 106, 107, 109, 110], "ci_microbenchmark_runn": 7, "benchmark_result": 7, "json": [7, 96, 102], "specif": [7, 9, 11, 18, 21, 23, 24, 60, 61, 76, 86, 92, 93, 94, 95, 96, 98, 106, 109, 110, 111], "requir": [7, 11, 23, 25, 92, 93, 94, 96, 98, 101, 106, 109, 111], "mode": [7, 9, 44, 45, 53, 94, 99, 106, 108, 109, 110, 111], "extra_info": 7, "arch": 7, "nvidia": [7, 98], "a100": [7, 11, 94], "sxm4": 7, "80gb": [7, 94], "1024": [7, 79, 89, 94, 95, 109], "custom": [7, 11, 18, 70, 85, 90, 92, 93, 94, 98, 101, 102, 106, 107, 109, 111], "layer": [7, 21, 38, 41, 43, 45, 47, 48, 51, 53, 60, 61, 63, 65, 66, 67, 72, 73, 75, 76, 82, 83, 86, 87, 92, 96, 98, 99, 101, 102, 106, 111], "origin": [7, 11, 12, 22, 43, 47, 64, 80, 86, 93, 94, 95, 96, 98, 106, 107, 111], "metric": [7, 11, 86], "speedup": [7, 9, 11, 45, 92, 93, 94, 96, 98], "wrt": 7, "bf16": [7, 11, 54, 70, 93, 94, 98, 109, 110], "benchmark_valu": 7, "25": [7, 94], "target_valu": 7, "0": [7, 9, 11, 12, 53, 60, 69, 72, 73, 80, 83, 86, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 110, 111], "depend": [7, 12, 44, 53, 95, 98, 101, 107, 108, 110], "step": [7, 11, 23, 39, 53, 70, 71, 92, 93, 98, 106, 107, 108, 109, 110, 111], "workflow": [7, 79, 89, 92, 94, 98, 111], "github": [7, 9, 12, 20, 40, 94, 96], "action": [7, 102, 107, 108], "upload": 7, "verifi": [7, 94, 95, 101], "setup": [7, 96], "suit": [7, 9, 107, 109], "unittest": 7, "discov": 7, "out": [7, 9, 11, 24, 49, 53, 86, 92, 93, 94, 98, 101, 106, 107, 108, 109], "memori": [7, 9, 11, 12, 92, 94, 98, 101, 109, 110], "reduc": [7, 11, 39, 70, 92, 96, 98, 109], "matrix": [7, 13, 16, 41, 42, 57, 81, 86, 94, 98, 109], "compil": [7, 11, 53, 79, 81, 90, 92, 93, 94, 99, 101, 109, 110], "error": [7, 49, 53, 69, 92, 101, 107], "set": [7, 11, 12, 16, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 55, 69, 79, 82, 86, 94, 98, 106, 108, 109, 110], "debug": [7, 82], "miss": [7, 98], "properli": [7, 95], "instal": [7, 92, 94, 96, 107, 110], "Not": [7, 98], "avail": [7, 93, 106, 107, 108, 109, 110], "check": [7, 9, 11, 12, 20, 93, 94, 95, 101, 106, 108, 111], "driver": 7, "basic": [7, 9, 23, 94, 99, 101], "shape": [7, 9, 12, 20, 53, 57, 81, 94, 99, 101, 102, 107, 110], "comprehens": [7, 102, 109], "analysi": [7, 98], "enabl": [7, 78, 92, 93, 96, 102, 109], "profil": [7, 9], "onli": [7, 9, 11, 17, 38, 41, 43, 44, 45, 46, 47, 48, 51, 63, 70, 76, 89, 92, 94, 95, 96, 98, 101, 102, 106, 107, 109, 110, 111], "overhead": [7, 98, 102, 109], "multipl": [7, 11, 16, 41, 42, 53, 57, 58, 81, 94, 98, 99, 101, 102, 109, 111], "possibl": [7, 12, 98, 107, 108, 109, 111], "consist": [7, 96, 98, 101, 109, 110, 111], "reproduc": [7, 96], "differ": [7, 9, 11, 18, 45, 55, 58, 80, 81, 92, 93, 94, 95, 96, 98, 101, 102, 107, 108, 109, 111], "case": [7, 8, 9, 53, 70, 81, 96, 98, 101, 102, 106, 107, 111], "user": [7, 11, 53, 58, 70, 76, 90, 92, 93, 94, 96, 98, 99, 101, 105, 107, 108, 109, 110, 111], "more": [7, 9, 11, 12, 40, 44, 45, 46, 51, 53, 92, 93, 94, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110], "about": [7, 9, 11, 45, 93, 94, 95, 96, 98, 107, 108, 109, 111], "compon": [7, 93, 101, 102], "see": [7, 9, 11, 12, 20, 40, 92, 93, 94, 95, 96, 98, 99, 101, 102, 106, 107, 111], "directori": [7, 92], "intend": [8, 93, 107], "provid": [8, 9, 11, 18, 21, 24, 25, 53, 54, 58, 74, 92, 93, 96, 98, 101, 102, 107, 108, 110, 111], "instruct": [8, 11, 94, 96, 107, 108, 109], "most": [8, 23, 70, 93, 96, 98, 102, 107, 108, 111], "fequent": 8, "have": [8, 9, 11, 44, 45, 49, 53, 65, 66, 67, 80, 86, 93, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "ani": [8, 9, 23, 53, 63, 65, 74, 84, 86, 93, 98, 101, 106, 108, 110], "answer": [8, 98], "creat": [8, 9, 12, 28, 29, 31, 92, 93, 98, 101, 106, 107, 109, 110, 111], "an": [8, 9, 11, 12, 25, 30, 31, 53, 68, 69, 70, 76, 86, 90, 92, 93, 94, 96, 98, 99, 101, 106, 107, 108, 109, 110, 111], "issu": [8, 9, 93, 94, 101, 109], "train": [9, 35, 58, 69, 70, 90, 94, 98, 101, 111], "fp4": 9, "s": [9, 11, 12, 49, 53, 54, 56, 80, 92, 93, 94, 96, 98, 99, 101, 107, 108, 109, 110, 111], "fine": [9, 44, 45, 46, 51, 90, 92, 96, 98], "start": [9, 11, 36, 37, 49, 50, 52, 53, 71, 92, 93, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "prototyp": [9, 69, 74, 93, 111], "folder": [9, 96, 107, 108], "could": [9, 93, 101, 106, 107, 109, 110, 111], "also": [9, 11, 53, 69, 79, 93, 94, 95, 98, 99, 101, 102, 107, 110, 111], "take": [9, 22, 60, 61, 72, 79, 85, 89, 93, 98, 106, 107, 108, 109, 110, 111], "look": [9, 12, 92, 93, 98, 106, 107, 108, 109, 110], "affinequantizedtensor": [9, 20, 28, 29, 31, 93, 94, 95, 99, 101], "what": [9, 11, 12, 20, 53, 92, 93, 94, 96, 98, 99, 102, 105, 107, 111], "want": [9, 79, 89, 93, 94, 95, 98, 101, 102, 106, 107, 108, 111], "do": [9, 50, 53, 57, 79, 93, 96, 98, 99, 101, 102, 107, 108, 109, 111], "mostli": [9, 55, 70, 94, 109], "e": [9, 11, 12, 40, 49, 53, 54, 56, 58, 69, 70, 79, 80, 92, 93, 95, 99, 101, 106, 111], "g": [9, 11, 12, 40, 49, 53, 54, 56, 58, 69, 70, 79, 80, 93, 95, 99, 101, 106, 111], "int3": 9, "exact": [9, 11, 76, 107, 108], "same": [9, 11, 12, 41, 54, 55, 56, 76, 80, 81, 89, 92, 93, 98, 99, 101, 108, 109, 110, 111], "affin": [9, 12, 14, 15, 16, 17, 21, 24, 25, 30, 56, 80, 93], "feel": [9, 93, 98, 101, 102], "free": [9, 93, 101], "open": [9, 93, 98], "question": [9, 93, 95, 98, 101, 111], "overview": [9, 90, 94, 102], "page": [9, 94, 109], "contribut": [9, 94, 98], "exist": [9, 50, 70, 92, 93, 98, 99, 101, 107, 111], "base": [9, 18, 23, 49, 59, 62, 70, 74, 86, 93, 94, 98, 101, 102, 106, 107, 108, 109, 110, 111], "make": [9, 93, 94, 101, 102, 107, 111], "trainabl": [9, 11, 93, 101], "add": [9, 23, 101, 105, 109, 111], "parallel": [9, 92, 101, 102], "affine_quantized_tensor": [9, 95], "api": [9, 53, 93, 94, 98, 99, 101, 106, 107, 108, 109, 110], "quant_api": [9, 79, 95, 96, 99], "primit": [9, 12, 20, 101, 107], "op": [9, 11, 12, 20, 45, 53, 79, 94, 98, 101, 102, 107, 108, 109, 111], "slight": [9, 98], "variat": [9, 93], "quant_primit": [9, 12, 20, 99], "mp": 9, "csrc": 9, "mayb": [9, 34], "well": [9, 18, 53, 93, 94, 98, 107, 108, 111], "spars": [9, 13, 21, 24, 60, 72, 73, 86, 93, 98], "marlin": [9, 19, 20, 21, 32], "aqt": 9, "621": 9, "ar": [9, 11, 12, 16, 24, 26, 38, 40, 41, 44, 45, 53, 54, 56, 58, 60, 61, 68, 70, 79, 80, 81, 86, 92, 93, 94, 95, 96, 98, 99, 102, 106, 107, 108, 109, 110, 111], "still": [9, 11, 93, 98, 107, 111], "decid": [9, 93, 98, 99], "split": [9, 96, 107, 108], "implement": [9, 11, 35, 72, 73, 75, 76, 95, 98, 99, 106, 107, 111], "regist": [9, 60, 61, 72, 85, 101], "mai": [9, 55, 69, 93, 95, 99, 107, 108, 109, 110, 111], "own": [9, 11, 90, 92, 94, 98, 99, 107, 108, 111], "int4": [9, 11, 14, 17, 46, 49, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 79, 89, 94, 95, 96, 102], "access": [9, 47, 106], "my_custom_op": 9, "condit": [9, 93], "__torch_function__": [9, 93, 101], "__torch_dispatch__": [9, 101], "oper": [9, 11, 12, 16, 18, 21, 47, 55, 94, 96, 106, 107, 108, 109, 110], "uint4": [9, 45, 93, 94], "weight": [9, 11, 21, 22, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 60, 61, 63, 65, 66, 67, 69, 70, 72, 73, 75, 76, 79, 86, 89, 90, 92, 94, 95, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111], "found": [9, 93, 94, 96, 98, 99, 101], "allow": [9, 76, 94, 98, 101, 106, 107, 108, 109, 111], "peopl": [9, 93, 95, 102, 111], "two": [9, 11, 20, 24, 41, 70, 93, 94, 98, 101, 106, 107, 108, 109, 111], "dispatch_condit": [9, 93], "impl": [9, 12, 93], "actual": [9, 11, 43, 70, 93, 99, 101, 102, 107, 108, 111], "run": [9, 11, 39, 53, 60, 61, 72, 79, 82, 85, 92, 93, 94, 96, 98, 101, 105, 106, 107, 108, 109, 110, 111], "both": [9, 12, 41, 70, 76, 93, 94, 98, 99, 101, 107, 109, 110, 111], "input_tensor": [9, 22, 93, 102], "weight_tensor": [9, 93, 102], "argument": [9, 12, 25, 53, 56, 69, 70, 79, 92, 93, 96, 109], "register_aqt_quantized_linear_dispatch": 9, "show": [9, 80, 92, 93, 94, 96, 98, 102, 107, 108], "sometim": [9, 98], "ha": [9, 11, 12, 70, 93, 96, 98, 101, 102, 106, 107, 108, 110, 111], "pack": [9, 12, 14, 25, 26, 40, 44, 51, 93], "order": [9, 53, 58, 93, 98, 101, 111], "yield": [9, 11, 98], "And": [9, 22, 41, 93, 101, 109, 111], "abstract": [9, 93], "after": [9, 11, 39, 53, 92, 93, 95, 98, 106, 107, 108, 109, 110, 111], "wrap": [9, 53, 101, 109, 110], "factori": 9, "convert": [9, 11, 12, 20, 22, 27, 30, 32, 33, 35, 58, 64, 65, 70, 79, 89, 92, 93, 96, 98, 106, 109, 110, 111], "from": [9, 11, 12, 22, 23, 28, 29, 31, 40, 46, 55, 64, 68, 70, 79, 80, 89, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111], "float": [9, 11, 12, 20, 22, 30, 32, 33, 40, 45, 49, 52, 53, 54, 55, 56, 60, 69, 72, 73, 80, 83, 86, 93, 94, 95, 101, 107, 108, 111], "point": [9, 12, 20, 32, 40, 45, 49, 52, 56, 69, 73, 74, 75, 76, 92, 93, 94, 95, 98, 99, 101, 107, 111], "my": [9, 98, 108], "to_my_dtyp": 9, "mydtypetensor": 9, "from_float": [9, 99, 101], "level": [9, 86, 93, 98, 101, 106, 107, 109, 110], "reus": [9, 93, 101], "appli": [9, 11, 12, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 58, 62, 63, 68, 70, 79, 89, 93, 94, 96, 98, 102, 108], "convers": [9, 11, 12, 38, 93], "filter": [9, 11, 38, 53, 92, 99], "choos": [9, 93, 98, 101, 107, 109], "should": [9, 11, 12, 39, 44, 56, 60, 61, 64, 70, 72, 85, 86, 92, 93, 98, 102, 106, 107, 111], "algorithm": [9, 45, 51, 96, 98, 106], "dynam": [9, 11, 34, 35, 39, 41, 44, 46, 47, 63, 67, 69, 76, 89, 96, 99, 101, 107, 108, 109], "quant": [9, 12, 20, 40, 93, 96, 102, 107, 110, 111], "static": [9, 12, 18, 22, 28, 31, 35, 42, 55, 69, 90, 94, 107, 108, 109, 110, 111], "2": [9, 12, 15, 17, 21, 24, 45, 49, 53, 60, 69, 72, 73, 80, 87, 89, 90, 92, 93, 98, 99, 101, 105], "4": [9, 11, 15, 21, 24, 33, 44, 87, 89, 93, 94, 95, 96, 98, 101, 107, 108], "below": [9, 92, 93, 98, 101, 102, 105, 106], "follow": [9, 11, 45, 69, 70, 92, 93, 94, 96, 98, 99, 101, 106, 107, 108, 109, 110, 111], "import": [9, 11, 64, 68, 70, 79, 89, 94, 95, 96, 98, 99, 101, 102, 105, 106, 109, 110], "unwrap_tensor_subclass": [9, 94], "m_unwrap": 9, "In": [9, 11, 70, 92, 93, 94, 98, 99, 101, 106, 107, 108, 109, 110, 111], "aim": [9, 93, 98, 110], "fullgraph": [9, 94], "first": [9, 22, 53, 57, 70, 86, 93, 96, 99, 101, 102, 107, 108, 111], "remov": [9, 54, 86, 92, 98, 102, 107, 108], "unnecessari": 9, "graph": [9, 94, 107, 108, 111], "break": 9, "torch_log": 9, "output_cod": 9, "script": [9, 94, 96, 99, 101, 105, 108, 109, 110], "inductor": [9, 53, 90, 94, 106, 107], "checkout": [9, 12, 20, 90, 93], "doc": [9, 92, 93, 94, 96, 101], "huggingfac": 9, "transform": [9, 11, 12, 93, 99, 106, 107, 108, 109, 110], "deseri": [9, 93, 107, 108], "save_pretrain": [9, 96], "push_to_hub": [9, 96, 102], "from_pretrain": [9, 11, 96, 102], "http": [9, 12, 20, 40, 53, 86, 94, 96, 98, 110], "co": [9, 96], "main": [9, 12, 20, 45, 93, 94, 96, 98, 99, 101, 107, 111], "en": [9, 53], "anoth": [9, 93, 98, 101, 107, 111], "diffus": 9, "com": [9, 12, 20, 40, 96], "sayakpaul": 9, "blob": [9, 12, 20], "serialization_and_load": 9, "md": 9, "abov": [9, 11, 49, 93, 95, 98, 99, 101, 107, 108, 111], "just": [9, 49, 69, 93, 95, 98, 101, 107, 108, 111], "talk": [9, 93, 96], "fsdp": [9, 93], "ll": [9, 49, 92, 93, 96, 101, 107, 108, 111], "put": [9, 89, 109, 111], "developer_api_guid": 9, "cover": [9, 93, 105, 107, 110, 111], "executorch": [9, 46, 79, 90, 94, 107, 108], "torchchat": 9, "todo": [9, 93], "qat": [9, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 90, 96, 109], "dtensor": [9, 101], "recommend": [9, 11, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 92, 106, 109, 110], "copi": [9, 12, 86, 94, 95, 98, 99, 101, 108, 109], "past": [9, 98], "adapt": [9, 92, 99], "befor": [9, 11, 70, 79, 93, 95, 96, 98, 99, 101, 107, 108, 111], "some": [9, 53, 79, 86, 93, 94, 96, 98, 99, 101, 106, 107, 108, 109, 110, 111], "singl": [9, 11, 34, 39, 41, 53, 55, 92, 94, 98, 107, 111], "comput": [9, 21, 25, 39, 43, 60, 61, 72, 85, 86, 98, 99, 101, 107, 108, 109, 110], "intens": 9, "get": [9, 11, 22, 76, 92, 93, 94, 96, 98, 102, 106, 107, 108, 109, 111], "sens": [9, 93, 101], "d": [9, 93, 96, 108], "benchmark_aq": 9, "A": [9, 11, 12, 26, 53, 55, 85, 98, 101, 102, 107], "quick": [9, 90], "wai": [9, 12, 53, 70, 92, 93, 96, 98, 99, 101, 107, 108, 111], "relev": [9, 45, 93, 105], "chang": [9, 79, 92, 93, 94, 95, 96, 98, 99, 101, 106, 107, 108, 110, 111], "interest": [9, 93, 98, 101], "print_op_and_shap": 9, "output": [9, 11, 35, 53, 54, 56, 80, 92, 93, 94, 96, 98, 105, 106, 107, 108, 109, 110, 111], "torch_func": 9, "built": [9, 92, 101], "_c": 9, "tensorbas": 9, "object": [9, 26, 79, 89, 101, 107, 108, 111], "arg": [9, 12, 60, 61, 63, 65, 73, 86, 101, 102, 108, 111], "all": [9, 39, 49, 53, 55, 60, 61, 63, 65, 72, 74, 85, 86, 87, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 109, 111], "under": [9, 11, 96], "benchmark_your_kernel": 9, "helper": [9, 77, 78], "right": [9, 93, 98, 107], "1": [9, 21, 26, 36, 37, 45, 49, 50, 51, 52, 53, 71, 80, 86, 90, 93, 94, 95, 97, 98, 99, 101, 104, 105, 107, 108], "either": [9, 12, 41, 86, 96, 98, 108, 109, 110], "one": [9, 41, 53, 55, 60, 61, 70, 72, 85, 92, 93, 98, 101, 102, 108, 111], "probabl": 9, "keep": [9, 21, 47, 86, 107], "futur": [9, 40, 99, 102, 107, 108, 109, 111], "llama": [9, 11, 96, 102, 106], "llama2": 9, "llama3": [9, 11, 92], "sam": 9, "alreadi": [9, 12, 53, 101, 111], "modifi": [9, 38, 79, 86, 92, 93, 98, 101], "friendli": [9, 93], "compar": [9, 11, 45, 86, 92, 93, 96, 107, 109, 111], "techniqu": [9, 11, 92, 95, 96, 98, 99, 101, 102], "repres": [9, 12, 13, 16, 18, 29, 35, 59, 69, 80, 86, 93, 95, 101, 107, 108], "bound": [9, 96, 98, 102], "help": [9, 11, 92, 93, 96, 102, 106, 107], "each": [9, 22, 53, 63, 69, 73, 75, 76, 82, 85, 93, 98, 99, 101, 102, 107, 108, 111], "understand": [9, 92, 109, 111], "profile_path": 9, "chrome": 9, "trace": [9, 93], "let": [9, 49, 80, 93, 94, 98, 99, 101, 111], "know": [9, 53, 101], "end": [11, 92, 93, 96, 98, 101, 102, 105, 108, 111], "pre": [11, 18, 21, 25, 90, 94, 96, 98, 111], "serv": [11, 12, 18, 90, 92, 101, 110], "flow": [11, 46, 92, 96, 98, 99, 106, 107, 108, 109, 110], "leverag": [11, 92, 94, 96, 101, 109, 110], "partner": [11, 92, 96], "showcas": [11, 92, 96], "focus": [11, 92, 93, 96, 98], "domain": [11, 12, 45, 52, 54, 56, 69, 92], "demonstr": [11, 92, 93, 94, 96, 101, 106, 108], "dure": [11, 12, 20, 47, 53, 56, 69, 70, 83, 92, 94, 96, 98, 99, 101, 106, 108], "numer": [11, 53, 70, 75, 76, 92, 98, 107, 108, 109], "goal": [11, 70], "mitig": [11, 98], "degrad": [11, 70, 98], "eventu": [11, 70, 92], "blog": 11, "resourc": [11, 101], "small": 11, "matric": [11, 24, 98], "freez": [11, 108, 109, 110], "checkpoint": [11, 92, 96, 102], "effici": [11, 25, 75, 94, 98, 99, 110], "paper": [11, 40, 98, 105], "speed": [11, 79, 96, 98, 106], "up": [11, 22, 69, 79, 92, 93, 94, 98, 106, 107, 108, 111], "high": [11, 12, 27, 28, 29, 30, 31, 70, 92, 93, 96, 98, 99, 101, 106, 107, 109, 110], "precis": [11, 12, 27, 28, 29, 30, 31, 43, 47, 63, 66, 67, 70, 73, 75, 76, 93, 99, 101, 106, 109, 110], "similar": [11, 93, 98, 99, 108, 109], "so": [11, 53, 92, 93, 94, 95, 98, 101, 107, 108, 111], "inevit": 11, "presum": 11, "been": [11, 53, 101, 108, 109, 110, 111], "successfulli": [11, 98], "recent": [11, 90], "releas": [11, 94, 109], "1b": [11, 102], "3b": 11, "llamaguard": 11, "8b": [11, 92], "improv": [11, 92, 96, 98, 107, 110, 111], "qualiti": [11, 98], "involv": [11, 16, 70, 98], "separ": [11, 60, 61, 69, 98, 102, 107, 111], "prepar": [11, 53, 58, 63, 65, 70, 82, 86, 93, 98, 106, 109, 110, 111], "fake": [11, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 92, 107, 108, 111], "mean": [11, 12, 22, 49, 54, 56, 80, 92, 93, 94, 98, 107, 108, 111], "valu": [11, 12, 22, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 71, 80, 82, 86, 93, 98, 99, 101, 106, 107, 108, 111], "map": [11, 47, 49, 69, 93, 101, 107, 111], "without": [11, 64, 93, 98, 102, 109, 111], "cast": [11, 34, 36], "lower": [11, 46, 93, 94, 96, 98, 99, 108], "replac": [11, 83, 98, 102], "real": [11, 94, 107, 111], "doe": [11, 23, 45, 70, 93, 98, 101, 107, 109, 110], "perform": [11, 12, 25, 39, 44, 47, 48, 53, 57, 60, 61, 65, 66, 67, 72, 81, 82, 85, 92, 94, 98, 99, 101, 102, 106, 108, 109, 110], "There": [11, 70, 93, 99, 101, 107, 111], "directli": [11, 49, 55, 70, 93, 98, 99, 101], "loop": [11, 92, 98], "distribut": [11, 92, 99, 101, 102, 106], "recip": [11, 35, 60, 61, 72, 85], "instead": [11, 45, 55, 60, 61, 69, 70, 72, 85, 92, 93, 94, 98, 101, 108, 109, 110, 111], "command": [11, 92, 94], "regular": [11, 106, 109, 110], "nnode": 11, "nproc_per_nod": 11, "full_finetune_distribut": 11, "llama3_2": 11, "3b_full": 11, "batch_siz": [11, 95, 96, 99, 107, 108], "16": [11, 61, 92], "equival": [11, 69, 83, 98, 108, 109, 111], "specifi": [11, 12, 35, 38, 48, 51, 58, 60, 61, 62, 70, 76, 79, 80, 86, 89, 92, 98, 106, 107, 108, 111], "default": [11, 12, 13, 16, 23, 25, 26, 41, 42, 43, 44, 45, 51, 53, 54, 56, 63, 69, 76, 79, 82, 83, 92, 94, 101, 102, 106, 107, 108, 109, 110, 111], "asymmetr": [11, 44, 45, 46, 49, 51, 54, 69, 93, 94, 99, 106, 110, 111], "per": [11, 12, 43, 45, 46, 47, 48, 51, 54, 56, 63, 65, 66, 67, 69, 72, 73, 75, 76, 80, 86, 92, 93, 94, 98, 99, 110], "token": [11, 46, 47, 67, 69, 76, 92, 96], "int8": [11, 22, 46, 47, 48, 61, 67, 68, 69, 70, 76, 79, 89, 93, 96, 101, 107, 109, 110, 111], "symmetr": [11, 41, 42, 43, 44, 46, 47, 48, 49, 54, 60, 63, 69, 101, 106, 107, 110, 111], "configur": [11, 16, 34, 35, 38, 41, 42, 43, 45, 46, 47, 48, 51, 79, 89, 92, 93, 94, 96, 109, 110, 111], "_component_": 11, "qat_distribut": 11, "3b_qat_ful": 11, "evalu": [11, 108], "whether": [11, 45, 51, 52, 53, 54, 69, 101], "wa": [11, 101, 108], "llama3_2_3b": 11, "fullmodelhfcheckpoint": 11, "checkpoint_fil": 11, "00001": 11, "00002": 11, "safetensor": 11, "int8dynactint4weightquant": 11, "groupsiz": [11, 66, 67, 75, 76, 80], "32": [11, 44, 45, 46, 61, 68, 69, 70, 72, 73, 79, 89, 92, 94, 95, 96, 99, 101, 108], "hellaswag": [11, 96], "wikitext": 11, "eleuther_ev": 11, "eleuther_evalu": 11, "task": [11, 96], "fullmodeltorchtunecheckpoint": 11, "8da4w": [11, 96], "ckpt": 11, "llama3_token": 11, "path": [11, 79, 81, 94, 96, 106, 107, 108, 109, 111], "tmp": [11, 94], "meta": [11, 95, 102, 111], "print": [11, 86, 94, 95, 96, 101, 105, 107, 108], "version": [11, 17, 69, 92, 94, 101, 102, 107, 108, 111], "shot": [11, 98], "stderr": 11, "none": [11, 12, 16, 20, 27, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 48, 49, 50, 52, 53, 54, 55, 56, 60, 61, 63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 84, 86, 89, 99, 101, 102, 106, 107, 108, 110], "acc": [11, 107, 108], "5021": 11, "0050": 11, "acc_norm": 11, "6797": 11, "0047": 11, "bits_per_byt": 11, "6965": 11, "byte_perplex": 11, "6206": 11, "word_perplex": 11, "13": 11, "2199": 11, "much": [11, 94, 98, 111], "openassist": 11, "oasst1": 11, "dataset": [11, 92, 93, 96, 106, 109, 110], "find": [11, 22, 98, 107, 111], "achiev": [11, 22, 92, 98, 99, 101, 108, 109], "higher": [11, 92, 93, 101, 106, 107, 109, 110], "accuraci": [11, 92, 96, 98, 99, 106, 108, 109], "than": [11, 26, 69, 92, 93, 98, 101, 107], "recov": [11, 98, 108], "69": [11, 99], "8": [11, 25, 26, 44, 45, 49, 60, 61, 66, 75, 92, 93, 94, 96, 102, 109, 110], "overal": [11, 90, 94, 107, 111], "vanilla": 11, "compos": [11, 58, 93, 98, 101, 107, 108, 111], "lora": 11, "89x": 11, "usag": [11, 12, 39, 53, 58, 60, 61, 64, 68, 69, 70, 90, 92, 96, 109, 110], "36": [11, 92, 96], "qat_lora_finetune_distribut": 11, "3b_qat_lora": 11, "try": [11, 93, 98, 101, 107], "fsdp2": [11, 92], "yaml": 11, "onc": [11, 53, 98], "complet": [11, 53, 96, 106, 110], "save": [11, 86, 92, 94, 95, 96, 102], "qat_out": 11, "quatiz": 11, "document": [11, 101, 102, 106, 107, 109], "prefer": [11, 93, 94, 101], "call": [11, 12, 53, 60, 61, 72, 85, 93, 94, 95, 98, 99, 101, 102, 108, 110], "These": [11, 98, 101, 106, 107, 108, 111], "hood": 11, "mini": [11, 96], "gpu": [11, 90, 92, 94, 102, 105, 106], "smaller": [11, 26, 44, 45, 46, 51, 94, 95], "fit": [11, 25, 93, 95], "adjust": [11, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53], "attribut": [11, 101, 102, 109, 110], "accordingli": 11, "get_model": 11, "vocab_s": 11, "4096": [11, 92], "num_lay": 11, "num_head": 11, "num_kv_head": 11, "embed_dim": 11, "2048": [11, 92], "max_seq_len": 11, "train_loop": [11, 70], "sgd": 11, "lr": [11, 92], "001": 11, "momentum": [11, 108], "9": [11, 92], "weight_decai": 11, "1e": [11, 92], "5": [11, 49, 60, 83, 86, 92, 94, 96, 98, 102, 105, 107, 108], "loss_fn": 11, "crossentropyloss": [11, 107, 108], "i": [11, 81, 92, 96, 98, 106, 107, 108], "rang": [11, 49, 92, 98, 99, 107, 108], "randint": 11, "loss": [11, 92, 98, 107, 108], "backward": [11, 39, 92, 98, 108], "zero_grad": [11, 92, 108], "next": [11, 92, 93, 99, 107, 108, 109, 110], "scheme": [11, 47, 48, 60, 61, 70, 96, 106], "although": [11, 60, 61, 72, 85, 101], "integ": [11, 12, 30, 31, 44, 45, 49, 52, 54, 56, 57, 69, 81, 99, 107, 108, 109], "arithmet": [11, 70], "float32": [11, 12, 28, 56, 65, 67, 69, 72, 73, 76, 80, 95, 96, 98, 99, 101, 109, 110, 111], "becaus": [11, 21, 92, 93, 95, 98, 101, 108, 111], "int8dynamicactivationint4weightconfig": [11, 70, 76], "qatconfig": [11, 71], "swap": [11, 38, 63, 65, 92, 93, 98, 99, 108], "fakequantizedlinear": [11, 63, 64, 77, 78], "base_config": [11, 70], "structur": [11, 24, 89, 94, 95, 98, 101, 107], "attun": 11, "benefici": 11, "later": [11, 93, 101, 107, 108, 110], "readi": [11, 92, 94, 96, 99, 101, 108], "did": [11, 46], "altern": [11, 69, 93, 99, 101, 109, 110], "legaci": 11, "offer": [11, 101, 107], "customiz": [11, 79], "unlik": [11, 99], "int8dynactint4weightqatquant": 11, "qat_quant": 11, "insert": [11, 94, 99, 106, 107, 108, 109, 110, 111], "int8dynactint4weightqatlinear": 11, "int8dynactint4weightlinear": 11, "fraction": 11, "therebi": 11, "significantli": [11, 106, 107, 109, 110], "footprint": 11, "extens": [11, 101, 107, 109], "addition": [11, 109, 110], "frozen": 11, "further": [11, 93, 101, 106, 107, 108, 109], "nf4": [11, 22], "propos": [11, 86], "express": [11, 94, 101, 106, 107, 108, 111], "subclass": [11, 12, 20, 38, 53, 60, 61, 72, 85, 89, 94, 95, 98], "nf4tensor": 11, "cleanli": 11, "simpli": [11, 53, 98, 99, 101], "to_nf4": 11, "frozennf4linear": 11, "in_dim": 11, "out_dim": 11, "bool": [11, 12, 30, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 60, 61, 67, 69, 72, 73, 75, 76, 78, 79, 82, 89, 99], "quantization_kwarg": 11, "No": [11, 93, 95, 98], "requires_grad_": 11, "nf4_weight": 11, "requires_grad": [11, 93, 99, 101, 102], "though": [11, 101], "shown": [11, 96, 98, 108, 111], "competit": [11, 92], "baselin": [11, 92, 96, 107], "while": [11, 60, 61, 70, 72, 85, 86, 96, 98, 101, 106, 107, 111], "even": [11, 12, 92, 98, 111], "newer": 11, "mxfp4": 11, "nvfp4": 11, "blackwel": 11, "reap": 11, "benefit": [11, 98, 101, 107, 110], "vari": [11, 107, 108, 109, 110], "tradeoff": [11, 98], "incorpor": 11, "its": [11, 44, 98, 101, 102, 107, 111], "loralinear": 11, "lora_finetune_single_devic": 11, "3b_qlora_single_devic": 11, "limit": [11, 92, 101, 102, 107], "yet": [11, 46, 50, 70, 101, 102, 108, 109, 110], "invok": [11, 109], "loraconfig": 11, "get_peft_model": 11, "automodelforcausallm": [11, 96, 102], "torchaoconfig": [11, 96, 102], "int8weightonlyconfig": [11, 102], "base_model": 11, "quantization_config": [11, 96, 102, 110], "peft_config": 11, "throughput": [11, 92, 96], "increas": [11, 98, 107], "torchtitan": 11, "enable_fp8_train": 11, "fp8_recipe_nam": 11, "tensorwis": [11, 34, 35], "initi": [11, 12, 74, 93, 94, 95, 108], "experi": [11, 92, 110], "saw": 11, "experiment_nam": 11, "tok": 11, "peak_mem_reserv": 11, "6502": 11, "143": 11, "000": 11, "30": [11, 92, 94, 107], "090": 11, "fp8_nonam": 11, "7205": 11, "386": 11, "816": 11, "010": 11, "266": 11, "fp8_tensorwis": 11, "7222": 11, "198": 11, "11": [11, 92], "074": [11, 92], "fp8_rowwis": 11, "6387": 11, "968": 11, "756": 11, "29": [11, 92], "158": 11, "096": 11, "fp8_rowwise_with_gw_hp": 11, "7573": 11, "698": 11, "480": 11, "516": 11, "908": 11, "hellaswag_acc": 11, "wikitext_word_perplex": 11, "533": 11, "12": [11, 92, 110, 111], "407": [11, 92], "414": 11, "007": 11, "412": 11, "005": 11, "420": 11, "013": [11, 92], "534": 11, "416": 11, "009": 11, "tensor_impl": [12, 20, 93, 99], "aqttensorimpl": [12, 20], "block_siz": [12, 18, 20, 22, 27, 28, 30, 31, 32, 33, 54, 55, 56, 80, 94, 99], "tupl": [12, 20, 22, 27, 28, 30, 31, 32, 41, 42, 54, 55, 56, 74, 80, 86, 101, 102, 107, 108, 111], "quant_min": [12, 20, 30, 31, 32, 49, 54, 55, 56, 80, 93, 94, 101, 110, 111], "union": [12, 20, 35, 41, 42, 54, 56, 69, 79, 80], "quant_max": [12, 20, 30, 31, 32, 49, 54, 55, 56, 80, 93, 94, 101, 110, 111], "zero_point_domain": [12, 20, 30, 31, 32, 45, 54, 55, 69], "zeropointdomain": [12, 20, 30, 31, 32, 45, 54, 55, 69], "stride": [12, 20, 93, 101], "sourc": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 96, 103, 105], "quantized_tensor": 12, "float_tensor": [12, 101], "scale": [12, 18, 21, 28, 31, 36, 39, 42, 49, 52, 54, 55, 56, 57, 63, 69, 73, 74, 75, 76, 80, 82, 83, 93, 98, 99, 101, 102, 111], "zero_point": [12, 18, 31, 45, 52, 54, 55, 56, 80, 93, 98, 99, 101, 111], "happen": [12, 20, 53, 93, 101, 107, 109], "choose_qparam": [12, 93], "dequant": [12, 20, 22, 45, 56, 93, 94, 101, 102, 107, 109, 110, 111], "ao": [12, 20, 98, 102], "three": [12, 53, 86, 89, 93, 109, 110], "choose_qparams_affin": [12, 45, 55, 93], "quantize_affin": [12, 45, 93], "qand": 12, "dequantize_affin": [12, 45], "extern": [12, 109], "regardless": 12, "intern": [12, 25], "represent": [12, 18, 29, 45, 93, 98, 102, 107, 111], "orient": 12, "field": [12, 69, 71, 111], "storag": [12, 21, 93, 98], "store": [12, 21, 22, 26, 47, 85, 93, 98, 102, 107, 108], "plain": [12, 102], "int_data": [12, 101], "format": [12, 21, 22, 40, 44, 93, 96, 98, 107, 108, 111], "kernel": [12, 14, 15, 17, 21, 25, 40, 44, 45, 75, 79, 94, 96, 98, 106, 109, 110], "granular": [12, 36, 41, 42, 44, 45, 46, 48, 51, 54, 56, 60, 61, 62, 63, 69, 80, 92, 93, 96, 99, 102], "element": [12, 24, 26, 53, 54, 56, 63, 73, 75, 76, 80, 98], "share": [12, 54, 56, 80, 98], "qparam": [12, 54, 56, 80], "minimum": [12, 53, 54, 56, 80], "deriv": [12, 55, 80], "maximum": [12, 54, 56, 80, 82], "zero": [12, 24, 45, 47, 54, 56, 69, 73, 74, 75, 76, 86, 98, 99, 111], "subtract": [12, 22], "unquant": [12, 111], "given": [12, 20, 33, 92, 98, 102, 111], "classmethod": [12, 20, 99, 101, 102], "from_hp_to_floatx": 12, "input_float": [12, 20, 27, 28, 29, 30, 31, 32, 84], "target_dtyp": [12, 27, 28, 30, 31, 34, 35, 54, 55, 93, 99], "_layout": [12, 20, 27, 28, 29, 30, 31, 32, 93, 94, 99], "layout": [12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 45, 46, 47, 89, 98], "scale_dtyp": [12, 27, 28, 30, 54, 55, 99], "float8": [12, 15, 16, 27, 28, 34, 35, 36, 37, 38, 39, 41, 42, 43, 63, 90, 93, 96, 99], "from_hp_to_floatx_stat": 12, "from_hp_to_fpx": 12, "floatx": [12, 29, 93], "ebit": [12, 29, 40], "mbit": [12, 29, 40], "float1": [12, 29], "float7": [12, 29], "from_hp_to_intx": [12, 20], "mapping_typ": [12, 30, 46, 54, 55, 69], "mappingtyp": [12, 30, 46, 47, 54, 55, 69, 99], "ep": [12, 30, 54, 55, 69, 99, 108, 110, 111], "zero_point_dtyp": [12, 30, 54, 55, 99], "preserve_zero": [12, 30, 45, 54, 55], "plainlayout": [12, 30, 31, 46, 47, 99], "use_hqq": [12, 30, 45, 51, 102], "from_hp_to_intx_stat": 12, "correct": [12, 21, 107, 108], "otherwis": [12, 48, 58, 69, 93, 108], "desir": [12, 53, 99], "non_block": 12, "memory_format": [12, 109, 110], "preserve_format": 12, "attempt": 12, "asynchron": 12, "respect": [12, 98, 108], "host": [12, 102], "behavior": [12, 18, 58, 102, 107, 108], "pin": 12, "pageabl": 12, "howev": [12, 98, 102, 108, 111], "caution": 12, "advis": [12, 93], "good": [12, 94, 101, 111], "pin_memori": 12, "match": [12, 56, 57, 75, 76, 98, 107], "float64": 12, "5044": 12, "0005": 12, "3310": 12, "0584": 12, "cuda0": 12, "blocksiz": 13, "64": [13, 33, 45, 51, 63, 95, 96, 99, 101, 102], "block": [13, 22, 86, 98], "variabl": [13, 16, 25, 26, 86, 98], "cutlass": [14, 15], "mm_config": [16, 41, 42], "float8mmconfig": [16, 41, 42], "tinygemm": [17, 45, 75, 79, 93, 94], "_weight_int4pack_mm_for_cpu": [17, 45], "least": 17, "6": [17, 69, 92, 93, 94, 96, 98, 107, 108, 109], "It": [18, 21, 23, 25, 39, 94, 98, 101, 111], "post": [18, 25, 70, 90, 94, 101, 108, 111], "design": [18, 21, 24, 96, 102, 106, 107, 111], "extend": [18, 93, 98, 109], "conjunct": 18, "tensorimpl": 18, "interact": [18, 93, 107], "qqq": [19, 20, 32], "marlinqqq": 20, "inherit": [20, 23, 101, 102, 109, 110], "_choose_qparams_and_quantize_affine_qqq": 20, "_dequantize_affine_qqq": 20, "pattern": [21, 24, 93, 94, 102, 106, 107], "preprocess": [21, 24], "manag": 21, "pre_process": 21, "1\u00ba": 21, "transpos": [21, 93, 101], "sinc": [21, 60, 61, 72, 85, 93, 95, 96, 98, 99, 101, 107, 108, 109, 110, 111], "2\u00ba": 21, "inject": 21, "3\u00ba": 21, "again": [21, 22, 98, 107, 111], "dim": [21, 99, 101, 102, 107, 108], "tensor_meta": 22, "subclasstensorarg": 22, "n_block": 22, "scaler_block_s": [22, 33], "quantized_scal": 22, "quantization_factor": 22, "scaler_mean": 22, "quantized_data": [22, 102], "qlora": [22, 90, 96], "convert_to_norm_float_weight": 22, "normal": [22, 33, 53, 98, 107, 108], "dequantize_scal": 22, "unpack": [22, 93], "doubl": 22, "scaler": 22, "per_scaler_block": 22, "factor": [22, 57, 83, 92, 98], "inpt_weight": 22, "double_quantize_scal": 22, "calcul": [22, 39, 49, 54, 55, 82, 93, 98, 107, 111], "absmax": 22, "posit": 22, "per_block": 22, "int16": [22, 107], "n_scaler_block": 22, "get_original_weight": 22, "quantize_tensor_nearest": 22, "float16": [22, 80, 98], "nearest": 22, "round": [22, 49, 101], "metadata": [23, 93, 96, 101, 102], "semi": [24, 89, 98], "everi": [24, 60, 61, 72, 85, 98, 101, 107, 108], "four": [24, 106], "prune": [24, 86], "conform": 24, "inner_k_til": [25, 45, 66, 75, 94], "core": [25, 50, 93, 99, 102, 107], "tile": [25, 93], "affect": [25, 98], "matmul": [25, 43, 93, 98, 101], "pack_dim": [26, 51], "uintx": [26, 51, 93], "standard": [26, 93, 102], "byte": [26, 40, 51], "uintxtensor": 26, "determin": [26, 54, 70, 92, 98, 102], "along": [26, 98, 102, 106], "indic": [26, 52, 98, 111], "last": [26, 92, 106], "256": [33, 45, 65, 66, 67, 75, 76, 96, 107, 108, 111], "scaling_typ": [34, 35], "scalingtyp": [34, 35], "scaling_granular": [34, 35], "scalinggranular": [34, 35], "cast_config_input": 35, "castconfig": 35, "cast_config_input_for_grad_weight": 35, "cast_config_weight": 35, "cast_config_weight_for_grad_input": 35, "cast_config_grad_output": 35, "cast_config_grad_output_for_grad_weight": 35, "gemm_config_output": 35, "float8gemmconfig": 35, "use_fast_accum": 35, "gemm_config_grad_input": 35, "gemm_config_grad_weight": 35, "enable_fsdp_float8_all_gath": 35, "pad_inner_dim": 35, "emul": 35, "force_recompute_fp8_weight_in_bwd": 35, "round_scales_to_power_of_2": 35, "from_recipe_nam": 35, "recipe_nam": [35, 92], "float8linearrecipenam": 35, "qualnam": [36, 37, 49, 50, 52, 71], "boundari": [36, 37, 49, 50, 52, 71], "strategi": 36, "module_filter_fn": [38, 92], "callabl": [38, 53, 79, 84, 89, 102], "float8linearconfig": 38, "float8linear": [38, 92], "instanc": [38, 60, 61, 72, 79, 85, 89, 95, 101, 107, 109, 110, 111], "fqn": [38, 86, 89, 92, 99], "sum": [39, 107, 108], "set_inductor_config": [40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53], "sub": [40, 51, 98], "expon": 40, "mantissa": 40, "fp6_e3_m2": 40, "fp6_e2_m3": 40, "fp6": 40, "llm": 40, "arxiv": [40, 86, 98], "org": [40, 53, 86, 93, 94, 96, 98, 110], "ab": [40, 86, 98], "2401": 40, "14112": 40, "repo": 40, "usyd": 40, "fsalab": 40, "fp6_llm": 40, "renam": [40, 107, 108], "fpxtensorcoreaqttensorimpl": 40, "experiment": [40, 70, 106], "merg": 40, "to_affine_quantized_floatx": 40, "activation_dtyp": [41, 42], "float8_e4m3fn": [41, 42, 43, 93], "weight_dtyp": [41, 42, 43, 96], "pertensor": [41, 42, 99], "perrow": [41, 42, 96], "list": [41, 53, 56, 58, 83, 86, 93, 94, 101, 102, 106, 108, 111], "fast": [41, 42, 98], "accumul": [41, 42], "torchinductor": [41, 42, 43, 44, 45, 46, 47, 48, 51, 109, 110], "float8_e4m": 42, "channel": [43, 47, 48, 63, 65, 66, 67, 69, 72, 73, 75, 76, 85, 99, 110], "128": [44, 45, 92, 96, 99, 101, 102, 110, 111], "packing_bitwidth": 44, "weight_onli": 44, "gemlit": 44, "triton": [44, 93, 109, 110], "associ": [44, 99], "fp16": [44, 54], "control": [44, 45, 46, 47, 48, 51, 86, 98, 102, 107], "grain": [44, 45, 46, 51, 101], "impact": [44, 53, 92, 96, 102], "hardwar": [44, 93, 94, 96, 98], "runtim": [44, 93, 107], "tensorcoretiledlayout": [45, 93, 94], "tensor_core_til": [45, 93], "int4mm": [45, 94], "aten": [45, 93, 94, 101, 102, 106, 107, 108, 109, 110], "_weight_int4pack_mm": [45, 93], "tradit": 45, "exactli": [45, 101], "chosen": [45, 98], "choic": 45, "hqq": [45, 51, 93], "preserv": [45, 54, 86, 96, 98, 106], "Will": [45, 64, 68], "act_mapping_typ": [46, 47], "produc": [46, 94, 106, 107, 108, 109, 110], "backend": [46, 90, 94, 96, 98, 111], "marlinqqqlayout": 46, "cutlassint4packedlayout": 46, "weight_only_decod": 47, "around": [47, 92, 94, 95, 107], "decod": [47, 96], "better": [47, 48, 92, 101, 107, 108, 109, 110, 111], "number": [49, 51, 53, 63, 73, 75, 76, 86, 96, 98, 101, 108, 109], "sai": [49, 80, 93, 102, 111], "3": [49, 53, 60, 80, 90, 92, 93, 94, 98, 105, 107, 108], "7": [49, 92, 96, 109, 110], "symmetric_no_clipping_err": 49, "variant": [49, 55, 101], "smin": 49, "smax": 49, "min_val_neg": [49, 101], "max_val_po": [49, 101], "By": [49, 98], "individu": [49, 98], "less": [49, 98, 101, 107], "neg": 49, "placehold": [50, 110], "uint1": [51, 93], "uint7": [51, 93], "enum": [52, 71], "quantized_v": 52, "float_val": 52, "mid_point": 52, "example_input": [53, 74, 94, 95, 99, 106, 107, 108, 109, 110, 111], "qtensor_class_list": 53, "aqdefaultlinearweight": 53, "aqint8weightonlyquantizedlinearweight": 53, "aqint8weightonlyquantizedlinearweight2": 53, "aqint8dynamicallyquantizedlinearweight": 53, "filter_fn": [53, 79, 89], "interpol": 53, "85": 53, "manual": [53, 108], "supress_autoquant_error": 53, "min_sqnr": 53, "aq_kwarg": 53, "autoquant": 53, "identifi": [53, 99, 111], "fastest": 53, "over": [53, 92, 98, 107, 108], "potenti": [53, 98, 99, 106, 107, 109, 110], "qtensor": 53, "search": [53, 98], "whose": [53, 111], "exchang": 53, "autoquantizablelinearweight": 53, "calibr": [53, 55, 94, 106, 108, 109, 110], "seen": 53, "record": [53, 93, 99], "final": [53, 79, 93, 94, 98, 106, 107, 108, 109, 110, 111], "benchmark": [53, 82, 90, 92, 94, 106, 109, 110], "member": 53, "pick": 53, "highli": 53, "had": [53, 101, 107], "proce": 53, "combin": [53, 69, 96, 98, 101, 107, 109], "finalize_autoqu": 53, "log": [53, 101], "fulli": [53, 79, 83, 89, 96, 98, 107], "unless": [53, 102], "default_autoquant_class_list": 53, "second": [53, 57, 70, 92, 93, 105, 111], "stop": 53, "wait": [53, 93], "sever": [53, 92, 102, 106, 111], "automat": [53, 70, 92, 96, 101, 102, 105], "suppress": 53, "accept": [53, 96, 111], "signal": 53, "nois": 53, "ration": 53, "wikipedia": 53, "wiki": 53, "noise_ratio": 53, "v": [53, 111], "non": [53, 93, 98, 101, 106, 109, 110], "caus": [53, 92], "too": 53, "larg": [53, 96, 101, 109], "resaon": 53, "40": [53, 92], "keyword": [53, 69, 70], "example_input1": 53, "example_input2": 53, "int32": [54, 65, 69, 72, 73, 93, 94, 107, 111], "fp32": [54, 56, 69, 76, 99, 101, 107, 109], "optioanl": 54, "param": [54, 55, 86, 96], "request": [54, 56, 80], "min_val": [55, 93, 101], "max_val": [55, 93, 101], "observ": [55, 85, 98, 99, 106, 107, 108, 109, 110, 111], "obtain": 55, "track": [55, 93, 102], "input_dtyp": 56, "output_dtyp": [56, 72, 80], "uint8": [56, 80, 93, 99, 111], "b": 57, "scales1": 57, "multipli": [57, 81, 98], "rais": [57, 68, 70, 81, 92, 101, 102], "assertionerror": [57, 81, 92, 101], "expect": [57, 92, 98, 101, 106, 107, 109, 110, 111], "twostepquant": 58, "easili": [58, 106], "thei": [58, 92, 93, 94, 98, 101, 107, 108, 111], "constructor": [58, 101], "must": [58, 69, 70, 76, 92, 98, 102, 108, 110, 111], "embed": [58, 60, 65, 68, 70, 72, 73], "undefin": [58, 86], "my_quant": 58, "qatquantizer1": 58, "qatquantizer2": 58, "qatquantizer3": 58, "num_embed": [60, 72, 73], "embedding_dim": [60, 72, 73], "padding_idx": [60, 72, 73], "max_norm": [60, 72, 73], "norm_typ": [60, 72, 73], "scale_grad_by_freq": [60, 72, 73], "weight_config": [60, 61, 68, 70], "fakequantizeconfigbas": [60, 61, 62, 68, 70], "intxfakequantizeconfig": [60, 61, 68, 70], "fq_embed": 60, "longtensor": 60, "overridden": [60, 61, 72, 85], "within": [60, 61, 72, 85, 96, 98, 102, 109, 110], "afterward": [60, 61, 72, 85], "former": [60, 61, 72, 85], "care": [60, 61, 72, 85, 95, 98, 107], "hook": [60, 61, 72, 85, 93], "latter": [60, 61, 72, 85, 108], "silent": [60, 61, 72, 85, 109], "ignor": [60, 61, 72, 85, 92, 107, 108], "in_featur": [61, 75, 76, 92, 94, 95, 99, 101], "out_featur": [61, 75, 76, 92, 94, 99, 101], "activation_config": [61, 68, 70], "per_token": [61, 68, 69, 70], "is_symmetr": [61, 68, 69, 70], "fq_linear": 61, "symmetri": 62, "properti": [62, 69, 93], "scale_precis": [63, 65, 69, 72, 73], "rowwis": 63, "deprec": [64, 68], "fakequantizedembed": 64, "back": [64, 101], "model_with_fake_quantized_linear": 64, "zero_point_precis": [65, 69, 72, 73], "int4weightonlyqatembed": 65, "int4weightonlyembed": 65, "scales_precis": [66, 67, 75, 76], "padding_allow": 67, "valueerror": [68, 70], "torchaodtyp": 69, "is_dynam": [69, 109, 110, 111], "range_learn": 69, "simul": [69, 70, 87, 93, 98], "older": 69, "int1": [69, 93], "int7": 69, "pergroup": [69, 96], "pertoken": 69, "per_channel": 69, "peraxi": [69, 96, 99], "per_group": [69, 80], "leav": 69, "empti": [69, 93], "throw": 69, "els": [69, 96, 102, 107, 108], "qatstep": 70, "awar": [70, 86, 90, 94, 98, 101], "ptq": [70, 108, 109], "phase": [70, 111], "common": [70, 92, 93, 98], "int4weightonlyconfig": [70, 93, 94, 95, 102], "qat_config": 70, "act_config": 70, "alwai": [70, 96, 101], "One": [70, 98, 101, 102, 111], "neither": 70, "nor": 70, "fakequant": 74, "weightonlyint4linear": 75, "hardcod": [76, 93, 111], "mod": [77, 78, 92, 98, 101], "disabl": [77, 101, 108], "inplac": [79, 86, 94], "qualifi": [79, 83, 89, 98], "move": [79, 93, 99, 102, 108, 109], "predefin": [79, 111], "execut": [79, 97, 101, 104], "int8_dynamic_activation_int4_weight": 79, "int8_dynamic_activation_int8_weight": [79, 89], "mm": [79, 101, 107], "int4_weight_onli": 79, "int8_weight_onli": 79, "sequenti": [79, 89, 92], "tabl": [80, 92, 93, 98], "per_tensor": 80, "per_axi": 80, "axi": [80, 99], "mat2": 81, "safe": 81, "consid": [81, 93, 98], "cubla": 81, "fallback": [81, 102], "j": 81, "debug_skip_calibr": 82, "smoothquant": [82, 83, 106], "smoothfakedynamicallyquantizedlinear": [82, 83], "skip_fqn_list": 83, "cur_fqn": 83, "alpha": 83, "skip": [83, 86, 98], "being": [83, 92, 93, 98, 102, 109, 110], "input_quant_func": [84, 93], "quant_kwarg": 84, "dict": [84, 86, 101, 102, 110, 111], "l2": [85, 98], "norm": [85, 86, 98], "buffer": 85, "x_orig": 85, "sparsity_level": [86, 98], "semi_structured_block_s": 86, "wanda": 86, "sparsifi": [86, 90, 95, 98], "2306": 86, "11695": 86, "product": [86, 96, 102, 109, 111], "magnitud": [86, 98], "parametr": 86, "deepcopi": [86, 94, 99, 101, 108], "squash_mask": [86, 98], "params_to_keep": 86, "params_to_keep_per_lay": 86, "squash": 86, "mask": [86, 98], "appropri": [86, 93, 106, 107, 108, 109, 110], "sparse_param": 86, "attach": [86, 98, 111], "kei": [86, 98, 105], "xdoctest": 86, "local": [86, 96, 98], "don": [86, 92, 94, 98, 102, 111], "t": [86, 92, 93, 94, 98, 99, 101, 102, 107, 108, 111], "hasattr": [86, 102], "submodule1": 86, "linear1": [86, 94, 95, 99, 101], "foo": [86, 107], "bar": [86, 107], "submodule2": 86, "linear42": 86, "baz": 86, "42": [86, 99], "24": 86, "ones": [86, 93, 108], "update_mask": 86, "tensor_nam": [86, 102], "statist": [86, 93, 98, 99, 107, 108], "retriev": 86, "act_per_input": 86, "Then": [86, 101, 110, 111], "across": [86, 96, 98, 101, 102], "whole": [86, 111], "alia": [88, 102], "semisparseweightconfig": 88, "sparsify_": 89, "apply_tensor_subclass": [89, 93], "essenti": [89, 102, 106], "semi_sparse_weight": 89, "semisparselayout": 89, "sparsemarlinlayout": 89, "isinst": [89, 92, 98, 99, 101, 102, 108, 111], "sparse_api": 89, "librari": [90, 95], "gradient": [90, 98], "nativ": [90, 92, 101, 107], "introduct": [90, 93, 96], "highlight": [90, 101, 105], "guid": [90, 93, 96, 106], "contributor": [90, 94], "part": [90, 93, 98, 101, 108], "tune": [90, 92, 96, 98, 106], "vllm": 90, "sglang": 90, "serial": [90, 93, 107, 108], "write": [90, 94, 106, 107, 108], "advanc": [90, 99, 101, 106, 109, 110], "export": 90, "x86": [90, 94], "intel": [90, 106, 109], "openvino": [90, 94], "5x": 92, "cluster": 92, "34": 92, "43x": 92, "2k": 92, "h200": 92, "latest": [92, 94], "offic": 92, "offici": 92, "popular": [92, 93], "flagship": 92, "form": [92, 93, 98], "quickli": [92, 101], "batteri": 92, "includ": [92, 93, 101, 106, 109, 110, 111], "commonli": [92, 98], "fork": 92, "build": [92, 93, 98, 101, 102, 107], "top": [92, 93, 101, 106, 107, 108, 109, 110], "re": [92, 95, 96, 101, 107, 108], "virtual": 92, "environ": [92, 96], "conda": 92, "venv": 92, "download": [92, 94, 96, 103, 105, 107, 108, 110], "job": 92, "root": [92, 96], "launch": 92, "ngpu": 92, "config_fil": 92, "train_config": 92, "llama3_8b": 92, "toml": 92, "run_train": 92, "sh": [92, 96], "hyperparamet": 92, "edit": [92, 96], "line": [92, 98], "flag": [92, 108], "termin": 92, "rank0": 92, "titan": 92, "2025": 92, "06": 92, "04": 92, "08": 92, "51": 92, "48": 92, "info": 92, "2254": 92, "27": 92, "34gib": 92, "28": 92, "78": 92, "tp": [92, 102], "375": 92, "tflop": 92, "21": 92, "73": [92, 99], "mfu": 92, "20": [92, 96, 108], "58": 92, "557": 92, "7069": 92, "99gib": 92, "62": 92, "034": 92, "35": [92, 96, 99], "41": [92, 96], "19": 92, "52": 92, "224": [92, 99, 106, 107, 108, 109, 110], "9196": 92, "022": 92, "406": [92, 107, 108], "65": 92, "904": 92, "1423": 92, "014": 92, "23": [92, 99], "As": [92, 93, 107, 111], "warmup": 92, "7k": 92, "99gb": 92, "peak": [92, 96], "against": 92, "02": 92, "37": 92, "404": 92, "2611": 92, "22gib": 92, "595": 92, "47": 92, "49": [92, 99], "027": 92, "4260": 92, "89gib": 92, "344": 92, "367": 92, "39": 92, "03": 92, "01": 92, "988": 92, "9482": 92, "321": 92, "366": 92, "14": 92, "991": 92, "1183": 92, "300": 92, "364": 92, "89": 92, "4659": 92, "291": 92, "84": 92, "769": 92, "gc": 92, "peform": 92, "period": 92, "collect": [92, 93, 98], "3k": 92, "89gb": 92, "11x": 92, "nearli": 92, "ident": [92, 98], "performan": 92, "vs": [92, 98, 107, 111], "curv": [92, 98], "omit": [92, 107, 108, 109], "648": 92, "2648": 92, "28gib": 92, "71": 92, "26": 92, "475": 92, "9106": 92, "91gib": 92, "53": [92, 96], "503": 92, "434": 92, "43": 92, "94": [92, 107], "166": 92, "0774": 92, "663": 92, "443": 92, "44": [92, 99], "87": 92, "50": [92, 98, 99, 106, 107, 109, 110], "885": 92, "3233": 92, "643": 92, "442": 92, "66": [92, 96, 99], "76": 92, "613": 92, "6150": 92, "637": 92, "72": [92, 96], "6k": 92, "91gb": 92, "21x": [92, 96], "tl": 92, "dr": 92, "priorit": 92, "accur": [92, 98, 106], "stabil": 92, "cost": [92, 99], "slightli": [92, 101], "outlier": 92, "underflow": 92, "8xh100": 92, "box": [92, 98, 109], "toi": [92, 94, 99, 101, 109], "convert_to_float8_train": 92, "recurs": 92, "kind": [92, 107], "gemm": [92, 109, 110], "snippet": [92, 107, 108], "f": [92, 93, 95, 96, 98, 99, 101, 102, 107, 108], "float8_linear_util": 92, "float8_linear": 92, "torch_version_at_least_2_5": [92, 94], "greater": 92, "sampl": [92, 93, 107, 109, 110], "adamw": 92, "elig": 92, "divis": 92, "_": [92, 99, 102, 106, 107, 108, 109], "label": 92, "purpos": [92, 93, 101, 107], "fake_label": 92, "ones_lik": 92, "mse_loss": 92, "model_state_dict": 92, "state_dict": [92, 95, 107, 108], "optimizer_state_dict": 92, "pth": [92, 107, 108], "explor": [92, 94, 110], "few": [92, 101, 107, 108], "lai": 93, "stack": [93, 96], "awq": 93, "gptq": 93, "codebookquantizedtensor": 93, "float3": 93, "overload": [93, 98], "term": [93, 98, 107, 111], "extra": [93, 96], "dev": 93, "discuss": [93, 101], "1833": 93, "matter": [93, 98], "float3_e2_m0": 93, "float4_e2_m1": 93, "float4_e3_m0": 93, "float5_e2_m2": 93, "float5_e3_m1": 93, "float6_e2_m3": 93, "float6_e3_m2": 93, "float8_e5m2": 93, "float8_e4m3fnuz": 93, "float8_e5m2fnuz": 93, "plan": [93, 108], "float4": 93, "float6": 93, "becom": [93, 107], "uint2": 93, "117208": 93, "outsid": 93, "mention": [93, 107], "criteria": 93, "wide": 93, "adopt": 93, "fundament": [93, 98, 108], "until": 93, "evid": 93, "hopefulli": 93, "amen": 93, "haven": 93, "enough": 93, "ont": 93, "revisit": 93, "intx": 93, "connect": [93, 111], "int4tensor": 93, "previou": [93, 96, 107, 108, 109, 110], "between": [93, 98, 101, 102, 106, 108, 109, 111], "preicison": 93, "mainli": [93, 106, 109, 111], "accommod": 93, "choose_qparams_affine_with_min_max": 93, "min": [93, 99, 101, 107, 111], "int_matmul": 93, "int_scaled_matmul": 93, "reli": [93, 94, 98, 99, 101], "On": [93, 94], "glue": 93, "everyth": 93, "togeth": [93, 96, 107, 109, 111], "construct": [93, 107, 111], "low_precision_v": 93, "high_precision_v": 93, "procedur": 93, "veri": [93, 98, 102, 108], "straightforward": [93, 111], "high_preicsion_v": 93, "especi": [93, 95, 98, 109, 110], "bitwidth": [93, 111], "codebook": 93, "select": [93, 107], "multi": 93, "dimension": [93, 98], "view": [93, 101, 107, 108], "mkldnn": 93, "coo": [93, 98], "sparse_coo": [93, 98], "sparsetensorimpl": 93, "idea": [93, 98], "nice": [93, 98], "concept": [93, 105, 107, 109, 110, 111], "why": [93, 101, 105], "c": [93, 94, 101, 109, 110], "conflict": 93, "quantized_linear": [93, 99, 107], "semant": 93, "stai": [93, 94, 101, 109], "develop": [93, 94, 107, 108, 111], "tradition": 93, "to_affine_quant": 93, "simplic": 93, "explain": [93, 106, 109], "simplest": [93, 98], "easi": [93, 96], "linear_modul": 93, "to_affine_quantized_intx": 93, "to_linear_activation_quant": 93, "quantized_weight": [93, 102], "activation_and_weight_quant": 93, "encount": 93, "input_qunat_func": 93, "redispatch": 93, "fx": [93, 107, 111], "symbolic_trac": 93, "But": [93, 101, 102, 111], "easier": [93, 111], "modif": 93, "figur": [93, 98, 107], "At": [93, 98, 107], "thing": [93, 95, 98, 101, 107], "address": [93, 107], "stat": [93, 108], "averag": [93, 99, 107, 108], "calculate_qparam": [93, 99, 111], "affinequantizedminmaxobserv": [93, 99], "insert_observer_": 93, "observedlinear": [93, 99], "complic": [93, 98, 107], "done": [93, 101], "manner": 93, "autoround": 93, "multitensor": 93, "sure": [93, 96, 111], "describ": [93, 95, 98, 105, 107, 108], "todai": [93, 96], "low_bit_optim": 93, "quantized_train": 93, "progress": [93, 102], "lot": [93, 98], "walk": [93, 99, 101, 105, 106, 109], "_convert_weight_to_int4pack": 93, "tensorcoretiledaqttensorimpl": 93, "_quantized_linear_op": 93, "goe": 93, "_aqt_qlinear_dispatch_t": 93, "dispatch": 93, "explan": 93, "wint4": 93, "stabl": 94, "pip": [94, 96, 106, 107], "nightli": [94, 96], "index": [94, 96, 98, 110], "url": [94, 96, 110], "whl": [94, 96, 110], "cu121": 94, "major": 94, "entri": 94, "mutat": 94, "logic": [94, 101, 102], "toylinearmodel": [94, 95, 99], "linear2": [94, 95, 99, 101], "eval": [94, 95, 96, 99, 106, 108, 109, 110], "faster": [94, 98], "model_bf16": 94, "mix": [94, 96, 106, 109, 110], "tensor_impl_dtyp": 94, "roughli": [94, 98], "quarter": 94, "os": [94, 107, 108], "int4_model": 94, "pt": [94, 96], "bfloat16_model": 94, "int4_model_size_mb": 94, "getsiz": [94, 107, 108], "bfloat16_model_size_mb": 94, "2f": [94, 107, 108], "mb": [94, 95, 97, 104, 107, 108], "00": [94, 97, 104], "benchmark_model": 94, "temporari": 94, "workaround": [94, 102], "num_run": 94, "100": [94, 101, 107, 108], "_dynamo": [94, 101], "reset": [94, 107, 108], "bf16_time": 94, "int4_tim": 94, "time": [94, 98, 101, 105, 106, 107, 108], "3f": [94, 108], "ms": 94, "1fx": 94, "393": 94, "410": 94, "9x": 94, "recogn": [94, 111], "decis": 94, "pt2e": [94, 106, 107, 108, 109, 110], "fuse": [94, 98, 101, 108], "deleg": [94, 107], "x86inductorquant": [94, 109, 110], "quantize_pt2": [94, 106, 107, 108, 109, 110], "prepare_pt2": [94, 106, 107, 109, 110], "x86_inductor_quant": [94, 109], "get_default_x86_inductor_quantization_config": [94, 109], "float_model": [94, 101, 106, 107, 108, 109, 110], "data_load": [94, 107, 108, 109, 110], "no_grad": [94, 101, 106, 107, 108, 109, 110], "imag": [94, 106, 107, 108, 109, 110], "program": [94, 107, 108, 109, 111], "captur": [94, 107, 108, 111], "expos": [94, 107, 108], "set_glob": [94, 107, 108, 109, 110], "xiq": [94, 109], "prepare_qat_pt2": [94, 108, 109], "sample_inference_data": 94, "convert_pt2": [94, 106, 107, 108, 109, 110], "wrapper": [94, 101, 109], "_inductor": [94, 109], "cpp_wrapper": [94, 109], "optimized_model": [94, 106, 109, 110], "converted_model": [94, 109, 110], "xpu": [94, 110], "simpl": [94, 98, 99, 101, 106, 109, 110], "visit": 94, "would": [94, 98, 101, 108, 110], "forget": 94, "tempfil": 95, "get_model_size_in_byt": 95, "ref": [95, 107], "namedtemporaryfil": 95, "seek": [95, 98], "load": [95, 96, 102], "m_load": 95, "load_state_dict": [95, 107, 108], "assign": 95, "assert": [95, 99, 101, 102, 111], "equal": [95, 98], "float_weight1": 95, "float_weight2": 95, "quantized_weight1": 95, "quantized_weight2": 95, "go": [95, 101, 105, 111], "techinqu": 95, "reduct": [95, 96, 98, 101], "4x": [95, 96], "0625": 95, "reason": [95, 98], "avoid": [95, 98], "deploi": 96, "underli": [96, 101], "engin": 96, "seamlessli": [96, 101, 109, 110], "seamless": [96, 109], "git": 96, "cu126": 96, "acceler": [96, 98], "float8dynamicactivationfloat8weightconfig": 96, "phi": 96, "autotoken": 96, "model_id": 96, "microsoft": 96, "quant_config": 96, "quant_typ": [96, 102], "quantized_model": [96, 101, 106, 107, 108], "device_map": [96, 102], "auto": [96, 102], "torch_dtyp": [96, 102], "push": [96, 98, 102], "hub": [96, 102], "user_id": 96, "your_user_id": 96, "model_nam": [96, 106, 109, 110], "save_to": 96, "safe_seri": [96, 102], "hf": 96, "signific": [96, 98], "wheel": 96, "ai": 96, "hug": 96, "face": [96, 98, 107], "server": [96, 102], "o3": 96, "client": 96, "curl": 96, "localhost": 96, "8000": 96, "v1": 96, "chat": 96, "h": 96, "content": 96, "applic": 96, "messag": 96, "role": 96, "give": [96, 98, 101], "me": 96, "short": 96, "languag": 96, "temperatur": 96, "top_p": 96, "95": 96, "top_k": 96, "max_token": 96, "32768": 96, "vram": 96, "15x": 96, "2x": [96, 98], "littl": [96, 102], "packag": 96, "pipelin": 96, "random": [96, 98, 107, 108], "manual_se": [96, 107, 108], "model_path": 96, "trust_remote_cod": 96, "assist": 96, "eat": 96, "banana": 96, "dragonfruit": 96, "smoothi": 96, "blend": 96, "milk": 96, "honei": 96, "salad": 96, "slice": [96, 102], "lemon": 96, "juic": 96, "solv": [96, 98, 101], "equat": 96, "pipe": 96, "text": 96, "generation_arg": 96, "max_new_token": 96, "500": 96, "return_full_text": 96, "do_sampl": 96, "generated_text": 96, "finetun": 96, "lm_head": 96, "those": [96, 98, 99, 101], "ti": 96, "autoprocessor": 96, "modeling_util": 96, "find_tied_paramet": 96, "untied_model": 96, "getattr": [96, 102], "get_text_config": 96, "tie_word_embed": 96, "setattr": [96, 101], "_tied_weights_kei": 96, "clone": [96, 102], "save_to_local_path": 96, "int8dynamicactivationintxweightconfig": 96, "ve": [96, 98], "intxweightonlyconfig": 96, "modulefqntoconfig": [96, 102], "untied_model_id": 96, "untied_model_local_path": 96, "embedding_config": 96, "linear_config": 96, "weight_granular": 96, "weight_scale_dtyp": 96, "_default": [96, 102], "embed_token": 96, "include_embed": 96, "untie_embedding_weight": 96, "modules_to_not_convert": 96, "pte": 96, "cd": 96, "install_requir": 96, "phi_4_mini": 96, "convert_weight": 96, "pytorch_model": 96, "bin": 96, "pytorch_model_convert": 96, "export_llama": 96, "kv": 96, "use_sdpa_with_kv_cach": 96, "get_bos_id": 96, "199999": 96, "get_eos_id": 96, "200020": 96, "max_seq_length": 96, "max_context_length": 96, "output_nam": 96, "phi4": 96, "phone": 96, "io": 96, "2gb": 96, "iphon": 96, "pro": [96, 98], "17": 96, "sec": 96, "maintain": [96, 98], "test": [96, 105, 107, 109], "lm": 96, "har": 96, "eleutherai": 96, "lm_eval": 96, "model_arg": 96, "pretrain": [96, 98, 106, 107, 108, 109], "reset_peak_memory_stat": 96, "prompt": 96, "hei": 96, "consciou": 96, "templated_prompt": 96, "apply_chat_templ": 96, "add_generation_prompt": 96, "templat": [96, 97, 103, 104], "return_tensor": 96, "generated_id": 96, "output_text": 96, "batch_decod": 96, "skip_special_token": 96, "clean_up_tokenization_spac": 96, "respons": 96, "len": [96, 102, 107, 108, 111], "mem": [96, 97, 104], "max_memory_reserv": 96, "1e9": 96, "02f": 96, "gb": 96, "hello": 96, "ye": 96, "am": 96, "digit": 96, "70": [96, 99], "91": 96, "benchmark_lat": 96, "vllm_disable_compile_cach": 96, "project": 96, "vllm_use_precompil": 96, "sharegpt": 96, "wget": 96, "anon8231489123": 96, "sharegpt_vicuna_unfilt": 96, "resolv": 96, "sharegpt_v3_unfiltered_cleaned_split": 96, "tree": 96, "num": 96, "benchmark_serv": 96, "16x": 96, "1s": 96, "14x": 96, "num_prompt": 96, "req": 96, "57": [96, 99], "1000": [96, 109], "68": 96, "80": 96, "entir": [96, 107, 108], "ml": 96, "gain": [96, 98, 110], "eas": 96, "valid": [96, 102, 111], "trade": [96, 98], "off": [96, 98], "003": [97, 104, 105], "total": [97, 104, 105], "galleri": [97, 103, 105], "tutorials_sourc": 97, "template_tutori": [97, 104, 105], "neural": [98, 106, 109], "network": [98, 101, 106, 109], "latenc": 98, "carefulli": 98, "pai": 98, "low": [98, 101, 106], "price": 98, "f1": 98, "problem": [98, 101], "research": [98, 105], "fragment": 98, "rightfulli": 98, "spent": 98, "compress": [98, 106], "place": [98, 106, 107, 108, 109, 110], "dens": 98, "focu": [98, 101], "realli": 98, "concret": [98, 111], "hope": 98, "modular": 98, "scratch": [98, 105], "minim": [98, 106, 109, 110], "algorthim": 98, "realiz": 98, "theoret": 98, "analog": 98, "fix": [98, 99], "unstructur": 98, "close": 98, "relat": 98, "retrain": 98, "neglig": 98, "area": 98, "agre": 98, "upon": 98, "consensu": 98, "mind": 98, "thought": 98, "subproblem": 98, "satisfi": 98, "independ": 98, "frontend": [98, 109], "arbitrari": 98, "handoff": 98, "piec": 98, "natur": [98, 101, 107, 111], "present": 98, "clear": 98, "contract": 98, "7x": 98, "advantag": 98, "anticip": 98, "mani": [98, 101], "solut": 98, "third": 98, "parti": 98, "to_sparse_semi_structur": 98, "sparsesemistructuredtensor": 98, "weightnormsparsifi": 98, "half": 98, "subnetwork": 98, "sparse_config": 98, "named_modul": 98, "tensor_fqn": 98, "sparse_block_shap": 98, "zeros_per_block": 98, "fakespars": 98, "manipul": 98, "dictionari": 98, "paramer": 98, "parameter": 98, "necessari": [98, 99, 101, 106, 107, 108, 109, 110], "suitabl": [98, 109], "0s": 98, "spot": 98, "definit": [98, 102], "academia": 98, "industri": 98, "often": [98, 101], "interchang": 98, "confus": [98, 107], "distinct": 98, "behind": 98, "doesn": [98, 108, 111], "itself": [98, 101], "loos": 98, "speak": 98, "tightli": 98, "coupl": [98, 101], "csc": 98, "fbgemm": 98, "qnnpack": 98, "descript": [98, 106], "coordin": 98, "vector": [98, 109], "locat": 98, "bsr": 98, "sparse_bsr": 98, "except": [98, 101, 111], "scalar": [98, 107], "csr": 98, "sparse_csr": 98, "sparse_csc": 98, "column": 98, "compact": 98, "sparse_matrix": 98, "1d": 98, "indexptr": 98, "\u00bd": 98, "bitmask": 98, "2bit": 98, "unprun": 98, "quit": [98, 101], "broken": 98, "down": 98, "sensit": 98, "effect": [98, 99, 101, 109, 110, 111], "best": [98, 109], "subsequ": [98, 101, 109, 110], "infinit": 98, "lost": 98, "degre": 98, "drop": 98, "proxi": 98, "aforement": 98, "smallest": 98, "absolut": 98, "global": [98, 101], "scope": 98, "impli": 98, "con": 98, "span": 98, "threshold": 98, "complex": 98, "constant": [98, 101, 107], "ctr_mobile_fe": 98, "score": 98, "w": [98, 102], "tenosr": 98, "udpat": 98, "cannot": [98, 99, 102], "histori": 98, "regrow": 98, "dw": 98, "via": [98, 106], "backprop": 98, "pat": 98, "unmask": 98, "resid": 98, "salienc": 98, "lowest": 98, "l1": 98, "abl": [98, 101, 102, 107, 111], "repeat": [98, 107, 108], "movement": 98, "2005": 98, "07683": 98, "rank": [98, 101], "wx": 98, "sqx": 98, "q": [98, 107], "usual": 98, "sort": 98, "wise": 98, "reconstruct": [98, 102], "randomli": 98, "tri": 98, "remedi": 98, "item": [98, 105], "ultim": [98, 99], "literatur": 98, "vision": 98, "nlp": [98, 105, 109], "iter": [98, 107, 108], "ctr_feed": 98, "na": 98, "multimask": 98, "pyspeech": 98, "fastna": 98, "approach": [98, 101, 106, 109, 110], "knowledg": [98, 105], "distil": 98, "pdf": 98, "2204": 98, "09656": 98, "arrang": 98, "recal": 98, "counterpart": 98, "slower": 98, "suffici": 98, "flexibl": [98, 101, 106, 109], "98": 98, "special": [98, 106, 107], "exhibit": 98, "penalti": 98, "expens": [98, 101], "dictat": 98, "characterist": 98, "highest": 98, "wouldn": [98, 101], "visual": 98, "fig": 98, "4x4": 98, "benchmak": 98, "fly": 99, "welcom": 99, "histogram": [99, 107], "act_ob": 99, "finfo": 99, "weight_ob": 99, "observed_input": 99, "observed_weight": 99, "cl": [99, 101, 102], "float_linear": 99, "observed_linear": 99, "_replace_with_custom_fn_if_matches_filt": 99, "insert_observers_": 99, "_is_linear": 99, "lambda": [99, 102], "replacement_fn": 99, "copied_act_ob": 99, "copied_weight_ob": 99, "popul": 99, "feed": 99, "simpler": [99, 107], "quantizedlinear": [99, 101], "isn": 99, "strictli": 99, "to_affine_quantized_intx_stat": 99, "act_scal": [99, 111], "act_zero_point": 99, "weight_scal": [99, 107, 111], "weight_zero_point": [99, 107], "qweight": 99, "qinput": 99, "from_observ": 99, "begin": [99, 101], "dataclass": [99, 102, 111], "transform_modul": [99, 102], "register_quantize_module_handl": [99, 102], "staticquantconfig": 99, "_apply_static_qu": 99, "is_observed_linear": 99, "optimizedmodul": 99, "_orig_mod": 99, "0237": 99, "plainaqttensorimpl": 99, "142": 99, "31": [99, 111], "113": 99, "157": 99, "59": 99, "160": 99, "150": 99, "67": 99, "241": 99, "238": 99, "235": 99, "228": 99, "255": [99, 111], "201": 99, "114": 99, "236": 99, "88": [99, 107], "83": 99, "109": 99, "209": 99, "92": 99, "184": 99, "141": 99, "110": 99, "0009": 99, "0010": 99, "130": 99, "122": 99, "132": 99, "125": 99, "126": 99, "129": 99, "127": [99, 101, 110, 111], "133": 99, "124": 99, "131": 99, "135": 99, "136": 99, "foundat": 101, "autograd": [101, 111], "interpos": 101, "namespac": 101, "continu": [101, 108, 109, 110, 111], "obviou": 101, "int8quantizedlinear": 101, "finer": 101, "intercept": 101, "contrast": 101, "long": [101, 107], "clunki": 101, "distributedlinear": 101, "duplic": 101, "bypass": 101, "outer": 101, "inner": 101, "allgath": 101, "bandwidth": 101, "read": 101, "zoo": 101, "podcast": 101, "edward": 101, "yang": 101, "int8_symmetric_quant": 101, "fp32_tensor": 101, "amin": 101, "keepdim": [101, 107, 108], "amax": 101, "zeros_lik": 101, "clamp": [101, 107], "w_int8": 101, "new_linear": 101, "left": [101, 111], "toymodel": 101, "child": 101, "named_children": 101, "drawback": 101, "won": 101, "suppos": 101, "clean": 101, "eleg": 101, "pretti": 101, "power": [101, 102], "overrid": 101, "almost": 101, "shard": [101, 102], "ragged": 101, "rag": 101, "nestedtensor": 101, "who": 101, "link": [101, 105], "googl": 101, "collab": 101, "flopcount": 101, "memorytrack": 101, "With": [101, 107, 109, 111], "bare": 101, "bone": 101, "int8symmetrictensor": 101, "hold": 101, "staticmethod": 101, "__new__": [101, 102], "_make_wrapper_subclass": [101, 102], "storage_offset": 101, "ndim": 101, "__tensor_flatten__": [101, 102], "pt2": [101, 109], "__tensor_unflatten__": [101, 102], "tensor_data_dict": [101, 102], "extra_metadata": 101, "outer_s": [101, 102], "outer_strid": [101, 102], "undo": 101, "__repr__": 101, "repr": 101, "ahead": 101, "insid": 101, "int8_tensor": 101, "func": [101, 102], "op_implementations_dict": 101, "conveni": 101, "register_op": 101, "_op": 101, "opoverload": 101, "impl_decor": 101, "op_impl": 101, "particular": 101, "largest": 101, "tell": 101, "desugar": 101, "decor": [101, 102], "surfac": 101, "coverag": [101, 106, 107, 109, 110], "brute": 101, "forc": 101, "repeatedli": 101, "loggingtensor": 101, "_python_dispatch": [101, 102], "return_and_correct_alias": [101, 102], "int8_mm": 101, "detach": [101, 102], "int8_view_op": 101, "out_data": 101, "out_scal": [101, 107], "notic": 101, "hit": 101, "background": 101, "decomposit": 101, "live": 101, "decomp": 101, "shrink": 101, "author": [101, 105, 106, 107, 108, 109, 110, 111], "pain": 101, "rather": 101, "worth": 101, "written": 101, "differenti": 101, "nuanc": 101, "longer": [101, 107, 108], "That": 101, "transposit": 101, "got": [101, 107, 111], "propag": [101, 107, 109, 110], "fact": 101, "themselv": [101, 107], "pointwis": [101, 109, 110], "were": 101, "might": [101, 102, 107, 111], "unwrap": 101, "dim0": 101, "dim1": 101, "confirm": 101, "quantized_model_module_swap": 101, "quantized_model_subclass": 101, "subclass_param": 101, "out_module_swap": 101, "allclos": 101, "out_compil": 101, "seri": 101, "e2": 102, "_type": 102, "_data": 102, "capabl": [102, 107, 109], "self_attn": 102, "q_proj": 102, "k_proj": 102, "mlp": 102, "gate_proj": 102, "usernam": 102, "narrow": 102, "copy_": 102, "state": 102, "chunk": 102, "_apply_fn_to_data": 102, "heavi": 102, "codebas": 102, "fn": 102, "ctx": 102, "new_tensor": 102, "__class__": 102, "principl": 102, "torchaobasetensor": 102, "mynewquantconfig": 102, "classvar": 102, "myquantizedtensor": 102, "fbgemmfp8tensor": 102, "tensor_data_attr": 102, "tensor_attribut": 102, "attr": 102, "_to_copi": 102, "fill_default": 102, "notimplementederror": 102, "_my_quant_transform": 102, "my_quantization_funct": 102, "use_cutlass_kernel": 102, "my_cutlass_linear": 102, "use_triton_kernel": 102, "my_triton_linear": 102, "disappear": 102, "extrem": 102, "sole": 102, "think": 102, "world": 102, "explicitli": [102, 111], "spooki": 102, "distanc": 102, "statu": 102, "due": [102, 106, 111], "team": 102, "2338": 102, "creation": 102, "detect": 102, "illustr": 102, "tutorials_python": 103, "zip": [103, 105], "jupyt": [103, 105], "notebook": [103, 105], "tutorials_jupyt": 103, "sphinx": [103, 105], "firstnam": 105, "lastnam": 105, "prerequisit": [105, 107], "v2": 105, "topic": 105, "rand": [105, 107, 108], "2971": 105, "4477": 105, "0928": 105, "3790": 105, "2645": 105, "0072": 105, "8598": 105, "5256": 105, "1604": 105, "9450": 105, "6881": 105, "3734": 105, "1965": 105, "4987": 105, "7013": 105, "practic": 105, "summar": 105, "takeawai": 105, "link1": 105, "link2": 105, "minut": 105, "ipynb": 105, "daniil": 106, "lyakhov": 106, "aamir": 106, "nazir": 106, "alexand": 106, "suslov": 106, "yamini": 106, "nimmagadda": 106, "kozlov": 106, "subject": [106, 108], "openvinoquant": 106, "unlock": 106, "placement": 106, "simplifi": [106, 107, 109, 110], "ux": [106, 107, 109], "torchdynamo": [106, 109, 110, 111], "eager": [106, 107, 108, 109, 110, 111], "mechan": [106, 109, 110], "torchvis": [106, 107, 108, 109, 110, 111], "resnet18": [106, 107, 108, 109, 110], "u": 106, "__dict__": [106, 107, 108, 109, 110], "dummi": [106, 109, 110], "traced_b": [106, 109, 110], "exported_model": [106, 107, 108, 109, 110], "preset": 106, "elu": 106, "prelu": 106, "gelu": 106, "quantizationpreset": 106, "bert": [106, 109], "modeltyp": 106, "ignored_scop": 106, "exclud": 106, "layer_1": 106, "layer_2": 106, "layer_3": 106, "ignoredscop": 106, "conv2d": [106, 107, 108, 109, 110, 111], "regex": 106, "layer_": 106, "subgraph": [106, 108], "node": [106, 108, 109, 110, 111], "target_devic": 106, "taken": 106, "account": 106, "cpu_spr": 106, "npu": 106, "targetdevic": 106, "fold": [106, 107, 109, 110], "batchnorm": [106, 107, 108, 109, 110], "preced": [106, 107, 109, 110], "prepared_model": [106, 107, 108, 109, 110], "fold_quant": 106, "finish": [106, 109], "comparison": 106, "biascorrect": 106, "discrep": 106, "calibration_load": 106, "dataload": [106, 107, 108], "transform_fn": 106, "data_item": 106, "calibration_dataset": 106, "smooth_quant": 106, "fast_bias_correct": 106, "deploy": [106, 109], "jerri": [107, 109, 111], "zhang": [107, 109, 110, 111], "_export": [107, 108, 109], "14k": 107, "programm": [107, 109, 110], "db": 107, "xnnpack": [107, 108, 111], "xnnpack_quant": [107, 108], "get_symmetric_quantization_config": [107, 108], "xnnpackquant": [107, 108, 111], "prior": 107, "qconfigmap": [107, 111], "backendconfig": [107, 111], "rel": 107, "intent": [107, 111], "qconfig": [107, 111], "3d": [107, 111], "incompat": 107, "great": 107, "ideal": 107, "fake_qu": 107, "hidden": 107, "summari": 107, "thu": 107, "queri": [107, 111], "previous": 107, "embedding_byt": 107, "executorchquant": 107, "concaten": 107, "prone": 107, "cleaner": 107, "composed_quant": 107, "quantization_cap": 107, "concern": 107, "decoupl": 107, "minmax": 107, "freed": 107, "identitc": 107, "imagenet": [107, 108], "unzip": [107, 108], "data_path": [107, 108], "resnet18_pretrained_float": [107, 108], "sy": [107, 108], "numpi": [107, 108], "np": [107, 108], "resnet": [107, 108, 109], "warn": [107, 108], "filterwarn": [107, 108], "categori": [107, 108], "deprecationwarn": [107, 108], "r": [107, 108], "seed": [107, 108], "191009": [107, 108], "averagemet": [107, 108], "fmt": [107, 108], "val": [107, 108], "avg": [107, 108], "count": [107, 108], "__str__": [107, 108], "fmtstr": [107, 108], "topk": [107, 108], "predict": [107, 108], "maxk": [107, 108], "pred": [107, 108], "eq": [107, 108], "expand_a": [107, 108], "correct_k": [107, 108], "reshap": [107, 108], "mul_": [107, 108], "criterion": [107, 108], "top1": [107, 108], "top5": [107, 108], "cnt": [107, 108], "acc1": [107, 108], "acc5": [107, 108], "load_model": [107, 108], "model_fil": [107, 108], "weights_onli": [107, 108], "print_size_of_model": [107, 108], "temp": [107, 108], "p": [107, 108], "1e6": [107, 108], "prepare_data_load": [107, 108], "485": [107, 108], "456": [107, 108], "std": [107, 108], "229": [107, 108], "225": [107, 108], "randomresizedcrop": [107, 108], "randomhorizontalflip": [107, 108], "totensor": [107, 108], "dataset_test": [107, 108], "resiz": [107, 108], "centercrop": [107, 108], "train_sampl": [107, 108], "randomsampl": [107, 108], "test_sampl": [107, 108], "sequentialsampl": [107, 108], "train_batch_s": [107, 108], "sampler": [107, 108], "data_loader_test": [107, 108, 109, 110], "eval_batch_s": [107, 108], "saved_model_dir": [107, 108], "float_model_fil": [107, 108], "model_to_quant": [107, 108], "capture_pre_autograd_graph": [107, 108, 109], "dynamic_shap": [107, 108], "export_for_train": 107, "dynamic_dim": [107, 108], "constraint": [107, 108, 111], "qconfig_opt": 107, "set_object_typ": 107, "set_module_nam": 107, "workload": 107, "themodel": 107, "feedback": 107, "dq": 107, "fp32_op": 107, "qauntiz": 107, "x_int8": 107, "x_scale": 107, "x_zero_point": 107, "weight_int8": 107, "bias_fp32": 107, "output_scal": 107, "output_zero_point": 107, "x_fp32": 107, "quantized_decompos": 107, "dequantize_per_tensor": 107, "x_i8": 107, "x_quant_min": 107, "x_quant_max": 107, "weight_fp32": 107, "weight_i8": 107, "weight_quant_min": 107, "weight_quant_max": 107, "weight_permut": 107, "permute_copi": 107, "out_fp32": 107, "addmm": 107, "out_i8": 107, "quantize_per_tensor": 107, "out_zero_point": 107, "out_quant_min": 107, "out_quant_max": 107, "float32_op": 107, "decompos": 107, "use_reference_represent": 107, "x_int16": 107, "weight_int16": 107, "acc_int32": 107, "out_dtyp": 107, "bias_scal": 107, "bias_int32": 107, "div": 107, "mul": 107, "out_int8": 107, "qmin": 107, "qmax": 107, "date": 107, "unus": 107, "serila": 107, "consult": 107, "exportedprogram": 107, "pt2e_quantized_model_file_path": 107, "resnet18_pt2e_quant": 107, "quantized_ep": 107, "loaded_quantized_ep": 107, "loaded_quantized_model": 107, "diff": 107, "79": 107, "82": 107, "55": 107, "edg": [107, 111], "went": 107, "andrew": 108, "Or": 108, "move_exported_model_to_ev": [108, 109], "correctli": 108, "certain": 108, "dropout": 108, "move_exported_model_to_train": 108, "jit": 108, "recursivescriptmodul": 108, "train_one_epoch": 108, "ntrain_batch": 108, "avgloss": 108, "5f": 108, "start_tim": 108, "global_avg": 108, "is_qat": [108, 109], "fusion": 108, "batchnorm2d": 108, "_native_batch_norm_legit": 108, "cudnn_batch_norm": 108, "mobilenetv2": 108, "recompil": 108, "consolid": 108, "epoch": 108, "far": 108, "num_epoch": 108, "num_train_batch": 108, "num_eval_batch": 108, "num_observer_update_epoch": 108, "num_batch_norm_update_epoch": 108, "num_epochs_between_ev": 108, "nepoch": 108, "subseq": 108, "disable_observ": 108, "bn": 108, "running_mean": 108, "running_var": 108, "new_arg": 108, "wish": 108, "prepared_model_copi": 108, "neval_batch": 108, "paus": 108, "resum": 108, "fail": [108, 111], "checkpoint_path": 108, "checkpoint_": 108, "behav": 108, "incorrectli": 108, "lesli": [109, 111], "fang": [109, 111], "weiwen": [109, 111], "xia": [109, 111], "jiong": [109, 111], "gong": [109, 111], "cnn": 109, "rnn": 109, "outstand": 109, "fourth": 109, "spr": 109, "xeon": 109, "processor": 109, "boost": 109, "contigu": [109, 110], "channels_last": [109, 110], "onednn": [109, 110], "assum": [109, 111], "word": 109, "satur": 109, "pure": 109, "dedic": 109, "scenario": [109, 110], "plai": [109, 110], "convolut": [109, 110, 111], "absenc": [109, 110], "enhanc": [109, 110], "mirror": [109, 110], "autocast": [109, 110], "context": [109, 110], "device_typ": [109, 110], "turn": [109, 110], "cpp": 109, "qconvolut": [109, 110], "qlinear": [109, 110], "presenc": [109, 110], "pair": [109, 110], "remain": [109, 110], "conting": [109, 110], "qmaxpool2d": [109, 110], "torchinductor_freez": [109, 110], "example_x86inductorquantizer_pytorch_2_1": 109, "torchbench": 109, "measur": 109, "proven": 109, "depth": 109, "shoud": 109, "example_x86inductorquantizer_qat": 109, "yan": 110, "zhiwei": 110, "wang": 110, "eikan": 110, "liangang": 110, "liu": 110, "river": 110, "cui": 110, "yifeng": 110, "xpuinductorquant": 110, "pip3": 110, "torchaudio": 110, "xpu_inductor_quantizer_exampl": 110, "xpu_inductor_quant": 110, "xpuiq": 110, "resnet18_weight": 110, "get_default_xpu_inductor_quantization_config": 110, "sign": 110, "wherea": 110, "histogramobserv": [110, 111], "perchannelminmaxobserv": 110, "quantizationspec": [110, 111], "quantizationconfig": [110, 111], "type_check": 110, "observerorfakequantizeconstructor": 110, "get_xpu_inductor_symm_quantization_config": 110, "extra_arg": 110, "act_observer_or_fake_quant_ctr": 110, "act_quantization_spec": [110, 111], "qscheme": [110, 111], "per_tensor_symmetr": [110, 111], "observer_or_fake_quant_ctr": [110, 111], "with_arg": [110, 111], "weight_observer_or_fake_quant_ctr": 110, "weight_quantization_spec": [110, 111], "per_channel_symmetr": 110, "ch_axi": 110, "oc": 110, "ic": 110, "kh": 110, "kw": 110, "conv": [110, 111], "bias_quantization_spec": 110, "amp": 110, "indcutor": 110, "kimish": 111, "patel": 111, "made": 111, "explicit": 111, "quantiat": 111, "encod": 111, "convei": 111, "quantizationannot": 111, "furthermor": 111, "minmaxobserv": 111, "input_qspec_map": 111, "output_qspec": 111, "_annot": 111, "conclud": 111, "matcher": 111, "get_source_partit": 111, "add_partit": 111, "gm": 111, "itertool": 111, "chain": 111, "add_nod": 111, "output_nod": 111, "per_tensor_affin": 111, "input_act_qspec": 111, "output_act_qspec": 111, "input_act0": 111, "input_act1": 111, "quantization_annot": 111, "substitut": 111, "among": 111, "sharedquantizationspec": 111, "maxpool": 111, "average_pool": 111, "concat": 111, "edgeornod": 111, "transit": 111, "spec": 111, "conv1": 111, "conv2": 111, "fed": 111, "cat": 111, "conv1_out": 111, "conv2_out": 111, "qspec1": 111, "cat_input0": 111, "cat_input1": 111, "implicitli": 111, "therefor": 111, "ob": 111, "consum": 111, "rewrit": 111, "share_qparams_with_input_act0_qspec": 111, "known": 111, "beforehand": 111, "sigmoid": 111, "fixedqparamsquantizationspec": 111, "act_qspec": 111, "sigmoid_nod": 111, "input_act": 111, "derivedquantizationspec": 111, "derive_qparams_fn": 111, "observerorfakequant": 111, "observerbas": 111, "fakequantizebas": 111, "heurist": 111, "obejct": 111, "obs_or_fq": 111, "fq": 111, "act_obs_or_fq": 111, "weight_obs_or_fq": 111, "act_zp": 111, "weight_zp": 111, "bias_qspec": 111, "derived_from": 111, "backendquant": 111, "get_input_act_qspec": 111, "get_output_act_qspec": 111, "get_weight_qspec": 111, "get_bias_qspec": 111, "intermedi": 111, "call_funct": 111, "relu_": 111, "relu_nod": 111, "maybe_conv_nod": 111, "conv1d": 111, "unexpect": 111, "recognz": 111, "subgraphmatch": 111, "conv_relu_pattern": 111, "name_node_map": 111, "input_nod": 111, "weight_nod": 111, "bias_nod": 111, "caveat": 111, "exhaust": 111, "2d": 111, "4d": 111, "symbol": 111, "outcom": 111}, "objects": {"torchao.dtypes": [[12, 0, 1, "", "AffineQuantizedTensor"], [13, 0, 1, "", "BlockSparseLayout"], [14, 0, 1, "", "CutlassInt4PackedLayout"], [15, 0, 1, "", "CutlassSemiSparseLayout"], [16, 0, 1, "", "Float8Layout"], [17, 0, 1, "", "Int4CPULayout"], [18, 0, 1, "", "Layout"], [19, 0, 1, "", "MarlinQQQLayout"], [20, 0, 1, "", "MarlinQQQTensor"], [21, 0, 1, "", "MarlinSparseLayout"], [22, 0, 1, "", "NF4Tensor"], [23, 0, 1, "", "PlainLayout"], [24, 0, 1, "", "SemiSparseLayout"], [25, 0, 1, "", "TensorCoreTiledLayout"], [26, 0, 1, "", "UintxLayout"], [27, 2, 1, "", "to_affine_quantized_floatx"], [28, 2, 1, "", "to_affine_quantized_floatx_static"], [29, 2, 1, "", "to_affine_quantized_fpx"], [30, 2, 1, "", "to_affine_quantized_intx"], [31, 2, 1, "", "to_affine_quantized_intx_static"], [32, 2, 1, "", "to_marlinqqq_quantized_intx"], [33, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[12, 1, 1, "", "dequantize"], [12, 1, 1, "", "from_hp_to_floatx"], [12, 1, 1, "", "from_hp_to_floatx_static"], [12, 1, 1, "", "from_hp_to_fpx"], [12, 1, 1, "", "from_hp_to_intx"], [12, 1, 1, "", "from_hp_to_intx_static"], [12, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[20, 1, 1, "", "dequantize"], [20, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[21, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[22, 1, 1, "", "convert_to_norm_float_weight"], [22, 1, 1, "", "dequantize"], [22, 1, 1, "", "dequantize_scalers"], [22, 1, 1, "", "double_quantize_scalers"], [22, 1, 1, "", "get_original_weight"], [22, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[34, 0, 1, "", "CastConfig"], [35, 0, 1, "", "Float8LinearConfig"], [36, 0, 1, "", "ScalingGranularity"], [37, 0, 1, "", "ScalingType"], [38, 2, 1, "", "convert_to_float8_training"], [39, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[35, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[40, 0, 1, "", "FPXWeightOnlyConfig"], [41, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [42, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [43, 0, 1, "", "Float8WeightOnlyConfig"], [44, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [45, 0, 1, "", "Int4WeightOnlyConfig"], [46, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [47, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [48, 0, 1, "", "Int8WeightOnlyConfig"], [49, 0, 1, "", "MappingType"], [50, 0, 1, "", "TorchAODType"], [51, 0, 1, "", "UIntXWeightOnlyConfig"], [52, 0, 1, "", "ZeroPointDomain"], [53, 2, 1, "", "autoquant"], [54, 2, 1, "", "choose_qparams_affine"], [55, 2, 1, "", "choose_qparams_affine_with_min_max"], [56, 2, 1, "", "dequantize_affine"], [57, 2, 1, "", "int_scaled_matmul"], [79, 2, 1, "", "quantize_"], [80, 2, 1, "", "quantize_affine"], [81, 2, 1, "", "safe_int_mm"], [82, 2, 1, "", "smooth_fq_linear_to_inference"], [83, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [84, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[58, 0, 1, "", "ComposableQATQuantizer"], [59, 0, 1, "", "FakeQuantizeConfigBase"], [60, 0, 1, "", "FakeQuantizedEmbedding"], [61, 0, 1, "", "FakeQuantizedLinear"], [62, 0, 1, "", "FakeQuantizer"], [63, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [64, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [65, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [66, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [67, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [68, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [69, 0, 1, "", "IntxFakeQuantizeConfig"], [70, 0, 1, "", "QATConfig"], [71, 0, 1, "", "QATStep"], [74, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[60, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[61, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizer": [[62, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[63, 1, 1, "", "prepare"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[65, 1, 1, "", "convert"], [65, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[69, 3, 1, "", "group_size"], [69, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.embedding": [[72, 0, 1, "", "Int4WeightOnlyEmbedding"], [73, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[72, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[75, 0, 1, "", "Int4WeightOnlyQATLinear"], [76, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [77, 2, 1, "", "disable_linear_fake_quant"], [78, 2, 1, "", "enable_linear_fake_quant"]], "torchao": [[6, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[85, 0, 1, "", "PerChannelNormObserver"], [86, 0, 1, "", "WandaSparsifier"], [87, 2, 1, "", "apply_fake_sparsity"], [88, 5, 1, "", "semi_sparse_weight"], [89, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[85, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[86, 1, 1, "", "prepare"], [86, 1, 1, "", "squash_mask"], [86, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:module", "5": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "module", "Python module"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 9, 11, 90, 92, 93, 102], "dtype": [0, 10, 93], "layout": [0, 9, 18, 93], "tensor": [0, 9, 93, 100, 101, 102, 111], "subclass": [0, 9, 93, 101, 102], "quantiz": [0, 4, 5, 11, 79, 90, 93, 94, 96, 99, 100, 101, 102, 106, 107, 108, 109, 110, 111], "techniqu": 0, "float8": [1, 11, 92], "main": [1, 4, 5], "train": [1, 11, 92, 93, 96, 106, 107, 108, 109, 110], "api": [1, 2, 4, 5, 7, 11, 90, 92, 111], "other": [1, 5, 9, 93], "type": 1, "refer": [2, 90], "python": 2, "kernel": [3, 9, 91, 93, 102], "qat": [4, 11, 108], "config": 4, "quantize_": [4, 5], "custom": [4, 9], "legaci": 4, "prototyp": 4, "infer": [5, 96], "primit": [5, 93], "sparsiti": [6, 98], "benchmark": [7, 8, 9, 96], "guid": [7, 8, 9, 94, 102], "add": [7, 93, 102], "an": [7, 95], "recip": [7, 92], "model": [7, 9, 92, 93, 95, 96, 102, 106, 107, 108], "design": [7, 98], "consider": 7, "hf": 7, "ci": 7, "dashboard": 7, "1": [7, 11, 92, 96, 102, 106, 109, 110, 111], "modifi": 7, "exist": 7, "configur": [7, 98, 102, 107, 108], "2": [7, 11, 94, 96, 102, 106, 107, 108, 109, 110, 111], "run": 7, "3": [7, 11, 96, 102, 106, 109, 110, 111], "output": [7, 101], "format": 7, "4": [7, 106, 111], "integr": [7, 11, 93, 102], "pipelin": 7, "troubleshoot": 7, "test": [7, 9], "common": [7, 111], "issu": 7, "best": 7, "practic": 7, "user": 8, "contributor": 9, "gener": 9, "extend": 9, "ad": [9, 93, 102], "effici": [9, 93], "triton": 9, "hand": 9, "written": 9, "dispatch": [9, 102], "tensorimpl": [9, 93], "flow": [9, 93, 95, 102, 111], "us": [9, 111], "torch": [9, 106, 107, 108], "compil": [9, 102, 106], "perform": [9, 91, 96, 107], "serial": [9, 95, 102], "featur": 9, "support": [9, 93, 102], "function": [9, 93, 107, 108], "compos": 9, "microbenchmark": 9, "eval": [9, 107], "part": [11, 92, 96], "fine": 11, "tune": 11, "qlora": 11, "awar": [11, 93, 108, 109], "option": [11, 96, 105, 106], "torchtun": 11, "axolotl": 11, "low": [11, 93], "rank": 11, "adapt": 11, "huggingfac": [11, 96, 102], "peft": 11, "affinequantizedtensor": 12, "blocksparselayout": 13, "cutlassint4packedlayout": 14, "cutlasssemisparselayout": 15, "float8layout": 16, "int4cpulayout": 17, "marlinqqqlayout": 19, "marlinqqqtensor": 20, "marlinsparselayout": 21, "nf4tensor": 22, "plainlayout": 23, "semisparselayout": 24, "tensorcoretiledlayout": 25, "uintxlayout": 26, "to_affine_quantized_floatx": 27, "to_affine_quantized_floatx_stat": 28, "to_affine_quantized_fpx": 29, "to_affine_quantized_intx": 30, "to_affine_quantized_intx_stat": 31, "to_marlinqqq_quantized_intx": 32, "to_nf4": 33, "castconfig": 34, "float8linearconfig": 35, "scalinggranular": 36, "scalingtyp": 37, "convert_to_float8_train": 38, "precompute_float8_dynamic_scale_for_fsdp": 39, "fpxweightonlyconfig": 40, "float8dynamicactivationfloat8weightconfig": 41, "float8staticactivationfloat8weightconfig": 42, "float8weightonlyconfig": 43, "gemliteuintxweightonlyconfig": 44, "int4weightonlyconfig": 45, "int8dynamicactivationint4weightconfig": 46, "int8dynamicactivationint8weightconfig": 47, "int8weightonlyconfig": 48, "mappingtyp": 49, "torchaodtyp": 50, "uintxweightonlyconfig": 51, "zeropointdomain": 52, "autoqu": 53, "choose_qparams_affin": 54, "choose_qparams_affine_with_min_max": 55, "dequantize_affin": 56, "int_scaled_matmul": 57, "composableqatquant": 58, "fakequantizeconfigbas": 59, "fakequantizedembed": 60, "fakequantizedlinear": 61, "fakequant": 62, "float8actint4weightqatquant": 63, "fromintxquantizationawaretrainingconfig": 64, "int4weightonlyembeddingqatquant": 65, "int4weightonlyqatquant": 66, "int8dynactint4weightqatquant": 67, "intxquantizationawaretrainingconfig": 68, "intxfakequantizeconfig": 69, "qatconfig": 70, "qatstep": 71, "int4weightonlyembed": 72, "int4weightonlyqatembed": 73, "initialize_fake_quant": 74, "int4weightonlyqatlinear": 75, "int8dynactint4weightqatlinear": 76, "disable_linear_fake_qu": 77, "enable_linear_fake_qu": 78, "quantize_affin": 80, "safe_int_mm": 81, "smooth_fq_linear_to_infer": 82, "swap_linear_with_smooth_fq_linear": 83, "to_linear_activation_quant": 84, "perchannelnormobserv": 85, "wandasparsifi": 86, "apply_fake_spars": 87, "semi_sparse_weight": 88, "sparsifi": 89, "welcom": 90, "document": 90, "get": 90, "start": [90, 94], "develop": 90, "note": [90, 92, 111], "eager": 90, "tutori": [90, 105], "pt2e": [90, 111], "pre": 92, "torchtitan": 92, "prerequisit": [92, 106, 109, 110, 111], "rowwis": 92, "scale": 92, "tensorwis": 92, "pick": 92, "import": [92, 107, 108], "directli": [92, 111], "convers": 92, "overview": [93, 98, 105], "basic": 93, "current": 93, "placehold": 93, "pytorch": [93, 94, 106, 107, 108, 109, 110, 111], "implement": [93, 101, 102], "oper": [93, 101, 102, 111], "nativ": 93, "factori": 93, "op": 93, "deriv": [93, 111], "algorithm": 93, "weight": [93, 96], "onli": 93, "dynam": 93, "activ": 93, "static": [93, 99], "insert": 93, "observ": 93, "how": [93, 107, 108, 111], "defin": [93, 107, 108], "modul": [93, 101, 102], "calibr": [93, 99, 107], "bit": 93, "optim": [93, 95, 96], "case": 93, "studi": 93, "int4": 93, "work": 93, "dure": 93, "execut": 93, "save": [93, 107, 108], "load": [93, 107, 108], "quick": 94, "first": 94, "exampl": [94, 102, 111], "export": [94, 96, 106, 107, 108, 109, 110, 111], "next": [94, 101], "step": [94, 96, 101, 102, 105], "deseri": 95, "what": [95, 101], "happen": 95, "when": 95, "serv": [96, 102], "vllm": [96, 102], "sglang": 96, "executorch": 96, "post": [96, 106, 107, 109, 110], "transform": [96, 102], "mobil": 96, "deploy": 96, "unti": 96, "embed": 96, "creat": [96, 102], "characterist": 96, "evalu": [96, 107], "qualiti": 96, "assess": 96, "memori": 96, "latenc": 96, "result": 96, "h100": 96, "machin": 96, "conclus": [96, 105, 106, 107, 108, 109, 110, 111], "comput": [97, 104], "time": [97, 104], "goal": 98, "context": 98, "prune": 98, "criteria": 98, "strategi": 98, "pattern": [98, 111], "phase": 99, "write": [100, 101, 111], "your": [100, 101, 102], "own": [100, 101], "advanc": 100, "ar": 101, "swap": 101, "which": 101, "should": 101, "we": 101, "compar": 101, "architectur": 102, "usag": 102, "system": 102, "class": 102, "level": 102, "new": 102, "method": 102, "minim": 102, "requir": 102, "compat": 102, "why": 102, "regist": 102, "s": 102, "kei": 102, "detail": 102, "hardwar": 102, "specif": [102, 107, 108], "linear": 102, "benefit": 102, "trade": 102, "off": 102, "share": [102, 111], "safetensor": 102, "diagram": 102, "high": 102, "point": 102, "bring": 102, "extern": 102, "templat": 105, "addit": 105, "exercis": 105, "further": 105, "read": 105, "openvino": 106, "backend": [106, 107, 108, 109, 110], "introduct": [106, 109, 110, 111], "nncf": 106, "instal": 106, "captur": [106, 109, 110], "fx": [106, 109, 110], "graph": [106, 109, 110], "appli": [106, 109, 110], "lower": [106, 107, 109, 110], "represent": 106, "improv": 106, "metric": 106, "motiv": [107, 111], "helper": [107, 108], "prepar": [107, 108], "dataset": [107, 108], "set": 107, "mode": 107, "convert": [107, 108], "check": 107, "size": 107, "accuraci": 107, "debug": 107, "loop": 108, "checkpoint": 108, "x86": 109, "through": [109, 110], "inductor": [109, 110], "intel": 110, "gpu": 110, "annot": 111, "param": 111, "fix": 111, "paramet": 111, "5": 111, "A": 111, "toi": 111, "resnet18": 111, "ir": 111, "problem": 111, "match": 111, "aten": 111, "recommend": 111, "subgraphmatcherwithnamenodemap": 111}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})