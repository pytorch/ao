Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8ActivationInt4WeightConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8ActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8ActivationInt4WeightConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "quantize_affine", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 7, 8, 9, 11, 12, 21, 22, 23, 24, 26, 39, 40, 42, 45, 46, 47, 48, 49, 50, 54, 55, 56, 57, 61, 62, 65, 70, 72, 74, 75, 77, 78, 81, 82, 87, 88, 89, 91, 94, 95, 96, 97, 98, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112, 113], "section": [2, 9, 95, 100, 104, 109, 110, 113], "introduc": [2, 11, 108, 109, 111, 112, 113], "dive": 2, "detail": [2, 7, 9, 11, 40, 54, 94, 95, 96, 98, 100, 101, 103, 108, 109, 110, 111], "how": [2, 4, 9, 11, 12, 18, 26, 41, 46, 48, 50, 55, 70, 82, 92, 94, 96, 97, 98, 100, 101, 103, 104, 108, 111, 112], "integr": [2, 9, 92, 94, 97, 98, 100, 103, 111, 113], "pytorch": [2, 7, 9, 11, 12, 17, 20, 51, 70, 92, 94, 98, 100, 103, 104, 107], "optim": [2, 9, 11, 21, 39, 54, 81, 92, 94, 100, 103, 108, 110, 111, 112], "your": [2, 7, 9, 11, 92, 94, 95, 96, 98, 100, 109, 110, 111, 112, 113], "machin": [2, 110], "learn": [2, 46, 70, 96, 100, 107, 109, 111, 112, 113], "model": [2, 11, 39, 45, 47, 54, 59, 64, 65, 66, 67, 68, 69, 72, 76, 81, 84, 85, 88, 89, 91, 96, 100, 101, 103, 111, 112, 113], "dtype": [2, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 42, 43, 44, 51, 52, 54, 55, 56, 57, 61, 62, 64, 66, 67, 68, 70, 74, 75, 77, 78, 82, 91, 92, 94, 96, 97, 101, 103, 104, 109, 111, 112, 113], "quantiz": [2, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 30, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 91, 94, 97, 100], "sparsiti": [2, 7, 11, 15, 21, 24, 87, 88, 89, 90, 91, 92, 94, 95, 97, 98], "tba": [3, 10, 93], "For": [4, 7, 9, 11, 12, 40, 70, 95, 96, 97, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "full": [4, 9, 11, 96, 101, 107, 108, 110], "exampl": [4, 7, 9, 11, 12, 39, 50, 54, 59, 61, 62, 65, 69, 70, 72, 76, 81, 88, 91, 95, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112], "us": [4, 7, 8, 11, 12, 16, 17, 18, 21, 22, 23, 26, 28, 31, 42, 43, 44, 46, 47, 48, 50, 52, 54, 55, 56, 57, 59, 64, 65, 69, 70, 72, 77, 78, 82, 88, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112], "our": [4, 9, 11, 22, 94, 96, 98, 100, 101, 103, 109, 110], "pleas": [4, 8, 9, 11, 12, 20, 40, 46, 65, 69, 92, 95, 96, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "refer": [4, 7, 9, 11, 12, 72, 78, 94, 98, 100, 101, 103, 104, 108, 109, 110, 111], "readm": [4, 7, 11, 92, 96, 100], "tutori": [7, 9, 11, 12, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113], "you": [7, 8, 9, 11, 70, 88, 94, 95, 96, 97, 98, 100, 103, 104, 107, 108, 109, 110, 111, 112, 113], "through": [7, 9, 11, 56, 61, 62, 92, 95, 96, 98, 101, 103, 104, 107, 108, 109, 113], "torchao": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 97, 98, 100, 101, 103, 108, 109, 110, 111, 112], "framework": [7, 11, 94, 98, 108], "The": [7, 9, 11, 12, 13, 18, 21, 26, 38, 40, 42, 43, 44, 54, 58, 72, 81, 83, 84, 85, 88, 94, 95, 96, 97, 98, 100, 103, 104, 108, 109, 110, 111, 112, 113], "contain": [7, 54, 84, 85, 100, 103, 110, 113], "new": [7, 9, 11, 12, 94, 95, 101, 103, 109, 110, 111, 113], "architectur": [7, 92, 98, 100, 108, 109, 111, 112], "micro": 7, "current": [7, 42, 47, 64, 72, 81, 85, 88, 91, 94, 96, 100, 103, 104, 109, 110, 112], "support": [7, 11, 12, 29, 41, 42, 47, 64, 69, 70, 72, 91, 94, 96, 97, 98, 100, 103, 108, 109, 110, 111, 112, 113], "which": [7, 9, 11, 20, 26, 54, 72, 77, 94, 95, 96, 97, 98, 100, 101, 104, 108, 109, 110, 111, 112, 113], "can": [7, 9, 11, 12, 25, 42, 45, 50, 54, 59, 70, 81, 82, 94, 95, 96, 97, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "quantize_": [7, 9, 11, 65, 69, 72, 81, 91, 95, 96, 97, 98, 101], "sparsity_": 7, "function": [7, 11, 12, 25, 38, 54, 61, 62, 74, 79, 80, 81, 87, 88, 89, 91, 94, 96, 97, 100, 101, 103, 104, 108, 113], "To": [7, 9, 11, 12, 20, 54, 78, 94, 95, 96, 97, 98, 100, 101, 104, 109, 110, 111, 113], "correspond": [7, 11, 65, 72, 81, 95, 97, 100, 103, 112, 113], "string": [7, 35, 70, 88], "string_to_config": 7, "microbenchmark": 7, "util": [7, 9, 45, 94, 95, 96, 97, 103, 104, 108, 109, 110, 111, 112, 113], "py": [7, 9, 12, 20, 98, 99, 106, 107, 111, 112], "def": [7, 11, 91, 94, 95, 96, 97, 101, 103, 104, 108, 109, 110, 111, 112, 113], "option": [7, 9, 12, 16, 20, 27, 30, 31, 32, 34, 35, 38, 42, 43, 45, 46, 48, 49, 54, 55, 56, 57, 61, 62, 64, 67, 69, 70, 72, 74, 75, 81, 82, 84, 85, 86, 88, 91, 94, 96, 104, 109, 110, 111, 112, 113], "str": [7, 35, 38, 45, 70, 72, 81, 85, 86, 88, 91, 94, 103, 104, 112], "kwarg": [7, 12, 61, 62, 63, 64, 66, 70, 75, 87, 88, 89, 103, 104], "aobaseconfig": [7, 72, 81, 91, 101, 104], "code": [7, 9, 46, 94, 95, 96, 98, 100, 101, 103, 105, 107, 109, 110, 111, 112, 113], "elif": [7, 104], "my_new_quant": 7, "If": [7, 8, 11, 12, 16, 38, 42, 48, 49, 54, 58, 69, 70, 72, 83, 84, 88, 95, 96, 98, 100, 103, 109, 110], "addit": [7, 11, 18, 23, 54, 94, 100, 103, 108, 109, 112, 113], "inform": [7, 12, 42, 98, 100, 104, 108, 109], "need": [7, 9, 11, 42, 61, 62, 74, 87, 88, 95, 96, 97, 98, 100, 103, 104, 109, 110, 111, 113], "pass": [7, 38, 48, 54, 56, 61, 62, 72, 74, 87, 95, 101, 103, 104, 110, 113], "process": [7, 11, 18, 21, 23, 25, 26, 54, 85, 95, 100, 107, 108, 112], "here": [7, 8, 9, 12, 72, 78, 82, 95, 96, 97, 98, 101, 103, 104, 108, 109, 110, 111, 112, 113], "return": [7, 11, 12, 20, 21, 22, 38, 54, 58, 70, 81, 83, 84, 85, 91, 94, 95, 96, 97, 101, 103, 104, 108, 109, 110, 111, 112, 113], "mynewquantizationconfig": 7, "my_new_spars": 7, "mynewsparsityconfig": 7, "rest": [7, 103, 110], "now": [7, 9, 11, 40, 47, 55, 94, 95, 96, 100, 101, 103, 108, 109, 111, 113], "we": [7, 9, 11, 12, 22, 42, 44, 50, 52, 54, 55, 56, 57, 69, 70, 72, 78, 81, 82, 91, 94, 95, 96, 97, 98, 100, 101, 104, 108, 109, 110, 111, 112, 113], "throughout": 7, "note": [7, 9, 11, 59, 69, 78, 88, 95, 96, 98, 100, 103, 104, 110, 111, 112], "input": [7, 9, 12, 21, 22, 24, 35, 38, 39, 54, 55, 56, 57, 58, 72, 76, 81, 82, 83, 88, 91, 94, 95, 96, 98, 101, 103, 108, 109, 110, 111, 112, 113], "paramet": [7, 11, 12, 18, 21, 22, 28, 31, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 58, 64, 70, 72, 75, 77, 78, 81, 82, 83, 84, 85, 88, 91, 94, 95, 97, 98, 100, 103, 104, 108, 109], "like": [7, 9, 11, 18, 42, 54, 94, 95, 96, 97, 100, 103, 104, 108, 109, 110, 111, 112, 113], "bit": [7, 11, 26, 33, 40, 45, 52, 71, 98, 103, 104, 109, 111, 112], "width": [7, 26, 45, 71], "group": [7, 11, 41, 42, 46, 47, 49, 52, 64, 66, 67, 68, 70, 74, 75, 77, 78, 95, 96], "size": [7, 9, 12, 13, 20, 22, 41, 45, 46, 47, 49, 52, 55, 57, 70, 82, 94, 96, 97, 98, 100, 101, 103, 104, 110], "etc": [7, 9, 42, 61, 62, 95, 108, 113], "them": [7, 11, 54, 61, 62, 74, 87, 95, 113], "append": [7, 100, 109, 110], "config": [7, 11, 35, 38, 42, 44, 54, 60, 61, 62, 63, 65, 69, 70, 71, 72, 81, 88, 91, 96, 98, 100, 101, 104, 109, 111, 112], "gemliteuintxweightonlyconfig": 7, "gemlitewo": 7, "bit_width": [7, 45], "group_siz": [7, 11, 41, 45, 46, 47, 49, 52, 61, 62, 64, 66, 69, 70, 72, 74, 75, 81, 96, 104], "system": [7, 9, 98], "model_architectur": 7, "type": [7, 9, 11, 12, 21, 22, 26, 35, 36, 37, 38, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 58, 70, 73, 82, 83, 92, 95, 97, 98, 100, 103, 104, 108, 109, 111, 112, 113], "defin": [7, 9, 18, 26, 36, 40, 61, 62, 74, 87, 88, 96, 100, 101, 103, 104, 108, 111, 112, 113], "class": [7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 87, 88, 95, 96, 97, 101, 103, 109, 110, 111, 113], "mycustommodel": 7, "torch": [7, 11, 12, 21, 22, 26, 28, 35, 38, 42, 43, 44, 46, 52, 54, 55, 57, 58, 61, 62, 64, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 81, 82, 83, 84, 85, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 107, 111, 112, 113], "nn": [7, 11, 35, 38, 54, 59, 64, 66, 69, 72, 81, 84, 85, 91, 94, 95, 96, 97, 98, 100, 101, 103, 104, 109, 110, 111, 113], "modul": [7, 9, 11, 35, 36, 37, 38, 39, 50, 51, 53, 54, 59, 61, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 87, 88, 91, 94, 96, 97, 101, 108, 109, 110, 111, 112, 113], "__init__": [7, 11, 96, 97, 101, 103, 104, 109, 110, 111], "self": [7, 11, 12, 95, 96, 97, 101, 103, 104, 109, 110, 111], "input_dim": 7, "output_dim": 7, "bfloat16": [7, 9, 22, 64, 67, 77, 82, 94, 95, 96, 97, 98, 100, 101, 104, 111, 112], "super": [7, 11, 96, 97, 101, 103, 109, 110, 111], "layer1": 7, "linear": [7, 9, 11, 21, 35, 38, 41, 42, 44, 46, 47, 48, 49, 52, 54, 59, 62, 64, 67, 68, 69, 72, 77, 78, 79, 80, 81, 85, 89, 91, 94, 95, 96, 97, 98, 100, 101, 103, 108, 109, 110, 111, 113], "512": [7, 94], "bia": [7, 9, 11, 62, 77, 78, 95, 96, 97, 101, 103, 104, 110, 113], "fals": [7, 11, 12, 30, 35, 43, 46, 48, 52, 54, 61, 62, 68, 69, 70, 72, 74, 75, 77, 78, 84, 88, 94, 95, 96, 97, 98, 101, 103, 104, 108, 109, 110, 112, 113], "activ": [7, 9, 11, 42, 43, 45, 47, 48, 54, 61, 62, 64, 68, 69, 70, 72, 78, 84, 88, 92, 96, 98, 100, 101, 104, 108, 111, 112, 113], "relu": [7, 96, 108, 113], "layer2": 7, "forward": [7, 48, 54, 61, 62, 71, 74, 77, 87, 95, 96, 97, 100, 101, 103, 104, 109, 110, 111], "x": [7, 52, 61, 62, 71, 74, 94, 96, 97, 98, 101, 103, 104, 107, 108, 109, 110, 111, 112], "updat": [7, 92, 96, 97, 100, 109, 110, 111, 113], "create_model_and_input_data": 7, "handl": [7, 21, 24, 25, 54, 95], "model_typ": [7, 11, 104, 108], "m": [7, 9, 11, 81, 91, 94, 96, 97, 98, 101, 103, 109, 110, 111], "int": [7, 11, 12, 13, 20, 22, 25, 26, 27, 28, 30, 31, 32, 33, 40, 41, 42, 44, 45, 46, 47, 49, 52, 55, 56, 57, 61, 62, 64, 66, 67, 68, 70, 74, 75, 77, 78, 81, 82, 88, 96, 101, 103, 104], "k": [7, 9, 83, 96, 97, 101, 103, 109, 110], "n": [7, 9, 11, 96, 97, 101, 103, 109, 110, 113], "high_precision_dtyp": 7, "devic": [7, 9, 11, 12, 74, 77, 78, 81, 83, 94, 96, 97, 98, 101, 103, 104, 108, 109, 110, 111, 112], "cuda": [7, 9, 11, 12, 81, 94, 96, 97, 98, 100, 101, 103, 110], "my_custom_model": 7, "input_data": 7, "randn": [7, 11, 12, 62, 94, 96, 97, 101, 103, 108, 109, 110, 111, 112], "when": [7, 9, 11, 12, 23, 55, 57, 72, 82, 94, 95, 98, 100, 101, 104, 108, 109, 110, 111, 112, 113], "ad": [7, 11, 12, 57, 88, 100, 101, 103, 110], "dimens": [7, 9, 12, 26, 52, 55, 57, 58, 82, 94, 103, 104, 109, 110], "ensur": [7, 21, 98, 110], "convent": 7, "where": [7, 24, 50, 52, 56, 66, 67, 68, 95, 100, 104, 113], "batch": [7, 98, 101, 110], "sequenc": 7, "length": 7, "featur": [7, 11, 12, 103, 108, 111, 112], "data": [7, 11, 12, 13, 18, 21, 26, 42, 43, 44, 46, 48, 56, 92, 95, 97, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "typic": [7, 11, 22, 23, 95, 96, 97, 101, 104, 113], "compat": [7, 9, 21, 70, 96], "work": [7, 9, 11, 24, 45, 94, 97, 100, 103, 104, 109, 110, 111], "cpu": [7, 9, 12, 17, 97, 100, 101, 104, 108, 109, 110, 111], "other": [7, 11, 12, 18, 42, 71, 88, 94, 97, 98, 100, 103, 104, 107, 109, 110, 111, 113], "target": [7, 9, 11, 12, 42, 43, 44, 46, 55, 61, 62, 70, 88, 96, 100, 108, 109, 110, 111, 112, 113], "method": [7, 9, 18, 21, 24, 25, 54, 81, 88, 96, 100, 101, 103, 108, 109, 110, 112, 113], "come": [7, 8, 94, 95, 98, 100, 101, 102, 110, 111, 112], "soon": [7, 8, 98, 102, 110], "file": [7, 9, 94, 98, 99, 103, 104, 106, 109, 110], "microbenchmark_quantization_config": 7, "yml": 7, "benchmark_mod": 7, "infer": [7, 9, 11, 12, 72, 84, 92, 95, 96, 97, 100, 101, 103, 108, 109, 110, 111, 112], "quantization_config_recipe_nam": 7, "int8wo": 7, "int8dq": 7, "float8dq": [7, 98], "tensor": [7, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 43, 44, 46, 47, 48, 54, 55, 56, 57, 58, 61, 62, 63, 71, 82, 83, 86, 88, 92, 94, 96, 97, 100, 101, 107, 109, 111, 112], "row": [7, 41, 58, 94, 100], "float8wo": 7, "output_dir": 7, "result": [7, 11, 12, 54, 58, 83, 95, 100, 101, 109, 110, 111, 112, 113], "model_param": 7, "name": [7, 36, 37, 50, 51, 53, 73, 81, 85, 88, 91, 98, 100, 103, 104, 108, 109, 110, 113], "small_bf16_linear": 7, "matrix_shap": 7, "small_sweep": 7, "min_pow": 7, "10": [7, 9, 11, 50, 61, 82, 94, 96, 98, 101, 109, 110], "max_pow": 7, "15": [7, 94, 96, 98], "use_torch_compil": 7, "true": [7, 9, 11, 12, 30, 35, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 61, 62, 69, 70, 72, 80, 81, 84, 91, 94, 96, 97, 98, 101, 103, 104, 108, 109, 110, 111, 113], "torch_compile_mod": 7, "max": [7, 9, 50, 95, 96, 101, 103, 109, 110, 113], "autotun": [7, 9, 96, 101], "runner": 7, "gener": [7, 11, 12, 61, 62, 63, 71, 95, 96, 98, 100, 101, 103, 104, 105, 107, 108, 110, 111, 112, 113], "oss": 7, "databas": 7, "python": [7, 9, 95, 96, 98, 100, 105, 107, 108, 109, 111, 112], "ci_microbenchmark_runn": 7, "benchmark_result": 7, "json": [7, 98, 104], "specif": [7, 9, 11, 18, 21, 23, 24, 61, 62, 78, 88, 94, 95, 96, 97, 98, 100, 108, 111, 112, 113], "requir": [7, 11, 12, 23, 25, 94, 95, 96, 98, 100, 103, 108, 111, 113], "mode": [7, 9, 45, 46, 54, 96, 101, 108, 110, 111, 112, 113], "extra_info": 7, "arch": 7, "nvidia": [7, 100], "a100": [7, 11, 96], "sxm4": 7, "80gb": [7, 96], "1024": [7, 81, 91, 96, 97, 111], "custom": [7, 11, 18, 72, 87, 92, 94, 95, 96, 100, 103, 104, 108, 109, 111, 113], "layer": [7, 21, 38, 42, 44, 46, 48, 49, 52, 54, 61, 62, 64, 66, 67, 68, 74, 75, 77, 78, 84, 85, 88, 89, 94, 98, 100, 101, 103, 104, 108, 113], "origin": [7, 11, 12, 22, 44, 48, 65, 82, 88, 95, 96, 97, 98, 100, 108, 109, 113], "metric": [7, 11, 88], "speedup": [7, 9, 11, 46, 94, 95, 96, 98, 100], "wrt": 7, "bf16": [7, 11, 55, 72, 95, 96, 100, 111, 112], "benchmark_valu": 7, "25": [7, 96], "target_valu": 7, "0": [7, 9, 11, 12, 54, 61, 70, 74, 75, 82, 85, 88, 94, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113], "depend": [7, 12, 45, 54, 97, 100, 103, 109, 110, 112], "step": [7, 11, 23, 39, 54, 72, 73, 94, 95, 100, 108, 109, 110, 111, 112, 113], "workflow": [7, 81, 91, 94, 96, 100, 113], "github": [7, 9, 12, 20, 40, 96, 98], "action": [7, 104, 109, 110], "upload": 7, "verifi": [7, 96, 97, 103], "setup": [7, 98], "suit": [7, 9, 109, 111], "unittest": 7, "discov": 7, "out": [7, 9, 11, 24, 50, 54, 88, 94, 95, 96, 100, 103, 108, 109, 110, 111], "memori": [7, 9, 11, 12, 94, 96, 100, 103, 111, 112], "reduc": [7, 11, 39, 72, 94, 98, 100, 111], "matrix": [7, 13, 16, 42, 43, 58, 83, 88, 96, 100, 111], "compil": [7, 11, 54, 81, 83, 92, 94, 95, 96, 101, 103, 111, 112], "error": [7, 50, 54, 70, 94, 103, 109], "set": [7, 11, 12, 16, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 56, 70, 81, 84, 88, 96, 100, 108, 110, 111, 112], "debug": [7, 84], "miss": [7, 100], "properli": [7, 97], "instal": [7, 94, 96, 98, 109, 112], "Not": [7, 100], "avail": [7, 46, 95, 108, 109, 110, 111, 112], "check": [7, 9, 11, 12, 20, 95, 96, 97, 103, 108, 110, 113], "driver": 7, "basic": [7, 9, 23, 96, 101, 103], "shape": [7, 9, 12, 20, 54, 58, 83, 96, 101, 103, 104, 109, 112], "comprehens": [7, 104, 111], "analysi": [7, 100], "enabl": [7, 80, 94, 95, 98, 104, 111], "profil": [7, 9], "onli": [7, 9, 11, 12, 17, 38, 41, 42, 44, 45, 46, 47, 48, 49, 52, 64, 72, 78, 91, 94, 96, 97, 98, 100, 103, 104, 108, 109, 111, 112, 113], "overhead": [7, 100, 104, 111], "multipl": [7, 11, 16, 42, 43, 54, 58, 59, 83, 96, 100, 101, 103, 104, 111, 113], "possibl": [7, 12, 100, 109, 110, 111, 113], "consist": [7, 98, 100, 103, 111, 112, 113], "reproduc": [7, 98], "differ": [7, 9, 11, 18, 46, 56, 59, 82, 83, 94, 95, 96, 97, 98, 100, 103, 104, 109, 110, 111, 113], "case": [7, 8, 9, 54, 72, 83, 98, 100, 103, 104, 108, 109, 113], "user": [7, 11, 42, 54, 59, 72, 78, 92, 94, 95, 96, 98, 100, 101, 103, 107, 109, 110, 111, 112, 113], "more": [7, 9, 11, 12, 40, 45, 46, 47, 52, 54, 94, 95, 96, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112], "about": [7, 9, 11, 46, 95, 96, 97, 98, 100, 109, 110, 111, 113], "compon": [7, 95, 103, 104], "see": [7, 9, 11, 12, 20, 40, 94, 95, 96, 97, 98, 100, 101, 103, 104, 108, 109, 113], "directori": [7, 94], "intend": [8, 95, 109], "provid": [8, 9, 11, 18, 21, 24, 25, 54, 55, 59, 76, 94, 95, 98, 100, 103, 104, 109, 110, 112, 113], "instruct": [8, 11, 96, 98, 109, 110, 111], "most": [8, 23, 72, 95, 98, 100, 104, 109, 110, 113], "fequent": 8, "have": [8, 9, 11, 45, 46, 50, 54, 66, 67, 68, 82, 88, 95, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "ani": [8, 9, 23, 54, 64, 66, 76, 86, 88, 95, 100, 103, 108, 110, 112], "answer": [8, 100], "creat": [8, 9, 12, 28, 29, 31, 94, 95, 100, 103, 108, 109, 111, 112, 113], "an": [8, 9, 11, 12, 25, 30, 31, 54, 69, 70, 72, 78, 88, 92, 94, 95, 96, 98, 100, 101, 103, 108, 109, 110, 111, 112, 113], "issu": [8, 9, 95, 96, 103, 111], "train": [9, 35, 59, 70, 72, 92, 96, 100, 103, 113], "fp4": 9, "s": [9, 11, 12, 50, 54, 55, 57, 82, 94, 95, 96, 98, 100, 101, 103, 109, 110, 111, 112, 113], "fine": [9, 45, 46, 47, 52, 92, 94, 98, 100], "start": [9, 11, 36, 37, 50, 51, 53, 54, 73, 94, 95, 98, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "prototyp": [9, 70, 76, 95, 113], "folder": [9, 98, 109, 110], "could": [9, 95, 103, 108, 109, 111, 112, 113], "also": [9, 11, 54, 70, 81, 95, 96, 97, 100, 101, 103, 104, 109, 112, 113], "take": [9, 22, 61, 62, 74, 81, 87, 91, 95, 100, 108, 109, 110, 111, 112, 113], "look": [9, 12, 94, 95, 100, 108, 109, 110, 111, 112], "affinequantizedtensor": [9, 20, 28, 29, 31, 42, 44, 95, 96, 97, 101, 103], "what": [9, 11, 12, 20, 54, 94, 95, 96, 98, 100, 101, 104, 107, 109, 113], "want": [9, 81, 91, 95, 96, 97, 100, 103, 104, 108, 109, 110, 113], "do": [9, 51, 54, 58, 81, 95, 98, 100, 101, 103, 104, 109, 110, 111, 113], "mostli": [9, 56, 72, 96, 111], "e": [9, 11, 12, 40, 50, 54, 55, 57, 59, 70, 72, 81, 82, 94, 95, 97, 101, 103, 108, 113], "g": [9, 11, 12, 40, 50, 54, 55, 57, 59, 70, 72, 81, 82, 95, 97, 101, 103, 108, 113], "int3": 9, "exact": [9, 11, 78, 109, 110], "same": [9, 11, 12, 42, 55, 56, 57, 78, 82, 83, 91, 94, 95, 100, 101, 103, 110, 111, 112, 113], "affin": [9, 12, 14, 15, 16, 17, 21, 24, 25, 30, 57, 82, 95], "feel": [9, 95, 100, 103, 104], "free": [9, 95, 103], "open": [9, 95, 100], "question": [9, 95, 97, 100, 103, 113], "overview": [9, 92, 96, 104], "page": [9, 96, 111], "contribut": [9, 96, 100], "exist": [9, 51, 72, 94, 95, 100, 101, 103, 109, 113], "base": [9, 18, 23, 42, 50, 60, 71, 72, 76, 88, 95, 96, 100, 103, 104, 108, 109, 110, 111, 112, 113], "make": [9, 95, 96, 103, 104, 109, 113], "trainabl": [9, 11, 95, 103], "add": [9, 23, 103, 107, 111, 113], "parallel": [9, 94, 103, 104], "affine_quantized_tensor": [9, 97], "api": [9, 54, 95, 96, 100, 101, 103, 108, 109, 110, 111, 112], "quant_api": [9, 81, 97, 98, 101], "primit": [9, 12, 20, 103, 109], "op": [9, 11, 12, 20, 42, 46, 54, 81, 96, 100, 103, 104, 109, 110, 111, 113], "slight": [9, 100], "variat": [9, 95], "quant_primit": [9, 12, 20, 101], "mp": 9, "csrc": 9, "mayb": [9, 34], "well": [9, 18, 54, 95, 96, 100, 109, 110, 113], "spars": [9, 13, 21, 24, 61, 74, 75, 88, 95, 100], "marlin": [9, 19, 20, 21, 32], "aqt": 9, "621": 9, "ar": [9, 11, 12, 16, 24, 26, 38, 40, 42, 45, 46, 54, 55, 57, 59, 61, 62, 69, 72, 81, 82, 83, 88, 94, 95, 96, 97, 98, 100, 101, 104, 108, 109, 110, 111, 112, 113], "still": [9, 11, 95, 100, 109, 113], "decid": [9, 95, 100, 101], "split": [9, 42, 44, 98, 109, 110], "implement": [9, 11, 35, 74, 75, 77, 78, 97, 100, 101, 108, 109, 113], "regist": [9, 61, 62, 74, 87, 103], "mai": [9, 12, 56, 70, 95, 97, 101, 109, 110, 111, 112, 113], "own": [9, 11, 92, 94, 96, 100, 101, 109, 110, 113], "int4": [9, 11, 14, 17, 41, 46, 47, 50, 61, 62, 64, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 81, 91, 96, 97, 98, 104], "access": [9, 48, 108], "my_custom_op": 9, "condit": [9, 95], "__torch_function__": [9, 95, 103], "__torch_dispatch__": [9, 103], "oper": [9, 11, 12, 16, 18, 21, 48, 56, 96, 98, 108, 109, 110, 111, 112], "uint4": [9, 46, 95, 96], "weight": [9, 11, 21, 22, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 61, 62, 64, 66, 67, 68, 70, 72, 74, 75, 77, 78, 81, 88, 91, 92, 94, 96, 97, 100, 101, 103, 104, 108, 109, 110, 111, 112, 113], "found": [9, 95, 96, 98, 100, 101, 103], "allow": [9, 78, 96, 100, 103, 108, 109, 110, 111, 113], "peopl": [9, 95, 97, 104, 113], "two": [9, 11, 20, 24, 42, 72, 95, 96, 100, 103, 108, 109, 110, 111, 113], "dispatch_condit": [9, 95], "impl": [9, 12, 95], "actual": [9, 11, 44, 72, 95, 101, 103, 104, 109, 110, 113], "run": [9, 11, 39, 54, 61, 62, 74, 81, 84, 87, 94, 95, 96, 98, 100, 103, 107, 108, 109, 110, 111, 112, 113], "both": [9, 12, 42, 72, 78, 95, 96, 100, 101, 103, 109, 111, 112, 113], "input_tensor": [9, 22, 95, 104], "weight_tensor": [9, 95, 104], "argument": [9, 12, 25, 54, 57, 70, 72, 81, 94, 95, 98, 111], "register_aqt_quantized_linear_dispatch": 9, "show": [9, 82, 94, 95, 96, 98, 100, 104, 109, 110], "sometim": [9, 100], "ha": [9, 11, 12, 72, 95, 98, 100, 103, 104, 108, 109, 110, 112, 113], "pack": [9, 12, 14, 25, 26, 40, 41, 45, 46, 52, 95], "order": [9, 54, 59, 95, 100, 103, 113], "yield": [9, 11, 100], "And": [9, 22, 42, 95, 103, 111, 113], "abstract": [9, 95], "after": [9, 11, 39, 54, 94, 95, 97, 100, 108, 109, 110, 111, 112, 113], "wrap": [9, 54, 103, 111, 112], "factori": 9, "convert": [9, 11, 12, 20, 22, 27, 30, 32, 33, 35, 59, 65, 66, 72, 81, 91, 94, 95, 98, 100, 108, 111, 112, 113], "from": [9, 11, 12, 22, 23, 28, 29, 31, 40, 46, 47, 56, 65, 69, 72, 81, 82, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113], "float": [9, 11, 12, 20, 22, 30, 32, 33, 40, 42, 46, 50, 53, 54, 55, 56, 57, 61, 70, 74, 75, 82, 85, 88, 95, 96, 97, 103, 109, 110, 113], "point": [9, 12, 20, 32, 40, 46, 50, 53, 57, 70, 75, 76, 77, 78, 94, 95, 96, 97, 100, 101, 103, 109, 113], "my": [9, 100, 110], "to_my_dtyp": 9, "mydtypetensor": 9, "from_float": [9, 101, 103], "level": [9, 88, 95, 100, 103, 108, 109, 111, 112], "reus": [9, 95, 103], "appli": [9, 11, 12, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 59, 63, 64, 69, 71, 72, 81, 91, 95, 96, 98, 100, 104, 110], "convers": [9, 11, 12, 38, 95], "filter": [9, 11, 38, 54, 94, 101], "choos": [9, 95, 100, 103, 109, 111], "should": [9, 11, 12, 39, 45, 57, 61, 62, 65, 72, 74, 87, 88, 94, 95, 100, 104, 108, 109, 113], "algorithm": [9, 46, 52, 98, 100, 108], "dynam": [9, 11, 34, 35, 39, 41, 42, 45, 47, 48, 64, 68, 70, 78, 91, 98, 101, 103, 109, 110, 111], "quant": [9, 12, 20, 40, 95, 98, 104, 109, 112, 113], "static": [9, 12, 18, 22, 28, 31, 35, 43, 56, 70, 92, 96, 109, 110, 111, 112, 113], "2": [9, 12, 15, 17, 21, 24, 42, 44, 46, 50, 54, 61, 70, 74, 75, 82, 89, 91, 92, 94, 95, 100, 101, 103, 107], "4": [9, 11, 15, 21, 24, 33, 45, 89, 91, 95, 96, 97, 98, 100, 103, 109, 110], "below": [9, 94, 95, 100, 103, 104, 107, 108], "follow": [9, 11, 46, 70, 72, 94, 95, 96, 98, 100, 101, 103, 108, 109, 110, 111, 112, 113], "import": [9, 11, 65, 69, 72, 81, 91, 96, 97, 98, 100, 101, 103, 104, 107, 108, 111, 112], "unwrap_tensor_subclass": [9, 96], "m_unwrap": 9, "In": [9, 11, 72, 94, 95, 96, 100, 101, 103, 108, 109, 110, 111, 112, 113], "aim": [9, 95, 100, 112], "fullgraph": [9, 96], "first": [9, 22, 54, 58, 72, 88, 95, 98, 101, 103, 104, 109, 110, 113], "remov": [9, 55, 88, 94, 100, 104, 109, 110], "unnecessari": 9, "graph": [9, 96, 109, 110, 113], "break": 9, "torch_log": 9, "output_cod": 9, "script": [9, 96, 98, 101, 103, 107, 110, 111, 112], "inductor": [9, 54, 92, 96, 108, 109], "checkout": [9, 12, 20, 92, 95], "doc": [9, 94, 95, 96, 98, 103], "huggingfac": 9, "transform": [9, 11, 12, 95, 101, 108, 109, 110, 111, 112], "deseri": [9, 95, 109, 110], "save_pretrain": [9, 98], "push_to_hub": [9, 98, 104], "from_pretrain": [9, 11, 98, 104], "http": [9, 12, 20, 40, 54, 88, 96, 98, 100, 112], "co": [9, 98], "main": [9, 12, 20, 46, 95, 96, 98, 100, 101, 103, 109, 113], "en": [9, 54], "anoth": [9, 95, 100, 103, 109, 113], "diffus": 9, "com": [9, 12, 20, 40, 98], "sayakpaul": 9, "blob": [9, 12, 20], "serialization_and_load": 9, "md": 9, "abov": [9, 11, 46, 50, 95, 97, 100, 101, 103, 109, 110, 113], "just": [9, 50, 70, 95, 97, 100, 103, 109, 110, 113], "talk": [9, 95, 98], "fsdp": [9, 95], "ll": [9, 50, 94, 95, 98, 103, 109, 110, 113], "put": [9, 91, 111, 113], "developer_api_guid": 9, "cover": [9, 95, 107, 109, 112, 113], "executorch": [9, 47, 81, 92, 96, 109, 110], "torchchat": 9, "todo": [9, 95], "qat": [9, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 92, 98, 111], "dtensor": [9, 103], "recommend": [9, 11, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 94, 108, 111, 112], "copi": [9, 12, 88, 96, 97, 100, 101, 103, 110, 111], "past": [9, 100], "adapt": [9, 94, 101], "befor": [9, 11, 72, 81, 95, 97, 98, 100, 101, 103, 109, 110, 113], "some": [9, 54, 81, 88, 95, 96, 98, 100, 101, 103, 108, 109, 110, 111, 112, 113], "singl": [9, 11, 34, 39, 42, 54, 56, 94, 96, 100, 109, 113], "comput": [9, 21, 25, 39, 44, 61, 62, 74, 87, 88, 100, 101, 103, 109, 110, 111, 112], "intens": 9, "get": [9, 11, 22, 78, 94, 95, 96, 98, 100, 104, 108, 109, 110, 111, 113], "sens": [9, 95, 103], "d": [9, 95, 98, 110], "benchmark_aq": 9, "A": [9, 11, 12, 26, 54, 56, 87, 100, 103, 104, 109], "quick": [9, 92], "wai": [9, 12, 54, 72, 94, 95, 98, 100, 101, 103, 109, 110, 113], "relev": [9, 46, 95, 107], "chang": [9, 81, 94, 95, 96, 97, 98, 100, 101, 103, 108, 109, 110, 112, 113], "interest": [9, 95, 100, 103], "print_op_and_shap": 9, "output": [9, 11, 35, 54, 55, 57, 82, 94, 95, 96, 98, 100, 107, 108, 109, 110, 111, 112, 113], "torch_func": 9, "built": [9, 94, 103], "_c": 9, "tensorbas": 9, "object": [9, 26, 81, 91, 103, 109, 110, 113], "arg": [9, 12, 61, 62, 63, 64, 66, 75, 88, 103, 104, 110, 113], "all": [9, 39, 50, 54, 56, 61, 62, 64, 66, 74, 76, 87, 88, 89, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108, 109, 111, 113], "under": [9, 11, 98], "benchmark_your_kernel": 9, "helper": [9, 79, 80], "right": [9, 95, 100, 109], "1": [9, 21, 26, 36, 37, 42, 44, 46, 50, 51, 52, 53, 54, 73, 82, 88, 92, 95, 96, 97, 99, 100, 101, 103, 106, 107, 109, 110], "either": [9, 12, 42, 88, 98, 100, 110, 111, 112], "one": [9, 42, 54, 56, 61, 62, 72, 74, 87, 94, 95, 100, 103, 104, 110, 113], "probabl": 9, "keep": [9, 21, 48, 88, 109], "futur": [9, 40, 101, 104, 109, 110, 111, 113], "llama": [9, 11, 98, 104, 108], "llama2": 9, "llama3": [9, 11, 94], "sam": 9, "alreadi": [9, 12, 54, 103, 113], "modifi": [9, 38, 81, 88, 94, 95, 100, 103], "friendli": [9, 95], "compar": [9, 11, 46, 88, 94, 95, 98, 109, 111, 113], "techniqu": [9, 11, 94, 97, 98, 100, 101, 103, 104], "repres": [9, 12, 13, 16, 18, 29, 35, 60, 70, 82, 88, 95, 97, 103, 109, 110], "bound": [9, 42, 98, 100, 104], "help": [9, 11, 94, 95, 98, 104, 108, 109], "each": [9, 22, 54, 64, 70, 75, 77, 78, 84, 87, 95, 100, 101, 103, 104, 109, 110, 113], "understand": [9, 94, 111, 113], "profile_path": 9, "chrome": 9, "trace": [9, 95], "let": [9, 50, 82, 95, 96, 100, 101, 103, 113], "know": [9, 54, 103], "end": [11, 94, 95, 98, 100, 103, 104, 107, 110, 113], "pre": [11, 18, 21, 25, 92, 96, 98, 100, 113], "serv": [11, 12, 18, 92, 94, 103, 112], "flow": [11, 47, 94, 98, 100, 101, 108, 109, 110, 111, 112], "leverag": [11, 94, 96, 98, 103, 111, 112], "partner": [11, 94, 98], "showcas": [11, 94, 98], "focus": [11, 94, 95, 98, 100], "domain": [11, 12, 46, 53, 55, 57, 70, 94], "demonstr": [11, 94, 95, 96, 98, 103, 108, 110], "dure": [11, 12, 20, 48, 54, 57, 70, 72, 85, 94, 96, 98, 100, 101, 103, 108, 110], "numer": [11, 54, 72, 77, 78, 94, 100, 109, 110, 111], "goal": [11, 72], "mitig": [11, 100], "degrad": [11, 72, 100], "eventu": [11, 72, 94], "blog": 11, "resourc": [11, 103], "small": 11, "matric": [11, 24, 100], "freez": [11, 110, 111, 112], "checkpoint": [11, 94, 98, 104], "effici": [11, 25, 77, 96, 100, 101, 112], "paper": [11, 40, 100, 107], "speed": [11, 81, 98, 100, 108], "up": [11, 22, 70, 81, 94, 95, 96, 100, 108, 109, 110, 113], "high": [11, 12, 27, 28, 29, 30, 31, 72, 94, 95, 98, 100, 101, 103, 108, 109, 111, 112], "precis": [11, 12, 27, 28, 29, 30, 31, 44, 48, 64, 67, 68, 72, 75, 77, 78, 95, 101, 103, 108, 111, 112], "similar": [11, 95, 100, 101, 110, 111], "so": [11, 54, 94, 95, 96, 97, 100, 103, 109, 110, 113], "inevit": 11, "presum": 11, "been": [11, 54, 103, 110, 111, 112, 113], "successfulli": [11, 100], "recent": [11, 92], "releas": [11, 96, 111], "1b": [11, 104], "3b": 11, "llamaguard": 11, "8b": [11, 94], "improv": [11, 94, 98, 100, 109, 112, 113], "qualiti": [11, 100], "involv": [11, 16, 72, 100], "separ": [11, 61, 62, 70, 100, 104, 109, 113], "prepar": [11, 54, 59, 64, 66, 72, 84, 88, 95, 100, 108, 111, 112, 113], "fake": [11, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 94, 109, 110, 113], "mean": [11, 12, 22, 50, 55, 57, 82, 94, 95, 96, 100, 109, 110, 113], "valu": [11, 12, 22, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 73, 82, 84, 88, 95, 100, 101, 103, 108, 109, 110, 113], "map": [11, 48, 50, 70, 95, 103, 109, 113], "without": [11, 65, 95, 100, 104, 111, 113], "cast": [11, 12, 34, 36], "lower": [11, 42, 47, 95, 96, 98, 100, 101, 110], "replac": [11, 85, 100, 104], "real": [11, 96, 109, 113], "doe": [11, 23, 46, 72, 95, 100, 103, 109, 111, 112], "perform": [11, 12, 25, 39, 45, 48, 49, 54, 58, 61, 62, 66, 67, 68, 74, 83, 84, 87, 94, 96, 100, 101, 103, 104, 108, 110, 111, 112], "There": [11, 72, 95, 101, 103, 109, 113], "directli": [11, 50, 56, 72, 95, 100, 101, 103], "loop": [11, 94, 100], "distribut": [11, 94, 101, 103, 104, 108], "recip": [11, 35, 61, 62, 74, 87], "instead": [11, 46, 56, 61, 62, 65, 69, 70, 72, 74, 87, 94, 95, 96, 100, 103, 110, 111, 112, 113], "command": [11, 94, 96], "regular": [11, 108, 111, 112], "nnode": 11, "nproc_per_nod": 11, "full_finetune_distribut": 11, "llama3_2": 11, "3b_full": 11, "batch_siz": [11, 97, 98, 101, 109, 110], "16": [11, 62, 94], "equival": [11, 70, 85, 100, 110, 111, 113], "specifi": [11, 12, 35, 38, 49, 52, 59, 61, 62, 63, 71, 72, 78, 81, 82, 88, 91, 94, 100, 108, 109, 110, 113], "default": [11, 12, 13, 16, 23, 25, 26, 42, 43, 44, 45, 46, 52, 54, 55, 57, 64, 70, 78, 81, 84, 85, 94, 96, 103, 104, 108, 109, 110, 111, 112, 113], "asymmetr": [11, 45, 46, 47, 50, 52, 55, 70, 95, 96, 101, 108, 112, 113], "per": [11, 12, 41, 44, 46, 47, 48, 49, 52, 55, 57, 64, 66, 67, 68, 70, 74, 75, 77, 78, 82, 88, 94, 95, 96, 100, 101, 112], "token": [11, 47, 48, 68, 70, 78, 94, 98], "int8": [11, 22, 47, 48, 49, 62, 68, 69, 70, 72, 78, 81, 91, 95, 98, 103, 109, 111, 112, 113], "symmetr": [11, 42, 43, 44, 45, 47, 48, 49, 50, 55, 61, 64, 70, 103, 108, 109, 112, 113], "configur": [11, 16, 34, 35, 38, 41, 42, 43, 44, 46, 47, 48, 49, 52, 81, 91, 94, 95, 96, 98, 111, 112, 113], "_component_": 11, "qat_distribut": 11, "3b_qat_ful": 11, "evalu": [11, 110], "whether": [11, 46, 52, 53, 54, 55, 70, 103], "wa": [11, 103, 110], "llama3_2_3b": 11, "fullmodelhfcheckpoint": 11, "checkpoint_fil": 11, "00001": 11, "00002": 11, "safetensor": 11, "int8dynactint4weightquant": 11, "groupsiz": [11, 67, 68, 77, 78, 82], "32": [11, 45, 46, 47, 62, 69, 70, 72, 74, 75, 81, 91, 94, 96, 97, 98, 101, 103, 110], "hellaswag": [11, 98], "wikitext": 11, "eleuther_ev": 11, "eleuther_evalu": 11, "task": [11, 98], "fullmodeltorchtunecheckpoint": 11, "8da4w": [11, 98], "ckpt": 11, "llama3_token": 11, "path": [11, 81, 83, 96, 98, 108, 109, 110, 111, 113], "tmp": [11, 96], "meta": [11, 97, 104, 113], "print": [11, 88, 96, 97, 98, 103, 107, 109, 110], "version": [11, 17, 42, 44, 46, 70, 94, 96, 103, 104, 109, 110, 113], "shot": [11, 100], "stderr": 11, "none": [11, 12, 16, 20, 27, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 45, 46, 49, 50, 51, 53, 54, 55, 56, 57, 61, 62, 64, 69, 70, 72, 73, 74, 75, 76, 77, 78, 81, 82, 84, 85, 86, 88, 91, 101, 103, 104, 108, 109, 110, 112], "acc": [11, 109, 110], "5021": 11, "0050": 11, "acc_norm": 11, "6797": 11, "0047": 11, "bits_per_byt": 11, "6965": 11, "byte_perplex": 11, "6206": 11, "word_perplex": 11, "13": 11, "2199": 11, "much": [11, 96, 100, 113], "openassist": 11, "oasst1": 11, "dataset": [11, 94, 95, 98, 108, 111, 112], "find": [11, 22, 100, 109, 113], "achiev": [11, 22, 94, 100, 101, 103, 110, 111], "higher": [11, 94, 95, 103, 108, 109, 111, 112], "accuraci": [11, 94, 98, 100, 101, 108, 110, 111], "than": [11, 26, 70, 94, 95, 100, 103, 109], "recov": [11, 100, 110], "69": [11, 101], "8": [11, 25, 26, 45, 46, 50, 61, 62, 67, 77, 94, 95, 96, 98, 104, 111, 112], "overal": [11, 92, 96, 109, 113], "vanilla": 11, "compos": [11, 59, 95, 100, 103, 109, 110, 113], "lora": 11, "89x": 11, "usag": [11, 12, 39, 54, 59, 61, 62, 65, 69, 70, 72, 92, 94, 98, 111, 112], "36": [11, 94, 98], "qat_lora_finetune_distribut": 11, "3b_qat_lora": 11, "try": [11, 95, 100, 103, 109], "fsdp2": [11, 94], "yaml": 11, "onc": [11, 54, 100], "complet": [11, 54, 98, 108, 112], "save": [11, 88, 94, 96, 97, 98, 104], "qat_out": 11, "quatiz": 11, "document": [11, 103, 104, 108, 109, 111], "prefer": [11, 42, 95, 96, 103], "call": [11, 12, 54, 61, 62, 74, 87, 95, 96, 97, 100, 101, 103, 104, 110, 112], "These": [11, 100, 103, 108, 109, 110, 113], "hood": 11, "mini": [11, 98], "gpu": [11, 92, 94, 96, 104, 107, 108], "smaller": [11, 26, 45, 46, 47, 52, 96, 97], "fit": [11, 12, 25, 95, 97], "adjust": [11, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54], "attribut": [11, 103, 104, 111, 112], "accordingli": 11, "get_model": 11, "vocab_s": 11, "4096": [11, 94], "num_lay": 11, "num_head": 11, "num_kv_head": 11, "embed_dim": 11, "2048": [11, 94], "max_seq_len": 11, "train_loop": [11, 72], "sgd": 11, "lr": [11, 94], "001": 11, "momentum": [11, 110], "9": [11, 94], "weight_decai": 11, "1e": [11, 94], "5": [11, 50, 61, 85, 88, 94, 96, 98, 100, 104, 107, 109, 110], "loss_fn": 11, "crossentropyloss": [11, 109, 110], "i": [11, 83, 94, 98, 100, 108, 109, 110], "rang": [11, 50, 94, 100, 101, 109, 110], "randint": 11, "loss": [11, 94, 100, 109, 110], "backward": [11, 39, 94, 100, 110], "zero_grad": [11, 94, 110], "next": [11, 94, 95, 101, 109, 110, 111, 112], "scheme": [11, 48, 49, 61, 62, 72, 98, 108], "although": [11, 61, 62, 74, 87, 103], "integ": [11, 12, 30, 31, 45, 46, 50, 53, 55, 57, 58, 70, 71, 83, 101, 109, 110, 111], "arithmet": [11, 72], "float32": [11, 12, 28, 57, 66, 68, 70, 74, 75, 78, 82, 97, 98, 100, 101, 103, 111, 112, 113], "becaus": [11, 12, 21, 94, 95, 97, 100, 103, 110, 113], "int8dynamicactivationint4weightconfig": [11, 72, 78], "qatconfig": [11, 65, 69, 73], "swap": [11, 38, 64, 66, 94, 95, 100, 101, 110], "fakequantizedlinear": [11, 64, 65, 79, 80], "base_config": [11, 72], "structur": [11, 24, 91, 96, 97, 100, 103, 109], "attun": 11, "benefici": 11, "later": [11, 95, 103, 109, 110, 112], "readi": [11, 94, 96, 98, 101, 103, 110], "did": [11, 47], "altern": [11, 70, 95, 101, 103, 111, 112], "legaci": 11, "offer": [11, 103, 109], "customiz": [11, 81], "unlik": [11, 101], "int8dynactint4weightqatquant": 11, "qat_quant": 11, "insert": [11, 96, 101, 108, 109, 110, 111, 112, 113], "int8dynactint4weightqatlinear": 11, "int8dynactint4weightlinear": 11, "fraction": [11, 12], "therebi": 11, "significantli": [11, 108, 109, 111, 112], "footprint": 11, "extens": [11, 103, 109, 111], "addition": [11, 111, 112], "frozen": 11, "further": [11, 95, 103, 108, 109, 110, 111], "nf4": [11, 22], "propos": [11, 88], "express": [11, 96, 103, 108, 109, 110, 113], "subclass": [11, 12, 20, 38, 54, 61, 62, 74, 87, 91, 96, 97, 100], "nf4tensor": 11, "cleanli": 11, "simpli": [11, 54, 100, 101, 103], "to_nf4": 11, "frozennf4linear": 11, "in_dim": 11, "out_dim": 11, "bool": [11, 12, 30, 35, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 61, 62, 68, 70, 74, 75, 77, 78, 80, 81, 84, 91, 101], "quantization_kwarg": 11, "No": [11, 95, 97, 100], "requires_grad_": 11, "nf4_weight": 11, "requires_grad": [11, 12, 95, 101, 103, 104], "though": [11, 103], "shown": [11, 98, 100, 110, 113], "competit": [11, 94], "baselin": [11, 94, 98, 109], "while": [11, 61, 62, 72, 74, 87, 88, 98, 100, 103, 108, 109, 113], "even": [11, 12, 94, 100, 113], "newer": 11, "mxfp4": 11, "nvfp4": 11, "blackwel": 11, "reap": 11, "benefit": [11, 100, 103, 109, 112], "vari": [11, 12, 109, 110, 111, 112], "tradeoff": [11, 100], "incorpor": 11, "its": [11, 45, 100, 103, 104, 109, 113], "loralinear": 11, "lora_finetune_single_devic": 11, "3b_qlora_single_devic": 11, "limit": [11, 94, 103, 104, 109], "yet": [11, 47, 51, 72, 103, 104, 110, 111, 112], "invok": [11, 111], "loraconfig": 11, "get_peft_model": 11, "automodelforcausallm": [11, 98, 104], "torchaoconfig": [11, 98, 104], "int8weightonlyconfig": [11, 104], "base_model": 11, "quantization_config": [11, 98, 104, 112], "peft_config": 11, "throughput": [11, 94, 98], "increas": [11, 100, 109], "torchtitan": 11, "enable_fp8_train": 11, "fp8_recipe_nam": 11, "tensorwis": [11, 34, 35], "initi": [11, 12, 76, 95, 96, 97, 110], "experi": [11, 94, 112], "saw": 11, "experiment_nam": 11, "tok": 11, "peak_mem_reserv": 11, "6502": 11, "143": 11, "000": 11, "30": [11, 94, 96, 109], "090": 11, "fp8_nonam": 11, "7205": 11, "386": 11, "816": 11, "010": 11, "266": 11, "fp8_tensorwis": 11, "7222": 11, "198": 11, "11": [11, 94], "074": [11, 94], "fp8_rowwis": 11, "6387": 11, "968": 11, "756": 11, "29": [11, 94], "158": 11, "096": 11, "fp8_rowwise_with_gw_hp": 11, "7573": 11, "698": 11, "480": 11, "516": 11, "908": 11, "hellaswag_acc": 11, "wikitext_word_perplex": 11, "533": 11, "12": [11, 94, 112, 113], "407": [11, 94], "414": 11, "007": 11, "412": 11, "005": 11, "420": 11, "013": [11, 94], "534": 11, "416": 11, "009": 11, "tensor_impl": [12, 20, 95, 101], "aqttensorimpl": [12, 20], "block_siz": [12, 18, 20, 22, 27, 28, 30, 31, 32, 33, 55, 56, 57, 82, 96, 101], "tupl": [12, 20, 22, 27, 28, 30, 31, 32, 42, 43, 55, 56, 57, 76, 82, 88, 103, 104, 109, 110, 113], "quant_min": [12, 20, 30, 31, 32, 50, 55, 56, 57, 82, 95, 96, 103, 112, 113], "union": [12, 20, 35, 42, 43, 55, 57, 70, 81, 82], "quant_max": [12, 20, 30, 31, 32, 50, 55, 56, 57, 82, 95, 96, 103, 112, 113], "zero_point_domain": [12, 20, 30, 31, 32, 46, 55, 56, 70], "zeropointdomain": [12, 20, 30, 31, 32, 46, 55, 56, 70], "stride": [12, 20, 95, 103], "sourc": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 91, 98, 105, 107], "quantized_tensor": 12, "float_tensor": [12, 103], "scale": [12, 18, 21, 28, 31, 36, 39, 42, 43, 50, 53, 55, 56, 57, 58, 64, 70, 75, 76, 77, 78, 82, 84, 85, 95, 100, 101, 103, 104, 113], "zero_point": [12, 18, 31, 46, 53, 55, 56, 57, 82, 95, 100, 101, 103, 113], "happen": [12, 20, 54, 95, 103, 109, 111], "choose_qparam": [12, 95], "dequant": [12, 20, 22, 46, 57, 95, 96, 103, 104, 109, 111, 112, 113], "ao": [12, 20, 100, 104], "three": [12, 54, 88, 91, 95, 111, 112], "choose_qparams_affin": [12, 46, 56, 95], "quantize_affin": [12, 46, 95], "qand": 12, "dequantize_affin": [12, 46], "extern": [12, 111], "regardless": 12, "intern": [12, 25], "represent": [12, 18, 29, 46, 95, 100, 104, 109, 113], "orient": 12, "field": [12, 70, 73, 113], "storag": [12, 21, 95, 100], "store": [12, 21, 22, 26, 48, 87, 95, 100, 104, 109, 110], "plain": [12, 46, 104], "int_data": [12, 103], "format": [12, 21, 22, 40, 45, 46, 95, 98, 100, 109, 110, 113], "kernel": [12, 14, 15, 17, 21, 25, 40, 42, 45, 46, 77, 81, 96, 98, 100, 108, 111, 112], "granular": [12, 36, 42, 43, 45, 46, 47, 49, 52, 55, 57, 61, 62, 64, 70, 71, 82, 94, 95, 98, 101, 104], "element": [12, 24, 26, 54, 55, 57, 64, 75, 77, 78, 82, 100], "share": [12, 55, 57, 82, 100], "qparam": [12, 55, 57, 82], "minimum": [12, 54, 55, 57, 82], "deriv": [12, 56, 82], "maximum": [12, 55, 57, 82, 84], "zero": [12, 24, 46, 48, 55, 57, 70, 75, 76, 77, 78, 88, 100, 101, 113], "subtract": [12, 22], "unquant": [12, 113], "given": [12, 20, 33, 94, 100, 104, 113], "classmethod": [12, 20, 101, 103, 104], "from_hp_to_floatx": 12, "input_float": [12, 20, 27, 28, 29, 30, 31, 32, 86], "target_dtyp": [12, 27, 28, 30, 31, 34, 35, 55, 56, 95, 101], "_layout": [12, 20, 27, 28, 29, 30, 31, 32, 95, 96, 101], "layout": [12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 46, 47, 48, 91, 100], "scale_dtyp": [12, 27, 28, 30, 55, 56, 101], "float8": [12, 15, 16, 27, 28, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 64, 92, 95, 98, 101], "from_hp_to_floatx_stat": 12, "from_hp_to_fpx": 12, "floatx": [12, 29, 95], "ebit": [12, 29, 40], "mbit": [12, 29, 40], "float1": [12, 29], "float7": [12, 29], "from_hp_to_intx": [12, 20], "mapping_typ": [12, 30, 47, 55, 56, 70], "mappingtyp": [12, 30, 47, 48, 55, 56, 70, 101], "ep": [12, 30, 55, 56, 70, 101, 110, 112, 113], "zero_point_dtyp": [12, 30, 55, 56, 101], "preserve_zero": [12, 30, 46, 55, 56], "plainlayout": [12, 30, 31, 47, 48, 101], "use_hqq": [12, 30, 46, 52, 104], "from_hp_to_intx_stat": 12, "correct": [12, 21, 109, 110], "otherwis": [12, 49, 59, 70, 95, 110], "desir": [12, 54, 101], "gradient": [12, 92, 100], "implicitli": [12, 113], "complex": [12, 100], "non_block": 12, "memory_format": [12, 111, 112], "preserve_format": 12, "accord": 12, "c": [12, 95, 96, 103, 111, 112], "rule": 12, "truncat": 12, "part": [12, 92, 95, 100, 103, 110], "cannot": [12, 100, 101, 104], "inf": 12, "long": [12, 103, 109], "behavior": [12, 18, 59, 104, 109, 110], "undefin": [12, 59, 88], "across": [12, 88, 98, 100, 103, 104], "platform": 12, "attempt": 12, "asynchron": 12, "respect": [12, 100, 110], "host": [12, 104], "pin": 12, "pageabl": 12, "howev": [12, 100, 104, 110, 113], "caution": 12, "advis": [12, 95], "good": [12, 96, 103, 113], "pin_memori": 12, "match": [12, 57, 58, 77, 78, 100, 109], "float64": 12, "5044": 12, "0005": 12, "3310": 12, "0584": 12, "cuda0": 12, "blocksiz": 13, "64": [13, 33, 46, 52, 64, 97, 98, 101, 103, 104], "block": [13, 22, 88, 100], "variabl": [13, 16, 25, 26, 88, 100], "cutlass": [14, 15], "mm_config": [16, 42, 43], "float8mmconfig": [16, 42, 43], "tinygemm": [17, 46, 77, 81, 95, 96], "_weight_int4pack_mm_for_cpu": [17, 46], "least": 17, "6": [17, 70, 94, 95, 96, 98, 100, 109, 110, 111], "It": [18, 21, 23, 25, 39, 96, 100, 103, 113], "post": [18, 25, 72, 92, 96, 103, 110, 113], "design": [18, 21, 24, 98, 104, 108, 109, 113], "extend": [18, 95, 100, 111], "conjunct": 18, "tensorimpl": 18, "interact": [18, 95, 109], "qqq": [19, 20, 32], "marlinqqq": 20, "inherit": [20, 23, 103, 104, 111, 112], "_choose_qparams_and_quantize_affine_qqq": 20, "_dequantize_affine_qqq": 20, "pattern": [21, 24, 95, 96, 104, 108, 109], "preprocess": [21, 24], "manag": 21, "pre_process": 21, "1\u00ba": 21, "transpos": [21, 95, 103], "sinc": [21, 61, 62, 74, 87, 95, 97, 98, 100, 101, 103, 109, 110, 111, 112, 113], "2\u00ba": 21, "inject": 21, "3\u00ba": 21, "again": [21, 22, 100, 109, 113], "dim": [21, 101, 103, 104, 109, 110], "tensor_meta": 22, "subclasstensorarg": 22, "n_block": 22, "scaler_block_s": [22, 33], "quantized_scal": 22, "quantization_factor": 22, "scaler_mean": 22, "quantized_data": [22, 104], "qlora": [22, 92, 98], "convert_to_norm_float_weight": 22, "normal": [22, 33, 54, 100, 109, 110], "dequantize_scal": 22, "unpack": [22, 95], "doubl": 22, "scaler": 22, "per_scaler_block": 22, "factor": [22, 58, 85, 94, 100], "inpt_weight": 22, "double_quantize_scal": 22, "calcul": [22, 39, 42, 50, 55, 56, 84, 95, 100, 109, 113], "absmax": 22, "posit": 22, "per_block": 22, "int16": [22, 109], "n_scaler_block": 22, "get_original_weight": 22, "quantize_tensor_nearest": 22, "float16": [22, 82, 100], "nearest": 22, "round": [22, 50, 103], "metadata": [23, 95, 98, 103, 104], "semi": [24, 91, 100], "everi": [24, 61, 62, 74, 87, 100, 103, 109, 110], "four": [24, 108], "prune": [24, 88], "conform": 24, "inner_k_til": [25, 46, 67, 77, 96], "core": [25, 51, 95, 101, 104, 109], "tile": [25, 95], "affect": [25, 100], "matmul": [25, 42, 44, 95, 100, 103], "pack_dim": [26, 52], "uintx": [26, 52, 95], "standard": [26, 95, 104], "byte": [26, 40, 52], "uintxtensor": 26, "determin": [26, 55, 72, 94, 100, 104], "along": [26, 100, 104, 108], "indic": [26, 53, 100, 113], "last": [26, 94, 108], "256": [33, 46, 66, 67, 68, 77, 78, 98, 109, 110, 113], "scaling_typ": [34, 35], "scalingtyp": [34, 35], "scaling_granular": [34, 35], "scalinggranular": [34, 35], "cast_config_input": 35, "castconfig": 35, "cast_config_input_for_grad_weight": 35, "cast_config_weight": 35, "cast_config_weight_for_grad_input": 35, "cast_config_grad_output": 35, "cast_config_grad_output_for_grad_weight": 35, "gemm_config_output": 35, "float8gemmconfig": 35, "use_fast_accum": [35, 43], "gemm_config_grad_input": 35, "gemm_config_grad_weight": 35, "enable_fsdp_float8_all_gath": 35, "pad_inner_dim": [35, 43], "emul": [35, 43], "force_recompute_fp8_weight_in_bwd": 35, "round_scales_to_power_of_2": 35, "from_recipe_nam": 35, "recipe_nam": [35, 94], "float8linearrecipenam": 35, "qualnam": [36, 37, 50, 51, 53, 73], "boundari": [36, 37, 50, 51, 53, 73], "strategi": 36, "module_filter_fn": [38, 94], "callabl": [38, 54, 81, 86, 91, 104], "float8linearconfig": 38, "float8linear": [38, 94], "instanc": [38, 61, 62, 74, 81, 87, 91, 97, 103, 109, 111, 112, 113], "fqn": [38, 88, 91, 94, 101], "sum": [39, 109, 110], "set_inductor_config": [40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54], "sub": [40, 52, 100], "expon": 40, "mantissa": 40, "fp6_e3_m2": 40, "fp6_e2_m3": 40, "fp6": 40, "llm": 40, "arxiv": [40, 88, 100], "org": [40, 54, 88, 95, 96, 98, 100, 112], "ab": [40, 88, 100], "2401": 40, "14112": 40, "repo": 40, "usyd": 40, "fsalab": 40, "fp6_llm": 40, "renam": [40, 109, 110], "fpxtensorcoreaqttensorimpl": 40, "experiment": [40, 72, 108], "merg": 40, "to_affine_quantized_floatx": 40, "128": [41, 45, 46, 94, 98, 101, 103, 104, 112, 113], "packing_format": [41, 46], "packingformat": [41, 46], "preshuffl": 41, "groupwis": 41, "activation_dtyp": [42, 43], "float8_e4m3fn": [42, 43, 44, 95], "weight_dtyp": [42, 43, 44, 98], "pertensor": [42, 43, 101], "perrow": [42, 43, 98], "list": [42, 54, 57, 59, 85, 88, 95, 96, 103, 104, 108, 110, 113], "activation_value_lb": 42, "activation_value_ub": 42, "kernel_prefer": 42, "kernelprefer": 42, "auto": [42, 98, 104], "fp8granular": 42, "fast": [42, 43, 100], "accumul": [42, 43], "upper": 42, "defalut": 42, "chosen": [42, 46, 100], "hardwar": [42, 45, 95, 96, 98, 100], "torchinductor": [42, 43, 44, 45, 46, 47, 48, 49, 52, 111, 112], "plan": [42, 44, 95, 110], "deprec": [42, 44, 65, 69], "float8tensor": [42, 44], "float8_e4m": 43, "channel": [44, 48, 49, 64, 66, 67, 68, 70, 74, 75, 77, 78, 87, 101, 112], "packing_bitwidth": 45, "weight_onli": 45, "gemlit": 45, "triton": [45, 95, 111, 112], "associ": [45, 101], "fp16": [45, 55], "control": [45, 46, 47, 48, 49, 52, 88, 100, 104, 109], "grain": [45, 46, 47, 52, 103], "impact": [45, 54, 94, 98, 104], "runtim": [45, 95, 109], "tensorcoretiledlayout": [46, 95, 96], "tensor_core_til": [46, 95], "int4mm": [46, 96], "aten": [46, 95, 96, 103, 104, 108, 109, 110, 111, 112], "_weight_int4pack_mm": [46, 95], "tradit": 46, "exactli": [46, 103], "choic": 46, "hqq": [46, 52, 95], "preserv": [46, 55, 88, 98, 100, 108], "Will": 46, "act_mapping_typ": [47, 48], "produc": [47, 96, 108, 109, 110, 111, 112], "backend": [47, 92, 96, 98, 100, 113], "marlinqqqlayout": 47, "cutlassint4packedlayout": 47, "weight_only_decod": 48, "around": [48, 94, 96, 97, 109], "decod": [48, 98], "better": [48, 49, 94, 103, 109, 110, 111, 112, 113], "number": [50, 52, 54, 64, 75, 77, 78, 88, 98, 100, 103, 110, 111], "sai": [50, 82, 95, 104, 113], "3": [50, 54, 61, 82, 92, 94, 95, 96, 100, 107, 109, 110], "7": [50, 94, 98, 111, 112], "symmetric_no_clipping_err": 50, "variant": [50, 56, 103], "smin": 50, "smax": 50, "min_val_neg": [50, 103], "max_val_po": [50, 103], "By": [50, 100], "individu": [50, 100], "less": [50, 100, 103, 109], "neg": 50, "placehold": [51, 112], "uint1": [52, 95], "uint7": [52, 95], "enum": [53, 73], "quantized_v": 53, "float_val": 53, "mid_point": 53, "example_input": [54, 76, 96, 97, 101, 108, 109, 110, 111, 112, 113], "qtensor_class_list": 54, "aqdefaultlinearweight": 54, "aqint8weightonlyquantizedlinearweight": 54, "aqint8weightonlyquantizedlinearweight2": 54, "aqint8dynamicallyquantizedlinearweight": 54, "filter_fn": [54, 81, 91], "interpol": 54, "85": 54, "manual": [54, 110], "supress_autoquant_error": 54, "min_sqnr": 54, "aq_kwarg": 54, "autoquant": 54, "identifi": [54, 101, 113], "fastest": 54, "over": [54, 94, 100, 109, 110], "potenti": [54, 100, 101, 108, 109, 111, 112], "qtensor": 54, "search": [54, 100], "whose": [54, 113], "exchang": 54, "autoquantizablelinearweight": 54, "calibr": [54, 56, 96, 108, 110, 111, 112], "seen": 54, "record": [54, 95, 101], "final": [54, 81, 95, 96, 100, 108, 109, 110, 111, 112, 113], "benchmark": [54, 84, 92, 94, 96, 108, 111, 112], "member": 54, "pick": 54, "highli": 54, "had": [54, 103, 109], "proce": 54, "combin": [54, 70, 98, 100, 103, 109, 111], "finalize_autoqu": 54, "log": [54, 103], "fulli": [54, 81, 85, 91, 98, 100, 109], "unless": [54, 104], "default_autoquant_class_list": 54, "second": [54, 58, 72, 94, 95, 107, 113], "stop": 54, "wait": [54, 95], "sever": [54, 94, 104, 108, 113], "automat": [54, 72, 94, 98, 103, 104, 107], "suppress": 54, "accept": [54, 98, 113], "signal": 54, "nois": 54, "ration": 54, "wikipedia": 54, "wiki": 54, "noise_ratio": 54, "v": [54, 113], "non": [54, 95, 100, 103, 108, 111, 112], "caus": [54, 94], "too": 54, "larg": [54, 98, 103, 111], "resaon": 54, "40": [54, 94], "keyword": [54, 70, 72], "example_input1": 54, "example_input2": 54, "int32": [55, 66, 70, 74, 75, 95, 96, 109, 113], "fp32": [55, 57, 70, 78, 101, 103, 109, 111], "optioanl": 55, "param": [55, 56, 88, 98], "request": [55, 57, 82], "min_val": [56, 95, 103], "max_val": [56, 95, 103], "observ": [56, 87, 100, 101, 108, 109, 110, 111, 112, 113], "obtain": 56, "track": [56, 95, 104], "input_dtyp": 57, "output_dtyp": [57, 74, 82], "uint8": [57, 82, 95, 101, 113], "b": 58, "scales1": 58, "multipli": [58, 83, 100], "rais": [58, 69, 72, 83, 94, 103, 104], "assertionerror": [58, 83, 94, 103], "expect": [58, 94, 100, 103, 108, 109, 111, 112, 113], "twostepquant": 59, "easili": [59, 108], "thei": [59, 94, 95, 96, 100, 103, 109, 110, 113], "constructor": [59, 103], "must": [59, 70, 72, 78, 94, 100, 104, 110, 112, 113], "embed": [59, 61, 66, 69, 72, 74, 75], "my_quant": 59, "qatquantizer1": 59, "qatquantizer2": 59, "qatquantizer3": 59, "num_embed": [61, 74, 75], "embedding_dim": [61, 74, 75], "padding_idx": [61, 74, 75], "max_norm": [61, 74, 75], "norm_typ": [61, 74, 75], "scale_grad_by_freq": [61, 74, 75], "weight_config": [61, 62, 69, 72], "fakequantizeconfigbas": [61, 62, 69, 72], "intxfakequantizeconfig": [61, 62, 69, 71, 72], "fq_embed": 61, "longtensor": 61, "overridden": [61, 62, 74, 87], "within": [61, 62, 74, 87, 98, 100, 104, 111, 112], "afterward": [61, 62, 74, 87], "former": [61, 62, 74, 87], "care": [61, 62, 74, 87, 97, 100, 109], "hook": [61, 62, 74, 87, 95], "latter": [61, 62, 74, 87, 110], "silent": [61, 62, 74, 87, 111], "ignor": [61, 62, 74, 87, 94, 109, 110], "in_featur": [62, 77, 78, 94, 96, 97, 101, 103], "out_featur": [62, 77, 78, 94, 96, 101, 103], "activation_config": [62, 69, 72], "per_token": [62, 69, 70, 72], "is_symmetr": [62, 69, 70, 72], "fq_linear": 62, "scale_precis": [64, 66, 70, 74, 75], "rowwis": 64, "fakequantizedembed": 65, "back": [65, 103], "model_with_fake_quantized_linear": 65, "zero_point_precis": [66, 70, 74, 75], "int4weightonlyqatembed": 66, "int4weightonlyembed": 66, "scales_precis": [67, 68, 77, 78], "padding_allow": 68, "valueerror": [69, 72], "torchaodtyp": 70, "is_dynam": [70, 111, 112, 113], "range_learn": 70, "simul": [70, 72, 89, 95, 100], "older": 70, "int1": [70, 95], "int7": 70, "pergroup": [70, 98], "pertoken": 70, "per_channel": 70, "peraxi": [70, 98, 101], "per_group": [70, 82], "leav": 70, "empti": [70, 95], "properti": [70, 71, 95], "throw": 70, "els": [70, 98, 104, 109, 110], "symmetri": 71, "qatstep": 72, "awar": [72, 88, 92, 96, 100, 103], "ptq": [72, 110, 111], "phase": [72, 113], "common": [72, 94, 95, 100], "int4weightonlyconfig": [72, 95, 96, 97, 104], "qat_config": 72, "act_config": 72, "alwai": [72, 98, 103], "One": [72, 100, 103, 104, 113], "neither": 72, "nor": 72, "intxfakequantizerbas": 76, "weightonlyint4linear": 77, "hardcod": [78, 95, 113], "mod": [79, 80, 94, 100, 103], "disabl": [79, 103, 110], "inplac": [81, 88, 96], "qualifi": [81, 85, 91, 100], "move": [81, 95, 101, 104, 110, 111], "predefin": [81, 113], "execut": [81, 99, 103, 106], "int8_dynamic_activation_int4_weight": 81, "int8_dynamic_activation_int8_weight": [81, 91], "mm": [81, 103, 109], "int4_weight_onli": 81, "int8_weight_onli": 81, "sequenti": [81, 91, 94], "tabl": [82, 94, 95, 100], "per_tensor": 82, "per_axi": 82, "axi": [82, 101], "mat2": 83, "safe": 83, "consid": [83, 95, 100], "cubla": 83, "fallback": [83, 104], "j": 83, "debug_skip_calibr": 84, "smoothquant": [84, 85, 108], "smoothfakedynamicallyquantizedlinear": [84, 85], "skip_fqn_list": 85, "cur_fqn": 85, "alpha": 85, "skip": [85, 88, 100], "being": [85, 94, 95, 100, 104, 111, 112], "input_quant_func": [86, 95], "quant_kwarg": 86, "dict": [86, 88, 103, 104, 112, 113], "l2": [87, 100], "norm": [87, 88, 100], "buffer": 87, "x_orig": 87, "sparsity_level": [88, 100], "semi_structured_block_s": 88, "wanda": 88, "sparsifi": [88, 92, 97, 100], "2306": 88, "11695": 88, "product": [88, 98, 104, 111, 113], "magnitud": [88, 100], "parametr": 88, "deepcopi": [88, 96, 101, 103, 110], "squash_mask": [88, 100], "params_to_keep": 88, "params_to_keep_per_lay": 88, "squash": 88, "mask": [88, 100], "appropri": [88, 95, 108, 109, 110, 111, 112], "sparse_param": 88, "attach": [88, 100, 113], "kei": [88, 100, 107], "xdoctest": 88, "local": [88, 98, 100], "don": [88, 94, 96, 100, 104, 113], "t": [88, 94, 95, 96, 100, 101, 103, 104, 109, 110, 113], "hasattr": [88, 104], "submodule1": 88, "linear1": [88, 96, 97, 101, 103], "foo": [88, 109], "bar": [88, 109], "submodule2": 88, "linear42": 88, "baz": 88, "42": [88, 101], "24": 88, "ones": [88, 95, 110], "update_mask": 88, "tensor_nam": [88, 104], "statist": [88, 95, 100, 101, 109, 110], "retriev": 88, "act_per_input": 88, "Then": [88, 103, 112, 113], "whole": [88, 113], "alia": [90, 104], "semisparseweightconfig": 90, "sparsify_": 91, "apply_tensor_subclass": [91, 95], "essenti": [91, 104, 108], "semi_sparse_weight": 91, "semisparselayout": 91, "sparsemarlinlayout": 91, "isinst": [91, 94, 100, 101, 103, 104, 110, 113], "sparse_api": 91, "librari": [92, 97], "nativ": [92, 94, 103, 109], "introduct": [92, 95, 98], "highlight": [92, 103, 107], "guid": [92, 95, 98, 108], "contributor": [92, 96], "tune": [92, 94, 98, 100, 108], "vllm": 92, "sglang": 92, "serial": [92, 95, 109, 110], "write": [92, 96, 108, 109, 110], "advanc": [92, 101, 103, 108, 111, 112], "export": 92, "x86": [92, 96], "intel": [92, 108, 111], "openvino": [92, 96], "5x": 94, "cluster": 94, "34": 94, "43x": 94, "2k": 94, "h200": 94, "latest": [94, 96], "offic": 94, "offici": 94, "popular": [94, 95], "flagship": 94, "form": [94, 95, 100], "quickli": [94, 103], "batteri": 94, "includ": [94, 95, 103, 108, 111, 112, 113], "commonli": [94, 100], "fork": 94, "build": [94, 95, 100, 103, 104, 109], "top": [94, 95, 103, 108, 109, 110, 111, 112], "re": [94, 97, 98, 103, 109, 110], "virtual": 94, "environ": [94, 98], "conda": 94, "venv": 94, "download": [94, 96, 98, 105, 107, 109, 110, 112], "job": 94, "root": [94, 98], "launch": 94, "ngpu": 94, "config_fil": 94, "train_config": 94, "llama3_8b": 94, "toml": 94, "run_train": 94, "sh": [94, 98], "hyperparamet": 94, "edit": [94, 98], "line": [94, 100], "flag": [94, 110], "termin": 94, "rank0": 94, "titan": 94, "2025": 94, "06": 94, "04": 94, "08": 94, "51": 94, "48": 94, "info": 94, "2254": 94, "27": 94, "34gib": 94, "28": 94, "78": 94, "tp": [94, 104], "375": 94, "tflop": 94, "21": 94, "73": [94, 101], "mfu": 94, "20": [94, 98, 110], "58": 94, "557": 94, "7069": 94, "99gib": 94, "62": 94, "034": 94, "35": [94, 98, 101], "41": [94, 98], "19": 94, "52": 94, "224": [94, 101, 108, 109, 110, 111, 112], "9196": 94, "022": 94, "406": [94, 109, 110], "65": 94, "904": 94, "1423": 94, "014": 94, "23": [94, 101], "As": [94, 95, 109, 113], "warmup": 94, "7k": 94, "99gb": 94, "peak": [94, 98], "against": 94, "02": 94, "37": 94, "404": 94, "2611": 94, "22gib": 94, "595": 94, "47": 94, "49": [94, 101], "027": 94, "4260": 94, "89gib": 94, "344": 94, "367": 94, "39": 94, "03": 94, "01": 94, "988": 94, "9482": 94, "321": 94, "366": 94, "14": 94, "991": 94, "1183": 94, "300": 94, "364": 94, "89": 94, "4659": 94, "291": 94, "84": 94, "769": 94, "gc": 94, "peform": 94, "period": 94, "collect": [94, 95, 100], "3k": 94, "89gb": 94, "11x": 94, "nearli": 94, "ident": [94, 100], "performan": 94, "vs": [94, 100, 109, 113], "curv": [94, 100], "omit": [94, 109, 110, 111], "648": 94, "2648": 94, "28gib": 94, "71": 94, "26": 94, "475": 94, "9106": 94, "91gib": 94, "53": [94, 98], "503": 94, "434": 94, "43": 94, "94": [94, 109], "166": 94, "0774": 94, "663": 94, "443": 94, "44": [94, 101], "87": 94, "50": [94, 100, 101, 108, 109, 111, 112], "885": 94, "3233": 94, "643": 94, "442": 94, "66": [94, 98, 101], "76": 94, "613": 94, "6150": 94, "637": 94, "72": [94, 98], "6k": 94, "91gb": 94, "21x": [94, 98], "tl": 94, "dr": 94, "priorit": 94, "accur": [94, 100, 108], "stabil": 94, "cost": [94, 101], "slightli": [94, 103], "outlier": 94, "underflow": 94, "8xh100": 94, "box": [94, 100, 111], "toi": [94, 96, 101, 103, 111], "convert_to_float8_train": 94, "recurs": 94, "kind": [94, 109], "gemm": [94, 111, 112], "snippet": [94, 109, 110], "f": [94, 95, 97, 98, 100, 101, 103, 104, 109, 110], "float8_linear_util": 94, "float8_linear": 94, "torch_version_at_least_2_5": [94, 96], "greater": 94, "sampl": [94, 95, 109, 111, 112], "adamw": 94, "elig": 94, "divis": 94, "_": [94, 101, 104, 108, 109, 110, 111], "label": 94, "purpos": [94, 95, 103, 109], "fake_label": 94, "ones_lik": 94, "mse_loss": 94, "model_state_dict": 94, "state_dict": [94, 97, 109, 110], "optimizer_state_dict": 94, "pth": [94, 109, 110], "explor": [94, 96, 112], "few": [94, 103, 109, 110], "lai": 95, "stack": [95, 98], "awq": 95, "gptq": 95, "codebookquantizedtensor": 95, "float3": 95, "overload": [95, 100], "term": [95, 100, 109, 113], "extra": [95, 98], "dev": 95, "discuss": [95, 103], "1833": 95, "matter": [95, 100], "float3_e2_m0": 95, "float4_e2_m1": 95, "float4_e3_m0": 95, "float5_e2_m2": 95, "float5_e3_m1": 95, "float6_e2_m3": 95, "float6_e3_m2": 95, "float8_e5m2": 95, "float8_e4m3fnuz": 95, "float8_e5m2fnuz": 95, "float4": 95, "float6": 95, "becom": [95, 109], "uint2": 95, "117208": 95, "outsid": 95, "mention": [95, 109], "criteria": 95, "wide": 95, "adopt": 95, "fundament": [95, 100, 110], "until": 95, "evid": 95, "hopefulli": 95, "amen": 95, "haven": 95, "enough": 95, "ont": 95, "revisit": 95, "intx": 95, "connect": [95, 113], "int4tensor": 95, "previou": [95, 98, 109, 110, 111, 112], "between": [95, 100, 103, 104, 108, 110, 111, 113], "preicison": 95, "mainli": [95, 108, 111, 113], "accommod": 95, "choose_qparams_affine_with_min_max": 95, "min": [95, 101, 103, 109, 113], "int_matmul": 95, "int_scaled_matmul": 95, "reli": [95, 96, 100, 101, 103], "On": [95, 96], "glue": 95, "everyth": 95, "togeth": [95, 98, 109, 111, 113], "construct": [95, 109, 113], "low_precision_v": 95, "high_precision_v": 95, "procedur": 95, "veri": [95, 100, 104, 110], "straightforward": [95, 113], "high_preicsion_v": 95, "especi": [95, 97, 100, 111, 112], "bitwidth": [95, 113], "codebook": 95, "select": [95, 109], "multi": 95, "dimension": [95, 100], "view": [95, 103, 109, 110], "mkldnn": 95, "coo": [95, 100], "sparse_coo": [95, 100], "sparsetensorimpl": 95, "idea": [95, 100], "nice": [95, 100], "concept": [95, 107, 109, 111, 112, 113], "why": [95, 103, 107], "conflict": 95, "quantized_linear": [95, 101, 109], "semant": 95, "stai": [95, 96, 103, 111], "develop": [95, 96, 109, 110, 113], "tradition": 95, "to_affine_quant": 95, "simplic": 95, "explain": [95, 108, 111], "simplest": [95, 100], "easi": [95, 98], "linear_modul": 95, "to_affine_quantized_intx": 95, "to_linear_activation_quant": 95, "quantized_weight": [95, 104], "activation_and_weight_quant": 95, "encount": 95, "input_qunat_func": 95, "redispatch": 95, "fx": [95, 109, 113], "symbolic_trac": 95, "But": [95, 103, 104, 113], "easier": [95, 113], "modif": 95, "figur": [95, 100, 109], "At": [95, 100, 109], "thing": [95, 97, 100, 103, 109], "address": [95, 109], "stat": [95, 110], "averag": [95, 101, 109, 110], "calculate_qparam": [95, 101, 113], "affinequantizedminmaxobserv": [95, 101], "insert_observer_": 95, "observedlinear": [95, 101], "complic": [95, 100, 109], "done": [95, 103], "manner": 95, "autoround": 95, "multitensor": 95, "sure": [95, 98, 113], "describ": [95, 97, 100, 107, 109, 110], "todai": [95, 98], "low_bit_optim": 95, "quantized_train": 95, "progress": [95, 104], "lot": [95, 100], "walk": [95, 101, 103, 107, 108, 111], "_convert_weight_to_int4pack": 95, "tensorcoretiledaqttensorimpl": 95, "_quantized_linear_op": 95, "goe": 95, "_aqt_qlinear_dispatch_t": 95, "dispatch": 95, "explan": 95, "wint4": 95, "stabl": 96, "pip": [96, 98, 108, 109], "nightli": [96, 98], "index": [96, 98, 100, 112], "url": [96, 98, 112], "whl": [96, 98, 112], "cu121": 96, "major": 96, "entri": 96, "mutat": 96, "logic": [96, 103, 104], "toylinearmodel": [96, 97, 101], "linear2": [96, 97, 101, 103], "eval": [96, 97, 98, 101, 108, 110, 111, 112], "faster": [96, 100], "model_bf16": 96, "mix": [96, 98, 108, 111, 112], "tensor_impl_dtyp": 96, "roughli": [96, 100], "quarter": 96, "os": [96, 109, 110], "int4_model": 96, "pt": [96, 98], "bfloat16_model": 96, "int4_model_size_mb": 96, "getsiz": [96, 109, 110], "bfloat16_model_size_mb": 96, "2f": [96, 109, 110], "mb": [96, 97, 99, 106, 109, 110], "00": [96, 99, 106], "benchmark_model": 96, "temporari": 96, "workaround": [96, 104], "num_run": 96, "100": [96, 103, 109, 110], "_dynamo": [96, 103], "reset": [96, 109, 110], "bf16_time": 96, "int4_tim": 96, "time": [96, 100, 103, 107, 108, 109, 110], "3f": [96, 110], "ms": 96, "1fx": 96, "393": 96, "410": 96, "9x": 96, "recogn": [96, 113], "decis": 96, "pt2e": [96, 108, 109, 110, 111, 112], "fuse": [96, 100, 103, 110], "deleg": [96, 109], "x86inductorquant": [96, 111, 112], "quantize_pt2": [96, 108, 109, 110, 111, 112], "prepare_pt2": [96, 108, 109, 111, 112], "x86_inductor_quant": [96, 111], "get_default_x86_inductor_quantization_config": [96, 111], "float_model": [96, 103, 108, 109, 110, 111, 112], "data_load": [96, 109, 110, 111, 112], "no_grad": [96, 103, 108, 109, 110, 111, 112], "imag": [96, 108, 109, 110, 111, 112], "program": [96, 109, 110, 111, 113], "captur": [96, 109, 110, 113], "expos": [96, 109, 110], "set_glob": [96, 109, 110, 111, 112], "xiq": [96, 111], "prepare_qat_pt2": [96, 110, 111], "sample_inference_data": 96, "convert_pt2": [96, 108, 109, 110, 111, 112], "wrapper": [96, 103, 111], "_inductor": [96, 111], "cpp_wrapper": [96, 111], "optimized_model": [96, 108, 111, 112], "converted_model": [96, 111, 112], "xpu": [96, 112], "simpl": [96, 100, 101, 103, 108, 111, 112], "visit": 96, "would": [96, 100, 103, 110, 112], "forget": 96, "tempfil": 97, "get_model_size_in_byt": 97, "ref": [97, 109], "namedtemporaryfil": 97, "seek": [97, 100], "load": [97, 98, 104], "m_load": 97, "load_state_dict": [97, 109, 110], "assign": 97, "assert": [97, 101, 103, 104, 113], "equal": [97, 100], "float_weight1": 97, "float_weight2": 97, "quantized_weight1": 97, "quantized_weight2": 97, "go": [97, 103, 107, 113], "techinqu": 97, "reduct": [97, 98, 100, 103], "4x": [97, 98], "0625": 97, "reason": [97, 100], "avoid": [97, 100], "deploi": 98, "underli": [98, 103], "engin": 98, "seamlessli": [98, 103, 111, 112], "seamless": [98, 111], "git": 98, "cu126": 98, "acceler": [98, 100], "float8dynamicactivationfloat8weightconfig": 98, "phi": 98, "autotoken": 98, "model_id": 98, "microsoft": 98, "quant_config": 98, "quant_typ": [98, 104], "quantized_model": [98, 103, 108, 109, 110], "device_map": [98, 104], "torch_dtyp": [98, 104], "push": [98, 100, 104], "hub": [98, 104], "user_id": 98, "your_user_id": 98, "model_nam": [98, 108, 111, 112], "save_to": 98, "safe_seri": [98, 104], "hf": 98, "signific": [98, 100], "wheel": 98, "ai": 98, "hug": 98, "face": [98, 100, 109], "server": [98, 104], "o3": 98, "client": 98, "curl": 98, "localhost": 98, "8000": 98, "v1": 98, "chat": 98, "h": 98, "content": 98, "applic": 98, "messag": 98, "role": 98, "give": [98, 100, 103], "me": 98, "short": 98, "languag": 98, "temperatur": 98, "top_p": 98, "95": 98, "top_k": 98, "max_token": 98, "32768": 98, "vram": 98, "15x": 98, "2x": [98, 100], "littl": [98, 104], "packag": 98, "pipelin": 98, "random": [98, 100, 109, 110], "manual_se": [98, 109, 110], "model_path": 98, "trust_remote_cod": 98, "assist": 98, "eat": 98, "banana": 98, "dragonfruit": 98, "smoothi": 98, "blend": 98, "milk": 98, "honei": 98, "salad": 98, "slice": [98, 104], "lemon": 98, "juic": 98, "solv": [98, 100, 103], "equat": 98, "pipe": 98, "text": 98, "generation_arg": 98, "max_new_token": 98, "500": 98, "return_full_text": 98, "do_sampl": 98, "generated_text": 98, "finetun": 98, "lm_head": 98, "those": [98, 100, 101, 103], "ti": 98, "autoprocessor": 98, "modeling_util": 98, "find_tied_paramet": 98, "untied_model": 98, "getattr": [98, 104], "get_text_config": 98, "tie_word_embed": 98, "setattr": [98, 103], "_tied_weights_kei": 98, "clone": [98, 104], "save_to_local_path": 98, "int8dynamicactivationintxweightconfig": 98, "ve": [98, 100], "intxweightonlyconfig": 98, "modulefqntoconfig": [98, 104], "untied_model_id": 98, "untied_model_local_path": 98, "embedding_config": 98, "linear_config": 98, "weight_granular": 98, "weight_scale_dtyp": 98, "_default": [98, 104], "embed_token": 98, "include_embed": 98, "untie_embedding_weight": 98, "modules_to_not_convert": 98, "pte": 98, "cd": 98, "install_requir": 98, "phi_4_mini": 98, "convert_weight": 98, "pytorch_model": 98, "bin": 98, "pytorch_model_convert": 98, "export_llama": 98, "kv": 98, "use_sdpa_with_kv_cach": 98, "get_bos_id": 98, "199999": 98, "get_eos_id": 98, "200020": 98, "max_seq_length": 98, "max_context_length": 98, "output_nam": 98, "phi4": 98, "phone": 98, "io": 98, "2gb": 98, "iphon": 98, "pro": [98, 100], "17": 98, "sec": 98, "maintain": [98, 100], "test": [98, 107, 109, 111], "lm": 98, "har": 98, "eleutherai": 98, "lm_eval": 98, "model_arg": 98, "pretrain": [98, 100, 108, 109, 110, 111], "reset_peak_memory_stat": 98, "prompt": 98, "hei": 98, "consciou": 98, "templated_prompt": 98, "apply_chat_templ": 98, "add_generation_prompt": 98, "templat": [98, 99, 105, 106], "return_tensor": 98, "generated_id": 98, "output_text": 98, "batch_decod": 98, "skip_special_token": 98, "clean_up_tokenization_spac": 98, "respons": 98, "len": [98, 104, 109, 110, 113], "mem": [98, 99, 106], "max_memory_reserv": 98, "1e9": 98, "02f": 98, "gb": 98, "hello": 98, "ye": 98, "am": 98, "digit": 98, "70": [98, 101], "91": 98, "benchmark_lat": 98, "vllm_disable_compile_cach": 98, "project": 98, "vllm_use_precompil": 98, "sharegpt": 98, "wget": 98, "anon8231489123": 98, "sharegpt_vicuna_unfilt": 98, "resolv": 98, "sharegpt_v3_unfiltered_cleaned_split": 98, "tree": 98, "num": 98, "benchmark_serv": 98, "16x": 98, "1s": 98, "14x": 98, "num_prompt": 98, "req": 98, "57": [98, 101], "1000": [98, 111], "68": 98, "80": 98, "entir": [98, 109, 110], "ml": 98, "gain": [98, 100, 112], "eas": 98, "valid": [98, 104, 113], "trade": [98, 100], "off": [98, 100], "003": [99, 106, 107], "total": [99, 106, 107], "galleri": [99, 105, 107], "tutorials_sourc": 99, "template_tutori": [99, 106, 107], "neural": [100, 108, 111], "network": [100, 103, 108, 111], "latenc": 100, "carefulli": 100, "pai": 100, "low": [100, 103, 108], "price": 100, "f1": 100, "problem": [100, 103], "research": [100, 107], "fragment": 100, "rightfulli": 100, "spent": 100, "compress": [100, 108], "place": [100, 108, 109, 110, 111, 112], "dens": 100, "focu": [100, 103], "realli": 100, "concret": [100, 113], "hope": 100, "modular": 100, "scratch": [100, 107], "minim": [100, 108, 111, 112], "algorthim": 100, "realiz": 100, "theoret": 100, "analog": 100, "fix": [100, 101], "unstructur": 100, "close": 100, "relat": 100, "retrain": 100, "neglig": 100, "area": 100, "agre": 100, "upon": 100, "consensu": 100, "mind": 100, "thought": 100, "subproblem": 100, "satisfi": 100, "independ": 100, "frontend": [100, 111], "arbitrari": 100, "handoff": 100, "piec": 100, "natur": [100, 103, 109, 113], "present": 100, "clear": 100, "contract": 100, "7x": 100, "advantag": 100, "anticip": 100, "mani": [100, 103], "solut": 100, "third": 100, "parti": 100, "to_sparse_semi_structur": 100, "sparsesemistructuredtensor": 100, "weightnormsparsifi": 100, "half": 100, "subnetwork": 100, "sparse_config": 100, "named_modul": 100, "tensor_fqn": 100, "sparse_block_shap": 100, "zeros_per_block": 100, "fakespars": 100, "manipul": 100, "dictionari": 100, "paramer": 100, "parameter": 100, "necessari": [100, 101, 103, 108, 109, 110, 111, 112], "suitabl": [100, 111], "0s": 100, "spot": 100, "definit": [100, 104], "academia": 100, "industri": 100, "often": [100, 103], "interchang": 100, "confus": [100, 109], "distinct": 100, "behind": 100, "doesn": [100, 110, 113], "itself": [100, 103], "loos": 100, "speak": 100, "tightli": 100, "coupl": [100, 103], "csc": 100, "fbgemm": 100, "qnnpack": 100, "descript": [100, 108], "coordin": 100, "vector": [100, 111], "locat": 100, "bsr": 100, "sparse_bsr": 100, "except": [100, 103, 113], "scalar": [100, 109], "csr": 100, "sparse_csr": 100, "sparse_csc": 100, "column": 100, "compact": 100, "sparse_matrix": 100, "1d": 100, "indexptr": 100, "\u00bd": 100, "bitmask": 100, "2bit": 100, "unprun": 100, "quit": [100, 103], "broken": 100, "down": 100, "sensit": 100, "effect": [100, 101, 103, 111, 112, 113], "best": [100, 111], "subsequ": [100, 103, 111, 112], "infinit": 100, "lost": 100, "degre": 100, "drop": 100, "proxi": 100, "aforement": 100, "smallest": 100, "absolut": 100, "global": [100, 103], "scope": 100, "impli": 100, "con": 100, "span": 100, "threshold": 100, "constant": [100, 103, 109], "ctr_mobile_fe": 100, "score": 100, "w": [100, 104], "tenosr": 100, "udpat": 100, "histori": 100, "regrow": 100, "dw": 100, "via": [100, 108], "backprop": 100, "pat": 100, "unmask": 100, "resid": 100, "salienc": 100, "lowest": 100, "l1": 100, "abl": [100, 103, 104, 109, 113], "repeat": [100, 109, 110], "movement": 100, "2005": 100, "07683": 100, "rank": [100, 103], "wx": 100, "sqx": 100, "q": [100, 109], "usual": 100, "sort": 100, "wise": 100, "reconstruct": [100, 104], "randomli": 100, "tri": 100, "remedi": 100, "item": [100, 107], "ultim": [100, 101], "literatur": 100, "vision": 100, "nlp": [100, 107, 111], "iter": [100, 109, 110], "ctr_feed": 100, "na": 100, "multimask": 100, "pyspeech": 100, "fastna": 100, "approach": [100, 103, 108, 111, 112], "knowledg": [100, 107], "distil": 100, "pdf": 100, "2204": 100, "09656": 100, "arrang": 100, "recal": 100, "counterpart": 100, "slower": 100, "suffici": 100, "flexibl": [100, 103, 108, 111], "98": 100, "special": [100, 108, 109], "exhibit": 100, "penalti": 100, "expens": [100, 103], "dictat": 100, "characterist": 100, "highest": 100, "wouldn": [100, 103], "visual": 100, "fig": 100, "4x4": 100, "benchmak": 100, "fly": 101, "welcom": 101, "histogram": [101, 109], "act_ob": 101, "finfo": 101, "weight_ob": 101, "observed_input": 101, "observed_weight": 101, "cl": [101, 103, 104], "float_linear": 101, "observed_linear": 101, "_replace_with_custom_fn_if_matches_filt": 101, "insert_observers_": 101, "_is_linear": 101, "lambda": [101, 104], "replacement_fn": 101, "copied_act_ob": 101, "copied_weight_ob": 101, "popul": 101, "feed": 101, "simpler": [101, 109], "quantizedlinear": [101, 103], "isn": 101, "strictli": 101, "to_affine_quantized_intx_stat": 101, "act_scal": [101, 113], "act_zero_point": 101, "weight_scal": [101, 109, 113], "weight_zero_point": [101, 109], "qweight": 101, "qinput": 101, "from_observ": 101, "begin": [101, 103], "dataclass": [101, 104, 113], "transform_modul": [101, 104], "register_quantize_module_handl": [101, 104], "staticquantconfig": 101, "_apply_static_qu": 101, "is_observed_linear": 101, "optimizedmodul": 101, "_orig_mod": 101, "0237": 101, "plainaqttensorimpl": 101, "142": 101, "31": [101, 113], "113": 101, "157": 101, "59": 101, "160": 101, "150": 101, "67": 101, "241": 101, "238": 101, "235": 101, "228": 101, "255": [101, 113], "201": 101, "114": 101, "236": 101, "88": [101, 109], "83": 101, "109": 101, "209": 101, "92": 101, "184": 101, "141": 101, "110": 101, "0009": 101, "0010": 101, "130": 101, "122": 101, "132": 101, "125": 101, "126": 101, "129": 101, "127": [101, 103, 112, 113], "133": 101, "124": 101, "131": 101, "135": 101, "136": 101, "foundat": 103, "autograd": [103, 113], "interpos": 103, "namespac": 103, "continu": [103, 110, 111, 112, 113], "obviou": 103, "int8quantizedlinear": 103, "finer": 103, "intercept": 103, "contrast": 103, "clunki": 103, "distributedlinear": 103, "duplic": 103, "bypass": 103, "outer": 103, "inner": 103, "allgath": 103, "bandwidth": 103, "read": 103, "zoo": 103, "podcast": 103, "edward": 103, "yang": 103, "int8_symmetric_quant": 103, "fp32_tensor": 103, "amin": 103, "keepdim": [103, 109, 110], "amax": 103, "zeros_lik": 103, "clamp": [103, 109], "w_int8": 103, "new_linear": 103, "left": [103, 113], "toymodel": 103, "child": 103, "named_children": 103, "drawback": 103, "won": 103, "suppos": 103, "clean": 103, "eleg": 103, "pretti": 103, "power": [103, 104], "overrid": 103, "almost": 103, "shard": [103, 104], "ragged": 103, "rag": 103, "nestedtensor": 103, "who": 103, "link": [103, 107], "googl": 103, "collab": 103, "flopcount": 103, "memorytrack": 103, "With": [103, 109, 111, 113], "bare": 103, "bone": 103, "int8symmetrictensor": 103, "hold": 103, "staticmethod": 103, "__new__": [103, 104], "_make_wrapper_subclass": [103, 104], "storage_offset": 103, "ndim": 103, "__tensor_flatten__": [103, 104], "pt2": [103, 111], "__tensor_unflatten__": [103, 104], "tensor_data_dict": [103, 104], "extra_metadata": 103, "outer_s": [103, 104], "outer_strid": [103, 104], "undo": 103, "__repr__": 103, "repr": 103, "ahead": 103, "insid": 103, "int8_tensor": 103, "func": [103, 104], "op_implementations_dict": 103, "conveni": 103, "register_op": 103, "_op": 103, "opoverload": 103, "impl_decor": 103, "op_impl": 103, "particular": 103, "largest": 103, "tell": 103, "desugar": 103, "decor": [103, 104], "surfac": 103, "coverag": [103, 108, 109, 111, 112], "brute": 103, "forc": 103, "repeatedli": 103, "loggingtensor": 103, "_python_dispatch": [103, 104], "return_and_correct_alias": [103, 104], "int8_mm": 103, "detach": [103, 104], "int8_view_op": 103, "out_data": 103, "out_scal": [103, 109], "notic": 103, "hit": 103, "background": 103, "decomposit": 103, "live": 103, "decomp": 103, "shrink": 103, "author": [103, 107, 108, 109, 110, 111, 112, 113], "pain": 103, "rather": 103, "worth": 103, "written": 103, "differenti": 103, "nuanc": 103, "longer": [103, 109, 110], "That": 103, "transposit": 103, "got": [103, 109, 113], "propag": [103, 109, 111, 112], "fact": 103, "themselv": [103, 109], "pointwis": [103, 111, 112], "were": 103, "might": [103, 104, 109, 113], "unwrap": 103, "dim0": 103, "dim1": 103, "confirm": 103, "quantized_model_module_swap": 103, "quantized_model_subclass": 103, "subclass_param": 103, "out_module_swap": 103, "allclos": 103, "out_compil": 103, "seri": 103, "e2": 104, "_type": 104, "_data": 104, "capabl": [104, 109, 111], "self_attn": 104, "q_proj": 104, "k_proj": 104, "mlp": 104, "gate_proj": 104, "usernam": 104, "narrow": 104, "copy_": 104, "state": 104, "chunk": 104, "_apply_fn_to_data": 104, "heavi": 104, "codebas": 104, "fn": 104, "ctx": 104, "new_tensor": 104, "__class__": 104, "principl": 104, "torchaobasetensor": 104, "mynewquantconfig": 104, "classvar": 104, "myquantizedtensor": 104, "fbgemmfp8tensor": 104, "tensor_data_attr": 104, "tensor_attribut": 104, "attr": 104, "_to_copi": 104, "fill_default": 104, "notimplementederror": 104, "_my_quant_transform": 104, "my_quantization_funct": 104, "use_cutlass_kernel": 104, "my_cutlass_linear": 104, "use_triton_kernel": 104, "my_triton_linear": 104, "disappear": 104, "extrem": 104, "sole": 104, "think": 104, "world": 104, "explicitli": [104, 113], "spooki": 104, "distanc": 104, "statu": 104, "due": [104, 108, 113], "team": 104, "2338": 104, "creation": 104, "detect": 104, "illustr": 104, "tutorials_python": 105, "zip": [105, 107], "jupyt": [105, 107], "notebook": [105, 107], "tutorials_jupyt": 105, "sphinx": [105, 107], "firstnam": 107, "lastnam": 107, "prerequisit": [107, 109], "v2": 107, "topic": 107, "rand": [107, 109, 110], "0563": 107, "7933": 107, "8028": 107, "2865": 107, "6117": 107, "3251": 107, "8736": 107, "4532": 107, "2669": 107, "9802": 107, "9794": 107, "1774": 107, "0154": 107, "5692": 107, "2646": 107, "practic": 107, "summar": 107, "takeawai": 107, "link1": 107, "link2": 107, "minut": 107, "ipynb": 107, "daniil": 108, "lyakhov": 108, "aamir": 108, "nazir": 108, "alexand": 108, "suslov": 108, "yamini": 108, "nimmagadda": 108, "kozlov": 108, "subject": [108, 110], "openvinoquant": 108, "unlock": 108, "placement": 108, "simplifi": [108, 109, 111, 112], "ux": [108, 109, 111], "torchdynamo": [108, 111, 112, 113], "eager": [108, 109, 110, 111, 112, 113], "mechan": [108, 111, 112], "torchvis": [108, 109, 110, 111, 112, 113], "resnet18": [108, 109, 110, 111, 112], "u": 108, "__dict__": [108, 109, 110, 111, 112], "dummi": [108, 111, 112], "traced_b": [108, 111, 112], "exported_model": [108, 109, 110, 111, 112], "preset": 108, "elu": 108, "prelu": 108, "gelu": 108, "quantizationpreset": 108, "bert": [108, 111], "modeltyp": 108, "ignored_scop": 108, "exclud": 108, "layer_1": 108, "layer_2": 108, "layer_3": 108, "ignoredscop": 108, "conv2d": [108, 109, 110, 111, 112, 113], "regex": 108, "layer_": 108, "subgraph": [108, 110], "node": [108, 110, 111, 112, 113], "target_devic": 108, "taken": 108, "account": 108, "cpu_spr": 108, "npu": 108, "targetdevic": 108, "fold": [108, 109, 111, 112], "batchnorm": [108, 109, 110, 111, 112], "preced": [108, 109, 111, 112], "prepared_model": [108, 109, 110, 111, 112], "fold_quant": 108, "finish": [108, 111], "comparison": 108, "biascorrect": 108, "discrep": 108, "calibration_load": 108, "dataload": [108, 109, 110], "transform_fn": 108, "data_item": 108, "calibration_dataset": 108, "smooth_quant": 108, "fast_bias_correct": 108, "deploy": [108, 111], "jerri": [109, 111, 113], "zhang": [109, 111, 112, 113], "_export": [109, 110, 111], "14k": 109, "programm": [109, 111, 112], "db": 109, "xnnpack": [109, 110, 113], "xnnpack_quant": [109, 110], "get_symmetric_quantization_config": [109, 110], "xnnpackquant": [109, 110, 113], "prior": 109, "qconfigmap": [109, 113], "backendconfig": [109, 113], "rel": 109, "intent": [109, 113], "qconfig": [109, 113], "3d": [109, 113], "incompat": 109, "great": 109, "ideal": 109, "fake_qu": 109, "hidden": 109, "summari": 109, "thu": 109, "queri": [109, 113], "previous": 109, "embedding_byt": 109, "executorchquant": 109, "concaten": 109, "prone": 109, "cleaner": 109, "composed_quant": 109, "quantization_cap": 109, "concern": 109, "decoupl": 109, "minmax": 109, "freed": 109, "identitc": 109, "imagenet": [109, 110], "unzip": [109, 110], "data_path": [109, 110], "resnet18_pretrained_float": [109, 110], "sy": [109, 110], "numpi": [109, 110], "np": [109, 110], "resnet": [109, 110, 111], "warn": [109, 110], "filterwarn": [109, 110], "categori": [109, 110], "deprecationwarn": [109, 110], "r": [109, 110], "seed": [109, 110], "191009": [109, 110], "averagemet": [109, 110], "fmt": [109, 110], "val": [109, 110], "avg": [109, 110], "count": [109, 110], "__str__": [109, 110], "fmtstr": [109, 110], "topk": [109, 110], "predict": [109, 110], "maxk": [109, 110], "pred": [109, 110], "eq": [109, 110], "expand_a": [109, 110], "correct_k": [109, 110], "reshap": [109, 110], "mul_": [109, 110], "criterion": [109, 110], "top1": [109, 110], "top5": [109, 110], "cnt": [109, 110], "acc1": [109, 110], "acc5": [109, 110], "load_model": [109, 110], "model_fil": [109, 110], "weights_onli": [109, 110], "print_size_of_model": [109, 110], "temp": [109, 110], "p": [109, 110], "1e6": [109, 110], "prepare_data_load": [109, 110], "485": [109, 110], "456": [109, 110], "std": [109, 110], "229": [109, 110], "225": [109, 110], "randomresizedcrop": [109, 110], "randomhorizontalflip": [109, 110], "totensor": [109, 110], "dataset_test": [109, 110], "resiz": [109, 110], "centercrop": [109, 110], "train_sampl": [109, 110], "randomsampl": [109, 110], "test_sampl": [109, 110], "sequentialsampl": [109, 110], "train_batch_s": [109, 110], "sampler": [109, 110], "data_loader_test": [109, 110, 111, 112], "eval_batch_s": [109, 110], "saved_model_dir": [109, 110], "float_model_fil": [109, 110], "model_to_quant": [109, 110], "capture_pre_autograd_graph": [109, 110, 111], "dynamic_shap": [109, 110], "export_for_train": 109, "dynamic_dim": [109, 110], "constraint": [109, 110, 113], "qconfig_opt": 109, "set_object_typ": 109, "set_module_nam": 109, "workload": 109, "themodel": 109, "feedback": 109, "dq": 109, "fp32_op": 109, "qauntiz": 109, "x_int8": 109, "x_scale": 109, "x_zero_point": 109, "weight_int8": 109, "bias_fp32": 109, "output_scal": 109, "output_zero_point": 109, "x_fp32": 109, "quantized_decompos": 109, "dequantize_per_tensor": 109, "x_i8": 109, "x_quant_min": 109, "x_quant_max": 109, "weight_fp32": 109, "weight_i8": 109, "weight_quant_min": 109, "weight_quant_max": 109, "weight_permut": 109, "permute_copi": 109, "out_fp32": 109, "addmm": 109, "out_i8": 109, "quantize_per_tensor": 109, "out_zero_point": 109, "out_quant_min": 109, "out_quant_max": 109, "float32_op": 109, "decompos": 109, "use_reference_represent": 109, "x_int16": 109, "weight_int16": 109, "acc_int32": 109, "out_dtyp": 109, "bias_scal": 109, "bias_int32": 109, "div": 109, "mul": 109, "out_int8": 109, "qmin": 109, "qmax": 109, "date": 109, "unus": 109, "serila": 109, "consult": 109, "exportedprogram": 109, "pt2e_quantized_model_file_path": 109, "resnet18_pt2e_quant": 109, "quantized_ep": 109, "loaded_quantized_ep": 109, "loaded_quantized_model": 109, "diff": 109, "79": 109, "82": 109, "55": 109, "edg": [109, 113], "went": 109, "andrew": 110, "Or": 110, "move_exported_model_to_ev": [110, 111], "correctli": 110, "certain": 110, "dropout": 110, "move_exported_model_to_train": 110, "jit": 110, "recursivescriptmodul": 110, "train_one_epoch": 110, "ntrain_batch": 110, "avgloss": 110, "5f": 110, "start_tim": 110, "global_avg": 110, "is_qat": [110, 111], "fusion": 110, "batchnorm2d": 110, "_native_batch_norm_legit": 110, "cudnn_batch_norm": 110, "mobilenetv2": 110, "recompil": 110, "consolid": 110, "epoch": 110, "far": 110, "num_epoch": 110, "num_train_batch": 110, "num_eval_batch": 110, "num_observer_update_epoch": 110, "num_batch_norm_update_epoch": 110, "num_epochs_between_ev": 110, "nepoch": 110, "subseq": 110, "disable_observ": 110, "bn": 110, "running_mean": 110, "running_var": 110, "new_arg": 110, "wish": 110, "prepared_model_copi": 110, "neval_batch": 110, "paus": 110, "resum": 110, "fail": [110, 113], "checkpoint_path": 110, "checkpoint_": 110, "behav": 110, "incorrectli": 110, "lesli": [111, 113], "fang": [111, 113], "weiwen": [111, 113], "xia": [111, 113], "jiong": [111, 113], "gong": [111, 113], "cnn": 111, "rnn": 111, "outstand": 111, "fourth": 111, "spr": 111, "xeon": 111, "processor": 111, "boost": 111, "contigu": [111, 112], "channels_last": [111, 112], "onednn": [111, 112], "assum": [111, 113], "word": 111, "satur": 111, "pure": 111, "dedic": 111, "scenario": [111, 112], "plai": [111, 112], "convolut": [111, 112, 113], "absenc": [111, 112], "enhanc": [111, 112], "mirror": [111, 112], "autocast": [111, 112], "context": [111, 112], "device_typ": [111, 112], "turn": [111, 112], "cpp": 111, "qconvolut": [111, 112], "qlinear": [111, 112], "presenc": [111, 112], "pair": [111, 112], "remain": [111, 112], "conting": [111, 112], "qmaxpool2d": [111, 112], "torchinductor_freez": [111, 112], "example_x86inductorquantizer_pytorch_2_1": 111, "torchbench": 111, "measur": 111, "proven": 111, "depth": 111, "shoud": 111, "example_x86inductorquantizer_qat": 111, "yan": 112, "zhiwei": 112, "wang": 112, "eikan": 112, "liangang": 112, "liu": 112, "river": 112, "cui": 112, "yifeng": 112, "xpuinductorquant": 112, "pip3": 112, "torchaudio": 112, "xpu_inductor_quantizer_exampl": 112, "xpu_inductor_quant": 112, "xpuiq": 112, "resnet18_weight": 112, "get_default_xpu_inductor_quantization_config": 112, "sign": 112, "wherea": 112, "histogramobserv": [112, 113], "perchannelminmaxobserv": 112, "quantizationspec": [112, 113], "quantizationconfig": [112, 113], "type_check": 112, "observerorfakequantizeconstructor": 112, "get_xpu_inductor_symm_quantization_config": 112, "extra_arg": 112, "act_observer_or_fake_quant_ctr": 112, "act_quantization_spec": [112, 113], "qscheme": [112, 113], "per_tensor_symmetr": [112, 113], "observer_or_fake_quant_ctr": [112, 113], "with_arg": [112, 113], "weight_observer_or_fake_quant_ctr": 112, "weight_quantization_spec": [112, 113], "per_channel_symmetr": 112, "ch_axi": 112, "oc": 112, "ic": 112, "kh": 112, "kw": 112, "conv": [112, 113], "bias_quantization_spec": 112, "amp": 112, "indcutor": 112, "kimish": 113, "patel": 113, "made": 113, "explicit": 113, "quantiat": 113, "encod": 113, "convei": 113, "quantizationannot": 113, "furthermor": 113, "minmaxobserv": 113, "input_qspec_map": 113, "output_qspec": 113, "_annot": 113, "conclud": 113, "matcher": 113, "get_source_partit": 113, "add_partit": 113, "gm": 113, "itertool": 113, "chain": 113, "add_nod": 113, "output_nod": 113, "per_tensor_affin": 113, "input_act_qspec": 113, "output_act_qspec": 113, "input_act0": 113, "input_act1": 113, "quantization_annot": 113, "substitut": 113, "among": 113, "sharedquantizationspec": 113, "maxpool": 113, "average_pool": 113, "concat": 113, "edgeornod": 113, "transit": 113, "spec": 113, "conv1": 113, "conv2": 113, "fed": 113, "cat": 113, "conv1_out": 113, "conv2_out": 113, "qspec1": 113, "cat_input0": 113, "cat_input1": 113, "therefor": 113, "ob": 113, "consum": 113, "rewrit": 113, "share_qparams_with_input_act0_qspec": 113, "known": 113, "beforehand": 113, "sigmoid": 113, "fixedqparamsquantizationspec": 113, "act_qspec": 113, "sigmoid_nod": 113, "input_act": 113, "derivedquantizationspec": 113, "derive_qparams_fn": 113, "observerorfakequant": 113, "observerbas": 113, "fakequantizebas": 113, "heurist": 113, "obejct": 113, "obs_or_fq": 113, "fq": 113, "act_obs_or_fq": 113, "weight_obs_or_fq": 113, "act_zp": 113, "weight_zp": 113, "bias_qspec": 113, "derived_from": 113, "backendquant": 113, "get_input_act_qspec": 113, "get_output_act_qspec": 113, "get_weight_qspec": 113, "get_bias_qspec": 113, "intermedi": 113, "call_funct": 113, "relu_": 113, "relu_nod": 113, "maybe_conv_nod": 113, "conv1d": 113, "unexpect": 113, "recognz": 113, "subgraphmatch": 113, "conv_relu_pattern": 113, "name_node_map": 113, "input_nod": 113, "weight_nod": 113, "bias_nod": 113, "caveat": 113, "exhaust": 113, "2d": 113, "4d": 113, "symbol": 113, "outcom": 113}, "objects": {"torchao.dtypes": [[12, 0, 1, "", "AffineQuantizedTensor"], [13, 0, 1, "", "BlockSparseLayout"], [14, 0, 1, "", "CutlassInt4PackedLayout"], [15, 0, 1, "", "CutlassSemiSparseLayout"], [16, 0, 1, "", "Float8Layout"], [17, 0, 1, "", "Int4CPULayout"], [18, 0, 1, "", "Layout"], [19, 0, 1, "", "MarlinQQQLayout"], [20, 0, 1, "", "MarlinQQQTensor"], [21, 0, 1, "", "MarlinSparseLayout"], [22, 0, 1, "", "NF4Tensor"], [23, 0, 1, "", "PlainLayout"], [24, 0, 1, "", "SemiSparseLayout"], [25, 0, 1, "", "TensorCoreTiledLayout"], [26, 0, 1, "", "UintxLayout"], [27, 2, 1, "", "to_affine_quantized_floatx"], [28, 2, 1, "", "to_affine_quantized_floatx_static"], [29, 2, 1, "", "to_affine_quantized_fpx"], [30, 2, 1, "", "to_affine_quantized_intx"], [31, 2, 1, "", "to_affine_quantized_intx_static"], [32, 2, 1, "", "to_marlinqqq_quantized_intx"], [33, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[12, 1, 1, "", "dequantize"], [12, 1, 1, "", "from_hp_to_floatx"], [12, 1, 1, "", "from_hp_to_floatx_static"], [12, 1, 1, "", "from_hp_to_fpx"], [12, 1, 1, "", "from_hp_to_intx"], [12, 1, 1, "", "from_hp_to_intx_static"], [12, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[20, 1, 1, "", "dequantize"], [20, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[21, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[22, 1, 1, "", "convert_to_norm_float_weight"], [22, 1, 1, "", "dequantize"], [22, 1, 1, "", "dequantize_scalers"], [22, 1, 1, "", "double_quantize_scalers"], [22, 1, 1, "", "get_original_weight"], [22, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[34, 0, 1, "", "CastConfig"], [35, 0, 1, "", "Float8LinearConfig"], [36, 0, 1, "", "ScalingGranularity"], [37, 0, 1, "", "ScalingType"], [38, 2, 1, "", "convert_to_float8_training"], [39, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[35, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[40, 0, 1, "", "FPXWeightOnlyConfig"], [41, 0, 1, "", "Float8ActivationInt4WeightConfig"], [42, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [43, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [44, 0, 1, "", "Float8WeightOnlyConfig"], [45, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [46, 0, 1, "", "Int4WeightOnlyConfig"], [47, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [48, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [49, 0, 1, "", "Int8WeightOnlyConfig"], [50, 0, 1, "", "MappingType"], [51, 0, 1, "", "TorchAODType"], [52, 0, 1, "", "UIntXWeightOnlyConfig"], [53, 0, 1, "", "ZeroPointDomain"], [54, 2, 1, "", "autoquant"], [55, 2, 1, "", "choose_qparams_affine"], [56, 2, 1, "", "choose_qparams_affine_with_min_max"], [57, 2, 1, "", "dequantize_affine"], [58, 2, 1, "", "int_scaled_matmul"], [81, 2, 1, "", "quantize_"], [82, 2, 1, "", "quantize_affine"], [83, 2, 1, "", "safe_int_mm"], [84, 2, 1, "", "smooth_fq_linear_to_inference"], [85, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [86, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[59, 0, 1, "", "ComposableQATQuantizer"], [60, 0, 1, "", "FakeQuantizeConfigBase"], [61, 0, 1, "", "FakeQuantizedEmbedding"], [62, 0, 1, "", "FakeQuantizedLinear"], [63, 0, 1, "", "FakeQuantizerBase"], [64, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [65, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [66, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [67, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [68, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [69, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [70, 0, 1, "", "IntxFakeQuantizeConfig"], [71, 0, 1, "", "IntxFakeQuantizer"], [72, 0, 1, "", "QATConfig"], [73, 0, 1, "", "QATStep"], [76, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[61, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[62, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[64, 1, 1, "", "prepare"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[66, 1, 1, "", "convert"], [66, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[70, 3, 1, "", "group_size"], [70, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[71, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[74, 0, 1, "", "Int4WeightOnlyEmbedding"], [75, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[74, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[77, 0, 1, "", "Int4WeightOnlyQATLinear"], [78, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [79, 2, 1, "", "disable_linear_fake_quant"], [80, 2, 1, "", "enable_linear_fake_quant"]], "torchao": [[6, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[87, 0, 1, "", "PerChannelNormObserver"], [88, 0, 1, "", "WandaSparsifier"], [89, 2, 1, "", "apply_fake_sparsity"], [90, 5, 1, "", "semi_sparse_weight"], [91, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[87, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[88, 1, 1, "", "prepare"], [88, 1, 1, "", "squash_mask"], [88, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:module", "5": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "module", "Python module"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 9, 11, 92, 94, 95, 104], "dtype": [0, 10, 95], "layout": [0, 9, 18, 95], "tensor": [0, 9, 95, 102, 103, 104, 113], "subclass": [0, 9, 95, 103, 104], "quantiz": [0, 4, 5, 11, 81, 92, 95, 96, 98, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113], "techniqu": 0, "float8": [1, 11, 94], "main": [1, 4, 5], "train": [1, 11, 94, 95, 98, 108, 109, 110, 111, 112], "api": [1, 2, 4, 5, 7, 11, 92, 94, 113], "other": [1, 5, 9, 95], "type": 1, "refer": [2, 92], "python": 2, "kernel": [3, 9, 93, 95, 104], "qat": [4, 11, 110], "config": 4, "quantize_": [4, 5], "custom": [4, 9], "legaci": 4, "prototyp": 4, "infer": [5, 98], "primit": [5, 95], "sparsiti": [6, 100], "benchmark": [7, 8, 9, 98], "guid": [7, 8, 9, 96, 104], "add": [7, 95, 104], "an": [7, 97], "recip": [7, 94], "model": [7, 9, 94, 95, 97, 98, 104, 108, 109, 110], "design": [7, 100], "consider": 7, "hf": 7, "ci": 7, "dashboard": 7, "1": [7, 11, 94, 98, 104, 108, 111, 112, 113], "modifi": 7, "exist": 7, "configur": [7, 100, 104, 109, 110], "2": [7, 11, 96, 98, 104, 108, 109, 110, 111, 112, 113], "run": 7, "3": [7, 11, 98, 104, 108, 111, 112, 113], "output": [7, 103], "format": 7, "4": [7, 108, 113], "integr": [7, 11, 95, 104], "pipelin": 7, "troubleshoot": 7, "test": [7, 9], "common": [7, 113], "issu": 7, "best": 7, "practic": 7, "user": 8, "contributor": 9, "gener": 9, "extend": 9, "ad": [9, 95, 104], "effici": [9, 95], "triton": 9, "hand": 9, "written": 9, "dispatch": [9, 104], "tensorimpl": [9, 95], "flow": [9, 95, 97, 104, 113], "us": [9, 113], "torch": [9, 108, 109, 110], "compil": [9, 104, 108], "perform": [9, 93, 98, 109], "serial": [9, 97, 104], "featur": 9, "support": [9, 95, 104], "function": [9, 95, 109, 110], "compos": 9, "microbenchmark": 9, "eval": [9, 109], "part": [11, 94, 98], "fine": 11, "tune": 11, "qlora": 11, "awar": [11, 95, 110, 111], "option": [11, 98, 107, 108], "torchtun": 11, "axolotl": 11, "low": [11, 95], "rank": 11, "adapt": 11, "huggingfac": [11, 98, 104], "peft": 11, "affinequantizedtensor": 12, "blocksparselayout": 13, "cutlassint4packedlayout": 14, "cutlasssemisparselayout": 15, "float8layout": 16, "int4cpulayout": 17, "marlinqqqlayout": 19, "marlinqqqtensor": 20, "marlinsparselayout": 21, "nf4tensor": 22, "plainlayout": 23, "semisparselayout": 24, "tensorcoretiledlayout": 25, "uintxlayout": 26, "to_affine_quantized_floatx": 27, "to_affine_quantized_floatx_stat": 28, "to_affine_quantized_fpx": 29, "to_affine_quantized_intx": 30, "to_affine_quantized_intx_stat": 31, "to_marlinqqq_quantized_intx": 32, "to_nf4": 33, "castconfig": 34, "float8linearconfig": 35, "scalinggranular": 36, "scalingtyp": 37, "convert_to_float8_train": 38, "precompute_float8_dynamic_scale_for_fsdp": 39, "fpxweightonlyconfig": 40, "float8activationint4weightconfig": 41, "float8dynamicactivationfloat8weightconfig": 42, "float8staticactivationfloat8weightconfig": 43, "float8weightonlyconfig": 44, "gemliteuintxweightonlyconfig": 45, "int4weightonlyconfig": 46, "int8dynamicactivationint4weightconfig": 47, "int8dynamicactivationint8weightconfig": 48, "int8weightonlyconfig": 49, "mappingtyp": 50, "torchaodtyp": 51, "uintxweightonlyconfig": 52, "zeropointdomain": 53, "autoqu": 54, "choose_qparams_affin": 55, "choose_qparams_affine_with_min_max": 56, "dequantize_affin": 57, "int_scaled_matmul": 58, "composableqatquant": 59, "fakequantizeconfigbas": 60, "fakequantizedembed": 61, "fakequantizedlinear": 62, "fakequantizerbas": 63, "float8actint4weightqatquant": 64, "fromintxquantizationawaretrainingconfig": 65, "int4weightonlyembeddingqatquant": 66, "int4weightonlyqatquant": 67, "int8dynactint4weightqatquant": 68, "intxquantizationawaretrainingconfig": 69, "intxfakequantizeconfig": 70, "intxfakequant": 71, "qatconfig": 72, "qatstep": 73, "int4weightonlyembed": 74, "int4weightonlyqatembed": 75, "initialize_fake_quant": 76, "int4weightonlyqatlinear": 77, "int8dynactint4weightqatlinear": 78, "disable_linear_fake_qu": 79, "enable_linear_fake_qu": 80, "quantize_affin": 82, "safe_int_mm": 83, "smooth_fq_linear_to_infer": 84, "swap_linear_with_smooth_fq_linear": 85, "to_linear_activation_quant": 86, "perchannelnormobserv": 87, "wandasparsifi": 88, "apply_fake_spars": 89, "semi_sparse_weight": 90, "sparsifi": 91, "welcom": 92, "document": 92, "get": 92, "start": [92, 96], "develop": 92, "note": [92, 94, 113], "eager": 92, "tutori": [92, 107], "pt2e": [92, 113], "pre": 94, "torchtitan": 94, "prerequisit": [94, 108, 111, 112, 113], "rowwis": 94, "scale": 94, "tensorwis": 94, "pick": 94, "import": [94, 109, 110], "directli": [94, 113], "convers": 94, "overview": [95, 100, 107], "basic": 95, "current": 95, "placehold": 95, "pytorch": [95, 96, 108, 109, 110, 111, 112, 113], "implement": [95, 103, 104], "oper": [95, 103, 104, 113], "nativ": 95, "factori": 95, "op": 95, "deriv": [95, 113], "algorithm": 95, "weight": [95, 98], "onli": 95, "dynam": 95, "activ": 95, "static": [95, 101], "insert": 95, "observ": 95, "how": [95, 109, 110, 113], "defin": [95, 109, 110], "modul": [95, 103, 104], "calibr": [95, 101, 109], "bit": 95, "optim": [95, 97, 98], "case": 95, "studi": 95, "int4": 95, "work": 95, "dure": 95, "execut": 95, "save": [95, 109, 110], "load": [95, 109, 110], "quick": 96, "first": 96, "exampl": [96, 104, 113], "export": [96, 98, 108, 109, 110, 111, 112, 113], "next": [96, 103], "step": [96, 98, 103, 104, 107], "deseri": 97, "what": [97, 103], "happen": 97, "when": 97, "serv": [98, 104], "vllm": [98, 104], "sglang": 98, "executorch": 98, "post": [98, 108, 109, 111, 112], "transform": [98, 104], "mobil": 98, "deploy": 98, "unti": 98, "embed": 98, "creat": [98, 104], "characterist": 98, "evalu": [98, 109], "qualiti": 98, "assess": 98, "memori": 98, "latenc": 98, "result": 98, "h100": 98, "machin": 98, "conclus": [98, 107, 108, 109, 110, 111, 112, 113], "comput": [99, 106], "time": [99, 106], "goal": 100, "context": 100, "prune": 100, "criteria": 100, "strategi": 100, "pattern": [100, 113], "phase": 101, "write": [102, 103, 113], "your": [102, 103, 104], "own": [102, 103], "advanc": 102, "ar": 103, "swap": 103, "which": 103, "should": 103, "we": 103, "compar": 103, "architectur": 104, "usag": 104, "system": 104, "class": 104, "level": 104, "new": 104, "method": 104, "minim": 104, "requir": 104, "compat": 104, "why": 104, "regist": 104, "s": 104, "kei": 104, "detail": 104, "hardwar": 104, "specif": [104, 109, 110], "linear": 104, "benefit": 104, "trade": 104, "off": 104, "share": [104, 113], "safetensor": 104, "diagram": 104, "high": 104, "point": 104, "bring": 104, "extern": 104, "templat": 107, "addit": 107, "exercis": 107, "further": 107, "read": 107, "openvino": 108, "backend": [108, 109, 110, 111, 112], "introduct": [108, 111, 112, 113], "nncf": 108, "instal": 108, "captur": [108, 111, 112], "fx": [108, 111, 112], "graph": [108, 111, 112], "appli": [108, 111, 112], "lower": [108, 109, 111, 112], "represent": 108, "improv": 108, "metric": 108, "motiv": [109, 113], "helper": [109, 110], "prepar": [109, 110], "dataset": [109, 110], "set": 109, "mode": 109, "convert": [109, 110], "check": 109, "size": 109, "accuraci": 109, "debug": 109, "loop": 110, "checkpoint": 110, "x86": 111, "through": [111, 112], "inductor": [111, 112], "intel": 112, "gpu": 112, "annot": 113, "param": 113, "fix": 113, "paramet": 113, "5": 113, "A": 113, "toi": 113, "resnet18": 113, "ir": 113, "problem": 113, "match": 113, "aten": 113, "recommend": 113, "subgraphmatcherwithnamenodemap": 113}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})