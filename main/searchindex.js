Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 20, 21, 22, 23, 25, 38, 41, 44, 45, 46, 47, 48, 50, 51, 52, 56, 61, 62, 67, 69, 71, 72, 74, 75, 78, 81, 82, 83, 85, 86, 87, 89, 90, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113], "section": [2, 10, 94, 99, 104, 109, 110, 113], "introduc": [2, 12, 108, 109, 111, 112, 113], "dive": 2, "detail": [2, 8, 10, 12, 44, 93, 94, 95, 97, 99, 100, 102, 108, 109, 110, 111], "how": [2, 4, 10, 12, 13, 17, 25, 42, 46, 48, 50, 67, 79, 80, 83, 91, 93, 95, 96, 97, 99, 100, 102, 103, 104, 108, 111, 112], "integr": [2, 10, 91, 93, 96, 97, 99, 102, 111, 113], "pytorch": [2, 8, 12, 13, 16, 19, 49, 67, 91, 93, 94, 97, 99, 102, 104, 107], "optim": [2, 10, 12, 20, 38, 78, 91, 93, 99, 102, 108, 110, 111, 112], "your": [2, 8, 10, 12, 91, 93, 94, 95, 97, 99, 103, 109, 110, 111, 112, 113], "machin": [2, 110], "learn": [2, 67, 95, 99, 107, 109, 111, 112, 113], "model": [2, 12, 38, 45, 54, 59, 62, 63, 64, 65, 66, 69, 73, 78, 86, 87, 89, 95, 99, 100, 102, 111, 112, 113], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 39, 40, 41, 43, 49, 50, 51, 52, 56, 57, 59, 60, 63, 64, 65, 67, 71, 72, 74, 75, 82, 83, 89, 91, 93, 95, 96, 97, 100, 102, 103, 104, 109, 111, 112, 113], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 26, 29, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 89, 93, 96, 99], "sparsiti": [2, 8, 12, 14, 20, 23, 85, 86, 87, 88, 89, 91, 93, 96, 97], "tba": [3, 11, 92], "For": [4, 8, 10, 12, 13, 44, 67, 94, 95, 96, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "full": [4, 12, 95, 100, 103, 107, 108, 110], "exampl": [4, 8, 10, 12, 13, 38, 48, 54, 56, 57, 62, 66, 67, 69, 73, 78, 79, 86, 89, 90, 94, 96, 97, 98, 99, 100, 102, 105, 106, 107, 108, 109, 110, 111, 112], "us": [4, 8, 9, 12, 13, 15, 16, 17, 20, 21, 22, 25, 27, 30, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 59, 62, 66, 67, 69, 74, 75, 79, 80, 83, 86, 90, 91, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112], "our": [4, 10, 12, 21, 93, 95, 97, 99, 100, 102, 109, 110], "pleas": [4, 9, 10, 12, 13, 19, 62, 66, 91, 94, 95, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "refer": [4, 8, 12, 13, 69, 75, 93, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111], "readm": [4, 8, 12, 91, 95, 99], "tutori": [8, 10, 12, 13, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113], "you": [8, 9, 10, 12, 67, 86, 90, 93, 94, 95, 96, 97, 99, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113], "through": [8, 10, 12, 51, 56, 57, 91, 94, 95, 97, 100, 102, 104, 107, 108, 109, 113], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 99, 100, 102, 103, 108, 109, 110, 111, 112], "framework": [8, 10, 12, 93, 97, 108], "The": [8, 10, 12, 13, 17, 20, 25, 37, 39, 41, 43, 53, 69, 78, 84, 86, 93, 94, 95, 96, 97, 99, 102, 103, 104, 108, 109, 110, 111, 112, 113], "contain": [8, 81, 82, 99, 102, 110, 113], "new": [8, 12, 13, 90, 93, 94, 100, 102, 109, 110, 111, 113], "architectur": [8, 91, 97, 99, 108, 109, 111, 112], "micro": 8, "current": [8, 41, 44, 45, 59, 60, 69, 78, 86, 89, 93, 94, 95, 99, 102, 103, 104, 109, 110, 112], "support": [8, 12, 13, 28, 41, 42, 44, 45, 59, 66, 67, 69, 81, 82, 89, 93, 94, 95, 96, 97, 99, 102, 108, 109, 110, 111, 112, 113], "which": [8, 10, 12, 19, 25, 69, 74, 93, 94, 96, 97, 99, 100, 104, 108, 109, 110, 111, 112, 113], "can": [8, 10, 12, 13, 24, 41, 48, 54, 67, 78, 79, 83, 90, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "quantize_": [8, 10, 12, 62, 66, 69, 78, 79, 80, 81, 82, 89, 91, 94, 95, 96, 97, 100], "sparsity_": 8, "function": [8, 12, 13, 24, 37, 56, 61, 71, 76, 77, 78, 85, 86, 87, 89, 90, 93, 94, 95, 96, 99, 100, 102, 104, 108, 113], "To": [8, 10, 12, 13, 19, 75, 93, 94, 95, 96, 97, 99, 100, 104, 109, 110, 111, 113], "correspond": [8, 12, 62, 69, 78, 94, 96, 99, 102, 112, 113], "string": [8, 34, 67, 86, 90], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 90, 91, 94, 95, 96, 102, 104, 108, 109, 110, 111, 112, 113], "py": [8, 10, 13, 19, 90, 98, 106, 107, 111, 112], "def": [8, 10, 12, 81, 89, 90, 93, 94, 95, 96, 100, 102, 104, 108, 109, 110, 111, 112, 113], "option": [8, 10, 13, 15, 19, 26, 29, 30, 31, 33, 34, 37, 41, 44, 46, 47, 50, 51, 52, 56, 57, 59, 60, 64, 66, 67, 69, 71, 72, 78, 79, 83, 86, 89, 90, 93, 94, 95, 103, 104, 109, 110, 111, 112, 113], "str": [8, 34, 37, 67, 69, 78, 86, 89, 90, 93, 102, 104, 112], "kwarg": [8, 10, 13, 56, 57, 58, 59, 63, 67, 72, 82, 85, 86, 87, 90, 94, 102, 104], "aobaseconfig": [8, 69, 78, 89, 100, 104], "code": [8, 10, 93, 94, 95, 97, 99, 100, 102, 105, 107, 109, 110, 111, 112, 113], "elif": [8, 104], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 37, 41, 46, 47, 53, 66, 67, 69, 84, 86, 90, 94, 97, 99, 102, 109, 110], "addit": [8, 12, 17, 22, 90, 93, 94, 99, 102, 103, 108, 109, 112, 113], "inform": [8, 13, 41, 94, 97, 99, 104, 108, 109], "need": [8, 10, 12, 41, 56, 61, 71, 80, 81, 82, 85, 86, 90, 94, 96, 97, 99, 102, 104, 109, 110, 111, 113], "pass": [8, 37, 46, 51, 56, 57, 61, 69, 71, 85, 90, 94, 100, 102, 104, 110, 113], "process": [8, 12, 17, 20, 22, 24, 25, 94, 99, 107, 108, 112], "here": [8, 9, 13, 69, 75, 83, 94, 95, 96, 97, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "return": [8, 10, 12, 13, 19, 20, 21, 37, 53, 67, 78, 84, 89, 90, 93, 94, 95, 96, 100, 102, 104, 108, 109, 110, 111, 112, 113], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 80, 102, 110], "now": [8, 10, 12, 42, 44, 45, 50, 93, 94, 95, 99, 100, 102, 108, 109, 111, 113], "we": [8, 10, 12, 13, 21, 41, 43, 44, 48, 50, 51, 52, 66, 67, 69, 75, 78, 83, 89, 90, 93, 94, 95, 96, 97, 99, 100, 103, 104, 108, 109, 110, 111, 112, 113], "throughout": 8, "note": [8, 10, 12, 44, 54, 66, 75, 86, 90, 94, 95, 97, 99, 102, 104, 110, 111, 112], "input": [8, 10, 13, 20, 21, 23, 34, 37, 38, 50, 51, 52, 53, 69, 73, 78, 83, 84, 86, 89, 93, 94, 95, 97, 100, 102, 108, 109, 110, 111, 112, 113], "paramet": [8, 12, 13, 17, 20, 21, 27, 30, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 67, 69, 72, 74, 75, 78, 83, 84, 86, 89, 90, 93, 94, 96, 97, 99, 102, 104, 108, 109], "like": [8, 10, 12, 17, 41, 93, 94, 95, 96, 99, 102, 103, 104, 108, 109, 110, 111, 112, 113], "bit": [8, 12, 25, 32, 68, 97, 102, 103, 104, 109, 111, 112], "width": [8, 25, 68], "group": [8, 10, 12, 41, 42, 45, 47, 59, 63, 64, 65, 67, 71, 72, 74, 75, 79, 95], "size": [8, 10, 13, 19, 21, 39, 44, 45, 47, 50, 52, 67, 83, 93, 95, 96, 97, 99, 100, 102, 104, 110], "etc": [8, 10, 41, 56, 57, 80, 82, 94, 108, 113], "them": [8, 12, 56, 61, 71, 85, 113], "append": [8, 99, 109, 110], "config": [8, 12, 34, 37, 41, 43, 44, 55, 56, 57, 58, 60, 61, 62, 66, 67, 68, 69, 78, 86, 89, 94, 95, 97, 99, 100, 104, 109, 111, 112], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 42, 44, 45, 47, 56, 57, 59, 63, 66, 67, 69, 71, 72, 78, 95, 103, 104], "system": [8, 10, 80, 97], "model_architectur": 8, "type": [8, 10, 12, 13, 20, 21, 25, 34, 35, 36, 37, 41, 43, 44, 45, 46, 48, 49, 53, 67, 70, 78, 79, 80, 81, 82, 83, 84, 90, 91, 94, 96, 97, 99, 102, 104, 108, 109, 111, 112, 113], "defin": [8, 10, 17, 25, 35, 56, 61, 71, 85, 86, 90, 94, 95, 99, 100, 102, 104, 108, 111, 112, 113], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 85, 86, 90, 95, 96, 100, 102, 109, 110, 111, 113], "mycustommodel": 8, "torch": [8, 12, 13, 20, 21, 25, 27, 34, 37, 41, 43, 50, 52, 53, 56, 57, 59, 60, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 78, 79, 83, 84, 89, 90, 91, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 107, 111, 112, 113], "nn": [8, 10, 12, 34, 37, 54, 59, 63, 66, 69, 78, 89, 90, 93, 94, 95, 96, 97, 99, 100, 102, 104, 109, 110, 111, 113], "modul": [8, 10, 12, 34, 35, 36, 37, 38, 48, 49, 54, 56, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 89, 93, 94, 95, 96, 100, 104, 108, 109, 110, 111, 112, 113], "__init__": [8, 12, 90, 95, 96, 100, 102, 104, 109, 110, 111], "self": [8, 12, 13, 90, 95, 96, 100, 102, 104, 109, 110, 111], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 21, 59, 64, 74, 83, 93, 94, 95, 96, 97, 99, 100, 103, 104, 111, 112], "super": [8, 12, 95, 96, 100, 102, 109, 110, 111], "layer1": 8, "linear": [8, 10, 12, 20, 34, 37, 41, 42, 43, 45, 46, 47, 54, 57, 59, 64, 65, 66, 69, 74, 75, 76, 77, 78, 87, 89, 90, 93, 94, 95, 96, 97, 99, 100, 102, 108, 109, 110, 111, 113], "512": [8, 93], "bia": [8, 12, 57, 74, 75, 94, 95, 96, 100, 102, 104, 110, 113], "fals": [8, 12, 13, 29, 34, 44, 46, 56, 57, 65, 66, 67, 69, 71, 72, 74, 75, 86, 93, 94, 95, 96, 97, 100, 102, 103, 104, 108, 109, 110, 112, 113], "activ": [8, 12, 41, 45, 46, 56, 57, 59, 65, 66, 67, 69, 75, 81, 82, 86, 91, 95, 97, 99, 100, 103, 104, 108, 111, 112, 113], "relu": [8, 95, 108, 113], "layer2": 8, "forward": [8, 46, 56, 57, 61, 68, 71, 74, 85, 95, 96, 99, 100, 102, 104, 109, 110, 111], "x": [8, 56, 57, 61, 68, 71, 93, 95, 96, 97, 100, 102, 104, 107, 108, 109, 110, 111, 112], "updat": [8, 91, 95, 96, 99, 109, 110, 113], "create_model_and_input_data": 8, "handl": [8, 10, 20, 23, 24], "model_typ": [8, 12, 104, 108], "m": [8, 10, 12, 78, 89, 93, 95, 96, 97, 100, 102, 109, 110, 111], "int": [8, 12, 13, 19, 21, 24, 25, 26, 27, 29, 30, 31, 32, 39, 41, 43, 44, 45, 47, 50, 51, 52, 56, 57, 59, 63, 64, 65, 67, 71, 72, 74, 75, 78, 83, 86, 90, 95, 100, 102, 104], "k": [8, 10, 84, 95, 96, 100, 102, 109, 110], "n": [8, 10, 12, 95, 96, 100, 102, 109, 110, 113], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 71, 74, 75, 78, 84, 93, 95, 96, 97, 100, 102, 104, 108, 109, 110, 111, 112], "cuda": [8, 10, 12, 13, 78, 93, 95, 96, 97, 99, 100, 102, 103, 110], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 57, 93, 95, 96, 100, 102, 108, 109, 110, 111, 112], "when": [8, 10, 12, 13, 22, 50, 52, 69, 83, 90, 93, 94, 97, 99, 100, 103, 104, 108, 109, 110, 111, 112, 113], "ad": [8, 12, 13, 52, 86, 90, 94, 99, 100, 102, 110], "dimens": [8, 10, 13, 25, 50, 52, 53, 83, 93, 94, 102, 104, 109, 110], "ensur": [8, 20, 97, 110], "convent": 8, "where": [8, 23, 48, 51, 63, 64, 65, 94, 99, 104, 113], "batch": [8, 97, 100, 110], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 102, 108, 111, 112], "data": [8, 12, 13, 17, 20, 25, 39, 41, 43, 44, 46, 51, 80, 90, 91, 94, 96, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "typic": [8, 12, 21, 22, 94, 95, 96, 100, 104, 113], "compat": [8, 10, 20, 67, 95], "work": [8, 10, 12, 23, 93, 96, 99, 102, 103, 104, 109, 110, 111], "cpu": [8, 10, 13, 16, 96, 99, 100, 103, 104, 108, 109, 110, 111], "other": [8, 12, 13, 17, 41, 44, 68, 79, 86, 93, 96, 97, 99, 102, 104, 107, 109, 110, 111, 113], "target": [8, 10, 12, 13, 41, 43, 44, 50, 56, 57, 60, 67, 86, 95, 99, 108, 109, 110, 111, 112, 113], "method": [8, 10, 17, 20, 23, 24, 78, 86, 95, 99, 100, 102, 103, 108, 109, 110, 112, 113], "come": [8, 9, 93, 94, 97, 99, 100, 101, 103, 110, 111, 112], "soon": [8, 9, 97, 101, 110], "file": [8, 10, 93, 97, 98, 102, 104, 106, 109, 110], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 69, 91, 94, 95, 96, 99, 100, 102, 103, 108, 109, 110, 111, 112], "quantization_config_recipe_nam": 8, "int8wo": [8, 103], "int8dq": 8, "float8dq": [8, 97], "tensor": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 43, 44, 45, 46, 50, 51, 52, 53, 56, 57, 58, 60, 61, 68, 79, 80, 81, 82, 83, 84, 86, 90, 91, 93, 95, 96, 99, 100, 103, 107, 109, 111, 112], "row": [8, 10, 42, 53, 93, 94, 99], "float8wo": 8, "output_dir": [8, 103], "result": [8, 12, 13, 53, 84, 94, 99, 100, 103, 109, 110, 111, 112, 113], "model_param": 8, "name": [8, 10, 35, 36, 48, 49, 70, 78, 79, 80, 86, 89, 90, 94, 97, 99, 102, 104, 108, 109, 110, 113], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 48, 56, 83, 93, 95, 97, 100, 109, 110], "max_pow": 8, "15": [8, 44, 93, 95, 97], "torch_compile_mod": 8, "max": [8, 10, 48, 94, 95, 100, 102, 109, 110, 113], "autotun": [8, 10, 95, 100], "runner": 8, "gener": [8, 12, 13, 56, 57, 58, 61, 68, 94, 95, 97, 99, 100, 102, 104, 105, 107, 108, 110, 111, 112, 113], "oss": 8, "databas": 8, "python": [8, 10, 95, 97, 99, 105, 107, 108, 109, 111, 112], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 97, 104], "specif": [8, 10, 12, 17, 20, 22, 23, 56, 57, 75, 80, 86, 93, 94, 95, 96, 97, 99, 103, 108, 111, 112, 113], "requir": [8, 12, 13, 22, 24, 79, 90, 94, 95, 97, 99, 102, 103, 108, 111, 113], "mode": [8, 10, 44, 95, 100, 108, 110, 111, 112, 113], "extra_info": 8, "arch": 8, "nvidia": [8, 99], "a100": [8, 12, 95, 103], "sxm4": 8, "80gb": [8, 95], "1024": [8, 78, 89, 95, 96, 111], "custom": [8, 12, 17, 69, 85, 91, 93, 94, 95, 99, 102, 104, 108, 109, 111, 113], "layer": [8, 20, 37, 41, 43, 46, 47, 56, 57, 59, 63, 64, 65, 71, 72, 74, 75, 86, 87, 93, 97, 99, 100, 102, 104, 108, 113], "origin": [8, 12, 13, 21, 43, 46, 62, 83, 86, 94, 95, 96, 97, 99, 108, 109, 113], "metric": [8, 12, 86], "speedup": [8, 10, 12, 93, 94, 95, 97, 99], "wrt": 8, "bf16": [8, 12, 50, 69, 95, 99, 111, 112], "benchmark_valu": 8, "25": [8, 95], "target_valu": 8, "0": [8, 10, 12, 13, 44, 56, 67, 71, 72, 83, 86, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 109, 110, 112, 113], "depend": [8, 13, 96, 99, 102, 109, 110, 112], "step": [8, 12, 22, 38, 69, 70, 93, 94, 99, 108, 109, 110, 111, 112, 113], "workflow": [8, 10, 78, 79, 89, 93, 95, 99, 113], "github": [8, 13, 19, 95, 97, 103], "action": [8, 104, 109, 110], "upload": 8, "verifi": [8, 95, 96, 102], "setup": [8, 97], "suit": [8, 10, 109, 111], "unittest": 8, "discov": 8, "out": [8, 10, 12, 23, 48, 80, 86, 93, 94, 95, 97, 99, 102, 108, 109, 110, 111], "memori": [8, 10, 12, 13, 93, 94, 95, 99, 102, 103, 111, 112], "reduc": [8, 10, 12, 38, 69, 93, 97, 99, 111], "matrix": [8, 15, 39, 41, 53, 79, 84, 86, 94, 95, 99, 111], "miss": [8, 99], "properli": [8, 96], "instal": [8, 10, 93, 94, 95, 97, 103, 109, 112], "Not": [8, 99], "avail": [8, 10, 80, 94, 97, 108, 109, 110, 111, 112], "check": [8, 10, 12, 13, 19, 94, 95, 96, 97, 102, 108, 110, 113], "driver": 8, "basic": [8, 10, 22, 95, 100, 102], "shape": [8, 10, 13, 19, 53, 80, 84, 94, 95, 100, 102, 104, 109, 112], "comprehens": [8, 104, 111], "analysi": [8, 99], "enabl": [8, 10, 77, 90, 93, 94, 97, 103, 104, 111], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 37, 41, 42, 43, 44, 45, 46, 47, 59, 69, 75, 89, 93, 95, 96, 97, 99, 102, 103, 104, 108, 109, 111, 112, 113], "overhead": [8, 99, 103, 104, 111], "multipl": [8, 10, 12, 15, 41, 53, 54, 79, 81, 84, 94, 95, 99, 100, 102, 104, 111, 113], "possibl": [8, 13, 94, 99, 109, 110, 111, 113], "consist": [8, 97, 99, 102, 111, 112, 113], "reproduc": [8, 97], "differ": [8, 10, 12, 17, 44, 51, 54, 83, 84, 93, 94, 95, 96, 97, 99, 102, 103, 104, 109, 110, 111, 113], "case": [8, 9, 10, 69, 84, 97, 99, 102, 104, 108, 109, 113], "user": [8, 10, 12, 41, 54, 69, 75, 91, 93, 94, 95, 97, 99, 100, 102, 107, 109, 110, 111, 112, 113], "more": [8, 10, 12, 13, 44, 45, 93, 94, 95, 97, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112], "about": [8, 10, 12, 94, 95, 96, 97, 99, 109, 110, 111, 113], "compon": [8, 94, 102, 104], "see": [8, 10, 12, 13, 19, 44, 90, 93, 94, 95, 96, 99, 100, 102, 103, 104, 108, 109, 113], "directori": [8, 93], "intend": [9, 94, 109], "provid": [9, 10, 12, 17, 20, 23, 24, 50, 54, 73, 90, 93, 94, 97, 99, 102, 104, 109, 110, 112, 113], "instruct": [9, 12, 94, 97, 109, 110, 111], "most": [9, 10, 22, 69, 94, 97, 99, 104, 109, 110, 113], "fequent": 9, "have": [9, 10, 12, 48, 63, 64, 65, 80, 83, 86, 90, 94, 99, 100, 102, 104, 108, 109, 110, 111, 112, 113], "ani": [9, 10, 22, 59, 63, 73, 86, 94, 99, 102, 108, 110, 112], "answer": [9, 99], "creat": [9, 10, 13, 27, 28, 30, 93, 99, 102, 103, 108, 109, 111, 112, 113], "an": [9, 12, 13, 24, 29, 30, 66, 67, 69, 75, 86, 91, 93, 94, 95, 97, 99, 100, 102, 103, 108, 109, 110, 111, 112, 113], "issu": [9, 94, 95, 102, 111], "start": [10, 12, 35, 36, 48, 49, 70, 79, 80, 93, 94, 97, 99, 100, 102, 104, 108, 109, 110, 111, 112, 113], "read": [10, 102], "overview": [10, 91, 95, 104], "page": [10, 95, 111], "first": [10, 21, 53, 69, 86, 90, 94, 97, 100, 102, 103, 104, 109, 110, 113], "contribut": [10, 95, 99], "exist": [10, 49, 69, 93, 94, 99, 100, 102, 109, 113], "base": [10, 17, 22, 41, 48, 55, 68, 69, 73, 81, 82, 86, 90, 94, 95, 99, 102, 103, 104, 108, 109, 110, 111, 112, 113], "api": [10, 94, 95, 99, 100, 102, 108, 109, 110, 111, 112], "quant_api": [10, 78, 96, 97, 100], "float8tensor": [10, 41, 43, 60, 81, 94, 104], "e": [10, 12, 13, 48, 50, 52, 54, 67, 69, 78, 81, 83, 90, 93, 94, 96, 100, 102, 103, 108, 113], "g": [10, 12, 13, 48, 50, 52, 54, 67, 69, 78, 81, 83, 90, 94, 96, 100, 102, 108, 113], "oper": [10, 12, 13, 15, 17, 20, 46, 51, 94, 95, 97, 108, 109, 110, 111, 112], "make": [10, 42, 44, 94, 95, 102, 104, 109, 113], "trainabl": [10, 12, 94, 102], "add": [10, 22, 90, 102, 107, 111, 113], "parallel": [10, 93, 102, 104], "primit": [10, 13, 19, 102, 109], "op": [10, 12, 13, 19, 41, 78, 79, 90, 95, 99, 102, 104, 109, 110, 111, 113], "slight": [10, 99], "variat": [10, 94], "quant_primit": [10, 13, 19, 100], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 23, 25, 37, 41, 44, 50, 52, 54, 56, 57, 66, 69, 78, 80, 83, 84, 86, 90, 93, 94, 95, 96, 97, 99, 100, 104, 108, 109, 110, 111, 112, 113], "structur": [10, 12, 23, 89, 94, 95, 96, 99, 102, 109], "deriv": [10, 13, 51, 82, 83], "pack": [10, 13, 24, 25, 40, 42, 44, 80], "format": [10, 13, 20, 21, 44, 80, 97, 99, 109, 110, 113], "understand": [10, 80, 93, 111, 113], "concept": [10, 94, 107, 109, 111, 112, 113], "i": [10, 12, 84, 93, 94, 97, 99, 103, 108, 109, 110], "doe": [10, 12, 22, 69, 80, 94, 99, 102, 109, 111, 112], "alreadi": [10, 13, 102, 113], "could": [10, 94, 102, 108, 109, 111, 112, 113], "context": [10, 111, 112], "also": [10, 12, 67, 78, 94, 95, 96, 99, 100, 102, 103, 104, 109, 112, 113], "write": [10, 91, 95, 108, 109, 110], "own": [10, 12, 91, 93, 95, 99, 100, 109, 110, 113], "torchaobasetensor": [10, 104], "help": [10, 12, 93, 94, 97, 104, 108, 109], "common": [10, 69, 79, 80, 81, 82, 91, 93, 94, 99], "specifi": [10, 12, 13, 34, 37, 47, 54, 56, 57, 58, 61, 68, 69, 75, 78, 79, 83, 86, 89, 93, 94, 99, 108, 109, 110, 113], "non": [10, 90, 99, 102, 108, 111, 112], "attribut": [10, 12, 90, 94, 102, 104, 111, 112], "mytensor": [10, 90], "tensor_data_nam": [10, 90], "qdata": [10, 94], "scale": [10, 13, 17, 20, 27, 30, 35, 38, 41, 48, 50, 51, 52, 53, 59, 60, 67, 72, 73, 74, 75, 83, 90, 94, 99, 100, 102, 104, 113], "tensor_attribute_nam": [10, 90], "With": [10, 102, 109, 111, 113], "abov": [10, 12, 42, 44, 48, 94, 96, 99, 100, 102, 109, 110, 113], "ll": [10, 48, 93, 94, 102, 109, 110, 113], "doc": [10, 93, 94, 95, 97, 102, 103], "mani": [10, 94, 99, 102], "still": [10, 12, 94, 99, 109, 113], "affinequantizedtensor": [10, 19, 27, 28, 30, 41, 43, 95, 96, 100, 102], "plan": [10, 41, 43, 44, 110], "move": [10, 78, 100, 104, 110, 111], "awai": 10, "from": [10, 12, 13, 21, 22, 27, 28, 30, 45, 51, 62, 66, 69, 78, 79, 83, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113], "abstract": [10, 94], "easier": [10, 113], "peopl": [10, 94, 96, 104, 113], "implement": [10, 12, 34, 44, 71, 72, 74, 75, 79, 90, 94, 96, 99, 100, 108, 109, 113], "regist": [10, 56, 61, 71, 85, 90, 94, 102], "mai": [10, 13, 51, 67, 80, 94, 96, 100, 103, 109, 110, 111, 112, 113], "well": [10, 17, 94, 95, 99, 109, 110, 113], "int4": [10, 12, 16, 40, 42, 44, 45, 48, 56, 57, 59, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 78, 89, 94, 95, 96, 97, 103, 104], "access": [10, 46, 108], "my_custom_op": 10, "call": [10, 12, 13, 56, 61, 71, 85, 94, 95, 96, 99, 100, 102, 104, 110, 112], "want": [10, 78, 89, 94, 95, 96, 99, 102, 104, 108, 109, 110, 113], "my_mm_for_mp": 10, "aten": [10, 90, 94, 95, 102, 104, 108, 109, 110, 111, 112], "default": [10, 12, 13, 15, 22, 24, 25, 39, 41, 43, 44, 50, 52, 59, 67, 75, 78, 90, 93, 94, 95, 102, 104, 108, 109, 110, 111, 112, 113], "_": [10, 90, 93, 94, 100, 104, 108, 109, 110, 111], "func": [10, 90, 94, 102, 104], "arg": [10, 13, 44, 56, 57, 58, 59, 63, 72, 86, 90, 94, 102, 104, 110, 113], "re": [10, 93, 94, 96, 97, 102, 109, 110], "input_tensor": [10, 21, 94, 104], "weight_tensor": [10, 94, 104], "some": [10, 78, 86, 90, 94, 95, 97, 99, 100, 102, 108, 109, 110, 111, 112, 113], "choic": [10, 44], "mm": [10, 78, 79, 102, 109], "recommend": [10, 12, 41, 43, 44, 45, 46, 47, 93, 94, 103, 108, 111, 112], "wai": [10, 13, 69, 93, 94, 97, 99, 100, 102, 109, 110, 113], "repres": [10, 13, 15, 17, 28, 34, 39, 55, 67, 80, 83, 86, 94, 96, 102, 109, 110], "group_mm": 10, "auto": [10, 41, 79, 97, 103, 104], "develop": [10, 95, 109, 110, 113], "choos": [10, 44, 82, 94, 99, 102, 109, 111], "whatev": 10, "think": [10, 104], "fastest": 10, "under": [10, 12, 79, 97], "condit": 10, "so": [10, 12, 93, 94, 95, 96, 99, 102, 103, 109, 110, 113], "don": [10, 86, 93, 94, 95, 99, 103, 104, 113], "t": [10, 86, 90, 93, 94, 95, 99, 100, 102, 103, 104, 109, 110, 113], "worri": 10, "debug": 10, "purpos": [10, 93, 94, 102, 109], "ha": [10, 12, 13, 69, 97, 99, 102, 104, 108, 109, 110, 112, 113], "hardwar": [10, 41, 80, 95, 97, 99, 103], "h100": [10, 94, 103], "sm89": 10, "sm90": 10, "librari": [10, 79, 80, 91, 94, 96], "whether": [10, 12, 44, 50, 67, 90, 102], "fbgemm_gpu_genai": [10, 79, 94], "granular": [10, 13, 35, 41, 44, 45, 47, 50, 52, 56, 57, 59, 60, 67, 68, 83, 93, 94, 97, 100, 104], "per": [10, 12, 13, 42, 43, 45, 46, 47, 50, 52, 59, 63, 64, 65, 67, 71, 72, 74, 75, 83, 86, 93, 94, 95, 99, 100, 112], "_choose_scale_float8": [10, 94], "_quantize_affine_float8": [10, 94], "_scaled_mm": [10, 94], "kerenel": 10, "fbgemm": [10, 94, 99], "f8f8bf16_rowwis": [10, 94], "level": [10, 86, 94, 99, 102, 108, 109, 111, 112], "reus": [10, 102], "allow": [10, 75, 94, 95, 99, 102, 108, 109, 110, 111, 113], "appli": [10, 12, 13, 41, 42, 43, 45, 46, 47, 54, 58, 59, 61, 66, 68, 69, 78, 89, 90, 94, 95, 97, 99, 104, 110], "convers": [10, 12, 13, 37], "weight": [10, 12, 20, 21, 38, 41, 42, 43, 44, 45, 46, 47, 56, 57, 59, 63, 64, 65, 67, 69, 71, 72, 74, 75, 78, 81, 86, 89, 91, 93, 95, 96, 99, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113], "filter": [10, 12, 37, 93, 100], "should": [10, 12, 13, 38, 52, 56, 61, 62, 69, 71, 85, 86, 90, 93, 99, 104, 108, 109, 113], "algorithm": [10, 44, 97, 99, 108], "dynam": [10, 12, 33, 34, 38, 41, 42, 45, 46, 59, 65, 67, 75, 89, 97, 100, 102, 103, 109, 110, 111], "quant": [10, 13, 19, 94, 97, 104, 109, 112, 113], "In": [10, 12, 44, 69, 93, 94, 95, 99, 100, 102, 108, 109, 110, 111, 112, 113], "order": [10, 54, 90, 99, 102, 113], "aim": [10, 99, 112], "run": [10, 12, 38, 56, 57, 61, 71, 78, 85, 93, 94, 95, 97, 99, 102, 107, 108, 109, 110, 111, 112, 113], "fullgraph": [10, 95], "true": [10, 12, 13, 29, 34, 41, 43, 44, 45, 46, 47, 50, 51, 56, 57, 66, 67, 69, 77, 78, 89, 93, 95, 96, 97, 100, 102, 103, 104, 108, 109, 110, 111, 113], "remov": [10, 50, 86, 93, 99, 104, 109, 110], "unnecessari": 10, "graph": [10, 95, 109, 110, 113], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 95, 97, 100, 102, 107, 110, 111, 112], "inductor": [10, 91, 95, 108, 109], "save": [10, 12, 86, 90, 93, 95, 96, 97, 104], "load": [10, 90, 96, 97, 103, 104], "relev": [10, 94, 107], "object": [10, 25, 78, 89, 94, 102, 109, 110, 113], "safe": [10, 84], "global": [10, 99, 102], "after": [10, 12, 38, 93, 94, 96, 99, 103, 108, 109, 110, 111, 112, 113], "2": [10, 13, 14, 16, 20, 23, 41, 43, 44, 48, 56, 67, 71, 72, 83, 87, 89, 91, 93, 94, 99, 100, 102, 107], "5": [10, 12, 48, 56, 86, 95, 97, 99, 104, 107, 109, 110], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 94], "checkout": [10, 13, 19, 91, 94], "huggingfac": [10, 103], "transform": [10, 12, 13, 90, 100, 108, 109, 110, 111, 112], "deseri": [10, 109, 110], "save_pretrain": [10, 97, 103], "push_to_hub": [10, 97, 103, 104], "from_pretrain": [10, 12, 97, 103, 104], "diffus": [10, 97], "just": [10, 48, 67, 94, 96, 99, 102, 109, 110, 113], "talk": [10, 94, 97], "train": [10, 34, 54, 67, 69, 91, 95, 99, 102, 113], "fsdp": [10, 94], "mydtypetensor": 10, "put": [10, 89, 111, 113], "developer_api_guid": 10, "folder": [10, 97, 109, 110], "cover": [10, 107, 109, 112, 113], "follow": [10, 12, 67, 69, 90, 93, 94, 95, 97, 99, 100, 102, 103, 108, 109, 110, 111, 112, 113], "executorch": [10, 45, 78, 91, 95, 103, 109, 110], "torchchat": 10, "dtensor": [10, 102], "copi": [10, 13, 86, 95, 96, 99, 100, 102, 110, 111], "past": [10, 99], "adapt": [10, 93, 100], "befor": [10, 12, 69, 78, 94, 96, 97, 99, 100, 102, 109, 110, 113], "do": [10, 49, 53, 78, 94, 97, 99, 100, 102, 104, 109, 110, 111, 113], "singl": [10, 12, 33, 38, 41, 51, 93, 94, 95, 99, 109, 113], "comput": [10, 20, 24, 38, 43, 56, 61, 71, 79, 85, 86, 94, 99, 100, 102, 103, 109, 110, 111, 112], "intens": 10, "get": [10, 12, 21, 75, 90, 93, 94, 95, 97, 99, 104, 108, 109, 110, 111, 113], "sens": [10, 94, 102], "d": [10, 90, 97, 110], "benchmark_aq": 10, "s": [10, 12, 13, 48, 50, 52, 79, 80, 83, 90, 93, 94, 95, 97, 99, 100, 102, 109, 110, 111, 112, 113], "import": [10, 12, 62, 66, 69, 78, 89, 95, 96, 97, 99, 100, 102, 103, 104, 107, 108, 111, 112], "A": [10, 12, 13, 25, 51, 85, 90, 94, 99, 102, 103, 104, 109], "quick": [10, 91], "chang": [10, 78, 93, 95, 96, 97, 99, 100, 102, 108, 109, 110, 112, 113], "interest": [10, 99, 102], "print_op_and_shap": 10, "output": [10, 12, 34, 50, 52, 83, 93, 94, 95, 97, 99, 103, 107, 108, 109, 110, 111, 112, 113], "torch_func": 10, "built": [10, 93, 102], "_c": 10, "tensorbas": 10, "all": [10, 38, 44, 48, 51, 56, 59, 61, 63, 71, 73, 85, 86, 87, 90, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105, 108, 109, 111, 113], "benchmark_your_kernel": 10, "helper": [10, 76, 77, 90], "right": [10, 42, 44, 99, 109], "1": [10, 20, 25, 35, 36, 41, 43, 44, 48, 49, 70, 78, 79, 80, 82, 83, 86, 91, 94, 95, 96, 98, 99, 100, 102, 106, 107, 109, 110], "feel": [10, 94, 99, 102, 104], "free": [10, 94, 102], "either": [10, 13, 41, 60, 69, 86, 97, 99, 110, 111, 112], "one": [10, 41, 51, 56, 61, 69, 71, 85, 93, 94, 99, 102, 104, 110, 113], "probabl": 10, "keep": [10, 20, 46, 86, 94, 109], "futur": [10, 100, 103, 104, 109, 110, 111, 113], "llama": [10, 12, 97, 103, 104, 108], "llama2": 10, "llama3": [10, 12, 93, 103], "sam": 10, "modifi": [10, 37, 78, 86, 93, 99, 102], "friendli": 10, "compar": [10, 12, 86, 93, 94, 97, 109, 111, 113], "techniqu": [10, 12, 93, 96, 97, 99, 100, 102, 104], "bound": [10, 41, 60, 97, 99, 104], "each": [10, 21, 59, 67, 72, 74, 75, 85, 90, 94, 99, 100, 102, 104, 109, 110, 113], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 48, 83, 94, 95, 99, 100, 102, 113], "know": [10, 102], "end": [12, 93, 94, 97, 99, 102, 103, 104, 107, 110, 113], "pre": [12, 17, 20, 24, 91, 97, 99, 113], "serv": [12, 13, 17, 91, 93, 102, 103, 112], "flow": [12, 45, 93, 97, 99, 100, 108, 109, 110, 111, 112], "leverag": [12, 93, 95, 97, 102, 111, 112], "partner": [12, 93, 97], "showcas": [12, 93, 97], "focus": [12, 93, 94, 97, 99], "domain": [12, 13, 50, 52, 67, 93], "demonstr": [12, 93, 94, 95, 97, 102, 108, 110], "dure": [12, 13, 19, 46, 52, 67, 69, 93, 95, 97, 99, 100, 102, 108, 110], "numer": [12, 69, 74, 75, 93, 99, 109, 110, 111], "goal": [12, 69], "mitig": [12, 99], "degrad": [12, 69, 99], "eventu": [12, 69, 93], "blog": 12, "resourc": [12, 102], "small": 12, "matric": [12, 23, 99], "freez": [12, 110, 111, 112], "checkpoint": [12, 90, 93, 97, 104], "effici": [12, 24, 74, 95, 99, 100, 112], "paper": [12, 99, 107], "speed": [12, 78, 97, 99, 108], "up": [12, 21, 67, 78, 93, 94, 95, 99, 108, 109, 110, 113], "high": [12, 13, 26, 27, 28, 29, 30, 60, 69, 93, 94, 97, 99, 100, 102, 108, 109, 111, 112], "precis": [12, 13, 26, 27, 28, 29, 30, 43, 46, 59, 60, 64, 65, 69, 72, 74, 75, 94, 100, 102, 103, 108, 111, 112], "similar": [12, 99, 100, 110, 111], "inevit": 12, "actual": [12, 43, 69, 94, 100, 102, 104, 109, 110, 113], "presum": 12, "been": [12, 90, 102, 110, 111, 112, 113], "successfulli": [12, 99], "recent": [12, 91], "releas": [12, 111], "1b": [12, 103, 104], "3b": 12, "llamaguard": 12, "8b": [12, 93, 103], "improv": [12, 93, 97, 99, 109, 112, 113], "qualiti": [12, 99, 103], "involv": [12, 15, 69, 99], "two": [12, 19, 23, 41, 69, 90, 94, 95, 99, 102, 108, 109, 110, 111, 113], "separ": [12, 56, 57, 67, 99, 104, 109, 113], "prepar": [12, 54, 59, 63, 69, 86, 99, 108, 111, 112, 113], "convert": [12, 13, 19, 21, 26, 29, 31, 32, 34, 54, 62, 63, 69, 78, 89, 93, 94, 97, 99, 108, 111, 112, 113], "fake": [12, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77, 93, 109, 110, 113], "mean": [12, 13, 21, 48, 50, 52, 83, 90, 93, 94, 95, 99, 109, 110, 113], "valu": [12, 13, 21, 34, 35, 36, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 60, 70, 79, 80, 83, 86, 94, 99, 100, 102, 108, 109, 110, 113], "map": [12, 46, 48, 67, 90, 94, 102, 109, 113], "without": [12, 62, 94, 99, 104, 111, 113], "cast": [12, 13, 33, 35], "lower": [12, 41, 45, 60, 94, 95, 97, 99, 100, 103, 110], "replac": [12, 99, 104], "real": [12, 94, 95, 109, 113], "perform": [12, 13, 24, 38, 46, 47, 53, 56, 61, 63, 64, 65, 71, 84, 85, 93, 95, 99, 100, 102, 103, 104, 108, 110, 111, 112], "There": [12, 69, 94, 100, 102, 109, 113], "directli": [12, 48, 51, 69, 94, 99, 100, 102], "loop": [12, 93, 99], "distribut": [12, 93, 100, 102, 104, 108], "recip": [12, 34, 56, 61, 71, 85], "instead": [12, 51, 56, 61, 62, 66, 67, 69, 71, 85, 93, 95, 99, 102, 110, 111, 112, 113], "command": [12, 93], "regular": [12, 108, 111, 112], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 20, 23, 32, 87, 89, 94, 95, 96, 97, 99, 102, 103, 109, 110], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 96, 97, 100, 109, 110], "16": [12, 57, 93], "equival": [12, 67, 99, 110, 111, 113], "asymmetr": [12, 45, 48, 50, 67, 95, 100, 108, 112, 113], "token": [12, 45, 46, 65, 67, 75, 93, 97, 103], "int8": [12, 21, 45, 46, 47, 57, 65, 66, 67, 69, 75, 78, 82, 89, 94, 97, 102, 109, 111, 112, 113], "symmetr": [12, 41, 43, 45, 46, 47, 48, 50, 56, 59, 67, 102, 108, 109, 112, 113], "configur": [12, 15, 33, 34, 37, 41, 42, 43, 44, 45, 46, 47, 78, 89, 93, 94, 95, 97, 103, 111, 112, 113], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 110], "same": [12, 13, 41, 44, 50, 51, 52, 75, 83, 84, 89, 90, 93, 94, 99, 100, 102, 110, 112, 113], "wa": [12, 102, 110], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 103], "int8dynactint4weightquant": 12, "groupsiz": [12, 64, 65, 74, 75, 83], "32": [12, 44, 45, 57, 66, 67, 69, 71, 72, 78, 89, 93, 95, 96, 97, 100, 102, 110], "hellaswag": [12, 97], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 97], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 97], "ckpt": 12, "llama3_token": 12, "path": [12, 78, 84, 95, 97, 108, 109, 110, 111, 113], "tmp": [12, 95], "meta": [12, 96, 103, 104, 113], "print": [12, 86, 95, 96, 97, 102, 107, 109, 110], "version": [12, 16, 41, 43, 44, 67, 78, 94, 96, 102, 104, 109, 110, 113], "shot": [12, 99], "stderr": 12, "none": [12, 13, 15, 19, 26, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 44, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 66, 67, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 83, 86, 89, 90, 94, 100, 102, 104, 108, 109, 110, 112], "acc": [12, 109, 110], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 95, 99, 113], "openassist": 12, "oasst1": 12, "dataset": [12, 93, 97, 108, 111, 112], "find": [12, 21, 99, 109, 113], "achiev": [12, 21, 93, 99, 100, 102, 110, 111], "higher": [12, 93, 102, 103, 108, 109, 111, 112], "accuraci": [12, 93, 97, 99, 100, 108, 110, 111], "than": [12, 25, 67, 93, 94, 99, 102, 109], "recov": [12, 99, 110], "69": [12, 100], "8": [12, 24, 25, 44, 48, 56, 57, 64, 74, 93, 94, 95, 97, 104, 111, 112], "overal": [12, 91, 95, 109, 113], "vanilla": 12, "compos": [12, 54, 94, 99, 102, 109, 110, 113], "lora": 12, "yield": [12, 99], "89x": 12, "usag": [12, 13, 38, 54, 56, 57, 62, 66, 67, 69, 90, 91, 93, 97, 111, 112], "36": [12, 93, 97], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 41, 43, 44, 45, 46, 47, 51, 67, 78, 86, 90, 95, 99, 108, 110, 111, 112], "try": [12, 99, 102, 109], "fsdp2": [12, 93], "yaml": 12, "onc": [12, 99], "complet": [12, 97, 108, 112], "qat_out": 12, "quatiz": 12, "document": [12, 102, 104, 108, 109, 111], "prefer": [12, 41, 94, 102], "These": [12, 99, 102, 108, 109, 110, 113], "what": [12, 13, 19, 93, 94, 95, 97, 99, 100, 104, 107, 109, 113], "hood": 12, "mini": [12, 97], "gpu": [12, 91, 93, 95, 103, 104, 107, 108], "smaller": [12, 25, 44, 45, 95, 96], "fit": [12, 13, 24, 94, 96], "adjust": [12, 41, 43, 44, 45, 46, 47], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 93], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 93], "max_seq_len": 12, "train_loop": [12, 69], "sgd": 12, "lr": [12, 93], "001": 12, "momentum": [12, 110], "9": [12, 93], "weight_decai": 12, "1e": [12, 93], "loss_fn": 12, "crossentropyloss": [12, 109, 110], "rang": [12, 48, 93, 99, 100, 109, 110], "randint": 12, "loss": [12, 93, 99, 109, 110], "backward": [12, 38, 93, 99, 110], "zero_grad": [12, 93, 110], "next": [12, 93, 100, 109, 110, 111, 112], "scheme": [12, 46, 47, 56, 57, 69, 97, 108], "although": [12, 44, 56, 61, 71, 85, 102], "integ": [12, 13, 29, 30, 48, 50, 52, 53, 67, 68, 84, 100, 109, 110, 111], "arithmet": [12, 69], "float": [12, 13, 19, 21, 29, 31, 32, 41, 44, 48, 50, 51, 52, 56, 60, 67, 71, 72, 83, 86, 94, 95, 96, 102, 109, 110, 113], "float32": [12, 13, 27, 52, 63, 65, 67, 71, 72, 75, 83, 96, 97, 99, 100, 102, 111, 112, 113], "becaus": [12, 13, 20, 93, 96, 99, 102, 110, 113], "int8dynamicactivationint4weightconfig": [12, 69, 75, 78], "qatconfig": [12, 62, 66, 70], "swap": [12, 37, 59, 63, 93, 99, 100, 110], "fakequantizedlinear": [12, 59, 62, 76, 77], "base_config": [12, 69], "exact": [12, 75, 109, 110], "attun": 12, "benefici": 12, "later": [12, 94, 102, 109, 110, 112], "readi": [12, 93, 95, 97, 100, 102, 110], "did": [12, 45], "altern": [12, 67, 100, 102, 111, 112], "legaci": [12, 44], "offer": [12, 102, 109], "customiz": [12, 78], "unlik": [12, 100], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 95, 100, 108, 109, 110, 111, 112, 113], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 108, 109, 111, 112], "footprint": 12, "extens": [12, 102, 109, 111], "addition": [12, 111, 112], "frozen": 12, "further": [12, 102, 108, 109, 110, 111], "nf4": [12, 21], "propos": [12, 86], "express": [12, 95, 102, 108, 109, 110, 113], "subclass": [12, 13, 19, 37, 56, 61, 71, 79, 80, 85, 89, 90, 95, 96, 99, 103], "nf4tensor": 12, "cleanli": 12, "compil": [12, 78, 84, 91, 93, 94, 95, 100, 102, 111, 112], "simpli": [12, 99, 100, 102], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 29, 34, 37, 41, 43, 44, 45, 46, 47, 50, 51, 56, 57, 65, 67, 71, 72, 74, 75, 77, 78, 89, 100], "quantization_kwarg": 12, "No": [12, 94, 96, 99], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 94, 100, 102, 104], "though": [12, 102], "shown": [12, 97, 99, 110, 113], "competit": [12, 93], "baselin": [12, 93, 97, 109], "while": [12, 56, 61, 69, 71, 81, 85, 86, 97, 99, 102, 103, 108, 109, 113], "even": [12, 13, 93, 99, 113], "newer": 12, "mxfp4": [12, 94], "nvfp4": [12, 94], "blackwel": 12, "reap": 12, "benefit": [12, 42, 99, 102, 109, 112], "vari": [12, 13, 109, 110, 111, 112], "tradeoff": [12, 99, 103], "incorpor": 12, "its": [12, 99, 102, 104, 109, 113], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 93, 94, 102, 103, 104, 109], "yet": [12, 45, 49, 69, 102, 103, 104, 110, 111, 112], "invok": [12, 111], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 97, 103, 104], "torchaoconfig": [12, 97, 103, 104], "int8weightonlyconfig": [12, 78, 104], "base_model": 12, "quantization_config": [12, 97, 103, 104, 112], "peft_config": 12, "throughput": [12, 93, 97], "increas": [12, 99, 109], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 33, 34, 94], "initi": [12, 13, 73, 94, 95, 96, 110], "experi": [12, 93, 112], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 93, 95, 109], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 93], "074": [12, 93], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 93], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 93, 112, 113], "407": [12, 93], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 93], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 19, 90, 100], "aqttensorimpl": [13, 19], "block_siz": [13, 17, 19, 21, 26, 27, 29, 30, 31, 32, 50, 51, 52, 83, 94, 95, 100], "tupl": [13, 19, 21, 26, 27, 29, 30, 31, 41, 50, 51, 52, 73, 83, 86, 90, 102, 104, 109, 110, 113], "quant_min": [13, 19, 29, 30, 31, 48, 50, 51, 52, 83, 95, 102, 112, 113], "union": [13, 19, 34, 41, 50, 52, 60, 67, 78, 83], "quant_max": [13, 19, 29, 30, 31, 48, 50, 51, 52, 83, 95, 102, 112, 113], "zero_point_domain": [13, 19, 29, 30, 31, 44, 50, 51, 67], "zeropointdomain": [13, 19, 29, 30, 31, 44, 50, 51, 67], "stride": [13, 19, 102], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 97, 105, 107], "affin": [13, 14, 15, 16, 20, 23, 24, 29, 40, 52, 83, 94], "point": [13, 19, 31, 44, 48, 52, 60, 67, 72, 73, 74, 75, 93, 94, 95, 96, 99, 100, 102, 109, 113], "quantized_tensor": 13, "float_tensor": [13, 102], "zero_point": [13, 17, 30, 50, 51, 52, 83, 90, 94, 99, 100, 102, 113], "happen": [13, 19, 94, 102, 109, 111], "choose_qparam": [13, 94], "dequant": [13, 19, 21, 52, 94, 95, 102, 104, 109, 111, 112, 113], "http": [13, 19, 86, 97, 99, 103, 112], "com": [13, 19, 97, 103], "ao": [13, 19, 99, 104], "blob": [13, 19], "main": [13, 19, 94, 95, 97, 99, 100, 102, 103, 109, 113], "three": [13, 86, 89, 111, 112], "choose_qparams_affin": [13, 51], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 93, 94, 99, 108, 109, 110, 111, 112], "extern": [13, 111], "regardless": 13, "intern": [13, 24], "represent": [13, 17, 28, 90, 99, 104, 109, 113], "orient": 13, "field": [13, 67, 70, 90, 113], "impl": [13, 90], "storag": [13, 20, 99], "store": [13, 20, 21, 25, 46, 81, 85, 94, 99, 103, 104, 109, 110], "plain": [13, 44, 80, 94, 104], "int_data": [13, 102], "kernel": [13, 14, 16, 20, 24, 40, 41, 42, 74, 78, 79, 95, 97, 99, 108, 111, 112], "element": [13, 23, 25, 50, 52, 59, 72, 74, 75, 83, 90, 94, 99], "share": [13, 50, 52, 83, 99], "qparam": [13, 44, 50, 52, 83], "minimum": [13, 50, 52, 83], "maximum": [13, 50, 52, 83], "zero": [13, 23, 44, 46, 50, 52, 67, 72, 73, 74, 75, 86, 99, 100, 113], "subtract": [13, 21], "unquant": [13, 113], "given": [13, 19, 32, 82, 93, 99, 104, 113], "classmethod": [13, 19, 81, 90, 100, 102, 104], "from_hp_to_floatx": 13, "input_float": [13, 19, 26, 27, 28, 29, 30, 31], "target_dtyp": [13, 26, 27, 29, 30, 33, 34, 50, 51, 94, 100], "_layout": [13, 19, 26, 27, 28, 29, 30, 31, 90, 95, 100], "layout": [13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 39, 40, 44, 45, 46, 89, 90, 99], "scale_dtyp": [13, 26, 27, 29, 50, 51, 100], "float8": [13, 14, 15, 26, 27, 33, 34, 35, 36, 37, 38, 41, 42, 43, 59, 60, 61, 82, 91, 97, 100], "from_hp_to_floatx_stat": 13, "static": [13, 17, 21, 27, 30, 34, 51, 67, 91, 95, 109, 110, 111, 112, 113], "from_hp_to_fpx": 13, "floatx": [13, 28], "ebit": [13, 28], "mbit": [13, 28], "float1": [13, 28], "float7": [13, 28], "from_hp_to_intx": [13, 19], "mapping_typ": [13, 29, 45, 50, 51, 67], "mappingtyp": [13, 29, 45, 46, 50, 51, 67, 100], "ep": [13, 29, 50, 51, 67, 100, 110, 112, 113], "zero_point_dtyp": [13, 29, 50, 51, 100], "preserve_zero": [13, 29, 44, 50, 51], "plainlayout": [13, 29, 30, 45, 46, 90, 100], "use_hqq": [13, 29, 44, 103, 104], "custom_scal": [13, 29], "custom_zero_point": [13, 29], "from_hp_to_intx_stat": 13, "argument": [13, 24, 52, 67, 69, 78, 81, 90, 93, 94, 97, 111], "correct": [13, 20, 109, 110], "otherwis": [13, 47, 54, 67, 110], "desir": [13, 100], "gradient": [13, 91, 99], "implicitli": [13, 113], "complex": [13, 99], "non_block": 13, "memory_format": [13, 111, 112], "preserve_format": 13, "accord": 13, "c": [13, 90, 95, 102, 111, 112], "rule": 13, "truncat": 13, "part": [13, 91, 99, 102, 103, 110], "cannot": [13, 99, 100, 103, 104], "inf": 13, "long": [13, 102, 109], "behavior": [13, 17, 54, 104, 109, 110], "undefin": [13, 54, 86], "across": [13, 86, 97, 99, 102, 104], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 99, 110], "host": [13, 104], "both": [13, 41, 44, 69, 75, 94, 95, 99, 100, 102, 109, 111, 112, 113], "pin": 13, "pageabl": 13, "howev": [13, 99, 103, 104, 110, 113], "caution": 13, "advis": [13, 94], "good": [13, 95, 102, 113], "pin_memori": 13, "match": [13, 52, 53, 74, 75, 90, 99, 109], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 40], "mm_config": [15, 41], "float8mmconfig": [15, 41], "variabl": [15, 24, 25, 39, 86, 90, 99], "tinygemm": [16, 44, 74, 78, 95], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 67, 93, 94, 95, 97, 99, 109, 110, 111], "It": [17, 20, 22, 24, 38, 95, 99, 102, 113], "post": [17, 24, 69, 91, 94, 95, 102, 110, 113], "design": [17, 20, 23, 97, 104, 108, 109, 113], "extend": [17, 94, 99, 111], "conjunct": 17, "tensorimpl": [17, 90], "interact": [17, 109], "marlin": [18, 19, 20, 31], "qqq": [18, 19, 31], "marlinqqq": 19, "inherit": [19, 22, 90, 102, 104, 111, 112], "_choose_qparams_and_quantize_affine_qqq": 19, "_dequantize_affine_qqq": 19, "spars": [20, 23, 39, 56, 71, 72, 86, 99], "pattern": [20, 23, 94, 95, 104, 108, 109], "preprocess": [20, 23], "manag": 20, "pre_process": 20, "1\u00ba": 20, "transpos": [20, 102], "sinc": [20, 42, 56, 61, 71, 85, 94, 96, 97, 99, 100, 102, 109, 110, 111, 112, 113], "2\u00ba": 20, "inject": 20, "3\u00ba": 20, "again": [20, 21, 99, 109, 113], "dim": [20, 100, 102, 104, 109, 110], "tensor_meta": 21, "subclasstensorarg": 21, "n_block": 21, "scaler_block_s": [21, 32], "quantized_scal": 21, "quantization_factor": 21, "scaler_mean": 21, "quantized_data": [21, 104], "qlora": [21, 91, 97], "convert_to_norm_float_weight": 21, "normal": [21, 32, 99, 109, 110], "dequantize_scal": 21, "unpack": 21, "doubl": 21, "scaler": 21, "per_scaler_block": 21, "factor": [21, 53, 93, 99], "inpt_weight": 21, "block": [21, 39, 86, 99], "double_quantize_scal": 21, "take": [21, 56, 61, 71, 78, 85, 89, 90, 94, 99, 108, 109, 110, 111, 112, 113], "calcul": [21, 38, 41, 48, 50, 51, 60, 94, 99, 109, 113], "absmax": 21, "posit": 21, "And": [21, 41, 102, 111, 113], "per_block": 21, "int16": [21, 109], "n_scaler_block": 21, "get_original_weight": 21, "quantize_tensor_nearest": 21, "float16": [21, 83, 99], "nearest": 21, "round": [21, 48, 102], "metadata": [22, 90, 94, 97, 102, 104], "semi": [23, 89, 99], "everi": [23, 56, 61, 71, 85, 99, 102, 109, 110], "four": [23, 108], "prune": [23, 86], "conform": 23, "inner_k_til": [24, 44, 64, 74, 95], "core": [24, 49, 78, 100, 104, 109], "tile": 24, "affect": [24, 79, 99], "matmul": [24, 41, 43, 94, 99, 102], "pack_dim": 25, "uintx": 25, "standard": [25, 104], "byte": 25, "uintxtensor": 25, "determin": [25, 50, 69, 93, 99, 104], "along": [25, 99, 104, 108], "indic": [25, 99, 113], "last": [25, 93, 108], "64": [32, 39, 44, 59, 96, 97, 100, 102, 104], "256": [32, 44, 63, 64, 65, 74, 75, 97, 109, 110, 113], "scaling_typ": [33, 34], "scalingtyp": [33, 34], "scaling_granular": [33, 34], "scalinggranular": [33, 34], "mayb": 33, "cast_config_input": 34, "castconfig": 34, "cast_config_input_for_grad_weight": 34, "cast_config_weight": 34, "cast_config_weight_for_grad_input": 34, "cast_config_grad_output": 34, "cast_config_grad_output_for_grad_weight": 34, "gemm_config_output": 34, "float8gemmconfig": 34, "use_fast_accum": 34, "gemm_config_grad_input": 34, "gemm_config_grad_weight": 34, "enable_fsdp_float8_all_gath": 34, "pad_inner_dim": 34, "emul": 34, "force_recompute_fp8_weight_in_bwd": 34, "round_scales_to_power_of_2": 34, "from_recipe_nam": 34, "recipe_nam": [34, 93], "float8linearrecipenam": 34, "qualnam": [35, 36, 48, 49, 70, 79, 80], "boundari": [35, 36, 48, 49, 70, 79, 80], "strategi": 35, "module_filter_fn": [37, 93], "callabl": [37, 78, 89, 90, 104], "float8linearconfig": 37, "float8linear": [37, 93], "instanc": [37, 56, 61, 71, 78, 85, 89, 90, 96, 102, 109, 111, 112, 113], "fqn": [37, 86, 89, 93, 100], "sum": [38, 109, 110], "prototyp": [39, 40, 67, 73, 94, 113], "blocksiz": 39, "activation_dtyp": [41, 94], "float8_e4m3fn": [41, 43, 60, 94], "weight_dtyp": [41, 43, 94, 97], "pertensor": [41, 60, 100], "perrow": [41, 60, 94], "list": [41, 52, 54, 86, 90, 95, 102, 104, 108, 110, 113], "activation_value_lb": 41, "activation_value_ub": 41, "kernel_prefer": [41, 94], "kernelprefer": 41, "set_inductor_config": [41, 43, 44, 45, 46, 47], "fp8granular": [41, 60], "fast": [41, 99], "accumul": 41, "upper": [41, 60], "defalut": 41, "chosen": [41, 82, 99], "torchinductor": [41, 43, 44, 45, 46, 47, 111, 112], "deprec": [41, 43, 44, 62, 66], "split": [41, 43, 97, 109, 110], "int4_packing_format": [42, 44, 95], "int4packingformat": [42, 44], "preshuffl": [42, 94], "128": [42, 44, 93, 97, 100, 102, 103, 104, 112, 113], "underli": [42, 97, 102], "bigger": 42, "channel": [43, 46, 47, 59, 63, 64, 65, 67, 71, 72, 74, 75, 85, 100, 112], "tensorcoretiledlayout": [44, 95], "int4_choose_qparams_algorithm": [44, 95], "int4chooseqparamsalgorithm": 44, "groupwis": 44, "mainli": [44, 94, 108, 111, 113], "distinguish": [44, 94], "packing_format": 44, "control": [44, 45, 46, 47, 86, 99, 104, 109], "fine": [44, 45, 91, 93, 97, 99], "grain": [44, 45, 102], "variant": [44, 48, 51, 102], "hqq": [44, 94, 95], "preserv": [44, 50, 86, 97, 99, 108], "Will": 44, "subset": [44, 94], "valid": [44, 90, 97, 104, 113], "state": [44, 104], "v1": [44, 97], "v2": [44, 107], "ignor": [44, 56, 61, 71, 85, 93, 109, 110], "less": [44, 48, 99, 102, 109], "confus": [44, 94, 99, 109], "act_mapping_typ": [45, 46], "produc": [45, 95, 108, 109, 110, 111, 112], "backend": [45, 91, 95, 97, 99, 113], "marlinqqqlayout": 45, "cutlassint4packedlayout": 45, "weight_only_decod": 46, "around": [46, 93, 94, 95, 96, 109], "decod": [46, 97], "better": [46, 47, 93, 102, 109, 110, 111, 112, 113], "number": [48, 59, 72, 74, 75, 86, 97, 99, 102, 110, 111], "sai": [48, 83, 94, 103, 104, 113], "3": [48, 56, 83, 91, 93, 94, 95, 99, 103, 107, 109, 110], "7": [48, 93, 97, 111, 112], "symmetric_no_clipping_err": 48, "smin": 48, "smax": 48, "min_val_neg": [48, 102], "max_val_po": [48, 102], "By": [48, 99], "individu": [48, 99], "error": [48, 67, 93, 102, 109], "neg": 48, "placehold": [49, 94, 112], "int32": [50, 63, 67, 71, 72, 94, 95, 109, 113], "fp32": [50, 52, 67, 75, 100, 102, 109, 111], "fp16": 50, "optioanl": 50, "param": [50, 51, 86, 97], "request": [50, 52, 83], "min_val": [51, 102], "max_val": [51, 102], "observ": [51, 85, 94, 99, 100, 108, 109, 110, 111, 112, 113], "obtain": 51, "track": [51, 103, 104], "calibr": [51, 95, 108, 110, 111, 112], "mostli": [51, 69, 95], "input_dtyp": 52, "output_dtyp": [52, 71, 83], "uint8": [52, 83, 94, 100, 113], "b": [53, 90], "scales1": 53, "multipli": [53, 84, 99], "second": [53, 69, 90, 93, 94, 107, 113], "rais": [53, 66, 69, 84, 102, 104], "assertionerror": [53, 84, 102], "expect": [53, 93, 99, 102, 108, 109, 111, 112, 113], "qat": [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 91, 97, 111], "twostepquant": 54, "easili": [54, 108], "thei": [54, 93, 95, 99, 102, 109, 110, 113], "constructor": [54, 90, 102], "must": [54, 67, 69, 75, 93, 99, 103, 104, 110, 112, 113], "embed": [54, 56, 63, 66, 69, 71, 72], "my_quant": 54, "qatquantizer1": 54, "qatquantizer2": 54, "qatquantizer3": 54, "num_embed": [56, 71, 72], "embedding_dim": [56, 71, 72], "padding_idx": [56, 71, 72], "max_norm": [56, 71, 72], "norm_typ": [56, 71, 72], "scale_grad_by_freq": [56, 71, 72], "weight_config": [56, 57, 66, 69], "fakequantizeconfigbas": [56, 57, 66, 69], "intxfakequantizeconfig": [56, 57, 66, 68, 69], "fq_embed": 56, "longtensor": 56, "overridden": [56, 61, 71, 85], "within": [56, 61, 71, 85, 97, 99, 104, 111, 112], "afterward": [56, 61, 71, 85], "former": [56, 61, 71, 85], "care": [56, 61, 71, 85, 96, 99, 109], "hook": [56, 61, 71, 85, 94], "latter": [56, 61, 71, 85, 110], "silent": [56, 61, 71, 85, 111], "in_featur": [57, 74, 75, 93, 95, 96, 100, 102], "out_featur": [57, 74, 75, 93, 95, 100, 102], "activation_config": [57, 66, 69], "per_token": [57, 66, 67, 69], "is_symmetr": [57, 66, 67, 69], "fq_linear": 57, "scale_precis": [59, 63, 67, 71, 72], "rowwis": [59, 94], "hp_value_lb": 60, "hp_value_ub": 60, "float8fakequantizeconfig": 61, "fakequantizedembed": 62, "back": [62, 102], "model_with_fake_quantized_linear": 62, "zero_point_precis": [63, 67, 71, 72], "int4weightonlyqatembed": 63, "int4weightonlyembed": 63, "scales_precis": [64, 65, 74, 75], "padding_allow": 65, "valueerror": [66, 69], "torchaodtyp": 67, "is_dynam": [67, 111, 112, 113], "range_learn": 67, "simul": [67, 69, 87, 99], "older": 67, "int1": [67, 94], "int7": [67, 94], "pergroup": [67, 97], "pertoken": 67, "per_channel": 67, "peraxi": [67, 97, 100], "per_group": [67, 83], "combin": [67, 97, 99, 102, 109, 111], "leav": 67, "empti": [67, 94], "keyword": [67, 69, 81, 94], "properti": [67, 68], "throw": 67, "els": [67, 94, 97, 104, 109, 110], "symmetri": 68, "qatstep": 69, "awar": [69, 86, 91, 95, 99, 102], "ptq": [69, 110, 111], "automat": [69, 93, 97, 102, 103, 104, 107], "phase": [69, 113], "int4weightonlyconfig": [69, 78, 95, 96, 104], "experiment": [69, 108], "qat_config": 69, "act_config": 69, "alwai": [69, 97, 102], "One": [69, 99, 102, 104, 113], "enum": [70, 79], "example_input": [73, 95, 96, 100, 108, 109, 110, 111, 112, 113], "intxfakequantizerbas": 73, "weightonlyint4linear": 74, "hardcod": [75, 113], "mod": [76, 77, 93, 99, 102], "disabl": [76, 102, 110], "filter_fn": [78, 89], "_is_linear": [78, 100], "inplac": [78, 86, 95], "fulli": [78, 89, 97, 99, 109], "qualifi": [78, 89, 99], "final": [78, 94, 95, 99, 108, 109, 110, 111, 112, 113], "predefin": [78, 80, 113], "execut": [78, 98, 102, 106], "int8dynamicactivationint8weightconfig": [78, 89], "int4_weight_onli": 78, "sequenti": [78, 89, 93], "select": [79, 109], "found": [79, 94, 95, 97, 99, 100, 102], "nativ": [79, 91, 93, 94, 102, 109], "laid": [80, 94], "opaqu": 80, "decid": [80, 99, 100], "adopt": [80, 94], "creation": [81, 104], "construct": [81, 94, 109, 113], "from_hp": [81, 94], "cl": [81, 90, 100, 102, 104], "quant_kwarg": [81, 82], "quantizetensorkwarg": 82, "flexibl": [82, 99, 102, 108, 111], "variou": 82, "tabl": [83, 90, 93, 94, 99], "show": [83, 93, 95, 97, 99, 104, 109, 110], "per_tensor": 83, "per_axi": 83, "axi": [83, 100], "mat2": 84, "consid": [84, 99], "cubla": 84, "fallback": [84, 104], "j": 84, "l2": [85, 99], "norm": [85, 86, 99], "buffer": 85, "x_orig": 85, "sparsity_level": [86, 99], "semi_structured_block_s": 86, "wanda": 86, "sparsifi": [86, 91, 96, 99], "arxiv": [86, 99], "org": [86, 97, 99, 112], "ab": [86, 99], "2306": 86, "11695": 86, "product": [86, 97, 103, 104, 111, 113], "magnitud": [86, 99], "dict": [86, 90, 102, 104, 112, 113], "parametr": 86, "deepcopi": [86, 95, 100, 102, 110], "squash_mask": [86, 99], "params_to_keep": 86, "params_to_keep_per_lay": 86, "squash": 86, "mask": [86, 99], "appropri": [86, 108, 109, 110, 111, 112], "sparse_param": 86, "attach": [86, 99, 113], "kei": [86, 99, 107], "xdoctest": 86, "skip": [86, 94, 99], "local": [86, 97, 99], "hasattr": [86, 104], "submodule1": 86, "linear1": [86, 95, 96, 100, 102], "foo": [86, 109], "bar": [86, 109], "submodule2": 86, "linear42": 86, "baz": 86, "42": [86, 100], "24": 86, "ones": [86, 110], "update_mask": 86, "tensor_nam": [86, 104], "statist": [86, 99, 100, 109, 110], "retriev": 86, "act_per_input": 86, "Then": [86, 102, 112, 113], "whole": [86, 113], "alia": [88, 90, 104], "semisparseweightconfig": 88, "sparsify_": 89, "apply_tensor_subclass": 89, "essenti": [89, 104, 108], "semi_sparse_weight": 89, "semisparselayout": 89, "sparsemarlinlayout": 89, "isinst": [89, 93, 99, 100, 102, 104, 110, 113], "sparse_api": 89, "commonli": [90, 93, 99], "includ": [90, 93, 94, 102, 108, 111, 112, 113], "_get_to_kwarg": 90, "register_layout": 90, "plainaqttensorimpl": [90, 100], "get_tensor_impl_constructor": 90, "tensor_impl_ctr": 90, "simplifi": [90, 108, 109, 111, 112], "implment": 90, "tensor_data": 90, "optional_tensor_data_nam": 90, "boilerpl": 90, "optional_tensor_attribute_nam": 90, "__new__": [90, 102, 104], "exaclti": 90, "present": [90, 99], "__tensor_flatten__": [90, 102, 104], "flatten": 90, "attribute_nam": 90, "__tensor_unflatten__": [90, 102, 104], "tensor_data_dict": [90, 102, 104], "_apply_fn_to_data": [90, 104], "recreat": 90, "__repr__": [90, 102], "_same_metadata": 90, "between": [90, 94, 99, 102, 104, 108, 110, 111, 113], "__setstate__": 90, "serial": [90, 91, 94, 103, 109, 110], "old": 90, "maintain": [90, 97, 99], "bc": 90, "contigu": [90, 94, 111, 112], "detach": [90, 102, 104], "clone": [90, 97, 104], "copy_": [90, 104], "_to_copi": [90, 104], "f": [90, 93, 94, 96, 97, 99, 100, 102, 104, 109, 110], "h": [90, 97], "layout_class": 90, "tensorimplclass": 90, "from_plain": 90, "tensor_class": 90, "aten_op": 90, "decor": [90, 102, 104], "__torch_dispatch__": [90, 102], "implements_torch_funct": 90, "torch_fn": 90, "__torch_function__": [90, 94, 102], "registr": 90, "aqt": 90, "introduct": [91, 94, 97], "highlight": [91, 102, 107], "guid": [91, 94, 97, 108], "contributor": [91, 94, 95], "benchmark": [91, 93, 95, 103, 108, 111, 112], "tune": [91, 93, 97, 99, 108], "vllm": [91, 103], "sglang": [91, 103], "hug": [91, 97], "face": [91, 94, 97, 99, 109], "advanc": [91, 100, 102, 108, 111, 112], "export": [91, 94], "x86": [91, 95], "intel": [91, 108, 111], "openvino": [91, 95], "5x": 93, "cluster": [93, 94], "34": 93, "43x": 93, "2k": 93, "h200": 93, "latest": 93, "offic": 93, "offici": [93, 94], "sever": [93, 104, 108, 113], "popular": 93, "flagship": 93, "form": [93, 94, 99], "quickli": [93, 102], "batteri": 93, "fork": 93, "build": [93, 94, 99, 102, 104, 109], "top": [93, 94, 102, 108, 109, 110, 111, 112], "virtual": 93, "environ": [93, 97], "conda": 93, "venv": 93, "download": [93, 97, 105, 107, 109, 110, 112], "job": 93, "below": [93, 94, 99, 102, 103, 104, 107, 108], "root": [93, 97], "launch": 93, "ngpu": 93, "config_fil": 93, "train_config": 93, "llama3_8b": 93, "toml": 93, "run_train": 93, "sh": [93, 97], "hyperparamet": 93, "edit": [93, 97], "line": [93, 99, 103], "flag": [93, 110], "termin": 93, "rank0": 93, "titan": 93, "2025": 93, "06": 93, "04": 93, "08": 93, "51": 93, "48": 93, "info": 93, "2254": 93, "27": 93, "34gib": 93, "28": 93, "78": 93, "tp": [93, 104], "375": 93, "tflop": 93, "21": 93, "73": [93, 100], "mfu": 93, "20": [93, 97, 110], "58": 93, "557": 93, "7069": 93, "99gib": 93, "62": 93, "034": 93, "35": [93, 97, 100], "41": [93, 97], "19": 93, "52": 93, "224": [93, 100, 108, 109, 110, 111, 112], "9196": 93, "022": 93, "406": [93, 109, 110], "65": 93, "904": 93, "1423": 93, "014": 93, "23": [93, 100], "As": [93, 109, 113], "warmup": 93, "7k": 93, "99gb": 93, "peak": [93, 97, 103], "against": 93, "02": 93, "37": 93, "404": 93, "2611": 93, "22gib": 93, "595": 93, "47": 93, "49": [93, 100], "027": 93, "4260": 93, "89gib": 93, "344": 93, "367": 93, "39": 93, "03": 93, "01": 93, "988": 93, "9482": 93, "321": 93, "366": 93, "14": 93, "991": 93, "1183": 93, "300": 93, "364": 93, "89": 93, "40": 93, "4659": 93, "291": 93, "84": 93, "769": 93, "gc": 93, "peform": 93, "period": 93, "collect": [93, 99], "3k": 93, "89gb": 93, "11x": 93, "nearli": 93, "ident": [93, 99], "performan": 93, "vs": [93, 99, 109, 113], "curv": [93, 99], "omit": [93, 94, 109, 110, 111], "648": 93, "2648": 93, "28gib": 93, "71": 93, "26": 93, "475": 93, "9106": 93, "91gib": 93, "53": [93, 97], "503": 93, "434": 93, "43": 93, "94": [93, 109], "166": 93, "0774": 93, "663": 93, "443": 93, "44": [93, 100], "87": 93, "50": [93, 99, 100, 108, 109, 111, 112], "885": 93, "3233": 93, "643": 93, "442": 93, "66": [93, 97, 100], "76": 93, "613": 93, "6150": 93, "637": 93, "72": [93, 97], "6k": 93, "91gb": 93, "21x": [93, 97], "tl": 93, "dr": 93, "priorit": 93, "accur": [93, 99, 108], "stabil": 93, "cost": [93, 100], "slightli": [93, 102], "impact": [93, 97, 104], "outlier": 93, "caus": 93, "underflow": 93, "8xh100": 93, "box": [93, 99, 111], "toi": [93, 95, 100, 102, 111], "convert_to_float8_train": 93, "recurs": 93, "kind": [93, 109], "over": [93, 99, 109, 110], "gemm": [93, 111, 112], "snippet": [93, 109, 110], "float8_linear_util": 93, "float8_linear": 93, "sampl": [93, 109, 111, 112], "adamw": 93, "being": [93, 99, 104, 111, 112], "elig": 93, "divis": 93, "label": 93, "fake_label": 93, "ones_lik": 93, "mse_loss": 93, "model_state_dict": 93, "state_dict": [93, 96, 109, 110], "optimizer_state_dict": 93, "pth": [93, 109, 110], "explor": [93, 95, 112], "few": [93, 102, 109, 110], "lai": 94, "stack": [94, 97], "awq": 94, "gptq": 94, "int4tensor": 94, "int4preshuffledtensor": 94, "uint1": 94, "uint7": 94, "float3": 94, "triton": [94, 111, 112], "overload": [94, 99], "term": [94, 99, 109, 113], "extra": [94, 97], "matter": [94, 99], "float4_e2m1fn_x2": 94, "float8_e4m3fnuz": 94, "float8_e5m2": 94, "float8_e5m2fnuz": 94, "float8_e8m0fnu": 94, "pr": 94, "shell": 94, "dervi": 94, "mxfp8": 94, "preicison": 94, "mention": [94, 109], "previou": [94, 97, 109, 110, 111, 112], "accommod": 94, "choose_qparams_affine_with_min_max": 94, "min": [94, 100, 102, 109, 113], "raw": 94, "quantize_fp8_row": 94, "int_matmul": 94, "int_scaled_matmul": 94, "reli": [94, 95, 99, 100, 102], "handwritten": 94, "On": [94, 95], "glue": 94, "everyth": 94, "togeth": [94, 97, 109, 111, 113], "anoth": [94, 99, 102, 109, 113], "side": 94, "swizzl": 94, "dtpype": 94, "act": 94, "adjac": 94, "special": [94, 99, 108, 109], "float8rowwisetensor": 94, "float8blockwisetensor": 94, "close": [94, 99], "low_precision_v": 94, "high_precision_v": 94, "procedur": 94, "especi": [94, 96, 99, 111, 112], "bitwidth": [94, 113], "codebook": 94, "index": [94, 97, 99, 112], "vector": [94, 99, 111], "kmean": 94, "tradition": 94, "explain": [94, 108, 111], "simplest": [94, 99], "easi": [94, 97], "linear_modul": 94, "runtim": [94, 109], "question": [94, 96, 99, 102, 113], "activation_granular": 94, "act_quant_kwarg": 94, "weight_granular": [94, 97], "quantized_weight": [94, 104], "float8_dtyp": 94, "haven": 94, "seen": 94, "pt2": [94, 102, 111], "autoround": 94, "multitensor": 94, "sure": [94, 97, 113], "open": [94, 99], "describ": [94, 96, 99, 107, 109, 110], "finetun": [94, 97], "quantized_train": 94, "progress": [94, 103, 104], "lot": [94, 99], "connect": [94, 113], "walk": [94, 100, 102, 107, 108, 111], "float8dynamicactivationfloat8weightconfig": 94, "len": [94, 97, 104, 109, 110, 113], "_choose_quant_func_and_quantize_tensor": 94, "relat": [94, 99], "xq": 94, "reshap": [94, 109, 110], "wq": 94, "x_scale": [94, 109], "w_scale": 94, "out_shap": 94, "entri": 95, "mutat": 95, "logic": [95, 102, 104], "toylinearmodel": [95, 96, 100], "linear2": [95, 96, 100, 102], "eval": [95, 96, 97, 100, 108, 110, 111, 112], "faster": [95, 99], "model_bf16": 95, "uint4": 95, "int4mm": 95, "mix": [95, 97, 108, 111, 112], "tile_packed_to_4d": 95, "stai": [95, 102], "tensor_impl_dtyp": 95, "roughli": [95, 99], "quarter": 95, "os": [95, 109, 110], "int4_model": 95, "pt": [95, 97], "bfloat16_model": 95, "int4_model_size_mb": 95, "getsiz": [95, 109, 110], "bfloat16_model_size_mb": 95, "2f": [95, 109, 110], "mb": [95, 96, 98, 106, 109, 110], "00": [95, 98, 106], "benchmark_model": 95, "unwrap_tensor_subclass": 95, "num_run": 95, "100": [95, 102, 109, 110], "_dynamo": [95, 102], "reset": [95, 109, 110], "bf16_time": 95, "int4_tim": 95, "time": [95, 99, 102, 103, 107, 108, 109, 110], "3f": [95, 110], "ms": 95, "1fx": 95, "393": 95, "410": 95, "9x": 95, "recogn": [95, 113], "decis": 95, "pt2e": [95, 108, 109, 110, 111, 112], "fuse": [95, 99, 102, 110], "deleg": [95, 109], "x86inductorquant": [95, 111], "quantize_pt2": [95, 108, 109, 110, 111, 112], "prepare_pt2": [95, 108, 109, 111, 112], "x86_inductor_quant": [95, 111], "get_default_x86_inductor_quantization_config": [95, 111], "float_model": [95, 102, 108, 109, 110, 111, 112], "data_load": [95, 109, 110, 111, 112], "no_grad": [95, 102, 108, 109, 110, 111, 112], "imag": [95, 103, 108, 109, 110, 111, 112], "program": [95, 109, 110, 111, 113], "captur": [95, 109, 110, 113], "expos": [95, 109, 110], "set_glob": [95, 109, 110, 111, 112], "xiq": [95, 111], "prepare_qat_pt2": [95, 110, 111], "sample_inference_data": 95, "convert_pt2": [95, 108, 109, 110, 111, 112], "wrapper": [95, 102, 111], "_inductor": [95, 111], "cpp_wrapper": [95, 111], "optimized_model": [95, 108, 111, 112], "converted_model": [95, 111, 112], "xpu": [95, 112], "simpl": [95, 99, 100, 102, 108, 111, 112], "visit": 95, "would": [95, 99, 102, 110, 112], "forget": 95, "tempfil": [96, 103], "get_model_size_in_byt": 96, "ref": [96, 109], "namedtemporaryfil": 96, "seek": [96, 99], "m_load": 96, "load_state_dict": [96, 109, 110], "assign": 96, "assert": [96, 100, 102, 104, 113], "equal": [96, 99], "thing": [96, 99, 102, 109], "float_weight1": 96, "float_weight2": 96, "quantized_weight1": 96, "quantized_weight2": 96, "go": [96, 102, 107, 113], "techinqu": 96, "reduct": [96, 97, 99, 102], "4x": [96, 97], "0625": 96, "reason": [96, 99], "avoid": [96, 99], "affine_quantized_tensor": 96, "deploi": 97, "engin": 97, "seamlessli": [97, 102, 111, 112], "seamless": [97, 111], "hf": [97, 103], "signific": [97, 99], "pip": [97, 103, 108, 109], "url": [97, 112], "whl": [97, 112], "nightli": 97, "cu128": 97, "push": [97, 99, 103, 104], "hub": [97, 103, 104], "server": [97, 104], "phi": 97, "fp8": 97, "microsoft": 97, "o3": 97, "client": 97, "curl": 97, "localhost": 97, "8000": 97, "chat": 97, "content": 97, "applic": 97, "messag": 97, "role": 97, "give": [97, 99, 102], "me": 97, "short": 97, "larg": [97, 102, 111], "languag": 97, "temperatur": 97, "top_p": 97, "95": 97, "top_k": 97, "max_token": 97, "32768": 97, "vram": 97, "15x": 97, "2x": [97, 99], "littl": [97, 104], "packag": [97, 103], "git": [97, 103], "acceler": [97, 99, 103], "autotoken": [97, 103], "pipelin": 97, "random": [97, 99, 109, 110], "manual_se": [97, 109, 110], "model_path": 97, "device_map": [97, 103, 104], "trust_remote_cod": 97, "ai": 97, "assist": 97, "eat": 97, "banana": 97, "dragonfruit": 97, "smoothi": 97, "blend": 97, "milk": 97, "honei": 97, "salad": 97, "slice": [97, 104], "lemon": 97, "juic": 97, "solv": [97, 99, 102], "equat": 97, "pipe": [97, 103], "text": 97, "generation_arg": 97, "max_new_token": 97, "500": 97, "return_full_text": 97, "do_sampl": 97, "generated_text": 97, "lm_head": 97, "those": [97, 99, 100, 102], "ti": 97, "autoprocessor": 97, "modeling_util": 97, "find_tied_paramet": 97, "model_id": [97, 103], "untied_model": 97, "getattr": [97, 104], "get_text_config": 97, "tie_word_embed": 97, "setattr": [97, 102], "_tied_weights_kei": 97, "user_id": 97, "your_user_id": 97, "model_nam": [97, 108, 111, 112], "save_to": [97, 103], "save_to_local_path": 97, "int8dynamicactivationintxweightconfig": 97, "ve": [97, 99], "intxweightonlyconfig": 97, "fqntoconfig": [97, 104], "untied_model_id": 97, "untied_model_local_path": 97, "embedding_config": 97, "linear_config": 97, "weight_scale_dtyp": 97, "quant_config": 97, "_default": [97, 104], "embed_token": 97, "quant_typ": [97, 103, 104], "include_embed": 97, "untie_embedding_weight": 97, "modules_to_not_convert": 97, "quantized_model": [97, 102, 103, 108, 109, 110], "safe_seri": [97, 103, 104], "pte": 97, "cd": 97, "install_requir": 97, "phi_4_mini": 97, "convert_weight": 97, "pytorch_model": 97, "bin": 97, "pytorch_model_convert": 97, "export_llama": 97, "kv": 97, "use_sdpa_with_kv_cach": 97, "get_bos_id": 97, "199999": 97, "get_eos_id": 97, "200020": 97, "max_seq_length": 97, "max_context_length": 97, "output_nam": 97, "phi4": 97, "phone": 97, "io": 97, "2gb": 97, "iphon": 97, "pro": [97, 99], "17": 97, "sec": 97, "test": [97, 103, 107, 109, 111], "lm": 97, "har": 97, "eleutherai": 97, "lm_eval": 97, "model_arg": 97, "pretrain": [97, 99, 108, 109, 110, 111], "reset_peak_memory_stat": 97, "prompt": [97, 103], "hei": 97, "consciou": 97, "templated_prompt": 97, "apply_chat_templ": 97, "add_generation_prompt": 97, "templat": [97, 98, 105, 106], "return_tensor": 97, "generated_id": 97, "output_text": 97, "batch_decod": 97, "skip_special_token": 97, "clean_up_tokenization_spac": 97, "respons": 97, "mem": [97, 98, 106], "max_memory_reserv": 97, "1e9": 97, "02f": 97, "gb": 97, "hello": [97, 103], "ye": 97, "am": 97, "digit": 97, "todai": 97, "70": [97, 100], "bench": 97, "vllm_disable_compile_cach": 97, "project": 97, "vllm_use_precompil": 97, "sharegpt": 97, "wget": 97, "co": 97, "anon8231489123": 97, "sharegpt_vicuna_unfilt": 97, "resolv": 97, "sharegpt_v3_unfiltered_cleaned_split": 97, "tree": 97, "num": 97, "benchmark_serv": 97, "16x": 97, "1s": 97, "14x": 97, "num_prompt": 97, "req": 97, "57": [97, 100], "1000": [97, 111], "68": 97, "80": 97, "entir": [97, 109, 110], "ml": 97, "gain": [97, 99, 112], "eas": 97, "accept": [97, 113], "trade": [97, 99], "off": [97, 99], "004": [98, 106, 107], "total": [98, 106, 107], "galleri": [98, 105, 107], "tutorials_sourc": 98, "template_tutori": [98, 106, 107], "neural": [99, 108, 111], "network": [99, 102, 108, 111], "latenc": 99, "carefulli": 99, "pai": 99, "low": [99, 102, 103, 108], "price": 99, "f1": 99, "problem": [99, 102], "research": [99, 107], "fragment": 99, "rightfulli": 99, "spent": 99, "figur": [99, 109], "compress": [99, 108], "place": [99, 108, 109, 110, 111, 112], "dens": 99, "focu": [99, 102], "realli": 99, "concret": [99, 113], "hope": 99, "modular": 99, "nice": 99, "scratch": [99, 107], "minim": [99, 108, 111, 112], "algorthim": 99, "realiz": 99, "theoret": 99, "analog": 99, "fix": [99, 100], "unstructur": 99, "retrain": 99, "neglig": 99, "area": 99, "agre": 99, "upon": 99, "consensu": 99, "mind": 99, "thought": 99, "subproblem": 99, "satisfi": 99, "my": [99, 110], "independ": 99, "frontend": [99, 111], "arbitrari": 99, "handoff": 99, "piec": 99, "natur": [99, 102, 109, 113], "clear": 99, "contract": 99, "7x": 99, "advantag": 99, "anticip": 99, "solut": 99, "third": 99, "parti": 99, "to_sparse_semi_structur": 99, "sparsesemistructuredtensor": 99, "weightnormsparsifi": 99, "half": 99, "subnetwork": 99, "sparse_config": 99, "named_modul": 99, "tensor_fqn": 99, "sparse_block_shap": 99, "zeros_per_block": 99, "fakespars": 99, "fundament": [99, 110], "manipul": 99, "dictionari": 99, "paramer": 99, "parameter": 99, "necessari": [99, 100, 102, 108, 109, 110, 111, 112], "suitabl": [99, 111], "0s": 99, "spot": 99, "definit": [99, 104], "academia": 99, "industri": 99, "often": [99, 102], "interchang": 99, "distinct": 99, "idea": 99, "behind": 99, "doesn": [99, 110, 113], "itself": [99, 102], "loos": 99, "speak": 99, "tightli": 99, "coupl": [99, 102], "csc": 99, "qnnpack": 99, "descript": [99, 108], "coo": 99, "sparse_coo": 99, "coordin": 99, "locat": 99, "bsr": 99, "sparse_bsr": 99, "veri": [99, 104, 110], "except": [99, 102, 113], "scalar": [99, 109], "dimension": 99, "csr": 99, "sparse_csr": 99, "sparse_csc": 99, "column": 99, "compact": 99, "sparse_matrix": 99, "1d": 99, "indexptr": 99, "\u00bd": 99, "bitmask": 99, "2bit": 99, "unprun": 99, "quit": [99, 102], "broken": 99, "down": 99, "sensit": 99, "effect": [99, 100, 102, 111, 112, 113], "best": [99, 111], "subsequ": [99, 102, 111, 112], "infinit": 99, "lost": 99, "degre": 99, "drop": 99, "proxi": 99, "aforement": 99, "smallest": 99, "absolut": 99, "scope": 99, "impli": 99, "con": 99, "potenti": [99, 100, 108, 109, 111, 112], "sub": 99, "span": 99, "threshold": 99, "constant": [99, 102, 109], "ctr_mobile_fe": 99, "score": 99, "w": [99, 104], "tenosr": 99, "udpat": 99, "histori": 99, "regrow": 99, "dw": 99, "via": [99, 108], "backprop": 99, "pat": 99, "unmask": 99, "resid": 99, "salienc": 99, "lowest": 99, "l1": 99, "abl": [99, 102, 104, 109, 113], "repeat": [99, 109, 110], "movement": 99, "2005": 99, "07683": 99, "rank": [99, 102], "wx": 99, "sqx": 99, "q": [99, 109], "usual": 99, "sort": 99, "wise": 99, "reconstruct": [99, 104], "randomli": 99, "tri": 99, "remedi": 99, "sometim": 99, "item": [99, 107], "ultim": [99, 100], "complic": [99, 109], "literatur": 99, "vision": 99, "nlp": [99, 107, 111], "iter": [99, 109, 110], "ctr_feed": 99, "na": 99, "multimask": 99, "search": 99, "pyspeech": 99, "fastna": 99, "approach": [99, 102, 108, 111, 112], "knowledg": [99, 107], "distil": 99, "pdf": 99, "2204": 99, "09656": 99, "arrang": 99, "recal": 99, "counterpart": 99, "slower": 99, "suffici": 99, "At": [99, 109], "98": 99, "exhibit": 99, "penalti": 99, "expens": [99, 102], "dictat": 99, "characterist": 99, "highest": 99, "wouldn": [99, 102], "visual": 99, "fig": 99, "4x4": 99, "benchmak": 99, "fly": [100, 103], "affinequantizedminmaxobserv": 100, "record": 100, "welcom": 100, "averag": [100, 109, 110], "histogram": [100, 109], "act_ob": 100, "finfo": 100, "weight_ob": 100, "observedlinear": 100, "observed_input": 100, "observed_weight": 100, "from_float": [100, 102], "float_linear": 100, "observed_linear": 100, "_replace_with_custom_fn_if_matches_filt": 100, "insert_observers_": 100, "lambda": [100, 104], "replacement_fn": 100, "copied_act_ob": 100, "copied_weight_ob": 100, "popul": 100, "feed": 100, "simpler": [100, 109], "quantizedlinear": [100, 102], "isn": 100, "strictli": 100, "to_affine_quantized_intx_stat": 100, "act_scal": [100, 113], "act_zero_point": 100, "calculate_qparam": [100, 113], "weight_scal": [100, 109, 113], "weight_zero_point": [100, 109], "qweight": 100, "qinput": 100, "from_observ": 100, "quantized_linear": [100, 109], "begin": [100, 102], "dataclass": [100, 104, 113], "transform_modul": [100, 104], "register_quantize_module_handl": [100, 104], "staticquantconfig": 100, "_apply_static_qu": 100, "associ": 100, "identifi": [100, 113], "is_observed_linear": 100, "optimizedmodul": 100, "_orig_mod": 100, "0237": 100, "142": 100, "31": [100, 113], "113": 100, "157": 100, "59": 100, "160": 100, "150": 100, "67": 100, "241": 100, "238": 100, "235": 100, "228": 100, "255": [100, 113], "201": 100, "114": 100, "236": 100, "88": [100, 109], "83": 100, "109": 100, "209": 100, "92": 100, "184": 100, "141": 100, "110": 100, "0009": 100, "0010": 100, "130": 100, "122": 100, "132": 100, "125": 100, "126": 100, "129": 100, "127": [100, 102, 112, 113], "133": 100, "124": 100, "131": 100, "135": 100, "136": 100, "foundat": 102, "autograd": [102, 113], "interpos": 102, "namespac": 102, "continu": [102, 110, 111, 112, 113], "obviou": 102, "int8quantizedlinear": 102, "finer": 102, "intercept": 102, "contrast": 102, "clunki": 102, "distributedlinear": 102, "duplic": 102, "bypass": 102, "wrap": [102, 111, 112], "outer": 102, "inner": 102, "allgath": 102, "bandwidth": 102, "exactli": 102, "zoo": 102, "podcast": 102, "edward": 102, "yang": 102, "int8_symmetric_quant": 102, "fp32_tensor": 102, "amin": 102, "keepdim": [102, 109, 110], "amax": 102, "zeros_lik": 102, "view": [102, 109, 110], "clamp": [102, 109], "w_int8": 102, "new_linear": 102, "left": [102, 113], "toymodel": 102, "child": 102, "named_children": 102, "drawback": 102, "won": 102, "suppos": 102, "clean": 102, "eleg": 102, "pretti": 102, "power": [102, 104], "overrid": 102, "almost": 102, "shard": [102, 104], "ragged": 102, "rag": 102, "nestedtensor": 102, "who": 102, "link": [102, 107], "why": [102, 107], "googl": 102, "collab": 102, "flopcount": 102, "memorytrack": 102, "bare": 102, "bone": 102, "int8symmetrictensor": 102, "hold": [102, 103], "staticmethod": 102, "_make_wrapper_subclass": [102, 104], "storage_offset": 102, "ndim": 102, "extra_metadata": 102, "outer_s": [102, 104], "outer_strid": [102, 104], "undo": 102, "repr": 102, "ahead": 102, "insid": 102, "int8_tensor": 102, "op_implementations_dict": 102, "conveni": 102, "register_op": 102, "_op": 102, "opoverload": 102, "impl_decor": 102, "op_impl": 102, "done": 102, "particular": 102, "largest": 102, "tell": 102, "desugar": 102, "surfac": 102, "coverag": [102, 108, 109, 111, 112], "brute": 102, "forc": 102, "repeatedli": 102, "log": 102, "loggingtensor": 102, "_python_dispatch": [102, 104], "return_and_correct_alias": [102, 104], "int8_mm": 102, "int8_view_op": 102, "out_data": 102, "out_scal": [102, 109], "notic": 102, "hit": 102, "background": 102, "decomposit": 102, "live": 102, "decomp": 102, "shrink": 102, "author": [102, 107, 108, 109, 110, 111, 112, 113], "But": [102, 104, 113], "pain": 102, "rather": 102, "worth": 102, "written": 102, "differenti": 102, "nuanc": 102, "longer": [102, 109, 110], "had": [102, 109], "That": 102, "transposit": 102, "got": [102, 109, 113], "propag": [102, 109, 111, 112], "fact": 102, "themselv": [102, 109], "pointwis": [102, 111, 112], "were": 102, "might": [102, 104, 109, 113], "unwrap": 102, "dim0": 102, "dim1": 102, "confirm": 102, "quantized_model_module_swap": 102, "quantized_model_subclass": 102, "subclass_param": 102, "out_module_swap": 102, "allclos": 102, "out_compil": 102, "seri": 102, "discuss": 102, "float8dynamicactivationint4weightconfig": 103, "torch_dtyp": 103, "fluxpipelin": 103, "fluxtransformer2dmodel": 103, "black": 103, "forest": 103, "lab": 103, "flux": 103, "dev": 103, "subfold": 103, "cat": [103, 113], "sign": [103, 112], "world": [103, 104], "num_inference_step": 103, "guidance_scal": 103, "png": 103, "temporarydirectori": 103, "tmp_dir": 103, "uncom": 103, "usernam": [103, 104], "statu": [103, 104], "due": [103, 104, 108, 113], "int4wo": 103, "workaround": [103, 104], "team": [103, 104], "retain": 103, "thoroughli": 103, "e2": 104, "_type": 104, "_data": 104, "capabl": [104, 109, 111], "self_attn": 104, "q_proj": 104, "k_proj": 104, "mlp": 104, "gate_proj": 104, "narrow": 104, "chunk": 104, "heavi": 104, "codebas": 104, "fn": 104, "ctx": 104, "new_tensor": 104, "__class__": 104, "principl": 104, "mynewquantconfig": 104, "classvar": 104, "myquantizedtensor": 104, "tensor_data_attr": 104, "tensor_attribut": 104, "attr": 104, "fill_default": 104, "notimplementederror": 104, "_my_quant_transform": 104, "my_quantization_funct": 104, "use_cutlass_kernel": 104, "my_cutlass_linear": 104, "use_triton_kernel": 104, "my_triton_linear": 104, "disappear": 104, "unless": 104, "extrem": 104, "sole": 104, "explicitli": [104, 113], "spooki": 104, "distanc": 104, "2338": 104, "detect": 104, "illustr": 104, "tutorials_python": 105, "zip": [105, 107], "jupyt": [105, 107], "notebook": [105, 107], "tutorials_jupyt": 105, "sphinx": [105, 107], "firstnam": 107, "lastnam": 107, "prerequisit": [107, 109], "topic": 107, "rand": [107, 109, 110], "7482": 107, "4445": 107, "5379": 107, "8237": 107, "0356": 107, "0983": 107, "6141": 107, "4512": 107, "6810": 107, "1303": 107, "3497": 107, "7027": 107, "9145": 107, "1851": 107, "8314": 107, "practic": 107, "summar": 107, "takeawai": 107, "link1": 107, "link2": 107, "minut": 107, "ipynb": 107, "daniil": 108, "lyakhov": 108, "aamir": 108, "nazir": 108, "alexand": 108, "suslov": 108, "yamini": 108, "nimmagadda": 108, "kozlov": 108, "subject": [108, 110], "openvinoquant": 108, "unlock": 108, "placement": 108, "ux": [108, 109, 111], "torchdynamo": [108, 111, 112, 113], "eager": [108, 109, 110, 111, 112, 113], "mechan": [108, 111, 112], "torchvis": [108, 109, 110, 111, 112, 113], "resnet18": [108, 109, 110, 111, 112], "u": 108, "__dict__": [108, 109, 110, 111, 112], "dummi": [108, 111, 112], "traced_b": [108, 111, 112], "exported_model": [108, 109, 110, 111, 112], "preset": 108, "elu": 108, "prelu": 108, "gelu": 108, "quantizationpreset": 108, "bert": [108, 111], "modeltyp": 108, "ignored_scop": 108, "exclud": 108, "layer_1": 108, "layer_2": 108, "layer_3": 108, "ignoredscop": 108, "conv2d": [108, 109, 110, 111, 112, 113], "regex": 108, "layer_": 108, "subgraph": [108, 110], "node": [108, 110, 111, 112, 113], "target_devic": 108, "taken": 108, "account": 108, "cpu_spr": 108, "npu": 108, "targetdevic": 108, "fold": [108, 109, 111, 112], "batchnorm": [108, 109, 110, 111, 112], "preced": [108, 109, 111, 112], "prepared_model": [108, 109, 110, 111, 112], "fold_quant": 108, "finish": [108, 111], "comparison": 108, "smoothquant": 108, "biascorrect": 108, "discrep": 108, "calibration_load": 108, "dataload": [108, 109, 110], "transform_fn": 108, "data_item": 108, "calibration_dataset": 108, "smooth_quant": 108, "fast_bias_correct": 108, "deploy": [108, 111], "jerri": [109, 111, 113], "zhang": [109, 111, 112, 113], "_export": [109, 110], "fx": [109, 113], "14k": 109, "programm": [109, 111, 112], "db": 109, "xnnpack": [109, 110, 113], "xnnpack_quant": [109, 110], "get_symmetric_quantization_config": [109, 110], "xnnpackquant": [109, 110, 113], "prior": 109, "qconfigmap": [109, 113], "backendconfig": [109, 113], "rel": 109, "intent": [109, 113], "qconfig": [109, 113], "3d": [109, 113], "incompat": 109, "great": 109, "ideal": 109, "fake_qu": 109, "hidden": 109, "summari": 109, "address": 109, "thu": 109, "queri": [109, 113], "becom": 109, "previous": 109, "embedding_byt": 109, "executorchquant": 109, "concaten": 109, "prone": 109, "cleaner": 109, "composed_quant": 109, "quantization_cap": 109, "concern": 109, "decoupl": 109, "minmax": 109, "freed": 109, "identitc": 109, "imagenet": [109, 110], "unzip": [109, 110], "data_path": [109, 110], "renam": [109, 110], "resnet18_pretrained_float": [109, 110], "sy": [109, 110], "numpi": [109, 110], "np": [109, 110], "resnet": [109, 110, 111], "warn": [109, 110], "filterwarn": [109, 110], "categori": [109, 110], "deprecationwarn": [109, 110], "r": [109, 110], "seed": [109, 110], "191009": [109, 110], "averagemet": [109, 110], "fmt": [109, 110], "val": [109, 110], "avg": [109, 110], "count": [109, 110], "__str__": [109, 110], "fmtstr": [109, 110], "topk": [109, 110], "predict": [109, 110], "maxk": [109, 110], "pred": [109, 110], "eq": [109, 110], "expand_a": [109, 110], "correct_k": [109, 110], "mul_": [109, 110], "criterion": [109, 110], "top1": [109, 110], "top5": [109, 110], "cnt": [109, 110], "acc1": [109, 110], "acc5": [109, 110], "load_model": [109, 110], "model_fil": [109, 110], "weights_onli": [109, 110], "print_size_of_model": [109, 110], "temp": [109, 110], "p": [109, 110], "1e6": [109, 110], "prepare_data_load": [109, 110], "485": [109, 110], "456": [109, 110], "std": [109, 110], "229": [109, 110], "225": [109, 110], "randomresizedcrop": [109, 110], "randomhorizontalflip": [109, 110], "totensor": [109, 110], "dataset_test": [109, 110], "resiz": [109, 110], "centercrop": [109, 110], "train_sampl": [109, 110], "randomsampl": [109, 110], "test_sampl": [109, 110], "sequentialsampl": [109, 110], "train_batch_s": [109, 110], "sampler": [109, 110], "data_loader_test": [109, 110, 111, 112], "eval_batch_s": [109, 110], "saved_model_dir": [109, 110], "float_model_fil": [109, 110], "model_to_quant": [109, 110], "capture_pre_autograd_graph": [109, 110], "dynamic_shap": [109, 110], "dynamic_dim": [109, 110], "constraint": [109, 110, 113], "qconfig_opt": 109, "set_object_typ": 109, "set_module_nam": 109, "workload": 109, "themodel": 109, "feedback": 109, "dq": 109, "fp32_op": 109, "qauntiz": 109, "x_int8": 109, "x_zero_point": 109, "weight_int8": 109, "bias_fp32": 109, "output_scal": 109, "output_zero_point": 109, "x_fp32": 109, "quantized_decompos": 109, "dequantize_per_tensor": 109, "x_i8": 109, "x_quant_min": 109, "x_quant_max": 109, "weight_fp32": 109, "weight_i8": 109, "weight_quant_min": 109, "weight_quant_max": 109, "weight_permut": 109, "permute_copi": 109, "out_fp32": 109, "addmm": 109, "out_i8": 109, "quantize_per_tensor": 109, "out_zero_point": 109, "out_quant_min": 109, "out_quant_max": 109, "float32_op": 109, "decompos": 109, "use_reference_represent": 109, "x_int16": 109, "weight_int16": 109, "acc_int32": 109, "out_dtyp": 109, "bias_scal": 109, "bias_int32": 109, "div": 109, "mul": 109, "out_int8": 109, "qmin": 109, "qmax": 109, "date": 109, "unus": 109, "serila": 109, "consult": 109, "exportedprogram": 109, "pt2e_quantized_model_file_path": 109, "resnet18_pt2e_quant": 109, "quantized_ep": 109, "loaded_quantized_ep": 109, "loaded_quantized_model": 109, "diff": 109, "79": 109, "82": 109, "55": 109, "edg": [109, 113], "went": 109, "andrew": 110, "Or": 110, "move_exported_model_to_ev": [110, 111], "correctli": 110, "certain": 110, "dropout": 110, "move_exported_model_to_train": 110, "jit": 110, "recursivescriptmodul": 110, "train_one_epoch": 110, "ntrain_batch": 110, "avgloss": 110, "5f": 110, "start_tim": 110, "global_avg": 110, "is_qat": [110, 111], "fusion": 110, "batchnorm2d": 110, "_native_batch_norm_legit": 110, "cudnn_batch_norm": 110, "mobilenetv2": 110, "manual": 110, "recompil": 110, "consolid": 110, "epoch": 110, "far": 110, "num_epoch": 110, "num_train_batch": 110, "num_eval_batch": 110, "num_observer_update_epoch": 110, "num_batch_norm_update_epoch": 110, "num_epochs_between_ev": 110, "nepoch": 110, "stat": 110, "subseq": 110, "disable_observ": 110, "bn": 110, "running_mean": 110, "running_var": 110, "new_arg": 110, "wish": 110, "prepared_model_copi": 110, "neval_batch": 110, "paus": 110, "resum": 110, "fail": [110, 113], "checkpoint_path": 110, "checkpoint_": 110, "behav": 110, "incorrectli": 110, "lesli": [111, 113], "fang": [111, 113], "weiwen": [111, 113], "xia": [111, 113], "jiong": [111, 113], "gong": [111, 113], "cnn": 111, "rnn": 111, "outstand": 111, "fourth": 111, "spr": 111, "xeon": 111, "processor": 111, "boost": 111, "channels_last": [111, 112], "onednn": [111, 112], "assum": [111, 113], "word": 111, "satur": 111, "pure": 111, "dedic": 111, "scenario": [111, 112], "plai": [111, 112], "convolut": [111, 112, 113], "absenc": [111, 112], "enhanc": [111, 112], "mirror": [111, 112], "autocast": [111, 112], "device_typ": [111, 112], "turn": [111, 112], "cpp": 111, "qconvolut": [111, 112], "qlinear": [111, 112], "presenc": [111, 112], "pair": [111, 112], "remain": [111, 112], "conting": [111, 112], "qmaxpool2d": [111, 112], "torchinductor_freez": [111, 112], "example_x86inductorquantizer_pytorch_2_1": 111, "torchbench": 111, "measur": 111, "proven": 111, "depth": 111, "example_x86inductorquantizer_qat": 111, "yan": 112, "zhiwei": 112, "wang": 112, "eikan": 112, "liangang": 112, "liu": 112, "river": 112, "cui": 112, "yifeng": 112, "xpuinductorquant": 112, "pip3": 112, "torchaudio": 112, "xpu_inductor_quantizer_exampl": 112, "xpu_inductor_quant": 112, "xpuiq": 112, "resnet18_weight": 112, "get_default_xpu_inductor_quantization_config": 112, "wherea": 112, "histogramobserv": [112, 113], "perchannelminmaxobserv": 112, "quantizationspec": [112, 113], "quantizationconfig": [112, 113], "type_check": 112, "observerorfakequantizeconstructor": 112, "get_xpu_inductor_symm_quantization_config": 112, "extra_arg": 112, "act_observer_or_fake_quant_ctr": 112, "act_quantization_spec": [112, 113], "qscheme": [112, 113], "per_tensor_symmetr": [112, 113], "observer_or_fake_quant_ctr": [112, 113], "with_arg": [112, 113], "weight_observer_or_fake_quant_ctr": 112, "weight_quantization_spec": [112, 113], "per_channel_symmetr": 112, "ch_axi": 112, "oc": 112, "ic": 112, "kh": 112, "kw": 112, "conv": [112, 113], "bias_quantization_spec": 112, "amp": 112, "indcutor": 112, "kimish": 113, "patel": 113, "made": 113, "explicit": 113, "quantiat": 113, "encod": 113, "convei": 113, "quantizationannot": 113, "furthermor": 113, "minmaxobserv": 113, "input_qspec_map": 113, "output_qspec": 113, "_annot": 113, "conclud": 113, "matcher": 113, "get_source_partit": 113, "add_partit": 113, "gm": 113, "itertool": 113, "chain": 113, "add_nod": 113, "output_nod": 113, "per_tensor_affin": 113, "input_act_qspec": 113, "output_act_qspec": 113, "input_act0": 113, "input_act1": 113, "quantization_annot": 113, "substitut": 113, "among": 113, "sharedquantizationspec": 113, "maxpool": 113, "average_pool": 113, "concat": 113, "whose": 113, "edgeornod": 113, "transit": 113, "spec": 113, "conv1": 113, "conv2": 113, "fed": 113, "conv1_out": 113, "conv2_out": 113, "qspec1": 113, "cat_input0": 113, "cat_input1": 113, "therefor": 113, "ob": 113, "consum": 113, "rewrit": 113, "share_qparams_with_input_act0_qspec": 113, "known": 113, "beforehand": 113, "sigmoid": 113, "fixedqparamsquantizationspec": 113, "act_qspec": 113, "sigmoid_nod": 113, "input_act": 113, "derivedquantizationspec": 113, "derive_qparams_fn": 113, "observerorfakequant": 113, "observerbas": 113, "fakequantizebas": 113, "heurist": 113, "obejct": 113, "obs_or_fq": 113, "fq": 113, "act_obs_or_fq": 113, "weight_obs_or_fq": 113, "act_zp": 113, "weight_zp": 113, "bias_qspec": 113, "derived_from": 113, "backendquant": 113, "get_input_act_qspec": 113, "get_output_act_qspec": 113, "get_weight_qspec": 113, "get_bias_qspec": 113, "intermedi": 113, "straightforward": 113, "call_funct": 113, "relu_": 113, "relu_nod": 113, "maybe_conv_nod": 113, "conv1d": 113, "unexpect": 113, "recognz": 113, "subgraphmatch": 113, "conv_relu_pattern": 113, "name_node_map": 113, "input_nod": 113, "weight_nod": 113, "bias_nod": 113, "caveat": 113, "exhaust": 113, "2d": 113, "4d": 113, "v": 113, "symbol": 113, "outcom": 113}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "MarlinQQQLayout"], [19, 0, 1, "", "MarlinQQQTensor"], [20, 0, 1, "", "MarlinSparseLayout"], [21, 0, 1, "", "NF4Tensor"], [22, 0, 1, "", "PlainLayout"], [23, 0, 1, "", "SemiSparseLayout"], [24, 0, 1, "", "TensorCoreTiledLayout"], [25, 0, 1, "", "UintxLayout"], [26, 2, 1, "", "to_affine_quantized_floatx"], [27, 2, 1, "", "to_affine_quantized_floatx_static"], [28, 2, 1, "", "to_affine_quantized_fpx"], [29, 2, 1, "", "to_affine_quantized_intx"], [30, 2, 1, "", "to_affine_quantized_intx_static"], [31, 2, 1, "", "to_marlinqqq_quantized_intx"], [32, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[19, 1, 1, "", "dequantize"], [19, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[20, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[21, 1, 1, "", "convert_to_norm_float_weight"], [21, 1, 1, "", "dequantize"], [21, 1, 1, "", "dequantize_scalers"], [21, 1, 1, "", "double_quantize_scalers"], [21, 1, 1, "", "get_original_weight"], [21, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[33, 0, 1, "", "CastConfig"], [34, 0, 1, "", "Float8LinearConfig"], [35, 0, 1, "", "ScalingGranularity"], [36, 0, 1, "", "ScalingType"], [37, 2, 1, "", "convert_to_float8_training"], [38, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[34, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[39, 0, 1, "", "BlockSparseLayout"], [40, 0, 1, "", "CutlassInt4PackedLayout"]], "torchao.quantization": [[41, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [42, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [43, 0, 1, "", "Float8WeightOnlyConfig"], [44, 0, 1, "", "Int4WeightOnlyConfig"], [45, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [46, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [47, 0, 1, "", "Int8WeightOnlyConfig"], [48, 0, 1, "", "MappingType"], [49, 0, 1, "", "TorchAODType"], [50, 2, 1, "", "choose_qparams_affine"], [51, 2, 1, "", "choose_qparams_affine_with_min_max"], [52, 2, 1, "", "dequantize_affine"], [53, 2, 1, "", "int_scaled_matmul"], [78, 2, 1, "", "quantize_"], [83, 2, 1, "", "quantize_affine"], [84, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[54, 0, 1, "", "ComposableQATQuantizer"], [55, 0, 1, "", "FakeQuantizeConfigBase"], [56, 0, 1, "", "FakeQuantizedEmbedding"], [57, 0, 1, "", "FakeQuantizedLinear"], [58, 0, 1, "", "FakeQuantizerBase"], [59, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [60, 0, 1, "", "Float8FakeQuantizeConfig"], [61, 0, 1, "", "Float8FakeQuantizer"], [62, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [63, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [64, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [65, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [66, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [67, 0, 1, "", "IntxFakeQuantizeConfig"], [68, 0, 1, "", "IntxFakeQuantizer"], [69, 0, 1, "", "QATConfig"], [70, 0, 1, "", "QATStep"], [73, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[56, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[57, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[59, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[61, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[63, 1, 1, "", "convert"], [63, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[67, 3, 1, "", "group_size"], [67, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[68, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[71, 0, 1, "", "Int4WeightOnlyEmbedding"], [72, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[71, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[74, 0, 1, "", "Int4WeightOnlyQATLinear"], [75, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [76, 2, 1, "", "disable_linear_fake_quant"], [77, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[79, 0, 1, "", "KernelPreference"], [80, 0, 1, "", "PackingFormat"], [81, 0, 1, "", "QuantizeTensorKwargs"], [82, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[79, 4, 1, "", "AUTO"], [79, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[80, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[85, 0, 1, "", "PerChannelNormObserver"], [86, 0, 1, "", "WandaSparsifier"], [87, 2, 1, "", "apply_fake_sparsity"], [88, 4, 1, "", "semi_sparse_weight"], [89, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[85, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[86, 1, 1, "", "prepare"], [86, 1, 1, "", "squash_mask"], [86, 1, 1, "", "update_mask"]], "torchao.utils": [[90, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[90, 1, 1, "", "get_tensor_impl_constructor"], [90, 1, 1, "", "implements"], [90, 1, 1, "", "implements_torch_function"], [90, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 91, 93, 94, 104], "dtype": [0, 11, 94], "layout": [0, 17], "tensor": [0, 7, 10, 94, 101, 102, 104, 113], "subclass": [0, 7, 10, 94, 102, 104], "quantiz": [0, 4, 5, 7, 12, 78, 91, 94, 95, 97, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 93, 94], "main": [1, 4, 5], "train": [1, 12, 93, 94, 97, 108, 109, 110, 111, 112], "api": [1, 2, 4, 5, 7, 8, 12, 91, 93, 113], "other": [1, 10, 94], "type": [1, 103], "refer": [2, 91], "python": 2, "kernel": [3, 10, 92, 94, 104], "qat": [4, 12, 110], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 97], "primit": [5, 94], "sparsiti": [6, 99], "util": 7, "common": [7, 8, 113], "benchmark": [8, 9, 10, 97], "guid": [8, 9, 10, 95, 104], "add": [8, 104], "an": [8, 96], "recip": [8, 93], "model": [8, 10, 93, 94, 96, 97, 103, 104, 108, 109, 110], "design": [8, 99], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 93, 97, 103, 104, 108, 111, 112, 113], "modifi": 8, "exist": 8, "configur": [8, 99, 104, 109, 110], "2": [8, 12, 95, 97, 103, 104, 108, 109, 110, 111, 112, 113], "run": 8, "3": [8, 12, 97, 104, 108, 111, 112, 113], "output": [8, 102], "format": [8, 94], "4": [8, 108, 113], "integr": [8, 12, 103, 104], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 104], "new": [10, 104], "effici": [10, 94], "triton": 10, "hand": 10, "written": 10, "us": [10, 113], "kernelprefer": [10, 79], "flow": [10, 94, 96, 104, 113], "torch": [10, 108, 109, 110], "compil": [10, 104, 108], "perform": [10, 92, 97, 109], "serial": [10, 96, 104], "featur": 10, "support": [10, 103, 104], "function": [10, 109, 110], "compos": 10, "microbenchmark": 10, "eval": [10, 109], "part": [12, 93, 97], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 94, 110, 111], "option": [12, 97, 107, 108], "torchtun": 12, "axolotl": 12, "low": [12, 94], "rank": 12, "adapt": 12, "huggingfac": [12, 97, 104], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "marlinqqqlayout": 18, "marlinqqqtensor": 19, "marlinsparselayout": 20, "nf4tensor": 21, "plainlayout": 22, "semisparselayout": 23, "tensorcoretiledlayout": 24, "uintxlayout": 25, "to_affine_quantized_floatx": 26, "to_affine_quantized_floatx_stat": 27, "to_affine_quantized_fpx": 28, "to_affine_quantized_intx": 29, "to_affine_quantized_intx_stat": 30, "to_marlinqqq_quantized_intx": 31, "to_nf4": 32, "castconfig": 33, "float8linearconfig": 34, "scalinggranular": 35, "scalingtyp": 36, "convert_to_float8_train": 37, "precompute_float8_dynamic_scale_for_fsdp": 38, "blocksparselayout": 39, "cutlassint4packedlayout": 40, "float8dynamicactivationfloat8weightconfig": 41, "float8dynamicactivationint4weightconfig": 42, "float8weightonlyconfig": 43, "int4weightonlyconfig": 44, "int8dynamicactivationint4weightconfig": 45, "int8dynamicactivationint8weightconfig": 46, "int8weightonlyconfig": 47, "mappingtyp": 48, "torchaodtyp": 49, "choose_qparams_affin": 50, "choose_qparams_affine_with_min_max": 51, "dequantize_affin": 52, "int_scaled_matmul": 53, "composableqatquant": 54, "fakequantizeconfigbas": 55, "fakequantizedembed": 56, "fakequantizedlinear": 57, "fakequantizerbas": 58, "float8actint4weightqatquant": 59, "float8fakequantizeconfig": 60, "float8fakequant": 61, "fromintxquantizationawaretrainingconfig": 62, "int4weightonlyembeddingqatquant": 63, "int4weightonlyqatquant": 64, "int8dynactint4weightqatquant": 65, "intxquantizationawaretrainingconfig": 66, "intxfakequantizeconfig": 67, "intxfakequant": 68, "qatconfig": 69, "qatstep": 70, "int4weightonlyembed": 71, "int4weightonlyqatembed": 72, "initialize_fake_quant": 73, "int4weightonlyqatlinear": 74, "int8dynactint4weightqatlinear": 75, "disable_linear_fake_qu": 76, "enable_linear_fake_qu": 77, "packingformat": 80, "quantizetensorkwarg": 81, "_choose_quant_func_and_quantize_tensor": 82, "quantize_affin": 83, "safe_int_mm": 84, "perchannelnormobserv": 85, "wandasparsifi": 86, "apply_fake_spars": 87, "semi_sparse_weight": 88, "sparsifi": 89, "torchaobasetensor": 90, "welcom": 91, "document": 91, "get": 91, "start": [91, 95, 103], "develop": 91, "note": [91, 93, 113], "eager": 91, "tutori": [91, 107], "pt2e": [91, 113], "pre": 93, "torchtitan": 93, "prerequisit": [93, 108, 111, 112, 113], "rowwis": 93, "scale": 93, "tensorwis": 93, "pick": 93, "import": [93, 109, 110], "directli": [93, 113], "convers": 93, "overview": [94, 99, 107], "basic": 94, "op": 94, "deriv": [94, 113], "pack": 94, "algorithm": 94, "weight": [94, 97], "onli": 94, "dynam": 94, "activ": 94, "static": [94, 100], "bit": 94, "optim": [94, 96, 97], "case": 94, "studi": 94, "how": [94, 109, 110, 113], "work": 94, "dure": 94, "execut": 94, "save": [94, 103, 109, 110], "load": [94, 109, 110], "quick": [95, 103], "first": 95, "exampl": [95, 103, 104, 113], "pytorch": [95, 108, 109, 110, 111, 112, 113], "export": [95, 97, 108, 109, 110, 111, 112, 113], "next": [95, 102], "step": [95, 97, 102, 104, 107], "deseri": 96, "what": [96, 102], "happen": 96, "when": 96, "serv": [97, 104], "vllm": [97, 104], "sglang": 97, "executorch": 97, "post": [97, 108, 109, 111, 112], "transform": [97, 103, 104], "mobil": 97, "deploy": 97, "unti": 97, "embed": 97, "creat": [97, 104], "characterist": 97, "evalu": [97, 109], "qualiti": 97, "assess": 97, "memori": 97, "latenc": 97, "result": 97, "h100": 97, "machin": 97, "conclus": [97, 107, 108, 109, 110, 111, 112, 113], "comput": [98, 106], "time": [98, 106], "goal": 99, "context": 99, "prune": 99, "criteria": 99, "strategi": 99, "pattern": [99, 113], "calibr": [100, 109], "phase": 100, "write": [101, 102, 113], "your": [101, 102, 104], "own": [101, 102], "advanc": 101, "ar": 102, "modul": 102, "swap": 102, "which": 102, "oper": [102, 104, 113], "should": 102, "we": 102, "implement": [102, 104], "compar": 102, "hug": 103, "face": 103, "usag": [103, 104], "diffus": 103, "architectur": 104, "system": 104, "class": 104, "fqn": 104, "method": 104, "minim": 104, "requir": 104, "compat": 104, "why": 104, "regist": 104, "s": 104, "kei": 104, "detail": 104, "hardwar": 104, "specif": [104, 109, 110], "linear": 104, "benefit": 104, "trade": 104, "off": 104, "share": [104, 113], "safetensor": 104, "diagram": 104, "high": 104, "level": 104, "point": 104, "dispatch": 104, "bring": 104, "extern": 104, "templat": 107, "addit": 107, "exercis": 107, "further": 107, "read": 107, "openvino": 108, "backend": [108, 109, 110, 111, 112], "introduct": [108, 111, 112, 113], "nncf": 108, "instal": 108, "captur": [108, 111, 112], "fx": [108, 111, 112], "graph": [108, 111, 112], "appli": [108, 111, 112], "lower": [108, 109, 111, 112], "represent": 108, "improv": 108, "metric": 108, "motiv": [109, 113], "defin": [109, 110], "helper": [109, 110], "prepar": [109, 110], "dataset": [109, 110], "set": 109, "mode": 109, "convert": [109, 110], "check": 109, "size": 109, "accuraci": 109, "debug": 109, "loop": 110, "checkpoint": 110, "x86": 111, "through": [111, 112], "inductor": [111, 112], "intel": 112, "gpu": 112, "annot": 113, "param": 113, "fix": 113, "paramet": 113, "5": 113, "A": 113, "toi": 113, "resnet18": 113, "ir": 113, "problem": 113, "match": 113, "aten": 113, "recommend": 113, "subgraphmatcherwithnamenodemap": 113}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})