Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout", "generated/torchao.prototype.dtypes.MarlinQQQLayout", "generated/torchao.prototype.dtypes.MarlinQQQTensor", "generated/torchao.prototype.dtypes.UintxLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQLayout.rst", "generated/torchao.prototype.dtypes.MarlinQQQTensor.rst", "generated/torchao.prototype.dtypes.UintxLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "Int8DynamicActInt4WeightCPULayout", "MarlinQQQLayout", "MarlinQQQTensor", "UintxLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 18, 19, 20, 21, 34, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 56, 61, 62, 67, 69, 71, 72, 74, 75, 78, 81, 82, 83, 85, 86, 87, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112], "section": [2, 10, 94, 98, 103, 108, 109, 112], "introduc": [2, 12, 107, 108, 110, 111, 112], "dive": 2, "detail": [2, 8, 10, 12, 44, 93, 94, 95, 97, 98, 99, 101, 107, 108, 109, 110], "how": [2, 4, 10, 12, 13, 17, 40, 42, 46, 48, 50, 67, 79, 80, 83, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 107, 110, 111], "integr": [2, 10, 91, 93, 96, 97, 98, 101, 110, 112], "pytorch": [2, 8, 12, 13, 16, 39, 49, 67, 91, 93, 94, 97, 98, 101, 103, 106], "optim": [2, 10, 12, 18, 34, 78, 91, 93, 98, 101, 107, 109, 110, 111], "your": [2, 8, 10, 12, 91, 93, 94, 95, 97, 98, 102, 108, 109, 110, 111, 112], "machin": [2, 109], "learn": [2, 67, 95, 98, 106, 108, 110, 111, 112], "model": [2, 12, 34, 45, 54, 59, 62, 63, 64, 65, 66, 69, 73, 78, 86, 87, 89, 95, 98, 99, 101, 110, 111, 112], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 43, 49, 50, 51, 52, 56, 57, 59, 60, 63, 64, 65, 67, 71, 72, 74, 75, 82, 83, 89, 91, 93, 95, 96, 97, 99, 101, 102, 103, 108, 110, 111, 112], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 89, 93, 96, 98], "sparsiti": [2, 8, 12, 14, 18, 21, 85, 86, 87, 88, 89, 91, 93, 96, 97], "tba": [3, 11, 92], "For": [4, 8, 10, 12, 13, 44, 67, 94, 95, 96, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 112], "full": [4, 12, 95, 99, 102, 106, 107, 109], "exampl": [4, 8, 10, 12, 13, 34, 48, 54, 56, 57, 62, 66, 67, 69, 73, 78, 79, 86, 89, 90, 94, 96, 97, 98, 99, 101, 104, 106, 107, 108, 109, 110, 111], "us": [4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 24, 26, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 59, 62, 66, 67, 69, 74, 75, 79, 80, 83, 86, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111], "our": [4, 10, 12, 19, 93, 95, 97, 98, 99, 101, 108, 109], "pleas": [4, 9, 10, 12, 13, 39, 62, 66, 91, 94, 95, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 112], "refer": [4, 8, 12, 13, 69, 75, 93, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110], "readm": [4, 8, 12, 91, 95, 98], "tutori": [8, 10, 12, 13, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112], "you": [8, 9, 10, 12, 67, 86, 90, 93, 94, 95, 96, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112], "through": [8, 10, 12, 51, 56, 57, 91, 94, 95, 97, 99, 101, 103, 106, 107, 108, 112], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 101, 102, 107, 108, 109, 110, 111], "framework": [8, 10, 12, 93, 97, 107], "The": [8, 10, 12, 13, 17, 18, 33, 35, 40, 41, 43, 53, 69, 78, 84, 86, 93, 94, 95, 96, 97, 98, 101, 102, 103, 107, 108, 109, 110, 111, 112], "contain": [8, 81, 82, 98, 101, 109, 112], "new": [8, 12, 13, 90, 93, 94, 99, 101, 108, 109, 110, 112], "architectur": [8, 91, 97, 98, 107, 108, 110, 111], "micro": 8, "current": [8, 41, 44, 45, 59, 60, 69, 78, 86, 89, 93, 94, 95, 98, 101, 102, 103, 108, 109, 111], "support": [8, 12, 41, 42, 44, 45, 59, 66, 67, 69, 79, 81, 82, 89, 93, 94, 95, 96, 97, 98, 101, 107, 108, 109, 110, 111, 112], "which": [8, 10, 12, 39, 40, 69, 74, 79, 93, 94, 96, 97, 98, 99, 103, 107, 108, 109, 110, 111, 112], "can": [8, 10, 12, 13, 22, 41, 48, 54, 67, 78, 79, 83, 90, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 112], "quantize_": [8, 10, 12, 62, 66, 69, 78, 79, 80, 81, 82, 89, 91, 94, 95, 96, 97, 99], "sparsity_": 8, "function": [8, 12, 13, 22, 33, 56, 61, 71, 76, 77, 78, 85, 86, 87, 89, 90, 93, 94, 95, 96, 98, 99, 101, 103, 107, 112], "To": [8, 10, 12, 13, 39, 75, 93, 94, 95, 96, 97, 98, 99, 103, 108, 109, 110, 112], "correspond": [8, 12, 62, 69, 78, 94, 96, 98, 101, 111, 112], "string": [8, 30, 67, 86, 90], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 90, 91, 94, 95, 96, 101, 103, 107, 108, 109, 110, 111, 112], "py": [8, 10, 90, 105, 106, 110, 111], "def": [8, 10, 12, 81, 89, 90, 93, 94, 95, 96, 99, 101, 103, 107, 108, 109, 110, 111, 112], "option": [8, 10, 13, 15, 23, 25, 26, 27, 29, 30, 33, 39, 41, 44, 46, 47, 50, 51, 52, 56, 57, 59, 60, 64, 66, 67, 69, 71, 72, 78, 79, 82, 83, 86, 89, 90, 93, 94, 95, 102, 103, 108, 109, 110, 111, 112], "str": [8, 30, 33, 67, 69, 78, 86, 89, 90, 93, 101, 103, 111], "kwarg": [8, 10, 13, 56, 57, 58, 59, 63, 67, 72, 82, 85, 86, 87, 90, 94, 101, 103], "aobaseconfig": [8, 69, 78, 89, 99, 103], "code": [8, 10, 93, 94, 95, 97, 98, 99, 101, 104, 106, 108, 109, 110, 111, 112], "elif": [8, 103], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 33, 41, 46, 47, 53, 66, 67, 69, 84, 86, 90, 94, 97, 98, 101, 108, 109], "addit": [8, 12, 17, 20, 90, 93, 94, 98, 101, 102, 107, 108, 111, 112], "inform": [8, 13, 41, 94, 97, 98, 103, 107, 108], "need": [8, 10, 12, 41, 56, 61, 71, 80, 81, 82, 85, 86, 90, 94, 96, 97, 98, 101, 103, 108, 109, 110, 112], "pass": [8, 33, 46, 51, 56, 57, 61, 69, 71, 85, 90, 94, 99, 101, 103, 109, 112], "process": [8, 12, 17, 18, 20, 22, 40, 94, 98, 106, 107, 111], "here": [8, 9, 13, 69, 75, 83, 94, 95, 96, 97, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112], "return": [8, 10, 12, 13, 18, 19, 33, 39, 53, 67, 78, 84, 89, 90, 93, 94, 95, 96, 99, 101, 103, 107, 108, 109, 110, 111, 112], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 80, 101, 109], "now": [8, 10, 12, 42, 44, 45, 50, 93, 94, 95, 98, 99, 101, 102, 107, 108, 110, 112], "we": [8, 10, 12, 13, 19, 44, 46, 48, 50, 51, 52, 66, 67, 69, 75, 78, 83, 89, 90, 93, 94, 95, 96, 97, 98, 99, 102, 103, 107, 108, 109, 110, 111, 112], "throughout": 8, "note": [8, 10, 12, 44, 54, 66, 75, 86, 90, 94, 95, 97, 98, 101, 103, 109, 110, 111], "input": [8, 10, 13, 18, 19, 21, 30, 33, 34, 50, 51, 52, 53, 69, 73, 78, 83, 84, 86, 89, 93, 94, 95, 97, 99, 101, 107, 108, 109, 110, 111, 112], "paramet": [8, 12, 13, 17, 18, 19, 24, 26, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 67, 69, 72, 74, 75, 78, 83, 84, 86, 89, 90, 93, 94, 96, 97, 98, 101, 103, 107, 108], "like": [8, 10, 12, 17, 41, 93, 94, 95, 96, 98, 101, 102, 103, 107, 108, 109, 110, 111, 112], "bit": [8, 12, 28, 40, 68, 97, 101, 102, 103, 108, 110, 111], "width": [8, 40, 68], "group": [8, 10, 12, 41, 42, 45, 47, 59, 63, 64, 65, 67, 71, 72, 74, 75, 79, 95], "size": [8, 10, 13, 19, 35, 39, 44, 45, 47, 50, 52, 67, 83, 93, 95, 96, 97, 98, 99, 101, 103, 109], "etc": [8, 10, 41, 56, 57, 80, 82, 94, 107, 112], "them": [8, 12, 56, 61, 71, 85, 112], "append": [8, 98, 108, 109], "config": [8, 12, 30, 33, 41, 43, 44, 46, 55, 56, 57, 58, 60, 61, 62, 66, 67, 68, 69, 78, 86, 89, 94, 95, 97, 98, 99, 102, 103, 108, 110, 111], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 42, 44, 45, 47, 56, 57, 59, 63, 66, 67, 69, 71, 72, 78, 95, 102, 103], "system": [8, 10, 80, 97], "model_architectur": 8, "type": [8, 10, 12, 13, 18, 19, 30, 31, 32, 33, 40, 41, 43, 44, 45, 46, 48, 49, 53, 67, 70, 78, 79, 80, 81, 82, 83, 84, 90, 91, 94, 96, 97, 98, 101, 103, 107, 108, 110, 111, 112], "defin": [8, 10, 17, 31, 40, 56, 61, 71, 85, 86, 90, 94, 95, 98, 99, 101, 103, 107, 110, 111, 112], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 85, 86, 90, 95, 96, 99, 101, 108, 109, 110, 112], "mycustommodel": 8, "torch": [8, 12, 13, 18, 19, 24, 30, 33, 40, 41, 43, 50, 52, 53, 56, 57, 59, 60, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 78, 79, 83, 84, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 110, 111, 112], "nn": [8, 10, 12, 30, 33, 54, 59, 63, 66, 69, 78, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 103, 108, 109, 110, 112], "modul": [8, 10, 12, 30, 31, 32, 33, 34, 48, 49, 54, 56, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 89, 93, 94, 95, 96, 99, 103, 107, 108, 109, 110, 111, 112], "__init__": [8, 12, 90, 95, 96, 99, 101, 103, 108, 109, 110], "self": [8, 12, 13, 90, 95, 96, 99, 101, 103, 108, 109, 110], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 19, 59, 64, 74, 83, 93, 94, 95, 96, 97, 98, 99, 102, 103, 110, 111], "super": [8, 12, 95, 96, 99, 101, 108, 109, 110], "layer1": 8, "linear": [8, 10, 12, 18, 30, 33, 41, 42, 43, 45, 46, 47, 54, 57, 59, 64, 65, 66, 69, 74, 75, 76, 77, 78, 87, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 107, 108, 109, 110, 112], "512": [8, 93], "bia": [8, 12, 57, 74, 75, 94, 95, 96, 99, 101, 103, 109, 112], "fals": [8, 12, 13, 25, 30, 44, 46, 50, 56, 57, 65, 66, 67, 69, 71, 72, 74, 75, 86, 93, 94, 95, 96, 97, 99, 101, 102, 103, 107, 108, 109, 111, 112], "activ": [8, 12, 41, 45, 46, 56, 57, 59, 65, 66, 67, 69, 75, 81, 82, 86, 91, 95, 97, 98, 99, 102, 103, 107, 110, 111, 112], "relu": [8, 95, 107, 112], "layer2": 8, "forward": [8, 46, 56, 57, 61, 68, 71, 74, 85, 95, 96, 98, 99, 101, 103, 108, 109, 110], "x": [8, 56, 57, 61, 68, 71, 93, 95, 96, 97, 99, 101, 103, 106, 107, 108, 109, 110, 111], "updat": [8, 91, 95, 96, 98, 108, 109, 112], "create_model_and_input_data": 8, "handl": [8, 10, 18, 21, 22], "model_typ": [8, 12, 103, 107], "m": [8, 10, 12, 78, 89, 93, 95, 96, 97, 99, 101, 108, 109, 110], "int": [8, 12, 13, 19, 22, 23, 24, 25, 26, 27, 28, 35, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 56, 57, 59, 63, 64, 65, 67, 71, 72, 74, 75, 78, 83, 86, 90, 95, 99, 101, 103], "k": [8, 10, 84, 95, 96, 99, 101, 108, 109], "n": [8, 10, 12, 95, 96, 99, 101, 108, 109, 112], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 71, 74, 75, 78, 84, 93, 95, 96, 97, 99, 101, 103, 107, 108, 109, 110, 111], "cuda": [8, 10, 12, 13, 78, 93, 95, 96, 97, 98, 99, 101, 102, 109], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 57, 93, 95, 96, 99, 101, 107, 108, 109, 110, 111], "when": [8, 10, 12, 13, 20, 50, 52, 69, 83, 90, 93, 94, 97, 98, 99, 102, 103, 107, 108, 109, 110, 111, 112], "ad": [8, 12, 13, 52, 86, 90, 94, 98, 99, 101, 109], "dimens": [8, 10, 13, 40, 50, 52, 53, 83, 93, 94, 101, 103, 108, 109], "ensur": [8, 18, 97, 109], "convent": 8, "where": [8, 21, 48, 51, 63, 64, 65, 94, 98, 103, 112], "batch": [8, 97, 99, 109], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 101, 107, 110, 111], "data": [8, 12, 13, 17, 18, 35, 40, 41, 43, 44, 46, 51, 80, 90, 91, 94, 96, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 112], "typic": [8, 12, 19, 20, 94, 95, 96, 99, 103, 112], "compat": [8, 10, 18, 67, 95], "work": [8, 10, 12, 21, 93, 96, 98, 101, 102, 103, 108, 109, 110], "cpu": [8, 10, 13, 16, 37, 96, 98, 99, 102, 103, 107, 108, 109, 110], "other": [8, 12, 13, 17, 41, 44, 68, 79, 86, 93, 96, 97, 98, 101, 103, 106, 108, 109, 110, 112], "target": [8, 10, 12, 13, 41, 43, 44, 50, 56, 57, 60, 67, 86, 95, 98, 107, 108, 109, 110, 111, 112], "method": [8, 10, 17, 18, 21, 22, 78, 86, 95, 98, 99, 101, 102, 107, 108, 109, 111, 112], "come": [8, 9, 93, 94, 97, 98, 99, 100, 102, 109, 110, 111], "soon": [8, 9, 97, 100, 109], "file": [8, 10, 93, 97, 101, 103, 105, 108, 109], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 69, 91, 94, 95, 96, 98, 99, 101, 102, 107, 108, 109, 110, 111], "quantization_config_recipe_nam": 8, "int8wo": [8, 102], "int8dq": 8, "float8dq": [8, 97], "tensor": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 36, 37, 39, 40, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 60, 61, 68, 79, 80, 81, 82, 83, 84, 86, 90, 91, 93, 95, 96, 98, 99, 102, 106, 108, 110, 111], "row": [8, 10, 42, 53, 93, 94, 98], "float8wo": 8, "output_dir": [8, 102], "result": [8, 12, 13, 53, 84, 94, 98, 99, 102, 108, 109, 110, 111, 112], "model_param": 8, "name": [8, 10, 31, 32, 48, 49, 70, 78, 79, 80, 86, 89, 90, 94, 97, 98, 101, 103, 107, 108, 109, 112], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 48, 56, 83, 93, 95, 97, 99, 108, 109], "max_pow": 8, "15": [8, 44, 93, 95, 97], "torch_compile_mod": 8, "max": [8, 10, 48, 94, 95, 99, 101, 108, 109, 112], "autotun": [8, 10, 95, 99], "runner": 8, "gener": [8, 12, 13, 56, 57, 58, 61, 68, 94, 95, 97, 98, 99, 101, 103, 104, 106, 107, 109, 110, 111, 112], "oss": 8, "databas": 8, "python": [8, 10, 95, 97, 98, 104, 106, 107, 108, 110, 111], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 97, 103], "specif": [8, 10, 12, 17, 18, 20, 21, 56, 57, 75, 80, 86, 93, 94, 95, 96, 97, 98, 102, 107, 110, 111, 112], "requir": [8, 12, 13, 20, 22, 79, 90, 94, 95, 97, 98, 101, 102, 107, 110, 112], "mode": [8, 10, 44, 95, 99, 107, 109, 110, 111, 112], "extra_info": 8, "arch": 8, "nvidia": [8, 98], "a100": [8, 12, 95, 102], "sxm4": 8, "80gb": [8, 95], "1024": [8, 78, 89, 95, 96, 110], "custom": [8, 12, 17, 69, 85, 91, 93, 94, 95, 98, 101, 103, 107, 108, 110, 112], "layer": [8, 18, 33, 41, 43, 46, 47, 56, 57, 59, 63, 64, 65, 71, 72, 74, 75, 86, 87, 93, 97, 98, 99, 101, 103, 107, 112], "origin": [8, 12, 13, 19, 43, 46, 62, 83, 86, 94, 95, 96, 97, 98, 107, 108, 112], "metric": [8, 12, 86], "speedup": [8, 10, 12, 93, 94, 95, 97, 98], "wrt": 8, "bf16": [8, 12, 50, 69, 95, 98, 110, 111], "benchmark_valu": 8, "25": [8, 95], "target_valu": 8, "0": [8, 10, 12, 13, 44, 56, 67, 71, 72, 83, 86, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 108, 109, 111, 112], "depend": [8, 13, 96, 98, 101, 108, 109, 111], "step": [8, 12, 20, 34, 69, 70, 93, 94, 98, 107, 108, 109, 110, 111, 112], "workflow": [8, 10, 78, 79, 89, 93, 95, 98, 112], "github": [8, 95, 97, 102], "action": [8, 103, 108, 109], "upload": 8, "verifi": [8, 95, 96, 101], "setup": [8, 97], "suit": [8, 10, 108, 110], "unittest": 8, "discov": 8, "out": [8, 10, 12, 21, 48, 80, 86, 93, 94, 95, 97, 98, 101, 107, 108, 109, 110], "memori": [8, 10, 12, 13, 93, 94, 95, 98, 101, 102, 110, 111], "reduc": [8, 10, 12, 34, 69, 93, 97, 98, 110], "matrix": [8, 15, 35, 41, 53, 79, 84, 86, 94, 95, 98, 110], "miss": [8, 98], "i": [8, 9, 10, 12, 13, 17, 18, 19, 20, 21, 22, 35, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 66, 67, 69, 78, 81, 82, 83, 84, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112], "properli": [8, 96], "instal": [8, 10, 93, 94, 95, 97, 102, 108, 111], "Not": [8, 98], "avail": [8, 10, 80, 94, 97, 107, 108, 109, 110, 111], "check": [8, 10, 12, 13, 39, 94, 95, 96, 97, 101, 107, 109, 112], "driver": 8, "basic": [8, 10, 20, 95, 99, 101], "shape": [8, 10, 13, 39, 53, 80, 84, 94, 95, 99, 101, 103, 108, 111], "comprehens": [8, 103, 110], "analysi": [8, 98], "enabl": [8, 10, 77, 90, 93, 94, 97, 103, 110], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 33, 41, 42, 43, 44, 45, 46, 47, 59, 69, 75, 89, 93, 95, 96, 97, 98, 101, 102, 103, 107, 108, 110, 111, 112], "overhead": [8, 98, 102, 103, 110], "multipl": [8, 10, 12, 15, 41, 53, 54, 79, 81, 84, 94, 95, 98, 99, 101, 103, 110, 112], "possibl": [8, 13, 94, 98, 108, 109, 110, 112], "consist": [8, 97, 98, 101, 110, 111, 112], "reproduc": [8, 97], "differ": [8, 10, 12, 17, 44, 51, 54, 83, 84, 93, 94, 95, 96, 97, 98, 101, 102, 103, 108, 109, 110, 112], "case": [8, 9, 10, 69, 79, 84, 97, 98, 101, 103, 107, 108, 112], "user": [8, 10, 12, 41, 54, 69, 75, 91, 93, 94, 95, 97, 98, 99, 101, 106, 108, 109, 110, 111, 112], "more": [8, 10, 12, 13, 44, 45, 93, 94, 95, 97, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111], "about": [8, 10, 12, 94, 95, 96, 97, 98, 108, 109, 110, 112], "compon": [8, 94, 101, 103], "see": [8, 10, 12, 13, 39, 44, 90, 93, 94, 95, 96, 98, 99, 101, 102, 103, 107, 108, 112], "directori": [8, 93], "intend": [9, 79, 94, 108], "provid": [9, 10, 12, 17, 18, 21, 22, 50, 54, 73, 90, 93, 94, 97, 98, 101, 103, 108, 109, 111, 112], "instruct": [9, 12, 94, 97, 108, 109, 110], "most": [9, 10, 20, 69, 94, 97, 98, 103, 108, 109, 112], "fequent": 9, "have": [9, 10, 12, 48, 63, 64, 65, 80, 83, 86, 90, 94, 98, 99, 101, 103, 107, 108, 109, 110, 111, 112], "ani": [9, 10, 20, 59, 63, 73, 86, 94, 98, 101, 107, 109, 111], "answer": [9, 98], "creat": [9, 10, 13, 24, 26, 93, 98, 101, 102, 107, 108, 110, 111, 112], "an": [9, 12, 13, 22, 25, 26, 66, 67, 69, 75, 86, 91, 93, 94, 95, 97, 98, 99, 101, 102, 107, 108, 109, 110, 111, 112], "issu": [9, 79, 94, 95, 101, 110], "start": [10, 12, 31, 32, 48, 49, 70, 79, 80, 93, 94, 97, 98, 99, 101, 103, 107, 108, 109, 110, 111, 112], "read": [10, 101], "overview": [10, 91, 95, 103], "page": [10, 95, 110], "first": [10, 19, 53, 69, 86, 90, 94, 97, 99, 101, 102, 103, 108, 109, 112], "contribut": [10, 95, 98], "exist": [10, 49, 69, 93, 94, 98, 99, 101, 108, 112], "base": [10, 17, 20, 41, 48, 55, 68, 69, 73, 81, 82, 86, 90, 94, 95, 98, 101, 102, 103, 107, 108, 109, 110, 111, 112], "api": [10, 94, 95, 98, 99, 101, 107, 108, 109, 110, 111], "quant_api": [10, 78, 96, 97, 99], "float8tensor": [10, 41, 43, 60, 81, 94, 103], "e": [10, 12, 13, 48, 50, 52, 54, 67, 69, 78, 81, 83, 90, 93, 94, 96, 99, 101, 102, 107, 112], "g": [10, 12, 13, 48, 50, 52, 54, 67, 69, 78, 81, 83, 90, 94, 96, 99, 101, 107, 112], "oper": [10, 12, 13, 15, 17, 18, 46, 51, 94, 95, 97, 107, 108, 109, 110, 111], "make": [10, 42, 44, 94, 95, 101, 103, 108, 112], "trainabl": [10, 12, 94, 101], "add": [10, 20, 90, 101, 102, 106, 110, 112], "parallel": [10, 93, 101, 103], "primit": [10, 13, 39, 101, 108], "op": [10, 12, 13, 39, 41, 78, 79, 90, 95, 98, 101, 103, 108, 109, 110, 112], "slight": [10, 98], "variat": [10, 94], "quant_primit": [10, 99], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 21, 33, 40, 41, 44, 50, 52, 54, 56, 57, 66, 69, 78, 79, 80, 83, 84, 86, 90, 93, 94, 95, 96, 97, 98, 99, 103, 107, 108, 109, 110, 111, 112], "structur": [10, 12, 21, 89, 94, 95, 96, 98, 101, 108], "deriv": [10, 13, 51, 82, 83], "pack": [10, 13, 22, 36, 40, 42, 44, 80], "format": [10, 13, 18, 19, 44, 80, 97, 98, 108, 109, 112], "understand": [10, 80, 93, 110, 112], "concept": [10, 94, 106, 108, 110, 111, 112], "doe": [10, 12, 20, 69, 79, 80, 94, 98, 101, 108, 110, 111], "alreadi": [10, 13, 101, 112], "could": [10, 94, 101, 107, 108, 110, 111, 112], "context": [10, 110, 111], "also": [10, 12, 67, 78, 94, 95, 96, 98, 99, 101, 102, 103, 108, 111, 112], "write": [10, 91, 95, 107, 108, 109], "own": [10, 12, 91, 93, 95, 98, 99, 108, 109, 112], "torchaobasetensor": [10, 103], "help": [10, 12, 93, 94, 97, 103, 107, 108], "common": [10, 69, 79, 80, 81, 82, 91, 93, 94, 98], "specifi": [10, 12, 13, 30, 33, 47, 54, 56, 57, 58, 61, 68, 69, 75, 78, 79, 83, 86, 89, 93, 94, 98, 107, 108, 109, 112], "non": [10, 90, 98, 101, 107, 110, 111], "attribut": [10, 12, 90, 94, 101, 103, 110, 111], "mytensor": [10, 90], "tensor_data_nam": [10, 90], "qdata": [10, 94], "scale": [10, 13, 17, 18, 24, 26, 31, 34, 41, 48, 50, 51, 52, 53, 59, 60, 67, 72, 73, 74, 75, 82, 83, 90, 94, 98, 99, 101, 103, 112], "tensor_attribute_nam": [10, 90], "With": [10, 101, 108, 110, 112], "abov": [10, 12, 42, 44, 48, 94, 96, 98, 99, 101, 108, 109, 112], "ll": [10, 48, 93, 94, 101, 108, 109, 112], "doc": [10, 93, 94, 95, 97, 101, 102], "mani": [10, 94, 98, 101], "still": [10, 12, 94, 98, 108, 112], "affinequantizedtensor": [10, 24, 26, 39, 46, 95, 96, 99, 101], "plan": [10, 44, 46, 109], "move": [10, 78, 99, 103, 109, 110], "awai": 10, "from": [10, 12, 13, 19, 20, 24, 26, 45, 51, 62, 66, 69, 78, 79, 83, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112], "abstract": [10, 94], "easier": [10, 112], "peopl": [10, 94, 96, 103, 112], "implement": [10, 12, 30, 44, 71, 72, 74, 75, 79, 90, 94, 96, 98, 99, 107, 108, 112], "regist": [10, 56, 61, 71, 85, 90, 94, 101], "mai": [10, 13, 51, 67, 80, 94, 96, 99, 102, 108, 109, 110, 111, 112], "well": [10, 17, 94, 95, 98, 108, 109, 112], "int4": [10, 12, 16, 36, 42, 44, 45, 48, 56, 57, 59, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 78, 89, 94, 95, 96, 97, 102, 103], "access": [10, 46, 107], "my_custom_op": 10, "call": [10, 12, 13, 56, 61, 71, 85, 94, 95, 96, 98, 99, 101, 103, 109, 111], "want": [10, 78, 89, 94, 95, 96, 98, 101, 103, 107, 108, 109, 112], "my_mm_for_mp": 10, "aten": [10, 90, 94, 95, 101, 103, 107, 108, 109, 110, 111], "default": [10, 12, 13, 15, 20, 22, 35, 40, 41, 43, 44, 50, 52, 59, 67, 75, 78, 90, 93, 94, 95, 101, 103, 107, 108, 109, 110, 111, 112], "_": [10, 90, 93, 94, 99, 103, 107, 108, 109, 110], "func": [10, 90, 94, 101, 103], "arg": [10, 13, 44, 56, 57, 58, 59, 63, 72, 86, 90, 94, 101, 103, 109, 112], "re": [10, 93, 94, 96, 97, 101, 108, 109], "input_tensor": [10, 19, 94, 103], "weight_tensor": [10, 94, 103], "some": [10, 78, 86, 90, 94, 95, 97, 98, 99, 101, 107, 108, 109, 110, 111, 112], "choic": [10, 44], "mm": [10, 78, 79, 101, 108], "recommend": [10, 12, 41, 43, 44, 45, 46, 47, 93, 94, 102, 107, 110, 111], "wai": [10, 13, 69, 93, 94, 97, 98, 99, 101, 108, 109, 112], "repres": [10, 13, 15, 17, 30, 35, 55, 67, 80, 83, 86, 94, 96, 101, 108, 109], "group_mm": 10, "auto": [10, 41, 79, 97, 102, 103], "develop": [10, 95, 108, 109, 112], "choos": [10, 44, 82, 94, 98, 101, 108, 110], "whatev": 10, "think": [10, 103], "fastest": 10, "under": [10, 12, 79, 97], "condit": 10, "so": [10, 12, 93, 94, 95, 96, 98, 101, 102, 108, 109, 112], "don": [10, 86, 93, 94, 95, 98, 102, 103, 112], "t": [10, 86, 90, 93, 94, 95, 98, 99, 101, 102, 103, 108, 109, 112], "worri": 10, "debug": [10, 79], "purpos": [10, 93, 94, 101, 108], "ha": [10, 12, 13, 69, 97, 98, 101, 103, 107, 108, 109, 111, 112], "hardwar": [10, 41, 79, 80, 95, 97, 98, 102], "h100": [10, 94, 102], "sm89": 10, "sm90": 10, "librari": [10, 79, 80, 91, 94, 96], "whether": [10, 12, 44, 50, 67, 90, 101], "fbgemm_gpu_genai": [10, 79, 94], "granular": [10, 13, 31, 41, 44, 45, 46, 47, 50, 52, 56, 57, 59, 60, 67, 68, 83, 93, 94, 97, 99, 103], "per": [10, 12, 13, 42, 43, 45, 46, 47, 50, 52, 59, 63, 64, 65, 67, 71, 72, 74, 75, 83, 86, 93, 94, 95, 98, 99, 111], "_choose_scale_float8": [10, 50, 94], "_quantize_affine_float8": [10, 94], "_scaled_mm": [10, 94], "kerenel": 10, "fbgemm": [10, 79, 94, 98], "f8f8bf16_rowwis": [10, 94], "level": [10, 86, 94, 98, 101, 107, 108, 110, 111], "reus": [10, 101], "allow": [10, 75, 94, 95, 98, 101, 107, 108, 109, 110, 112], "appli": [10, 12, 13, 41, 42, 43, 45, 46, 47, 54, 58, 59, 61, 66, 68, 69, 78, 89, 90, 94, 95, 97, 98, 103, 109], "convers": [10, 12, 13, 33], "weight": [10, 12, 18, 19, 34, 41, 42, 43, 44, 45, 46, 47, 56, 57, 59, 63, 64, 65, 67, 69, 71, 72, 74, 75, 78, 81, 86, 89, 91, 93, 95, 96, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 112], "filter": [10, 12, 33, 93, 99], "should": [10, 12, 13, 34, 52, 56, 61, 62, 69, 71, 85, 86, 90, 93, 98, 103, 107, 108, 112], "algorithm": [10, 44, 97, 98, 107], "dynam": [10, 12, 29, 30, 34, 41, 42, 45, 46, 59, 65, 67, 75, 89, 97, 99, 101, 102, 108, 109, 110], "quant": [10, 13, 39, 94, 97, 103, 108, 111, 112], "In": [10, 12, 44, 69, 93, 94, 95, 98, 99, 101, 107, 108, 109, 110, 111, 112], "order": [10, 54, 90, 98, 101, 112], "aim": [10, 98, 111], "run": [10, 12, 34, 56, 57, 61, 71, 78, 79, 85, 93, 94, 95, 97, 98, 101, 106, 107, 108, 109, 110, 111, 112], "fullgraph": [10, 95], "true": [10, 12, 13, 25, 30, 41, 43, 44, 45, 46, 47, 50, 51, 56, 57, 66, 67, 69, 77, 78, 89, 93, 95, 96, 97, 99, 101, 102, 103, 107, 108, 109, 110, 112], "remov": [10, 50, 86, 93, 98, 103, 108, 109], "unnecessari": 10, "graph": [10, 95, 108, 109, 112], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 95, 97, 99, 101, 106, 109, 110, 111], "inductor": [10, 91, 95, 107, 108], "save": [10, 12, 86, 90, 93, 95, 96, 97, 103], "load": [10, 90, 96, 97, 102, 103], "relev": [10, 94, 106], "object": [10, 40, 78, 89, 94, 101, 108, 109, 112], "safe": [10, 84], "global": [10, 98, 101], "after": [10, 12, 34, 93, 94, 96, 98, 102, 107, 108, 109, 110, 111, 112], "2": [10, 13, 14, 16, 18, 21, 41, 43, 44, 46, 47, 48, 56, 67, 71, 72, 83, 87, 89, 91, 93, 94, 98, 99, 101, 106], "5": [10, 12, 48, 56, 86, 95, 97, 98, 103, 106, 108, 109], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 94], "checkout": [10, 13, 39, 91, 94], "huggingfac": [10, 102], "transform": [10, 12, 13, 90, 99, 107, 108, 109, 110, 111], "deseri": [10, 108, 109], "save_pretrain": [10, 97, 102], "push_to_hub": [10, 97, 102, 103], "from_pretrain": [10, 12, 97, 102, 103], "diffus": [10, 97], "just": [10, 48, 67, 94, 96, 98, 101, 108, 109, 112], "talk": [10, 94, 97], "train": [10, 30, 54, 67, 69, 91, 95, 98, 101, 112], "fsdp": [10, 94], "mydtypetensor": 10, "put": [10, 89, 110, 112], "developer_api_guid": 10, "folder": [10, 97, 108, 109], "cover": [10, 106, 108, 111, 112], "follow": [10, 12, 67, 69, 90, 93, 94, 95, 97, 98, 99, 101, 102, 107, 108, 109, 110, 111, 112], "executorch": [10, 45, 91, 95, 102, 108, 109], "torchchat": 10, "dtensor": [10, 101], "copi": [10, 13, 86, 95, 96, 98, 99, 101, 109, 110], "past": [10, 98], "adapt": [10, 93, 99], "befor": [10, 12, 69, 78, 94, 96, 97, 98, 99, 101, 108, 109, 112], "do": [10, 49, 53, 78, 94, 97, 98, 99, 101, 103, 108, 109, 110, 112], "singl": [10, 12, 29, 34, 41, 51, 93, 95, 98, 108, 112], "comput": [10, 18, 22, 34, 43, 56, 61, 71, 79, 85, 86, 94, 98, 99, 101, 102, 108, 109, 110, 111], "intens": 10, "get": [10, 12, 19, 75, 90, 93, 94, 95, 97, 98, 103, 107, 108, 109, 110, 112], "sens": [10, 94, 101], "d": [10, 90, 97, 109], "benchmark_aq": 10, "": [10, 12, 13, 48, 50, 52, 79, 80, 83, 90, 93, 94, 95, 97, 98, 99, 101, 108, 109, 110, 111, 112], "import": [10, 12, 62, 66, 69, 78, 89, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 110, 111], "A": [10, 12, 13, 40, 51, 79, 85, 90, 94, 98, 101, 102, 103, 108], "quick": [10, 91], "chang": [10, 78, 93, 95, 96, 97, 98, 99, 101, 107, 108, 109, 111, 112], "interest": [10, 98, 101], "print_op_and_shap": 10, "output": [10, 12, 30, 50, 52, 83, 93, 94, 95, 97, 98, 102, 106, 107, 108, 109, 110, 111, 112], "torch_func": 10, "built": [10, 93, 101], "_c": 10, "tensorbas": 10, "all": [10, 34, 44, 48, 51, 56, 59, 61, 63, 71, 73, 85, 86, 87, 90, 94, 95, 96, 97, 98, 99, 101, 103, 104, 107, 108, 110, 112], "benchmark_your_kernel": 10, "helper": [10, 76, 77, 90], "right": [10, 42, 44, 98, 108], "1": [10, 18, 31, 32, 40, 41, 43, 44, 46, 47, 48, 49, 50, 60, 70, 78, 79, 80, 82, 83, 86, 91, 94, 95, 96, 98, 99, 101, 106, 108, 109], "feel": [10, 94, 98, 101, 103], "free": [10, 94, 101], "either": [10, 13, 41, 60, 69, 86, 97, 98, 109, 110, 111], "one": [10, 41, 51, 56, 61, 69, 71, 85, 93, 94, 98, 101, 103, 109, 112], "probabl": 10, "keep": [10, 18, 46, 50, 86, 94, 108], "futur": [10, 99, 102, 103, 108, 109, 110, 112], "llama": [10, 12, 97, 102, 103, 107], "llama2": 10, "llama3": [10, 12, 93, 102], "sam": 10, "modifi": [10, 33, 78, 86, 93, 98, 101], "friendli": 10, "compar": [10, 12, 86, 93, 94, 97, 108, 110, 112], "techniqu": [10, 12, 93, 96, 97, 98, 99, 101, 103], "bound": [10, 41, 60, 97, 98, 103], "each": [10, 19, 59, 67, 72, 74, 75, 85, 90, 94, 98, 99, 101, 103, 108, 109, 112], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 48, 83, 94, 95, 98, 99, 101, 112], "u": [10, 98, 107], "know": [10, 101], "end": [12, 93, 94, 97, 98, 101, 102, 103, 109, 112], "pre": [12, 17, 18, 22, 91, 97, 98, 112], "serv": [12, 13, 17, 91, 93, 101, 102, 111], "flow": [12, 45, 93, 97, 98, 99, 107, 108, 109, 110, 111], "leverag": [12, 93, 95, 97, 101, 110, 111], "partner": [12, 93, 97], "showcas": [12, 93, 97], "focus": [12, 93, 94, 97, 98], "domain": [12, 13, 50, 52, 67, 93], "demonstr": [12, 93, 94, 95, 97, 101, 107, 109], "dure": [12, 13, 39, 46, 52, 67, 69, 93, 95, 97, 98, 99, 101, 107, 109], "numer": [12, 69, 74, 75, 79, 93, 98, 108, 109, 110], "goal": [12, 69], "mitig": [12, 98], "degrad": [12, 69, 98], "eventu": [12, 69, 93], "blog": 12, "resourc": [12, 101], "small": 12, "matric": [12, 21, 98], "freez": [12, 109, 110, 111], "checkpoint": [12, 90, 93, 97, 103], "effici": [12, 22, 74, 95, 98, 99, 111], "paper": [12, 98, 106], "speed": [12, 78, 97, 98, 107], "up": [12, 19, 67, 78, 93, 94, 95, 98, 107, 108, 109, 112], "high": [12, 13, 23, 24, 25, 26, 60, 69, 93, 94, 97, 98, 99, 101, 107, 108, 110, 111], "precis": [12, 13, 23, 24, 25, 26, 43, 46, 59, 60, 64, 65, 69, 72, 74, 75, 94, 99, 101, 102, 107, 110, 111], "similar": [12, 98, 99, 109, 110], "inevit": 12, "actual": [12, 43, 69, 79, 94, 99, 101, 103, 108, 109, 112], "presum": 12, "been": [12, 90, 101, 109, 110, 111, 112], "successfulli": [12, 98], "recent": [12, 91], "releas": [12, 110], "1b": [12, 102, 103], "3b": 12, "llamaguard": 12, "8b": [12, 93, 102], "improv": [12, 93, 97, 98, 108, 111, 112], "qualiti": [12, 98, 102], "involv": [12, 15, 69, 98], "two": [12, 21, 39, 41, 69, 90, 94, 95, 98, 101, 107, 108, 109, 110, 112], "separ": [12, 56, 57, 67, 98, 103, 108, 112], "prepar": [12, 54, 59, 63, 69, 86, 98, 107, 110, 111, 112], "convert": [12, 13, 19, 23, 25, 27, 28, 30, 39, 54, 62, 63, 69, 78, 89, 93, 94, 97, 98, 107, 110, 111, 112], "fake": [12, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77, 93, 108, 109, 112], "mean": [12, 13, 19, 48, 50, 52, 83, 90, 93, 94, 95, 98, 108, 109, 112], "valu": [12, 13, 19, 30, 31, 32, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 60, 70, 79, 80, 83, 86, 94, 98, 99, 101, 107, 108, 109, 112], "map": [12, 46, 48, 67, 90, 94, 101, 108, 112], "without": [12, 62, 94, 98, 103, 110, 112], "cast": [12, 13, 29, 31], "lower": [12, 41, 45, 60, 94, 95, 97, 98, 99, 102, 109], "replac": [12, 98, 103], "real": [12, 94, 95, 108, 112], "perform": [12, 13, 22, 34, 46, 47, 53, 56, 61, 63, 64, 65, 71, 84, 85, 93, 95, 98, 99, 101, 102, 103, 107, 109, 110, 111], "There": [12, 69, 94, 99, 101, 108, 112], "directli": [12, 48, 51, 69, 94, 98, 99, 101], "loop": [12, 93, 98], "distribut": [12, 93, 99, 101, 103, 107], "recip": [12, 30, 56, 61, 71, 85], "instead": [12, 51, 56, 61, 62, 66, 67, 69, 71, 85, 93, 95, 98, 101, 109, 110, 111, 112], "command": [12, 93], "regular": [12, 107, 110, 111], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 18, 21, 28, 87, 89, 94, 95, 96, 97, 98, 101, 102, 108, 109], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 96, 97, 99, 108, 109], "16": [12, 57, 93], "equival": [12, 67, 98, 109, 110, 112], "asymmetr": [12, 45, 48, 50, 67, 95, 99, 107, 111, 112], "token": [12, 45, 46, 65, 67, 75, 93, 97, 102], "int8": [12, 19, 45, 46, 47, 57, 65, 66, 67, 69, 75, 78, 82, 89, 94, 97, 101, 108, 110, 111, 112], "symmetr": [12, 41, 43, 45, 46, 47, 48, 50, 56, 59, 67, 101, 107, 108, 111, 112], "configur": [12, 15, 29, 30, 33, 41, 42, 43, 44, 45, 46, 47, 78, 89, 93, 94, 95, 97, 102, 110, 111, 112], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 109], "same": [12, 13, 41, 44, 50, 51, 52, 75, 83, 84, 89, 90, 93, 94, 98, 99, 101, 109, 111, 112], "wa": [12, 101, 109], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 102], "int8dynactint4weightquant": 12, "groupsiz": [12, 64, 65, 74, 75, 83], "32": [12, 44, 45, 57, 66, 67, 69, 71, 72, 78, 89, 93, 95, 96, 97, 99, 101, 109], "hellaswag": [12, 97], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 97], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 97], "ckpt": 12, "llama3_token": 12, "path": [12, 78, 84, 95, 97, 107, 108, 109, 110, 112], "tmp": [12, 95], "meta": [12, 96, 102, 103, 112], "print": [12, 86, 95, 96, 97, 101, 106, 108, 109], "version": [12, 16, 41, 43, 44, 46, 47, 67, 78, 94, 96, 101, 103, 108, 109, 112], "shot": [12, 98], "stderr": 12, "none": [12, 13, 15, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 39, 41, 44, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 66, 67, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 82, 83, 86, 89, 90, 94, 99, 101, 103, 107, 108, 109, 111], "acc": [12, 108, 109], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 95, 98, 112], "openassist": 12, "oasst1": 12, "dataset": [12, 93, 97, 107, 110, 111], "find": [12, 19, 98, 108, 112], "achiev": [12, 19, 93, 98, 99, 101, 109, 110], "higher": [12, 93, 101, 102, 107, 108, 110, 111], "accuraci": [12, 93, 97, 98, 99, 107, 109, 110], "than": [12, 40, 67, 93, 94, 98, 101, 108], "recov": [12, 98, 109], "69": [12, 99], "8": [12, 22, 40, 44, 48, 56, 57, 64, 74, 93, 94, 95, 97, 103, 110, 111], "overal": [12, 91, 95, 108, 112], "vanilla": 12, "compos": [12, 54, 94, 98, 101, 108, 109, 112], "lora": 12, "yield": [12, 98], "89x": 12, "usag": [12, 13, 34, 54, 56, 57, 62, 66, 67, 69, 90, 91, 93, 97, 110, 111], "36": [12, 93, 97], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 41, 43, 44, 45, 46, 47, 51, 67, 78, 86, 90, 95, 98, 107, 109, 110, 111], "try": [12, 98, 101, 108], "fsdp2": [12, 93], "yaml": 12, "onc": [12, 98], "complet": [12, 97, 107, 111], "qat_out": 12, "quatiz": 12, "document": [12, 101, 103, 107, 108, 110], "prefer": [12, 41, 94, 101], "These": [12, 98, 101, 107, 108, 109, 112], "what": [12, 13, 39, 93, 94, 95, 97, 98, 99, 103, 106, 108, 112], "hood": 12, "mini": [12, 97], "gpu": [12, 91, 93, 95, 102, 103, 106, 107], "smaller": [12, 40, 44, 45, 95, 96], "fit": [12, 13, 22, 94, 96], "adjust": [12, 41, 43, 44, 45, 46, 47], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 93], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 93], "max_seq_len": 12, "train_loop": [12, 69], "sgd": 12, "lr": [12, 93], "001": 12, "momentum": [12, 109], "9": [12, 93], "weight_decai": 12, "1e": [12, 93], "loss_fn": 12, "crossentropyloss": [12, 108, 109], "rang": [12, 48, 93, 98, 99, 108, 109], "randint": 12, "loss": [12, 93, 98, 108, 109], "backward": [12, 34, 93, 98, 109], "zero_grad": [12, 93, 109], "next": [12, 93, 99, 108, 109, 110, 111], "scheme": [12, 46, 47, 56, 57, 69, 97, 107], "although": [12, 44, 56, 61, 71, 85, 101], "integ": [12, 13, 25, 26, 48, 50, 52, 53, 67, 68, 84, 99, 108, 109, 110], "arithmet": [12, 69], "float": [12, 13, 19, 25, 27, 28, 39, 41, 44, 48, 50, 51, 52, 56, 60, 67, 71, 72, 83, 86, 94, 95, 96, 101, 108, 109, 112], "float32": [12, 13, 24, 52, 63, 65, 67, 71, 72, 75, 83, 96, 97, 98, 99, 101, 110, 111, 112], "becaus": [12, 13, 18, 93, 96, 98, 101, 109, 112], "int8dynamicactivationint4weightconfig": [12, 69, 75], "qatconfig": [12, 62, 66, 70], "swap": [12, 33, 59, 63, 93, 98, 99, 109], "fakequantizedlinear": [12, 59, 62, 76, 77], "base_config": [12, 69], "exact": [12, 75, 108, 109], "attun": 12, "benefici": 12, "later": [12, 94, 101, 108, 109, 111], "readi": [12, 93, 95, 97, 99, 101, 109], "did": [12, 45], "altern": [12, 67, 99, 101, 110, 111], "legaci": [12, 44], "offer": [12, 101, 108], "customiz": [12, 78], "unlik": [12, 99], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 95, 99, 107, 108, 109, 110, 111, 112], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 107, 108, 110, 111], "footprint": 12, "extens": [12, 101, 108, 110], "addition": [12, 110, 111], "frozen": 12, "further": [12, 101, 107, 108, 109, 110], "nf4": [12, 19], "propos": [12, 86], "express": [12, 95, 101, 107, 108, 109, 112], "subclass": [12, 13, 33, 39, 56, 61, 71, 79, 80, 85, 89, 90, 94, 95, 96, 98, 102], "nf4tensor": 12, "cleanli": 12, "compil": [12, 78, 84, 91, 93, 94, 95, 99, 101, 110, 111], "simpli": [12, 98, 99, 101], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 25, 30, 33, 41, 43, 44, 45, 46, 47, 50, 51, 56, 57, 65, 67, 71, 72, 74, 75, 77, 78, 89, 99], "quantization_kwarg": 12, "No": [12, 94, 96, 98], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 94, 99, 101, 103], "though": [12, 101], "shown": [12, 97, 98, 109, 112], "competit": [12, 93], "baselin": [12, 93, 97, 108], "while": [12, 56, 61, 69, 71, 81, 85, 86, 97, 98, 101, 102, 107, 108, 112], "even": [12, 13, 93, 98, 112], "newer": 12, "mxfp4": [12, 94], "nvfp4": [12, 94], "blackwel": 12, "reap": 12, "benefit": [12, 42, 98, 101, 108, 111], "vari": [12, 13, 108, 109, 110, 111], "tradeoff": [12, 98, 102], "incorpor": 12, "its": [12, 98, 101, 103, 108, 112], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 93, 94, 101, 103, 108], "yet": [12, 45, 49, 69, 101, 103, 109, 110, 111], "invok": [12, 110], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 97, 102, 103], "torchaoconfig": [12, 97, 102, 103], "int8weightonlyconfig": [12, 78, 102, 103], "base_model": 12, "quantization_config": [12, 97, 102, 103, 111], "peft_config": 12, "throughput": [12, 93, 97], "increas": [12, 98, 108], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 29, 30, 94], "initi": [12, 13, 73, 94, 95, 96, 109], "experi": [12, 93, 111], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 93, 95, 108], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 93], "074": [12, 93], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 93], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 93, 111, 112], "407": [12, 93], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 93], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 39, 90, 99], "aqttensorimpl": [13, 39], "block_siz": [13, 17, 19, 23, 24, 25, 26, 27, 28, 39, 50, 51, 52, 83, 94, 95, 99], "tupl": [13, 19, 23, 24, 25, 26, 27, 39, 41, 50, 51, 52, 73, 83, 86, 90, 101, 103, 108, 109, 112], "quant_min": [13, 25, 26, 27, 39, 48, 50, 51, 52, 83, 95, 101, 111, 112], "union": [13, 30, 39, 41, 50, 52, 60, 67, 78, 83], "quant_max": [13, 25, 26, 27, 39, 48, 50, 51, 52, 83, 95, 101, 111, 112], "zero_point_domain": [13, 25, 26, 27, 39, 44, 50, 51, 67], "zeropointdomain": [13, 25, 26, 27, 39, 44, 50, 51, 67], "stride": [13, 39, 101], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 104, 106], "affin": [13, 14, 15, 16, 18, 21, 22, 25, 36, 37, 52, 83, 94], "point": [13, 27, 39, 44, 48, 52, 60, 67, 72, 73, 74, 75, 93, 94, 95, 96, 98, 99, 101, 108, 112], "quantized_tensor": 13, "float_tensor": [13, 101], "zero_point": [13, 17, 26, 50, 51, 52, 83, 90, 94, 98, 99, 101, 112], "happen": [13, 39, 94, 101, 108, 110], "choose_qparam": [13, 94], "dequant": [13, 19, 39, 52, 79, 94, 95, 101, 103, 108, 110, 111, 112], "ao": [13, 39, 98, 103], "three": [13, 86, 89, 110, 111], "choose_qparams_affin": [13, 51], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 93, 94, 98, 107, 108, 109, 110, 111], "extern": [13, 110], "regardless": 13, "intern": [13, 22], "represent": [13, 17, 90, 98, 103, 108, 112], "orient": 13, "field": [13, 67, 70, 90, 112], "impl": [13, 90], "storag": [13, 18, 98], "store": [13, 18, 19, 40, 46, 81, 85, 94, 98, 102, 103, 108, 109], "plain": [13, 41, 44, 80, 94, 103], "int_data": [13, 101], "kernel": [13, 14, 16, 18, 22, 36, 41, 42, 74, 78, 79, 95, 97, 98, 107, 110, 111], "element": [13, 21, 40, 50, 52, 59, 72, 74, 75, 83, 90, 94, 98], "share": [13, 50, 52, 83, 98], "qparam": [13, 44, 50, 52, 83], "minimum": [13, 50, 52, 83], "maximum": [13, 50, 52, 83], "zero": [13, 21, 44, 46, 50, 52, 67, 72, 73, 74, 75, 86, 98, 99, 112], "subtract": [13, 19], "unquant": [13, 112], "given": [13, 28, 39, 82, 93, 98, 103, 112], "classmethod": [13, 39, 81, 90, 99, 101, 103], "from_hp_to_floatx": 13, "input_float": [13, 23, 24, 25, 26, 27, 39], "target_dtyp": [13, 23, 24, 25, 26, 29, 30, 50, 51, 94, 99], "_layout": [13, 23, 24, 25, 26, 27, 39, 90, 95, 99], "layout": [13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 37, 38, 39, 40, 44, 45, 46, 89, 90, 98], "scale_dtyp": [13, 23, 24, 25, 50, 51, 99], "float8": [13, 14, 15, 23, 24, 29, 30, 31, 32, 33, 34, 41, 42, 43, 59, 60, 61, 82, 91, 97, 99], "from_hp_to_floatx_stat": 13, "static": [13, 17, 19, 24, 26, 30, 51, 67, 91, 95, 108, 109, 110, 111, 112], "from_hp_to_intx": [13, 39], "mapping_typ": [13, 25, 45, 50, 51, 67], "mappingtyp": [13, 25, 45, 46, 50, 51, 67, 99], "ep": [13, 25, 50, 51, 67, 99, 109, 111, 112], "zero_point_dtyp": [13, 25, 50, 51, 99], "preserve_zero": [13, 25, 44, 50, 51], "plainlayout": [13, 25, 26, 45, 46, 90, 99], "use_hqq": [13, 25, 44, 102, 103], "custom_scal": [13, 25], "custom_zero_point": [13, 25], "from_hp_to_intx_stat": 13, "argument": [13, 22, 52, 67, 69, 78, 81, 90, 93, 94, 97, 110], "correct": [13, 18, 108, 109], "otherwis": [13, 47, 54, 67, 109], "desir": [13, 99], "gradient": [13, 91, 98], "implicitli": [13, 112], "complex": [13, 98], "non_block": 13, "memory_format": [13, 110, 111], "preserve_format": 13, "accord": 13, "c": [13, 90, 95, 101, 110, 111], "rule": 13, "truncat": 13, "part": [13, 91, 98, 101, 102, 109], "cannot": [13, 98, 99, 103], "inf": 13, "long": [13, 101, 108], "behavior": [13, 17, 54, 103, 108, 109], "undefin": [13, 54, 86], "across": [13, 86, 97, 98, 101, 103], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 98, 109], "host": [13, 103], "both": [13, 41, 44, 69, 75, 94, 95, 98, 99, 101, 108, 110, 111, 112], "pin": 13, "pageabl": 13, "howev": [13, 98, 102, 103, 109, 112], "caution": 13, "advis": [13, 94], "good": [13, 95, 101, 112], "pin_memori": 13, "match": [13, 52, 53, 74, 75, 90, 98, 108], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 36], "mm_config": [15, 41], "float8mmconfig": [15, 41], "variabl": [15, 22, 35, 40, 86, 90, 98], "tinygemm": [16, 44, 74, 78, 95], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 67, 93, 94, 95, 97, 98, 108, 109, 110], "It": [17, 18, 20, 22, 34, 95, 98, 101, 112], "post": [17, 22, 69, 91, 94, 95, 101, 109, 112], "design": [17, 18, 21, 97, 103, 107, 108, 112], "extend": [17, 94, 98, 110], "conjunct": 17, "tensorimpl": [17, 90], "interact": [17, 108], "spars": [18, 21, 35, 56, 71, 72, 86, 98], "marlin": [18, 27, 38, 39], "pattern": [18, 21, 94, 95, 103, 107, 108], "preprocess": [18, 21], "manag": 18, "pre_process": 18, "1\u00ba": 18, "transpos": [18, 101], "sinc": [18, 42, 56, 61, 71, 85, 94, 96, 97, 98, 99, 101, 108, 109, 110, 111, 112], "2\u00ba": 18, "inject": 18, "3\u00ba": 18, "again": [18, 19, 98, 108, 112], "dim": [18, 46, 47, 60, 99, 101, 103, 108, 109], "tensor_meta": 19, "subclasstensorarg": 19, "n_block": 19, "scaler_block_s": [19, 28], "quantized_scal": 19, "quantization_factor": 19, "scaler_mean": 19, "quantized_data": [19, 103], "qlora": [19, 91, 97], "convert_to_norm_float_weight": 19, "normal": [19, 28, 98, 108, 109], "dequantize_scal": 19, "unpack": 19, "doubl": 19, "scaler": 19, "per_scaler_block": 19, "factor": [19, 53, 93, 98], "inpt_weight": 19, "block": [19, 35, 86, 98], "double_quantize_scal": 19, "take": [19, 56, 61, 71, 78, 85, 89, 90, 94, 98, 107, 108, 109, 110, 111, 112], "calcul": [19, 34, 41, 48, 50, 51, 60, 94, 98, 108, 112], "absmax": 19, "posit": 19, "And": [19, 41, 101, 110, 112], "per_block": 19, "int16": [19, 108], "n_scaler_block": 19, "get_original_weight": 19, "quantize_tensor_nearest": 19, "float16": [19, 83, 98], "nearest": 19, "round": [19, 48, 101], "inherit": [20, 39, 90, 101, 103, 110, 111], "metadata": [20, 90, 94, 97, 101, 103], "semi": [21, 89, 98], "everi": [21, 56, 61, 71, 85, 98, 101, 108, 109], "four": [21, 107], "prune": [21, 86], "conform": 21, "inner_k_til": [22, 44, 64, 74, 95], "core": [22, 49, 78, 99, 103, 108], "tile": 22, "affect": [22, 79, 98], "matmul": [22, 41, 43, 94, 98, 101], "qqq": [27, 38, 39], "64": [28, 35, 44, 59, 96, 97, 99, 101, 103], "256": [28, 44, 63, 64, 65, 74, 75, 97, 108, 109, 112], "scaling_typ": [29, 30], "scalingtyp": [29, 30], "scaling_granular": [29, 30], "scalinggranular": [29, 30], "mayb": 29, "cast_config_input": 30, "castconfig": 30, "cast_config_input_for_grad_weight": 30, "cast_config_weight": 30, "cast_config_weight_for_grad_input": 30, "cast_config_grad_output": 30, "cast_config_grad_output_for_grad_weight": 30, "gemm_config_output": 30, "float8gemmconfig": 30, "use_fast_accum": 30, "gemm_config_grad_input": 30, "gemm_config_grad_weight": 30, "enable_fsdp_float8_all_gath": 30, "pad_inner_dim": 30, "emul": [30, 79], "force_recompute_fp8_weight_in_bwd": 30, "round_scales_to_power_of_2": 30, "from_recipe_nam": 30, "recipe_nam": [30, 93], "float8linearrecipenam": 30, "qualnam": [31, 32, 48, 49, 70, 79, 80], "boundari": [31, 32, 48, 49, 70, 79, 80], "strategi": 31, "module_filter_fn": [33, 93], "callabl": [33, 78, 89, 90, 103], "float8linearconfig": 33, "float8linear": [33, 93], "instanc": [33, 56, 61, 71, 78, 85, 89, 90, 96, 101, 108, 110, 111, 112], "fqn": [33, 86, 89, 93, 99], "sum": [34, 108, 109], "prototyp": [35, 36, 37, 38, 39, 40, 67, 73, 94, 112], "blocksiz": 35, "da8w4": 37, "marlinqqq": 39, "_choose_qparams_and_quantize_affine_qqq": 39, "_dequantize_affine_qqq": 39, "pack_dim": 40, "uintx": 40, "standard": [40, 103], "byte": 40, "uintxtensor": 40, "determin": [40, 50, 69, 93, 98, 103], "along": [40, 98, 103, 107], "indic": [40, 98, 112], "last": [40, 93, 107], "activation_dtyp": [41, 94], "float8_e4m3fn": [41, 43, 60, 94], "weight_dtyp": [41, 43, 94, 97], "pertensor": [41, 47, 60, 99], "perrow": [41, 46, 47, 60, 94], "list": [41, 52, 54, 86, 90, 95, 101, 102, 103, 107, 109, 112], "packing_format": [41, 44], "float8packingformat": 41, "activation_value_lb": 41, "activation_value_ub": 41, "kernel_prefer": [41, 94], "kernelprefer": 41, "set_inductor_config": [41, 43, 44, 45, 46, 47], "fp8granular": [41, 60], "fast": [41, 98], "accumul": 41, "upper": [41, 60], "defalut": 41, "chosen": [41, 82, 98], "torchinductor": [41, 43, 44, 45, 46, 47, 110, 111], "deprec": [41, 43, 44, 46, 62, 66], "int4_packing_format": [42, 44, 95], "int4packingformat": [42, 44], "preshuffl": [42, 94], "128": [42, 44, 93, 97, 99, 101, 102, 103, 111, 112], "underli": [42, 97, 101], "bigger": 42, "channel": [43, 46, 47, 59, 63, 64, 65, 67, 71, 72, 74, 75, 85, 99, 111], "tensorcoretiledlayout": [44, 95], "int4_choose_qparams_algorithm": [44, 95], "int4chooseqparamsalgorithm": 44, "groupwis": 44, "mainli": [44, 94, 107, 110, 112], "distinguish": [44, 94], "control": [44, 45, 46, 86, 98, 103, 108], "fine": [44, 45, 91, 93, 97, 98], "grain": [44, 45, 101], "variant": [44, 48, 51, 101], "hqq": [44, 94, 95], "preserv": [44, 50, 86, 97, 98, 107], "Will": 44, "subset": [44, 94], "valid": [44, 90, 97, 103, 112], "state": [44, 103], "v1": [44, 97], "v2": [44, 106], "ignor": [44, 56, 61, 71, 85, 93, 108, 109], "less": [44, 48, 98, 101, 108], "confus": [44, 94, 98, 108], "act_mapping_typ": [45, 46], "produc": [45, 95, 107, 108, 109, 110, 111], "backend": [45, 91, 95, 97, 98, 112], "marlinqqqlayout": 45, "cutlassint4packedlayout": 45, "weight_only_decod": 46, "around": [46, 93, 94, 95, 96, 108], "decod": [46, 97], "better": [46, 47, 93, 101, 108, 109, 110, 111, 112], "split": [46, 97, 108, 109], "int8tensor": [46, 94], "number": [48, 59, 72, 74, 75, 86, 97, 98, 101, 109, 110], "sai": [48, 83, 94, 102, 103, 112], "3": [48, 56, 83, 91, 93, 94, 95, 98, 102, 106, 108, 109], "7": [48, 93, 97, 110, 111], "symmetric_no_clipping_err": 48, "smin": 48, "smax": 48, "min_val_neg": [48, 101], "max_val_po": [48, 101], "By": [48, 98], "individu": [48, 98], "error": [48, 67, 93, 101, 108], "neg": 48, "placehold": [49, 94, 111], "int32": [50, 63, 67, 71, 72, 94, 95, 108, 112], "keepdim": [50, 101, 108, 109], "fp32": [50, 52, 67, 75, 99, 101, 108, 110], "fp16": 50, "optioanl": 50, "align": 50, "param": [50, 51, 86, 97], "request": [50, 52, 83], "min_val": [51, 101], "max_val": [51, 101], "observ": [51, 85, 94, 98, 99, 107, 108, 109, 110, 111, 112], "obtain": 51, "track": [51, 102, 103], "calibr": [51, 95, 107, 109, 110, 111], "mostli": [51, 69, 95], "input_dtyp": 52, "output_dtyp": [52, 71, 83], "uint8": [52, 83, 94, 99, 112], "b": [53, 79, 90], "scales1": 53, "multipli": [53, 84, 98], "second": [53, 69, 90, 93, 94, 106, 112], "rais": [53, 66, 69, 84, 101, 103], "assertionerror": [53, 84, 101], "expect": [53, 93, 98, 101, 107, 108, 110, 111, 112], "qat": [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 91, 97, 110], "twostepquant": 54, "easili": [54, 107], "thei": [54, 93, 95, 98, 101, 102, 108, 109, 112], "constructor": [54, 90, 101], "must": [54, 67, 69, 75, 93, 98, 102, 103, 109, 111, 112], "embed": [54, 56, 63, 66, 69, 71, 72], "my_quant": 54, "qatquantizer1": 54, "qatquantizer2": 54, "qatquantizer3": 54, "num_embed": [56, 71, 72], "embedding_dim": [56, 71, 72], "padding_idx": [56, 71, 72], "max_norm": [56, 71, 72], "norm_typ": [56, 71, 72], "scale_grad_by_freq": [56, 71, 72], "weight_config": [56, 57, 66, 69], "fakequantizeconfigbas": [56, 57, 66, 69], "intxfakequantizeconfig": [56, 57, 66, 68, 69], "fq_embed": 56, "longtensor": 56, "overridden": [56, 61, 71, 85], "within": [56, 61, 71, 85, 97, 98, 103, 110, 111], "afterward": [56, 61, 71, 85], "former": [56, 61, 71, 85], "care": [56, 61, 71, 85, 96, 98, 108], "hook": [56, 61, 71, 85, 94], "latter": [56, 61, 71, 85, 109], "silent": [56, 61, 71, 85, 110], "in_featur": [57, 74, 75, 93, 95, 96, 99, 101], "out_featur": [57, 74, 75, 93, 95, 99, 101], "activation_config": [57, 66, 69], "per_token": [57, 66, 67, 69], "is_symmetr": [57, 66, 67, 69], "fq_linear": 57, "scale_precis": [59, 63, 67, 71, 72], "rowwis": [59, 94], "hp_value_lb": 60, "hp_value_ub": 60, "float8fakequantizeconfig": 61, "fakequantizedembed": 62, "back": [62, 101], "model_with_fake_quantized_linear": 62, "zero_point_precis": [63, 67, 71, 72], "int4weightonlyqatembed": 63, "int4weightonlyembed": 63, "scales_precis": [64, 65, 74, 75], "padding_allow": 65, "valueerror": [66, 69], "torchaodtyp": 67, "is_dynam": [67, 110, 111, 112], "range_learn": 67, "simul": [67, 69, 87, 98], "older": 67, "int1": [67, 94], "int7": [67, 94], "pergroup": [67, 97], "pertoken": 67, "per_channel": 67, "peraxi": [67, 97, 99], "per_group": [67, 83], "combin": [67, 97, 98, 101, 108, 110], "leav": 67, "empti": [67, 94], "keyword": [67, 69, 81, 94], "properti": [67, 68], "throw": 67, "els": [67, 94, 97, 103, 108, 109], "symmetri": 68, "qatstep": 69, "awar": [69, 86, 91, 95, 98, 101], "ptq": [69, 109, 110], "automat": [69, 93, 97, 101, 102, 103, 106], "phase": [69, 112], "int4weightonlyconfig": [69, 78, 95, 96, 102, 103], "experiment": [69, 107], "qat_config": 69, "act_config": 69, "alwai": [69, 97, 101], "One": [69, 98, 101, 103, 112], "enum": [70, 79], "example_input": [73, 95, 96, 99, 107, 108, 109, 110, 111, 112], "intxfakequantizerbas": 73, "weightonlyint4linear": 74, "hardcod": [75, 112], "mod": [76, 77, 93, 98, 101], "disabl": [76, 101, 109], "filter_fn": [78, 89], "_is_linear": [78, 99], "inplac": [78, 86, 95], "fulli": [78, 89, 97, 98, 108], "qualifi": [78, 89, 98], "final": [78, 94, 95, 98, 107, 108, 109, 110, 111, 112], "predefin": [78, 80, 112], "execut": [78, 101, 105], "int8dynamicactivationint8weightconfig": [78, 89, 102], "sequenti": [78, 89, 93], "select": [79, 108], "found": [79, 94, 95, 97, 98, 99, 101], "nativ": [79, 91, 93, 94, 101, 108], "gemm_lowp": 79, "gemm_fp32": 79, "ci": 79, "product": [79, 86, 97, 103, 110, 112], "logic": [79, 95, 101, 103], "lowp": 79, "gemm": [79, 93, 110, 111], "laid": [80, 94], "opaqu": 80, "decid": [80, 98, 99], "adopt": [80, 94], "creation": [81, 103], "construct": [81, 94, 108, 112], "from_hp": [81, 94], "cl": [81, 90, 99, 101, 103], "quant_kwarg": [81, 82], "quantizetensorkwarg": 82, "flexibl": [82, 98, 101, 107, 110], "variou": 82, "tabl": [83, 90, 93, 94, 98], "show": [83, 93, 95, 97, 98, 103, 108, 109], "per_tensor": 83, "per_axi": 83, "axi": [83, 99], "mat2": 84, "consid": [84, 98], "cubla": 84, "fallback": [84, 103], "j": 84, "l2": [85, 98], "norm": [85, 86, 98], "buffer": 85, "x_orig": 85, "sparsity_level": [86, 98], "semi_structured_block_s": 86, "wanda": 86, "sparsifi": [86, 91, 96, 98], "http": [86, 97, 98, 102, 111], "arxiv": [86, 98], "org": [86, 97, 98, 111], "ab": [86, 98], "2306": 86, "11695": 86, "magnitud": [86, 98], "dict": [86, 90, 101, 103, 111, 112], "parametr": 86, "deepcopi": [86, 95, 99, 101, 109], "squash_mask": [86, 98], "params_to_keep": 86, "params_to_keep_per_lay": 86, "squash": 86, "mask": [86, 98], "appropri": [86, 107, 108, 109, 110, 111], "sparse_param": 86, "attach": [86, 98, 112], "kei": [86, 98, 106], "xdoctest": 86, "skip": [86, 94, 98], "local": [86, 97, 98], "hasattr": [86, 103], "submodule1": 86, "linear1": [86, 95, 96, 99, 101], "foo": [86, 108], "bar": [86, 108], "submodule2": 86, "linear42": 86, "baz": 86, "42": [86, 99], "24": 86, "ones": [86, 109], "update_mask": 86, "tensor_nam": [86, 103], "statist": [86, 98, 99, 108, 109], "retriev": 86, "act_per_input": 86, "Then": [86, 101, 111, 112], "whole": [86, 112], "alia": [88, 90, 103], "semisparseweightconfig": 88, "sparsify_": 89, "apply_tensor_subclass": 89, "essenti": [89, 103, 107], "semi_sparse_weight": 89, "semisparselayout": 89, "sparsemarlinlayout": 89, "isinst": [89, 93, 98, 99, 101, 103, 109, 112], "sparse_api": 89, "commonli": [90, 93, 98], "includ": [90, 93, 94, 101, 107, 110, 111, 112], "_get_to_kwarg": 90, "register_layout": 90, "plainaqttensorimpl": [90, 99], "get_tensor_impl_constructor": 90, "tensor_impl_ctr": 90, "simplifi": [90, 107, 108, 110, 111], "implment": 90, "tensor_data": 90, "optional_tensor_data_nam": 90, "boilerpl": 90, "optional_tensor_attribute_nam": 90, "__new__": [90, 101, 103], "exaclti": 90, "present": [90, 98], "__tensor_flatten__": [90, 101, 103], "flatten": 90, "attribute_nam": 90, "__tensor_unflatten__": [90, 101, 103], "tensor_data_dict": [90, 101, 103], "_apply_fn_to_data": [90, 103], "recreat": 90, "__repr__": [90, 101], "_same_metadata": 90, "between": [90, 94, 98, 101, 103, 107, 109, 110, 112], "__setstate__": 90, "serial": [90, 91, 94, 102, 108, 109], "old": 90, "maintain": [90, 97, 98], "bc": 90, "contigu": [90, 94, 110, 111], "detach": [90, 101, 103], "clone": [90, 97, 103], "copy_": [90, 103], "_to_copi": [90, 103], "f": [90, 93, 94, 96, 97, 98, 99, 101, 103, 108, 109], "h": [90, 97], "layout_class": 90, "tensorimplclass": 90, "from_plain": 90, "tensor_class": 90, "aten_op": 90, "decor": [90, 101, 103], "__torch_dispatch__": [90, 101], "implements_torch_funct": 90, "torch_fn": 90, "__torch_function__": [90, 94, 101], "registr": 90, "aqt": 90, "introduct": [91, 94, 97], "highlight": [91, 101, 106], "guid": [91, 94, 97, 107], "contributor": [91, 94, 95], "benchmark": [91, 93, 95, 102, 107, 110, 111], "tune": [91, 93, 97, 98, 107], "vllm": [91, 102], "sglang": [91, 102], "hug": [91, 97], "face": [91, 94, 97, 98, 108], "advanc": [91, 99, 101, 107, 110, 111], "export": [91, 94], "x86": [91, 95], "intel": [91, 107, 110], "openvino": [91, 95], "5x": 93, "cluster": [93, 94], "34": 93, "43x": 93, "2k": 93, "h200": 93, "latest": 93, "offic": 93, "offici": [93, 94], "sever": [93, 103, 107, 112], "popular": 93, "flagship": 93, "form": [93, 94, 98], "quickli": [93, 101], "batteri": 93, "fork": 93, "build": [93, 94, 98, 101, 103, 108], "top": [93, 94, 101, 107, 108, 109, 110, 111], "virtual": 93, "environ": [93, 97], "conda": 93, "venv": 93, "download": [93, 97, 104, 106, 108, 109, 111], "job": 93, "below": [93, 94, 98, 101, 102, 103, 106, 107], "root": [93, 97], "launch": 93, "ngpu": 93, "config_fil": 93, "train_config": 93, "llama3_8b": 93, "toml": 93, "run_train": 93, "sh": [93, 97], "hyperparamet": 93, "edit": [93, 97], "line": [93, 98, 102], "flag": [93, 109], "termin": 93, "rank0": 93, "titan": 93, "2025": 93, "06": 93, "04": 93, "08": 93, "51": 93, "48": 93, "info": 93, "2254": 93, "27": 93, "34gib": 93, "28": 93, "78": 93, "tp": [93, 103], "375": 93, "tflop": 93, "21": 93, "73": [93, 99], "mfu": 93, "20": [93, 97, 109], "58": 93, "557": 93, "7069": 93, "99gib": 93, "62": 93, "034": 93, "35": [93, 97, 99], "41": [93, 97], "19": 93, "52": 93, "224": [93, 99, 107, 108, 109, 110, 111], "9196": 93, "022": 93, "406": [93, 108, 109], "65": 93, "904": 93, "1423": 93, "014": 93, "23": [93, 99], "As": [93, 108, 112], "warmup": 93, "7k": 93, "99gb": 93, "peak": [93, 97, 102], "against": 93, "02": 93, "37": 93, "404": 93, "2611": 93, "22gib": 93, "595": 93, "47": 93, "49": [93, 99], "027": 93, "4260": 93, "89gib": 93, "344": 93, "367": 93, "39": 93, "03": 93, "01": 93, "988": 93, "9482": 93, "321": 93, "366": 93, "14": 93, "991": 93, "1183": 93, "300": 93, "364": 93, "89": 93, "40": 93, "4659": 93, "291": 93, "84": 93, "769": 93, "gc": 93, "peform": 93, "period": 93, "collect": [93, 98], "3k": 93, "89gb": 93, "11x": 93, "nearli": 93, "ident": [93, 98], "performan": 93, "v": [93, 98, 108, 112], "curv": [93, 98], "omit": [93, 94, 108, 109, 110], "648": 93, "2648": 93, "28gib": 93, "71": 93, "26": 93, "475": 93, "9106": 93, "91gib": 93, "53": [93, 97], "503": 93, "434": 93, "43": 93, "94": [93, 108], "166": 93, "0774": 93, "663": 93, "443": 93, "44": [93, 99], "87": 93, "50": [93, 98, 99, 107, 108, 110, 111], "885": 93, "3233": 93, "643": 93, "442": 93, "66": [93, 97, 99], "76": 93, "613": 93, "6150": 93, "637": 93, "72": [93, 97], "6k": 93, "91gb": 93, "21x": [93, 97], "tl": 93, "dr": 93, "priorit": 93, "accur": [93, 98, 107], "stabil": 93, "cost": [93, 99], "slightli": [93, 101], "impact": [93, 97, 103], "outlier": 93, "caus": 93, "underflow": 93, "8xh100": 93, "box": [93, 98, 110], "toi": [93, 95, 99, 101, 110], "convert_to_float8_train": 93, "recurs": 93, "kind": [93, 108], "over": [93, 98, 108, 109], "snippet": [93, 108, 109], "float8_linear_util": 93, "float8_linear": 93, "sampl": [93, 108, 110, 111], "adamw": 93, "being": [93, 98, 103, 110, 111], "elig": 93, "divis": 93, "label": 93, "fake_label": 93, "ones_lik": 93, "mse_loss": 93, "model_state_dict": 93, "state_dict": [93, 96, 108, 109], "optimizer_state_dict": 93, "pth": [93, 108, 109], "explor": [93, 95, 111], "few": [93, 101, 108, 109], "lai": 94, "stack": [94, 97], "awq": 94, "gptq": 94, "int4tensor": 94, "int4preshuffledtensor": 94, "uint1": 94, "uint7": 94, "float3": 94, "triton": [94, 110, 111], "overload": [94, 98], "term": [94, 98, 108, 112], "extra": [94, 97], "matter": [94, 98], "float4_e2m1fn_x2": 94, "float8_e4m3fnuz": 94, "float8_e5m2": 94, "float8_e5m2fnuz": 94, "float8_e8m0fnu": 94, "pr": 94, "shell": 94, "dervi": 94, "mxfp8": 94, "preicison": 94, "mention": [94, 108], "previou": [94, 97, 108, 109, 110, 111], "accommod": 94, "choose_qparams_affine_with_min_max": 94, "min": [94, 99, 101, 108, 112], "raw": 94, "quantize_fp8_row": 94, "int_matmul": 94, "int_scaled_matmul": 94, "reli": [94, 95, 98, 99, 101], "handwritten": 94, "On": [94, 95], "glue": 94, "everyth": 94, "togeth": [94, 97, 108, 110, 112], "anoth": [94, 98, 101, 108, 112], "side": 94, "swizzl": 94, "dtpype": 94, "float8rowwisetensor": 94, "float8blockwisetensor": 94, "close": [94, 98], "low_precision_v": 94, "high_precision_v": 94, "procedur": 94, "especi": [94, 96, 98, 110, 111], "bitwidth": [94, 112], "codebook": 94, "index": [94, 97, 98, 111], "vector": [94, 98, 110], "kmean": 94, "tradition": 94, "explain": [94, 107, 110], "simplest": [94, 98], "easi": [94, 97], "linear_modul": 94, "runtim": [94, 108], "main": [94, 95, 97, 98, 99, 101, 102, 108, 112], "question": [94, 96, 98, 101, 112], "activation_granular": 94, "act_quant_kwarg": 94, "weight_granular": [94, 97], "quantized_weight": [94, 103], "float8_dtyp": 94, "haven": 94, "seen": 94, "pt2": [94, 101, 110], "autoround": 94, "multitensor": 94, "sure": [94, 97, 112], "open": [94, 98], "describ": [94, 96, 98, 106, 108, 109], "finetun": [94, 97], "quantized_train": 94, "progress": [94, 102, 103], "lot": [94, 98], "connect": [94, 112], "walk": [94, 99, 101, 106, 107, 110], "float8dynamicactivationfloat8weightconfig": [94, 102], "len": [94, 97, 103, 108, 109, 112], "_choose_quant_func_and_quantize_tensor": 94, "relat": [94, 98], "xq": 94, "reshap": [94, 108, 109], "wq": 94, "x_scale": [94, 108], "w_scale": 94, "out_shap": 94, "entri": 95, "mutat": 95, "toylinearmodel": [95, 96, 99], "linear2": [95, 96, 99, 101], "eval": [95, 96, 97, 99, 107, 109, 110, 111], "faster": [95, 98], "model_bf16": 95, "uint4": 95, "int4mm": 95, "mix": [95, 97, 107, 110, 111], "tile_packed_to_4d": 95, "stai": [95, 101], "tensor_impl_dtyp": 95, "roughli": [95, 98], "quarter": 95, "o": [95, 108, 109], "int4_model": 95, "pt": [95, 97], "bfloat16_model": 95, "int4_model_size_mb": 95, "getsiz": [95, 108, 109], "bfloat16_model_size_mb": 95, "2f": [95, 108, 109], "mb": [95, 96, 105, 108, 109], "00": [95, 105], "benchmark_model": 95, "unwrap_tensor_subclass": 95, "num_run": 95, "100": [95, 101, 108, 109], "_dynamo": [95, 101], "reset": [95, 108, 109], "bf16_time": 95, "int4_tim": 95, "time": [95, 98, 101, 102, 106, 107, 108, 109], "3f": [95, 109], "1fx": 95, "393": 95, "410": 95, "9x": 95, "recogn": [95, 112], "decis": 95, "pt2e": [95, 107, 108, 109, 110, 111], "fuse": [95, 98, 101, 109], "deleg": [95, 108], "x86inductorquant": [95, 110], "quantize_pt2": [95, 107, 108, 109, 110, 111], "prepare_pt2": [95, 107, 108, 110, 111], "x86_inductor_quant": [95, 110], "get_default_x86_inductor_quantization_config": [95, 110], "float_model": [95, 101, 107, 108, 109, 110, 111], "data_load": [95, 108, 109, 110, 111], "no_grad": [95, 101, 107, 108, 109, 110, 111], "imag": [95, 102, 107, 108, 109, 110, 111], "program": [95, 108, 109, 110, 112], "captur": [95, 108, 109, 112], "expos": [95, 108, 109], "set_glob": [95, 108, 109, 110, 111], "xiq": [95, 110], "prepare_qat_pt2": [95, 109, 110], "sample_inference_data": 95, "convert_pt2": [95, 107, 108, 109, 110, 111], "wrapper": [95, 101, 110], "_inductor": [95, 110], "cpp_wrapper": [95, 110], "optimized_model": [95, 107, 110, 111], "converted_model": [95, 110, 111], "xpu": [95, 111], "simpl": [95, 98, 99, 101, 107, 110, 111], "visit": 95, "would": [95, 98, 101, 109, 111], "forget": 95, "tempfil": [96, 102], "get_model_size_in_byt": 96, "ref": [96, 108], "namedtemporaryfil": 96, "seek": [96, 98], "m_load": 96, "load_state_dict": [96, 108, 109], "assign": 96, "assert": [96, 99, 101, 103, 112], "equal": [96, 98], "thing": [96, 98, 101, 108], "float_weight1": 96, "float_weight2": 96, "quantized_weight1": 96, "quantized_weight2": 96, "go": [96, 101, 112], "techinqu": 96, "reduct": [96, 97, 98, 101], "4x": [96, 97], "0625": 96, "reason": [96, 98], "avoid": [96, 98], "affine_quantized_tensor": 96, "deploi": 97, "engin": 97, "seamlessli": [97, 101, 110, 111], "seamless": [97, 110], "hf": [97, 102], "signific": [97, 98], "pip": [97, 102, 107, 108], "url": [97, 111], "whl": [97, 111], "nightli": 97, "cu128": 97, "push": [97, 98, 102, 103], "hub": [97, 102, 103], "server": [97, 103], "phi": 97, "fp8": 97, "microsoft": 97, "o3": 97, "client": 97, "curl": 97, "localhost": 97, "8000": 97, "chat": 97, "content": 97, "applic": 97, "messag": 97, "role": 97, "give": [97, 98, 101], "me": 97, "short": 97, "larg": [97, 101, 110], "languag": 97, "temperatur": 97, "top_p": 97, "95": 97, "top_k": 97, "max_token": 97, "32768": 97, "vram": 97, "15x": 97, "2x": [97, 98], "littl": [97, 103], "packag": [97, 102], "git": [97, 102], "com": [97, 102], "acceler": [97, 98, 102], "autotoken": [97, 102], "pipelin": 97, "random": [97, 98, 108, 109], "manual_se": [97, 108, 109], "model_path": 97, "device_map": [97, 102, 103], "trust_remote_cod": 97, "ai": 97, "assist": 97, "eat": 97, "banana": 97, "dragonfruit": 97, "smoothi": 97, "blend": 97, "milk": 97, "honei": 97, "salad": 97, "slice": [97, 103], "lemon": 97, "juic": 97, "solv": [97, 98, 101], "equat": 97, "pipe": [97, 102], "text": 97, "generation_arg": 97, "max_new_token": 97, "500": 97, "return_full_text": 97, "do_sampl": 97, "generated_text": 97, "lm_head": 97, "those": [97, 98, 99, 101], "ti": 97, "autoprocessor": 97, "modeling_util": 97, "find_tied_paramet": 97, "model_id": [97, 102], "untied_model": 97, "getattr": [97, 103], "get_text_config": 97, "tie_word_embed": 97, "setattr": [97, 101], "_tied_weights_kei": 97, "user_id": 97, "your_user_id": 97, "model_nam": [97, 107, 110, 111], "save_to": [97, 102], "save_to_local_path": 97, "int8dynamicactivationintxweightconfig": [97, 102], "ve": [97, 98], "intxweightonlyconfig": [97, 102], "fqntoconfig": [97, 103], "untied_model_id": 97, "untied_model_local_path": 97, "embedding_config": 97, "linear_config": 97, "weight_scale_dtyp": 97, "quant_config": 97, "_default": [97, 103], "embed_token": 97, "quant_typ": [97, 102, 103], "include_embed": 97, "untie_embedding_weight": 97, "modules_to_not_convert": 97, "quantized_model": [97, 101, 102, 107, 108, 109], "safe_seri": [97, 102, 103], "pte": 97, "cd": 97, "install_requir": 97, "phi_4_mini": 97, "convert_weight": 97, "pytorch_model": 97, "bin": 97, "pytorch_model_convert": 97, "export_llama": 97, "kv": 97, "use_sdpa_with_kv_cach": 97, "get_bos_id": 97, "199999": 97, "get_eos_id": 97, "200020": 97, "max_seq_length": 97, "max_context_length": 97, "output_nam": 97, "phi4": 97, "phone": 97, "io": 97, "2gb": 97, "iphon": 97, "pro": [97, 98], "17": 97, "sec": 97, "test": [97, 102, 106, 108, 110], "lm": 97, "har": 97, "eleutherai": 97, "lm_eval": 97, "model_arg": 97, "pretrain": [97, 98, 107, 108, 109, 110], "reset_peak_memory_stat": 97, "prompt": [97, 102], "hei": 97, "consciou": 97, "templated_prompt": 97, "apply_chat_templ": 97, "add_generation_prompt": 97, "templat": [97, 104, 105], "return_tensor": 97, "generated_id": 97, "output_text": 97, "batch_decod": 97, "skip_special_token": 97, "clean_up_tokenization_spac": 97, "respons": 97, "mem": 97, "max_memory_reserv": 97, "1e9": 97, "02f": 97, "gb": 97, "hello": [97, 102], "ye": 97, "am": 97, "digit": 97, "todai": 97, "70": [97, 99], "bench": 97, "vllm_disable_compile_cach": 97, "project": 97, "vllm_use_precompil": 97, "sharegpt": 97, "wget": 97, "co": 97, "anon8231489123": 97, "sharegpt_vicuna_unfilt": 97, "resolv": 97, "sharegpt_v3_unfiltered_cleaned_split": 97, "tree": 97, "num": 97, "benchmark_serv": 97, "16x": 97, "14x": 97, "num_prompt": 97, "req": 97, "57": [97, 99], "1000": [97, 110], "68": 97, "80": 97, "entir": [97, 108, 109], "ml": 97, "gain": [97, 98, 111], "eas": 97, "accept": [97, 112], "trade": [97, 98], "off": [97, 98], "neural": [98, 107, 110], "network": [98, 101, 107, 110], "latenc": 98, "carefulli": 98, "pai": 98, "low": [98, 101, 102, 107], "price": 98, "f1": 98, "problem": [98, 101], "research": [98, 106], "fragment": 98, "rightfulli": 98, "spent": 98, "figur": [98, 108], "compress": [98, 107], "place": [98, 107, 108, 109, 110, 111], "dens": 98, "focu": [98, 101], "realli": 98, "concret": [98, 112], "hope": 98, "modular": 98, "nice": 98, "scratch": [98, 106], "minim": [98, 107, 110, 111], "algorthim": 98, "realiz": 98, "theoret": 98, "analog": 98, "fix": [98, 99], "unstructur": 98, "retrain": 98, "neglig": 98, "area": 98, "agre": 98, "upon": 98, "consensu": 98, "mind": 98, "thought": 98, "subproblem": 98, "satisfi": 98, "my": [98, 109], "independ": 98, "frontend": [98, 110], "arbitrari": 98, "handoff": 98, "piec": 98, "natur": [98, 101, 108, 112], "clear": 98, "contract": 98, "7x": 98, "advantag": 98, "anticip": 98, "solut": 98, "third": 98, "parti": 98, "to_sparse_semi_structur": 98, "sparsesemistructuredtensor": 98, "weightnormsparsifi": 98, "half": 98, "subnetwork": 98, "sparse_config": 98, "named_modul": 98, "tensor_fqn": 98, "sparse_block_shap": 98, "zeros_per_block": 98, "fakespars": 98, "fundament": [98, 109], "manipul": 98, "dictionari": 98, "paramer": 98, "parameter": 98, "necessari": [98, 99, 101, 107, 108, 109, 110, 111], "suitabl": [98, 110], "spot": 98, "definit": [98, 103], "academia": 98, "industri": 98, "often": [98, 101], "interchang": 98, "distinct": 98, "idea": 98, "behind": 98, "doesn": [98, 109, 112], "itself": [98, 101], "loos": 98, "speak": 98, "tightli": 98, "coupl": [98, 101], "csc": 98, "qnnpack": 98, "descript": [98, 107], "coo": 98, "sparse_coo": 98, "coordin": 98, "locat": 98, "bsr": 98, "sparse_bsr": 98, "veri": [98, 103, 109], "except": [98, 101, 112], "scalar": [98, 108], "dimension": 98, "csr": 98, "sparse_csr": 98, "sparse_csc": 98, "column": 98, "compact": 98, "sparse_matrix": 98, "1d": 98, "indexptr": 98, "\u00bd": 98, "bitmask": 98, "2bit": 98, "unprun": 98, "quit": [98, 101], "broken": 98, "down": 98, "sensit": 98, "effect": [98, 99, 101, 110, 111, 112], "best": [98, 110], "subsequ": [98, 101, 110, 111], "infinit": 98, "lost": 98, "degre": 98, "drop": 98, "proxi": 98, "aforement": 98, "smallest": 98, "absolut": 98, "scope": 98, "impli": 98, "con": 98, "potenti": [98, 99, 107, 108, 110, 111], "sub": 98, "span": 98, "threshold": 98, "constant": [98, 101, 108], "ctr_mobile_fe": 98, "score": 98, "w": [98, 103], "tenosr": 98, "udpat": 98, "histori": 98, "regrow": 98, "dw": 98, "via": [98, 107], "backprop": 98, "pat": 98, "unmask": 98, "resid": 98, "salienc": 98, "lowest": 98, "l1": 98, "abl": [98, 101, 103, 108, 112], "repeat": [98, 108, 109], "movement": 98, "2005": 98, "07683": 98, "rank": [98, 101], "wx": 98, "sqx": 98, "q": [98, 108], "usual": 98, "sort": 98, "wise": 98, "reconstruct": [98, 103], "randomli": 98, "tri": 98, "remedi": 98, "sometim": 98, "item": [98, 106], "ultim": [98, 99], "complic": [98, 108], "literatur": 98, "vision": 98, "nlp": [98, 106, 110], "iter": [98, 108, 109], "ctr_feed": 98, "na": 98, "multimask": 98, "search": 98, "pyspeech": 98, "fastna": 98, "approach": [98, 101, 107, 110, 111], "knowledg": [98, 106], "distil": 98, "pdf": 98, "2204": 98, "09656": 98, "arrang": 98, "recal": 98, "counterpart": 98, "slower": 98, "suffici": 98, "At": [98, 108], "98": 98, "special": [98, 107, 108], "exhibit": 98, "penalti": 98, "expens": [98, 101], "dictat": 98, "characterist": 98, "highest": 98, "wouldn": [98, 101], "visual": 98, "fig": 98, "4x4": 98, "benchmak": 98, "fly": [99, 102], "affinequantizedminmaxobserv": 99, "record": 99, "welcom": 99, "averag": [99, 108, 109], "histogram": [99, 108], "act_ob": 99, "finfo": 99, "weight_ob": 99, "observedlinear": 99, "observed_input": 99, "observed_weight": 99, "from_float": [99, 101], "float_linear": 99, "observed_linear": 99, "_replace_with_custom_fn_if_matches_filt": 99, "insert_observers_": 99, "lambda": [99, 103], "replacement_fn": 99, "copied_act_ob": 99, "copied_weight_ob": 99, "popul": 99, "feed": 99, "simpler": [99, 108], "quantizedlinear": [99, 101], "isn": 99, "strictli": 99, "to_affine_quantized_intx_stat": 99, "act_scal": [99, 112], "act_zero_point": 99, "calculate_qparam": [99, 112], "weight_scal": [99, 108, 112], "weight_zero_point": [99, 108], "qweight": 99, "qinput": 99, "from_observ": 99, "quantized_linear": [99, 108], "begin": [99, 101], "dataclass": [99, 103, 112], "transform_modul": [99, 103], "register_quantize_module_handl": [99, 103], "staticquantconfig": 99, "_apply_static_qu": 99, "associ": 99, "identifi": [99, 112], "is_observed_linear": 99, "optimizedmodul": 99, "_orig_mod": 99, "0237": 99, "142": 99, "31": [99, 112], "113": 99, "157": 99, "59": 99, "160": 99, "150": 99, "67": 99, "241": 99, "238": 99, "235": 99, "228": 99, "255": [99, 112], "201": 99, "114": 99, "236": 99, "88": [99, 108], "83": 99, "109": 99, "209": 99, "92": 99, "184": 99, "141": 99, "110": 99, "0009": 99, "0010": 99, "130": 99, "122": 99, "132": 99, "125": 99, "126": 99, "129": 99, "127": [99, 101, 111, 112], "133": 99, "124": 99, "131": 99, "135": 99, "136": 99, "foundat": 101, "autograd": [101, 112], "interpos": 101, "namespac": 101, "continu": [101, 102, 109, 110, 111, 112], "obviou": 101, "int8quantizedlinear": 101, "finer": 101, "intercept": 101, "contrast": 101, "clunki": 101, "distributedlinear": 101, "duplic": 101, "bypass": 101, "wrap": [101, 110, 111], "outer": 101, "inner": 101, "allgath": 101, "bandwidth": 101, "exactli": 101, "zoo": 101, "podcast": 101, "edward": 101, "yang": 101, "int8_symmetric_quant": 101, "fp32_tensor": 101, "amin": 101, "amax": 101, "zeros_lik": 101, "view": [101, 108, 109], "clamp": [101, 108], "w_int8": 101, "new_linear": 101, "left": [101, 112], "toymodel": 101, "child": 101, "named_children": 101, "drawback": 101, "won": 101, "suppos": 101, "clean": 101, "eleg": 101, "pretti": 101, "power": [101, 103], "overrid": 101, "almost": 101, "shard": [101, 103], "ragged": 101, "rag": 101, "nestedtensor": 101, "who": 101, "link": [101, 106], "why": [101, 106], "googl": 101, "collab": 101, "flopcount": 101, "memorytrack": 101, "bare": 101, "bone": 101, "int8symmetrictensor": 101, "hold": [101, 102], "staticmethod": 101, "_make_wrapper_subclass": [101, 103], "storage_offset": 101, "ndim": 101, "extra_metadata": 101, "outer_s": [101, 103], "outer_strid": [101, 103], "undo": 101, "repr": 101, "ahead": 101, "insid": 101, "int8_tensor": 101, "op_implementations_dict": 101, "conveni": 101, "register_op": 101, "_op": 101, "opoverload": 101, "impl_decor": 101, "op_impl": 101, "done": 101, "particular": 101, "largest": 101, "tell": 101, "desugar": 101, "surfac": 101, "coverag": [101, 107, 108, 110, 111], "brute": 101, "forc": 101, "repeatedli": 101, "log": 101, "loggingtensor": 101, "_python_dispatch": [101, 103], "return_and_correct_alias": [101, 103], "int8_mm": 101, "int8_view_op": 101, "out_data": 101, "out_scal": [101, 108], "notic": 101, "hit": 101, "background": 101, "decomposit": 101, "live": 101, "decomp": 101, "shrink": 101, "author": [101, 106, 107, 108, 109, 110, 111, 112], "But": [101, 103, 112], "pain": 101, "rather": 101, "worth": 101, "written": 101, "differenti": 101, "nuanc": 101, "longer": [101, 108, 109], "had": [101, 108], "That": 101, "transposit": 101, "got": [101, 108, 112], "propag": [101, 108, 110, 111], "fact": 101, "themselv": [101, 108], "pointwis": [101, 110, 111], "were": 101, "might": [101, 103, 108, 112], "unwrap": 101, "dim0": 101, "dim1": 101, "confirm": 101, "quantized_model_module_swap": 101, "quantized_model_subclass": 101, "subclass_param": 101, "out_module_swap": 101, "allclos": 101, "out_compil": 101, "seri": 101, "discuss": 101, "float8dynamicactivationint4weightconfig": 102, "torch_dtyp": 102, "fluxpipelin": 102, "fluxtransformer2dmodel": 102, "black": 102, "forest": 102, "lab": 102, "flux": 102, "dev": 102, "subfold": 102, "cat": [102, 112], "sign": [102, 111], "world": [102, 103], "num_inference_step": 102, "guidance_scal": 102, "png": 102, "temporarydirectori": 102, "tmp_dir": 102, "uncom": 102, "usernam": [102, 103], "statu": [102, 103], "becom": [102, 108], "stabl": 102, "int4wo": 102, "team": [102, 103], "retain": 102, "thoroughli": 102, "e2": 103, "_type": 103, "_data": 103, "capabl": [103, 108, 110], "self_attn": 103, "q_proj": 103, "k_proj": 103, "mlp": 103, "gate_proj": 103, "narrow": 103, "chunk": 103, "heavi": 103, "codebas": 103, "fn": 103, "ctx": 103, "new_tensor": 103, "__class__": 103, "principl": 103, "mynewquantconfig": 103, "classvar": 103, "myquantizedtensor": 103, "tensor_data_attr": 103, "tensor_attribut": 103, "attr": 103, "fill_default": 103, "notimplementederror": 103, "_my_quant_transform": 103, "my_quantization_funct": 103, "use_cutlass_kernel": 103, "my_cutlass_linear": 103, "use_triton_kernel": 103, "my_triton_linear": 103, "disappear": 103, "unless": 103, "extrem": 103, "sole": 103, "explicitli": [103, 112], "spooki": 103, "distanc": 103, "due": [103, 107, 112], "workaround": 103, "2338": 103, "detect": 103, "illustr": 103, "tutorials_python": 104, "zip": 104, "jupyt": [104, 106], "notebook": [104, 106], "tutorials_jupyt": 104, "galleri": [104, 106], "sphinx": [104, 106], "004": [105, 106], "total": [105, 106], "template_tutori": [105, 106], "click": 106, "firstnam": 106, "lastnam": 106, "prerequisit": [106, 108], "topic": 106, "rand": [106, 108, 109], "1610": 106, "6619": 106, "4654": 106, "3134": 106, "9271": 106, "4490": 106, "9003": 106, "2489": 106, "1245": 106, "5498": 106, "1226": 106, "3705": 106, "2922": 106, "4025": 106, "2630": 106, "practic": 106, "summar": 106, "takeawai": 106, "link1": 106, "link2": 106, "minut": 106, "ipynb": 106, "daniil": 107, "lyakhov": 107, "aamir": 107, "nazir": 107, "alexand": 107, "suslov": 107, "yamini": 107, "nimmagadda": 107, "kozlov": 107, "subject": [107, 109], "openvinoquant": 107, "unlock": 107, "placement": 107, "ux": [107, 108, 110], "torchdynamo": [107, 110, 111, 112], "eager": [107, 108, 109, 110, 111, 112], "mechan": [107, 110, 111], "torchvis": [107, 108, 109, 110, 111, 112], "resnet18": [107, 108, 109, 110, 111], "__dict__": [107, 108, 109, 110, 111], "dummi": [107, 110, 111], "traced_b": [107, 110, 111], "exported_model": [107, 108, 109, 110, 111], "preset": 107, "elu": 107, "prelu": 107, "gelu": 107, "quantizationpreset": 107, "bert": [107, 110], "modeltyp": 107, "ignored_scop": 107, "exclud": 107, "layer_1": 107, "layer_2": 107, "layer_3": 107, "ignoredscop": 107, "conv2d": [107, 108, 109, 110, 111, 112], "regex": 107, "layer_": 107, "subgraph": [107, 109], "node": [107, 109, 110, 111, 112], "target_devic": 107, "taken": 107, "account": 107, "cpu_spr": 107, "npu": 107, "targetdevic": 107, "fold": [107, 108, 110, 111], "batchnorm": [107, 108, 109, 110, 111], "preced": [107, 108, 110, 111], "prepared_model": [107, 108, 109, 110, 111], "fold_quant": 107, "finish": [107, 110], "comparison": 107, "smoothquant": 107, "biascorrect": 107, "discrep": 107, "calibration_load": 107, "dataload": [107, 108, 109], "transform_fn": 107, "data_item": 107, "calibration_dataset": 107, "smooth_quant": 107, "fast_bias_correct": 107, "deploy": [107, 110], "jerri": [108, 110, 112], "zhang": [108, 110, 111, 112], "_export": [108, 109], "fx": [108, 112], "14k": 108, "programm": [108, 110, 111], "db": 108, "xnnpack": [108, 109, 112], "xnnpack_quant": [108, 109], "get_symmetric_quantization_config": [108, 109], "xnnpackquant": [108, 109, 112], "prior": 108, "qconfigmap": [108, 112], "backendconfig": [108, 112], "rel": 108, "intent": [108, 112], "qconfig": [108, 112], "3d": [108, 112], "incompat": 108, "great": 108, "ideal": 108, "fake_qu": 108, "hidden": 108, "summari": 108, "address": 108, "thu": 108, "queri": [108, 112], "previous": 108, "embedding_byt": 108, "executorchquant": 108, "concaten": 108, "prone": 108, "cleaner": 108, "composed_quant": 108, "quantization_cap": 108, "concern": 108, "decoupl": 108, "minmax": 108, "freed": 108, "identitc": 108, "imagenet": [108, 109], "unzip": [108, 109], "data_path": [108, 109], "renam": [108, 109], "resnet18_pretrained_float": [108, 109], "sy": [108, 109], "numpi": [108, 109], "np": [108, 109], "resnet": [108, 109, 110], "warn": [108, 109], "filterwarn": [108, 109], "categori": [108, 109], "deprecationwarn": [108, 109], "r": [108, 109], "seed": [108, 109], "191009": [108, 109], "averagemet": [108, 109], "fmt": [108, 109], "val": [108, 109], "avg": [108, 109], "count": [108, 109], "__str__": [108, 109], "fmtstr": [108, 109], "topk": [108, 109], "predict": [108, 109], "maxk": [108, 109], "pred": [108, 109], "eq": [108, 109], "expand_a": [108, 109], "correct_k": [108, 109], "mul_": [108, 109], "criterion": [108, 109], "top1": [108, 109], "top5": [108, 109], "cnt": [108, 109], "acc1": [108, 109], "acc5": [108, 109], "load_model": [108, 109], "model_fil": [108, 109], "weights_onli": [108, 109], "print_size_of_model": [108, 109], "temp": [108, 109], "p": [108, 109], "1e6": [108, 109], "prepare_data_load": [108, 109], "485": [108, 109], "456": [108, 109], "std": [108, 109], "229": [108, 109], "225": [108, 109], "randomresizedcrop": [108, 109], "randomhorizontalflip": [108, 109], "totensor": [108, 109], "dataset_test": [108, 109], "resiz": [108, 109], "centercrop": [108, 109], "train_sampl": [108, 109], "randomsampl": [108, 109], "test_sampl": [108, 109], "sequentialsampl": [108, 109], "train_batch_s": [108, 109], "sampler": [108, 109], "data_loader_test": [108, 109, 110, 111], "eval_batch_s": [108, 109], "saved_model_dir": [108, 109], "float_model_fil": [108, 109], "model_to_quant": [108, 109], "capture_pre_autograd_graph": [108, 109], "dynamic_shap": [108, 109], "dynamic_dim": [108, 109], "constraint": [108, 109, 112], "qconfig_opt": 108, "set_object_typ": 108, "set_module_nam": 108, "workload": 108, "themodel": 108, "feedback": 108, "dq": 108, "fp32_op": 108, "qauntiz": 108, "x_int8": 108, "x_zero_point": 108, "weight_int8": 108, "bias_fp32": 108, "output_scal": 108, "output_zero_point": 108, "x_fp32": 108, "quantized_decompos": 108, "dequantize_per_tensor": 108, "x_i8": 108, "x_quant_min": 108, "x_quant_max": 108, "weight_fp32": 108, "weight_i8": 108, "weight_quant_min": 108, "weight_quant_max": 108, "weight_permut": 108, "permute_copi": 108, "out_fp32": 108, "addmm": 108, "out_i8": 108, "quantize_per_tensor": 108, "out_zero_point": 108, "out_quant_min": 108, "out_quant_max": 108, "float32_op": 108, "decompos": 108, "use_reference_represent": 108, "x_int16": 108, "weight_int16": 108, "acc_int32": 108, "out_dtyp": 108, "bias_scal": 108, "bias_int32": 108, "div": 108, "mul": 108, "out_int8": 108, "qmin": 108, "qmax": 108, "date": 108, "unus": 108, "serila": 108, "consult": 108, "exportedprogram": 108, "pt2e_quantized_model_file_path": 108, "resnet18_pt2e_quant": 108, "quantized_ep": 108, "loaded_quantized_ep": 108, "loaded_quantized_model": 108, "diff": 108, "79": 108, "82": 108, "55": 108, "edg": [108, 112], "went": 108, "andrew": 109, "Or": 109, "move_exported_model_to_ev": [109, 110], "correctli": 109, "certain": 109, "dropout": 109, "move_exported_model_to_train": 109, "jit": 109, "recursivescriptmodul": 109, "train_one_epoch": 109, "ntrain_batch": 109, "avgloss": 109, "5f": 109, "start_tim": 109, "global_avg": 109, "is_qat": [109, 110], "fusion": 109, "batchnorm2d": 109, "_native_batch_norm_legit": 109, "cudnn_batch_norm": 109, "mobilenetv2": 109, "manual": 109, "recompil": 109, "consolid": 109, "epoch": 109, "far": 109, "num_epoch": 109, "num_train_batch": 109, "num_eval_batch": 109, "num_observer_update_epoch": 109, "num_batch_norm_update_epoch": 109, "num_epochs_between_ev": 109, "nepoch": 109, "stat": 109, "subseq": 109, "disable_observ": 109, "bn": 109, "running_mean": 109, "running_var": 109, "new_arg": 109, "wish": 109, "prepared_model_copi": 109, "neval_batch": 109, "paus": 109, "resum": 109, "fail": [109, 112], "checkpoint_path": 109, "checkpoint_": 109, "behav": 109, "incorrectli": 109, "lesli": [110, 112], "fang": [110, 112], "weiwen": [110, 112], "xia": [110, 112], "jiong": [110, 112], "gong": [110, 112], "cnn": 110, "rnn": 110, "outstand": 110, "fourth": 110, "spr": 110, "xeon": 110, "processor": 110, "boost": 110, "channels_last": [110, 111], "onednn": [110, 111], "assum": [110, 112], "word": 110, "satur": 110, "pure": 110, "dedic": 110, "scenario": [110, 111], "plai": [110, 111], "convolut": [110, 111, 112], "absenc": [110, 111], "enhanc": [110, 111], "mirror": [110, 111], "autocast": [110, 111], "device_typ": [110, 111], "turn": [110, 111], "cpp": 110, "qconvolut": [110, 111], "qlinear": [110, 111], "presenc": [110, 111], "pair": [110, 111], "remain": [110, 111], "conting": [110, 111], "qmaxpool2d": [110, 111], "torchinductor_freez": [110, 111], "example_x86inductorquantizer_pytorch_2_1": 110, "torchbench": 110, "measur": 110, "proven": 110, "depth": 110, "example_x86inductorquantizer_qat": 110, "yan": 111, "zhiwei": 111, "wang": 111, "eikan": 111, "liangang": 111, "liu": 111, "river": 111, "cui": 111, "yifeng": 111, "xpuinductorquant": 111, "pip3": 111, "torchaudio": 111, "xpu_inductor_quantizer_exampl": 111, "xpu_inductor_quant": 111, "xpuiq": 111, "resnet18_weight": 111, "get_default_xpu_inductor_quantization_config": 111, "wherea": 111, "histogramobserv": [111, 112], "perchannelminmaxobserv": 111, "quantizationspec": [111, 112], "quantizationconfig": [111, 112], "type_check": 111, "observerorfakequantizeconstructor": 111, "get_xpu_inductor_symm_quantization_config": 111, "extra_arg": 111, "act_observer_or_fake_quant_ctr": 111, "act_quantization_spec": [111, 112], "qscheme": [111, 112], "per_tensor_symmetr": [111, 112], "observer_or_fake_quant_ctr": [111, 112], "with_arg": [111, 112], "weight_observer_or_fake_quant_ctr": 111, "weight_quantization_spec": [111, 112], "per_channel_symmetr": 111, "ch_axi": 111, "oc": 111, "ic": 111, "kh": 111, "kw": 111, "conv": [111, 112], "bias_quantization_spec": 111, "amp": 111, "indcutor": 111, "kimish": 112, "patel": 112, "made": 112, "explicit": 112, "quantiat": 112, "encod": 112, "convei": 112, "quantizationannot": 112, "furthermor": 112, "minmaxobserv": 112, "input_qspec_map": 112, "output_qspec": 112, "_annot": 112, "conclud": 112, "matcher": 112, "get_source_partit": 112, "add_partit": 112, "gm": 112, "itertool": 112, "chain": 112, "add_nod": 112, "output_nod": 112, "per_tensor_affin": 112, "input_act_qspec": 112, "output_act_qspec": 112, "input_act0": 112, "input_act1": 112, "quantization_annot": 112, "substitut": 112, "among": 112, "sharedquantizationspec": 112, "maxpool": 112, "average_pool": 112, "concat": 112, "whose": 112, "edgeornod": 112, "transit": 112, "spec": 112, "conv1": 112, "conv2": 112, "fed": 112, "conv1_out": 112, "conv2_out": 112, "qspec1": 112, "cat_input0": 112, "cat_input1": 112, "therefor": 112, "ob": 112, "consum": 112, "rewrit": 112, "share_qparams_with_input_act0_qspec": 112, "known": 112, "beforehand": 112, "sigmoid": 112, "fixedqparamsquantizationspec": 112, "act_qspec": 112, "sigmoid_nod": 112, "input_act": 112, "derivedquantizationspec": 112, "derive_qparams_fn": 112, "observerorfakequant": 112, "observerbas": 112, "fakequantizebas": 112, "heurist": 112, "obejct": 112, "obs_or_fq": 112, "fq": 112, "act_obs_or_fq": 112, "weight_obs_or_fq": 112, "act_zp": 112, "weight_zp": 112, "bias_qspec": 112, "derived_from": 112, "backendquant": 112, "get_input_act_qspec": 112, "get_output_act_qspec": 112, "get_weight_qspec": 112, "get_bias_qspec": 112, "intermedi": 112, "straightforward": 112, "call_funct": 112, "relu_": 112, "relu_nod": 112, "maybe_conv_nod": 112, "conv1d": 112, "unexpect": 112, "recognz": 112, "subgraphmatch": 112, "conv_relu_pattern": 112, "name_node_map": 112, "input_nod": 112, "weight_nod": 112, "bias_nod": 112, "caveat": 112, "exhaust": 112, "2d": 112, "4d": 112, "symbol": 112, "outcom": 112}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "MarlinSparseLayout"], [19, 0, 1, "", "NF4Tensor"], [20, 0, 1, "", "PlainLayout"], [21, 0, 1, "", "SemiSparseLayout"], [22, 0, 1, "", "TensorCoreTiledLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_intx"], [26, 2, 1, "", "to_affine_quantized_intx_static"], [27, 2, 1, "", "to_marlinqqq_quantized_intx"], [28, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinSparseLayout": [[18, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[19, 1, 1, "", "convert_to_norm_float_weight"], [19, 1, 1, "", "dequantize"], [19, 1, 1, "", "dequantize_scalers"], [19, 1, 1, "", "double_quantize_scalers"], [19, 1, 1, "", "get_original_weight"], [19, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[29, 0, 1, "", "CastConfig"], [30, 0, 1, "", "Float8LinearConfig"], [31, 0, 1, "", "ScalingGranularity"], [32, 0, 1, "", "ScalingType"], [33, 2, 1, "", "convert_to_float8_training"], [34, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[30, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[35, 0, 1, "", "BlockSparseLayout"], [36, 0, 1, "", "CutlassInt4PackedLayout"], [37, 0, 1, "", "Int8DynamicActInt4WeightCPULayout"], [38, 0, 1, "", "MarlinQQQLayout"], [39, 0, 1, "", "MarlinQQQTensor"], [40, 0, 1, "", "UintxLayout"]], "torchao.prototype.dtypes.MarlinQQQTensor": [[39, 1, 1, "", "dequantize"], [39, 1, 1, "", "from_hp_to_intx"]], "torchao.quantization": [[41, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [42, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [43, 0, 1, "", "Float8WeightOnlyConfig"], [44, 0, 1, "", "Int4WeightOnlyConfig"], [45, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [46, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [47, 0, 1, "", "Int8WeightOnlyConfig"], [48, 0, 1, "", "MappingType"], [49, 0, 1, "", "TorchAODType"], [50, 2, 1, "", "choose_qparams_affine"], [51, 2, 1, "", "choose_qparams_affine_with_min_max"], [52, 2, 1, "", "dequantize_affine"], [53, 2, 1, "", "int_scaled_matmul"], [78, 2, 1, "", "quantize_"], [83, 2, 1, "", "quantize_affine"], [84, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[54, 0, 1, "", "ComposableQATQuantizer"], [55, 0, 1, "", "FakeQuantizeConfigBase"], [56, 0, 1, "", "FakeQuantizedEmbedding"], [57, 0, 1, "", "FakeQuantizedLinear"], [58, 0, 1, "", "FakeQuantizerBase"], [59, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [60, 0, 1, "", "Float8FakeQuantizeConfig"], [61, 0, 1, "", "Float8FakeQuantizer"], [62, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [63, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [64, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [65, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [66, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [67, 0, 1, "", "IntxFakeQuantizeConfig"], [68, 0, 1, "", "IntxFakeQuantizer"], [69, 0, 1, "", "QATConfig"], [70, 0, 1, "", "QATStep"], [73, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[56, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[57, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[59, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[61, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[63, 1, 1, "", "convert"], [63, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[67, 3, 1, "", "group_size"], [67, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[68, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[71, 0, 1, "", "Int4WeightOnlyEmbedding"], [72, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[71, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[74, 0, 1, "", "Int4WeightOnlyQATLinear"], [75, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [76, 2, 1, "", "disable_linear_fake_quant"], [77, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[79, 0, 1, "", "KernelPreference"], [80, 0, 1, "", "PackingFormat"], [81, 0, 1, "", "QuantizeTensorKwargs"], [82, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[79, 4, 1, "", "AUTO"], [79, 4, 1, "", "FBGEMM"], [79, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[80, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[85, 0, 1, "", "PerChannelNormObserver"], [86, 0, 1, "", "WandaSparsifier"], [87, 2, 1, "", "apply_fake_sparsity"], [88, 4, 1, "", "semi_sparse_weight"], [89, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[85, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[86, 1, 1, "", "prepare"], [86, 1, 1, "", "squash_mask"], [86, 1, 1, "", "update_mask"]], "torchao.utils": [[90, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[90, 1, 1, "", "get_tensor_impl_constructor"], [90, 1, 1, "", "implements"], [90, 1, 1, "", "implements_torch_function"], [90, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 91, 93, 94, 103], "dtype": [0, 11, 94], "layout": [0, 17], "tensor": [0, 7, 10, 94, 100, 101, 103, 112], "subclass": [0, 7, 10, 101, 103], "quantiz": [0, 4, 5, 7, 12, 78, 91, 94, 95, 97, 99, 100, 101, 102, 103, 107, 108, 109, 110, 111, 112], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 93, 94], "main": [1, 4, 5], "train": [1, 12, 93, 94, 97, 107, 108, 109, 110, 111], "api": [1, 2, 4, 5, 7, 8, 12, 91, 93, 112], "other": [1, 10, 94], "type": [1, 102], "refer": [2, 91], "python": 2, "kernel": [3, 10, 92, 94, 103], "qat": [4, 12, 109], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 97], "primit": [5, 94], "sparsiti": [6, 98], "util": 7, "common": [7, 8, 112], "benchmark": [8, 9, 10, 97], "guid": [8, 9, 10, 95, 103], "add": [8, 103], "an": [8, 96], "recip": [8, 93], "model": [8, 10, 93, 94, 96, 97, 102, 103, 107, 108, 109], "design": [8, 98], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 93, 97, 102, 103, 107, 110, 111, 112], "modifi": 8, "exist": 8, "configur": [8, 98, 103, 108, 109], "2": [8, 12, 95, 97, 102, 103, 107, 108, 109, 110, 111, 112], "run": 8, "3": [8, 12, 97, 103, 107, 110, 111, 112], "output": [8, 101], "format": [8, 94], "4": [8, 107, 112], "integr": [8, 12, 102, 103], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 103], "new": [10, 103], "effici": [10, 94], "triton": 10, "hand": 10, "written": 10, "us": [10, 112], "kernelprefer": [10, 79], "flow": [10, 94, 96, 103, 112], "torch": [10, 107, 108, 109], "compil": [10, 103, 107], "perform": [10, 92, 97, 108], "serial": [10, 96, 103], "featur": 10, "support": [10, 102, 103], "function": [10, 108, 109], "compos": 10, "microbenchmark": 10, "eval": [10, 108], "part": [12, 93, 97], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 94, 109, 110], "option": [12, 97, 106, 107], "torchtun": 12, "axolotl": 12, "low": [12, 94], "rank": 12, "adapt": 12, "huggingfac": [12, 97, 103], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "marlinsparselayout": 18, "nf4tensor": 19, "plainlayout": 20, "semisparselayout": 21, "tensorcoretiledlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_intx": 25, "to_affine_quantized_intx_stat": 26, "to_marlinqqq_quantized_intx": 27, "to_nf4": 28, "castconfig": 29, "float8linearconfig": 30, "scalinggranular": 31, "scalingtyp": 32, "convert_to_float8_train": 33, "precompute_float8_dynamic_scale_for_fsdp": 34, "blocksparselayout": 35, "cutlassint4packedlayout": 36, "int8dynamicactint4weightcpulayout": 37, "marlinqqqlayout": 38, "marlinqqqtensor": 39, "uintxlayout": 40, "float8dynamicactivationfloat8weightconfig": 41, "float8dynamicactivationint4weightconfig": 42, "float8weightonlyconfig": 43, "int4weightonlyconfig": 44, "int8dynamicactivationint4weightconfig": 45, "int8dynamicactivationint8weightconfig": 46, "int8weightonlyconfig": 47, "mappingtyp": 48, "torchaodtyp": 49, "choose_qparams_affin": 50, "choose_qparams_affine_with_min_max": 51, "dequantize_affin": 52, "int_scaled_matmul": 53, "composableqatquant": 54, "fakequantizeconfigbas": 55, "fakequantizedembed": 56, "fakequantizedlinear": 57, "fakequantizerbas": 58, "float8actint4weightqatquant": 59, "float8fakequantizeconfig": 60, "float8fakequant": 61, "fromintxquantizationawaretrainingconfig": 62, "int4weightonlyembeddingqatquant": 63, "int4weightonlyqatquant": 64, "int8dynactint4weightqatquant": 65, "intxquantizationawaretrainingconfig": 66, "intxfakequantizeconfig": 67, "intxfakequant": 68, "qatconfig": 69, "qatstep": 70, "int4weightonlyembed": 71, "int4weightonlyqatembed": 72, "initialize_fake_quant": 73, "int4weightonlyqatlinear": 74, "int8dynactint4weightqatlinear": 75, "disable_linear_fake_qu": 76, "enable_linear_fake_qu": 77, "packingformat": 80, "quantizetensorkwarg": 81, "_choose_quant_func_and_quantize_tensor": 82, "quantize_affin": 83, "safe_int_mm": 84, "perchannelnormobserv": 85, "wandasparsifi": 86, "apply_fake_spars": 87, "semi_sparse_weight": 88, "sparsifi": 89, "torchaobasetensor": 90, "welcom": 91, "document": 91, "get": 91, "start": [91, 95, 102], "develop": 91, "note": [91, 93, 112], "eager": 91, "tutori": [91, 106], "pt2e": [91, 112], "pre": 93, "torchtitan": 93, "prerequisit": [93, 107, 110, 111, 112], "rowwis": 93, "scale": 93, "tensorwis": 93, "pick": 93, "import": [93, 108, 109], "directli": [93, 112], "convers": 93, "overview": [94, 98, 106], "basic": 94, "op": 94, "deriv": [94, 112], "pack": 94, "algorithm": 94, "weight": [94, 97], "onli": 94, "dynam": 94, "activ": 94, "static": [94, 99], "bit": 94, "optim": [94, 96, 97], "case": 94, "studi": 94, "how": [94, 108, 109, 112], "work": 94, "dure": 94, "execut": 94, "save": [94, 102, 108, 109], "load": [94, 108, 109], "quick": [95, 102], "first": 95, "exampl": [95, 102, 103, 112], "pytorch": [95, 107, 108, 109, 110, 111, 112], "export": [95, 97, 107, 108, 109, 110, 111, 112], "next": [95, 101], "step": [95, 97, 101, 103, 106], "deseri": 96, "what": [96, 101], "happen": 96, "when": 96, "serv": [97, 103], "vllm": [97, 103], "sglang": 97, "executorch": 97, "post": [97, 107, 108, 110, 111], "transform": [97, 102, 103], "mobil": 97, "deploy": 97, "unti": 97, "embed": 97, "creat": [97, 103], "characterist": 97, "evalu": [97, 108], "qualiti": 97, "assess": 97, "memori": 97, "latenc": 97, "result": 97, "h100": 97, "machin": 97, "conclus": [97, 106, 107, 108, 109, 110, 111, 112], "goal": 98, "context": 98, "prune": 98, "criteria": 98, "strategi": 98, "pattern": [98, 112], "calibr": [99, 108], "phase": 99, "write": [100, 101, 112], "your": [100, 101, 103], "own": [100, 101], "advanc": 100, "ar": 101, "modul": 101, "swap": 101, "which": 101, "oper": [101, 103, 112], "should": 101, "we": 101, "implement": [101, 103], "compar": 101, "hug": 102, "face": 102, "usag": [102, 103], "diffus": 102, "architectur": 103, "system": 103, "class": 103, "fqn": 103, "method": 103, "minim": 103, "requir": 103, "compat": 103, "why": 103, "regist": 103, "": 103, "kei": 103, "detail": 103, "hardwar": 103, "specif": [103, 108, 109], "linear": 103, "benefit": 103, "trade": 103, "off": 103, "share": [103, 112], "safetensor": 103, "diagram": 103, "high": 103, "level": 103, "point": 103, "dispatch": 103, "bring": 103, "extern": 103, "comput": 105, "time": 105, "templat": 106, "addit": 106, "exercis": 106, "further": 106, "read": 106, "openvino": 107, "backend": [107, 108, 109, 110, 111], "introduct": [107, 110, 111, 112], "nncf": 107, "instal": 107, "captur": [107, 110, 111], "fx": [107, 110, 111], "graph": [107, 110, 111], "appli": [107, 110, 111], "lower": [107, 108, 110, 111], "represent": 107, "improv": 107, "metric": 107, "motiv": [108, 112], "defin": [108, 109], "helper": [108, 109], "prepar": [108, 109], "dataset": [108, 109], "set": 108, "mode": 108, "convert": [108, 109], "check": 108, "size": 108, "accuraci": 108, "debug": 108, "loop": 109, "checkpoint": 109, "x86": 110, "through": [110, 111], "inductor": [110, 111], "intel": 111, "gpu": 111, "annot": 112, "param": 112, "fix": 112, "paramet": 112, "5": 112, "A": 112, "toi": 112, "resnet18": 112, "ir": 112, "problem": 112, "match": 112, "aten": 112, "recommend": 112, "subgraphmatcherwithnamenodemap": 112}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.dtypes": [[0, "torchao-dtypes"]], "Layouts and Tensor Subclasses": [[0, "layouts-and-tensor-subclasses"]], "Quantization techniques": [[0, "quantization-techniques"]], "Prototype": [[0, "prototype"], [4, "prototype"]], "torchao.float8": [[1, "torchao-float8"]], "Main float8 training APIs": [[1, "main-float8-training-apis"]], "Other float8 training types": [[1, "other-float8-training-types"]], "torchao API Reference": [[2, "torchao-api-reference"]], "Python API Reference": [[2, null]], "torchao.kernel": [[3, "torchao-kernel"]], "torchao.quantization.qat": [[4, "torchao-quantization-qat"]], "Main Config for quantize_": [[4, "main-config-for-quantize"]], "Custom QAT APIs": [[4, "custom-qat-apis"]], "Legacy QAT APIs": [[4, "legacy-qat-apis"]], "torchao.quantization": [[5, "torchao-quantization"]], "Main Quantization APIs": [[5, "main-quantization-apis"]], "Inference APIs for quantize_": [[5, "inference-apis-for-quantize"]], "Quantization Primitives": [[5, "quantization-primitives"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "torchao.utils": [[7, "torchao-utils"]], "Tensor Subclass Utils": [[7, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[7, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[7, "quantize-api-common-utils"]], "Benchmarking API Guide": [[8, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[8, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[8, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[8, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[8, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[8, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[8, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[8, "run-ci-benchmarks"]], "3. CI Output Format": [[8, "ci-output-format"]], "4. Integration with CI Pipeline": [[8, "integration-with-ci-pipeline"]], "Troubleshooting": [[8, "troubleshooting"]], "Running Tests": [[8, "running-tests"]], "Common Issues": [[8, "common-issues"]], "Best Practices": [[8, "best-practices"]], "Benchmarking User Guide": [[9, "benchmarking-user-guide"]], "Contributor Guide": [[10, "contributor-guide"]], "General Guide on Extending torchao": [[10, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[10, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[10, "adding-efficient-kernels"]], "Custom triton kernels": [[10, "custom-triton-kernels"]], "Custom hand written kernels": [[10, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[10, "using-hand-written-kernels-in-tensor-subclasses"]], "KernelPreference": [[10, "kernelpreference"], [79, "kernelpreference"]], "Flow": [[10, "flow"]], "Using torch.compile for Performance": [[10, "using-torch-compile-for-performance"]], "Serialization": [[10, "serialization"], [96, "serialization"]], "Other Feature Support": [[10, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[10, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[10, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[10, "model-benchmarks-and-eval"]], "Dtypes": [[11, "dtypes"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[12, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[12, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[12, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[12, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[12, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[12, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[12, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[12, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[12, "float8-quantized-fine-tuning"]], "AffineQuantizedTensor": [[13, "affinequantizedtensor"]], "CutlassSemiSparseLayout": [[14, "cutlasssemisparselayout"]], "Float8Layout": [[15, "float8layout"]], "Int4CPULayout": [[16, "int4cpulayout"]], "Layout": [[17, "layout"]], "MarlinSparseLayout": [[18, "marlinsparselayout"]], "NF4Tensor": [[19, "nf4tensor"]], "PlainLayout": [[20, "plainlayout"]], "SemiSparseLayout": [[21, "semisparselayout"]], "TensorCoreTiledLayout": [[22, "tensorcoretiledlayout"]], "to_affine_quantized_floatx": [[23, "to-affine-quantized-floatx"]], "to_affine_quantized_floatx_static": [[24, "to-affine-quantized-floatx-static"]], "to_affine_quantized_intx": [[25, "to-affine-quantized-intx"]], "to_affine_quantized_intx_static": [[26, "to-affine-quantized-intx-static"]], "to_marlinqqq_quantized_intx": [[27, "to-marlinqqq-quantized-intx"]], "to_nf4": [[28, "to-nf4"]], "CastConfig": [[29, "castconfig"]], "Float8LinearConfig": [[30, "float8linearconfig"]], "ScalingGranularity": [[31, "scalinggranularity"]], "ScalingType": [[32, "scalingtype"]], "convert_to_float8_training": [[33, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[34, "precompute-float8-dynamic-scale-for-fsdp"]], "BlockSparseLayout": [[35, "blocksparselayout"]], "CutlassInt4PackedLayout": [[36, "cutlassint4packedlayout"]], "Int8DynamicActInt4WeightCPULayout": [[37, "int8dynamicactint4weightcpulayout"]], "MarlinQQQLayout": [[38, "marlinqqqlayout"]], "MarlinQQQTensor": [[39, "marlinqqqtensor"]], "UintxLayout": [[40, "uintxlayout"]], "Float8DynamicActivationFloat8WeightConfig": [[41, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[42, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[43, "float8weightonlyconfig"]], "Int4WeightOnlyConfig": [[44, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[45, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[46, "int8dynamicactivationint8weightconfig"]], "Int8WeightOnlyConfig": [[47, "int8weightonlyconfig"]], "MappingType": [[48, "mappingtype"]], "TorchAODType": [[49, "torchaodtype"]], "choose_qparams_affine": [[50, "choose-qparams-affine"]], "choose_qparams_affine_with_min_max": [[51, "choose-qparams-affine-with-min-max"]], "dequantize_affine": [[52, "dequantize-affine"]], "int_scaled_matmul": [[53, "int-scaled-matmul"]], "ComposableQATQuantizer": [[54, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[55, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[56, "fakequantizedembedding"]], "FakeQuantizedLinear": [[57, "fakequantizedlinear"]], "FakeQuantizerBase": [[58, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[59, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[60, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[61, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[62, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[63, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[64, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[65, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[66, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[67, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[68, "intxfakequantizer"]], "QATConfig": [[69, "qatconfig"]], "QATStep": [[70, "qatstep"]], "Int4WeightOnlyEmbedding": [[71, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[72, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[73, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[74, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[75, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[76, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[77, "enable-linear-fake-quant"]], "quantize": [[78, "quantize"]], "PackingFormat": [[80, "packingformat"]], "QuantizeTensorKwargs": [[81, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[82, "choose-quant-func-and-quantize-tensor"]], "quantize_affine": [[83, "quantize-affine"]], "safe_int_mm": [[84, "safe-int-mm"]], "PerChannelNormObserver": [[85, "perchannelnormobserver"]], "WandaSparsifier": [[86, "wandasparsifier"]], "apply_fake_sparsity": [[87, "apply-fake-sparsity"]], "semi_sparse_weight": [[88, "semi-sparse-weight"]], "sparsify": [[89, "sparsify"]], "TorchAOBaseTensor": [[90, "torchaobasetensor"]], "Welcome to the torchao Documentation": [[91, "welcome-to-the-torchao-documentation"]], "Getting Started": [[91, null]], "Developer Notes": [[91, null]], "API Reference": [[91, null]], "Eager Quantization Tutorials": [[91, null]], "PT2E Quantization Tutorials": [[91, null]], "Performant Kernels": [[92, "performant-kernels"]], "(Part 1) Pre-training with float8": [[93, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[93, "pre-training-with-torchtitan"]], "Prerequisites": [[93, "prerequisites"], [93, "id1"], [107, "prerequisites"], [110, "prerequisites"], [111, "prerequisites"]], "Rowwise scaling": [[93, "rowwise-scaling"]], "Tensorwise scaling": [[93, "tensorwise-scaling"]], "Picking a recipe": [[93, "picking-a-recipe"]], "Important notes": [[93, "important-notes"]], "Pre-training with torchao directly": [[93, "pre-training-with-torchao-directly"]], "Model conversion API": [[93, "model-conversion-api"]], "Quantization Overview": [[94, "quantization-overview"]], "Basic DTypes": [[94, "basic-dtypes"]], "Quantization Primitive Ops": [[94, "quantization-primitive-ops"]], "Efficient kernels": [[94, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[94, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[94, "quantization-algorithms-flows"]], "Weight Only Quantization": [[94, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[94, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[94, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[94, "other-quantization-flows"]], "Training": [[94, "training"]], "Quantization Aware Training": [[94, "quantization-aware-training"], [110, "quantization-aware-training"]], "Low Bit Optimizers": [[94, "low-bit-optimizers"]], "Quantized Training": [[94, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[94, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[94, "during-quantization"]], "During Model Execution": [[94, "during-model-execution"]], "During Save/Load": [[94, "during-save-load"]], "Quick Start Guide": [[95, "quick-start-guide"]], "First Quantization Example": [[95, "first-quantization-example"]], "PyTorch 2 Export Quantization": [[95, "pytorch-2-export-quantization"]], "Next Steps": [[95, "next-steps"], [101, "next-steps"]], "Serialization and deserialization flow": [[96, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[96, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[96, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[97, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[97, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[97, "serving-and-inference"]], "Serving and Inference with vLLM": [[97, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[97, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[97, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[97, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[97, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[97, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[97, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[97, "mobile-performance-characteristics"]], "Evaluation": [[97, "evaluation"]], "Model Quality Assessment": [[97, "model-quality-assessment"]], "Memory Benchmarking": [[97, "memory-benchmarking"]], "Performance Benchmarking": [[97, "performance-benchmarking"]], "Latency Benchmarking": [[97, "latency-benchmarking"]], "Serving Benchmarking": [[97, "serving-benchmarking"]], "Results (H100 machine)": [[97, "results-h100-machine"]], "Conclusion": [[97, "conclusion"], [106, "conclusion"], [107, "conclusion"], [108, "conclusion"], [109, "conclusion"], [110, "conclusion"], [111, "conclusion"], [112, "conclusion"]], "Sparsity Overview": [[98, "sparsity-overview"]], "Goal": [[98, "goal"]], "Design": [[98, "design"]], "Context": [[98, "context"]], "Pruning Configuration": [[98, "pruning-configuration"]], "Pruning Criteria": [[98, "pruning-criteria"]], "Pruning Strategy": [[98, "pruning-strategy"]], "Sparsity Pattern": [[98, "sparsity-pattern"]], "Static Quantization": [[99, "static-quantization"]], "Calibration Phase": [[99, "calibration-phase"]], "Quantization Phase": [[99, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[100, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[101, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[101, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[101, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[101, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[101, "which-operators-should-we-implement"]], "Comparing the Outputs": [[101, "comparing-the-outputs"]], "Hugging Face Integration": [[102, "hugging-face-integration"]], "Quick Start: Usage Example": [[102, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[102, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[102, "quantizing-models-with-diffusers"]], "Saving the Model": [[102, "saving-the-model"]], "Supported Quantization Types": [[102, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[103, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[103, "configuration-system"]], "1. HuggingFace Model Configuration": [[103, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[103, "torchao-configuration-classes"]], "3. FQN Configuration": [[103, "fqn-configuration"]], "Usage Examples": [[103, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[103, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[103, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[103, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[103, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[103, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[103, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[103, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[103, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[103, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[103, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[103, "hardware-specific-linear-operations"]], "Compilation Benefits": [[103, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[103, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[103, "serialization-and-model-sharing"]], "SafeTensors Support": [[103, "safetensors-support"]], "Integration Architecture Diagrams": [[103, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[103, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[103, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[103, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Computation times": [[105, "computation-times"]], "Template Tutorial": [[106, "template-tutorial"]], "Overview": [[106, "overview"]], "Steps": [[106, "steps"]], "(Optional) Additional Exercises": [[106, "optional-additional-exercises"]], "Further Reading": [[106, "further-reading"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[107, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[107, "introduction"], [110, "introduction"], [111, "introduction"], [112, "introduction"]], "Post Training Quantization": [[107, "post-training-quantization"], [110, "post-training-quantization"], [111, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[107, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[107, "capture-fx-graph"], [110, "capture-fx-graph"], [111, "capture-fx-graph"]], "2. Apply Quantization": [[107, "apply-quantization"], [110, "apply-quantization"], [111, "apply-quantization"]], "3. Lower into OpenVINO representation": [[107, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[107, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[108, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[108, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[108, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[108, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[108, "export-the-model-with-torch-export"], [109, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[108, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [109, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[108, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[108, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[108, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[108, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[108, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[108, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[108, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[109, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[109, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[109, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[109, "training-loop"]], "Saving and Loading Model Checkpoints": [[109, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[109, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[110, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[110, "lower-into-inductor"], [111, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[111, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[112, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[112, "prerequisites"]], "Annotation API": [[112, "annotation-api"]], "1. Annotate Common Operator Patterns": [[112, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[112, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[112, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[112, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[112, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[112, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[112, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[112, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]]}, "indexentries": {"module": [[6, "module-torchao.sparsity"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "affinequantizedtensor (class in torchao.dtypes)": [[13, "torchao.dtypes.AffineQuantizedTensor"]], "dequantize() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.dequantize"]], "from_hp_to_floatx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx"]], "from_hp_to_floatx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx_static"]], "from_hp_to_intx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx"]], "from_hp_to_intx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx_static"]], "to() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.to"]], "cutlasssemisparselayout (class in torchao.dtypes)": [[14, "torchao.dtypes.CutlassSemiSparseLayout"]], "float8layout (class in torchao.dtypes)": [[15, "torchao.dtypes.Float8Layout"]], "int4cpulayout (class in torchao.dtypes)": [[16, "torchao.dtypes.Int4CPULayout"]], "layout (class in torchao.dtypes)": [[17, "torchao.dtypes.Layout"]], "marlinsparselayout (class in torchao.dtypes)": [[18, "torchao.dtypes.MarlinSparseLayout"]], "pre_process() (torchao.dtypes.marlinsparselayout method)": [[18, "torchao.dtypes.MarlinSparseLayout.pre_process"]], "nf4tensor (class in torchao.dtypes)": [[19, "torchao.dtypes.NF4Tensor"]], "convert_to_norm_float_weight() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.convert_to_norm_float_weight"]], "dequantize() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.dequantize"]], "dequantize_scalers() (torchao.dtypes.nf4tensor method)": [[19, "torchao.dtypes.NF4Tensor.dequantize_scalers"]], "double_quantize_scalers() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.double_quantize_scalers"]], "get_original_weight() (torchao.dtypes.nf4tensor method)": [[19, "torchao.dtypes.NF4Tensor.get_original_weight"]], "quantize_tensor_nearest() (torchao.dtypes.nf4tensor static method)": [[19, "torchao.dtypes.NF4Tensor.quantize_tensor_nearest"]], "plainlayout (class in torchao.dtypes)": [[20, "torchao.dtypes.PlainLayout"]], "semisparselayout (class in torchao.dtypes)": [[21, "torchao.dtypes.SemiSparseLayout"]], "tensorcoretiledlayout (class in torchao.dtypes)": [[22, "torchao.dtypes.TensorCoreTiledLayout"]], "to_affine_quantized_floatx() (in module torchao.dtypes)": [[23, "torchao.dtypes.to_affine_quantized_floatx"]], "to_affine_quantized_floatx_static() (in module torchao.dtypes)": [[24, "torchao.dtypes.to_affine_quantized_floatx_static"]], "to_affine_quantized_intx() (in module torchao.dtypes)": [[25, "torchao.dtypes.to_affine_quantized_intx"]], "to_affine_quantized_intx_static() (in module torchao.dtypes)": [[26, "torchao.dtypes.to_affine_quantized_intx_static"]], "to_marlinqqq_quantized_intx() (in module torchao.dtypes)": [[27, "torchao.dtypes.to_marlinqqq_quantized_intx"]], "to_nf4() (in module torchao.dtypes)": [[28, "torchao.dtypes.to_nf4"]], "castconfig (class in torchao.float8)": [[29, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[30, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[30, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[31, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[32, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[33, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[34, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "blocksparselayout (class in torchao.prototype.dtypes)": [[35, "torchao.prototype.dtypes.BlockSparseLayout"]], "cutlassint4packedlayout (class in torchao.prototype.dtypes)": [[36, "torchao.prototype.dtypes.CutlassInt4PackedLayout"]], "int8dynamicactint4weightcpulayout (class in torchao.prototype.dtypes)": [[37, "torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout"]], "marlinqqqlayout (class in torchao.prototype.dtypes)": [[38, "torchao.prototype.dtypes.MarlinQQQLayout"]], "marlinqqqtensor (class in torchao.prototype.dtypes)": [[39, "torchao.prototype.dtypes.MarlinQQQTensor"]], "dequantize() (torchao.prototype.dtypes.marlinqqqtensor method)": [[39, "torchao.prototype.dtypes.MarlinQQQTensor.dequantize"]], "from_hp_to_intx() (torchao.prototype.dtypes.marlinqqqtensor class method)": [[39, "torchao.prototype.dtypes.MarlinQQQTensor.from_hp_to_intx"]], "uintxlayout (class in torchao.prototype.dtypes)": [[40, "torchao.prototype.dtypes.UintxLayout"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[41, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[42, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[43, "torchao.quantization.Float8WeightOnlyConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[44, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[45, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[46, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[47, "torchao.quantization.Int8WeightOnlyConfig"]], "mappingtype (class in torchao.quantization)": [[48, "torchao.quantization.MappingType"]], "torchaodtype (class in torchao.quantization)": [[49, "torchao.quantization.TorchAODType"]], "choose_qparams_affine() (in module torchao.quantization)": [[50, "torchao.quantization.choose_qparams_affine"]], "choose_qparams_affine_with_min_max() (in module torchao.quantization)": [[51, "torchao.quantization.choose_qparams_affine_with_min_max"]], "dequantize_affine() (in module torchao.quantization)": [[52, "torchao.quantization.dequantize_affine"]], "int_scaled_matmul() (in module torchao.quantization)": [[53, "torchao.quantization.int_scaled_matmul"]], "composableqatquantizer (class in torchao.quantization.qat)": [[54, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[55, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[56, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[56, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[57, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[57, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[58, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[59, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[59, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[60, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[61, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[61, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[62, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[63, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[63, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[63, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[64, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[65, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[66, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[67, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[67, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[67, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[68, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[68, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[69, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[70, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[71, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[71, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[72, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[73, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[74, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[75, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[76, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[77, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[78, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[79, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "fbgemm (torchao.quantization.quantize_.common.kernelpreference attribute)": [[79, "torchao.quantization.quantize_.common.KernelPreference.FBGEMM"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[79, "torchao.quantization.quantize_.common.KernelPreference"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[79, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[80, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[80, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[81, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[82, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "quantize_affine() (in module torchao.quantization)": [[83, "torchao.quantization.quantize_affine"]], "safe_int_mm() (in module torchao.quantization)": [[84, "torchao.quantization.safe_int_mm"]], "perchannelnormobserver (class in torchao.sparsity)": [[85, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[85, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[86, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[86, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[86, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[86, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[87, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[88, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[89, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[90, "torchao.utils.TorchAOBaseTensor"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[90, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[90, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[90, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[90, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})