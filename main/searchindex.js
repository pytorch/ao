Search.setIndex({"docnames": ["api_reference/api_ref_float8", "api_reference/api_ref_kernel", "api_reference/api_ref_qat", "api_reference/api_ref_quantization", "api_reference/api_ref_sparsity", "api_reference/api_ref_utils", "api_reference/generated/torchao.float8.CastConfig", "api_reference/generated/torchao.float8.Float8LinearConfig", "api_reference/generated/torchao.float8.ScalingGranularity", "api_reference/generated/torchao.float8.ScalingType", "api_reference/generated/torchao.float8.convert_to_float8_training", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig", "api_reference/generated/torchao.quantization.FqnToConfig", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer", "api_reference/generated/torchao.quantization.qat.QATConfig", "api_reference/generated/torchao.quantization.qat.QATStep", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "api_reference/generated/torchao.quantization.quantize_", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "api_reference/generated/torchao.sparsity.PerChannelNormObserver", "api_reference/generated/torchao.sparsity.WandaSparsifier", "api_reference/generated/torchao.sparsity.apply_fake_sparsity", "api_reference/generated/torchao.sparsity.semi_sparse_weight", "api_reference/generated/torchao.sparsity.sparsify_", "api_reference/generated/torchao.utils.TorchAOBaseTensor", "api_reference/index", "developer_notes/benchmarking_api_guide", "developer_notes/benchmarking_user_guide", "developer_notes/contributor_guide", "developer_notes/index", "developer_notes/quantization_overview", "developer_notes/sparsity", "eager_quantization/finetuning", "eager_quantization/first_quantization_example", "eager_quantization/index", "eager_quantization/pretraining", "eager_quantization/serialization", "eager_quantization/serving", "eager_quantization/static_quantization", "eager_quantization/subclass_advanced", "eager_quantization/subclass_basic", "eager_quantization/torchao_hf_integration", "eager_quantization/torchao_vllm_integration", "index", "performant_kernels", "pt2e_quantization/index", "pt2e_quantization/pt2e_quant_openvino_inductor", "pt2e_quantization/pt2e_quant_ptq", "pt2e_quantization/pt2e_quant_qat", "pt2e_quantization/pt2e_quant_x86_inductor", "pt2e_quantization/pt2e_quant_xpu_inductor", "pt2e_quantization/pt2e_quantizer", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "workflows/index", "workflows/qat"], "filenames": ["api_reference/api_ref_float8.rst", "api_reference/api_ref_kernel.rst", "api_reference/api_ref_qat.rst", "api_reference/api_ref_quantization.rst", "api_reference/api_ref_sparsity.rst", "api_reference/api_ref_utils.rst", "api_reference/generated/torchao.float8.CastConfig.rst", "api_reference/generated/torchao.float8.Float8LinearConfig.rst", "api_reference/generated/torchao.float8.ScalingGranularity.rst", "api_reference/generated/torchao.float8.ScalingType.rst", "api_reference/generated/torchao.float8.convert_to_float8_training.rst", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.FqnToConfig.rst", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.rst", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.rst", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.QATConfig.rst", "api_reference/generated/torchao.quantization.qat.QATStep.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.quantize_.rst", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.rst", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.rst", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "api_reference/generated/torchao.sparsity.PerChannelNormObserver.rst", "api_reference/generated/torchao.sparsity.WandaSparsifier.rst", "api_reference/generated/torchao.sparsity.apply_fake_sparsity.rst", "api_reference/generated/torchao.sparsity.semi_sparse_weight.rst", "api_reference/generated/torchao.sparsity.sparsify_.rst", "api_reference/generated/torchao.utils.TorchAOBaseTensor.rst", "api_reference/index.rst", "developer_notes/benchmarking_api_guide.md", "developer_notes/benchmarking_user_guide.md", "developer_notes/contributor_guide.rst", "developer_notes/index.rst", "developer_notes/quantization_overview.rst", "developer_notes/sparsity.rst", "eager_quantization/finetuning.rst", "eager_quantization/first_quantization_example.rst", "eager_quantization/index.rst", "eager_quantization/pretraining.rst", "eager_quantization/serialization.rst", "eager_quantization/serving.rst", "eager_quantization/static_quantization.rst", "eager_quantization/subclass_advanced.rst", "eager_quantization/subclass_basic.rst", "eager_quantization/torchao_hf_integration.md", "eager_quantization/torchao_vllm_integration.md", "index.rst", "performant_kernels.rst", "pt2e_quantization/index.rst", "pt2e_quantization/pt2e_quant_openvino_inductor.rst", "pt2e_quantization/pt2e_quant_ptq.rst", "pt2e_quantization/pt2e_quant_qat.rst", "pt2e_quantization/pt2e_quant_x86_inductor.rst", "pt2e_quantization/pt2e_quant_xpu_inductor.rst", "pt2e_quantization/pt2e_quantizer.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "workflows/index.md", "workflows/qat.md"], "titles": ["torchao.float8", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MXDynamicActivationMXWeightConfig", "NVFP4DynamicActivationNVFP4WeightConfig", "NVFP4WeightOnlyConfig", "Float8DynamicActivationFloat8SemiSparseWeightConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8DynamicActivationIntxWeightConfig", "Int8WeightOnlyConfig", "IntxWeightOnlyConfig", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "API Reference", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Developer Notes", "Quantization Overview", "Sparsity Overview", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "First Quantization Example", "Eager Quantization Tutorials", "(Part 1) Pre-training with float8", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "Welcome to the torchao Documentation", "Performant Kernels", "PT2E Quantization Tutorials", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization", "&lt;no title&gt;", "Computation times", "Template Tutorial", "Workflows", "Quantization-Aware Training (QAT)"], "terms": {"tba": [1, 80], "For": [2, 39, 62, 64, 66, 67, 68, 69, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 92], "full": [2, 68, 74, 77, 81, 82, 84, 90, 92], "exampl": [2, 11, 16, 18, 20, 22, 24, 26, 28, 29, 34, 38, 39, 41, 45, 50, 51, 56, 59, 60, 62, 64, 66, 67, 68, 70, 72, 73, 74, 76, 79, 81, 82, 83, 84, 85, 86, 88, 90, 92], "how": [2, 17, 22, 39, 51, 52, 64, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 81, 82, 85, 86, 91], "us": [2, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 31, 34, 38, 39, 41, 46, 47, 51, 52, 56, 60, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 91, 92], "our": [2, 64, 67, 68, 69, 71, 73, 74, 76, 79, 83, 84, 92], "pleas": [2, 34, 38, 60, 63, 64, 66, 67, 68, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 92], "refer": [2, 41, 47, 62, 67, 68, 71, 73, 74, 76, 77, 78, 82, 83, 84, 85, 92], "readm": [2, 62, 67, 68, 69, 79, 91], "class": [6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 51, 52, 53, 55, 56, 60, 62, 64, 68, 69, 72, 74, 76, 81, 83, 84, 85, 87, 92], "torchao": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 69, 72, 73, 74, 76, 77, 81, 82, 83, 84, 85, 86, 91], "float8": [6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 31, 32, 33, 54, 61, 70, 73, 74, 79, 91], "scaling_typ": [6, 7], "scalingtyp": [6, 7], "dynam": [6, 7, 11, 13, 15, 16, 17, 21, 22, 23, 31, 37, 39, 47, 59, 64, 68, 73, 74, 76, 77, 83, 84, 85, 92], "scaling_granular": [6, 7], "scalinggranular": [6, 7], "tensorwis": [6, 7, 16, 66, 68], "target_dtyp": [6, 7, 66, 74], "option": [6, 7, 10, 16, 19, 22, 23, 24, 25, 28, 29, 31, 32, 36, 38, 39, 41, 43, 44, 50, 51, 54, 56, 59, 60, 62, 64, 66, 69, 71, 77, 78, 79, 81, 83, 84, 85, 86, 87], "dtype": [6, 12, 15, 16, 18, 23, 25, 28, 29, 31, 32, 35, 36, 37, 39, 43, 44, 46, 47, 54, 59, 62, 64, 68, 69, 71, 72, 73, 74, 76, 77, 78, 83, 85, 86, 87, 92], "none": [6, 7, 8, 9, 10, 11, 16, 19, 23, 24, 25, 28, 29, 31, 32, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 56, 59, 60, 66, 68, 74, 76, 78, 82, 83, 84, 86], "sourc": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 73, 88, 90], "configur": [6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 50, 59, 66, 68, 71, 73, 77, 85, 86, 87, 92], "mayb": 6, "cast": [6, 8, 68, 92], "singl": [6, 11, 16, 64, 67, 68, 71, 83, 87, 92], "tensor": [6, 13, 15, 18, 20, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 40, 51, 52, 53, 54, 56, 60, 62, 67, 68, 69, 70, 71, 72, 74, 77, 83, 85, 86, 90, 91], "cast_config_input": 7, "config": [7, 10, 16, 18, 19, 20, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 38, 39, 40, 41, 50, 56, 59, 62, 66, 67, 68, 69, 73, 74, 77, 78, 81, 83, 85, 86, 92], "castconfig": 7, "cast_config_input_for_grad_weight": 7, "type": [7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 25, 39, 42, 50, 51, 52, 53, 54, 60, 62, 64, 66, 67, 68, 69, 72, 73, 76, 78, 79, 82, 83, 85, 86, 87, 92], "cast_config_weight": 7, "cast_config_weight_for_grad_input": 7, "cast_config_grad_output": 7, "cast_config_grad_output_for_grad_weight": 7, "gemm_config_output": 7, "float8gemmconfig": 7, "use_fast_accum": 7, "true": [7, 13, 14, 16, 18, 20, 21, 22, 24, 28, 29, 38, 39, 41, 49, 50, 59, 64, 68, 69, 71, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 87], "gemm_config_grad_input": 7, "fals": [7, 22, 28, 29, 37, 38, 39, 41, 43, 44, 46, 47, 56, 62, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 86, 87, 92], "gemm_config_grad_weight": 7, "enable_fsdp_float8_all_gath": 7, "bool": [7, 10, 13, 14, 16, 18, 20, 21, 22, 24, 28, 29, 37, 39, 43, 44, 46, 47, 49, 50, 59, 68, 74], "pad_inner_dim": 7, "emul": [7, 51], "force_recompute_fp8_weight_in_bwd": 7, "round_scales_to_power_of_2": 7, "convert": [7, 26, 34, 35, 41, 50, 59, 66, 67, 68, 71, 73, 82, 85, 86, 87, 92], "torch": [7, 10, 12, 15, 16, 18, 20, 23, 25, 28, 29, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 51, 59, 60, 62, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 85, 86, 87, 90, 92], "nn": [7, 10, 26, 31, 35, 38, 41, 50, 59, 60, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 78, 81, 83, 84, 85, 87, 92], "linear": [7, 10, 15, 16, 17, 18, 21, 22, 24, 26, 29, 31, 36, 37, 38, 41, 46, 47, 48, 49, 50, 57, 59, 60, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 81, 82, 83, 84, 85, 87, 92], "modul": [7, 8, 9, 10, 11, 12, 19, 26, 28, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 59, 62, 64, 66, 68, 69, 71, 72, 74, 78, 81, 82, 83, 84, 85, 86, 87, 92], "train": [7, 26, 39, 41, 64, 67, 70, 76, 81, 87], "static": [7, 39, 70, 81, 83, 84, 85, 86, 87], "from_recipe_nam": 7, "recipe_nam": [7, 71], "union": [7, 16, 32, 39, 50], "float8linearrecipenam": 7, "str": [7, 10, 19, 39, 41, 50, 56, 59, 60, 62, 71, 76, 78, 86], "input": [7, 10, 11, 13, 41, 45, 50, 56, 59, 62, 64, 66, 69, 71, 73, 74, 76, 81, 82, 83, 84, 85, 86, 87], "valu": [7, 8, 9, 16, 18, 20, 21, 22, 24, 32, 42, 51, 52, 56, 66, 67, 68, 74, 76, 82, 83, 84, 87, 92], "string": [7, 39, 56, 60, 62], "repres": [7, 27, 39, 52, 56, 64, 66, 72, 76, 83, 84, 92], "output": [7, 64, 66, 67, 68, 69, 71, 73, 77, 81, 82, 83, 84, 85, 86, 87, 90, 92], "implement": [7, 20, 43, 44, 46, 47, 51, 60, 64, 66, 67, 68, 72, 74, 82, 83, 87], "specifi": [7, 10, 19, 23, 24, 25, 26, 28, 29, 30, 33, 40, 41, 47, 50, 51, 56, 59, 64, 66, 67, 68, 71, 82, 83, 84, 87, 92], "recip": [7, 28, 33, 43, 55, 68, 92], "name": [8, 9, 19, 42, 50, 51, 52, 56, 59, 60, 62, 64, 66, 67, 73, 76, 78, 82, 83, 84, 87], "qualnam": [8, 9, 42, 51, 52], "start": [8, 9, 19, 42, 51, 52, 64, 66, 67, 68, 69, 71, 73, 74, 76, 78, 82, 83, 84, 85, 86, 87], "1": [8, 9, 16, 18, 19, 20, 22, 23, 24, 25, 32, 42, 51, 52, 54, 56, 60, 64, 66, 67, 69, 70, 72, 74, 76, 79, 81, 83, 84, 90, 91, 92], "boundari": [8, 9, 42, 51, 52], "defin": [8, 28, 33, 43, 55, 56, 60, 62, 64, 66, 67, 74, 76, 78, 81, 82, 85, 86, 87], "granular": [8, 16, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 39, 40, 64, 66, 71, 73, 74, 78], "scale": [8, 11, 13, 16, 23, 25, 31, 32, 39, 44, 45, 46, 47, 54, 64, 66, 67, 74, 76, 78, 87, 92], "strategi": 8, "module_filter_fn": [10, 71], "callabl": [10, 50, 59, 60, 78], "float8linearconfig": 10, "swap": [10, 31, 35, 67, 68, 71, 74, 84, 92], "float8linear": [10, 71], "paramet": [10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 31, 32, 39, 41, 44, 46, 47, 50, 56, 59, 60, 62, 66, 67, 68, 71, 72, 73, 76, 78, 82, 83, 92], "modifi": [10, 50, 56, 64, 67, 71, 76], "If": [10, 16, 22, 24, 38, 39, 41, 56, 60, 62, 63, 64, 66, 67, 68, 73, 76, 83, 84], "onli": [10, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 31, 41, 47, 62, 64, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 82, 83, 85, 86, 87, 92], "subclass": [10, 28, 33, 43, 51, 52, 55, 59, 60, 66, 67, 68, 69, 72, 77], "pass": [10, 22, 28, 29, 33, 41, 43, 55, 60, 62, 66, 74, 76, 78, 84, 87], "filter": [10, 19, 64, 68, 71, 74, 92], "function": [10, 28, 33, 43, 48, 49, 50, 55, 56, 57, 59, 60, 62, 66, 67, 68, 69, 71, 72, 74, 76, 78, 81, 82, 87, 92], "The": [10, 16, 18, 19, 23, 25, 41, 50, 56, 62, 64, 66, 67, 68, 69, 71, 72, 73, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92], "ar": [10, 16, 19, 20, 23, 25, 26, 28, 29, 38, 41, 50, 51, 52, 56, 60, 64, 66, 67, 68, 69, 71, 72, 73, 74, 78, 81, 82, 83, 84, 85, 86, 87, 92], "instanc": [10, 28, 33, 43, 50, 55, 59, 60, 72, 76, 83, 85, 86, 87], "fqn": [10, 19, 56, 59, 71, 74], "convers": [10, 64, 68, 92], "return": [10, 39, 50, 59, 60, 62, 64, 66, 68, 69, 71, 72, 74, 76, 78, 81, 82, 83, 84, 85, 86, 87, 92], "layer": [10, 15, 16, 18, 19, 22, 24, 28, 29, 31, 35, 36, 37, 43, 44, 46, 47, 56, 57, 62, 67, 71, 73, 74, 76, 78, 82, 87, 92], "calcul": [11, 16, 32, 66, 67, 83, 87], "all": [11, 19, 28, 31, 33, 35, 43, 45, 55, 56, 57, 60, 64, 66, 67, 69, 72, 73, 74, 76, 78, 81, 82, 83, 85, 87, 88], "thi": [11, 12, 13, 16, 21, 22, 23, 24, 28, 33, 34, 39, 41, 43, 44, 46, 47, 50, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 90, 91, 92], "should": [11, 19, 28, 33, 34, 41, 43, 55, 56, 60, 64, 67, 68, 71, 78, 82, 83, 87, 92], "run": [11, 12, 28, 29, 33, 43, 50, 51, 55, 64, 66, 67, 68, 71, 73, 76, 81, 82, 83, 84, 85, 86, 87, 90, 92], "after": [11, 64, 66, 67, 68, 71, 72, 77, 82, 83, 84, 85, 86, 87, 91, 92], "optim": [11, 20, 23, 50, 64, 67, 68, 71, 76, 82, 84, 85, 86, 92], "step": [11, 41, 42, 62, 66, 67, 68, 71, 81, 82, 83, 84, 85, 86, 87, 92], "It": [11, 67, 76, 81, 87], "perform": [11, 22, 23, 24, 28, 33, 35, 36, 37, 43, 55, 67, 68, 69, 71, 74, 76, 77, 78, 82, 84, 85, 86, 92], "reduc": [11, 41, 62, 64, 67, 68, 69, 71, 73, 85], "comput": [11, 13, 18, 28, 33, 43, 51, 55, 56, 64, 66, 67, 74, 76, 77, 83, 84, 85, 86], "weight": [11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 41, 43, 44, 46, 47, 50, 53, 56, 59, 64, 67, 68, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 91, 92], "usag": [11, 26, 28, 29, 34, 38, 39, 41, 60, 68, 70, 71, 73, 85, 86, 92], "model": [11, 16, 18, 20, 21, 22, 24, 26, 31, 34, 35, 36, 37, 38, 41, 45, 50, 56, 57, 59, 67, 68, 74, 76, 81, 85, 86, 87, 91, 92], "sum": [11, 83, 84], "backward": [11, 67, 68, 71, 84, 92], "prototyp": [12, 13, 14, 39, 45, 66, 87], "mx_format": [12, 13, 14], "block_siz": [12, 66, 74], "int": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 43, 44, 46, 47, 50, 56, 60, 62, 68, 74, 76, 78], "32": [12, 20, 21, 23, 29, 38, 39, 41, 43, 44, 50, 59, 68, 71, 72, 73, 74, 76, 79, 84, 92], "activation_dtyp": [12, 15, 16, 66], "float8_e4m3fn": [12, 13, 15, 16, 18, 32, 66], "weight_dtyp": [12, 15, 16, 18, 23, 25, 66, 73], "kernel_prefer": [12, 16, 66], "kernelprefer": [12, 16], "auto": [12, 16, 51, 64, 73, 77, 78], "mx": 12, "format": [12, 13, 19, 20, 23, 25, 52, 64, 67, 73, 83, 84, 87], "infer": [12, 13, 41, 62, 66, 67, 68, 69, 72, 74, 76, 77, 79, 82, 83, 84, 85, 86, 91, 92], "quantiz": [12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 59, 61, 62, 64, 65, 67, 71, 72], "provid": [12, 26, 45, 60, 63, 64, 66, 67, 68, 69, 71, 73, 76, 78, 83, 84, 86, 87, 91, 92], "support": [12, 15, 16, 17, 19, 20, 21, 23, 31, 38, 39, 41, 51, 53, 54, 59, 60, 62, 66, 67, 68, 69, 71, 72, 73, 76, 82, 83, 84, 85, 86, 87, 91, 92], "requir": [12, 23, 51, 60, 62, 66, 67, 68, 69, 73, 76, 77, 79, 81, 82, 85, 87], "nvidia": [12, 13, 62, 67], "sm100": 12, "hardwar": [12, 16, 51, 52, 64, 67, 69, 73, 77, 81, 91], "blackwel": [12, 68], "newer": [12, 68], "i": [12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 38, 39, 41, 50, 53, 54, 56, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 90, 92], "execut": [12, 50, 70, 76, 89], "pytorch": [12, 39, 60, 62, 66, 67, 68, 71, 73, 76, 78, 81, 90], "2": [12, 16, 18, 19, 20, 22, 23, 24, 25, 28, 39, 43, 44, 57, 59, 64, 66, 67, 69, 70, 71, 74, 76, 81, 90, 91, 92], "5": [12, 16, 18, 28, 56, 64, 67, 68, 73, 78, 81, 83, 84, 90, 92], "proper": 12, "serial": [12, 60, 66, 70, 77, 83, 84], "use_triton_kernel": [13, 78], "use_dynamic_per_tensor_scal": [13, 14], "fp4": 13, "nvfp4": [13, 66, 68, 91, 92], "special": [13, 67, 82, 83], "": [13, 19, 51, 52, 60, 64, 66, 67, 68, 69, 71, 73, 74, 76, 83, 84, 85, 86, 87, 92], "whether": [13, 39, 60, 64, 68, 76], "fuse": [13, 67, 76, 81, 84, 92], "triton": [13, 66, 85, 86], "kernel": [13, 16, 17, 46, 50, 51, 61, 67, 73, 82, 85, 86, 92], "activ": [13, 15, 16, 21, 22, 23, 28, 29, 31, 37, 38, 39, 41, 47, 53, 54, 56, 62, 67, 68, 73, 74, 77, 78, 79, 81, 82, 85, 86, 87, 91, 92], "default": [13, 16, 18, 20, 23, 31, 39, 47, 50, 60, 64, 66, 68, 71, 76, 78, 81, 82, 83, 84, 85, 86, 87], "per": [13, 17, 18, 21, 22, 23, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 56, 64, 66, 67, 68, 71, 74, 86, 92], "data": [13, 15, 16, 18, 22, 52, 60, 62, 66, 67, 68, 72, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 91], "float4_e2m1fn_x2": [13, 66], "block": [13, 56, 67, 91], "size": [13, 20, 21, 24, 39, 62, 64, 67, 71, 72, 73, 74, 76, 78, 84, 92], "16": [13, 29, 68, 71, 92], "along": [13, 67, 78, 82], "reduct": [13, 67, 69, 72, 73, 76], "dim": [13, 22, 24, 32, 74, 76, 78, 83, 84], "note": [13, 19, 20, 23, 25, 26, 38, 47, 56, 60, 62, 64, 66, 67, 68, 69, 73, 76, 78, 84, 85, 86], "work": [13, 62, 64, 65, 67, 68, 71, 72, 76, 77, 78, 83, 84, 85], "mode": [13, 62, 64, 69, 70, 74, 82, 84, 85, 86, 87], "ha": [13, 41, 64, 67, 68, 73, 76, 78, 82, 83, 84, 86, 87], "constraint": [13, 83, 84, 87], "dimens": [13, 62, 64, 66, 71, 76, 78, 83, 84], "must": [13, 19, 23, 25, 26, 39, 41, 47, 67, 71, 77, 78, 84, 86, 87], "satisfi": [13, 67], "m": [13, 50, 59, 62, 64, 68, 71, 72, 73, 74, 76, 81, 83, 84, 85, 92], "128": [13, 17, 20, 69, 71, 73, 74, 76, 77, 78, 86, 87, 92], "0": [13, 19, 23, 25, 28, 39, 43, 44, 56, 60, 62, 64, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 79, 83, 84, 86, 87, 89, 90, 92], "k": [13, 62, 64, 72, 74, 76, 83, 84], "64": [13, 20, 31, 72, 73, 74, 76, 78, 92], "Will": 13, "automat": [13, 41, 71, 73, 76, 77, 78, 90, 92], "fallback": [13, 19, 78], "when": [13, 19, 23, 41, 60, 62, 64, 66, 67, 68, 71, 73, 74, 77, 78, 82, 83, 84, 85, 86, 87], "aren": 13, "t": [13, 19, 56, 60, 64, 66, 67, 69, 71, 74, 76, 77, 78, 83, 84, 87], "met": 13, "layout": [15, 20, 21, 22, 23, 59, 60, 67], "cutlasssemisparselayout": 15, "float8_e5m2": [15, 66], "appli": [15, 16, 17, 18, 19, 21, 22, 24, 26, 30, 31, 33, 38, 40, 41, 50, 59, 60, 64, 66, 67, 68, 73, 78, 84, 92], "follow": [15, 39, 41, 60, 64, 66, 67, 68, 71, 73, 74, 76, 77, 81, 82, 83, 84, 85, 86, 87, 92], "compress": [15, 67, 82], "spars": [15, 28, 43, 44, 56, 67], "semi": [15, 59, 67], "structur": [15, 59, 64, 66, 67, 68, 69, 72, 76, 83], "moment": 15, "pertensor": [16, 24, 32, 74], "perrow": [16, 22, 24, 32, 66], "list": [16, 26, 56, 60, 69, 76, 77, 78, 82, 84, 87], "packing_format": [16, 20], "float8packingformat": 16, "plain": [16, 20, 52, 66, 78], "mm_config": 16, "float8mmconfig": 16, "activation_value_lb": 16, "float": [16, 28, 32, 39, 43, 44, 56, 66, 68, 72, 76, 81, 83, 84, 87, 92], "activation_value_ub": 16, "set_inductor_config": [16, 18, 20, 21, 22, 24], "version": [16, 18, 19, 20, 22, 23, 24, 25, 39, 60, 66, 68, 76, 78, 79, 83, 84, 87, 92], "symmetr": [16, 18, 21, 22, 23, 24, 25, 28, 31, 39, 68, 76, 82, 83, 86, 87, 92], "both": [16, 20, 41, 47, 66, 67, 69, 74, 76, 81, 83, 85, 86, 87, 92], "target": [16, 18, 20, 28, 29, 32, 39, 56, 62, 64, 67, 68, 81, 82, 83, 84, 85, 86, 87, 92], "fp8granular": [16, 32], "can": [16, 26, 39, 50, 51, 60, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92], "either": [16, 32, 41, 56, 64, 67, 73, 84, 85, 86], "tupl": [16, 45, 56, 60, 76, 78, 83, 84, 87], "two": [16, 41, 60, 66, 67, 68, 76, 81, 82, 83, 84, 85, 87, 92], "one": [16, 23, 25, 28, 33, 41, 43, 55, 64, 66, 67, 71, 76, 78, 84, 87, 92], "current": [16, 20, 21, 31, 32, 41, 50, 56, 59, 62, 66, 67, 71, 76, 77, 78, 81, 83, 84, 86, 92], "need": [16, 28, 33, 43, 52, 53, 54, 55, 56, 60, 62, 64, 66, 67, 68, 72, 73, 76, 78, 83, 84, 85, 87], "same": [16, 20, 23, 47, 59, 60, 66, 67, 68, 71, 74, 76, 84, 86, 87, 92], "And": [16, 76, 85, 87], "matrix": [16, 51, 56, 62, 66, 67, 85], "multipl": [16, 26, 51, 53, 62, 64, 66, 67, 68, 74, 76, 78, 85, 87, 92], "fast": [16, 67], "accumul": [16, 92], "lower": [16, 21, 32, 66, 67, 68, 73, 74, 77, 81, 84, 92], "bound": [16, 32, 64, 67, 73, 78], "upper": [16, 32], "prefer": [16, 66, 68, 76], "op": [16, 50, 51, 60, 64, 67, 68, 76, 78, 81, 83, 84, 85, 87, 92], "like": [16, 23, 60, 62, 64, 66, 67, 68, 69, 71, 72, 76, 77, 78, 82, 83, 84, 85, 86, 87], "matmul": [16, 18, 66, 67, 76], "group": [16, 17, 21, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 51, 62, 64, 68, 92], "etc": [16, 28, 29, 52, 54, 62, 64, 66, 82, 87], "defalut": 16, "chosen": [16, 54, 67], "user": [16, 26, 41, 47, 62, 64, 65, 66, 67, 68, 71, 73, 74, 76, 81, 83, 84, 85, 86, 87, 90, 92], "base": [16, 19, 23, 25, 27, 40, 41, 45, 53, 54, 56, 60, 64, 66, 67, 69, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92], "other": [16, 23, 40, 51, 56, 62, 67, 68, 71, 72, 73, 76, 78, 79, 83, 84, 85, 87, 90], "inform": [16, 60, 62, 66, 67, 73, 78, 82, 83], "set": [16, 18, 20, 21, 22, 24, 39, 50, 56, 60, 67, 68, 82, 84, 85, 86, 92], "adjust": [16, 18, 20, 21, 22, 24, 68], "torchinductor": [16, 18, 20, 21, 22, 24, 85, 86], "recommend": [16, 18, 20, 21, 22, 24, 64, 66, 68, 69, 71, 77, 79, 82, 85, 86, 91], "deprec": [16, 18, 19, 22, 34, 38, 60], "float8tensor": [16, 18, 32, 53, 64, 66, 78], "from": [16, 18, 19, 20, 21, 22, 24, 34, 38, 41, 50, 51, 59, 60, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 90, 92], "import": [16, 18, 20, 22, 24, 34, 38, 41, 50, 59, 64, 67, 68, 69, 72, 73, 74, 76, 77, 78, 79, 81, 82, 85, 86, 90, 92], "quantize_": [16, 18, 20, 22, 24, 34, 38, 41, 50, 51, 52, 53, 54, 59, 61, 62, 64, 66, 68, 69, 72, 73, 74, 79], "rowwis": [16, 31, 66, 91], "int4_packing_format": [17, 20, 79], "int4packingformat": [17, 20], "preshuffl": [17, 66], "row": [17, 62, 64, 66, 67, 71], "int4": [17, 20, 21, 23, 28, 29, 31, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 64, 66, 68, 72, 73, 77, 78, 79, 91, 92], "group_siz": [17, 20, 21, 23, 24, 28, 29, 31, 35, 38, 39, 41, 43, 44, 50, 62, 68, 77, 78, 79, 92], "right": [17, 20, 64, 67, 83], "now": [17, 20, 62, 64, 66, 67, 68, 69, 71, 74, 76, 77, 82, 83, 85, 87, 92], "sinc": [17, 19, 28, 33, 43, 55, 60, 66, 67, 72, 73, 74, 76, 83, 84, 85, 86, 87], "underli": [17, 73, 76], "abov": [17, 23, 25, 64, 66, 67, 68, 72, 74, 76, 83, 84, 87, 92], "benefit": [17, 67, 68, 76, 83, 86], "make": [17, 64, 66, 76, 78, 81, 83, 87], "bigger": 17, "pack": [17, 20, 23, 25, 52, 64], "channel": [18, 22, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 55, 74, 86], "actual": [18, 41, 51, 66, 68, 74, 76, 78, 83, 84, 87, 92], "origin": [18, 22, 34, 56, 62, 66, 67, 68, 69, 72, 73, 82, 83, 87], "precis": [18, 22, 31, 32, 36, 37, 41, 44, 46, 47, 66, 68, 74, 76, 77, 82, 85, 86], "fqn_to_config": 19, "ordereddict": 19, "core": [19, 50, 74, 78, 83], "aobaseconfig": [19, 41, 50, 59, 62, 74, 78], "factori": 19, "module_fqn_to_config": 19, "differ": [19, 20, 26, 62, 64, 66, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 83, 84, 85, 87, 91, 92], "fulli": [19, 50, 59, 67, 73, 83], "qualifi": [19, 50, 59, 67], "an": [19, 38, 39, 41, 47, 56, 63, 66, 67, 68, 71, 73, 74, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 91], "order": [19, 26, 60, 64, 67, 76, 87], "dictionari": [19, 67], "regex": [19, 82], "python": [19, 62, 64, 67, 73, 81, 82, 83, 85, 86, 88, 90], "re": [19, 64, 66, 71, 72, 73, 76, 83, 84], "prefix": 19, "3": [19, 28, 66, 67, 70, 71, 77, 79, 81, 83, 84, 90, 92], "_default": [19, 73, 78], "we": [19, 20, 22, 38, 39, 41, 47, 50, 59, 60, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87], "want": [19, 50, 59, 64, 66, 67, 72, 76, 78, 81, 82, 83, 84, 87], "param": [19, 25, 56, 73], "kei": [19, 56, 67, 90], "preced": [19, 82, 83, 85, 86], "e": [19, 26, 39, 41, 50, 53, 60, 64, 66, 68, 71, 72, 74, 76, 77, 79, 82, 87, 92], "g": [19, 26, 39, 41, 50, 53, 60, 64, 66, 68, 72, 74, 76, 82, 87, 92], "languag": [19, 73], "q_proj": [19, 78, 92], "first": [19, 41, 56, 60, 64, 66, 70, 73, 74, 76, 77, 78, 79, 83, 84, 87, 92], "match": [19, 46, 47, 60, 67, 83], "whichev": 19, "kept": 19, "consist": [19, 62, 67, 73, 76, 85, 86, 87], "previou": [19, 66, 73, 83, 84, 85, 86], "subset": [19, 23, 25, 66], "some": [19, 50, 56, 60, 64, 66, 67, 73, 74, 76, 81, 82, 83, 84, 85, 86, 87], "better": [19, 22, 24, 69, 71, 76, 83, 84, 85, 86, 87], "don": [19, 56, 64, 66, 67, 69, 71, 77, 78, 87], "befor": [19, 41, 50, 64, 66, 67, 68, 72, 73, 74, 76, 83, 84, 87, 92], "hand": 19, "them": [19, 28, 33, 43, 55, 62, 68, 87, 92], "norm": [19, 55, 56, 67], "linear_config": [19, 73], "filter_fn": [19, 50, 59, 92], "To": [19, 47, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 83, 84, 85, 87, 92], "maintain": [19, 60, 67, 73], "bc": [19, 60], "modulefqntoconfig": 19, "later": [19, 66, 68, 76, 83, 84, 86], "pattern": [19, 66, 78, 81, 82, 83], "mai": [19, 39, 52, 64, 66, 72, 74, 77, 83, 84, 85, 86, 87, 92], "matter": [19, 66, 67], "ignor": [19, 28, 33, 43, 55, 71, 83, 84], "replac": [19, 67, 68, 78], "int4_choose_qparams_algorithm": [20, 79], "int4chooseqparamsalgorithm": 20, "tinygemm": [20, 46, 50, 92], "groupwis": [20, 23, 25], "although": [20, 28, 33, 43, 55, 68, 76], "In": [20, 41, 64, 66, 67, 68, 69, 71, 74, 76, 82, 83, 84, 85, 86, 87, 92], "mainli": [20, 66, 82, 85, 87], "distinguish": [20, 66], "arg": [20, 23, 25, 28, 29, 30, 31, 35, 44, 56, 60, 64, 66, 76, 78, 84, 87], "control": [20, 21, 22, 56, 67, 78, 83], "smaller": [20, 21, 68, 69, 72, 92], "more": [20, 21, 23, 25, 62, 64, 66, 67, 68, 69, 71, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 92], "fine": [20, 21, 67, 70, 71, 73, 92], "grain": [20, 21, 76], "choic": [20, 64], "256": [20, 35, 36, 37, 46, 47, 73, 83, 84, 87], "variant": [20, 76], "choos": [20, 23, 25, 54, 64, 66, 67, 76, 83, 85], "qparam": 20, "algorithm": [20, 23, 25, 64, 67, 73, 82, 91], "hqq": [20, 66, 79, 91], "vari": [20, 68, 69, 83, 84, 85, 86], "backend": [20, 21, 67, 73, 81, 87], "cuda": [20, 50, 62, 64, 67, 68, 69, 71, 72, 73, 74, 76, 77, 79, 84, 92], "is_avail": [20, 79], "tile": 20, "tile_packed_to_4d": [20, 79], "elif": [20, 62, 78, 79], "xpu": [20, 79, 81, 86], "plain_int32": [20, 79], "plainlayout": [21, 22, 60, 74], "mapping_typ": [21, 25, 39], "mappingtyp": [21, 22, 23, 25, 39, 74], "act_mapping_typ": [21, 22, 23], "asymmetr": [21, 23, 25, 39, 68, 74, 82, 86, 87, 92], "int8": [21, 22, 23, 24, 25, 29, 37, 38, 39, 41, 47, 50, 54, 59, 66, 68, 69, 73, 76, 83, 85, 86, 87, 91, 92], "token": [21, 22, 23, 37, 39, 47, 68, 71, 73, 77, 92], "produc": [21, 81, 82, 83, 84, 85, 86, 92], "executorch": [21, 23, 64, 70, 77, 81, 83, 84], "did": [21, 68], "flow": [21, 67, 68, 71, 73, 74, 82, 83, 84, 85, 86], "yet": [21, 41, 68, 76, 78, 84, 85, 86], "weight_only_decod": 22, "store": [22, 53, 55, 66, 67, 77, 78, 83, 84], "access": [22, 64, 82], "map": [22, 23, 25, 39, 60, 66, 68, 76, 83, 87], "around": [22, 66, 71, 72, 81, 83], "zero": [22, 23, 25, 39, 44, 45, 46, 47, 56, 67, 74, 87, 92], "dure": [22, 39, 41, 67, 68, 71, 73, 74, 76, 81, 82, 84, 92], "forward": [22, 28, 29, 33, 40, 43, 46, 55, 62, 67, 69, 72, 74, 76, 78, 81, 83, 84, 85], "keep": [22, 56, 64, 66, 83], "decod": [22, 73], "oper": [22, 64, 66, 68, 73, 81, 82, 83, 84, 85, 86, 92], "scheme": [22, 24, 28, 29, 41, 68, 73, 82], "affinequantizedtensor": [22, 64, 72, 74, 76], "plan": [22, 64, 84, 91], "split": [22, 73, 83, 84], "int8tensor": [22, 66, 69], "weight_granular": [23, 66, 73], "pergroup": [23, 25, 39, 73], "weight_mapping_typ": 23, "weight_scale_dtyp": [23, 73], "intx_packing_format": [23, 25], "intxpackingformat": [23, 25], "unpacked_to_int8": [23, 25], "intx_choose_qparams_algorithm": [23, 25], "intxchooseqparamsalgorithm": [23, 25], "affin": [23, 25, 66], "intx": [23, 25, 91], "x": [23, 25, 28, 29, 33, 40, 43, 62, 69, 71, 72, 73, 74, 76, 78, 81, 82, 83, 84, 85, 86, 90], "8": [23, 25, 28, 29, 36, 46, 66, 68, 71, 73, 78, 85, 86, 92], "specif": [23, 28, 29, 47, 52, 56, 62, 64, 66, 67, 68, 71, 72, 73, 77, 82, 85, 86, 87, 92], "bit": [23, 25, 40, 62, 68, 73, 76, 77, 78, 83, 85, 86, 92], "channelwis": [23, 25], "manner": [23, 25], "number": [23, 25, 31, 44, 46, 47, 56, 67, 73, 76, 84, 85], "ident": [23, 67, 71], "int8dynamicactivationint4weightconfig": [23, 41, 47, 68, 92], "howev": [23, 67, 77, 78, 84, 87], "gener": [23, 28, 29, 30, 33, 40, 62, 66, 67, 68, 69, 73, 74, 76, 78, 82, 84, 85, 86, 87, 88, 90, 92], "where": [23, 25, 35, 36, 37, 62, 66, 67, 78, 87], "peraxi": [23, 25, 39, 73, 74], "axi": [23, 25, 74], "zeropointdomain": [23, 39], "intend": [23, 51, 63, 66, 83], "export": [23, 66, 81], "applic": [23, 73], "opaque_torchao_auto": 23, "cpu": [23, 62, 64, 67, 72, 74, 77, 78, 79, 82, 83, 84, 85], "valid": [23, 25, 60, 73, 78, 87], "see": [23, 25, 60, 62, 64, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 79, 82, 83, 87, 91, 92], "detail": [23, 25, 62, 64, 66, 67, 68, 69, 71, 73, 74, 76, 79, 82, 83, 84, 85, 91, 92], "otherwis": [24, 26, 39, 84], "scale_dtyp": [25, 74], "qat": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 61, 70, 73, 79, 85], "twostepquant": 26, "compos": [26, 66, 67, 68, 76, 83, 84, 87], "easili": [26, 82], "thei": [26, 67, 71, 76, 77, 81, 83, 84, 87], "constructor": [26, 60, 76], "embed": [26, 28, 35, 38, 41, 43, 44, 92], "behavior": [26, 78, 83, 84], "undefin": [26, 56], "my_quant": 26, "qatquantizer1": 26, "qatquantizer2": 26, "qatquantizer3": 26, "prepar": [26, 31, 35, 41, 56, 67, 68, 82, 85, 86, 87, 92], "fake": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 68, 71, 83, 84, 87, 92], "num_embed": [28, 43, 44], "embedding_dim": [28, 43, 44], "padding_idx": [28, 43, 44], "max_norm": [28, 43, 44], "norm_typ": [28, 43, 44], "scale_grad_by_freq": [28, 43, 44], "weight_config": [28, 29, 38, 41, 92], "fakequantizeconfigbas": [28, 29, 38, 41], "kwarg": [28, 29, 30, 31, 35, 39, 44, 54, 55, 56, 57, 60, 62, 64, 66, 76, 78], "through": [28, 29, 62, 64, 66, 68, 69, 73, 74, 76, 78, 81, 82, 83, 87, 90, 92], "separ": [28, 29, 39, 67, 68, 78, 83, 87], "intxfakequantizeconfig": [28, 29, 38, 40, 41, 92], "fq_embed": 28, "10": [28, 62, 64, 68, 69, 71, 73, 74, 81, 83, 84, 92], "longtensor": 28, "everi": [28, 33, 43, 55, 67, 76, 83, 84], "call": [28, 33, 43, 55, 60, 64, 66, 67, 68, 72, 74, 76, 78, 84, 86, 92], "overridden": [28, 33, 43, 55], "within": [28, 33, 43, 55, 67, 73, 78, 85, 86], "afterward": [28, 33, 43, 55], "instead": [28, 33, 34, 38, 39, 41, 43, 55, 67, 68, 71, 76, 81, 84, 85, 86, 87], "former": [28, 33, 43, 55], "take": [28, 33, 43, 50, 55, 59, 60, 66, 67, 82, 83, 84, 85, 86, 87], "care": [28, 33, 43, 55, 67, 72, 83], "regist": [28, 33, 43, 55, 60, 64, 66, 76], "hook": [28, 33, 43, 55, 66], "while": [28, 33, 41, 43, 53, 55, 56, 67, 68, 69, 73, 76, 77, 82, 83, 87, 92], "latter": [28, 33, 43, 55, 84], "silent": [28, 33, 43, 55, 85], "in_featur": [29, 46, 47, 69, 71, 72, 74, 76], "out_featur": [29, 46, 47, 71, 74, 76], "bia": [29, 46, 47, 62, 66, 68, 69, 72, 74, 76, 78, 84, 87], "activation_config": [29, 38, 41, 92], "per_token": [29, 38, 39, 41, 92], "is_symmetr": [29, 38, 39, 41, 92], "fq_linear": 29, "randn": [29, 62, 68, 69, 71, 72, 74, 76, 82, 83, 84, 85, 86, 92], "ani": [30, 31, 35, 45, 56, 63, 64, 66, 67, 76, 82, 84, 86], "scale_precis": [31, 35, 39, 43, 44], "bfloat16": [31, 36, 46, 62, 66, 67, 69, 71, 72, 73, 74, 77, 78, 85, 86, 91, 92], "element": [31, 44, 46, 47, 60, 66, 67], "each": [31, 39, 44, 46, 47, 55, 60, 64, 66, 67, 74, 76, 78, 83, 84, 87, 92], "fakequantizedlinear": [31, 34, 48, 49, 68, 92], "hp_value_lb": 32, "hp_value_ub": 32, "high": [32, 41, 66, 67, 68, 71, 73, 74, 76, 82, 83, 85, 86], "point": [32, 39, 44, 45, 46, 47, 66, 67, 69, 71, 72, 74, 76, 81, 83, 87, 92], "float8fakequantizeconfig": 33, "qatconfig": [34, 38, 42, 68, 92], "fakequantizedembed": 34, "back": [34, 76], "correspond": [34, 41, 50, 62, 66, 67, 68, 72, 76, 86, 87, 92], "without": [34, 66, 67, 68, 78, 85, 87, 92], "model_with_fake_quantized_linear": 34, "float32": [35, 37, 39, 43, 44, 47, 67, 68, 72, 73, 74, 76, 85, 86, 87], "zero_point_precis": [35, 39, 43, 44], "int32": [35, 39, 43, 44, 66, 83, 87], "have": [35, 36, 37, 52, 56, 63, 64, 66, 67, 68, 74, 76, 78, 82, 83, 84, 85, 86, 87, 92], "int4weightonlyqatembed": 35, "int4weightonlyembed": 35, "groupsiz": [36, 37, 46, 47, 68, 92], "inner_k_til": [36, 46], "scales_precis": [36, 37, 46, 47], "padding_allow": 37, "rais": [38, 41, 76, 78], "valueerror": [38, 41], "torchaodtyp": 39, "zero_point_domain": 39, "is_dynam": [39, 85, 86, 87], "range_learn": 39, "ep": [39, 74, 84, 86, 87], "integ": [39, 40, 68, 74, 83, 84, 85], "up": [39, 50, 66, 67, 68, 71, 82, 83, 84, 87, 92], "simul": [39, 41, 57, 67, 92], "older": [39, 60], "than": [39, 66, 67, 68, 69, 71, 76, 83], "6": [39, 66, 67, 71, 73, 79, 83, 84, 85], "you": [39, 56, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 76, 77, 78, 82, 83, 84, 85, 86, 87, 90, 92], "int1": [39, 66], "int7": [39, 66], "also": [39, 50, 64, 66, 67, 68, 69, 72, 74, 76, 77, 78, 83, 86, 87, 92], "equival": [39, 67, 68, 84, 85, 87, 92], "pertoken": 39, "per_channel": 39, "per_group": 39, "combin": [39, 67, 73, 76, 83, 85], "altern": [39, 68, 74, 76, 85, 86, 92], "just": [39, 64, 66, 67, 72, 76, 83, 84, 87], "leav": 39, "field": [39, 42, 87], "empti": [39, 66], "fp32": [39, 47, 74, 76, 83, 85], "domain": [39, 68, 71], "learn": [39, 67, 69, 83, 85, 86, 87, 90, 92], "compat": [39, 62, 64, 79], "keyword": [39, 41, 53, 66], "argument": [39, 41, 50, 53, 60, 66, 71, 73, 85], "properti": [39, 40], "throw": 39, "error": [39, 71, 76, 83], "els": [39, 66, 73, 78, 83, 84], "width": [40, 62, 92], "symmetri": 40, "base_config": [41, 68, 92], "qatstep": 41, "awar": [41, 56, 67, 76, 81], "here": [41, 47, 62, 63, 66, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 92], "numer": [41, 46, 47, 51, 67, 68, 71, 83, 84, 85, 92], "arithmet": [41, 68], "bf16": [41, 62, 67, 68, 85, 86, 92], "goal": [41, 68], "eventu": [41, 68, 71], "degrad": [41, 67, 68, 79], "There": [41, 66, 68, 74, 76, 83, 87], "wai": [41, 64, 66, 67, 71, 73, 74, 76, 83, 84, 87, 92], "involv": [41, 67, 68, 92], "post": [41, 66, 69, 76, 81, 84, 87, 91, 92], "ptq": [41, 84, 85, 91, 92], "which": [41, 46, 51, 62, 64, 66, 67, 68, 71, 72, 73, 74, 78, 82, 83, 84, 85, 86, 87, 92], "phase": [41, 87], "most": [41, 63, 64, 66, 67, 73, 78, 83, 84, 87, 92], "common": [41, 51, 52, 53, 54, 61, 64, 66, 67, 71], "case": [41, 51, 62, 63, 64, 67, 73, 76, 78, 82, 83, 87, 92], "train_loop": [41, 68, 92], "int4weightonlyconfig": [41, 50, 72, 77, 78, 79, 92], "second": [41, 60, 66, 71, 87, 90], "directli": [41, 66, 67, 68, 74, 76], "mostli": [41, 81], "experiment": [41, 82, 92], "doe": [41, 51, 52, 64, 66, 67, 68, 76, 83, 85, 86, 92], "exist": [41, 64, 66, 67, 71, 74, 76, 83, 87], "qat_config": [41, 92], "act_config": 41, "custom": [41, 55, 62, 66, 67, 68, 71, 76, 78, 79, 82, 83, 85, 87, 92], "alwai": [41, 73, 76], "One": [41, 67, 76, 78, 87], "determin": [41, 67, 71, 78], "enum": [42, 51], "devic": [43, 46, 47, 50, 62, 64, 68, 69, 71, 72, 73, 74, 76, 78, 82, 83, 84, 85, 86], "output_dtyp": 43, "example_input": [45, 69, 72, 74, 81, 82, 83, 84, 85, 86, 87], "initi": [45, 66, 68, 72, 81, 84], "intxfakequantizerbas": 45, "weightonlyint4linear": 46, "effici": [46, 67, 68, 74, 86, 92], "hardcod": [47, 87, 92], "allow": [47, 64, 66, 67, 76, 81, 82, 83, 84, 85, 87, 92], "get": [47, 60, 64, 66, 67, 68, 69, 71, 73, 78, 81, 82, 83, 84, 85, 87], "exact": [47, 68, 83, 84], "mod": [48, 49, 67, 71, 76], "helper": [48, 49, 60, 64], "disabl": [48, 76, 84], "enabl": [49, 60, 62, 64, 66, 69, 71, 73, 78, 85], "_is_linear": [50, 74], "inplac": [50, 56, 69], "workflow": [50, 51, 59, 62, 64, 67, 69, 71, 81, 87], "object": [50, 59, 64, 66, 76, 83, 84, 87], "move": [50, 64, 74, 78, 84, 85], "speed": [50, 67, 68, 73, 82], "final": [50, 66, 67, 69, 82, 83, 84, 85, 86, 87, 92], "do": [50, 64, 66, 67, 73, 74, 76, 78, 83, 84, 85, 87], "chang": [50, 64, 67, 69, 71, 72, 73, 74, 76, 82, 83, 84, 86, 87], "predefin": [50, 52, 87], "method": [50, 56, 60, 62, 64, 67, 74, 76, 77, 81, 82, 83, 84, 86, 87], "path": [50, 68, 69, 73, 81, 82, 83, 84, 85, 87], "customiz": [50, 68], "int8dynamicactivationint8weightconfig": [50, 59, 69, 77], "mm": [50, 51, 64, 76, 83], "compil": [50, 66, 68, 69, 71, 74, 76, 81, 85, 86], "int8weightonlyconfig": [50, 68, 77, 78], "quant_api": [50, 64, 72, 73, 74], "sequenti": [50, 59, 71], "1024": [50, 59, 62, 69, 72, 85], "affect": [51, 67], "select": [51, 83], "found": [51, 66, 67, 69, 73, 74, 76], "under": [51, 64, 68, 73], "nativ": [51, 66, 71, 76, 83], "mslk": [51, 64, 66], "gemm_lowp": 51, "A": [51, 55, 60, 64, 66, 67, 68, 76, 77, 78, 83, 92], "b": [51, 60], "gemm_fp32": 51, "dequant": [51, 66, 76, 78, 81, 83, 85, 86, 87, 92], "ci": 51, "product": [51, 56, 69, 73, 78, 85, 87], "logic": [51, 69, 76, 78], "lowp": 51, "gemm": [51, 71, 85, 86], "debug": [51, 64], "issu": [51, 63, 66, 69, 76, 85], "librari": [51, 52, 64, 66, 72, 79], "laid": [52, 66], "out": [52, 56, 62, 64, 66, 67, 68, 69, 71, 73, 76, 81, 82, 83, 84, 85], "opaqu": 52, "decid": [52, 67, 74], "shape": [52, 62, 64, 66, 74, 76, 78, 83, 86], "avail": [52, 62, 64, 66, 73, 82, 83, 84, 85, 86, 91], "rest": [52, 62, 76, 84], "system": [52, 62, 64, 73], "understand": [52, 64, 71, 85, 87], "adopt": [52, 66], "contain": [53, 54, 62, 67, 76, 84, 87], "creation": [53, 78], "construct": [53, 66, 83, 87], "classmethod": [53, 60, 74, 76, 78], "def": [53, 59, 60, 62, 64, 66, 68, 69, 71, 72, 74, 76, 78, 81, 82, 83, 84, 85, 86, 87, 92], "from_hp": [53, 66], "cl": [53, 60, 74, 76, 78], "quant_kwarg": [53, 54], "quantizetensorkwarg": 54, "given": [54, 67, 71, 78, 87], "deriv": [54, 64], "flexibl": [54, 67, 76, 82, 85, 92], "variou": 54, "sparsiti": [55, 56, 57, 58, 59, 61, 62, 65, 68, 71, 72, 73, 91], "observ": [55, 66, 67, 74, 82, 83, 84, 85, 86, 87], "l2": [55, 67], "buffer": 55, "x_orig": 55, "sparsity_level": [56, 67], "semi_structured_block_s": 56, "wanda": 56, "sparsifi": [56, 67, 72, 79], "prune": 56, "propos": [56, 68], "http": [56, 60, 67, 73, 77, 79, 86, 92], "arxiv": [56, 67], "org": [56, 60, 67, 73, 79, 86], "ab": [56, 67], "2306": 56, "11695": 56, "remov": [56, 64, 67, 71, 78, 83, 84, 92], "magnitud": [56, 67], "three": [56, 59, 85, 86], "variabl": [56, 67], "level": [56, 64, 66, 67, 76, 82, 83, 85, 86], "dict": [56, 60, 76, 78, 86, 87], "ad": [56, 60, 62, 66, 67, 68, 74, 76, 84], "parametr": 56, "preserv": [56, 67, 73, 82], "copi": [56, 64, 67, 69, 72, 74, 76, 84, 85], "deepcopi": [56, 69, 74, 76, 84], "squash_mask": [56, 67], "params_to_keep": 56, "params_to_keep_per_lay": 56, "squash": 56, "mask": [56, 67], "appropri": [56, 82, 83, 84, 85, 86], "sparse_param": 56, "attach": [56, 67, 87], "save": [56, 60, 64, 68, 69, 71, 72, 73, 78, 92], "xdoctest": 56, "skip": [56, 66, 67], "local": [56, 67, 73], "hasattr": [56, 78], "submodule1": 56, "linear1": [56, 69, 72, 74, 76], "foo": [56, 83], "bar": [56, 83], "submodule2": 56, "linear42": 56, "baz": 56, "print": [56, 68, 69, 72, 73, 76, 83, 84, 90], "42": [56, 74], "24": 56, "ones": [56, 84], "update_mask": 56, "tensor_nam": [56, 78], "statist": [56, 67, 74, 83, 84], "retriev": 56, "act_per_input": 56, "Then": [56, 76, 86, 87, 92], "metric": [56, 62, 68], "compar": [56, 64, 66, 68, 69, 71, 73, 83, 85, 87, 92], "across": [56, 67, 73, 76, 78], "whole": [56, 87], "4": [57, 59, 66, 67, 68, 69, 72, 73, 76, 77, 83, 84, 91, 92], "alia": [58, 60, 78], "semisparseweightconfig": 58, "sparsify_": 59, "apply_tensor_subclass": 59, "essenti": [59, 78, 82], "put": [59, 64, 85, 87], "semi_sparse_weight": 59, "semisparselayout": 59, "isinst": [59, 67, 71, 74, 76, 78, 84, 87, 92], "sparse_api": 59, "util": [60, 61, 62, 64, 66, 72, 76, 78, 82, 83, 84, 85, 86, 87], "commonli": [60, 67, 71], "new": [60, 62, 66, 68, 71, 74, 76, 83, 84, 85, 87], "inherit": [60, 76, 78, 85, 86], "attribut": [60, 64, 66, 68, 76, 78, 85, 86], "tensor_data_nam": [60, 64], "tensor_data": 60, "__init__": [60, 62, 68, 69, 72, 74, 76, 78, 81, 83, 84, 85], "been": [60, 68, 76, 84, 85, 86, 87], "section": [60, 64, 66, 67, 78, 83, 84, 87], "tensor_attribute_nam": [60, 64], "non": [60, 64, 67, 76, 82, 85, 86], "optional_tensor_data_nam": 60, "addit": [60, 62, 66, 67, 68, 71, 76, 77, 82, 83, 86, 87, 92], "optional_tensor_attribute_nam": 60, "__new__": [60, 76, 78], "exaclti": 60, "present": [60, 67], "includ": [60, 66, 71, 76, 82, 85, 86, 87, 91], "__tensor_flatten__": [60, 76, 78], "flatten": 60, "attribute_nam": 60, "__tensor_unflatten__": [60, 76, 78], "tensor_data_dict": [60, 76, 78], "_apply_fn_to_data": [60, 78], "recreat": 60, "transform": [60, 64, 68, 74, 82, 83, 84, 85, 86, 92], "__repr__": [60, 76], "represent": [60, 67, 78, 83, 87], "_same_metadata": 60, "metadata": [60, 66, 73, 76, 78], "between": [60, 66, 67, 76, 78, 82, 84, 85, 87, 92], "__setstate__": 60, "load": [60, 64, 72, 73, 77, 78], "checkpoint": [60, 68, 71, 73, 78], "old": 60, "add": [60, 64, 76, 77, 85, 87, 90], "__torch_function__": [60, 66, 76], "contigu": [60, 66, 85, 86], "aten": [60, 64, 66, 76, 78, 81, 82, 83, 84, 85, 86], "__torch_dispatch__": [60, 76], "detach": [60, 76, 78], "clone": [60, 73, 78], "copy_": [60, 78], "_to_copi": [60, 78], "mytensor": [60, 64], "c": [60, 76, 81, 85, 86], "d": [60, 64, 73, 84], "f": [60, 66, 67, 69, 71, 72, 73, 74, 76, 78, 83, 84], "h": [60, 73], "self": [60, 62, 68, 69, 72, 74, 76, 78, 81, 83, 84, 85], "get_layout": 60, "15": [60, 62, 71, 73], "part": [60, 67, 70, 76, 77, 84], "develop": [60, 64, 81, 83, 84, 87], "stack": [60, 66, 73], "about": [60, 62, 64, 66, 67, 68, 69, 72, 73, 83, 84, 85, 87, 92], "dev": [60, 77], "check": [60, 62, 64, 66, 68, 69, 72, 73, 76, 81, 82, 84, 87], "doc": [60, 64, 66, 71, 73, 76, 77, 81], "ao": [60, 67, 78], "main": [60, 66, 67, 69, 73, 74, 76, 77, 83, 87, 92], "quantization_overview": 60, "html": 60, "contributor_guid": 60, "get_tensor_impl_constructor": 60, "layout_class": 60, "tensorimpl": 60, "tensorimplclass": 60, "from_plain": 60, "tensor_class": 60, "mean": [60, 66, 67, 68, 71, 83, 84, 87], "impl": 60, "aten_op": 60, "decor": [60, 76, 78], "callback": 60, "_": [60, 64, 66, 69, 71, 74, 78, 82, 83, 84, 85, 92], "func": [60, 64, 66, 76, 78], "implements_torch_funct": 60, "torch_fn": 60, "register_layout": 60, "registr": 60, "aqt": 60, "py": [60, 62, 64, 85, 86, 89, 90], "tabl": [60, 66, 67, 71, 79], "comprehens": [61, 62, 69, 78, 85], "document": [61, 65, 68, 76, 78, 82, 83, 85, 91, 92], "tutori": [62, 64, 66, 67, 68, 69, 71, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 92], "framework": [62, 64, 68, 71, 73, 82], "architectur": [62, 67, 70, 73, 82, 83, 85, 86], "micro": 62, "sparsity_": 62, "string_to_config": 62, "microbenchmark": 62, "code": [62, 64, 66, 67, 69, 71, 73, 74, 76, 83, 84, 85, 86, 87, 88, 90], "my_new_quant": 62, "process": [62, 66, 67, 68, 82, 86, 90, 92], "mynewquantizationconfig": 62, "my_new_spars": 62, "mynewsparsityconfig": 62, "throughout": 62, "append": [62, 67, 83, 84], "gemliteuintxweightonlyconfig": 62, "gemlitewo": 62, "bit_width": 62, "model_architectur": 62, "your": [62, 64, 66, 67, 68, 69, 70, 71, 73, 77, 79, 83, 84, 85, 86, 87, 92], "mycustommodel": 62, "input_dim": [62, 69], "output_dim": [62, 69], "super": [62, 68, 69, 72, 74, 76, 81, 83, 84, 85], "layer1": 62, "512": [62, 71], "relu": [62, 81, 82, 87], "layer2": 62, "updat": [62, 67, 69, 72, 79, 83, 84, 87], "create_model_and_input_data": 62, "handl": [62, 64], "model_typ": [62, 68, 78, 82], "n": [62, 64, 68, 72, 74, 76, 83, 84, 87], "high_precision_dtyp": 62, "my_custom_model": 62, "input_data": 62, "ensur": [62, 73, 84], "convent": 62, "batch": [62, 73, 74, 84, 92], "sequenc": 62, "length": 62, "featur": [62, 68, 76, 82, 85, 86, 91], "typic": [62, 66, 68, 72, 74, 78, 81, 87, 92], "come": [62, 63, 66, 67, 71, 73, 74, 75, 77, 84, 85, 86, 92], "soon": [62, 63, 73, 75, 84, 92], "file": [62, 64, 69, 71, 73, 76, 78, 83, 84, 89], "microbenchmark_quantization_config": 62, "yml": 62, "benchmark_mod": 62, "quantization_config_recipe_nam": 62, "int8wo": [62, 77], "int8dq": 62, "float8dq": [62, 73], "float8wo": 62, "output_dir": [62, 77], "result": [62, 66, 67, 68, 69, 74, 77, 83, 84, 85, 86, 87], "model_param": 62, "small_bf16_linear": 62, "matrix_shap": 62, "small_sweep": 62, "min_pow": 62, "max_pow": 62, "torch_compile_mod": 62, "max": [62, 64, 66, 69, 74, 76, 83, 84, 87], "autotun": [62, 64, 69, 74], "runner": 62, "oss": 62, "databas": 62, "ci_microbenchmark_runn": 62, "benchmark_result": 62, "json": [62, 73, 78], "extra_info": 62, "arch": 62, "a100": [62, 68, 77, 91], "sxm4": 62, "80gb": 62, "speedup": [62, 64, 66, 67, 68, 71, 73], "wrt": 62, "benchmark_valu": 62, "25": 62, "target_valu": 62, "depend": [62, 67, 72, 76, 79, 83, 84, 86], "github": [62, 69, 73, 77, 92], "action": [62, 78, 83, 84], "upload": 62, "verifi": [62, 69, 72, 76], "setup": [62, 73], "suit": [62, 64, 83, 85], "unittest": 62, "discov": 62, "memori": [62, 64, 66, 67, 68, 71, 76, 77, 79, 85, 86, 92], "miss": [62, 67], "properli": [62, 72], "instal": [62, 64, 66, 71, 73, 77, 83, 86], "Not": [62, 67], "driver": 62, "basic": [62, 64, 74, 76], "analysi": [62, 67], "profil": [62, 64], "overhead": [62, 67, 69, 77, 78, 85], "possibl": [62, 66, 67, 83, 84, 85, 87], "reproduc": [62, 73], "compon": [62, 66, 76, 78], "directori": [62, 71], "instruct": [63, 66, 68, 73, 83, 84, 85, 92], "fequent": 63, "answer": [63, 67], "creat": [63, 64, 67, 69, 71, 76, 77, 82, 83, 85, 86, 87], "read": [64, 76, 92], "overview": [64, 65, 69, 78, 91], "page": [64, 69, 85, 91], "contribut": [64, 67, 69], "api": [64, 65, 66, 67, 69, 74, 76, 81, 82, 83, 84, 85, 86], "trainabl": [64, 66, 68, 76], "parallel": [64, 71, 76, 78], "primit": [64, 76, 83], "slight": [64, 67], "variat": [64, 66], "quant_primit": [64, 74], "mp": 64, "csrc": 64, "concept": [64, 66, 83, 85, 86, 87, 90], "alreadi": [64, 76, 87], "could": [64, 66, 76, 82, 83, 85, 86, 87], "context": [64, 85, 86], "write": [64, 70, 81, 82, 83, 84], "own": [64, 67, 68, 70, 71, 74, 81, 83, 84, 87], "torchaobasetensor": [64, 78], "help": [64, 66, 68, 71, 73, 78, 82, 83], "qdata": [64, 66], "With": [64, 76, 83, 85, 87], "ll": [64, 66, 71, 76, 83, 84, 87], "mani": [64, 66, 67, 76], "still": [64, 66, 67, 68, 69, 83, 87, 92], "awai": 64, "abstract": [64, 66], "easier": [64, 87], "peopl": [64, 66, 72, 78, 87], "well": [64, 66, 67, 81, 83, 84, 87], "my_custom_op": 64, "my_mm_for_mp": 64, "input_tensor": [64, 66, 78], "weight_tensor": [64, 66, 78], "group_mm": 64, "whatev": 64, "think": [64, 78], "fastest": 64, "condit": 64, "so": [64, 66, 67, 68, 69, 71, 72, 76, 77, 83, 84, 87], "worri": 64, "purpos": [64, 66, 71, 76, 83, 92], "h100": [64, 66, 77, 91, 92], "sm89": 64, "sm90": 64, "_choose_scale_float8": [64, 66], "_quantize_affine_float8": [64, 66], "_scaled_mm": [64, 66], "kerenel": 64, "f8f8bf16_rowwis": [64, 66], "reus": [64, 76], "quant": [64, 66, 73, 78, 83, 86, 87], "aim": [64, 67, 86], "fullgraph": [64, 69], "unnecessari": 64, "graph": [64, 81, 83, 84, 87], "break": 64, "torch_log": 64, "output_cod": 64, "script": [64, 69, 73, 74, 76, 84, 85, 86, 90], "inductor": [64, 81, 82, 83], "relev": [64, 66, 90], "safe": 64, "global": [64, 67, 76], "add_safe_glob": 64, "quantizetensortofloat8kwarg": [64, 66], "checkout": [64, 66, 79], "integr": [64, 67, 70, 71, 72, 73, 76, 85, 87], "huggingfac": [64, 77], "deseri": [64, 83, 84], "save_pretrain": [64, 73, 77], "push_to_hub": [64, 73, 77, 78], "from_pretrain": [64, 68, 73, 77, 78, 92], "diffus": [64, 73], "talk": [64, 66, 73], "fsdp": [64, 66], "mydtypetensor": 64, "developer_api_guid": 64, "folder": [64, 73, 83, 84, 91], "cover": [64, 83, 86, 87, 90], "torchchat": 64, "dtensor": [64, 76], "past": [64, 67], "adapt": [64, 71, 74], "intens": 64, "sens": [64, 66, 76], "benchmark_aq": 64, "quick": 64, "interest": [64, 67, 76], "print_op_and_shap": 64, "torch_func": 64, "built": [64, 71, 76], "_c": 64, "tensorbas": 64, "benchmark_your_kernel": 64, "feel": [64, 66, 67, 76, 78], "free": [64, 66, 76], "probabl": 64, "futur": [64, 74, 77, 78, 83, 84, 85, 87], "llama": [64, 68, 73, 77, 78, 79, 82, 92], "llama2": 64, "llama3": [64, 68, 71, 77, 92], "sam": 64, "friendli": 64, "techniqu": [64, 67, 68, 71, 72, 73, 74, 76, 78, 91], "profile_path": 64, "chrome": 64, "trace": 64, "let": [64, 66, 67, 69, 74, 76, 87], "u": [64, 67, 82], "know": [64, 76], "technic": 65, "contributor": [65, 66, 69], "guid": [65, 66, 69, 70, 73, 82], "benchmark": [65, 69, 71, 77, 81, 82, 85, 86], "lai": 66, "awq": [66, 91], "gptq": 66, "int4tensor": 66, "int4preshuffledtensor": 66, "uint1": 66, "uint7": 66, "float3": 66, "overload": [66, 67], "term": [66, 67, 83, 87], "extra": [66, 73], "No": [66, 67, 68, 72], "what": [66, 67, 68, 71, 73, 74, 78, 83, 87, 90], "end": [66, 67, 68, 71, 73, 76, 77, 78, 84, 87], "float8_e4m3fnuz": 66, "float8_e5m2fnuz": 66, "float8_e8m0fnu": 66, "placehold": [66, 86], "real": [66, 68, 81, 83, 87], "pr": 66, "shell": 66, "limit": [66, 68, 71, 76, 78, 83], "offici": [66, 71], "dervi": 66, "mxfp8": [66, 91], "mxfp4": [66, 68, 91], "preicison": 66, "choose_qparam": 66, "zero_point": [66, 67, 74, 76, 87], "mention": [66, 83], "accommod": 66, "choose_qparams_affine_with_min_max": 66, "min": [66, 74, 76, 83, 87], "raw": 66, "quantize_fp8_row": 66, "int_matmul": 66, "int_scaled_matmul": 66, "reli": [66, 67, 74, 76, 81], "handwritten": 66, "On": 66, "top": [66, 71, 76, 82, 83, 84, 85, 86], "glue": 66, "everyth": 66, "togeth": [66, 73, 83, 85, 87], "build": [66, 67, 71, 76, 78, 79, 83], "anoth": [66, 67, 76, 83, 87], "side": 66, "uint8": [66, 74, 87], "swizzl": 66, "dtpype": 66, "float8rowwisetensor": 66, "float8blockwisetensor": 66, "confus": [66, 67, 83], "close": [66, 67], "low_precision_v": 66, "high_precision_v": 66, "procedur": 66, "especi": [66, 67, 72, 85, 86], "bitwidth": [66, 87], "codebook": 66, "look": [66, 67, 71, 82, 83, 84, 85, 86], "index": [66, 67, 73, 79, 86], "vector": [66, 67, 85], "kmean": 66, "cluster": [66, 71], "tradition": 66, "demonstr": [66, 68, 69, 71, 73, 76, 82, 84], "sai": [66, 77, 78, 87], "below": [66, 67, 71, 76, 77, 78, 82, 90], "explain": [66, 82, 85], "introduct": [66, 73, 79], "simplest": [66, 67], "form": [66, 67, 71], "easi": [66, 73], "linear_modul": 66, "requires_grad": [66, 68, 74, 76, 78], "runtim": [66, 69, 83], "question": [66, 67, 72, 76, 87], "activation_granular": 66, "act_quant_kwarg": 66, "quantized_weight": [66, 78], "float8_dtyp": 66, "haven": 66, "seen": 66, "pt2": [66, 76, 85], "fit": [66, 68, 72, 92], "autoround": 66, "multitensor": 66, "sure": [66, 73, 87], "open": [66, 67], "describ": [66, 67, 72, 83, 84, 90], "advis": 66, "focus": [66, 67, 68, 71, 73], "face": [66, 67, 70, 73, 83], "finetun": [66, 73], "quantized_train": 66, "extend": [66, 67, 85], "progress": [66, 77, 78], "lot": [66, 67], "connect": [66, 87], "walk": [66, 74, 76, 82, 85, 90], "float8dynamicactivationfloat8weightconfig": [66, 77], "happen": [66, 76, 83, 85], "len": [66, 73, 78, 83, 84, 87], "_choose_quant_func_and_quantize_tensor": 66, "omit": [66, 71, 83, 84, 85], "relat": [66, 67], "xq": 66, "reshap": [66, 83, 84], "wq": 66, "x_scale": [66, 83], "w_scale": 66, "out_shap": 66, "neural": [67, 82, 85], "network": [67, 76, 82, 85], "its": [67, 68, 76, 78, 83, 87], "latenc": 67, "By": 67, "carefulli": 67, "achiev": [67, 68, 69, 71, 74, 76, 84, 85], "signific": [67, 73], "pai": 67, "reason": [67, 72, 92], "low": [67, 76, 77, 82], "price": 67, "qualiti": [67, 68, 77], "accuraci": [67, 68, 69, 71, 73, 74, 79, 82, 84, 85, 91, 92], "f1": 67, "problem": [67, 76], "research": [67, 90, 92], "fragment": 67, "rightfulli": 67, "show": [67, 71, 73, 78, 81, 83, 84], "time": [67, 69, 76, 77, 82, 83, 84, 90], "spent": 67, "figur": [67, 83], "place": [67, 82, 83, 84, 85, 86], "dens": [67, 91], "solv": [67, 73, 76], "onc": [67, 68, 92], "focu": [67, 76], "realli": 67, "push": [67, 73, 77, 78], "accur": [67, 71, 82], "concret": [67, 87], "hope": 67, "modular": 67, "acceler": [67, 73, 77], "nice": 67, "scratch": [67, 90], "minim": [67, 82, 85, 86], "loss": [67, 68, 71, 83, 84, 92], "recov": [67, 68, 79, 84, 92], "algorthim": 67, "realiz": 67, "improv": [67, 68, 71, 73, 83, 86, 87, 91], "trade": [67, 73], "off": [67, 73], "theoret": 67, "gain": [67, 73, 86], "float16": [67, 91], "yield": [67, 68], "2x": [67, 69, 73], "analog": 67, "would": [67, 69, 76, 84, 86], "fix": [67, 74], "50": [67, 71, 74, 82, 83, 85, 86], "expect": [67, 71, 76, 82, 83, 85, 86, 87], "matric": [67, 68], "unstructur": 67, "share": 67, "mitig": [67, 68], "retrain": 67, "neglig": 67, "even": [67, 68, 71, 87], "area": 67, "agre": 67, "upon": 67, "consensu": 67, "mind": 67, "thought": 67, "subproblem": 67, "find": [67, 68, 83, 87], "my": [67, 84], "independ": 67, "frontend": [67, 85], "arbitrari": 67, "collect": [67, 71], "handoff": 67, "piec": 67, "natur": [67, 76, 83, 87], "becaus": [67, 68, 69, 71, 72, 76, 84, 87], "clear": 67, "contract": 67, "7x": 67, "advantag": 67, "anticip": 67, "solut": 67, "third": 67, "parti": 67, "to_sparse_semi_structur": 67, "sparsesemistructuredtensor": 67, "weightnormsparsifi": 67, "half": 67, "subnetwork": 67, "sparse_config": 67, "named_modul": 67, "tensor_fqn": 67, "sparse_block_shap": 67, "zeros_per_block": 67, "fakespars": 67, "fundament": [67, 84], "manipul": 67, "paramer": 67, "parameter": 67, "necessari": [67, 74, 76, 82, 83, 84, 85, 86], "ve": [67, 73], "suitabl": [67, 85], "spot": 67, "definit": [67, 78], "academia": 67, "industri": 67, "often": [67, 76], "interchang": 67, "thing": [67, 72, 76, 83], "distinct": 67, "being": [67, 71, 78, 85, 86], "pretrain": [67, 73, 82, 83, 84, 85], "avoid": [67, 72], "try": [67, 68, 76, 83], "roughli": 67, "idea": 67, "behind": 67, "doesn": [67, 84, 87], "box": [67, 71, 85], "itself": [67, 76], "those": [67, 73, 74, 76], "multipli": 67, "loos": 67, "speak": 67, "tightli": 67, "coupl": [67, 76], "csc": 67, "fbgemm": 67, "qnnpack": 67, "descript": [67, 82], "coo": 67, "sparse_coo": 67, "coordin": 67, "locat": 67, "bsr": 67, "sparse_bsr": 67, "veri": [67, 78, 84], "similar": [67, 68, 74, 84, 85], "except": [67, 76, 87], "individu": 67, "scalar": [67, 83], "dimension": 67, "csr": 67, "sparse_csr": 67, "sparse_csc": 67, "column": 67, "indic": [67, 87], "compact": 67, "sparse_matrix": 67, "1d": 67, "indexptr": 67, "storag": 67, "\u00bd": 67, "bitmask": 67, "2bit": 67, "unprun": 67, "quit": [67, 76], "simpl": [67, 69, 74, 76, 82, 85, 86], "successfulli": [67, 68], "These": [67, 68, 76, 82, 83, 84, 87], "broken": 67, "down": 67, "equal": [67, 72], "sensit": 67, "effect": [67, 74, 76, 85, 86, 87], "best": [67, 69, 85], "subsequ": [67, 76, 85, 86], "infinit": 67, "lost": 67, "degre": 67, "drop": 67, "give": [67, 73, 76], "curv": [67, 71], "proxi": 67, "much": [67, 68, 87], "aforement": 67, "factor": [67, 71], "less": [67, 76, 79, 83], "smallest": 67, "absolut": 67, "consid": 67, "v": [67, 71, 83, 87], "scope": 67, "impli": 67, "respect": [67, 84], "pro": [67, 73, 92], "con": 67, "potenti": [67, 74, 82, 83, 85, 86], "sub": 67, "tradeoff": [67, 68, 77], "span": 67, "over": [67, 71, 83, 84], "threshold": 67, "normal": [67, 83, 84], "increas": [67, 68, 83], "complex": 67, "constant": [67, 76, 83], "gradient": [67, 79, 92], "pre": [67, 68, 70, 73, 79, 87], "ctr_mobile_fe": 67, "paper": [67, 68, 90], "score": 67, "w": [67, 78], "tenosr": 67, "udpat": 67, "cannot": [67, 74, 78], "histori": 67, "regrow": 67, "dw": 67, "via": [67, 82], "backprop": 67, "pat": 67, "unmask": 67, "resid": 67, "salienc": 67, "lowest": 67, "l1": 67, "shown": [67, 68, 73, 84, 87, 92], "abl": [67, 76, 78, 83, 87], "repeat": [67, 83, 84], "loop": [67, 68, 71, 92], "shot": [67, 68], "movement": 67, "tune": [67, 70, 71, 73, 82, 92], "2005": 67, "07683": 67, "rank": [67, 76], "wx": 67, "sqx": 67, "q": [67, 83], "usual": 67, "sort": 67, "wise": 67, "reconstruct": [67, 78], "seek": [67, 72], "random": [67, 73, 83, 84], "randomli": 67, "tri": 67, "remedi": 67, "line": [67, 71, 77], "sometim": 67, "item": [67, 90], "ultim": [67, 74], "complic": [67, 83], "literatur": 67, "rang": [67, 68, 69, 71, 74, 83, 84, 92], "vision": 67, "nlp": [67, 85, 90], "simpli": [67, 68, 74, 76], "again": [67, 83, 87], "iter": [67, 83, 84], "ctr_feed": 67, "na": 67, "multimask": 67, "search": 67, "pyspeech": 67, "fastna": 67, "approach": [67, 76, 82, 85, 86], "knowledg": [67, 90], "distil": 67, "pdf": 67, "2204": 67, "09656": 67, "arrang": 67, "recal": 67, "faster": [67, 69, 79, 92], "counterpart": 67, "slower": 67, "suffici": 67, "At": [67, 83], "98": 67, "exhibit": [67, 92], "penalti": 67, "expens": [67, 76], "dictat": 67, "characterist": 67, "highest": 67, "wouldn": [67, 76], "visual": 67, "fig": 67, "4x4": 67, "benchmak": 67, "serv": [68, 69, 70, 71, 76, 77, 86], "leverag": [68, 71, 73, 76, 85, 86, 92], "partner": [68, 71, 73], "showcas": [68, 71, 73], "blog": [68, 92], "resourc": [68, 76], "introduc": [68, 82, 83, 85, 86, 87], "small": [68, 69], "freez": [68, 84, 85, 86], "inevit": 68, "presum": 68, "recent": [68, 79], "releas": [68, 85], "1b": [68, 77, 78], "3b": [68, 92], "llamaguard": 68, "8b": [68, 69, 71, 77, 79, 92], "distribut": [68, 71, 74, 76, 78, 82, 92], "command": [68, 71, 92], "regular": [68, 82, 85, 86], "nnode": [68, 92], "nproc_per_nod": [68, 92], "full_finetune_distribut": 68, "llama3_2": 68, "3b_full": 68, "batch_siz": [68, 69, 72, 73, 74, 83, 84], "_component_": 68, "qat_distribut": [68, 92], "3b_qat_ful": 68, "evalu": [68, 69, 84], "wa": [68, 76, 84, 92], "llama3_2_3b": 68, "fullmodelhfcheckpoint": 68, "checkpoint_fil": 68, "00001": 68, "00002": 68, "safetensor": [68, 77], "int8dynactint4weightquant": 68, "hellaswag": [68, 73], "wikitext": [68, 92], "eleuther_ev": 68, "eleuther_evalu": 68, "task": [68, 73, 92], "fullmodeltorchtunecheckpoint": 68, "8da4w": [68, 73], "ckpt": 68, "llama3_token": 68, "tmp": 68, "meta": [68, 72, 77, 78, 87], "stderr": 68, "acc": [68, 83, 84], "5021": 68, "0050": 68, "acc_norm": 68, "6797": 68, "0047": 68, "bits_per_byt": 68, "6965": 68, "byte_perplex": 68, "6206": 68, "word_perplex": 68, "13": [68, 92], "2199": 68, "openassist": 68, "oasst1": 68, "dataset": [68, 71, 73, 82, 85, 86, 92], "higher": [68, 71, 76, 77, 82, 83, 85, 86, 92], "69": [68, 74], "overal": [68, 69, 79, 83, 87], "vanilla": [68, 92], "lora": [68, 92], "89x": [68, 79, 92], "36": [68, 71, 73, 92], "qat_lora_finetune_distribut": [68, 92], "3b_qat_lora": 68, "fsdp2": [68, 71, 92], "yaml": [68, 92], "complet": [68, 73, 82, 86, 92], "qat_out": [68, 92], "quatiz": [68, 92], "hood": 68, "mini": [68, 73], "gpu": [68, 69, 71, 77, 78, 82, 90, 91, 92], "accordingli": 68, "get_model": [68, 92], "vocab_s": [68, 92], "4096": [68, 71, 92], "num_lay": [68, 92], "num_head": [68, 92], "num_kv_head": [68, 92], "embed_dim": [68, 92], "2048": [68, 71, 92], "max_seq_len": [68, 92], "sgd": [68, 92], "lr": [68, 71, 92], "001": [68, 92], "momentum": [68, 84, 92], "9": [68, 71, 79, 92], "weight_decai": [68, 92], "1e": [68, 71, 92], "loss_fn": [68, 92], "crossentropyloss": [68, 83, 84, 92], "randint": [68, 92], "zero_grad": [68, 71, 84, 92], "next": [68, 71, 74, 83, 84, 85, 86], "attun": 68, "benefici": 68, "readi": [68, 69, 71, 73, 74, 76, 84], "legaci": [68, 92], "offer": [68, 69, 76, 83], "unlik": [68, 74], "int8dynactint4weightqatquant": [68, 92], "qat_quant": [68, 92], "insert": [68, 69, 74, 81, 82, 83, 84, 85, 86, 87, 92], "int8dynactint4weightqatlinear": [68, 92], "int8dynactint4weightlinear": [68, 92], "fraction": 68, "therebi": [68, 92], "significantli": [68, 69, 82, 83, 85, 86], "footprint": 68, "extens": [68, 76, 83, 85], "addition": [68, 85, 86, 92], "frozen": 68, "further": [68, 76, 82, 83, 84, 85], "nf4": 68, "express": [68, 76, 81, 82, 83, 84, 87], "nf4tensor": 68, "cleanli": 68, "to_nf4": 68, "frozennf4linear": 68, "in_dim": 68, "out_dim": 68, "quantization_kwarg": 68, "requires_grad_": 68, "nf4_weight": 68, "though": [68, 76], "competit": [68, 71], "baselin": [68, 71, 73, 83, 92], "reap": 68, "incorpor": 68, "loralinear": 68, "lora_finetune_single_devic": 68, "3b_qlora_single_devic": 68, "invok": [68, 85], "loraconfig": 68, "get_peft_model": [68, 92], "automodelforcausallm": [68, 73, 77, 78], "torchaoconfig": [68, 73, 77, 78], "base_model": 68, "quantization_config": [68, 73, 77, 78, 86], "peft_config": 68, "throughput": [68, 69, 71, 73], "torchtitan": 68, "enable_fp8_train": 68, "fp8_recipe_nam": 68, "experi": [68, 71, 86, 92], "saw": 68, "experiment_nam": 68, "tok": 68, "peak_mem_reserv": 68, "6502": 68, "143": 68, "000": 68, "30": [68, 71, 83], "090": 68, "fp8_nonam": 68, "7205": 68, "386": 68, "816": 68, "010": 68, "266": 68, "fp8_tensorwis": 68, "7222": [68, 92], "198": 68, "11": [68, 71], "074": [68, 71], "fp8_rowwis": 68, "6387": 68, "968": 68, "756": 68, "29": [68, 71], "158": 68, "096": 68, "fp8_rowwise_with_gw_hp": 68, "7573": 68, "698": 68, "480": 68, "516": 68, "908": 68, "hellaswag_acc": 68, "wikitext_word_perplex": 68, "533": 68, "12": [68, 71, 79, 86, 87, 92], "407": [68, 71], "414": 68, "007": 68, "412": 68, "005": 68, "420": [68, 92], "013": [68, 71], "534": 68, "416": 68, "009": 68, "entri": 69, "mutat": 69, "toylinearmodel": [69, 72, 74], "hidden_dim": 69, "has_bia": 69, "linear2": [69, 72, 74, 76], "eval": [69, 72, 73, 74, 81, 82, 84, 85, 86, 92], "model_w16a16": 69, "model_w8a8": 69, "chapter": 69, "remain": [69, 85, 86], "unchang": 69, "__name__": 69, "approxim": 69, "disk": 69, "o": [69, 83, 84], "state_dict": [69, 71, 72, 83, 84], "pth": [69, 71, 83, 84], "original_s": 69, "getsiz": [69, 83, 84], "quantized_s": 69, "2f": [69, 83, 84], "mb": [69, 72, 83, 84, 89], "00x": 69, "00mb": 69, "warmup": [69, 71], "synchron": 69, "100": [69, 76, 83, 84], "original_tim": 69, "quantized_tim": 69, "03x": 69, "larger": 69, "enough": 69, "toi": [69, 71, 74, 76, 85], "address": [69, 83], "vllm": [69, 70, 77], "lm": [69, 73], "visit": 69, "forget": 69, "good": [69, 76, 87], "qlora": [70, 73], "sglang": [70, 77], "hug": [70, 73], "advanc": [70, 74, 76, 82, 85, 86], "5x": [71, 79], "34": 71, "43x": 71, "2k": 71, "h200": 71, "latest": [71, 79], "offic": 71, "sever": [71, 78, 82, 87], "popular": 71, "flagship": 71, "quickli": [71, 76], "batteri": 71, "fork": 71, "virtual": 71, "environ": [71, 73], "conda": 71, "venv": 71, "download": [71, 73, 79, 83, 84, 86, 88, 90], "job": 71, "root": [71, 73], "launch": 71, "ngpu": 71, "config_fil": 71, "train_config": 71, "llama3_8b": 71, "toml": 71, "run_train": 71, "sh": [71, 73], "hyperparamet": 71, "edit": [71, 73], "flag": [71, 79, 84], "termin": 71, "rank0": 71, "titan": 71, "2025": 71, "06": 71, "04": 71, "08": 71, "51": 71, "48": 71, "info": 71, "2254": 71, "27": 71, "34gib": 71, "28": 71, "78": 71, "tp": [71, 78], "375": 71, "tflop": 71, "21": 71, "73": [71, 74], "mfu": 71, "20": [71, 73, 84], "58": [71, 79], "557": 71, "7069": 71, "99gib": 71, "62": 71, "7": [71, 73, 85, 86, 91], "034": 71, "35": [71, 73, 74], "41": [71, 73], "19": 71, "52": 71, "224": [71, 74, 82, 83, 84, 85, 86], "9196": 71, "022": 71, "406": [71, 83, 84], "65": 71, "904": 71, "1423": 71, "014": 71, "23": [71, 74], "As": [71, 83, 87], "7k": 71, "99gb": 71, "peak": [71, 73, 77], "against": 71, "02": 71, "37": 71, "404": 71, "2611": 71, "22gib": 71, "595": 71, "47": 71, "49": [71, 74], "027": 71, "4260": 71, "89gib": 71, "344": 71, "367": 71, "39": [71, 92], "03": 71, "01": 71, "988": 71, "9482": 71, "321": 71, "366": 71, "14": 71, "991": 71, "1183": 71, "300": 71, "364": 71, "89": 71, "40": [71, 92], "4659": 71, "291": 71, "84": 71, "769": 71, "gc": 71, "peform": 71, "period": 71, "3k": 71, "89gb": 71, "11x": 71, "nearli": 71, "performan": 71, "648": 71, "2648": 71, "28gib": 71, "71": 71, "26": [71, 92], "475": 71, "9106": 71, "91gib": 71, "53": [71, 73], "503": 71, "434": 71, "43": 71, "94": [71, 83], "166": 71, "0774": 71, "663": 71, "443": 71, "44": [71, 74], "87": 71, "885": 71, "3233": 71, "643": 71, "442": 71, "66": [71, 73, 74, 92], "76": 71, "613": 71, "6150": 71, "637": 71, "72": [71, 73], "6k": 71, "91gb": 71, "21x": [71, 73], "tl": 71, "dr": 71, "priorit": 71, "stabil": 71, "cost": [71, 74], "slightli": [71, 76], "impact": [71, 73, 78], "outlier": 71, "caus": 71, "underflow": 71, "8xh100": 71, "convert_to_float8_train": 71, "recurs": 71, "kind": [71, 83], "snippet": [71, 83, 84], "float8_linear_util": 71, "float8_linear": 71, "sampl": [71, 83, 85, 86], "adamw": 71, "elig": 71, "last": [71, 82], "divis": 71, "label": 71, "fake_label": 71, "ones_lik": 71, "mse_loss": 71, "model_state_dict": 71, "optimizer_state_dict": 71, "explor": [71, 86], "few": [71, 76, 83, 84, 92], "tempfil": [72, 77], "get_model_size_in_byt": 72, "ref": [72, 83], "namedtemporaryfil": 72, "m_load": 72, "load_state_dict": [72, 83, 84], "assign": 72, "assert": [72, 74, 76, 78, 87], "float_weight1": 72, "float_weight2": 72, "quantized_weight1": 72, "quantized_weight2": 72, "go": [72, 76, 87], "techinqu": 72, "4x": [72, 73], "0625": 72, "affine_quantized_tensor": 72, "deploi": 73, "engin": 73, "seamlessli": [73, 76, 85, 86], "seamless": [73, 85], "hf": [73, 77], "pip": [73, 77, 79, 82, 83], "url": [73, 79, 86], "whl": [73, 79, 86], "nightli": [73, 79], "cu128": [73, 79], "hub": [73, 77, 78], "server": [73, 78], "phi": 73, "fp8": 73, "microsoft": 73, "o3": 73, "client": 73, "curl": 73, "localhost": 73, "8000": 73, "v1": 73, "chat": 73, "content": 73, "messag": 73, "role": 73, "me": 73, "short": 73, "larg": [73, 76, 85], "temperatur": 73, "top_p": 73, "95": 73, "top_k": 73, "max_token": 73, "32768": 73, "vram": 73, "15x": 73, "littl": [73, 78], "packag": [73, 77], "git": [73, 77], "com": [73, 77, 92], "autotoken": [73, 77], "pipelin": 73, "manual_se": [73, 83, 84], "model_path": 73, "device_map": [73, 77, 78], "trust_remote_cod": 73, "ai": 73, "assist": 73, "eat": 73, "banana": 73, "dragonfruit": 73, "smoothi": 73, "blend": 73, "milk": 73, "honei": 73, "salad": 73, "mix": [73, 82, 85, 86], "slice": [73, 78], "lemon": 73, "juic": 73, "equat": 73, "pipe": [73, 77], "text": 73, "generation_arg": 73, "max_new_token": 73, "500": 73, "return_full_text": 73, "do_sampl": 73, "generated_text": 73, "design": [73, 78, 82, 83, 87], "lm_head": 73, "ti": 73, "autoprocessor": 73, "modeling_util": 73, "find_tied_paramet": 73, "model_id": [73, 77], "untied_model": 73, "getattr": [73, 78], "get_text_config": 73, "tie_word_embed": 73, "setattr": [73, 76], "_tied_weights_kei": 73, "user_id": 73, "your_user_id": 73, "model_nam": [73, 82, 85, 86], "save_to": [73, 77], "save_to_local_path": 73, "int8dynamicactivationintxweightconfig": [73, 77], "intxweightonlyconfig": [73, 77], "fqntoconfig": [73, 78], "untied_model_id": 73, "untied_model_local_path": 73, "embedding_config": 73, "quant_config": 73, "embed_token": 73, "quant_typ": [73, 77, 78], "include_embed": 73, "untie_embedding_weight": 73, "modules_to_not_convert": 73, "quantized_model": [73, 76, 77, 82, 83, 84], "safe_seri": [73, 77, 78], "pte": 73, "cd": 73, "install_requir": 73, "phi_4_mini": 73, "convert_weight": 73, "pytorch_model": 73, "bin": 73, "pytorch_model_convert": 73, "export_llama": 73, "kv": 73, "use_sdpa_with_kv_cach": 73, "get_bos_id": 73, "199999": 73, "get_eos_id": 73, "200020": 73, "max_seq_length": 73, "max_context_length": 73, "output_nam": 73, "phi4": 73, "phone": 73, "io": 73, "2gb": 73, "iphon": 73, "17": [73, 92], "sec": 73, "test": [73, 77, 83, 85, 90], "har": 73, "eleutherai": 73, "lm_eval": 73, "model_arg": 73, "reset_peak_memory_stat": 73, "prompt": [73, 77], "hei": 73, "consciou": 73, "templated_prompt": 73, "apply_chat_templ": 73, "add_generation_prompt": 73, "templat": [73, 88, 89], "return_tensor": 73, "pt": 73, "generated_id": 73, "output_text": 73, "batch_decod": 73, "skip_special_token": 73, "clean_up_tokenization_spac": 73, "respons": 73, "mem": 73, "max_memory_reserv": 73, "1e9": 73, "02f": 73, "gb": 73, "hello": [73, 77], "ye": 73, "am": 73, "digit": 73, "todai": 73, "70": [73, 74], "bench": 73, "vllm_disable_compile_cach": 73, "project": 73, "vllm_use_precompil": 73, "sharegpt": 73, "wget": 73, "co": 73, "anon8231489123": 73, "sharegpt_vicuna_unfilt": 73, "resolv": 73, "sharegpt_v3_unfiltered_cleaned_split": 73, "tree": 73, "num": 73, "benchmark_serv": 73, "16x": 73, "14x": 73, "num_prompt": 73, "req": 73, "57": [73, 74], "1000": [73, 85], "68": 73, "80": 73, "entir": [73, 83, 84], "ml": 73, "eas": 73, "accept": [73, 87, 92], "fly": [74, 77], "affinequantizedminmaxobserv": 74, "record": 74, "welcom": 74, "desir": 74, "averag": [74, 83, 84], "histogram": [74, 83], "act_ob": 74, "finfo": 74, "zero_point_dtyp": 74, "weight_ob": 74, "observedlinear": 74, "observed_input": 74, "observed_weight": 74, "from_float": [74, 76], "float_linear": 74, "observed_linear": 74, "_replace_with_custom_fn_if_matches_filt": 74, "insert_observers_": 74, "lambda": [74, 78, 92], "replacement_fn": 74, "copied_act_ob": 74, "copied_weight_ob": 74, "popul": 74, "feed": 74, "simpler": [74, 83], "quantizedlinear": [74, 76], "isn": 74, "strictli": 74, "to_affine_quantized_intx_stat": 74, "act_scal": [74, 87], "act_zero_point": 74, "calculate_qparam": [74, 87], "weight_scal": [74, 83, 87], "weight_zero_point": [74, 83], "qweight": 74, "qinput": 74, "from_observ": 74, "quantized_linear": [74, 83], "begin": [74, 76], "dataclass": [74, 78, 87], "transform_modul": [74, 78], "register_quantize_module_handl": [74, 78], "staticquantconfig": 74, "_apply_static_qu": 74, "associ": 74, "identifi": [74, 87], "is_observed_linear": 74, "optimizedmodul": 74, "_orig_mod": 74, "0237": 74, "tensor_impl": 74, "plainaqttensorimpl": 74, "142": 74, "31": [74, 87], "113": 74, "157": 74, "59": 74, "160": 74, "150": 74, "67": [74, 79], "241": 74, "238": 74, "235": 74, "228": 74, "255": [74, 87], "201": 74, "114": 74, "236": 74, "88": [74, 83], "83": 74, "109": 74, "209": 74, "92": 74, "184": 74, "141": 74, "110": 74, "0009": 74, "0010": 74, "130": 74, "122": 74, "132": 74, "125": 74, "126": 74, "129": 74, "127": [74, 76, 86, 87], "133": 74, "124": 74, "131": 74, "135": 74, "136": 74, "_layout": 74, "foundat": 76, "autograd": [76, 87], "highlight": [76, 79, 90], "interpos": 76, "namespac": 76, "continu": [76, 77, 84, 85, 86, 87], "obviou": 76, "int8quantizedlinear": 76, "finer": 76, "intercept": 76, "contrast": [76, 92], "long": [76, 83], "clunki": 76, "distributedlinear": 76, "duplic": 76, "bypass": 76, "wrap": [76, 85, 86], "outer": 76, "inner": 76, "allgath": 76, "bandwidth": 76, "stai": 76, "exactli": [76, 92], "zoo": 76, "podcast": 76, "edward": 76, "yang": 76, "int8_symmetric_quant": 76, "fp32_tensor": 76, "quant_min": [76, 86, 87], "quant_max": [76, 86, 87], "min_val": 76, "amin": 76, "keepdim": [76, 83, 84], "max_val": 76, "amax": 76, "min_val_neg": 76, "zeros_lik": 76, "max_val_po": 76, "view": [76, 83, 84], "round": [76, 92], "clamp": [76, 83, 92], "w_int8": 76, "new_linear": 76, "left": [76, 87], "toymodel": 76, "float_model": [76, 81, 82, 83, 84, 85, 86], "child": 76, "named_children": 76, "drawback": 76, "won": 76, "suppos": 76, "clean": [76, 92], "eleg": 76, "pretti": 76, "power": [76, 78], "overrid": 76, "almost": 76, "shard": [76, 78], "ragged": 76, "rag": 76, "nestedtensor": 76, "who": 76, "link": [76, 90, 91], "why": [76, 90], "googl": [76, 92], "collab": 76, "flopcount": 76, "memorytrack": 76, "bare": 76, "bone": 76, "int8symmetrictensor": 76, "hold": [76, 77], "int_data": 76, "staticmethod": 76, "_dynamo": 76, "_make_wrapper_subclass": [76, 78], "stride": 76, "storage_offset": 76, "ndim": 76, "extra_metadata": 76, "outer_s": [76, 78], "outer_strid": [76, 78], "undo": 76, "repr": 76, "float_tensor": 76, "ahead": 76, "insid": 76, "int8_tensor": 76, "op_implementations_dict": 76, "assertionerror": 76, "conveni": 76, "register_op": 76, "_op": 76, "opoverload": 76, "impl_decor": 76, "op_impl": 76, "done": [76, 92], "wrapper": [76, 81, 85], "particular": 76, "largest": 76, "tell": 76, "desugar": 76, "surfac": 76, "coverag": [76, 82, 83, 85, 86], "brute": 76, "forc": 76, "repeatedli": 76, "log": 76, "loggingtensor": 76, "_python_dispatch": [76, 78], "return_and_correct_alias": [76, 78], "int8_mm": 76, "int8_view_op": 76, "out_data": 76, "out_scal": [76, 83], "notic": 76, "hit": 76, "background": 76, "decomposit": 76, "live": 76, "decomp": 76, "shrink": 76, "author": [76, 82, 83, 84, 85, 86, 87, 90], "But": [76, 78, 87], "pain": 76, "rather": 76, "worth": 76, "written": 76, "differenti": 76, "nuanc": 76, "longer": [76, 83, 84], "had": [76, 83], "transpos": 76, "That": 76, "transposit": 76, "got": [76, 83, 87], "propag": [76, 83, 85, 86], "fact": 76, "themselv": [76, 83], "pointwis": [76, 85, 86], "were": 76, "might": [76, 78, 83, 87], "unwrap": 76, "dim0": 76, "dim1": 76, "confirm": 76, "quantized_model_module_swap": 76, "quantized_model_subclass": 76, "subclass_param": 76, "no_grad": [76, 81, 82, 83, 84, 85, 86], "out_module_swap": 76, "allclos": 76, "out_compil": 76, "seri": 76, "discuss": 76, "float8dynamicactivationint4weightconfig": 77, "use_hqq": [77, 78], "torch_dtyp": 77, "fluxpipelin": 77, "fluxtransformer2dmodel": 77, "black": 77, "forest": 77, "lab": 77, "flux": 77, "subfold": 77, "cat": [77, 87], "sign": [77, 86], "world": [77, 78], "imag": [77, 81, 82, 83, 84, 85, 86], "num_inference_step": 77, "guidance_scal": 77, "png": 77, "temporarydirectori": 77, "tmp_dir": 77, "uncom": 77, "usernam": [77, 78], "statu": [77, 78], "becom": [77, 83], "stabl": [77, 79], "int4wo": 77, "team": [77, 78], "track": [77, 78], "retain": 77, "thoroughli": 77, "e2": 78, "_type": 78, "_data": 78, "capabl": [78, 83, 85], "self_attn": 78, "k_proj": [78, 92], "mlp": 78, "gate_proj": [78, 92], "narrow": 78, "host": 78, "state": 78, "chunk": 78, "heavi": 78, "codebas": 78, "fn": 78, "ctx": 78, "new_tensor": 78, "__class__": 78, "principl": 78, "mynewquantconfig": 78, "classvar": 78, "myquantizedtensor": 78, "tensor_data_attr": 78, "quantized_data": 78, "tensor_attribut": 78, "attr": 78, "fill_default": 78, "notimplementederror": 78, "_my_quant_transform": 78, "my_quantization_funct": 78, "use_cutlass_kernel": 78, "my_cutlass_linear": 78, "my_triton_linear": 78, "standard": 78, "disappear": 78, "unless": 78, "extrem": 78, "sole": 78, "explicitli": [78, 87], "spooki": 78, "distanc": 78, "due": [78, 82, 87], "workaround": 78, "2338": 78, "detect": 78, "illustr": 78, "70b": 79, "gemma3": [79, 92], "4b": [79, 92], "cu126": 79, "cu129": 79, "isol": 79, "use_cuda": 79, "use_xpu": 79, "use_cpp": 79, "recogn": [81, 87], "decis": 81, "deleg": [81, 83], "x86inductorquant": [81, 85], "quantize_pt2": [81, 82, 83, 84, 85, 86], "prepare_pt2": [81, 82, 83, 85, 86], "x86_inductor_quant": [81, 85], "get_default_x86_inductor_quantization_config": [81, 85], "calibr": [81, 82, 84, 85, 86], "data_load": [81, 83, 84, 85, 86], "program": [81, 83, 84, 85, 87], "captur": [81, 83, 84, 87], "expos": [81, 83, 84], "set_glob": [81, 83, 84, 85, 86], "xiq": [81, 85], "prepare_qat_pt2": [81, 84, 85], "sample_inference_data": 81, "convert_pt2": [81, 82, 83, 84, 85, 86], "_inductor": [81, 85], "cpp_wrapper": [81, 85], "optimized_model": [81, 82, 85, 86], "converted_model": [81, 85, 86], "x86": 81, "openvino": 81, "daniil": 82, "lyakhov": 82, "aamir": 82, "nazir": 82, "alexand": 82, "suslov": 82, "yamini": 82, "nimmagadda": 82, "kozlov": 82, "subject": [82, 84], "openvinoquant": 82, "unlock": 82, "placement": 82, "simplifi": [82, 83, 85, 86], "ux": [82, 83, 85], "torchdynamo": [82, 85, 86, 87], "four": 82, "eager": [82, 83, 84, 85, 86, 87], "mechan": [82, 85, 86], "torchvis": [82, 83, 84, 85, 86, 87], "resnet18": [82, 83, 84, 85, 86], "pt2e": [82, 83, 84, 85, 86], "__dict__": [82, 83, 84, 85, 86], "dummi": [82, 85, 86], "traced_b": [82, 85, 86], "exported_model": [82, 83, 84, 85, 86], "preset": 82, "elu": 82, "prelu": 82, "gelu": 82, "quantizationpreset": 82, "bert": [82, 85], "modeltyp": 82, "ignored_scop": 82, "exclud": 82, "layer_1": 82, "layer_2": 82, "layer_3": 82, "ignoredscop": 82, "conv2d": [82, 83, 84, 85, 86, 87], "layer_": 82, "subgraph": [82, 84], "node": [82, 84, 85, 86, 87], "target_devic": 82, "taken": 82, "account": 82, "cpu_spr": 82, "npu": 82, "targetdevic": 82, "fold": [82, 83, 85, 86], "batchnorm": [82, 83, 84, 85, 86], "prepared_model": [82, 83, 84, 85, 86], "fold_quant": 82, "finish": [82, 85], "intel": [82, 85, 91], "comparison": 82, "smoothquant": 82, "biascorrect": 82, "discrep": 82, "calibration_load": 82, "dataload": [82, 83, 84], "transform_fn": 82, "data_item": 82, "calibration_dataset": 82, "smooth_quant": 82, "fast_bias_correct": 82, "deploy": [82, 85], "jerri": [83, 85, 87], "zhang": [83, 85, 86, 87], "_export": [83, 84], "fx": [83, 87], "14k": 83, "programm": [83, 85, 86], "prerequisit": [83, 90], "db": 83, "xnnpack": [83, 84, 87], "xnnpack_quant": [83, 84], "get_symmetric_quantization_config": [83, 84], "xnnpackquant": [83, 84, 87], "prior": 83, "qconfigmap": [83, 87], "backendconfig": [83, 87], "rel": 83, "intent": [83, 87], "qconfig": [83, 87], "3d": [83, 87], "incompat": 83, "great": 83, "ideal": 83, "fake_qu": 83, "hidden": 83, "summari": 83, "interact": 83, "thu": 83, "queri": [83, 87], "previous": 83, "embedding_byt": 83, "executorchquant": 83, "concaten": 83, "prone": 83, "cleaner": 83, "composed_quant": 83, "quantization_cap": 83, "concern": 83, "decoupl": 83, "minmax": 83, "freed": 83, "identitc": 83, "imagenet": [83, 84], "unzip": [83, 84], "data_path": [83, 84], "renam": [83, 84], "resnet18_pretrained_float": [83, 84], "sy": [83, 84], "numpi": [83, 84], "np": [83, 84], "resnet": [83, 84, 85], "warn": [83, 84], "filterwarn": [83, 84], "categori": [83, 84], "deprecationwarn": [83, 84], "r": [83, 84, 92], "seed": [83, 84], "191009": [83, 84], "averagemet": [83, 84], "fmt": [83, 84], "reset": [83, 84], "val": [83, 84], "avg": [83, 84], "count": [83, 84], "__str__": [83, 84], "fmtstr": [83, 84], "topk": [83, 84], "predict": [83, 84], "maxk": [83, 84], "pred": [83, 84], "correct": [83, 84], "eq": [83, 84], "expand_a": [83, 84], "correct_k": [83, 84], "mul_": [83, 84], "criterion": [83, 84], "top1": [83, 84], "top5": [83, 84], "cnt": [83, 84], "acc1": [83, 84], "acc5": [83, 84], "load_model": [83, 84], "model_fil": [83, 84], "weights_onli": [83, 84], "print_size_of_model": [83, 84], "temp": [83, 84], "p": [83, 84], "1e6": [83, 84], "prepare_data_load": [83, 84], "485": [83, 84], "456": [83, 84], "std": [83, 84], "229": [83, 84], "225": [83, 84], "randomresizedcrop": [83, 84], "randomhorizontalflip": [83, 84], "totensor": [83, 84], "dataset_test": [83, 84], "resiz": [83, 84], "centercrop": [83, 84], "train_sampl": [83, 84], "randomsampl": [83, 84], "test_sampl": [83, 84], "sequentialsampl": [83, 84], "train_batch_s": [83, 84], "sampler": [83, 84], "data_loader_test": [83, 84, 85, 86], "eval_batch_s": [83, 84], "saved_model_dir": [83, 84], "float_model_fil": [83, 84], "model_to_quant": [83, 84], "rand": [83, 84, 90], "capture_pre_autograd_graph": [83, 84], "dynamic_shap": [83, 84], "dynamic_dim": [83, 84], "qconfig_opt": 83, "set_object_typ": 83, "set_module_nam": 83, "workload": 83, "themodel": 83, "feedback": 83, "dq": 83, "fp32_op": 83, "qauntiz": 83, "x_int8": 83, "x_zero_point": 83, "weight_int8": 83, "bias_fp32": 83, "output_scal": 83, "output_zero_point": 83, "x_fp32": 83, "quantized_decompos": 83, "dequantize_per_tensor": 83, "x_i8": 83, "x_quant_min": 83, "x_quant_max": 83, "weight_fp32": 83, "weight_i8": 83, "weight_quant_min": 83, "weight_quant_max": 83, "weight_permut": 83, "permute_copi": 83, "out_fp32": 83, "addmm": 83, "out_i8": 83, "quantize_per_tensor": 83, "out_zero_point": 83, "out_quant_min": 83, "out_quant_max": 83, "float32_op": 83, "decompos": 83, "use_reference_represent": 83, "x_int16": 83, "int16": 83, "weight_int16": 83, "acc_int32": 83, "out_dtyp": 83, "bias_scal": 83, "bias_int32": 83, "div": 83, "mul": 83, "out_int8": 83, "qmin": [83, 92], "qmax": [83, 92], "date": 83, "unus": 83, "serila": 83, "consult": 83, "exportedprogram": 83, "pt2e_quantized_model_file_path": 83, "resnet18_pt2e_quant": 83, "quantized_ep": 83, "loaded_quantized_ep": 83, "loaded_quantized_model": 83, "diff": 83, "79": 83, "82": 83, "55": 83, "edg": [83, 87, 91], "went": 83, "andrew": 84, "Or": 84, "move_exported_model_to_ev": [84, 85], "correctli": 84, "certain": 84, "dropout": 84, "move_exported_model_to_train": 84, "jit": 84, "recursivescriptmodul": 84, "train_one_epoch": 84, "ntrain_batch": 84, "avgloss": 84, "5f": 84, "start_tim": 84, "3f": 84, "global_avg": 84, "is_qat": [84, 85], "fusion": 84, "batchnorm2d": 84, "_native_batch_norm_legit": 84, "cudnn_batch_norm": 84, "mobilenetv2": 84, "manual": 84, "recompil": 84, "consolid": 84, "epoch": 84, "far": 84, "num_epoch": 84, "num_train_batch": 84, "num_eval_batch": 84, "num_observer_update_epoch": 84, "num_batch_norm_update_epoch": 84, "num_epochs_between_ev": 84, "nepoch": 84, "stat": 84, "subseq": 84, "disable_observ": 84, "bn": 84, "running_mean": 84, "running_var": 84, "new_arg": 84, "wish": 84, "prepared_model_copi": 84, "neval_batch": 84, "paus": 84, "resum": 84, "fail": [84, 87], "machin": 84, "checkpoint_path": 84, "checkpoint_": 84, "behav": 84, "incorrectli": 84, "lesli": [85, 87], "fang": [85, 87], "weiwen": [85, 87], "xia": [85, 87], "jiong": [85, 87], "gong": [85, 87], "cnn": 85, "rnn": 85, "outstand": 85, "fourth": 85, "spr": 85, "xeon": 85, "processor": 85, "boost": 85, "memory_format": [85, 86], "channels_last": [85, 86], "onednn": [85, 86], "assum": [85, 87], "word": 85, "satur": 85, "extern": 85, "pure": 85, "dedic": 85, "scenario": [85, 86], "plai": [85, 86], "convolut": [85, 86, 87], "absenc": [85, 86], "enhanc": [85, 86], "mirror": [85, 86], "autocast": [85, 86], "device_typ": [85, 86], "turn": [85, 86], "cpp": 85, "qconvolut": [85, 86], "qlinear": [85, 86], "presenc": [85, 86], "pair": [85, 86], "conting": [85, 86], "qmaxpool2d": [85, 86], "torchinductor_freez": [85, 86], "example_x86inductorquantizer_pytorch_2_1": 85, "torchbench": 85, "measur": 85, "proven": 85, "depth": 85, "example_x86inductorquantizer_qat": 85, "yan": 86, "zhiwei": 86, "wang": 86, "eikan": 86, "liangang": 86, "liu": 86, "river": 86, "cui": 86, "yifeng": 86, "xpuinductorquant": 86, "pip3": 86, "torchaudio": 86, "xpu_inductor_quantizer_exampl": 86, "xpu_inductor_quant": 86, "xpuiq": 86, "resnet18_weight": 86, "get_default_xpu_inductor_quantization_config": 86, "wherea": 86, "histogramobserv": [86, 87], "perchannelminmaxobserv": 86, "quantizationspec": [86, 87], "quantizationconfig": [86, 87], "type_check": 86, "observerorfakequantizeconstructor": 86, "get_xpu_inductor_symm_quantization_config": 86, "extra_arg": 86, "act_observer_or_fake_quant_ctr": 86, "act_quantization_spec": [86, 87], "qscheme": [86, 87], "per_tensor_symmetr": [86, 87], "observer_or_fake_quant_ctr": [86, 87], "with_arg": [86, 87], "weight_observer_or_fake_quant_ctr": 86, "weight_quantization_spec": [86, 87], "per_channel_symmetr": 86, "ch_axi": 86, "oc": 86, "ic": 86, "kh": 86, "kw": 86, "conv": [86, 87], "bias_quantization_spec": 86, "amp": 86, "indcutor": 86, "kimish": 87, "patel": 87, "made": 87, "explicit": 87, "quantiat": 87, "encod": 87, "convei": 87, "quantizationannot": 87, "furthermor": 87, "minmaxobserv": 87, "input_qspec_map": 87, "output_qspec": 87, "_annot": 87, "conclud": 87, "matcher": 87, "get_source_partit": 87, "add_partit": 87, "gm": 87, "itertool": 87, "chain": 87, "add_nod": 87, "output_nod": 87, "per_tensor_affin": 87, "input_act_qspec": 87, "output_act_qspec": 87, "input_act0": 87, "input_act1": 87, "quantization_annot": 87, "substitut": 87, "among": 87, "sharedquantizationspec": 87, "maxpool": 87, "average_pool": 87, "concat": 87, "whose": 87, "edgeornod": 87, "transit": 87, "spec": 87, "conv1": 87, "conv2": 87, "fed": 87, "conv1_out": 87, "conv2_out": 87, "qspec1": 87, "cat_input0": 87, "cat_input1": 87, "implicitli": 87, "therefor": 87, "ob": 87, "consum": 87, "rewrit": 87, "share_qparams_with_input_act0_qspec": 87, "known": 87, "beforehand": 87, "sigmoid": 87, "fixedqparamsquantizationspec": 87, "act_qspec": 87, "sigmoid_nod": 87, "input_act": 87, "derivedquantizationspec": 87, "derive_qparams_fn": 87, "observerorfakequant": 87, "observerbas": 87, "fakequantizebas": 87, "heurist": 87, "obejct": 87, "obs_or_fq": 87, "fq": 87, "act_obs_or_fq": 87, "weight_obs_or_fq": 87, "act_zp": 87, "weight_zp": 87, "bias_qspec": 87, "derived_from": 87, "backendquant": 87, "get_input_act_qspec": 87, "get_output_act_qspec": 87, "get_weight_qspec": 87, "get_bias_qspec": 87, "intermedi": 87, "straightforward": 87, "call_funct": 87, "relu_": 87, "relu_nod": 87, "maybe_conv_nod": 87, "conv1d": 87, "unexpect": 87, "recognz": 87, "unquant": 87, "subgraphmatch": 87, "conv_relu_pattern": 87, "name_node_map": 87, "input_nod": 87, "weight_nod": 87, "bias_nod": 87, "caveat": 87, "exhaust": 87, "2d": 87, "4d": 87, "symbol": 87, "outcom": 87, "tutorials_python": 88, "zip": 88, "jupyt": [88, 90], "notebook": [88, 90, 92], "tutorials_jupyt": 88, "galleri": [88, 90], "sphinx": [88, 90], "00": 89, "004": [89, 90], "total": [89, 90], "template_tutori": [89, 90], "click": 90, "firstnam": 90, "lastnam": 90, "v2": 90, "topic": 90, "8361": 90, "3612": 90, "1353": 90, "2485": 90, "0942": 90, "4525": 90, "0229": 90, "5811": 90, "3643": 90, "4914": 90, "1033": 90, "6675": 90, "5015": 90, "8620": 90, "6301": 90, "practic": 90, "summar": 90, "takeawai": 90, "link1": 90, "link2": 90, "minut": 90, "ipynb": [90, 92], "b200": [91, 92], "bmg": 91, "mi350x": 91, "moe": 91, "128x128": 91, "blockwis": 91, "1x128": 91, "md": 91, "perplex": 92, "x_q": 92, "zp": 92, "x_float": 92, "x_fq": 92, "proce": 92, "torchtun": 92, "int8dynactint4qatquant": 92, "int4weightonlyqatquant": 92, "int4weightonlyembeddingqatquant": 92, "composableqatquant": 92, "fastlanguagemodel": 92, "qwen3": 92, "2507": 92, "load_in_4bit": 92, "full_finetun": 92, "target_modul": 92, "v_proj": 92, "o_proj": 92, "up_proj": 92, "down_proj": 92, "lora_alpha": 92, "qat_schem": 92, "colab": 92, "unslothai": 92, "blob": 92, "nb": 92, "qwen3_": 92, "14b": 92, "8b_qat_ful": 92, "earli": 92, "8b_qat_lora": 92, "mlabonn": 92, "finetom": 92, "100k": 92, "rate": 92, "2e": 92, "12b": 92, "1477": 92, "7745": 92, "5631": 92, "33": 92, "727": 92, "bbh": 92, "8079": 92, "7624": 92, "7831": 92, "45": 92, "495": 92, "1155": 92, "247": 92, "797": 92, "770": 92, "7074": 92, "6415": 92, "6666": 92, "38": 92, "088": 92, "gpqa": 92, "3232": 92, "3081": 92, "3182": 92, "887": 92, "mmlu": 92, "4909": 92, "4328": 92, "4524": 92, "735": 92, "1322": 92, "3459": 92, "8796": 92, "5483": 92, "4967": 92, "5174": 92, "116": 92, "3333": 92, "2879": 92, "303": 92, "260": 92, "2771": 92, "2562": 92, "2629": 92, "057": 92, "8x": 92, "yahma": 92, "alpaca": 92, "7527": 92, "7068": 92, "551": 92, "4074": 92, "3621": 92, "3702": 92, "881": 92, "7771": 92, "7262": 92, "7397": 92, "523": 92, "4929": 92, "4519": 92, "4686": 92, "732": 92}, "objects": {"torchao.float8": [[6, 0, 1, "", "CastConfig"], [7, 0, 1, "", "Float8LinearConfig"], [8, 0, 1, "", "ScalingGranularity"], [9, 0, 1, "", "ScalingType"], [10, 2, 1, "", "convert_to_float8_training"], [11, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[7, 1, 1, "", "from_recipe_name"]], "torchao.prototype.mx_formats": [[12, 0, 1, "", "MXDynamicActivationMXWeightConfig"], [13, 0, 1, "", "NVFP4DynamicActivationNVFP4WeightConfig"], [14, 0, 1, "", "NVFP4WeightOnlyConfig"]], "torchao.quantization": [[15, 0, 1, "", "Float8DynamicActivationFloat8SemiSparseWeightConfig"], [16, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [17, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [18, 0, 1, "", "Float8WeightOnlyConfig"], [19, 0, 1, "", "FqnToConfig"], [20, 0, 1, "", "Int4WeightOnlyConfig"], [21, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [22, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [23, 0, 1, "", "Int8DynamicActivationIntxWeightConfig"], [24, 0, 1, "", "Int8WeightOnlyConfig"], [25, 0, 1, "", "IntxWeightOnlyConfig"], [50, 2, 1, "", "quantize_"]], "torchao.quantization.qat": [[26, 0, 1, "", "ComposableQATQuantizer"], [27, 0, 1, "", "FakeQuantizeConfigBase"], [28, 0, 1, "", "FakeQuantizedEmbedding"], [29, 0, 1, "", "FakeQuantizedLinear"], [30, 0, 1, "", "FakeQuantizerBase"], [31, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [32, 0, 1, "", "Float8FakeQuantizeConfig"], [33, 0, 1, "", "Float8FakeQuantizer"], [34, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [35, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [36, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [37, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [38, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [39, 0, 1, "", "IntxFakeQuantizeConfig"], [40, 0, 1, "", "IntxFakeQuantizer"], [41, 0, 1, "", "QATConfig"], [42, 0, 1, "", "QATStep"], [45, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[28, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[29, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[31, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[33, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[35, 1, 1, "", "convert"], [35, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[39, 3, 1, "", "group_size"], [39, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[40, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[43, 0, 1, "", "Int4WeightOnlyEmbedding"], [44, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[43, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[46, 0, 1, "", "Int4WeightOnlyQATLinear"], [47, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [48, 2, 1, "", "disable_linear_fake_quant"], [49, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[51, 0, 1, "", "KernelPreference"], [52, 0, 1, "", "PackingFormat"], [53, 0, 1, "", "QuantizeTensorKwargs"], [54, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[51, 4, 1, "", "AUTO"], [51, 4, 1, "", "MSLK"], [51, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[52, 4, 1, "", "PLAIN"]], "torchao": [[4, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[55, 0, 1, "", "PerChannelNormObserver"], [56, 0, 1, "", "WandaSparsifier"], [57, 2, 1, "", "apply_fake_sparsity"], [58, 4, 1, "", "semi_sparse_weight"], [59, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[55, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[56, 1, 1, "", "prepare"], [56, 1, 1, "", "squash_mask"], [56, 1, 1, "", "update_mask"]], "torchao.utils": [[60, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[60, 1, 1, "", "get_layout"], [60, 1, 1, "", "get_tensor_impl_constructor"], [60, 1, 1, "", "implements"], [60, 1, 1, "", "implements_torch_function"], [60, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 64, 66, 68, 71, 78, 79, 92], "float8": [0, 3, 66, 68, 71], "main": [0, 2, 3], "train": [0, 66, 68, 71, 73, 79, 82, 83, 84, 85, 86, 91, 92], "api": [0, 2, 3, 5, 61, 62, 68, 71, 79, 87, 92], "other": [0, 64, 66, 91], "type": [0, 77], "kernel": [1, 64, 66, 78, 80], "quantiz": [2, 3, 5, 50, 66, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 91, 92], "qat": [2, 68, 84, 91, 92], "config": [2, 3], "quantize_": [2, 5, 92], "custom": [2, 64], "legaci": 2, "prototyp": [2, 3, 91], "workflow": [3, 79, 91], "weight": [3, 66, 69, 73], "int8": 3, "int4": 3, "intx": 3, "mx": 3, "nvfp4": 3, "sparsiti": [4, 67], "util": 5, "tensor": [5, 64, 66, 75, 76, 78, 87], "subclass": [5, 64, 76, 78], "common": [5, 62, 87], "castconfig": 6, "float8linearconfig": 7, "scalinggranular": 8, "scalingtyp": 9, "convert_to_float8_train": 10, "precompute_float8_dynamic_scale_for_fsdp": 11, "mxdynamicactivationmxweightconfig": 12, "nvfp4dynamicactivationnvfp4weightconfig": 13, "nvfp4weightonlyconfig": 14, "float8dynamicactivationfloat8semisparseweightconfig": 15, "float8dynamicactivationfloat8weightconfig": 16, "float8dynamicactivationint4weightconfig": 17, "float8weightonlyconfig": 18, "fqntoconfig": 19, "int4weightonlyconfig": 20, "int8dynamicactivationint4weightconfig": 21, "int8dynamicactivationint8weightconfig": 22, "int8dynamicactivationintxweightconfig": 23, "int8weightonlyconfig": 24, "intxweightonlyconfig": 25, "composableqatquant": 26, "fakequantizeconfigbas": 27, "fakequantizedembed": 28, "fakequantizedlinear": 29, "fakequantizerbas": 30, "float8actint4weightqatquant": 31, "float8fakequantizeconfig": 32, "float8fakequant": 33, "fromintxquantizationawaretrainingconfig": 34, "int4weightonlyembeddingqatquant": 35, "int4weightonlyqatquant": 36, "int8dynactint4weightqatquant": 37, "intxquantizationawaretrainingconfig": 38, "intxfakequantizeconfig": 39, "intxfakequant": 40, "qatconfig": 41, "qatstep": 42, "int4weightonlyembed": 43, "int4weightonlyqatembed": 44, "initialize_fake_quant": 45, "int4weightonlyqatlinear": 46, "int8dynactint4weightqatlinear": 47, "disable_linear_fake_qu": 48, "enable_linear_fake_qu": 49, "kernelprefer": [51, 64], "packingformat": 52, "quantizetensorkwarg": 53, "_choose_quant_func_and_quantize_tensor": 54, "perchannelnormobserv": 55, "wandasparsifi": 56, "apply_fake_spars": 57, "semi_sparse_weight": 58, "sparsifi": 59, "torchaobasetensor": 60, "refer": [61, 79], "benchmark": [62, 63, 64, 73], "guid": [62, 63, 64, 78], "add": [62, 78], "an": [62, 72], "recip": [62, 71], "model": [62, 64, 66, 69, 71, 72, 73, 77, 78, 79, 82, 83, 84], "design": [62, 67], "consider": 62, "hf": 62, "ci": 62, "dashboard": 62, "1": [62, 68, 71, 73, 77, 78, 82, 85, 86, 87], "modifi": 62, "exist": 62, "configur": [62, 67, 78, 83, 84], "2": [62, 68, 73, 77, 78, 82, 83, 84, 85, 86, 87], "run": 62, "3": [62, 68, 73, 78, 82, 85, 86, 87], "output": [62, 76], "format": [62, 66], "4": [62, 82, 87], "integr": [62, 68, 77, 78, 92], "pipelin": 62, "troubleshoot": 62, "test": [62, 64], "issu": 62, "best": 62, "practic": 62, "user": 63, "contributor": 64, "gener": 64, "extend": 64, "ad": [64, 78], "new": [64, 78], "effici": [64, 66], "triton": 64, "hand": 64, "written": 64, "us": [64, 87], "flow": [64, 66, 72, 78, 87], "torch": [64, 82, 83, 84], "compil": [64, 78, 82], "perform": [64, 73, 80, 83], "serial": [64, 72, 78], "featur": 64, "support": [64, 77, 78], "function": [64, 83, 84], "compos": 64, "microbenchmark": 64, "eval": [64, 83], "develop": [65, 79], "note": [65, 71, 79, 87], "overview": [66, 67, 90], "basic": 66, "dtype": 66, "primit": 66, "op": 66, "deriv": [66, 87], "pack": 66, "algorithm": 66, "onli": 66, "dynam": [66, 69], "activ": [66, 69], "static": [66, 74], "awar": [66, 68, 84, 85, 91, 92], "low": [66, 68], "bit": [66, 69], "optim": [66, 72, 73, 79], "case": 66, "studi": 66, "how": [66, 83, 84, 87], "work": 66, "dure": 66, "execut": 66, "save": [66, 77, 83, 84], "load": [66, 83, 84], "goal": 67, "context": 67, "prune": 67, "criteria": 67, "strategi": 67, "pattern": [67, 87], "part": [68, 71, 73], "fine": 68, "tune": 68, "qlora": 68, "option": [68, 73, 82, 90], "torchtun": 68, "axolotl": [68, 92], "rank": 68, "adapt": 68, "huggingfac": [68, 73, 78], "peft": 68, "first": 69, "exampl": [69, 77, 78, 87], "set": [69, 83], "up": 69, "w8a8": 69, "int": 69, "8": 69, "size": [69, 83], "comparison": 69, "speedup": 69, "next": [69, 76], "step": [69, 73, 76, 78, 90], "eager": [70, 79], "tutori": [70, 79, 81, 90], "pre": 71, "torchtitan": 71, "prerequisit": [71, 82, 85, 86, 87], "rowwis": 71, "scale": 71, "tensorwis": 71, "pick": 71, "import": [71, 83, 84], "directli": [71, 87], "convers": 71, "deseri": 72, "what": [72, 76], "happen": 72, "when": 72, "serv": [73, 78, 79], "vllm": [73, 78], "sglang": 73, "executorch": 73, "post": [73, 82, 83, 85, 86], "infer": 73, "transform": [73, 77, 78], "mobil": 73, "deploy": 73, "unti": 73, "embed": 73, "creat": [73, 78], "export": [73, 82, 83, 84, 85, 86, 87], "characterist": 73, "evalu": [73, 83, 92], "qualiti": 73, "assess": 73, "memori": 73, "latenc": 73, "result": [73, 92], "h100": 73, "machin": 73, "conclus": [73, 82, 83, 84, 85, 86, 87, 90], "calibr": [74, 83], "phase": 74, "write": [75, 76, 87], "your": [75, 76, 78], "own": [75, 76], "advanc": 75, "ar": 76, "modul": 76, "swap": 76, "which": 76, "oper": [76, 78, 87], "should": 76, "we": 76, "implement": [76, 78], "compar": 76, "hug": 77, "face": 77, "quick": [77, 79, 81], "start": [77, 79, 81], "usag": [77, 78], "diffus": 77, "architectur": 78, "system": 78, "class": 78, "fqn": 78, "method": 78, "minim": 78, "requir": 78, "compat": 78, "why": 78, "regist": 78, "": 78, "kei": 78, "detail": 78, "hardwar": 78, "specif": [78, 83, 84], "linear": 78, "benefit": 78, "trade": 78, "off": 78, "share": [78, 87], "safetensor": 78, "diagram": 78, "high": 78, "level": 78, "point": 78, "dispatch": 78, "bring": 78, "extern": 78, "welcom": 79, "document": 79, "pytorch": [79, 82, 83, 84, 85, 86, 87], "nativ": 79, "instal": [79, 82], "pt2e": [79, 81, 87], "openvino": 82, "backend": [82, 83, 84, 85, 86], "introduct": [82, 85, 86, 87], "nncf": 82, "captur": [82, 85, 86], "fx": [82, 85, 86], "graph": [82, 85, 86], "appli": [82, 85, 86], "lower": [82, 83, 85, 86], "represent": 82, "improv": 82, "metric": 82, "motiv": [83, 87], "defin": [83, 84], "helper": [83, 84], "prepar": [83, 84], "dataset": [83, 84], "mode": 83, "convert": [83, 84], "check": 83, "accuraci": 83, "debug": 83, "loop": 84, "checkpoint": 84, "x86": 85, "through": [85, 86], "inductor": [85, 86], "intel": 86, "gpu": 86, "annot": 87, "param": 87, "fix": 87, "paramet": 87, "5": 87, "A": 87, "toi": 87, "resnet18": 87, "ir": 87, "problem": 87, "match": 87, "aten": 87, "recommend": [87, 92], "subgraphmatcherwithnamenodemap": 87, "comput": 89, "time": 89, "templat": 90, "addit": 90, "exercis": 90, "further": 90, "read": 90, "stabl": 91, "unsloth": 92}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao.kernel": [[1, "torchao-kernel"]], "torchao.quantization.qat": [[2, "torchao-quantization-qat"]], "Main Config for quantize_": [[2, "main-config-for-quantize"]], "Custom QAT APIs": [[2, "custom-qat-apis"]], "Legacy QAT APIs": [[2, "legacy-qat-apis"]], "Prototype": [[2, "prototype"]], "torchao.quantization": [[3, "torchao-quantization"]], "Main Quantization APIs": [[3, "main-quantization-apis"]], "Workflow Configs": [[3, "workflow-configs"]], "float8 weight configs": [[3, "float8-weight-configs"]], "int8 weight configs": [[3, "int8-weight-configs"]], "int4 weight configs": [[3, "int4-weight-configs"]], "intx weight configs": [[3, "intx-weight-configs"]], "mx weight configs (prototype)": [[3, "mx-weight-configs-prototype"]], "nvfp4 weight configs (prototype)": [[3, "nvfp4-weight-configs-prototype"]], "torchao.sparsity": [[4, "module-torchao.sparsity"]], "torchao.utils": [[5, "torchao-utils"]], "Tensor Subclass Utils": [[5, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[5, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[5, "quantize-api-common-utils"]], "CastConfig": [[6, "castconfig"]], "Float8LinearConfig": [[7, "float8linearconfig"]], "ScalingGranularity": [[8, "scalinggranularity"]], "ScalingType": [[9, "scalingtype"]], "convert_to_float8_training": [[10, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[11, "precompute-float8-dynamic-scale-for-fsdp"]], "MXDynamicActivationMXWeightConfig": [[12, "mxdynamicactivationmxweightconfig"]], "NVFP4DynamicActivationNVFP4WeightConfig": [[13, "nvfp4dynamicactivationnvfp4weightconfig"]], "NVFP4WeightOnlyConfig": [[14, "nvfp4weightonlyconfig"]], "Float8DynamicActivationFloat8SemiSparseWeightConfig": [[15, "float8dynamicactivationfloat8semisparseweightconfig"]], "Float8DynamicActivationFloat8WeightConfig": [[16, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[17, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[18, "float8weightonlyconfig"]], "FqnToConfig": [[19, "fqntoconfig"]], "Int4WeightOnlyConfig": [[20, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[21, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[22, "int8dynamicactivationint8weightconfig"]], "Int8DynamicActivationIntxWeightConfig": [[23, "int8dynamicactivationintxweightconfig"]], "Int8WeightOnlyConfig": [[24, "int8weightonlyconfig"]], "IntxWeightOnlyConfig": [[25, "intxweightonlyconfig"]], "ComposableQATQuantizer": [[26, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[27, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[28, "fakequantizedembedding"]], "FakeQuantizedLinear": [[29, "fakequantizedlinear"]], "FakeQuantizerBase": [[30, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[31, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[32, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[33, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[34, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[35, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[36, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[37, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[38, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[39, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[40, "intxfakequantizer"]], "QATConfig": [[41, "qatconfig"]], "QATStep": [[42, "qatstep"]], "Int4WeightOnlyEmbedding": [[43, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[44, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[45, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[46, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[47, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[48, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[49, "enable-linear-fake-quant"]], "quantize": [[50, "quantize"]], "KernelPreference": [[51, "kernelpreference"], [64, "kernelpreference"]], "PackingFormat": [[52, "packingformat"]], "QuantizeTensorKwargs": [[53, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[54, "choose-quant-func-and-quantize-tensor"]], "PerChannelNormObserver": [[55, "perchannelnormobserver"]], "WandaSparsifier": [[56, "wandasparsifier"]], "apply_fake_sparsity": [[57, "apply-fake-sparsity"]], "semi_sparse_weight": [[58, "semi-sparse-weight"]], "sparsify": [[59, "sparsify"]], "TorchAOBaseTensor": [[60, "torchaobasetensor"]], "API Reference": [[61, "api-reference"], [79, null]], "Benchmarking API Guide": [[62, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[62, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[62, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[62, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[62, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[62, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[62, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[62, "run-ci-benchmarks"]], "3. CI Output Format": [[62, "ci-output-format"]], "4. Integration with CI Pipeline": [[62, "integration-with-ci-pipeline"]], "Troubleshooting": [[62, "troubleshooting"]], "Running Tests": [[62, "running-tests"]], "Common Issues": [[62, "common-issues"]], "Best Practices": [[62, "best-practices"]], "Benchmarking User Guide": [[63, "benchmarking-user-guide"]], "Contributor Guide": [[64, "contributor-guide"]], "General Guide on Extending torchao": [[64, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[64, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[64, "adding-efficient-kernels"]], "Custom triton kernels": [[64, "custom-triton-kernels"]], "Custom hand written kernels": [[64, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[64, "using-hand-written-kernels-in-tensor-subclasses"]], "Flow": [[64, "flow"]], "Using torch.compile for Performance": [[64, "using-torch-compile-for-performance"]], "Serialization": [[64, "serialization"], [72, "serialization"]], "Other Feature Support": [[64, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[64, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[64, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[64, "model-benchmarks-and-eval"]], "Developer Notes": [[65, "developer-notes"], [79, null]], "Quantization Overview": [[66, "quantization-overview"]], "Basic DTypes": [[66, "basic-dtypes"]], "Quantization Primitive Ops": [[66, "quantization-primitive-ops"]], "Efficient kernels": [[66, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[66, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[66, "quantization-algorithms-flows"]], "Weight Only Quantization": [[66, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[66, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[66, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[66, "other-quantization-flows"]], "Training": [[66, "training"]], "Quantization Aware Training": [[66, "quantization-aware-training"], [85, "quantization-aware-training"]], "Low Bit Optimizers": [[66, "low-bit-optimizers"]], "Quantized Training": [[66, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[66, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[66, "during-quantization"]], "During Model Execution": [[66, "during-model-execution"]], "During Save/Load": [[66, "during-save-load"]], "Sparsity Overview": [[67, "sparsity-overview"]], "Goal": [[67, "goal"]], "Design": [[67, "design"]], "Context": [[67, "context"]], "Pruning Configuration": [[67, "pruning-configuration"]], "Pruning Criteria": [[67, "pruning-criteria"]], "Pruning Strategy": [[67, "pruning-strategy"]], "Sparsity Pattern": [[67, "sparsity-pattern"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[68, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[68, "quantization-aware-training-qat"], [91, "quantization-aware-training-qat"], [92, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[68, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[68, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[68, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[68, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[68, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[68, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[68, "float8-quantized-fine-tuning"]], "First Quantization Example": [[69, "first-quantization-example"]], "Setting Up the Model": [[69, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[69, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[69, "model-size-comparison"]], "Speedup Comparison": [[69, "speedup-comparison"]], "Next Steps": [[69, "next-steps"], [76, "next-steps"]], "Eager Quantization Tutorials": [[70, "eager-quantization-tutorials"], [79, null]], "(Part 1) Pre-training with float8": [[71, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[71, "pre-training-with-torchtitan"]], "Prerequisites": [[71, "prerequisites"], [71, "id1"], [82, "prerequisites"], [85, "prerequisites"], [86, "prerequisites"]], "Rowwise scaling": [[71, "rowwise-scaling"]], "Tensorwise scaling": [[71, "tensorwise-scaling"]], "Picking a recipe": [[71, "picking-a-recipe"]], "Important notes": [[71, "important-notes"]], "Pre-training with torchao directly": [[71, "pre-training-with-torchao-directly"]], "Model conversion API": [[71, "model-conversion-api"]], "Serialization and deserialization flow": [[72, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[72, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[72, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[73, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[73, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[73, "serving-and-inference"]], "Serving and Inference with vLLM": [[73, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[73, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[73, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[73, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[73, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[73, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[73, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[73, "mobile-performance-characteristics"]], "Evaluation": [[73, "evaluation"]], "Model Quality Assessment": [[73, "model-quality-assessment"]], "Memory Benchmarking": [[73, "memory-benchmarking"]], "Performance Benchmarking": [[73, "performance-benchmarking"]], "Latency Benchmarking": [[73, "latency-benchmarking"]], "Serving Benchmarking": [[73, "serving-benchmarking"]], "Results (H100 machine)": [[73, "results-h100-machine"]], "Conclusion": [[73, "conclusion"], [82, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [87, "conclusion"], [90, "conclusion"]], "Static Quantization": [[74, "static-quantization"]], "Calibration Phase": [[74, "calibration-phase"]], "Quantization Phase": [[74, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[75, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[76, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[76, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[76, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[76, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[76, "which-operators-should-we-implement"]], "Comparing the Outputs": [[76, "comparing-the-outputs"]], "Hugging Face Integration": [[77, "hugging-face-integration"]], "Quick Start: Usage Example": [[77, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[77, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[77, "quantizing-models-with-diffusers"]], "Saving the Model": [[77, "saving-the-model"]], "Supported Quantization Types": [[77, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[78, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[78, "configuration-system"]], "1. HuggingFace Model Configuration": [[78, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[78, "torchao-configuration-classes"]], "3. FQN Configuration": [[78, "fqn-configuration"]], "Usage Examples": [[78, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[78, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[78, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[78, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[78, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[78, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[78, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[78, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[78, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[78, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[78, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[78, "hardware-specific-linear-operations"]], "Compilation Benefits": [[78, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[78, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[78, "serialization-and-model-sharing"]], "SafeTensors Support": [[78, "safetensors-support"]], "Integration Architecture Diagrams": [[78, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[78, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[78, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[78, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Welcome to the torchao Documentation": [[79, "welcome-to-the-torchao-documentation"]], "PyTorch-Native Training-to-Serving Model Optimization": [[79, "pytorch-native-training-to-serving-model-optimization"]], "Quick Start": [[79, "quick-start"], [81, "quick-start"]], "Installation": [[79, "installation"]], "Workflows": [[79, null], [91, "workflows"]], "PT2E Quantization Tutorials": [[79, null], [81, "pt2e-quantization-tutorials"]], "Performant Kernels": [[80, "performant-kernels"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[82, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[82, "introduction"], [85, "introduction"], [86, "introduction"], [87, "introduction"]], "Post Training Quantization": [[82, "post-training-quantization"], [85, "post-training-quantization"], [86, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[82, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[82, "capture-fx-graph"], [85, "capture-fx-graph"], [86, "capture-fx-graph"]], "2. Apply Quantization": [[82, "apply-quantization"], [85, "apply-quantization"], [86, "apply-quantization"]], "3. Lower into OpenVINO representation": [[82, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[82, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[83, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[83, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[83, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[83, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[83, "export-the-model-with-torch-export"], [84, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[83, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [84, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[83, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[83, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[83, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[83, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[83, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[83, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[83, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[84, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[84, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[84, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[84, "training-loop"]], "Saving and Loading Model Checkpoints": [[84, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[84, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[85, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[85, "lower-into-inductor"], [86, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[86, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[87, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[87, "prerequisites"]], "Annotation API": [[87, "annotation-api"]], "1. Annotate Common Operator Patterns": [[87, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[87, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[87, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[87, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[87, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[87, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[87, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[87, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]], "Computation times": [[89, "computation-times"]], "Template Tutorial": [[90, "template-tutorial"]], "Overview": [[90, "overview"]], "Steps": [[90, "steps"]], "(Optional) Additional Exercises": [[90, "optional-additional-exercises"]], "Further Reading": [[90, "further-reading"]], "Stable Workflows": [[91, "stable-workflows"]], "Prototype Workflows": [[91, "prototype-workflows"]], "Other": [[91, "other"]], "torchao APIs": [[92, "torchao-apis"]], "quantize_ API (recommended)": [[92, "quantize-api-recommended"]], "Axolotl integration": [[92, "axolotl-integration"]], "Unsloth integration": [[92, "unsloth-integration"]], "Evaluation Results": [[92, "evaluation-results"]]}, "indexentries": {"module": [[4, "module-torchao.sparsity"]], "torchao.sparsity": [[4, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[6, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[7, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[7, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[8, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[9, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[10, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[11, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "mxdynamicactivationmxweightconfig (class in torchao.prototype.mx_formats)": [[12, "torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig"]], "nvfp4dynamicactivationnvfp4weightconfig (class in torchao.prototype.mx_formats)": [[13, "torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig"]], "nvfp4weightonlyconfig (class in torchao.prototype.mx_formats)": [[14, "torchao.prototype.mx_formats.NVFP4WeightOnlyConfig"]], "float8dynamicactivationfloat8semisparseweightconfig (class in torchao.quantization)": [[15, "torchao.quantization.Float8DynamicActivationFloat8SemiSparseWeightConfig"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[16, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[17, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[19, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[20, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8dynamicactivationintxweightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationIntxWeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8WeightOnlyConfig"]], "intxweightonlyconfig (class in torchao.quantization)": [[25, "torchao.quantization.IntxWeightOnlyConfig"]], "composableqatquantizer (class in torchao.quantization.qat)": [[26, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[27, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[29, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[29, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[30, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[33, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[40, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[44, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[45, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[46, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[47, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[48, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[49, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[50, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[51, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[52, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[52, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[53, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[54, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "perchannelnormobserver (class in torchao.sparsity)": [[55, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[55, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[56, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[57, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[58, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[59, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[60, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[60, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})