Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 22, 23, 24, 25, 27, 40, 41, 42, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 62, 63, 66, 71, 73, 75, 76, 78, 79, 82, 85, 86, 87, 92, 93, 94, 96, 97, 100, 101, 102, 103, 104, 106, 107, 109, 110, 113, 114, 115, 116, 117, 118, 119], "section": [2, 10, 101, 106, 110, 115, 116, 119], "introduc": [2, 12, 114, 115, 117, 118, 119], "dive": 2, "detail": [2, 8, 10, 12, 41, 55, 100, 101, 102, 104, 106, 107, 109, 114, 115, 116, 117], "how": [2, 4, 10, 12, 13, 19, 27, 43, 47, 49, 51, 56, 71, 83, 84, 87, 98, 100, 102, 103, 104, 106, 107, 109, 110, 114, 117, 118], "integr": [2, 10, 98, 100, 103, 104, 106, 109, 117, 119], "pytorch": [2, 8, 12, 13, 18, 21, 52, 71, 98, 100, 101, 104, 106, 109, 110, 113], "optim": [2, 10, 12, 22, 40, 55, 82, 98, 100, 106, 109, 114, 116, 117, 118], "your": [2, 8, 10, 12, 98, 100, 101, 102, 104, 106, 115, 116, 117, 118, 119], "machin": [2, 116], "learn": [2, 47, 71, 102, 106, 113, 115, 117, 118, 119], "model": [2, 12, 40, 46, 48, 55, 60, 65, 66, 67, 68, 69, 70, 73, 77, 82, 89, 90, 93, 94, 96, 102, 106, 107, 109, 117, 118, 119], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 44, 45, 52, 53, 55, 56, 57, 58, 62, 63, 65, 67, 68, 69, 71, 75, 76, 78, 79, 86, 87, 96, 98, 100, 102, 103, 107, 109, 110, 115, 117, 118, 119], "quantiz": [2, 8, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 31, 33, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 100, 103, 106], "sparsiti": [2, 8, 12, 16, 22, 25, 92, 93, 94, 95, 96, 98, 100, 103, 104], "tba": [3, 11, 99], "For": [4, 8, 10, 12, 13, 41, 71, 101, 102, 103, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "full": [4, 12, 102, 107, 113, 114, 116], "exampl": [4, 8, 10, 12, 13, 40, 51, 55, 60, 62, 63, 66, 70, 71, 73, 77, 82, 83, 93, 96, 97, 101, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118], "us": [4, 8, 9, 12, 13, 17, 18, 19, 22, 23, 24, 27, 29, 32, 42, 44, 45, 47, 48, 49, 51, 53, 55, 56, 57, 58, 60, 65, 66, 70, 71, 73, 78, 79, 83, 84, 87, 93, 97, 98, 100, 101, 102, 103, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118], "our": [4, 10, 12, 23, 100, 102, 104, 106, 107, 109, 115, 116], "pleas": [4, 9, 10, 12, 13, 21, 41, 47, 66, 70, 98, 101, 102, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "refer": [4, 8, 12, 13, 73, 79, 84, 100, 104, 106, 107, 109, 110, 114, 115, 116, 117], "readm": [4, 8, 12, 98, 102, 106], "tutori": [8, 10, 12, 13, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119], "you": [8, 9, 10, 12, 71, 93, 97, 100, 101, 102, 103, 104, 106, 109, 110, 113, 114, 115, 116, 117, 118, 119], "through": [8, 10, 12, 57, 62, 63, 98, 101, 102, 104, 107, 109, 110, 113, 114, 115, 119], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 103, 104, 106, 107, 109, 114, 115, 116, 117, 118], "framework": [8, 10, 12, 100, 104, 114], "The": [8, 10, 12, 13, 14, 19, 22, 27, 39, 41, 42, 44, 45, 55, 59, 73, 82, 88, 89, 90, 93, 100, 101, 102, 103, 104, 106, 109, 110, 114, 115, 116, 117, 118, 119], "contain": [8, 55, 85, 86, 89, 90, 106, 109, 116, 119], "new": [8, 12, 13, 97, 100, 101, 107, 109, 115, 116, 117, 119], "architectur": [8, 98, 104, 106, 114, 115, 117, 118], "micro": 8, "current": [8, 42, 48, 65, 73, 82, 90, 93, 96, 100, 101, 102, 106, 109, 110, 115, 116, 118], "support": [8, 12, 13, 30, 42, 43, 48, 65, 70, 71, 73, 85, 86, 96, 100, 101, 102, 103, 104, 106, 109, 114, 115, 116, 117, 118, 119], "which": [8, 10, 12, 21, 27, 55, 73, 78, 100, 101, 102, 103, 104, 106, 107, 110, 114, 115, 116, 117, 118, 119], "can": [8, 10, 12, 13, 26, 42, 46, 51, 55, 60, 71, 82, 83, 87, 97, 100, 101, 102, 103, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "quantize_": [8, 10, 12, 66, 70, 73, 82, 83, 84, 85, 86, 96, 98, 101, 102, 103, 104, 107], "sparsity_": 8, "function": [8, 12, 13, 26, 39, 55, 62, 63, 75, 80, 81, 82, 92, 93, 94, 96, 97, 100, 101, 102, 103, 106, 107, 109, 110, 114, 119], "To": [8, 10, 12, 13, 21, 55, 79, 100, 101, 102, 103, 104, 106, 107, 110, 115, 116, 117, 119], "correspond": [8, 12, 66, 73, 82, 101, 103, 106, 109, 118, 119], "string": [8, 36, 71, 93, 97], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 46, 97, 98, 101, 102, 103, 109, 110, 114, 115, 116, 117, 118, 119], "py": [8, 10, 13, 21, 97, 104, 105, 112, 113, 117, 118], "def": [8, 10, 12, 85, 96, 97, 100, 101, 102, 103, 107, 109, 110, 114, 115, 116, 117, 118, 119], "option": [8, 10, 13, 17, 21, 28, 31, 32, 33, 35, 36, 39, 42, 44, 46, 47, 49, 50, 55, 56, 57, 58, 62, 63, 65, 68, 70, 71, 73, 75, 76, 82, 83, 87, 89, 90, 91, 93, 96, 97, 100, 101, 102, 110, 115, 116, 117, 118, 119], "str": [8, 36, 39, 46, 71, 73, 82, 90, 91, 93, 96, 97, 100, 109, 110, 118], "kwarg": [8, 10, 13, 62, 63, 64, 65, 67, 71, 76, 86, 92, 93, 94, 97, 101, 109, 110], "aobaseconfig": [8, 73, 82, 96, 107, 110], "code": [8, 10, 47, 100, 101, 102, 104, 106, 107, 109, 111, 113, 115, 116, 117, 118, 119], "elif": [8, 110], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 17, 39, 42, 49, 50, 55, 59, 70, 71, 73, 88, 89, 93, 97, 101, 102, 104, 106, 109, 115, 116], "addit": [8, 12, 19, 24, 55, 97, 100, 101, 106, 109, 114, 115, 118, 119], "inform": [8, 13, 42, 101, 104, 106, 110, 114, 115], "need": [8, 10, 12, 42, 62, 63, 75, 85, 86, 92, 93, 97, 101, 102, 103, 104, 106, 109, 110, 115, 116, 117, 119], "pass": [8, 39, 49, 55, 57, 62, 63, 73, 75, 92, 97, 101, 107, 109, 110, 116, 119], "process": [8, 12, 19, 22, 24, 26, 27, 55, 90, 101, 106, 113, 114, 118], "here": [8, 9, 13, 73, 79, 87, 101, 102, 103, 104, 107, 109, 110, 114, 115, 116, 117, 118, 119], "return": [8, 10, 12, 13, 21, 22, 23, 39, 55, 59, 71, 82, 88, 89, 90, 96, 97, 100, 101, 102, 103, 107, 109, 110, 114, 115, 116, 117, 118, 119], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 109, 116], "now": [8, 10, 12, 41, 48, 56, 100, 101, 102, 106, 107, 109, 114, 115, 117, 119], "we": [8, 10, 12, 13, 23, 42, 45, 51, 53, 55, 56, 57, 58, 70, 71, 73, 79, 82, 87, 96, 100, 101, 102, 103, 104, 106, 107, 110, 114, 115, 116, 117, 118, 119], "throughout": 8, "note": [8, 10, 12, 60, 70, 79, 93, 101, 102, 104, 106, 109, 110, 116, 117, 118], "input": [8, 10, 13, 22, 23, 25, 36, 39, 40, 55, 56, 57, 58, 59, 73, 77, 82, 87, 88, 93, 96, 100, 101, 102, 104, 107, 109, 114, 115, 116, 117, 118, 119], "paramet": [8, 12, 13, 19, 22, 23, 29, 32, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 58, 59, 65, 71, 73, 76, 78, 79, 82, 87, 88, 89, 90, 93, 96, 97, 100, 101, 103, 104, 106, 109, 110, 114, 115], "like": [8, 10, 12, 19, 42, 55, 100, 101, 102, 103, 106, 109, 110, 114, 115, 116, 117, 118, 119], "bit": [8, 12, 27, 34, 41, 46, 53, 72, 104, 109, 110, 115, 117, 118], "width": [8, 27, 46, 72], "group": [8, 10, 12, 42, 43, 47, 48, 50, 53, 65, 67, 68, 69, 71, 75, 76, 78, 79, 83, 102], "size": [8, 10, 13, 14, 21, 23, 43, 46, 47, 48, 50, 53, 56, 58, 71, 87, 100, 102, 103, 104, 106, 107, 109, 110, 116], "etc": [8, 10, 42, 62, 63, 86, 101, 114, 119], "them": [8, 12, 55, 62, 63, 75, 92, 119], "append": [8, 106, 115, 116], "config": [8, 12, 36, 39, 42, 45, 55, 61, 62, 63, 64, 66, 70, 71, 72, 73, 82, 93, 96, 101, 102, 104, 106, 107, 110, 115, 117, 118], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": [8, 46], "group_siz": [8, 12, 43, 46, 47, 48, 50, 53, 62, 63, 65, 67, 70, 71, 73, 75, 76, 82, 102, 110], "system": [8, 10, 104], "model_architectur": 8, "type": [8, 10, 12, 13, 22, 23, 27, 36, 37, 38, 39, 42, 44, 45, 47, 48, 49, 51, 52, 54, 55, 59, 71, 74, 83, 84, 85, 86, 87, 88, 97, 98, 101, 103, 104, 106, 109, 110, 114, 115, 117, 118, 119], "defin": [8, 10, 19, 27, 37, 41, 62, 63, 75, 92, 93, 97, 101, 102, 106, 107, 109, 110, 114, 117, 118, 119], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 83, 84, 85, 92, 93, 97, 102, 103, 107, 109, 115, 116, 117, 119], "mycustommodel": 8, "torch": [8, 12, 13, 22, 23, 27, 29, 36, 39, 42, 44, 45, 47, 53, 55, 56, 58, 59, 62, 63, 65, 67, 68, 69, 70, 71, 73, 75, 76, 78, 79, 82, 83, 87, 88, 89, 90, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 109, 110, 113, 117, 118, 119], "nn": [8, 10, 12, 36, 39, 55, 60, 65, 67, 70, 73, 82, 89, 90, 96, 97, 100, 101, 102, 103, 104, 106, 107, 109, 110, 115, 116, 117, 119], "modul": [8, 10, 12, 36, 37, 38, 39, 40, 51, 52, 54, 55, 60, 62, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 92, 93, 96, 100, 101, 102, 103, 107, 114, 115, 116, 117, 118, 119], "__init__": [8, 12, 97, 102, 103, 107, 109, 110, 115, 116, 117], "self": [8, 12, 13, 97, 102, 103, 107, 109, 110, 115, 116, 117], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 23, 65, 68, 78, 87, 100, 101, 102, 103, 104, 106, 107, 110, 117, 118], "super": [8, 12, 102, 103, 107, 109, 115, 116, 117], "layer1": 8, "linear": [8, 10, 12, 22, 36, 39, 42, 43, 45, 47, 48, 49, 50, 53, 55, 60, 63, 65, 68, 69, 70, 73, 78, 79, 80, 81, 82, 90, 94, 96, 97, 100, 101, 102, 103, 104, 106, 107, 109, 114, 115, 116, 117, 119], "512": [8, 100], "bia": [8, 12, 63, 78, 79, 101, 102, 103, 107, 109, 110, 116, 119], "fals": [8, 12, 13, 31, 36, 44, 47, 49, 53, 55, 62, 63, 69, 70, 71, 73, 75, 76, 78, 79, 89, 93, 100, 101, 102, 103, 104, 107, 109, 110, 114, 115, 116, 118, 119], "activ": [8, 12, 42, 44, 46, 48, 49, 55, 62, 63, 65, 69, 70, 71, 73, 79, 85, 86, 89, 93, 98, 102, 104, 106, 107, 110, 114, 117, 118, 119], "relu": [8, 102, 114, 119], "layer2": 8, "forward": [8, 49, 55, 62, 63, 72, 75, 78, 92, 102, 103, 106, 107, 109, 110, 115, 116, 117], "x": [8, 53, 62, 63, 72, 75, 100, 102, 103, 104, 107, 109, 110, 113, 114, 115, 116, 117, 118], "updat": [8, 98, 102, 103, 106, 115, 116, 119], "create_model_and_input_data": 8, "handl": [8, 10, 22, 25, 26, 55], "model_typ": [8, 12, 110, 114], "m": [8, 10, 12, 82, 96, 100, 102, 103, 104, 107, 109, 115, 116, 117], "int": [8, 12, 13, 14, 21, 23, 26, 27, 28, 29, 31, 32, 33, 34, 41, 42, 43, 45, 46, 47, 48, 50, 53, 56, 57, 58, 62, 63, 65, 67, 68, 69, 71, 75, 76, 78, 79, 82, 87, 93, 97, 102, 107, 109, 110], "k": [8, 10, 88, 102, 103, 107, 109, 115, 116], "n": [8, 10, 12, 102, 103, 107, 109, 115, 116, 119], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 75, 78, 79, 82, 88, 100, 102, 103, 104, 107, 109, 110, 114, 115, 116, 117, 118], "cuda": [8, 10, 12, 13, 82, 100, 102, 103, 104, 106, 107, 109, 116], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 63, 100, 102, 103, 107, 109, 114, 115, 116, 117, 118], "when": [8, 10, 12, 13, 24, 56, 58, 73, 87, 97, 100, 101, 104, 106, 107, 110, 114, 115, 116, 117, 118, 119], "ad": [8, 12, 13, 58, 93, 97, 101, 106, 107, 109, 116], "dimens": [8, 10, 13, 27, 53, 56, 58, 59, 87, 100, 101, 109, 110, 115, 116], "ensur": [8, 22, 104, 116], "convent": 8, "where": [8, 25, 51, 53, 57, 67, 68, 69, 101, 106, 110, 119], "batch": [8, 104, 107, 116], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 109, 114, 117, 118], "data": [8, 12, 13, 14, 19, 22, 27, 42, 44, 45, 47, 49, 57, 84, 97, 98, 101, 103, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "typic": [8, 12, 23, 24, 101, 102, 103, 107, 110, 119], "compat": [8, 10, 22, 71, 102], "work": [8, 10, 12, 25, 46, 100, 103, 106, 109, 110, 115, 116, 117], "cpu": [8, 10, 13, 18, 103, 106, 107, 110, 114, 115, 116, 117], "other": [8, 12, 13, 19, 42, 72, 83, 93, 100, 103, 104, 106, 109, 110, 113, 115, 116, 117, 119], "target": [8, 10, 12, 13, 42, 44, 45, 47, 56, 62, 63, 71, 93, 102, 106, 114, 115, 116, 117, 118, 119], "method": [8, 10, 19, 22, 25, 26, 55, 82, 93, 102, 106, 107, 109, 114, 115, 116, 118, 119], "come": [8, 9, 100, 101, 104, 106, 107, 108, 116, 117, 118], "soon": [8, 9, 104, 108, 116], "file": [8, 10, 100, 104, 105, 109, 110, 112, 115, 116], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 73, 89, 98, 101, 102, 103, 106, 107, 109, 114, 115, 116, 117, 118], "quantization_config_recipe_nam": 8, "int8wo": 8, "int8dq": 8, "float8dq": [8, 104], "tensor": [8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 47, 48, 49, 55, 56, 57, 58, 59, 62, 63, 64, 72, 83, 84, 85, 86, 87, 88, 91, 93, 97, 98, 100, 102, 103, 106, 107, 113, 115, 117, 118], "row": [8, 10, 43, 59, 100, 101, 106], "float8wo": 8, "output_dir": 8, "result": [8, 12, 13, 55, 59, 88, 101, 106, 107, 115, 116, 117, 118, 119], "model_param": 8, "name": [8, 10, 37, 38, 51, 52, 54, 74, 82, 83, 84, 90, 93, 96, 97, 101, 104, 106, 109, 110, 114, 115, 116, 119], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 51, 62, 87, 100, 102, 104, 107, 115, 116], "max_pow": 8, "15": [8, 100, 102, 104], "torch_compile_mod": 8, "max": [8, 10, 51, 101, 102, 107, 109, 115, 116, 119], "autotun": [8, 10, 102, 107], "runner": 8, "gener": [8, 12, 13, 62, 63, 64, 72, 101, 102, 104, 106, 107, 109, 110, 111, 113, 114, 116, 117, 118, 119], "oss": 8, "databas": 8, "python": [8, 10, 102, 104, 106, 111, 113, 114, 115, 117, 118], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 104, 110], "specif": [8, 10, 12, 19, 22, 24, 25, 62, 63, 79, 93, 100, 101, 102, 103, 104, 106, 114, 117, 118, 119], "requir": [8, 12, 13, 24, 26, 83, 97, 101, 102, 104, 106, 109, 114, 117, 119], "mode": [8, 10, 46, 47, 55, 102, 107, 114, 116, 117, 118, 119], "extra_info": 8, "arch": 8, "nvidia": [8, 106], "a100": [8, 12, 102], "sxm4": 8, "80gb": [8, 102], "1024": [8, 82, 96, 102, 103, 117], "custom": [8, 12, 19, 73, 92, 98, 100, 101, 102, 106, 109, 110, 114, 115, 117, 119], "layer": [8, 22, 39, 42, 45, 47, 49, 50, 53, 55, 62, 63, 65, 67, 68, 69, 75, 76, 78, 79, 89, 90, 93, 94, 100, 104, 106, 107, 109, 110, 114, 119], "origin": [8, 12, 13, 23, 45, 49, 66, 87, 93, 101, 102, 103, 104, 106, 114, 115, 119], "metric": [8, 12, 93], "speedup": [8, 10, 12, 47, 100, 101, 102, 104, 106], "wrt": 8, "bf16": [8, 12, 56, 73, 102, 106, 117, 118], "benchmark_valu": 8, "25": [8, 102], "target_valu": 8, "0": [8, 10, 12, 13, 55, 62, 71, 75, 76, 87, 90, 93, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 112, 113, 115, 116, 118, 119], "depend": [8, 13, 46, 55, 103, 106, 109, 115, 116, 118], "step": [8, 12, 24, 40, 55, 73, 74, 100, 101, 106, 114, 115, 116, 117, 118, 119], "workflow": [8, 10, 82, 83, 96, 100, 102, 106, 119], "github": [8, 13, 21, 41, 102, 104], "action": [8, 110, 115, 116], "upload": 8, "verifi": [8, 102, 103, 109], "setup": [8, 104], "suit": [8, 10, 115, 117], "unittest": 8, "discov": 8, "out": [8, 10, 12, 25, 51, 55, 84, 93, 100, 101, 102, 106, 109, 114, 115, 116, 117], "memori": [8, 10, 12, 13, 100, 101, 102, 106, 109, 117, 118], "reduc": [8, 10, 12, 40, 73, 100, 104, 106, 117], "matrix": [8, 14, 17, 42, 44, 59, 83, 88, 93, 101, 102, 106, 117], "miss": [8, 106], "properli": [8, 103], "instal": [8, 10, 100, 101, 102, 104, 115, 118], "Not": [8, 106], "avail": [8, 10, 47, 101, 114, 115, 116, 117, 118], "check": [8, 10, 12, 13, 21, 101, 102, 103, 109, 114, 116, 119], "driver": 8, "basic": [8, 10, 24, 102, 107, 109], "shape": [8, 10, 13, 21, 55, 59, 88, 101, 102, 107, 109, 110, 115, 118], "comprehens": [8, 110, 117], "analysi": [8, 106], "enabl": [8, 10, 81, 97, 100, 101, 104, 110, 117], "profil": [8, 10], "onli": [8, 10, 12, 13, 18, 39, 42, 43, 45, 46, 47, 48, 49, 50, 53, 65, 73, 79, 96, 100, 102, 103, 104, 106, 109, 110, 114, 115, 117, 118, 119], "overhead": [8, 106, 110, 117], "multipl": [8, 10, 12, 17, 42, 44, 55, 59, 60, 83, 85, 88, 101, 102, 106, 107, 109, 110, 117, 119], "possibl": [8, 13, 101, 106, 115, 116, 117, 119], "consist": [8, 104, 106, 109, 117, 118, 119], "reproduc": [8, 104], "differ": [8, 10, 12, 19, 47, 57, 60, 87, 88, 100, 101, 102, 103, 104, 106, 109, 110, 115, 116, 117, 119], "case": [8, 9, 10, 55, 73, 88, 104, 106, 109, 110, 114, 115, 119], "user": [8, 10, 12, 42, 55, 60, 73, 79, 97, 98, 100, 101, 102, 104, 106, 107, 109, 113, 115, 116, 117, 118, 119], "more": [8, 10, 12, 13, 41, 46, 47, 48, 53, 55, 100, 101, 102, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118], "about": [8, 10, 12, 47, 101, 102, 103, 104, 106, 115, 116, 117, 119], "compon": [8, 101, 109, 110], "see": [8, 10, 12, 13, 21, 41, 97, 100, 101, 102, 103, 104, 106, 107, 109, 110, 114, 115, 119], "directori": [8, 100], "intend": [9, 101, 115], "provid": [9, 10, 12, 19, 22, 25, 26, 55, 56, 60, 77, 97, 100, 101, 104, 106, 109, 110, 115, 116, 118, 119], "instruct": [9, 12, 101, 102, 104, 115, 116, 117], "most": [9, 10, 24, 73, 101, 104, 106, 110, 115, 116, 119], "fequent": 9, "have": [9, 10, 12, 46, 47, 51, 55, 67, 68, 69, 87, 93, 97, 101, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "ani": [9, 10, 24, 55, 65, 67, 77, 91, 93, 101, 106, 109, 114, 116, 118], "answer": [9, 106], "creat": [9, 10, 13, 29, 30, 32, 100, 106, 109, 114, 115, 117, 118, 119], "an": [9, 12, 13, 26, 31, 32, 55, 70, 71, 73, 79, 93, 97, 98, 100, 101, 102, 104, 106, 107, 109, 114, 115, 116, 117, 118, 119], "issu": [9, 101, 102, 109, 117], "start": [10, 12, 37, 38, 51, 52, 54, 55, 74, 83, 84, 100, 101, 104, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "read": [10, 109], "overview": [10, 98, 102, 110], "page": [10, 102, 117], "first": [10, 23, 55, 59, 73, 93, 97, 101, 104, 107, 109, 110, 115, 116, 119], "contribut": [10, 102, 106], "exist": [10, 52, 73, 100, 101, 106, 107, 109, 115, 119], "base": [10, 19, 24, 42, 51, 61, 72, 73, 77, 85, 86, 93, 97, 101, 102, 106, 109, 110, 114, 115, 116, 117, 118, 119], "api": [10, 55, 101, 102, 106, 107, 109, 114, 115, 116, 117, 118], "quant_api": [10, 82, 103, 104, 107], "float8tensor": [10, 42, 45, 85, 101], "e": [10, 12, 13, 41, 51, 55, 56, 58, 60, 71, 73, 82, 85, 87, 97, 100, 101, 103, 107, 109, 114, 119], "g": [10, 12, 13, 41, 51, 55, 56, 58, 60, 71, 73, 82, 85, 87, 97, 101, 103, 107, 109, 114, 119], "oper": [10, 12, 13, 17, 19, 22, 49, 57, 101, 102, 104, 114, 115, 116, 117, 118], "make": [10, 101, 102, 109, 110, 115, 119], "trainabl": [10, 12, 101, 109], "add": [10, 24, 109, 113, 117, 119], "parallel": [10, 100, 109, 110], "primit": [10, 13, 21, 109, 115], "op": [10, 12, 13, 21, 42, 47, 55, 82, 83, 97, 102, 106, 109, 110, 115, 116, 117, 119], "slight": [10, 106], "variat": [10, 101], "quant_primit": [10, 13, 21, 107], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 17, 25, 27, 39, 41, 42, 46, 47, 55, 56, 58, 60, 62, 63, 70, 73, 82, 84, 87, 88, 93, 97, 100, 101, 102, 103, 104, 106, 107, 110, 114, 115, 116, 117, 118, 119], "structur": [10, 12, 25, 96, 101, 102, 103, 106, 109, 115], "deriv": [10, 13, 57, 86, 87], "pack": [10, 13, 15, 26, 27, 41, 43, 46, 47, 53, 84], "format": [10, 13, 22, 23, 41, 46, 47, 84, 104, 106, 115, 116, 119], "understand": [10, 100, 117, 119], "concept": [10, 101, 113, 115, 117, 118, 119], "i": [10, 12, 88, 100, 101, 104, 106, 114, 115, 116], "doe": [10, 12, 24, 47, 73, 101, 106, 109, 115, 117, 118], "alreadi": [10, 13, 55, 109, 119], "could": [10, 101, 109, 114, 115, 117, 118, 119], "context": [10, 117, 118], "also": [10, 12, 55, 71, 82, 101, 102, 103, 106, 107, 109, 110, 115, 118, 119], "write": [10, 98, 102, 114, 115, 116], "own": [10, 12, 98, 100, 102, 106, 107, 115, 116, 119], "torchaobasetensor": [10, 110], "help": [10, 12, 100, 101, 104, 110, 114, 115], "common": [10, 73, 83, 84, 85, 86, 98, 100, 101, 106], "specifi": [10, 12, 13, 36, 39, 50, 53, 60, 62, 63, 64, 72, 73, 79, 82, 83, 87, 93, 96, 100, 101, 106, 114, 115, 116, 119], "non": [10, 55, 97, 106, 109, 114, 117, 118], "attribut": [10, 12, 97, 101, 109, 110, 117, 118], "mytensor": [10, 97], "tensor_data_nam": [10, 97], "qdata": [10, 101], "scale": [10, 13, 19, 22, 29, 32, 37, 40, 42, 44, 51, 54, 56, 57, 58, 59, 65, 71, 76, 77, 78, 79, 87, 89, 90, 97, 101, 106, 107, 109, 110, 119], "tensor_attribute_nam": [10, 97], "With": [10, 109, 115, 117, 119], "abov": [10, 12, 47, 51, 101, 103, 106, 107, 109, 115, 116, 119], "ll": [10, 51, 100, 101, 104, 109, 115, 116, 119], "doc": [10, 100, 101, 102, 104, 109], "mani": [10, 101, 106, 109], "still": [10, 12, 101, 106, 115, 119], "affinequantizedtensor": [10, 21, 29, 30, 32, 42, 45, 102, 103, 107, 109], "plan": [10, 42, 45, 116], "move": [10, 82, 107, 110, 116, 117], "awai": 10, "from": [10, 12, 13, 23, 24, 29, 30, 32, 41, 47, 48, 57, 66, 70, 73, 82, 87, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119], "abstract": [10, 101], "easier": [10, 119], "peopl": [10, 101, 103, 110, 119], "implement": [10, 12, 36, 75, 76, 78, 79, 83, 97, 101, 103, 106, 107, 114, 115, 119], "regist": [10, 62, 63, 75, 92, 97, 101, 109], "mai": [10, 13, 57, 71, 101, 103, 107, 115, 116, 117, 118, 119], "well": [10, 19, 55, 101, 102, 106, 115, 116, 119], "int4": [10, 12, 15, 18, 43, 47, 48, 51, 62, 63, 65, 67, 68, 69, 70, 71, 73, 75, 76, 78, 79, 82, 96, 101, 102, 103, 104, 110], "access": [10, 49, 114], "my_custom_op": 10, "call": [10, 12, 13, 55, 62, 63, 75, 92, 101, 102, 103, 106, 107, 109, 110, 116, 118], "want": [10, 82, 96, 101, 102, 103, 106, 109, 110, 114, 115, 116, 119], "my_mm_for_mp": 10, "aten": [10, 47, 97, 101, 102, 109, 110, 114, 115, 116, 117, 118], "default": [10, 12, 13, 14, 17, 24, 26, 27, 42, 44, 45, 46, 47, 53, 55, 56, 58, 65, 71, 79, 82, 89, 90, 97, 100, 101, 102, 109, 110, 114, 115, 116, 117, 118, 119], "_": [10, 97, 100, 101, 107, 110, 114, 115, 116, 117], "func": [10, 97, 101, 109, 110], "arg": [10, 13, 62, 63, 64, 65, 67, 76, 93, 97, 101, 109, 110, 116, 119], "re": [10, 100, 101, 103, 104, 109, 115, 116], "input_tensor": [10, 23, 101, 110], "weight_tensor": [10, 101, 110], "some": [10, 55, 82, 93, 97, 101, 102, 104, 106, 107, 109, 114, 115, 116, 117, 118, 119], "choic": [10, 47], "mm": [10, 82, 83, 109, 115], "recommend": [10, 12, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 100, 101, 114, 117, 118], "wai": [10, 13, 55, 73, 100, 101, 104, 106, 107, 109, 115, 116, 119], "repres": [10, 13, 14, 17, 19, 30, 36, 61, 71, 84, 87, 93, 101, 103, 109, 115, 116], "group_mm": 10, "auto": [10, 42, 83, 104, 110], "develop": [10, 102, 115, 116, 119], "choos": [10, 86, 101, 106, 109, 115, 117], "whatev": 10, "think": [10, 110], "fastest": [10, 55], "under": [10, 12, 83, 104], "condit": 10, "so": [10, 12, 55, 100, 101, 102, 103, 106, 109, 115, 116, 119], "don": [10, 93, 100, 101, 102, 106, 110, 119], "t": [10, 93, 97, 100, 101, 102, 106, 107, 109, 110, 115, 116, 119], "worri": 10, "debug": [10, 89], "purpos": [10, 100, 101, 109, 115], "ha": [10, 12, 13, 73, 104, 106, 109, 110, 114, 115, 116, 118, 119], "hardwar": [10, 42, 46, 102, 104, 106], "h100": [10, 101], "sm89": 10, "sm90": 10, "librari": [10, 83, 98, 101, 103], "whether": [10, 12, 47, 53, 54, 55, 56, 71, 109], "fbgemm_gpu_genai": [10, 83, 101], "granular": [10, 13, 37, 42, 44, 46, 47, 48, 50, 53, 56, 58, 62, 63, 65, 71, 72, 87, 100, 101, 104, 107, 110], "per": [10, 12, 13, 43, 45, 47, 48, 49, 50, 53, 56, 58, 65, 67, 68, 69, 71, 75, 76, 78, 79, 87, 93, 100, 101, 102, 106, 107, 118], "_choose_scale_float8": [10, 101], "_quantize_affine_float8": [10, 101], "_scaled_mm": [10, 101], "kerenel": 10, "fbgemm": [10, 83, 84, 101, 106], "f8f8bf16_rowwis": [10, 101], "level": [10, 93, 101, 106, 109, 114, 115, 117, 118], "reus": [10, 109], "allow": [10, 79, 101, 102, 106, 109, 114, 115, 116, 117, 119], "appli": [10, 12, 13, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 60, 64, 65, 70, 72, 73, 82, 96, 97, 101, 102, 104, 106, 110, 116], "convers": [10, 12, 13, 39], "weight": [10, 12, 22, 23, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 62, 63, 65, 67, 68, 69, 71, 73, 75, 76, 78, 79, 82, 85, 93, 96, 98, 100, 102, 103, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119], "filter": [10, 12, 39, 55, 100, 107], "should": [10, 12, 13, 40, 46, 58, 62, 63, 66, 73, 75, 92, 93, 97, 100, 106, 110, 114, 115, 119], "algorithm": [10, 47, 53, 104, 106, 114], "dynam": [10, 12, 35, 36, 40, 42, 43, 46, 48, 49, 65, 69, 71, 79, 96, 104, 107, 109, 115, 116, 117], "quant": [10, 13, 21, 41, 101, 104, 110, 115, 118, 119], "In": [10, 12, 73, 100, 101, 102, 106, 107, 109, 114, 115, 116, 117, 118, 119], "order": [10, 55, 60, 97, 106, 109, 119], "aim": [10, 106, 118], "run": [10, 12, 40, 55, 62, 63, 75, 82, 89, 92, 100, 101, 102, 104, 106, 109, 113, 114, 115, 116, 117, 118, 119], "fullgraph": [10, 102], "true": [10, 12, 13, 31, 36, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 62, 63, 70, 71, 73, 81, 82, 89, 96, 100, 102, 103, 104, 107, 109, 110, 114, 115, 116, 117, 119], "remov": [10, 56, 93, 100, 106, 110, 115, 116], "unnecessari": 10, "graph": [10, 102, 115, 116, 119], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 102, 104, 107, 109, 113, 116, 117, 118], "inductor": [10, 55, 98, 102, 114, 115], "save": [10, 12, 93, 100, 102, 103, 104, 110], "load": [10, 103, 104, 110], "relev": [10, 47, 101, 113], "object": [10, 27, 82, 96, 97, 101, 109, 115, 116, 119], "safe": [10, 88], "global": [10, 106, 109], "after": [10, 12, 40, 55, 100, 101, 103, 106, 114, 115, 116, 117, 118, 119], "2": [10, 13, 16, 18, 22, 25, 42, 45, 47, 51, 55, 62, 71, 75, 76, 87, 94, 96, 98, 100, 101, 106, 107, 109, 113], "5": [10, 12, 51, 62, 90, 93, 102, 104, 106, 110, 113, 115, 116], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 101], "checkout": [10, 13, 21, 98, 101], "huggingfac": 10, "transform": [10, 12, 13, 97, 107, 114, 115, 116, 117, 118], "deseri": [10, 115, 116], "save_pretrain": [10, 104], "push_to_hub": [10, 104, 110], "from_pretrain": [10, 12, 104, 110], "diffus": 10, "just": [10, 51, 71, 101, 103, 106, 109, 115, 116, 119], "talk": [10, 101, 104], "train": [10, 36, 60, 71, 73, 98, 102, 106, 109, 119], "fsdp": [10, 101], "mydtypetensor": 10, "put": [10, 96, 117, 119], "developer_api_guid": 10, "folder": [10, 104, 115, 116], "cover": [10, 113, 115, 118, 119], "follow": [10, 12, 47, 71, 73, 97, 100, 101, 102, 104, 106, 107, 109, 114, 115, 116, 117, 118, 119], "executorch": [10, 48, 82, 98, 102, 115, 116], "torchchat": 10, "dtensor": [10, 109], "copi": [10, 13, 93, 102, 103, 106, 107, 109, 116, 117], "past": [10, 106], "adapt": [10, 100, 107], "befor": [10, 12, 73, 82, 101, 103, 104, 106, 107, 109, 115, 116, 119], "do": [10, 52, 55, 59, 82, 101, 104, 106, 107, 109, 110, 115, 116, 117, 119], "singl": [10, 12, 35, 40, 42, 55, 57, 97, 100, 101, 102, 106, 115, 119], "comput": [10, 22, 26, 40, 45, 62, 63, 75, 83, 92, 93, 101, 106, 107, 109, 115, 116, 117, 118], "intens": 10, "get": [10, 12, 23, 79, 97, 100, 101, 102, 104, 106, 110, 114, 115, 116, 117, 119], "sens": [10, 101, 109], "d": [10, 97, 104, 116], "benchmark_aq": 10, "s": [10, 12, 13, 51, 55, 56, 58, 83, 87, 97, 100, 101, 102, 104, 106, 107, 109, 115, 116, 117, 118, 119], "import": [10, 12, 66, 70, 73, 82, 96, 102, 103, 104, 106, 107, 109, 110, 113, 114, 117, 118], "A": [10, 12, 13, 27, 55, 57, 92, 97, 101, 106, 109, 110, 115], "quick": [10, 98], "chang": [10, 82, 100, 102, 103, 104, 106, 107, 109, 114, 115, 116, 118, 119], "interest": [10, 106, 109], "print_op_and_shap": 10, "output": [10, 12, 36, 55, 56, 58, 87, 100, 101, 102, 104, 106, 113, 114, 115, 116, 117, 118, 119], "torch_func": 10, "built": [10, 100, 109], "_c": 10, "tensorbas": 10, "all": [10, 40, 51, 55, 57, 62, 63, 65, 67, 75, 77, 92, 93, 94, 97, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 114, 115, 117, 119], "benchmark_your_kernel": 10, "helper": [10, 80, 81, 97], "right": [10, 106, 115], "1": [10, 22, 27, 37, 38, 42, 45, 47, 51, 52, 53, 54, 55, 74, 83, 84, 86, 87, 93, 98, 101, 102, 103, 105, 106, 107, 109, 112, 113, 115, 116], "feel": [10, 101, 106, 109, 110], "free": [10, 101, 109], "either": [10, 13, 42, 73, 93, 104, 106, 116, 117, 118], "one": [10, 42, 55, 57, 62, 63, 73, 75, 92, 100, 101, 106, 109, 110, 116, 119], "probabl": 10, "keep": [10, 22, 49, 93, 101, 115], "futur": [10, 41, 107, 110, 115, 116, 117, 119], "llama": [10, 12, 104, 110, 114], "llama2": 10, "llama3": [10, 12, 100], "sam": 10, "modifi": [10, 39, 82, 93, 100, 106, 109], "friendli": 10, "compar": [10, 12, 47, 93, 100, 101, 104, 115, 117, 119], "techniqu": [10, 12, 100, 103, 104, 106, 107, 109, 110], "bound": [10, 42, 104, 106, 110], "each": [10, 23, 55, 65, 71, 76, 78, 79, 89, 92, 97, 101, 106, 107, 109, 110, 115, 116, 119], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 51, 87, 101, 102, 106, 107, 109, 119], "know": [10, 55, 109], "end": [12, 100, 101, 104, 106, 109, 110, 113, 116, 119], "pre": [12, 19, 22, 26, 98, 102, 104, 106, 119], "serv": [12, 13, 19, 98, 100, 109, 118], "flow": [12, 48, 100, 104, 106, 107, 114, 115, 116, 117, 118], "leverag": [12, 100, 102, 104, 109, 117, 118], "partner": [12, 100, 104], "showcas": [12, 100, 104], "focus": [12, 100, 101, 104, 106], "domain": [12, 13, 47, 54, 56, 58, 71, 100], "demonstr": [12, 100, 101, 102, 104, 109, 114, 116], "dure": [12, 13, 21, 49, 55, 58, 71, 73, 90, 100, 102, 104, 106, 107, 109, 114, 116], "numer": [12, 55, 73, 78, 79, 100, 106, 115, 116, 117], "goal": [12, 73], "mitig": [12, 106], "degrad": [12, 73, 106], "eventu": [12, 73, 100], "blog": 12, "resourc": [12, 109], "small": 12, "matric": [12, 25, 106], "freez": [12, 116, 117, 118], "checkpoint": [12, 100, 104, 110], "effici": [12, 26, 78, 102, 106, 107, 118], "paper": [12, 41, 106, 113], "speed": [12, 82, 104, 106, 114], "up": [12, 23, 71, 82, 100, 101, 102, 106, 114, 115, 116, 119], "high": [12, 13, 28, 29, 30, 31, 32, 73, 100, 101, 104, 106, 107, 109, 114, 115, 117, 118], "precis": [12, 13, 28, 29, 30, 31, 32, 45, 49, 65, 68, 69, 73, 76, 78, 79, 101, 107, 109, 114, 117, 118], "similar": [12, 106, 107, 116, 117], "inevit": 12, "actual": [12, 45, 73, 101, 107, 109, 110, 115, 116, 119], "presum": 12, "been": [12, 55, 97, 109, 116, 117, 118, 119], "successfulli": [12, 106], "recent": [12, 98], "releas": [12, 102, 117], "1b": [12, 110], "3b": 12, "llamaguard": 12, "8b": [12, 100], "improv": [12, 100, 104, 106, 115, 118, 119], "qualiti": [12, 106], "involv": [12, 17, 73, 106], "two": [12, 21, 25, 42, 73, 101, 102, 106, 109, 114, 115, 116, 117, 119], "separ": [12, 62, 63, 71, 106, 110, 115, 119], "prepar": [12, 55, 60, 65, 67, 73, 89, 93, 106, 114, 117, 118, 119], "convert": [12, 13, 21, 23, 28, 31, 33, 34, 36, 60, 66, 67, 73, 82, 96, 100, 101, 104, 106, 114, 117, 118, 119], "fake": [12, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 100, 115, 116, 119], "mean": [12, 13, 23, 51, 56, 58, 87, 97, 100, 101, 102, 106, 115, 116, 119], "valu": [12, 13, 23, 36, 37, 38, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 74, 83, 84, 87, 89, 93, 101, 106, 107, 109, 114, 115, 116, 119], "map": [12, 49, 51, 71, 97, 101, 109, 115, 119], "without": [12, 66, 101, 106, 110, 117, 119], "cast": [12, 13, 35, 37], "lower": [12, 42, 48, 101, 102, 104, 106, 107, 116], "replac": [12, 90, 106, 110], "real": [12, 101, 102, 115, 119], "perform": [12, 13, 26, 40, 46, 49, 50, 55, 59, 62, 63, 67, 68, 69, 75, 88, 89, 92, 100, 102, 106, 107, 109, 110, 114, 116, 117, 118], "There": [12, 73, 101, 107, 109, 115, 119], "directli": [12, 51, 57, 73, 101, 106, 107, 109], "loop": [12, 100, 106], "distribut": [12, 100, 107, 109, 110, 114], "recip": [12, 36, 62, 63, 75, 92], "instead": [12, 47, 57, 62, 63, 66, 70, 71, 73, 75, 92, 100, 102, 106, 109, 116, 117, 118, 119], "command": [12, 100, 102], "regular": [12, 114, 117, 118], "nnode": 12, "nproc_per_nod": 12, "4": [12, 16, 22, 25, 34, 46, 94, 96, 101, 102, 103, 104, 106, 109, 115, 116], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 103, 104, 107, 115, 116], "16": [12, 63, 100], "equival": [12, 71, 90, 106, 116, 117, 119], "asymmetr": [12, 46, 47, 48, 51, 53, 56, 71, 102, 107, 114, 118, 119], "token": [12, 48, 49, 69, 71, 79, 100, 104], "int8": [12, 23, 48, 49, 50, 63, 69, 70, 71, 73, 79, 82, 86, 96, 101, 104, 109, 115, 117, 118, 119], "symmetr": [12, 42, 44, 45, 46, 48, 49, 50, 51, 56, 62, 65, 71, 109, 114, 115, 118, 119], "configur": [12, 17, 35, 36, 39, 42, 43, 44, 45, 47, 48, 49, 50, 53, 82, 96, 100, 101, 102, 104, 117, 118, 119], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 116], "same": [12, 13, 42, 56, 57, 58, 79, 87, 88, 96, 100, 101, 106, 107, 109, 116, 118, 119], "wa": [12, 109, 116], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": 12, "int8dynactint4weightquant": 12, "groupsiz": [12, 68, 69, 78, 79, 87], "32": [12, 46, 47, 48, 63, 70, 71, 73, 75, 76, 82, 96, 100, 102, 103, 104, 107, 109, 116], "hellaswag": [12, 104], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 104], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 104], "ckpt": 12, "llama3_token": 12, "path": [12, 82, 88, 102, 104, 114, 115, 116, 117, 119], "tmp": [12, 102], "meta": [12, 103, 110, 119], "print": [12, 93, 102, 103, 104, 109, 113, 115, 116], "version": [12, 18, 42, 45, 47, 71, 101, 102, 109, 110, 115, 116, 119], "shot": [12, 106], "stderr": 12, "none": [12, 13, 17, 21, 28, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 50, 51, 52, 54, 55, 56, 57, 58, 62, 63, 65, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 89, 90, 91, 93, 96, 101, 107, 109, 110, 114, 115, 116, 118], "acc": [12, 115, 116], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 102, 106, 119], "openassist": 12, "oasst1": 12, "dataset": [12, 100, 104, 114, 117, 118], "find": [12, 23, 106, 115, 119], "achiev": [12, 23, 100, 106, 107, 109, 116, 117], "higher": [12, 100, 109, 114, 115, 117, 118], "accuraci": [12, 100, 104, 106, 107, 114, 116, 117], "than": [12, 27, 71, 100, 101, 106, 109, 115], "recov": [12, 106, 116], "69": [12, 107], "8": [12, 26, 27, 46, 47, 51, 62, 63, 68, 78, 100, 101, 102, 104, 110, 117, 118], "overal": [12, 98, 102, 115, 119], "vanilla": 12, "compos": [12, 60, 101, 106, 109, 115, 116, 119], "lora": 12, "yield": [12, 106], "89x": 12, "usag": [12, 13, 40, 55, 60, 62, 63, 66, 70, 71, 73, 97, 98, 100, 104, 117, 118], "36": [12, 100, 104], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 17, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 57, 71, 82, 89, 93, 102, 106, 114, 116, 117, 118], "try": [12, 106, 109, 115], "fsdp2": [12, 100], "yaml": 12, "onc": [12, 55, 106], "complet": [12, 55, 104, 114, 118], "qat_out": 12, "quatiz": 12, "document": [12, 109, 110, 114, 115, 117], "prefer": [12, 42, 101, 102, 109], "These": [12, 106, 109, 114, 115, 116, 119], "what": [12, 13, 21, 55, 100, 101, 102, 104, 106, 107, 110, 113, 115, 119], "hood": 12, "mini": [12, 104], "gpu": [12, 98, 100, 102, 110, 113, 114], "smaller": [12, 27, 46, 47, 48, 53, 102, 103], "fit": [12, 13, 26, 101, 103], "adjust": [12, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 100], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 100], "max_seq_len": 12, "train_loop": [12, 73], "sgd": 12, "lr": [12, 100], "001": 12, "momentum": [12, 116], "9": [12, 100], "weight_decai": 12, "1e": [12, 100], "loss_fn": 12, "crossentropyloss": [12, 115, 116], "rang": [12, 51, 100, 106, 107, 115, 116], "randint": 12, "loss": [12, 100, 106, 115, 116], "backward": [12, 40, 100, 106, 116], "zero_grad": [12, 100, 116], "next": [12, 100, 107, 115, 116, 117, 118], "scheme": [12, 49, 50, 62, 63, 73, 104, 114], "although": [12, 62, 63, 75, 92, 109], "integ": [12, 13, 31, 32, 46, 47, 51, 54, 56, 58, 59, 71, 72, 88, 107, 115, 116, 117], "arithmet": [12, 73], "float": [12, 13, 21, 23, 31, 33, 34, 41, 42, 47, 51, 54, 55, 56, 57, 58, 62, 71, 75, 76, 87, 90, 93, 101, 102, 103, 109, 115, 116, 119], "float32": [12, 13, 29, 58, 67, 69, 71, 75, 76, 79, 87, 103, 104, 106, 107, 109, 117, 118, 119], "becaus": [12, 13, 22, 100, 103, 106, 109, 116, 119], "int8dynamicactivationint4weightconfig": [12, 73, 79], "qatconfig": [12, 66, 70, 74], "swap": [12, 39, 65, 67, 100, 106, 107, 116], "fakequantizedlinear": [12, 65, 66, 80, 81], "base_config": [12, 73], "exact": [12, 79, 115, 116], "attun": 12, "benefici": 12, "later": [12, 101, 109, 115, 116, 118], "readi": [12, 100, 102, 104, 107, 109, 116], "did": [12, 48], "altern": [12, 71, 107, 109, 117, 118], "legaci": 12, "offer": [12, 109, 115], "customiz": [12, 82], "unlik": [12, 107], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 102, 107, 114, 115, 116, 117, 118, 119], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 114, 115, 117, 118], "footprint": 12, "extens": [12, 109, 115, 117], "addition": [12, 117, 118], "frozen": 12, "further": [12, 109, 114, 115, 116, 117], "nf4": [12, 23], "propos": [12, 93], "express": [12, 102, 109, 114, 115, 116, 119], "subclass": [12, 13, 21, 39, 55, 62, 63, 75, 83, 84, 92, 96, 97, 102, 103, 106], "nf4tensor": 12, "cleanli": 12, "compil": [12, 55, 82, 88, 98, 100, 101, 102, 107, 109, 117, 118], "simpli": [12, 55, 106, 107, 109], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 31, 36, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 62, 63, 69, 71, 75, 76, 78, 79, 81, 82, 89, 96, 107], "quantization_kwarg": 12, "No": [12, 101, 103, 106], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 101, 107, 109, 110], "though": [12, 109], "shown": [12, 104, 106, 116, 119], "competit": [12, 100], "baselin": [12, 100, 104, 115], "while": [12, 62, 63, 73, 75, 85, 92, 93, 104, 106, 109, 114, 115, 119], "even": [12, 13, 100, 106, 119], "newer": 12, "mxfp4": [12, 101], "nvfp4": [12, 101], "blackwel": 12, "reap": 12, "benefit": [12, 106, 109, 115, 118], "vari": [12, 13, 115, 116, 117, 118], "tradeoff": [12, 106], "incorpor": 12, "its": [12, 46, 106, 109, 110, 115, 119], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 100, 101, 109, 110, 115], "yet": [12, 48, 52, 73, 109, 110, 116, 117, 118], "invok": [12, 117], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 104, 110], "torchaoconfig": [12, 104, 110], "int8weightonlyconfig": [12, 110], "base_model": 12, "quantization_config": [12, 104, 110, 118], "peft_config": 12, "throughput": [12, 100, 104], "increas": [12, 106, 115], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 35, 36, 101], "initi": [12, 13, 77, 101, 102, 103, 116], "experi": [12, 100, 118], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 100, 102, 115], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 100], "074": [12, 100], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 100], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 100, 118, 119], "407": [12, 100], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 100], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 21, 97, 107], "aqttensorimpl": [13, 21], "block_siz": [13, 19, 21, 23, 28, 29, 31, 32, 33, 34, 56, 57, 58, 87, 101, 102, 107], "tupl": [13, 21, 23, 28, 29, 31, 32, 33, 42, 44, 56, 57, 58, 77, 87, 93, 97, 109, 110, 115, 116, 119], "quant_min": [13, 21, 31, 32, 33, 51, 56, 57, 58, 87, 102, 109, 118, 119], "union": [13, 21, 36, 42, 44, 56, 58, 71, 82, 87], "quant_max": [13, 21, 31, 32, 33, 51, 56, 57, 58, 87, 102, 109, 118, 119], "zero_point_domain": [13, 21, 31, 32, 33, 47, 56, 57, 71], "zeropointdomain": [13, 21, 31, 32, 33, 47, 56, 57, 71], "stride": [13, 21, 109], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 96, 97, 104, 111, 113], "affin": [13, 15, 16, 17, 18, 22, 25, 26, 31, 58, 87, 101], "point": [13, 21, 33, 41, 47, 51, 54, 58, 71, 76, 77, 78, 79, 100, 101, 102, 103, 106, 107, 109, 115, 119], "quantized_tensor": 13, "float_tensor": [13, 109], "zero_point": [13, 19, 32, 47, 54, 56, 57, 58, 87, 97, 101, 106, 107, 109, 119], "happen": [13, 21, 55, 101, 109, 115, 117], "choose_qparam": [13, 101], "dequant": [13, 21, 23, 47, 58, 101, 102, 109, 110, 115, 117, 118, 119], "http": [13, 21, 41, 55, 93, 102, 104, 106, 118], "com": [13, 21, 41, 104], "ao": [13, 21, 106, 110], "blob": [13, 21], "main": [13, 21, 47, 101, 102, 104, 106, 107, 109, 115, 119], "three": [13, 55, 93, 96, 117, 118], "choose_qparams_affin": [13, 47, 57], "quantize_affin": [13, 47], "qand": 13, "dequantize_affin": [13, 47], "look": [13, 100, 101, 106, 114, 115, 116, 117, 118], "extern": [13, 117], "regardless": 13, "intern": [13, 26], "represent": [13, 19, 30, 47, 97, 106, 110, 115, 119], "orient": 13, "field": [13, 71, 74, 97, 119], "impl": [13, 97], "storag": [13, 22, 106], "store": [13, 22, 23, 27, 49, 85, 92, 101, 106, 110, 115, 116], "plain": [13, 47, 84, 101, 110], "int_data": [13, 109], "kernel": [13, 15, 16, 18, 22, 26, 41, 42, 46, 47, 78, 82, 83, 84, 102, 104, 106, 114, 117, 118], "element": [13, 25, 27, 55, 56, 58, 65, 76, 78, 79, 87, 97, 101, 106], "share": [13, 56, 58, 87, 106], "qparam": [13, 56, 58, 87], "minimum": [13, 55, 56, 58, 87], "maximum": [13, 56, 58, 87, 89], "zero": [13, 25, 47, 49, 56, 58, 71, 76, 77, 78, 79, 93, 106, 107, 119], "subtract": [13, 23], "unquant": [13, 119], "given": [13, 21, 34, 86, 100, 106, 110, 119], "classmethod": [13, 21, 85, 97, 107, 109, 110], "from_hp_to_floatx": 13, "input_float": [13, 21, 28, 29, 30, 31, 32, 33, 91], "target_dtyp": [13, 28, 29, 31, 32, 35, 36, 56, 57, 101, 107], "_layout": [13, 21, 28, 29, 30, 31, 32, 33, 97, 102, 107], "layout": [13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 47, 48, 49, 96, 97, 106], "scale_dtyp": [13, 28, 29, 31, 56, 57, 107], "float8": [13, 16, 17, 28, 29, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 65, 86, 98, 104, 107], "from_hp_to_floatx_stat": 13, "static": [13, 19, 23, 29, 32, 36, 44, 57, 71, 98, 102, 115, 116, 117, 118, 119], "from_hp_to_fpx": 13, "floatx": [13, 30], "ebit": [13, 30, 41], "mbit": [13, 30, 41], "float1": [13, 30], "float7": [13, 30], "from_hp_to_intx": [13, 21], "mapping_typ": [13, 31, 48, 56, 57, 71], "mappingtyp": [13, 31, 48, 49, 56, 57, 71, 107], "ep": [13, 31, 56, 57, 71, 107, 116, 118, 119], "zero_point_dtyp": [13, 31, 56, 57, 107], "preserve_zero": [13, 31, 47, 56, 57], "plainlayout": [13, 31, 32, 48, 49, 97, 107], "use_hqq": [13, 31, 47, 53, 110], "from_hp_to_intx_stat": 13, "argument": [13, 26, 55, 58, 71, 73, 82, 85, 97, 100, 101, 104, 117], "correct": [13, 22, 115, 116], "otherwis": [13, 50, 60, 71, 116], "desir": [13, 55, 107], "gradient": [13, 98, 106], "implicitli": [13, 119], "complex": [13, 106], "non_block": 13, "memory_format": [13, 117, 118], "preserve_format": 13, "accord": 13, "c": [13, 97, 102, 109, 117, 118], "rule": 13, "truncat": 13, "part": [13, 98, 106, 109, 116], "cannot": [13, 106, 107, 110], "inf": 13, "long": [13, 109, 115], "behavior": [13, 19, 60, 110, 115, 116], "undefin": [13, 60, 93], "across": [13, 93, 104, 106, 109, 110], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 106, 116], "host": [13, 110], "both": [13, 42, 73, 79, 101, 102, 106, 107, 109, 115, 117, 118, 119], "pin": 13, "pageabl": 13, "howev": [13, 106, 110, 116, 119], "caution": 13, "advis": [13, 101], "good": [13, 102, 109, 119], "pin_memori": 13, "match": [13, 58, 59, 78, 79, 97, 106, 115], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "blocksiz": 14, "64": [14, 34, 47, 53, 65, 103, 104, 107, 109, 110], "block": [14, 23, 93, 106], "spars": [14, 22, 25, 62, 75, 76, 93, 106], "variabl": [14, 17, 26, 27, 93, 97, 106], "cutlass": [15, 16], "mm_config": [17, 42, 44], "float8mmconfig": [17, 42, 44], "tinygemm": [18, 47, 78, 82, 102], "_weight_int4pack_mm_for_cpu": [18, 47], "least": 18, "6": [18, 71, 100, 101, 102, 104, 106, 115, 116, 117], "It": [19, 22, 24, 26, 40, 102, 106, 109, 119], "post": [19, 26, 73, 98, 101, 102, 109, 116, 119], "design": [19, 22, 25, 104, 110, 114, 115, 119], "extend": [19, 101, 106, 117], "conjunct": 19, "tensorimpl": [19, 97], "interact": [19, 115], "marlin": [20, 21, 22, 33], "qqq": [20, 21, 33], "marlinqqq": 21, "inherit": [21, 24, 97, 109, 110, 117, 118], "_choose_qparams_and_quantize_affine_qqq": 21, "_dequantize_affine_qqq": 21, "pattern": [22, 25, 101, 102, 110, 114, 115], "preprocess": [22, 25], "manag": 22, "pre_process": 22, "1\u00ba": 22, "transpos": [22, 109], "sinc": [22, 62, 63, 75, 92, 101, 103, 104, 106, 107, 109, 115, 116, 117, 118, 119], "2\u00ba": 22, "inject": 22, "3\u00ba": 22, "again": [22, 23, 106, 115, 119], "dim": [22, 107, 109, 110, 115, 116], "tensor_meta": 23, "subclasstensorarg": 23, "n_block": 23, "scaler_block_s": [23, 34], "quantized_scal": 23, "quantization_factor": 23, "scaler_mean": 23, "quantized_data": [23, 110], "qlora": [23, 98, 104], "convert_to_norm_float_weight": 23, "normal": [23, 34, 55, 106, 115, 116], "dequantize_scal": 23, "unpack": 23, "doubl": 23, "scaler": 23, "per_scaler_block": 23, "factor": [23, 59, 90, 100, 106], "inpt_weight": 23, "double_quantize_scal": 23, "take": [23, 62, 63, 75, 82, 92, 96, 97, 101, 106, 114, 115, 116, 117, 118, 119], "calcul": [23, 40, 42, 51, 56, 57, 89, 101, 106, 115, 119], "absmax": 23, "posit": 23, "And": [23, 42, 109, 117, 119], "per_block": 23, "int16": [23, 115], "n_scaler_block": 23, "get_original_weight": 23, "quantize_tensor_nearest": 23, "float16": [23, 87, 106], "nearest": 23, "round": [23, 51, 109], "metadata": [24, 101, 104, 109, 110], "semi": [25, 96, 106], "everi": [25, 62, 63, 75, 92, 106, 109, 115, 116], "four": [25, 114], "prune": [25, 93], "conform": 25, "inner_k_til": [26, 47, 68, 78, 102], "core": [26, 52, 107, 110, 115], "tile": 26, "affect": [26, 83, 106], "matmul": [26, 42, 45, 101, 106, 109], "pack_dim": [27, 53], "uintx": [27, 53], "standard": [27, 110], "byte": [27, 41, 53], "uintxtensor": 27, "determin": [27, 56, 73, 100, 106, 110], "along": [27, 106, 110, 114], "indic": [27, 54, 106, 119], "last": [27, 100, 114], "256": [34, 47, 67, 68, 69, 78, 79, 104, 115, 116, 119], "scaling_typ": [35, 36], "scalingtyp": [35, 36], "scaling_granular": [35, 36], "scalinggranular": [35, 36], "mayb": 35, "cast_config_input": 36, "castconfig": 36, "cast_config_input_for_grad_weight": 36, "cast_config_weight": 36, "cast_config_weight_for_grad_input": 36, "cast_config_grad_output": 36, "cast_config_grad_output_for_grad_weight": 36, "gemm_config_output": 36, "float8gemmconfig": 36, "use_fast_accum": [36, 44], "gemm_config_grad_input": 36, "gemm_config_grad_weight": 36, "enable_fsdp_float8_all_gath": 36, "pad_inner_dim": [36, 44], "emul": [36, 44], "force_recompute_fp8_weight_in_bwd": 36, "round_scales_to_power_of_2": 36, "from_recipe_nam": 36, "recipe_nam": [36, 100], "float8linearrecipenam": 36, "qualnam": [37, 38, 51, 52, 54, 74, 83, 84], "boundari": [37, 38, 51, 52, 54, 74, 83, 84], "strategi": 37, "module_filter_fn": [39, 100], "callabl": [39, 55, 82, 91, 96, 97, 110], "float8linearconfig": 39, "float8linear": [39, 100], "instanc": [39, 62, 63, 75, 82, 92, 96, 97, 103, 109, 115, 117, 118, 119], "fqn": [39, 93, 96, 100, 107], "sum": [40, 115, 116], "set_inductor_config": [41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55], "sub": [41, 53, 106], "expon": 41, "mantissa": 41, "fp6_e3_m2": 41, "fp6_e2_m3": 41, "fp6": 41, "llm": 41, "arxiv": [41, 93, 106], "org": [41, 55, 93, 102, 104, 106, 118], "ab": [41, 93, 106], "2401": 41, "14112": 41, "repo": 41, "usyd": 41, "fsalab": 41, "fp6_llm": 41, "renam": [41, 115, 116], "fpxtensorcoreaqttensorimpl": 41, "experiment": [41, 73, 114], "merg": 41, "to_affine_quantized_floatx": 41, "activation_dtyp": [42, 44, 101], "float8_e4m3fn": [42, 44, 45, 101], "weight_dtyp": [42, 44, 45, 101, 104], "pertensor": [42, 44, 107], "perrow": [42, 44, 101, 104], "list": [42, 55, 58, 60, 90, 93, 97, 102, 109, 110, 114, 116, 119], "activation_value_lb": 42, "activation_value_ub": 42, "kernel_prefer": [42, 101], "kernelprefer": 42, "fp8granular": 42, "fast": [42, 44, 106], "accumul": [42, 44], "upper": 42, "defalut": 42, "chosen": [42, 47, 86, 106], "torchinductor": [42, 44, 45, 46, 47, 48, 49, 50, 53, 117, 118], "deprec": [42, 45, 66, 70], "split": [42, 45, 104, 115, 116], "128": [43, 46, 47, 100, 104, 107, 109, 110, 118, 119], "packing_format": [43, 47], "packingformat": [43, 47], "preshuffl": [43, 84, 101], "groupwis": 43, "float8_e4m": 44, "channel": [45, 49, 50, 65, 67, 68, 69, 71, 75, 76, 78, 79, 92, 107, 118], "packing_bitwidth": 46, "weight_onli": 46, "gemlit": 46, "triton": [46, 101, 117, 118], "associ": [46, 107], "fp16": [46, 56], "control": [46, 47, 48, 49, 50, 53, 93, 106, 110, 115], "fine": [46, 47, 48, 53, 98, 100, 104, 106], "grain": [46, 47, 48, 53, 109], "impact": [46, 55, 100, 104, 110], "runtim": [46, 101, 115], "tensorcoretiledlayout": [47, 102], "uint4": [47, 102], "tensor_core_til": 47, "int4mm": [47, 102], "_weight_int4pack_mm": 47, "tradit": 47, "exactli": [47, 109], "hqq": [47, 53, 101], "preserv": [47, 56, 93, 104, 106, 114], "Will": 47, "act_mapping_typ": [48, 49], "produc": [48, 102, 114, 115, 116, 117, 118], "backend": [48, 98, 102, 104, 106, 119], "marlinqqqlayout": 48, "cutlassint4packedlayout": 48, "weight_only_decod": 49, "around": [49, 100, 101, 102, 103, 115], "decod": [49, 104], "better": [49, 50, 100, 109, 115, 116, 117, 118, 119], "number": [51, 53, 55, 65, 76, 78, 79, 93, 104, 106, 109, 116, 117], "sai": [51, 87, 101, 110, 119], "3": [51, 55, 62, 87, 98, 100, 101, 102, 106, 113, 115, 116], "7": [51, 100, 104, 117, 118], "symmetric_no_clipping_err": 51, "variant": [51, 57, 109], "smin": 51, "smax": 51, "min_val_neg": [51, 109], "max_val_po": [51, 109], "By": [51, 106], "individu": [51, 106], "less": [51, 106, 109, 115], "error": [51, 55, 71, 100, 109, 115], "neg": 51, "placehold": [52, 101, 118], "uint1": [53, 101], "uint7": [53, 101], "enum": [54, 74, 83], "quantized_v": 54, "float_val": 54, "mid_point": 54, "example_input": [55, 77, 102, 103, 107, 114, 115, 116, 117, 118, 119], "qtensor_class_list": 55, "aqdefaultlinearweight": 55, "aqint8weightonlyquantizedlinearweight": 55, "aqint8weightonlyquantizedlinearweight2": 55, "aqint8dynamicallyquantizedlinearweight": 55, "filter_fn": [55, 82, 96], "interpol": 55, "85": 55, "manual": [55, 116], "supress_autoquant_error": 55, "min_sqnr": 55, "aq_kwarg": 55, "autoquant": 55, "identifi": [55, 107, 119], "over": [55, 100, 106, 115, 116], "potenti": [55, 106, 107, 114, 115, 117, 118], "qtensor": 55, "search": [55, 106], "whose": [55, 119], "exchang": 55, "autoquantizablelinearweight": 55, "calibr": [55, 57, 102, 114, 116, 117, 118], "seen": [55, 101], "record": [55, 107], "final": [55, 82, 101, 102, 106, 114, 115, 116, 117, 118, 119], "benchmark": [55, 89, 98, 100, 102, 114, 117, 118], "member": 55, "pick": 55, "highli": 55, "had": [55, 109, 115], "proce": 55, "combin": [55, 71, 104, 106, 109, 115, 117], "finalize_autoqu": 55, "log": [55, 109], "fulli": [55, 82, 90, 96, 104, 106, 115], "unless": [55, 110], "default_autoquant_class_list": 55, "second": [55, 59, 73, 97, 100, 101, 113, 119], "stop": 55, "wait": 55, "sever": [55, 100, 110, 114, 119], "automat": [55, 73, 100, 104, 109, 110, 113], "suppress": 55, "accept": [55, 104, 119], "signal": 55, "nois": 55, "ration": 55, "en": 55, "wikipedia": 55, "wiki": 55, "noise_ratio": 55, "v": [55, 119], "caus": [55, 100], "too": 55, "larg": [55, 104, 109, 117], "resaon": 55, "40": [55, 100], "keyword": [55, 71, 73, 85, 101], "wrap": [55, 109, 117, 118], "example_input1": 55, "example_input2": 55, "int32": [56, 67, 71, 75, 76, 101, 102, 115, 119], "fp32": [56, 58, 71, 79, 107, 109, 115, 117], "optioanl": 56, "param": [56, 57, 93, 104], "request": [56, 58, 87], "min_val": [57, 109], "max_val": [57, 109], "observ": [57, 92, 101, 106, 107, 114, 115, 116, 117, 118, 119], "obtain": 57, "track": [57, 110], "mostli": [57, 73, 102], "input_dtyp": 58, "output_dtyp": [58, 75, 87], "uint8": [58, 87, 101, 107, 119], "b": [59, 97], "scales1": 59, "multipli": [59, 88, 106], "rais": [59, 70, 73, 88, 109, 110], "assertionerror": [59, 88, 109], "expect": [59, 100, 106, 109, 114, 115, 117, 118, 119], "qat": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 98, 104, 117], "twostepquant": 60, "easili": [60, 114], "thei": [60, 100, 102, 106, 109, 115, 116, 119], "constructor": [60, 97, 109], "must": [60, 71, 73, 79, 100, 106, 110, 116, 118, 119], "embed": [60, 62, 67, 70, 73, 75, 76], "my_quant": 60, "qatquantizer1": 60, "qatquantizer2": 60, "qatquantizer3": 60, "num_embed": [62, 75, 76], "embedding_dim": [62, 75, 76], "padding_idx": [62, 75, 76], "max_norm": [62, 75, 76], "norm_typ": [62, 75, 76], "scale_grad_by_freq": [62, 75, 76], "weight_config": [62, 63, 70, 73], "fakequantizeconfigbas": [62, 63, 70, 73], "intxfakequantizeconfig": [62, 63, 70, 72, 73], "fq_embed": 62, "longtensor": 62, "overridden": [62, 63, 75, 92], "within": [62, 63, 75, 92, 104, 106, 110, 117, 118], "afterward": [62, 63, 75, 92], "former": [62, 63, 75, 92], "care": [62, 63, 75, 92, 103, 106, 115], "hook": [62, 63, 75, 92, 101], "latter": [62, 63, 75, 92, 116], "silent": [62, 63, 75, 92, 117], "ignor": [62, 63, 75, 92, 100, 115, 116], "in_featur": [63, 78, 79, 100, 102, 103, 107, 109], "out_featur": [63, 78, 79, 100, 102, 107, 109], "activation_config": [63, 70, 73], "per_token": [63, 70, 71, 73], "is_symmetr": [63, 70, 71, 73], "fq_linear": 63, "scale_precis": [65, 67, 71, 75, 76], "rowwis": [65, 101], "fakequantizedembed": 66, "back": [66, 109], "model_with_fake_quantized_linear": 66, "zero_point_precis": [67, 71, 75, 76], "int4weightonlyqatembed": 67, "int4weightonlyembed": 67, "scales_precis": [68, 69, 78, 79], "padding_allow": 69, "valueerror": [70, 73], "torchaodtyp": 71, "is_dynam": [71, 117, 118, 119], "range_learn": 71, "simul": [71, 73, 94, 106], "older": 71, "int1": [71, 101], "int7": [71, 101], "pergroup": [71, 104], "pertoken": 71, "per_channel": 71, "peraxi": [71, 104, 107], "per_group": [71, 87], "leav": 71, "empti": [71, 101], "prototyp": [71, 77, 101, 119], "properti": [71, 72], "throw": 71, "els": [71, 101, 104, 110, 115, 116], "symmetri": 72, "qatstep": 73, "awar": [73, 93, 98, 102, 106, 109], "ptq": [73, 116, 117], "phase": [73, 119], "int4weightonlyconfig": [73, 102, 103, 110], "qat_config": 73, "act_config": 73, "alwai": [73, 104, 109], "One": [73, 106, 109, 110, 119], "neither": 73, "nor": 73, "intxfakequantizerbas": 77, "weightonlyint4linear": 78, "hardcod": [79, 119], "mod": [80, 81, 100, 106, 109], "disabl": [80, 109, 116], "inplac": [82, 93, 102], "qualifi": [82, 90, 96, 106], "predefin": [82, 119], "execut": [82, 105, 109, 112], "int8_dynamic_activation_int4_weight": 82, "int8_dynamic_activation_int8_weight": [82, 96], "int4_weight_onli": 82, "int8_weight_onli": 82, "sequenti": [82, 96, 100], "select": [83, 115], "found": [83, 101, 102, 104, 106, 107, 109], "nativ": [83, 98, 100, 101, 109, 115], "laid": [84, 101], "creation": [85, 110], "construct": [85, 101, 115, 119], "to_float8": 85, "cl": [85, 97, 107, 109, 110], "quant_kwarg": [85, 86, 91], "quantizetensorkwarg": 86, "flexibl": [86, 106, 109, 114, 117], "variou": 86, "tabl": [87, 97, 100, 101, 106], "show": [87, 100, 102, 104, 106, 110, 115, 116], "per_tensor": 87, "per_axi": 87, "axi": [87, 107], "mat2": 88, "consid": [88, 106], "cubla": 88, "fallback": [88, 110], "j": 88, "debug_skip_calibr": 89, "smoothquant": [89, 90, 114], "smoothfakedynamicallyquantizedlinear": [89, 90], "skip_fqn_list": 90, "cur_fqn": 90, "alpha": 90, "skip": [90, 93, 101, 106], "being": [90, 100, 106, 110, 117, 118], "input_quant_func": 91, "dict": [91, 93, 109, 110, 118, 119], "l2": [92, 106], "norm": [92, 93, 106], "buffer": 92, "x_orig": 92, "sparsity_level": [93, 106], "semi_structured_block_s": 93, "wanda": 93, "sparsifi": [93, 98, 103, 106], "2306": 93, "11695": 93, "product": [93, 104, 110, 117, 119], "magnitud": [93, 106], "parametr": 93, "deepcopi": [93, 102, 107, 109, 116], "squash_mask": [93, 106], "params_to_keep": 93, "params_to_keep_per_lay": 93, "squash": 93, "mask": [93, 106], "appropri": [93, 114, 115, 116, 117, 118], "sparse_param": 93, "attach": [93, 106, 119], "kei": [93, 106, 113], "xdoctest": 93, "local": [93, 104, 106], "hasattr": [93, 110], "submodule1": 93, "linear1": [93, 102, 103, 107, 109], "foo": [93, 115], "bar": [93, 115], "submodule2": 93, "linear42": 93, "baz": 93, "42": [93, 107], "24": 93, "ones": [93, 116], "update_mask": 93, "tensor_nam": [93, 110], "statist": [93, 106, 107, 115, 116], "retriev": 93, "act_per_input": 93, "Then": [93, 109, 118, 119], "whole": [93, 119], "alia": [95, 97, 110], "semisparseweightconfig": 95, "sparsify_": 96, "apply_tensor_subclass": 96, "essenti": [96, 110, 114], "semi_sparse_weight": 96, "semisparselayout": 96, "sparsemarlinlayout": 96, "isinst": [96, 100, 106, 107, 109, 110, 116, 119], "sparse_api": 96, "commonli": [97, 100, 106], "includ": [97, 100, 101, 109, 114, 117, 118, 119], "_get_to_kwarg": 97, "register_layout": 97, "plainaqttensorimpl": [97, 107], "get_tensor_impl_constructor": 97, "tensor_impl_ctr": 97, "simplifi": [97, 114, 115, 117, 118], "implment": 97, "tensor_data": 97, "optional_tensor_data_nam": 97, "boilerpl": 97, "__tensor_flatten__": [97, 109, 110], "flatten": 97, "valid": [97, 104, 110, 119], "__tensor_unflatten__": [97, 109, 110], "tensor_data_dict": [97, 109, 110], "_apply_fn_to_data": [97, 110], "recreat": 97, "__repr__": [97, 109], "contigu": [97, 101, 117, 118], "detach": [97, 109, 110], "clone": [97, 104, 110], "copy_": [97, 110], "_to_copi": [97, 110], "f": [97, 100, 101, 103, 104, 106, 107, 109, 110, 115, 116], "__new__": [97, 109, 110], "layout_class": 97, "tensorimplclass": 97, "from_plain": 97, "tensor_class": 97, "aten_ops_or_torch_fn": 97, "decor": [97, 109, 110], "__torch_dispatch__": [97, 109], "__torch_function__": [97, 101, 109], "_implement": 97, "registr": 97, "aqt": 97, "introduct": [98, 101, 104], "highlight": [98, 109, 113], "guid": [98, 101, 104, 114], "contributor": [98, 101, 102], "tune": [98, 100, 104, 106, 114], "vllm": 98, "sglang": 98, "serial": [98, 101, 115, 116], "advanc": [98, 107, 109, 114, 117, 118], "export": [98, 101], "x86": [98, 102], "intel": [98, 114, 117], "openvino": [98, 102], "5x": 100, "cluster": [100, 101], "34": 100, "43x": 100, "2k": 100, "h200": 100, "latest": [100, 102], "offic": 100, "offici": [100, 101], "popular": 100, "flagship": 100, "form": [100, 101, 106], "quickli": [100, 109], "batteri": 100, "fork": 100, "build": [100, 101, 106, 109, 110, 115], "top": [100, 101, 109, 114, 115, 116, 117, 118], "virtual": 100, "environ": [100, 104], "conda": 100, "venv": 100, "download": [100, 102, 104, 111, 113, 115, 116, 118], "job": 100, "below": [100, 101, 106, 109, 110, 113, 114], "root": [100, 104], "launch": 100, "ngpu": 100, "config_fil": 100, "train_config": 100, "llama3_8b": 100, "toml": 100, "run_train": 100, "sh": [100, 104], "hyperparamet": 100, "edit": [100, 104], "line": [100, 106], "flag": [100, 116], "termin": 100, "rank0": 100, "titan": 100, "2025": 100, "06": 100, "04": 100, "08": 100, "51": 100, "48": 100, "info": 100, "2254": 100, "27": 100, "34gib": 100, "28": 100, "78": 100, "tp": [100, 110], "375": 100, "tflop": 100, "21": 100, "73": [100, 107], "mfu": 100, "20": [100, 104, 116], "58": 100, "557": 100, "7069": 100, "99gib": 100, "62": 100, "034": 100, "35": [100, 104, 107], "41": [100, 104], "19": 100, "52": 100, "224": [100, 107, 114, 115, 116, 117, 118], "9196": 100, "022": 100, "406": [100, 115, 116], "65": 100, "904": 100, "1423": 100, "014": 100, "23": [100, 107], "As": [100, 115, 119], "warmup": 100, "7k": 100, "99gb": 100, "peak": [100, 104], "against": 100, "02": 100, "37": 100, "404": 100, "2611": 100, "22gib": 100, "595": 100, "47": 100, "49": [100, 107], "027": 100, "4260": 100, "89gib": 100, "344": 100, "367": 100, "39": 100, "03": 100, "01": 100, "988": 100, "9482": 100, "321": 100, "366": 100, "14": 100, "991": 100, "1183": 100, "300": 100, "364": 100, "89": 100, "4659": 100, "291": 100, "84": 100, "769": 100, "gc": 100, "peform": 100, "period": 100, "collect": [100, 106], "3k": 100, "89gb": 100, "11x": 100, "nearli": 100, "ident": [100, 106], "performan": 100, "vs": [100, 106, 115, 119], "curv": [100, 106], "omit": [100, 101, 115, 116, 117], "648": 100, "2648": 100, "28gib": 100, "71": 100, "26": 100, "475": 100, "9106": 100, "91gib": 100, "53": [100, 104], "503": 100, "434": 100, "43": 100, "94": [100, 115], "166": 100, "0774": 100, "663": 100, "443": 100, "44": [100, 107], "87": 100, "50": [100, 106, 107, 114, 115, 117, 118], "885": 100, "3233": 100, "643": 100, "442": 100, "66": [100, 104, 107], "76": 100, "613": 100, "6150": 100, "637": 100, "72": [100, 104], "6k": 100, "91gb": 100, "21x": [100, 104], "tl": 100, "dr": 100, "priorit": 100, "accur": [100, 106, 114], "stabil": 100, "cost": [100, 107], "slightli": [100, 109], "outlier": 100, "underflow": 100, "8xh100": 100, "box": [100, 106, 117], "toi": [100, 102, 107, 109, 117], "convert_to_float8_train": 100, "recurs": 100, "kind": [100, 115], "gemm": [100, 117, 118], "snippet": [100, 115, 116], "float8_linear_util": 100, "float8_linear": 100, "sampl": [100, 115, 117, 118], "adamw": 100, "elig": 100, "divis": 100, "label": 100, "fake_label": 100, "ones_lik": 100, "mse_loss": 100, "model_state_dict": 100, "state_dict": [100, 103, 115, 116], "optimizer_state_dict": 100, "pth": [100, 115, 116], "explor": [100, 102, 118], "few": [100, 109, 115, 116], "lai": 101, "stack": [101, 104], "awq": 101, "gptq": 101, "int4tensor": 101, "int4preshuffledtensor": 101, "float3": 101, "overload": [101, 106], "term": [101, 106, 115, 119], "extra": [101, 104], "matter": [101, 106], "float4_e2m1fn_x2": 101, "float8_e4m3fnuz": 101, "float8_e5m2": 101, "float8_e5m2fnuz": 101, "float8_e8m0fnu": 101, "pr": 101, "shell": 101, "dervi": 101, "mxfp8": 101, "between": [101, 106, 109, 110, 114, 116, 117, 119], "preicison": 101, "mainli": [101, 114, 117, 119], "mention": [101, 115], "previou": [101, 104, 115, 116, 117, 118], "accommod": 101, "choose_qparams_affine_with_min_max": 101, "min": [101, 107, 109, 115, 119], "raw": 101, "quantize_fp8_row": 101, "int_matmul": 101, "int_scaled_matmul": 101, "reli": [101, 102, 106, 107, 109], "handwritten": 101, "On": [101, 102], "glue": 101, "everyth": 101, "togeth": [101, 104, 115, 117, 119], "anoth": [101, 106, 109, 115, 119], "side": 101, "swizzl": 101, "dtpype": 101, "act": 101, "adjac": 101, "special": [101, 106, 114, 115], "float8rowwisetensor": 101, "float8blockwisetensor": 101, "distinguish": 101, "subset": 101, "confus": [101, 106, 115], "close": [101, 106], "low_precision_v": 101, "high_precision_v": 101, "procedur": 101, "especi": [101, 103, 106, 117, 118], "bitwidth": [101, 119], "codebook": 101, "index": [101, 102, 104, 106, 118], "vector": [101, 106, 117], "kmean": 101, "tradition": 101, "from_hp": 101, "explain": [101, 114, 117], "simplest": [101, 106], "easi": [101, 104], "linear_modul": 101, "question": [101, 103, 106, 109, 119], "activation_granular": 101, "act_quant_kwarg": 101, "weight_granular": [101, 104], "quantized_weight": [101, 110], "float8_dtyp": 101, "haven": 101, "pt2": [101, 109, 117], "adopt": 101, "autoround": 101, "multitensor": 101, "sure": [101, 104, 119], "open": [101, 106], "describ": [101, 103, 106, 113, 115, 116], "face": [101, 104, 106, 115], "finetun": [101, 104], "quantized_train": 101, "progress": [101, 110], "lot": [101, 106], "connect": [101, 119], "walk": [101, 107, 109, 113, 114, 117], "float8dynamicactivationfloat8weightconfig": [101, 104], "len": [101, 104, 110, 115, 116, 119], "_choose_quant_func_and_quantize_tensor": 101, "relat": [101, 106], "xq": 101, "reshap": [101, 115, 116], "wq": 101, "x_scale": [101, 115], "w_scale": 101, "out_shap": 101, "stabl": 102, "pip": [102, 104, 114, 115], "nightli": [102, 104], "url": [102, 104, 118], "whl": [102, 104, 118], "cu121": 102, "major": 102, "entri": 102, "mutat": 102, "logic": [102, 109, 110], "toylinearmodel": [102, 103, 107], "linear2": [102, 103, 107, 109], "eval": [102, 103, 104, 107, 114, 116, 117, 118], "faster": [102, 106], "model_bf16": 102, "mix": [102, 104, 114, 117, 118], "stai": [102, 109], "tensor_impl_dtyp": 102, "roughli": [102, 106], "quarter": 102, "os": [102, 115, 116], "int4_model": 102, "pt": [102, 104], "bfloat16_model": 102, "int4_model_size_mb": 102, "getsiz": [102, 115, 116], "bfloat16_model_size_mb": 102, "2f": [102, 115, 116], "mb": [102, 103, 105, 112, 115, 116], "00": [102, 105, 112], "benchmark_model": 102, "unwrap_tensor_subclass": 102, "num_run": 102, "100": [102, 109, 115, 116], "_dynamo": [102, 109], "reset": [102, 115, 116], "bf16_time": 102, "int4_tim": 102, "time": [102, 106, 109, 113, 114, 115, 116], "3f": [102, 116], "ms": 102, "1fx": 102, "393": 102, "410": 102, "9x": 102, "recogn": [102, 119], "decis": 102, "pt2e": [102, 114, 115, 116, 117, 118], "fuse": [102, 106, 109, 116], "deleg": [102, 115], "x86inductorquant": [102, 117, 118], "quantize_pt2": [102, 114, 115, 116, 117, 118], "prepare_pt2": [102, 114, 115, 117, 118], "x86_inductor_quant": [102, 117], "get_default_x86_inductor_quantization_config": [102, 117], "float_model": [102, 109, 114, 115, 116, 117, 118], "data_load": [102, 115, 116, 117, 118], "no_grad": [102, 109, 114, 115, 116, 117, 118], "imag": [102, 114, 115, 116, 117, 118], "program": [102, 115, 116, 117, 119], "captur": [102, 115, 116, 119], "expos": [102, 115, 116], "set_glob": [102, 115, 116, 117, 118], "xiq": [102, 117], "prepare_qat_pt2": [102, 116, 117], "sample_inference_data": 102, "convert_pt2": [102, 114, 115, 116, 117, 118], "wrapper": [102, 109, 117], "_inductor": [102, 117], "cpp_wrapper": [102, 117], "optimized_model": [102, 114, 117, 118], "converted_model": [102, 117, 118], "xpu": [102, 118], "simpl": [102, 106, 107, 109, 114, 117, 118], "visit": 102, "would": [102, 106, 109, 116, 118], "forget": 102, "tempfil": 103, "get_model_size_in_byt": 103, "ref": [103, 115], "namedtemporaryfil": 103, "seek": [103, 106], "m_load": 103, "load_state_dict": [103, 115, 116], "assign": 103, "assert": [103, 107, 109, 110, 119], "equal": [103, 106], "thing": [103, 106, 109, 115], "float_weight1": 103, "float_weight2": 103, "quantized_weight1": 103, "quantized_weight2": 103, "go": [103, 109, 113, 119], "techinqu": 103, "reduct": [103, 104, 106, 109], "4x": [103, 104], "0625": 103, "reason": [103, 106], "avoid": [103, 106], "affine_quantized_tensor": 103, "deploi": 104, "underli": [104, 109], "engin": 104, "seamlessli": [104, 109, 117, 118], "seamless": [104, 117], "git": 104, "cu126": 104, "acceler": [104, 106], "phi": 104, "autotoken": 104, "model_id": 104, "microsoft": 104, "quant_config": 104, "quant_typ": [104, 110], "quantized_model": [104, 109, 114, 115, 116], "device_map": [104, 110], "torch_dtyp": [104, 110], "push": [104, 106, 110], "hub": [104, 110], "user_id": 104, "your_user_id": 104, "model_nam": [104, 114, 117, 118], "save_to": 104, "safe_seri": [104, 110], "hf": 104, "signific": [104, 106], "wheel": 104, "ai": 104, "hug": 104, "server": [104, 110], "o3": 104, "client": 104, "curl": 104, "localhost": 104, "8000": 104, "v1": 104, "chat": 104, "h": 104, "content": 104, "applic": 104, "messag": 104, "role": 104, "give": [104, 106, 109], "me": 104, "short": 104, "languag": 104, "temperatur": 104, "top_p": 104, "95": 104, "top_k": 104, "max_token": 104, "32768": 104, "vram": 104, "15x": 104, "2x": [104, 106], "littl": [104, 110], "packag": 104, "pipelin": 104, "random": [104, 106, 115, 116], "manual_se": [104, 115, 116], "model_path": 104, "trust_remote_cod": 104, "assist": 104, "eat": 104, "banana": 104, "dragonfruit": 104, "smoothi": 104, "blend": 104, "milk": 104, "honei": 104, "salad": 104, "slice": [104, 110], "lemon": 104, "juic": 104, "solv": [104, 106, 109], "equat": 104, "pipe": 104, "text": 104, "generation_arg": 104, "max_new_token": 104, "500": 104, "return_full_text": 104, "do_sampl": 104, "generated_text": 104, "lm_head": 104, "those": [104, 106, 107, 109], "ti": 104, "autoprocessor": 104, "modeling_util": 104, "find_tied_paramet": 104, "untied_model": 104, "getattr": [104, 110], "get_text_config": 104, "tie_word_embed": 104, "setattr": [104, 109], "_tied_weights_kei": 104, "save_to_local_path": 104, "int8dynamicactivationintxweightconfig": 104, "ve": [104, 106], "intxweightonlyconfig": 104, "modulefqntoconfig": [104, 110], "untied_model_id": 104, "untied_model_local_path": 104, "embedding_config": 104, "linear_config": 104, "weight_scale_dtyp": 104, "_default": [104, 110], "embed_token": 104, "include_embed": 104, "untie_embedding_weight": 104, "modules_to_not_convert": 104, "pte": 104, "cd": 104, "install_requir": 104, "phi_4_mini": 104, "convert_weight": 104, "pytorch_model": 104, "bin": 104, "pytorch_model_convert": 104, "export_llama": 104, "kv": 104, "use_sdpa_with_kv_cach": 104, "get_bos_id": 104, "199999": 104, "get_eos_id": 104, "200020": 104, "max_seq_length": 104, "max_context_length": 104, "output_nam": 104, "phi4": 104, "phone": 104, "io": 104, "2gb": 104, "iphon": 104, "pro": [104, 106], "17": 104, "sec": 104, "maintain": [104, 106], "test": [104, 113, 115, 117], "lm": 104, "har": 104, "eleutherai": 104, "lm_eval": 104, "model_arg": 104, "pretrain": [104, 106, 114, 115, 116, 117], "reset_peak_memory_stat": 104, "prompt": 104, "hei": 104, "consciou": 104, "templated_prompt": 104, "apply_chat_templ": 104, "add_generation_prompt": 104, "templat": [104, 105, 111, 112], "return_tensor": 104, "generated_id": 104, "output_text": 104, "batch_decod": 104, "skip_special_token": 104, "clean_up_tokenization_spac": 104, "respons": 104, "mem": [104, 105, 112], "max_memory_reserv": 104, "1e9": 104, "02f": 104, "gb": 104, "hello": 104, "ye": 104, "am": 104, "digit": 104, "todai": 104, "70": [104, 107], "91": 104, "benchmark_lat": 104, "vllm_disable_compile_cach": 104, "project": 104, "vllm_use_precompil": 104, "sharegpt": 104, "wget": 104, "co": 104, "anon8231489123": 104, "sharegpt_vicuna_unfilt": 104, "resolv": 104, "sharegpt_v3_unfiltered_cleaned_split": 104, "tree": 104, "num": 104, "benchmark_serv": 104, "16x": 104, "1s": 104, "14x": 104, "num_prompt": 104, "req": 104, "57": [104, 107], "1000": [104, 117], "68": 104, "80": 104, "entir": [104, 115, 116], "ml": 104, "gain": [104, 106, 118], "eas": 104, "trade": [104, 106], "off": [104, 106], "003": [105, 112, 113], "total": [105, 112, 113], "galleri": [105, 111, 113], "tutorials_sourc": 105, "template_tutori": [105, 112, 113], "neural": [106, 114, 117], "network": [106, 109, 114, 117], "latenc": 106, "carefulli": 106, "pai": 106, "low": [106, 109, 114], "price": 106, "f1": 106, "problem": [106, 109], "research": [106, 113], "fragment": 106, "rightfulli": 106, "spent": 106, "figur": [106, 115], "compress": [106, 114], "place": [106, 114, 115, 116, 117, 118], "dens": 106, "focu": [106, 109], "realli": 106, "concret": [106, 119], "hope": 106, "modular": 106, "nice": 106, "scratch": [106, 113], "minim": [106, 114, 117, 118], "algorthim": 106, "realiz": 106, "theoret": 106, "analog": 106, "fix": [106, 107], "unstructur": 106, "retrain": 106, "neglig": 106, "area": 106, "agre": 106, "upon": 106, "consensu": 106, "mind": 106, "thought": 106, "subproblem": 106, "satisfi": 106, "my": [106, 116], "independ": 106, "frontend": [106, 117], "arbitrari": 106, "handoff": 106, "piec": 106, "natur": [106, 109, 115, 119], "present": 106, "clear": 106, "contract": 106, "7x": 106, "advantag": 106, "anticip": 106, "solut": 106, "third": 106, "parti": 106, "to_sparse_semi_structur": 106, "sparsesemistructuredtensor": 106, "weightnormsparsifi": 106, "half": 106, "subnetwork": 106, "sparse_config": 106, "named_modul": 106, "tensor_fqn": 106, "sparse_block_shap": 106, "zeros_per_block": 106, "fakespars": 106, "fundament": [106, 116], "manipul": 106, "dictionari": 106, "paramer": 106, "parameter": 106, "necessari": [106, 107, 109, 114, 115, 116, 117, 118], "suitabl": [106, 117], "0s": 106, "spot": 106, "definit": [106, 110], "academia": 106, "industri": 106, "often": [106, 109], "interchang": 106, "distinct": 106, "idea": 106, "behind": 106, "doesn": [106, 116, 119], "itself": [106, 109], "loos": 106, "speak": 106, "tightli": 106, "coupl": [106, 109], "csc": 106, "qnnpack": 106, "descript": [106, 114], "coo": 106, "sparse_coo": 106, "coordin": 106, "locat": 106, "bsr": 106, "sparse_bsr": 106, "veri": [106, 110, 116], "except": [106, 109, 119], "scalar": [106, 115], "dimension": 106, "csr": 106, "sparse_csr": 106, "sparse_csc": 106, "column": 106, "compact": 106, "sparse_matrix": 106, "1d": 106, "indexptr": 106, "\u00bd": 106, "bitmask": 106, "2bit": 106, "unprun": 106, "quit": [106, 109], "broken": 106, "down": 106, "decid": [106, 107], "sensit": 106, "effect": [106, 107, 109, 117, 118, 119], "best": [106, 117], "subsequ": [106, 109, 117, 118], "infinit": 106, "lost": 106, "degre": 106, "drop": 106, "proxi": 106, "aforement": 106, "smallest": 106, "absolut": 106, "scope": 106, "impli": 106, "con": 106, "span": 106, "threshold": 106, "constant": [106, 109, 115], "ctr_mobile_fe": 106, "score": 106, "w": [106, 110], "tenosr": 106, "udpat": 106, "histori": 106, "regrow": 106, "dw": 106, "via": [106, 114], "backprop": 106, "pat": 106, "unmask": 106, "resid": 106, "salienc": 106, "lowest": 106, "l1": 106, "abl": [106, 109, 110, 115, 119], "repeat": [106, 115, 116], "movement": 106, "2005": 106, "07683": 106, "rank": [106, 109], "wx": 106, "sqx": 106, "q": [106, 115], "usual": 106, "sort": 106, "wise": 106, "reconstruct": [106, 110], "randomli": 106, "tri": 106, "remedi": 106, "sometim": 106, "item": [106, 113], "ultim": [106, 107], "complic": [106, 115], "literatur": 106, "vision": 106, "nlp": [106, 113, 117], "iter": [106, 115, 116], "ctr_feed": 106, "na": 106, "multimask": 106, "pyspeech": 106, "fastna": 106, "approach": [106, 109, 114, 117, 118], "knowledg": [106, 113], "distil": 106, "pdf": 106, "2204": 106, "09656": 106, "arrang": 106, "recal": 106, "counterpart": 106, "slower": 106, "suffici": 106, "At": [106, 115], "98": 106, "exhibit": 106, "penalti": 106, "expens": [106, 109], "dictat": 106, "characterist": 106, "highest": 106, "wouldn": [106, 109], "visual": 106, "fig": 106, "4x4": 106, "benchmak": 106, "fly": 107, "affinequantizedminmaxobserv": 107, "welcom": 107, "averag": [107, 115, 116], "histogram": [107, 115], "act_ob": 107, "finfo": 107, "weight_ob": 107, "observedlinear": 107, "observed_input": 107, "observed_weight": 107, "from_float": [107, 109], "float_linear": 107, "observed_linear": 107, "_replace_with_custom_fn_if_matches_filt": 107, "insert_observers_": 107, "_is_linear": 107, "lambda": [107, 110], "replacement_fn": 107, "copied_act_ob": 107, "copied_weight_ob": 107, "popul": 107, "feed": 107, "simpler": [107, 115], "quantizedlinear": [107, 109], "isn": 107, "strictli": 107, "to_affine_quantized_intx_stat": 107, "act_scal": [107, 119], "act_zero_point": 107, "calculate_qparam": [107, 119], "weight_scal": [107, 115, 119], "weight_zero_point": [107, 115], "qweight": 107, "qinput": 107, "from_observ": 107, "quantized_linear": [107, 115], "begin": [107, 109], "dataclass": [107, 110, 119], "transform_modul": [107, 110], "register_quantize_module_handl": [107, 110], "staticquantconfig": 107, "_apply_static_qu": 107, "is_observed_linear": 107, "optimizedmodul": 107, "_orig_mod": 107, "0237": 107, "142": 107, "31": [107, 119], "113": 107, "157": 107, "59": 107, "160": 107, "150": 107, "67": 107, "241": 107, "238": 107, "235": 107, "228": 107, "255": [107, 119], "201": 107, "114": 107, "236": 107, "88": [107, 115], "83": 107, "109": 107, "209": 107, "92": 107, "184": 107, "141": 107, "110": 107, "0009": 107, "0010": 107, "130": 107, "122": 107, "132": 107, "125": 107, "126": 107, "129": 107, "127": [107, 109, 118, 119], "133": 107, "124": 107, "131": 107, "135": 107, "136": 107, "foundat": 109, "autograd": [109, 119], "interpos": 109, "namespac": 109, "continu": [109, 116, 117, 118, 119], "obviou": 109, "int8quantizedlinear": 109, "finer": 109, "intercept": 109, "contrast": 109, "clunki": 109, "distributedlinear": 109, "duplic": 109, "bypass": 109, "outer": 109, "inner": 109, "allgath": 109, "bandwidth": 109, "zoo": 109, "podcast": 109, "edward": 109, "yang": 109, "int8_symmetric_quant": 109, "fp32_tensor": 109, "amin": 109, "keepdim": [109, 115, 116], "amax": 109, "zeros_lik": 109, "view": [109, 115, 116], "clamp": [109, 115], "w_int8": 109, "new_linear": 109, "left": [109, 119], "toymodel": 109, "child": 109, "named_children": 109, "drawback": 109, "won": 109, "suppos": 109, "clean": 109, "eleg": 109, "pretti": 109, "power": [109, 110], "overrid": 109, "almost": 109, "shard": [109, 110], "ragged": 109, "rag": 109, "nestedtensor": 109, "who": 109, "link": [109, 113], "why": [109, 113], "googl": 109, "collab": 109, "flopcount": 109, "memorytrack": 109, "bare": 109, "bone": 109, "int8symmetrictensor": 109, "hold": 109, "staticmethod": 109, "_make_wrapper_subclass": [109, 110], "storage_offset": 109, "ndim": 109, "extra_metadata": 109, "outer_s": [109, 110], "outer_strid": [109, 110], "undo": 109, "repr": 109, "ahead": 109, "insid": 109, "int8_tensor": 109, "op_implementations_dict": 109, "conveni": 109, "register_op": 109, "_op": 109, "opoverload": 109, "impl_decor": 109, "op_impl": 109, "done": 109, "particular": 109, "largest": 109, "tell": 109, "desugar": 109, "surfac": 109, "coverag": [109, 114, 115, 117, 118], "brute": 109, "forc": 109, "repeatedli": 109, "loggingtensor": 109, "_python_dispatch": [109, 110], "return_and_correct_alias": [109, 110], "int8_mm": 109, "int8_view_op": 109, "out_data": 109, "out_scal": [109, 115], "notic": 109, "hit": 109, "background": 109, "decomposit": 109, "live": 109, "decomp": 109, "shrink": 109, "author": [109, 113, 114, 115, 116, 117, 118, 119], "But": [109, 110, 119], "pain": 109, "rather": 109, "worth": 109, "written": 109, "differenti": 109, "nuanc": 109, "longer": [109, 115, 116], "That": 109, "transposit": 109, "got": [109, 115, 119], "propag": [109, 115, 117, 118], "fact": 109, "themselv": [109, 115], "pointwis": [109, 117, 118], "were": 109, "might": [109, 110, 115, 119], "unwrap": 109, "dim0": 109, "dim1": 109, "confirm": 109, "quantized_model_module_swap": 109, "quantized_model_subclass": 109, "subclass_param": 109, "out_module_swap": 109, "allclos": 109, "out_compil": 109, "seri": 109, "discuss": 109, "e2": 110, "_type": 110, "_data": 110, "capabl": [110, 115, 117], "self_attn": 110, "q_proj": 110, "k_proj": 110, "mlp": 110, "gate_proj": 110, "usernam": 110, "narrow": 110, "state": 110, "chunk": 110, "heavi": 110, "codebas": 110, "fn": 110, "ctx": 110, "new_tensor": 110, "__class__": 110, "principl": 110, "mynewquantconfig": 110, "classvar": 110, "myquantizedtensor": 110, "fbgemmfp8tensor": 110, "tensor_data_attr": 110, "tensor_attribut": 110, "attr": 110, "fill_default": 110, "notimplementederror": 110, "_my_quant_transform": 110, "my_quantization_funct": 110, "use_cutlass_kernel": 110, "my_cutlass_linear": 110, "use_triton_kernel": 110, "my_triton_linear": 110, "disappear": 110, "extrem": 110, "sole": 110, "world": 110, "explicitli": [110, 119], "spooki": 110, "distanc": 110, "statu": 110, "due": [110, 114, 119], "workaround": 110, "team": 110, "2338": 110, "detect": 110, "illustr": 110, "tutorials_python": 111, "zip": [111, 113], "jupyt": [111, 113], "notebook": [111, 113], "tutorials_jupyt": 111, "sphinx": [111, 113], "firstnam": 113, "lastnam": 113, "prerequisit": [113, 115], "v2": 113, "topic": 113, "rand": [113, 115, 116], "8649": 113, "6869": 113, "0852": 113, "9362": 113, "8827": 113, "1109": 113, "4733": 113, "4622": 113, "4426": 113, "7681": 113, "4600": 113, "3967": 113, "7108": 113, "2060": 113, "9895": 113, "practic": 113, "summar": 113, "takeawai": 113, "link1": 113, "link2": 113, "minut": 113, "ipynb": 113, "daniil": 114, "lyakhov": 114, "aamir": 114, "nazir": 114, "alexand": 114, "suslov": 114, "yamini": 114, "nimmagadda": 114, "kozlov": 114, "subject": [114, 116], "openvinoquant": 114, "unlock": 114, "placement": 114, "ux": [114, 115, 117], "torchdynamo": [114, 117, 118, 119], "eager": [114, 115, 116, 117, 118, 119], "mechan": [114, 117, 118], "torchvis": [114, 115, 116, 117, 118, 119], "resnet18": [114, 115, 116, 117, 118], "u": 114, "__dict__": [114, 115, 116, 117, 118], "dummi": [114, 117, 118], "traced_b": [114, 117, 118], "exported_model": [114, 115, 116, 117, 118], "preset": 114, "elu": 114, "prelu": 114, "gelu": 114, "quantizationpreset": 114, "bert": [114, 117], "modeltyp": 114, "ignored_scop": 114, "exclud": 114, "layer_1": 114, "layer_2": 114, "layer_3": 114, "ignoredscop": 114, "conv2d": [114, 115, 116, 117, 118, 119], "regex": 114, "layer_": 114, "subgraph": [114, 116], "node": [114, 116, 117, 118, 119], "target_devic": 114, "taken": 114, "account": 114, "cpu_spr": 114, "npu": 114, "targetdevic": 114, "fold": [114, 115, 117, 118], "batchnorm": [114, 115, 116, 117, 118], "preced": [114, 115, 117, 118], "prepared_model": [114, 115, 116, 117, 118], "fold_quant": 114, "finish": [114, 117], "comparison": 114, "biascorrect": 114, "discrep": 114, "calibration_load": 114, "dataload": [114, 115, 116], "transform_fn": 114, "data_item": 114, "calibration_dataset": 114, "smooth_quant": 114, "fast_bias_correct": 114, "deploy": [114, 117], "jerri": [115, 117, 119], "zhang": [115, 117, 118, 119], "_export": [115, 116], "fx": [115, 119], "14k": 115, "programm": [115, 117, 118], "db": 115, "xnnpack": [115, 116, 119], "xnnpack_quant": [115, 116], "get_symmetric_quantization_config": [115, 116], "xnnpackquant": [115, 116, 119], "prior": 115, "qconfigmap": [115, 119], "backendconfig": [115, 119], "rel": 115, "intent": [115, 119], "qconfig": [115, 119], "3d": [115, 119], "incompat": 115, "great": 115, "ideal": 115, "fake_qu": 115, "hidden": 115, "summari": 115, "address": 115, "thu": 115, "queri": [115, 119], "becom": 115, "previous": 115, "embedding_byt": 115, "executorchquant": 115, "concaten": 115, "prone": 115, "cleaner": 115, "composed_quant": 115, "quantization_cap": 115, "concern": 115, "decoupl": 115, "minmax": 115, "freed": 115, "identitc": 115, "imagenet": [115, 116], "unzip": [115, 116], "data_path": [115, 116], "resnet18_pretrained_float": [115, 116], "sy": [115, 116], "numpi": [115, 116], "np": [115, 116], "resnet": [115, 116, 117], "warn": [115, 116], "filterwarn": [115, 116], "categori": [115, 116], "deprecationwarn": [115, 116], "r": [115, 116], "seed": [115, 116], "191009": [115, 116], "averagemet": [115, 116], "fmt": [115, 116], "val": [115, 116], "avg": [115, 116], "count": [115, 116], "__str__": [115, 116], "fmtstr": [115, 116], "topk": [115, 116], "predict": [115, 116], "maxk": [115, 116], "pred": [115, 116], "eq": [115, 116], "expand_a": [115, 116], "correct_k": [115, 116], "mul_": [115, 116], "criterion": [115, 116], "top1": [115, 116], "top5": [115, 116], "cnt": [115, 116], "acc1": [115, 116], "acc5": [115, 116], "load_model": [115, 116], "model_fil": [115, 116], "weights_onli": [115, 116], "print_size_of_model": [115, 116], "temp": [115, 116], "p": [115, 116], "1e6": [115, 116], "prepare_data_load": [115, 116], "485": [115, 116], "456": [115, 116], "std": [115, 116], "229": [115, 116], "225": [115, 116], "randomresizedcrop": [115, 116], "randomhorizontalflip": [115, 116], "totensor": [115, 116], "dataset_test": [115, 116], "resiz": [115, 116], "centercrop": [115, 116], "train_sampl": [115, 116], "randomsampl": [115, 116], "test_sampl": [115, 116], "sequentialsampl": [115, 116], "train_batch_s": [115, 116], "sampler": [115, 116], "data_loader_test": [115, 116, 117, 118], "eval_batch_s": [115, 116], "saved_model_dir": [115, 116], "float_model_fil": [115, 116], "model_to_quant": [115, 116], "capture_pre_autograd_graph": [115, 116], "dynamic_shap": [115, 116], "dynamic_dim": [115, 116], "constraint": [115, 116, 119], "qconfig_opt": 115, "set_object_typ": 115, "set_module_nam": 115, "workload": 115, "themodel": 115, "feedback": 115, "dq": 115, "fp32_op": 115, "qauntiz": 115, "x_int8": 115, "x_zero_point": 115, "weight_int8": 115, "bias_fp32": 115, "output_scal": 115, "output_zero_point": 115, "x_fp32": 115, "quantized_decompos": 115, "dequantize_per_tensor": 115, "x_i8": 115, "x_quant_min": 115, "x_quant_max": 115, "weight_fp32": 115, "weight_i8": 115, "weight_quant_min": 115, "weight_quant_max": 115, "weight_permut": 115, "permute_copi": 115, "out_fp32": 115, "addmm": 115, "out_i8": 115, "quantize_per_tensor": 115, "out_zero_point": 115, "out_quant_min": 115, "out_quant_max": 115, "float32_op": 115, "decompos": 115, "use_reference_represent": 115, "x_int16": 115, "weight_int16": 115, "acc_int32": 115, "out_dtyp": 115, "bias_scal": 115, "bias_int32": 115, "div": 115, "mul": 115, "out_int8": 115, "qmin": 115, "qmax": 115, "date": 115, "unus": 115, "serila": 115, "consult": 115, "exportedprogram": 115, "pt2e_quantized_model_file_path": 115, "resnet18_pt2e_quant": 115, "quantized_ep": 115, "loaded_quantized_ep": 115, "loaded_quantized_model": 115, "diff": 115, "79": 115, "82": 115, "55": 115, "edg": [115, 119], "went": 115, "andrew": 116, "Or": 116, "move_exported_model_to_ev": [116, 117], "correctli": 116, "certain": 116, "dropout": 116, "move_exported_model_to_train": 116, "jit": 116, "recursivescriptmodul": 116, "train_one_epoch": 116, "ntrain_batch": 116, "avgloss": 116, "5f": 116, "start_tim": 116, "global_avg": 116, "is_qat": [116, 117], "fusion": 116, "batchnorm2d": 116, "_native_batch_norm_legit": 116, "cudnn_batch_norm": 116, "mobilenetv2": 116, "recompil": 116, "consolid": 116, "epoch": 116, "far": 116, "num_epoch": 116, "num_train_batch": 116, "num_eval_batch": 116, "num_observer_update_epoch": 116, "num_batch_norm_update_epoch": 116, "num_epochs_between_ev": 116, "nepoch": 116, "stat": 116, "subseq": 116, "disable_observ": 116, "bn": 116, "running_mean": 116, "running_var": 116, "new_arg": 116, "wish": 116, "prepared_model_copi": 116, "neval_batch": 116, "paus": 116, "resum": 116, "fail": [116, 119], "checkpoint_path": 116, "checkpoint_": 116, "behav": 116, "incorrectli": 116, "lesli": [117, 119], "fang": [117, 119], "weiwen": [117, 119], "xia": [117, 119], "jiong": [117, 119], "gong": [117, 119], "cnn": 117, "rnn": 117, "outstand": 117, "fourth": 117, "spr": 117, "xeon": 117, "processor": 117, "boost": 117, "channels_last": [117, 118], "onednn": [117, 118], "assum": [117, 119], "word": 117, "satur": 117, "pure": 117, "dedic": 117, "scenario": [117, 118], "plai": [117, 118], "convolut": [117, 118, 119], "absenc": [117, 118], "enhanc": [117, 118], "mirror": [117, 118], "autocast": [117, 118], "device_typ": [117, 118], "turn": [117, 118], "cpp": 117, "qconvolut": [117, 118], "qlinear": [117, 118], "presenc": [117, 118], "pair": [117, 118], "remain": [117, 118], "conting": [117, 118], "qmaxpool2d": [117, 118], "torchinductor_freez": [117, 118], "example_x86inductorquantizer_pytorch_2_1": 117, "torchbench": 117, "measur": 117, "proven": 117, "depth": 117, "example_x86inductorquantizer_qat": 117, "yan": 118, "zhiwei": 118, "wang": 118, "eikan": 118, "liangang": 118, "liu": 118, "river": 118, "cui": 118, "yifeng": 118, "xpuinductorquant": 118, "pip3": 118, "torchaudio": 118, "xpu_inductor_quantizer_exampl": 118, "xpu_inductor_quant": 118, "xpuiq": 118, "resnet18_weight": 118, "get_default_xpu_inductor_quantization_config": 118, "sign": 118, "wherea": 118, "histogramobserv": [118, 119], "perchannelminmaxobserv": 118, "quantizationspec": [118, 119], "quantizationconfig": [118, 119], "type_check": 118, "observerorfakequantizeconstructor": 118, "get_xpu_inductor_symm_quantization_config": 118, "extra_arg": 118, "act_observer_or_fake_quant_ctr": 118, "act_quantization_spec": [118, 119], "qscheme": [118, 119], "per_tensor_symmetr": [118, 119], "observer_or_fake_quant_ctr": [118, 119], "with_arg": [118, 119], "weight_observer_or_fake_quant_ctr": 118, "weight_quantization_spec": [118, 119], "per_channel_symmetr": 118, "ch_axi": 118, "oc": 118, "ic": 118, "kh": 118, "kw": 118, "conv": [118, 119], "bias_quantization_spec": 118, "amp": 118, "indcutor": 118, "kimish": 119, "patel": 119, "made": 119, "explicit": 119, "quantiat": 119, "encod": 119, "convei": 119, "quantizationannot": 119, "furthermor": 119, "minmaxobserv": 119, "input_qspec_map": 119, "output_qspec": 119, "_annot": 119, "conclud": 119, "matcher": 119, "get_source_partit": 119, "add_partit": 119, "gm": 119, "itertool": 119, "chain": 119, "add_nod": 119, "output_nod": 119, "per_tensor_affin": 119, "input_act_qspec": 119, "output_act_qspec": 119, "input_act0": 119, "input_act1": 119, "quantization_annot": 119, "substitut": 119, "among": 119, "sharedquantizationspec": 119, "maxpool": 119, "average_pool": 119, "concat": 119, "edgeornod": 119, "transit": 119, "spec": 119, "conv1": 119, "conv2": 119, "fed": 119, "cat": 119, "conv1_out": 119, "conv2_out": 119, "qspec1": 119, "cat_input0": 119, "cat_input1": 119, "therefor": 119, "ob": 119, "consum": 119, "rewrit": 119, "share_qparams_with_input_act0_qspec": 119, "known": 119, "beforehand": 119, "sigmoid": 119, "fixedqparamsquantizationspec": 119, "act_qspec": 119, "sigmoid_nod": 119, "input_act": 119, "derivedquantizationspec": 119, "derive_qparams_fn": 119, "observerorfakequant": 119, "observerbas": 119, "fakequantizebas": 119, "heurist": 119, "obejct": 119, "obs_or_fq": 119, "fq": 119, "act_obs_or_fq": 119, "weight_obs_or_fq": 119, "act_zp": 119, "weight_zp": 119, "bias_qspec": 119, "derived_from": 119, "backendquant": 119, "get_input_act_qspec": 119, "get_output_act_qspec": 119, "get_weight_qspec": 119, "get_bias_qspec": 119, "intermedi": 119, "straightforward": 119, "call_funct": 119, "relu_": 119, "relu_nod": 119, "maybe_conv_nod": 119, "conv1d": 119, "unexpect": 119, "recognz": 119, "subgraphmatch": 119, "conv_relu_pattern": 119, "name_node_map": 119, "input_nod": 119, "weight_nod": 119, "bias_nod": 119, "caveat": 119, "exhaust": 119, "2d": 119, "4d": 119, "symbol": 119, "outcom": 119}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "BlockSparseLayout"], [15, 0, 1, "", "CutlassInt4PackedLayout"], [16, 0, 1, "", "CutlassSemiSparseLayout"], [17, 0, 1, "", "Float8Layout"], [18, 0, 1, "", "Int4CPULayout"], [19, 0, 1, "", "Layout"], [20, 0, 1, "", "MarlinQQQLayout"], [21, 0, 1, "", "MarlinQQQTensor"], [22, 0, 1, "", "MarlinSparseLayout"], [23, 0, 1, "", "NF4Tensor"], [24, 0, 1, "", "PlainLayout"], [25, 0, 1, "", "SemiSparseLayout"], [26, 0, 1, "", "TensorCoreTiledLayout"], [27, 0, 1, "", "UintxLayout"], [28, 2, 1, "", "to_affine_quantized_floatx"], [29, 2, 1, "", "to_affine_quantized_floatx_static"], [30, 2, 1, "", "to_affine_quantized_fpx"], [31, 2, 1, "", "to_affine_quantized_intx"], [32, 2, 1, "", "to_affine_quantized_intx_static"], [33, 2, 1, "", "to_marlinqqq_quantized_intx"], [34, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_fpx"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[21, 1, 1, "", "dequantize"], [21, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[22, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[23, 1, 1, "", "convert_to_norm_float_weight"], [23, 1, 1, "", "dequantize"], [23, 1, 1, "", "dequantize_scalers"], [23, 1, 1, "", "double_quantize_scalers"], [23, 1, 1, "", "get_original_weight"], [23, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[35, 0, 1, "", "CastConfig"], [36, 0, 1, "", "Float8LinearConfig"], [37, 0, 1, "", "ScalingGranularity"], [38, 0, 1, "", "ScalingType"], [39, 2, 1, "", "convert_to_float8_training"], [40, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[36, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[41, 0, 1, "", "FPXWeightOnlyConfig"], [42, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [43, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [44, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [45, 0, 1, "", "Float8WeightOnlyConfig"], [46, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [47, 0, 1, "", "Int4WeightOnlyConfig"], [48, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [49, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [50, 0, 1, "", "Int8WeightOnlyConfig"], [51, 0, 1, "", "MappingType"], [52, 0, 1, "", "TorchAODType"], [53, 0, 1, "", "UIntXWeightOnlyConfig"], [54, 0, 1, "", "ZeroPointDomain"], [55, 2, 1, "", "autoquant"], [56, 2, 1, "", "choose_qparams_affine"], [57, 2, 1, "", "choose_qparams_affine_with_min_max"], [58, 2, 1, "", "dequantize_affine"], [59, 2, 1, "", "int_scaled_matmul"], [82, 2, 1, "", "quantize_"], [87, 2, 1, "", "quantize_affine"], [88, 2, 1, "", "safe_int_mm"], [89, 2, 1, "", "smooth_fq_linear_to_inference"], [90, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [91, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[60, 0, 1, "", "ComposableQATQuantizer"], [61, 0, 1, "", "FakeQuantizeConfigBase"], [62, 0, 1, "", "FakeQuantizedEmbedding"], [63, 0, 1, "", "FakeQuantizedLinear"], [64, 0, 1, "", "FakeQuantizerBase"], [65, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [66, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [67, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [68, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [69, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [70, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [71, 0, 1, "", "IntxFakeQuantizeConfig"], [72, 0, 1, "", "IntxFakeQuantizer"], [73, 0, 1, "", "QATConfig"], [74, 0, 1, "", "QATStep"], [77, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[62, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[63, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[65, 1, 1, "", "prepare"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[67, 1, 1, "", "convert"], [67, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[71, 3, 1, "", "group_size"], [71, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[72, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[75, 0, 1, "", "Int4WeightOnlyEmbedding"], [76, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[75, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[78, 0, 1, "", "Int4WeightOnlyQATLinear"], [79, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [80, 2, 1, "", "disable_linear_fake_quant"], [81, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[83, 0, 1, "", "KernelPreference"], [84, 0, 1, "", "PackingFormat"], [85, 0, 1, "", "QuantizeTensorKwargs"], [86, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[83, 4, 1, "", "AUTO"], [83, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[84, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[92, 0, 1, "", "PerChannelNormObserver"], [93, 0, 1, "", "WandaSparsifier"], [94, 2, 1, "", "apply_fake_sparsity"], [95, 4, 1, "", "semi_sparse_weight"], [96, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[92, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[93, 1, 1, "", "prepare"], [93, 1, 1, "", "squash_mask"], [93, 1, 1, "", "update_mask"]], "torchao.utils": [[97, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[97, 1, 1, "", "get_tensor_impl_constructor"], [97, 1, 1, "", "implements"], [97, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 98, 100, 101, 110], "dtype": [0, 11, 101], "layout": [0, 19], "tensor": [0, 7, 10, 101, 108, 109, 110, 119], "subclass": [0, 7, 10, 101, 109, 110], "quantiz": [0, 4, 5, 7, 12, 82, 98, 101, 102, 104, 107, 108, 109, 110, 114, 115, 116, 117, 118, 119], "techniqu": 0, "float8": [1, 12, 100, 101], "main": [1, 4, 5], "train": [1, 12, 100, 101, 104, 114, 115, 116, 117, 118], "api": [1, 2, 4, 5, 7, 8, 12, 98, 100, 119], "other": [1, 5, 10, 101], "type": 1, "refer": [2, 98], "python": 2, "kernel": [3, 10, 99, 101, 110], "qat": [4, 12, 116], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "prototyp": 4, "infer": [5, 104], "primit": [5, 101], "sparsiti": [6, 106], "util": 7, "common": [7, 8, 119], "benchmark": [8, 9, 10, 104], "guid": [8, 9, 10, 102, 110], "add": [8, 110], "an": [8, 103], "recip": [8, 100], "model": [8, 10, 100, 101, 103, 104, 110, 114, 115, 116], "design": [8, 106], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 100, 104, 110, 114, 117, 118, 119], "modifi": 8, "exist": 8, "configur": [8, 106, 110, 115, 116], "2": [8, 12, 102, 104, 110, 114, 115, 116, 117, 118, 119], "run": 8, "3": [8, 12, 104, 110, 114, 117, 118, 119], "output": [8, 109], "format": [8, 101], "4": [8, 114, 119], "integr": [8, 12, 110], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 110], "new": [10, 110], "effici": [10, 101], "triton": 10, "hand": 10, "written": 10, "us": [10, 119], "kernelprefer": [10, 83], "flow": [10, 101, 103, 110, 119], "torch": [10, 114, 115, 116], "compil": [10, 110, 114], "perform": [10, 99, 104, 115], "serial": [10, 103, 110], "featur": 10, "support": [10, 110], "function": [10, 115, 116], "compos": 10, "microbenchmark": 10, "eval": [10, 115], "part": [12, 100, 104], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 101, 116, 117], "option": [12, 104, 113, 114], "torchtun": 12, "axolotl": 12, "low": [12, 101], "rank": 12, "adapt": 12, "huggingfac": [12, 104, 110], "peft": 12, "affinequantizedtensor": 13, "blocksparselayout": 14, "cutlassint4packedlayout": 15, "cutlasssemisparselayout": 16, "float8layout": 17, "int4cpulayout": 18, "marlinqqqlayout": 20, "marlinqqqtensor": 21, "marlinsparselayout": 22, "nf4tensor": 23, "plainlayout": 24, "semisparselayout": 25, "tensorcoretiledlayout": 26, "uintxlayout": 27, "to_affine_quantized_floatx": 28, "to_affine_quantized_floatx_stat": 29, "to_affine_quantized_fpx": 30, "to_affine_quantized_intx": 31, "to_affine_quantized_intx_stat": 32, "to_marlinqqq_quantized_intx": 33, "to_nf4": 34, "castconfig": 35, "float8linearconfig": 36, "scalinggranular": 37, "scalingtyp": 38, "convert_to_float8_train": 39, "precompute_float8_dynamic_scale_for_fsdp": 40, "fpxweightonlyconfig": 41, "float8dynamicactivationfloat8weightconfig": 42, "float8dynamicactivationint4weightconfig": 43, "float8staticactivationfloat8weightconfig": 44, "float8weightonlyconfig": 45, "gemliteuintxweightonlyconfig": 46, "int4weightonlyconfig": 47, "int8dynamicactivationint4weightconfig": 48, "int8dynamicactivationint8weightconfig": 49, "int8weightonlyconfig": 50, "mappingtyp": 51, "torchaodtyp": 52, "uintxweightonlyconfig": 53, "zeropointdomain": 54, "autoqu": 55, "choose_qparams_affin": 56, "choose_qparams_affine_with_min_max": 57, "dequantize_affin": 58, "int_scaled_matmul": 59, "composableqatquant": 60, "fakequantizeconfigbas": 61, "fakequantizedembed": 62, "fakequantizedlinear": 63, "fakequantizerbas": 64, "float8actint4weightqatquant": 65, "fromintxquantizationawaretrainingconfig": 66, "int4weightonlyembeddingqatquant": 67, "int4weightonlyqatquant": 68, "int8dynactint4weightqatquant": 69, "intxquantizationawaretrainingconfig": 70, "intxfakequantizeconfig": 71, "intxfakequant": 72, "qatconfig": 73, "qatstep": 74, "int4weightonlyembed": 75, "int4weightonlyqatembed": 76, "initialize_fake_quant": 77, "int4weightonlyqatlinear": 78, "int8dynactint4weightqatlinear": 79, "disable_linear_fake_qu": 80, "enable_linear_fake_qu": 81, "packingformat": 84, "quantizetensorkwarg": 85, "_choose_quant_func_and_quantize_tensor": 86, "quantize_affin": 87, "safe_int_mm": 88, "smooth_fq_linear_to_infer": 89, "swap_linear_with_smooth_fq_linear": 90, "to_linear_activation_quant": 91, "perchannelnormobserv": 92, "wandasparsifi": 93, "apply_fake_spars": 94, "semi_sparse_weight": 95, "sparsifi": 96, "torchaobasetensor": 97, "welcom": 98, "document": 98, "get": 98, "start": [98, 102], "develop": 98, "note": [98, 100, 119], "eager": 98, "tutori": [98, 113], "pt2e": [98, 119], "pre": 100, "torchtitan": 100, "prerequisit": [100, 114, 117, 118, 119], "rowwis": 100, "scale": 100, "tensorwis": 100, "pick": 100, "import": [100, 115, 116], "directli": [100, 119], "convers": 100, "overview": [101, 106, 113], "basic": 101, "op": 101, "deriv": [101, 119], "pack": 101, "algorithm": 101, "weight": [101, 104], "onli": 101, "dynam": 101, "activ": 101, "static": [101, 107], "bit": 101, "optim": [101, 103, 104], "case": 101, "studi": 101, "how": [101, 115, 116, 119], "work": 101, "dure": 101, "execut": 101, "save": [101, 115, 116], "load": [101, 115, 116], "quick": 102, "first": 102, "exampl": [102, 110, 119], "pytorch": [102, 114, 115, 116, 117, 118, 119], "export": [102, 104, 114, 115, 116, 117, 118, 119], "next": [102, 109], "step": [102, 104, 109, 110, 113], "deseri": 103, "what": [103, 109], "happen": 103, "when": 103, "serv": [104, 110], "vllm": [104, 110], "sglang": 104, "executorch": 104, "post": [104, 114, 115, 117, 118], "transform": [104, 110], "mobil": 104, "deploy": 104, "unti": 104, "embed": 104, "creat": [104, 110], "characterist": 104, "evalu": [104, 115], "qualiti": 104, "assess": 104, "memori": 104, "latenc": 104, "result": 104, "h100": 104, "machin": 104, "conclus": [104, 113, 114, 115, 116, 117, 118, 119], "comput": [105, 112], "time": [105, 112], "goal": 106, "context": 106, "prune": 106, "criteria": 106, "strategi": 106, "pattern": [106, 119], "calibr": [107, 115], "phase": 107, "write": [108, 109, 119], "your": [108, 109, 110], "own": [108, 109], "advanc": 108, "ar": 109, "modul": [109, 110], "swap": 109, "which": 109, "oper": [109, 110, 119], "should": 109, "we": 109, "implement": [109, 110], "compar": 109, "architectur": 110, "usag": 110, "system": 110, "class": 110, "level": 110, "method": 110, "minim": 110, "requir": 110, "compat": 110, "why": 110, "regist": 110, "s": 110, "kei": 110, "detail": 110, "hardwar": 110, "specif": [110, 115, 116], "linear": 110, "benefit": 110, "trade": 110, "off": 110, "share": [110, 119], "safetensor": 110, "diagram": 110, "high": 110, "point": 110, "dispatch": 110, "bring": 110, "extern": 110, "templat": 113, "addit": 113, "exercis": 113, "further": 113, "read": 113, "openvino": 114, "backend": [114, 115, 116, 117, 118], "introduct": [114, 117, 118, 119], "nncf": 114, "instal": 114, "captur": [114, 117, 118], "fx": [114, 117, 118], "graph": [114, 117, 118], "appli": [114, 117, 118], "lower": [114, 115, 117, 118], "represent": 114, "improv": 114, "metric": 114, "motiv": [115, 119], "defin": [115, 116], "helper": [115, 116], "prepar": [115, 116], "dataset": [115, 116], "set": 115, "mode": 115, "convert": [115, 116], "check": 115, "size": 115, "accuraci": 115, "debug": 115, "loop": 116, "checkpoint": 116, "x86": 117, "through": [117, 118], "inductor": [117, 118], "intel": 118, "gpu": 118, "annot": 119, "param": 119, "fix": 119, "paramet": 119, "5": 119, "A": 119, "toi": 119, "resnet18": 119, "ir": 119, "problem": 119, "match": 119, "aten": 119, "recommend": 119, "subgraphmatcherwithnamenodemap": 119}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})