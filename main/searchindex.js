Search.setIndex({"docnames": ["api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [1, 7, 8, 9, 11, 17, 18, 22, 23, 24, 25, 27, 28, 29, 33, 38, 39, 44, 46, 48, 49, 51, 52, 55, 58, 59, 60, 62, 63, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89], "section": [1, 9, 71, 75, 80, 85, 86, 89], "introduc": [1, 11, 84, 85, 87, 88, 89], "dive": 1, "detail": [1, 7, 9, 11, 70, 71, 72, 74, 75, 76, 78, 84, 85, 86, 87], "how": [1, 3, 9, 11, 19, 23, 25, 27, 44, 56, 57, 60, 68, 70, 72, 73, 74, 75, 76, 78, 79, 80, 84, 87, 88], "integr": [1, 9, 68, 70, 73, 74, 75, 78, 87, 89], "pytorch": [1, 7, 11, 26, 44, 68, 70, 71, 74, 75, 78, 80, 83], "optim": [1, 9, 11, 17, 55, 68, 70, 75, 78, 84, 86, 87, 88], "your": [1, 7, 9, 11, 68, 70, 71, 72, 74, 75, 79, 85, 86, 87, 88, 89], "machin": [1, 86], "learn": [1, 44, 72, 75, 83, 85, 87, 88, 89], "model": [1, 11, 17, 22, 31, 36, 39, 40, 41, 42, 43, 46, 50, 55, 63, 64, 66, 75, 76, 78, 87, 88, 89], "quantiz": [1, 7, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 66, 70, 73, 75], "sparsiti": [1, 7, 11, 62, 63, 64, 65, 66, 68, 70, 73, 74], "tba": [2, 10, 69], "For": [3, 7, 9, 11, 44, 71, 72, 73, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 89], "full": [3, 11, 72, 76, 79, 83, 84, 86], "exampl": [3, 7, 9, 11, 17, 25, 31, 33, 34, 39, 43, 44, 46, 50, 55, 56, 63, 66, 67, 71, 73, 74, 75, 76, 78, 81, 83, 84, 85, 86, 87, 88], "us": [3, 7, 8, 11, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 31, 36, 39, 43, 44, 46, 51, 52, 56, 57, 60, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88], "our": [3, 9, 11, 70, 72, 74, 75, 76, 78, 85, 86], "pleas": [3, 8, 9, 11, 39, 43, 68, 71, 72, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 89], "refer": [3, 7, 11, 46, 52, 70, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87], "readm": [3, 7, 11, 68, 72, 75], "tutori": [7, 9, 11, 70, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89], "you": [7, 8, 9, 11, 44, 63, 67, 70, 71, 72, 73, 74, 75, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89], "through": [7, 9, 11, 28, 33, 34, 68, 71, 72, 74, 76, 78, 80, 83, 84, 85, 89], "torchao": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72, 73, 74, 75, 76, 78, 79, 84, 85, 86, 87, 88], "framework": [7, 9, 11, 70, 74, 84], "The": [7, 9, 11, 16, 18, 20, 30, 46, 55, 61, 63, 70, 71, 72, 73, 74, 75, 78, 79, 80, 84, 85, 86, 87, 88, 89], "contain": [7, 58, 59, 75, 78, 86, 89], "new": [7, 11, 67, 70, 71, 76, 78, 85, 86, 87, 89], "architectur": [7, 68, 74, 75, 84, 85, 87, 88], "micro": 7, "current": [7, 18, 21, 22, 36, 37, 46, 55, 63, 66, 70, 71, 72, 75, 78, 79, 80, 85, 86, 88], "support": [7, 11, 18, 19, 21, 22, 36, 43, 44, 46, 56, 58, 59, 66, 70, 71, 72, 73, 74, 75, 78, 84, 85, 86, 87, 88, 89], "which": [7, 9, 11, 46, 51, 56, 70, 71, 73, 74, 75, 76, 80, 84, 85, 86, 87, 88, 89], "can": [7, 9, 11, 18, 25, 31, 44, 55, 56, 60, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 89], "quantize_": [7, 9, 11, 39, 43, 46, 55, 56, 57, 58, 59, 66, 68, 71, 72, 73, 74, 76], "sparsity_": 7, "function": [7, 11, 16, 33, 38, 48, 53, 54, 55, 62, 63, 64, 66, 67, 70, 71, 72, 73, 75, 76, 78, 80, 84, 89], "To": [7, 9, 11, 52, 70, 71, 72, 73, 74, 75, 76, 80, 85, 86, 87, 89], "correspond": [7, 11, 39, 46, 55, 71, 73, 75, 78, 88, 89], "string": [7, 13, 44, 63, 67], "string_to_config": 7, "microbenchmark": 7, "util": [7, 9, 67, 68, 71, 73, 78, 80, 84, 85, 86, 87, 88, 89], "py": [7, 9, 67, 82, 83, 87, 88], "def": [7, 9, 11, 58, 66, 67, 70, 71, 72, 73, 76, 78, 80, 84, 85, 86, 87, 88, 89], "option": [7, 9, 12, 13, 16, 18, 23, 24, 27, 28, 29, 33, 34, 36, 37, 41, 43, 44, 46, 48, 49, 55, 56, 59, 60, 63, 66, 67, 70, 71, 72, 79, 80, 85, 86, 87, 88, 89], "str": [7, 13, 16, 44, 46, 55, 63, 66, 67, 70, 78, 80, 88], "kwarg": [7, 9, 33, 34, 35, 36, 40, 44, 49, 59, 62, 63, 64, 67, 71, 78, 80], "aobaseconfig": [7, 46, 55, 66, 76, 80], "code": [7, 9, 70, 71, 72, 74, 75, 76, 78, 81, 83, 85, 86, 87, 88, 89], "elif": [7, 80], "my_new_quant": 7, "If": [7, 8, 9, 11, 16, 18, 23, 24, 30, 43, 44, 46, 61, 63, 67, 71, 74, 75, 78, 85, 86], "addit": [7, 11, 67, 70, 71, 75, 78, 79, 84, 85, 88, 89], "inform": [7, 18, 71, 74, 75, 80, 84, 85], "need": [7, 9, 11, 18, 33, 38, 48, 57, 58, 59, 62, 63, 67, 71, 73, 74, 75, 78, 80, 85, 86, 87, 89], "pass": [7, 16, 23, 28, 33, 34, 38, 46, 48, 62, 67, 71, 76, 78, 80, 86, 89], "process": [7, 11, 71, 75, 83, 84, 88], "here": [7, 8, 46, 52, 60, 71, 72, 73, 74, 76, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89], "return": [7, 9, 11, 16, 30, 44, 55, 61, 66, 67, 70, 71, 72, 73, 76, 78, 80, 84, 85, 86, 87, 88, 89], "mynewquantizationconfig": 7, "my_new_spars": 7, "mynewsparsityconfig": 7, "rest": [7, 57, 78, 86], "now": [7, 9, 11, 19, 21, 22, 27, 70, 71, 72, 75, 76, 78, 79, 84, 85, 87, 89], "we": [7, 9, 11, 21, 23, 25, 27, 28, 29, 43, 44, 46, 52, 55, 60, 66, 67, 70, 71, 72, 73, 74, 75, 76, 79, 80, 84, 85, 86, 87, 88, 89], "throughout": 7, "note": [7, 9, 11, 31, 43, 52, 63, 67, 71, 72, 74, 75, 78, 80, 86, 87, 88], "input": [7, 9, 13, 16, 17, 27, 28, 29, 30, 46, 50, 55, 60, 61, 63, 66, 70, 71, 72, 74, 76, 78, 84, 85, 86, 87, 88, 89], "paramet": [7, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 36, 37, 44, 46, 49, 51, 52, 55, 60, 61, 63, 66, 67, 70, 71, 73, 74, 75, 78, 80, 84, 85], "like": [7, 9, 11, 18, 70, 71, 72, 73, 75, 78, 79, 80, 84, 85, 86, 87, 88, 89], "bit": [7, 11, 45, 74, 78, 79, 80, 85, 87, 88], "width": [7, 45], "group": [7, 9, 11, 18, 19, 22, 24, 36, 40, 41, 42, 44, 48, 49, 51, 52, 56], "size": [7, 9, 21, 22, 24, 27, 29, 44, 60, 70, 73, 74, 75, 76, 78, 80, 86], "etc": [7, 9, 18, 33, 34, 57, 59, 71, 84, 89], "them": [7, 11, 33, 38, 48, 62, 89], "append": [7, 75, 85, 86], "config": [7, 11, 13, 16, 18, 20, 21, 23, 32, 33, 34, 35, 37, 38, 39, 43, 44, 45, 46, 55, 63, 66, 71, 72, 74, 75, 76, 79, 80, 85, 87, 88], "gemliteuintxweightonlyconfig": 7, "gemlitewo": 7, "bit_width": 7, "group_siz": [7, 11, 19, 21, 22, 24, 33, 34, 36, 40, 43, 44, 46, 48, 49, 55, 79, 80], "system": [7, 9, 57, 74], "model_architectur": 7, "type": [7, 9, 11, 13, 14, 15, 16, 18, 20, 22, 23, 25, 26, 30, 44, 47, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71, 72, 73, 74, 75, 78, 80, 84, 85, 87, 88, 89], "defin": [7, 9, 14, 33, 38, 48, 62, 63, 67, 71, 72, 75, 76, 78, 80, 84, 87, 88, 89], "class": [7, 9, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 56, 57, 58, 62, 63, 67, 72, 73, 76, 78, 85, 86, 87, 89], "mycustommodel": 7, "torch": [7, 11, 13, 16, 18, 20, 27, 29, 30, 33, 34, 36, 37, 40, 41, 42, 43, 44, 46, 48, 49, 51, 52, 55, 56, 60, 61, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 83, 87, 88, 89], "nn": [7, 9, 11, 13, 16, 31, 36, 40, 43, 46, 55, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 80, 85, 86, 87, 89], "modul": [7, 9, 11, 13, 14, 15, 16, 17, 25, 26, 31, 33, 35, 36, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 62, 63, 66, 70, 71, 72, 73, 76, 80, 84, 85, 86, 87, 88, 89], "__init__": [7, 11, 67, 72, 73, 76, 78, 80, 85, 86, 87], "self": [7, 11, 67, 72, 73, 76, 78, 80, 85, 86, 87], "input_dim": [7, 72], "output_dim": [7, 72], "dtype": [7, 9, 11, 12, 18, 20, 26, 27, 28, 29, 33, 34, 36, 37, 40, 41, 42, 44, 48, 49, 51, 52, 59, 60, 66, 70, 72, 73, 74, 76, 78, 79, 80, 85, 87, 88, 89], "bfloat16": [7, 36, 41, 51, 60, 70, 71, 72, 73, 74, 75, 76, 79, 80, 87, 88], "super": [7, 11, 72, 73, 76, 78, 85, 86, 87], "layer1": 7, "linear": [7, 9, 11, 13, 16, 18, 19, 20, 22, 23, 24, 31, 34, 36, 41, 42, 43, 46, 51, 52, 53, 54, 55, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 84, 85, 86, 87, 89], "512": [7, 70], "bia": [7, 11, 34, 51, 52, 71, 72, 73, 76, 78, 80, 86, 89], "fals": [7, 11, 13, 23, 27, 33, 34, 42, 43, 44, 46, 48, 49, 51, 52, 63, 70, 71, 72, 73, 74, 76, 78, 79, 80, 84, 85, 86, 88, 89], "activ": [7, 11, 18, 22, 23, 33, 34, 36, 42, 43, 44, 46, 52, 58, 59, 63, 68, 74, 75, 76, 79, 80, 84, 87, 88, 89], "relu": [7, 72, 84, 89], "layer2": 7, "forward": [7, 23, 33, 34, 38, 45, 48, 51, 62, 72, 73, 75, 76, 78, 80, 85, 86, 87], "x": [7, 33, 34, 38, 45, 48, 70, 72, 73, 74, 76, 78, 80, 83, 84, 85, 86, 87, 88], "updat": [7, 68, 72, 73, 75, 85, 86, 89], "create_model_and_input_data": 7, "handl": [7, 9], "model_typ": [7, 11, 80, 84], "m": [7, 9, 11, 55, 66, 70, 72, 73, 74, 76, 78, 85, 86, 87], "int": [7, 11, 18, 20, 21, 22, 23, 24, 27, 28, 29, 33, 34, 36, 40, 41, 42, 44, 48, 49, 51, 52, 55, 60, 63, 67, 76, 78, 80], "k": [7, 9, 61, 73, 76, 78, 85, 86], "n": [7, 9, 11, 73, 76, 78, 85, 86, 89], "high_precision_dtyp": 7, "devic": [7, 9, 11, 48, 51, 52, 55, 61, 70, 72, 73, 74, 76, 78, 80, 84, 85, 86, 87, 88], "cuda": [7, 9, 11, 55, 70, 72, 73, 74, 75, 76, 78, 79, 86], "my_custom_model": 7, "input_data": 7, "randn": [7, 11, 34, 70, 72, 73, 76, 78, 84, 85, 86, 87, 88], "when": [7, 9, 11, 27, 29, 46, 60, 67, 70, 71, 74, 75, 76, 79, 80, 84, 85, 86, 87, 88, 89], "ad": [7, 11, 29, 63, 67, 71, 75, 76, 78, 86], "dimens": [7, 9, 27, 29, 30, 60, 70, 71, 78, 80, 85, 86], "ensur": [7, 74, 86], "convent": 7, "where": [7, 25, 28, 40, 41, 42, 71, 75, 80, 89], "batch": [7, 74, 76, 86], "sequenc": 7, "length": 7, "featur": [7, 11, 78, 84, 87, 88], "data": [7, 11, 18, 20, 23, 28, 57, 67, 68, 71, 73, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 89], "typic": [7, 11, 71, 72, 73, 76, 80, 89], "compat": [7, 9, 44, 72], "work": [7, 9, 11, 70, 73, 75, 78, 79, 80, 85, 86, 87], "cpu": [7, 9, 73, 75, 76, 79, 80, 84, 85, 86, 87], "other": [7, 11, 18, 45, 56, 63, 70, 73, 74, 75, 78, 80, 83, 85, 86, 87, 89], "target": [7, 9, 11, 18, 20, 21, 27, 33, 34, 37, 44, 63, 72, 75, 84, 85, 86, 87, 88, 89], "method": [7, 9, 55, 63, 72, 75, 76, 78, 79, 84, 85, 86, 88, 89], "come": [7, 8, 70, 71, 74, 75, 76, 77, 79, 86, 87, 88], "soon": [7, 8, 74, 77, 86], "file": [7, 9, 70, 72, 74, 78, 80, 82, 85, 86], "microbenchmark_quantization_config": 7, "yml": 7, "benchmark_mod": 7, "infer": [7, 11, 46, 68, 71, 72, 73, 75, 76, 78, 79, 84, 85, 86, 87, 88], "quantization_config_recipe_nam": 7, "int8wo": [7, 79], "int8dq": 7, "float8dq": [7, 74], "tensor": [7, 11, 12, 20, 21, 22, 23, 24, 27, 28, 29, 30, 33, 34, 35, 37, 38, 45, 56, 57, 58, 59, 60, 61, 63, 67, 68, 70, 72, 73, 75, 76, 79, 83, 85, 87, 88], "row": [7, 9, 19, 30, 70, 71, 75], "float8wo": 7, "output_dir": [7, 79], "result": [7, 11, 30, 61, 71, 72, 75, 76, 79, 85, 86, 87, 88, 89], "model_param": 7, "name": [7, 9, 14, 15, 25, 26, 47, 55, 56, 57, 63, 66, 67, 71, 74, 75, 78, 80, 84, 85, 86, 89], "small_bf16_linear": 7, "matrix_shap": 7, "small_sweep": 7, "min_pow": 7, "10": [7, 9, 11, 25, 33, 60, 70, 72, 74, 76, 85, 86], "max_pow": 7, "15": [7, 70, 74], "torch_compile_mod": 7, "max": [7, 9, 25, 71, 72, 76, 78, 85, 86, 89], "autotun": [7, 9, 72, 76], "runner": 7, "gener": [7, 11, 33, 34, 35, 38, 45, 71, 72, 74, 75, 76, 78, 80, 81, 83, 84, 86, 87, 88, 89], "oss": 7, "databas": 7, "python": [7, 9, 72, 74, 75, 81, 83, 84, 85, 87, 88], "ci_microbenchmark_runn": 7, "benchmark_result": 7, "json": [7, 74, 80], "specif": [7, 9, 11, 33, 34, 52, 57, 63, 70, 71, 73, 74, 75, 79, 84, 87, 88, 89], "requir": [7, 11, 56, 67, 71, 72, 74, 75, 78, 79, 84, 87, 89], "mode": [7, 9, 72, 76, 84, 86, 87, 88, 89], "extra_info": 7, "arch": 7, "nvidia": [7, 75], "a100": [7, 11, 79], "sxm4": 7, "80gb": 7, "1024": [7, 55, 66, 72, 73, 87], "custom": [7, 11, 46, 62, 68, 70, 71, 75, 78, 80, 84, 85, 87, 89], "layer": [7, 16, 18, 20, 23, 24, 33, 34, 36, 40, 41, 42, 48, 49, 51, 52, 63, 64, 70, 74, 75, 76, 78, 80, 84, 89], "origin": [7, 11, 20, 23, 39, 60, 63, 71, 72, 73, 74, 75, 84, 85, 89], "metric": [7, 11, 63], "speedup": [7, 9, 11, 70, 71, 74, 75], "wrt": 7, "bf16": [7, 11, 27, 46, 75, 87, 88], "benchmark_valu": 7, "25": 7, "target_valu": 7, "0": [7, 9, 11, 33, 44, 48, 49, 60, 63, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 85, 86, 88, 89], "depend": [7, 73, 75, 78, 85, 86, 88], "step": [7, 11, 17, 46, 47, 70, 71, 75, 84, 85, 86, 87, 88, 89], "workflow": [7, 9, 55, 56, 66, 70, 72, 75, 89], "github": [7, 72, 74, 79], "action": [7, 80, 85, 86], "upload": 7, "verifi": [7, 72, 73, 78], "setup": [7, 74], "suit": [7, 9, 85, 87], "unittest": 7, "discov": 7, "out": [7, 9, 11, 25, 57, 63, 70, 71, 72, 74, 75, 78, 84, 85, 86, 87], "memori": [7, 9, 11, 70, 71, 75, 78, 79, 87, 88], "reduc": [7, 9, 11, 17, 46, 70, 72, 74, 75, 87], "matrix": [7, 18, 30, 56, 61, 63, 71, 75, 87], "miss": [7, 75], "i": [7, 8, 9, 11, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 43, 44, 46, 55, 58, 59, 60, 61, 63, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89], "properli": [7, 73], "instal": [7, 9, 70, 71, 72, 74, 79, 85, 88], "Not": [7, 75], "avail": [7, 9, 57, 71, 74, 84, 85, 86, 87, 88], "check": [7, 9, 11, 71, 72, 73, 74, 78, 84, 86, 89], "driver": 7, "basic": [7, 9, 72, 76, 78], "shape": [7, 9, 30, 57, 61, 71, 76, 78, 80, 85, 88], "comprehens": [7, 72, 80, 87], "analysi": [7, 75], "enabl": [7, 9, 54, 67, 70, 71, 72, 74, 80, 87], "profil": [7, 9], "onli": [7, 9, 11, 16, 18, 19, 20, 21, 22, 23, 24, 36, 46, 52, 70, 72, 73, 74, 75, 78, 79, 80, 84, 85, 87, 88, 89], "overhead": [7, 72, 75, 79, 80, 87], "multipl": [7, 9, 11, 18, 30, 31, 56, 58, 61, 71, 75, 76, 78, 80, 87, 89], "possibl": [7, 71, 75, 85, 86, 87, 89], "consist": [7, 74, 75, 78, 87, 88, 89], "reproduc": [7, 74], "differ": [7, 9, 11, 21, 28, 31, 60, 61, 70, 71, 72, 73, 74, 75, 78, 79, 80, 85, 86, 87, 89], "case": [7, 8, 9, 46, 56, 61, 74, 75, 78, 80, 84, 85, 89], "user": [7, 9, 11, 18, 31, 46, 52, 68, 70, 71, 72, 74, 75, 76, 78, 83, 85, 86, 87, 88, 89], "more": [7, 9, 11, 21, 22, 70, 71, 72, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88], "about": [7, 9, 11, 71, 72, 73, 74, 75, 85, 86, 87, 89], "compon": [7, 71, 78, 80], "see": [7, 9, 11, 67, 70, 71, 72, 73, 75, 76, 78, 79, 80, 84, 85, 89], "directori": [7, 70], "intend": [8, 56, 71, 85], "provid": [8, 9, 11, 27, 31, 50, 67, 70, 71, 72, 74, 75, 78, 80, 85, 86, 88, 89], "instruct": [8, 11, 71, 74, 85, 86, 87], "most": [8, 9, 46, 71, 74, 75, 80, 85, 86, 89], "fequent": 8, "have": [8, 9, 11, 25, 40, 41, 42, 57, 60, 63, 67, 71, 75, 76, 78, 80, 84, 85, 86, 87, 88, 89], "ani": [8, 9, 35, 36, 40, 50, 63, 71, 75, 78, 84, 86, 88], "answer": [8, 75], "creat": [8, 9, 70, 72, 75, 78, 79, 84, 85, 87, 88, 89], "an": [8, 11, 43, 44, 46, 52, 63, 68, 70, 71, 72, 74, 75, 76, 78, 79, 84, 85, 86, 87, 88, 89], "issu": [8, 56, 71, 72, 78, 87], "start": [9, 11, 14, 15, 25, 26, 47, 56, 57, 70, 71, 74, 75, 76, 78, 80, 84, 85, 86, 87, 88, 89], "read": [9, 78], "overview": [9, 68, 72, 80], "page": [9, 72, 87], "first": [9, 30, 46, 63, 67, 71, 74, 76, 78, 79, 80, 85, 86, 89], "contribut": [9, 72, 75], "exist": [9, 26, 46, 70, 71, 75, 76, 78, 85, 89], "base": [9, 18, 25, 32, 45, 46, 50, 58, 59, 63, 67, 71, 72, 75, 78, 79, 80, 84, 85, 86, 87, 88, 89], "api": [9, 71, 72, 75, 76, 78, 84, 85, 86, 87, 88], "quant_api": [9, 55, 73, 74, 76], "float8tensor": [9, 18, 20, 37, 58, 71, 80], "e": [9, 11, 25, 27, 29, 31, 44, 46, 55, 58, 60, 67, 70, 71, 73, 76, 78, 79, 84, 89], "g": [9, 11, 25, 27, 29, 31, 44, 46, 55, 58, 60, 67, 71, 73, 76, 78, 84, 89], "oper": [9, 11, 23, 28, 71, 72, 74, 84, 85, 86, 87, 88], "make": [9, 19, 71, 72, 78, 80, 85, 89], "trainabl": [9, 11, 71, 78], "add": [9, 67, 78, 79, 83, 87, 89], "parallel": [9, 70, 78, 80], "primit": [9, 78, 85], "op": [9, 11, 18, 55, 56, 67, 72, 75, 78, 80, 85, 86, 87, 89], "slight": [9, 75], "variat": [9, 71], "quant_primit": [9, 76], "mp": 9, "csrc": 9, "ar": [9, 11, 16, 18, 21, 27, 29, 31, 33, 34, 43, 46, 55, 56, 57, 60, 61, 63, 67, 70, 71, 72, 73, 74, 75, 76, 80, 84, 85, 86, 87, 88, 89], "structur": [9, 11, 66, 71, 72, 73, 75, 78, 85], "deriv": [9, 28, 59, 60], "pack": [9, 19, 21, 57], "format": [9, 21, 57, 74, 75, 85, 86, 89], "understand": [9, 57, 70, 87, 89], "concept": [9, 71, 83, 85, 87, 88, 89], "doe": [9, 11, 46, 56, 57, 71, 75, 78, 85, 87, 88], "alreadi": [9, 78, 89], "could": [9, 71, 78, 84, 85, 87, 88, 89], "context": [9, 87, 88], "also": [9, 11, 44, 55, 71, 72, 73, 75, 76, 78, 79, 80, 85, 88, 89], "write": [9, 68, 72, 84, 85, 86], "own": [9, 11, 68, 70, 72, 75, 76, 85, 86, 89], "torchaobasetensor": [9, 80], "help": [9, 11, 70, 71, 74, 80, 84, 85], "common": [9, 46, 56, 57, 58, 59, 68, 70, 71, 75], "specifi": [9, 11, 13, 16, 24, 31, 33, 34, 35, 38, 45, 46, 52, 55, 56, 60, 63, 66, 70, 71, 75, 84, 85, 86, 89], "non": [9, 67, 75, 78, 84, 87, 88], "attribut": [9, 11, 67, 71, 78, 80, 87, 88], "mytensor": [9, 67], "tensor_data_nam": [9, 67], "qdata": [9, 71], "scale": [9, 14, 17, 18, 25, 27, 28, 29, 30, 36, 37, 44, 49, 50, 51, 52, 59, 60, 67, 71, 75, 76, 78, 80, 89], "tensor_attribute_nam": [9, 67], "With": [9, 78, 85, 87, 89], "abov": [9, 11, 19, 25, 71, 73, 75, 76, 78, 85, 86, 89], "ll": [9, 25, 70, 71, 78, 85, 86, 89], "doc": [9, 70, 71, 72, 74, 78, 79], "mani": [9, 71, 75, 78], "still": [9, 11, 71, 72, 75, 85, 89], "affinequantizedtensor": [9, 23, 73, 76, 78], "plan": [9, 23, 86], "move": [9, 55, 76, 80, 86, 87], "awai": 9, "from": [9, 11, 22, 28, 39, 43, 46, 55, 56, 60, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89], "abstract": [9, 71], "easier": [9, 89], "peopl": [9, 71, 73, 80, 89], "implement": [9, 11, 13, 21, 48, 49, 51, 52, 56, 67, 71, 73, 75, 76, 84, 85, 89], "regist": [9, 33, 38, 48, 62, 67, 71, 78], "mai": [9, 28, 44, 57, 71, 73, 76, 79, 85, 86, 87, 88, 89], "well": [9, 71, 72, 75, 85, 86, 89], "int4": [9, 11, 19, 21, 22, 25, 33, 34, 36, 40, 41, 42, 43, 44, 46, 48, 49, 51, 52, 55, 71, 73, 74, 79, 80], "access": [9, 23, 84], "my_custom_op": 9, "call": [9, 11, 33, 38, 48, 62, 71, 73, 75, 76, 78, 80, 86, 88], "want": [9, 55, 66, 71, 72, 73, 75, 78, 80, 84, 85, 86, 89], "my_mm_for_mp": 9, "aten": [9, 67, 71, 72, 78, 80, 84, 85, 86, 87, 88], "default": [9, 11, 18, 20, 21, 27, 29, 36, 44, 52, 55, 67, 70, 71, 72, 78, 80, 84, 85, 86, 87, 88, 89], "_": [9, 67, 70, 71, 72, 76, 80, 84, 85, 86, 87], "func": [9, 67, 71, 78, 80], "arg": [9, 21, 33, 34, 35, 36, 40, 49, 63, 67, 71, 78, 80, 86, 89], "re": [9, 70, 71, 73, 74, 78, 85, 86], "input_tensor": [9, 71, 80], "weight_tensor": [9, 71, 80], "some": [9, 55, 63, 67, 71, 72, 74, 75, 76, 78, 84, 85, 86, 87, 88, 89], "choic": [9, 21], "mm": [9, 55, 56, 78, 85], "recommend": [9, 11, 18, 20, 21, 22, 23, 24, 70, 71, 72, 79, 84, 87, 88], "wai": [9, 46, 70, 71, 74, 75, 76, 78, 85, 86, 89], "repres": [9, 13, 32, 44, 57, 60, 63, 71, 73, 78, 85, 86], "group_mm": 9, "auto": [9, 18, 56, 74, 79, 80], "develop": [9, 72, 85, 86, 89], "choos": [9, 21, 59, 71, 75, 78, 85, 87], "whatev": 9, "think": [9, 80], "fastest": 9, "under": [9, 11, 56, 74], "condit": 9, "so": [9, 11, 70, 71, 72, 73, 75, 78, 79, 85, 86, 89], "don": [9, 63, 70, 71, 72, 75, 79, 80, 89], "t": [9, 63, 67, 70, 71, 72, 75, 76, 78, 79, 80, 85, 86, 89], "worri": 9, "debug": [9, 56], "purpos": [9, 70, 71, 78, 85], "ha": [9, 11, 46, 74, 75, 78, 80, 84, 85, 86, 88, 89], "hardwar": [9, 18, 56, 57, 72, 74, 75, 79], "h100": [9, 71, 79], "sm89": 9, "sm90": 9, "librari": [9, 56, 57, 68, 71, 73], "whether": [9, 11, 27, 44, 67, 78], "fbgemm_gpu_genai": [9, 56, 71], "granular": [9, 14, 18, 21, 22, 23, 24, 27, 29, 33, 34, 36, 37, 44, 45, 60, 70, 71, 74, 76, 80], "per": [9, 11, 19, 20, 22, 23, 24, 27, 29, 36, 40, 41, 42, 44, 48, 49, 51, 52, 60, 63, 70, 71, 75, 76, 88], "_choose_scale_float8": [9, 27, 71], "_quantize_affine_float8": [9, 71], "_scaled_mm": [9, 71], "kerenel": 9, "fbgemm": [9, 56, 71, 75], "f8f8bf16_rowwis": [9, 71], "level": [9, 63, 71, 75, 78, 84, 85, 87, 88], "reus": [9, 78], "allow": [9, 52, 71, 72, 75, 78, 84, 85, 86, 87, 89], "appli": [9, 11, 18, 19, 20, 22, 23, 24, 31, 35, 36, 38, 43, 45, 46, 55, 66, 67, 71, 74, 75, 80, 86], "convers": [9, 11, 16], "weight": [9, 11, 17, 18, 19, 20, 21, 22, 23, 24, 33, 34, 36, 40, 41, 42, 44, 46, 48, 49, 51, 52, 55, 58, 63, 66, 68, 70, 73, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 89], "filter": [9, 11, 16, 70, 76], "should": [9, 11, 17, 29, 33, 38, 39, 46, 48, 62, 63, 67, 70, 75, 80, 84, 85, 89], "algorithm": [9, 21, 74, 75, 84], "dynam": [9, 11, 12, 13, 17, 18, 19, 22, 23, 36, 42, 44, 52, 66, 74, 76, 78, 79, 85, 86, 87], "quant": [9, 71, 74, 80, 85, 88, 89], "In": [9, 11, 21, 46, 70, 71, 72, 75, 76, 78, 84, 85, 86, 87, 88, 89], "order": [9, 31, 67, 75, 78, 89], "aim": [9, 75, 88], "run": [9, 11, 17, 33, 34, 38, 48, 55, 56, 62, 70, 71, 72, 74, 75, 78, 83, 84, 85, 86, 87, 88, 89], "fullgraph": [9, 72], "true": [9, 11, 13, 18, 20, 21, 22, 23, 24, 27, 28, 33, 34, 43, 44, 46, 54, 55, 66, 70, 72, 73, 74, 76, 78, 79, 80, 84, 85, 86, 87, 89], "remov": [9, 27, 63, 70, 75, 80, 85, 86], "unnecessari": 9, "graph": [9, 72, 85, 86, 89], "break": 9, "torch_log": 9, "output_cod": 9, "script": [9, 72, 74, 76, 78, 83, 86, 87, 88], "inductor": [9, 68, 72, 84, 85], "save": [9, 11, 63, 67, 70, 72, 73, 74, 80], "load": [9, 67, 73, 74, 79, 80], "relev": [9, 71, 83], "object": [9, 55, 66, 71, 78, 85, 86, 89], "safe": [9, 61], "global": [9, 75, 78], "after": [9, 11, 17, 70, 71, 73, 75, 79, 84, 85, 86, 87, 88, 89], "2": [9, 18, 20, 21, 23, 24, 25, 33, 44, 48, 49, 60, 64, 66, 68, 70, 71, 75, 76, 78, 83], "5": [9, 11, 25, 33, 63, 72, 74, 75, 80, 83, 85, 86], "add_safe_glob": 9, "quantizetensortofloat8kwarg": [9, 71], "checkout": [9, 68, 71], "huggingfac": [9, 79], "transform": [9, 11, 67, 76, 84, 85, 86, 87, 88], "deseri": [9, 85, 86], "save_pretrain": [9, 74, 79], "push_to_hub": [9, 74, 79, 80], "from_pretrain": [9, 11, 74, 79, 80], "diffus": [9, 74], "just": [9, 25, 44, 71, 73, 75, 78, 85, 86, 89], "talk": [9, 71, 74], "train": [9, 13, 31, 44, 46, 68, 72, 75, 78, 89], "fsdp": [9, 71], "mydtypetensor": 9, "put": [9, 66, 87, 89], "developer_api_guid": 9, "folder": [9, 74, 85, 86], "cover": [9, 83, 85, 88, 89], "follow": [9, 11, 44, 46, 67, 70, 71, 72, 74, 75, 76, 78, 79, 84, 85, 86, 87, 88, 89], "executorch": [9, 22, 68, 72, 79, 85, 86], "torchchat": 9, "dtensor": [9, 78], "copi": [9, 63, 72, 73, 75, 76, 78, 86, 87], "past": [9, 75], "adapt": [9, 70, 76], "befor": [9, 11, 46, 55, 71, 73, 74, 75, 76, 78, 85, 86, 89], "do": [9, 26, 30, 55, 71, 74, 75, 76, 78, 80, 85, 86, 87, 89], "singl": [9, 11, 12, 17, 18, 28, 70, 75, 85, 89], "comput": [9, 17, 20, 33, 38, 48, 56, 62, 63, 71, 75, 76, 78, 79, 85, 86, 87, 88], "intens": 9, "get": [9, 11, 52, 67, 70, 71, 72, 74, 75, 80, 84, 85, 86, 87, 89], "sens": [9, 71, 78], "d": [9, 67, 74, 86], "benchmark_aq": 9, "": [9, 11, 25, 27, 29, 56, 57, 60, 67, 70, 71, 72, 74, 75, 76, 78, 85, 86, 87, 88, 89], "import": [9, 11, 39, 43, 46, 55, 66, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 87, 88], "A": [9, 11, 28, 56, 62, 67, 71, 75, 78, 79, 80, 85], "quick": [9, 68], "chang": [9, 55, 70, 72, 73, 74, 75, 76, 78, 84, 85, 86, 88, 89], "interest": [9, 75, 78], "print_op_and_shap": 9, "output": [9, 11, 13, 27, 29, 60, 70, 71, 72, 74, 75, 79, 83, 84, 85, 86, 87, 88, 89], "torch_func": 9, "built": [9, 70, 78], "_c": 9, "tensorbas": 9, "all": [9, 17, 25, 28, 33, 36, 38, 40, 48, 50, 62, 63, 64, 67, 71, 72, 73, 74, 75, 76, 78, 80, 81, 84, 85, 87, 89], "benchmark_your_kernel": 9, "helper": [9, 53, 54, 67], "right": [9, 19, 21, 75, 85], "1": [9, 14, 15, 18, 20, 21, 23, 24, 25, 26, 27, 37, 47, 56, 57, 59, 60, 63, 68, 71, 72, 73, 75, 76, 78, 83, 85, 86], "feel": [9, 71, 75, 78, 80], "free": [9, 71, 78], "either": [9, 18, 37, 46, 63, 74, 75, 86, 87, 88], "one": [9, 18, 28, 33, 38, 46, 48, 62, 70, 71, 75, 78, 80, 86, 89], "probabl": 9, "keep": [9, 23, 27, 63, 71, 85], "futur": [9, 76, 79, 80, 85, 86, 87, 89], "llama": [9, 11, 74, 79, 80, 84], "llama2": 9, "llama3": [9, 11, 70, 79], "sam": 9, "modifi": [9, 16, 55, 63, 70, 75, 78], "friendli": 9, "compar": [9, 11, 63, 70, 71, 72, 74, 85, 87, 89], "techniqu": [9, 11, 70, 73, 74, 75, 76, 78, 80], "bound": [9, 18, 37, 74, 75, 80], "each": [9, 36, 44, 49, 51, 52, 62, 67, 71, 75, 76, 78, 80, 85, 86, 89], "profile_path": 9, "chrome": 9, "trace": 9, "let": [9, 25, 60, 71, 72, 75, 76, 78, 89], "u": [9, 75, 84], "know": [9, 78], "end": [11, 70, 71, 74, 75, 78, 79, 80, 86, 89], "pre": [11, 68, 74, 75, 89], "serv": [11, 68, 70, 72, 78, 79, 88], "flow": [11, 22, 70, 74, 75, 76, 84, 85, 86, 87, 88], "leverag": [11, 70, 74, 78, 87, 88], "partner": [11, 70, 74], "showcas": [11, 70, 74], "focus": [11, 70, 71, 74, 75], "domain": [11, 27, 29, 44, 70], "demonstr": [11, 70, 71, 72, 74, 78, 84, 86], "dure": [11, 23, 29, 44, 46, 70, 72, 74, 75, 76, 78, 84, 86], "numer": [11, 46, 51, 52, 56, 70, 75, 85, 86, 87], "goal": [11, 46], "mitig": [11, 75], "degrad": [11, 46, 75], "eventu": [11, 46, 70], "blog": 11, "resourc": [11, 78], "small": [11, 72], "matric": [11, 75], "freez": [11, 86, 87, 88], "checkpoint": [11, 67, 70, 74, 80], "effici": [11, 51, 75, 76, 88], "paper": [11, 75, 83], "speed": [11, 55, 74, 75, 84], "up": [11, 44, 55, 70, 71, 75, 84, 85, 86, 89], "high": [11, 37, 46, 70, 71, 74, 75, 76, 78, 84, 85, 87, 88], "precis": [11, 20, 23, 36, 37, 41, 42, 46, 49, 51, 52, 71, 76, 78, 79, 84, 87, 88], "similar": [11, 75, 76, 86, 87], "inevit": 11, "actual": [11, 20, 46, 56, 71, 76, 78, 80, 85, 86, 89], "presum": 11, "been": [11, 67, 78, 86, 87, 88, 89], "successfulli": [11, 75], "recent": [11, 68], "releas": [11, 87], "1b": [11, 79, 80], "3b": 11, "llamaguard": 11, "8b": [11, 70, 72, 79], "improv": [11, 70, 74, 75, 85, 88, 89], "qualiti": [11, 75, 79], "involv": [11, 46, 75], "two": [11, 18, 46, 67, 71, 72, 75, 78, 84, 85, 86, 87, 89], "separ": [11, 33, 34, 44, 75, 80, 85, 89], "prepar": [11, 31, 36, 40, 46, 63, 75, 84, 87, 88, 89], "convert": [11, 13, 31, 39, 40, 46, 55, 66, 70, 71, 74, 75, 84, 87, 88, 89], "fake": [11, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 70, 85, 86, 89], "mean": [11, 25, 27, 29, 60, 67, 70, 71, 75, 85, 86, 89], "valu": [11, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 37, 47, 56, 57, 60, 63, 71, 75, 76, 78, 84, 85, 86, 89], "map": [11, 23, 25, 44, 67, 71, 78, 85, 89], "without": [11, 39, 71, 75, 80, 87, 89], "cast": [11, 12, 14], "lower": [11, 18, 22, 37, 71, 72, 74, 75, 76, 79, 86], "replac": [11, 75, 80], "real": [11, 71, 72, 85, 89], "perform": [11, 17, 23, 24, 30, 33, 38, 40, 41, 42, 48, 61, 62, 70, 72, 75, 76, 78, 79, 80, 84, 86, 87, 88], "There": [11, 46, 71, 76, 78, 85, 89], "directli": [11, 25, 28, 46, 71, 75, 76, 78], "loop": [11, 70, 75], "distribut": [11, 70, 76, 78, 80, 84], "recip": [11, 13, 33, 38, 48, 62], "instead": [11, 28, 33, 38, 39, 43, 44, 46, 48, 62, 70, 72, 75, 78, 86, 87, 88, 89], "command": [11, 70], "regular": [11, 84, 87, 88], "nnode": 11, "nproc_per_nod": 11, "4": [11, 64, 66, 71, 72, 73, 74, 75, 78, 79, 85, 86], "full_finetune_distribut": 11, "llama3_2": 11, "3b_full": 11, "batch_siz": [11, 72, 73, 74, 76, 85, 86], "16": [11, 34, 70], "equival": [11, 44, 75, 86, 87, 89], "asymmetr": [11, 22, 25, 27, 44, 76, 84, 88, 89], "token": [11, 22, 23, 42, 44, 52, 70, 74, 79], "int8": [11, 22, 23, 24, 34, 42, 43, 44, 46, 52, 55, 59, 66, 71, 72, 74, 78, 85, 87, 88, 89], "symmetr": [11, 18, 20, 22, 23, 24, 25, 27, 33, 36, 44, 78, 84, 85, 88, 89], "configur": [11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 55, 66, 70, 71, 74, 79, 87, 88, 89], "_component_": 11, "qat_distribut": 11, "3b_qat_ful": 11, "evalu": [11, 72, 86], "same": [11, 18, 21, 27, 28, 29, 52, 60, 61, 66, 67, 70, 71, 75, 76, 78, 86, 88, 89], "wa": [11, 78, 86], "llama3_2_3b": 11, "fullmodelhfcheckpoint": 11, "checkpoint_fil": 11, "00001": 11, "00002": 11, "safetensor": [11, 79], "int8dynactint4weightquant": 11, "groupsiz": [11, 41, 42, 51, 52, 60], "32": [11, 21, 22, 34, 43, 44, 46, 48, 49, 55, 66, 70, 73, 74, 76, 78, 86], "hellaswag": [11, 74], "wikitext": 11, "eleuther_ev": 11, "eleuther_evalu": 11, "task": [11, 74], "fullmodeltorchtunecheckpoint": 11, "8da4w": [11, 74], "ckpt": 11, "llama3_token": 11, "path": [11, 55, 61, 72, 74, 84, 85, 86, 87, 89], "tmp": 11, "meta": [11, 73, 79, 80, 89], "print": [11, 63, 72, 73, 74, 78, 83, 85, 86], "version": [11, 18, 20, 21, 23, 24, 44, 71, 78, 80, 85, 86, 89], "shot": [11, 75], "stderr": 11, "none": [11, 12, 13, 14, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 33, 34, 36, 37, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59, 60, 63, 66, 67, 71, 76, 78, 80, 84, 85, 86, 88], "acc": [11, 85, 86], "5021": 11, "0050": 11, "acc_norm": 11, "6797": 11, "0047": 11, "bits_per_byt": 11, "6965": 11, "byte_perplex": 11, "6206": 11, "word_perplex": 11, "13": 11, "2199": 11, "much": [11, 75, 89], "openassist": 11, "oasst1": 11, "dataset": [11, 70, 74, 84, 87, 88], "find": [11, 75, 85, 89], "achiev": [11, 70, 72, 75, 76, 78, 86, 87], "higher": [11, 70, 78, 79, 84, 85, 87, 88], "accuraci": [11, 70, 72, 74, 75, 76, 84, 86, 87], "than": [11, 44, 70, 71, 72, 75, 78, 85], "recov": [11, 75, 86], "69": [11, 76], "8": [11, 25, 33, 34, 41, 51, 70, 71, 74, 80, 87, 88], "overal": [11, 68, 72, 85, 89], "vanilla": 11, "compos": [11, 31, 71, 75, 78, 85, 86, 89], "lora": 11, "yield": [11, 75], "89x": 11, "usag": [11, 17, 31, 33, 34, 39, 43, 44, 46, 67, 68, 70, 74, 87, 88], "36": [11, 70, 74], "qat_lora_finetune_distribut": 11, "3b_qat_lora": 11, "set": [11, 18, 20, 21, 22, 23, 24, 28, 44, 55, 63, 67, 75, 84, 86, 87, 88], "try": [11, 75, 78, 85], "fsdp2": [11, 70], "yaml": 11, "onc": [11, 75], "complet": [11, 74, 84, 88], "qat_out": 11, "quatiz": 11, "document": [11, 78, 80, 84, 85, 87], "prefer": [11, 18, 71, 78], "These": [11, 75, 78, 84, 85, 86, 89], "what": [11, 70, 71, 74, 75, 76, 80, 83, 85, 89], "hood": 11, "mini": [11, 74], "gpu": [11, 68, 70, 72, 79, 80, 83, 84], "smaller": [11, 21, 22, 72, 73], "fit": [11, 71, 73], "adjust": [11, 18, 20, 21, 22, 23, 24], "accordingli": 11, "get_model": 11, "vocab_s": 11, "4096": [11, 70], "num_lay": 11, "num_head": 11, "num_kv_head": 11, "embed_dim": 11, "2048": [11, 70], "max_seq_len": 11, "train_loop": [11, 46], "sgd": 11, "lr": [11, 70], "001": 11, "momentum": [11, 86], "9": [11, 70], "weight_decai": 11, "1e": [11, 70], "loss_fn": 11, "crossentropyloss": [11, 85, 86], "rang": [11, 25, 70, 72, 75, 76, 85, 86], "randint": 11, "loss": [11, 70, 75, 85, 86], "backward": [11, 17, 70, 75, 86], "zero_grad": [11, 70, 86], "next": [11, 70, 76, 85, 86, 87, 88], "scheme": [11, 23, 24, 33, 34, 46, 74, 84], "although": [11, 21, 33, 38, 48, 62, 78], "integ": [11, 25, 27, 29, 30, 44, 45, 61, 76, 85, 86, 87], "arithmet": [11, 46], "float": [11, 18, 25, 27, 28, 29, 33, 37, 44, 48, 49, 60, 63, 71, 72, 73, 78, 85, 86, 89], "float32": [11, 29, 40, 42, 44, 48, 49, 52, 60, 73, 74, 75, 76, 78, 87, 88, 89], "becaus": [11, 70, 72, 73, 75, 78, 86, 89], "int8dynamicactivationint4weightconfig": [11, 46, 52], "qatconfig": [11, 39, 43, 47], "swap": [11, 16, 36, 40, 70, 75, 76, 86], "fakequantizedlinear": [11, 36, 39, 53, 54], "base_config": [11, 46], "exact": [11, 52, 85, 86], "attun": 11, "benefici": 11, "later": [11, 71, 78, 85, 86, 88], "readi": [11, 70, 72, 74, 76, 78, 86], "did": [11, 22], "altern": [11, 44, 76, 78, 87, 88], "legaci": 11, "offer": [11, 72, 78, 85], "customiz": [11, 55], "unlik": [11, 76], "int8dynactint4weightqatquant": 11, "qat_quant": 11, "insert": [11, 72, 76, 84, 85, 86, 87, 88, 89], "int8dynactint4weightqatlinear": 11, "int8dynactint4weightlinear": 11, "fraction": 11, "therebi": 11, "significantli": [11, 72, 84, 85, 87, 88], "footprint": 11, "extens": [11, 78, 85, 87], "addition": [11, 87, 88], "frozen": 11, "further": [11, 78, 84, 85, 86, 87], "nf4": 11, "propos": [11, 63], "express": [11, 72, 78, 84, 85, 86, 89], "subclass": [11, 16, 33, 38, 48, 56, 57, 62, 66, 67, 71, 72, 73, 75, 79], "nf4tensor": 11, "cleanli": 11, "compil": [11, 55, 61, 68, 70, 71, 72, 76, 78, 87, 88], "simpli": [11, 75, 76, 78], "to_nf4": 11, "frozennf4linear": 11, "in_dim": 11, "out_dim": 11, "bool": [11, 13, 16, 18, 20, 21, 22, 23, 24, 27, 28, 33, 34, 42, 44, 48, 49, 51, 52, 54, 55, 66, 76], "quantization_kwarg": 11, "No": [11, 71, 73, 75], "requires_grad_": 11, "nf4_weight": 11, "requires_grad": [11, 71, 76, 78, 80], "though": [11, 78], "shown": [11, 74, 75, 86, 89], "competit": [11, 70], "baselin": [11, 70, 74, 85], "while": [11, 33, 38, 46, 48, 58, 62, 63, 72, 74, 75, 78, 79, 84, 85, 89], "even": [11, 70, 75, 89], "newer": 11, "mxfp4": [11, 71], "nvfp4": [11, 71], "blackwel": 11, "reap": 11, "benefit": [11, 19, 75, 78, 85, 88], "vari": [11, 72, 85, 86, 87, 88], "tradeoff": [11, 75, 79], "incorpor": 11, "its": [11, 75, 78, 80, 85, 89], "loralinear": 11, "lora_finetune_single_devic": 11, "3b_qlora_single_devic": 11, "limit": [11, 70, 71, 78, 80, 85], "yet": [11, 22, 26, 46, 78, 80, 86, 87, 88], "invok": [11, 87], "loraconfig": 11, "get_peft_model": 11, "automodelforcausallm": [11, 74, 79, 80], "torchaoconfig": [11, 74, 79, 80], "int8weightonlyconfig": [11, 55, 79, 80], "base_model": 11, "quantization_config": [11, 74, 79, 80, 88], "peft_config": 11, "throughput": [11, 70, 72, 74], "increas": [11, 75, 85], "torchtitan": 11, "enable_fp8_train": 11, "fp8_recipe_nam": 11, "tensorwis": [11, 12, 13, 71], "initi": [11, 50, 71, 72, 73, 86], "experi": [11, 70, 88], "saw": 11, "experiment_nam": 11, "tok": 11, "peak_mem_reserv": 11, "6502": 11, "143": 11, "000": 11, "30": [11, 70, 85], "090": 11, "fp8_nonam": 11, "7205": 11, "386": 11, "816": 11, "010": 11, "266": 11, "fp8_tensorwis": 11, "7222": 11, "198": 11, "11": [11, 70], "074": [11, 70], "fp8_rowwis": 11, "6387": 11, "968": 11, "756": 11, "29": [11, 70], "158": 11, "096": 11, "fp8_rowwise_with_gw_hp": 11, "7573": 11, "698": 11, "480": 11, "516": 11, "908": 11, "hellaswag_acc": 11, "wikitext_word_perplex": 11, "533": 11, "12": [11, 70, 88, 89], "407": [11, 70], "414": 11, "007": 11, "412": 11, "005": 11, "420": 11, "013": [11, 70], "534": 11, "416": 11, "009": 11, "float8": [12, 13, 14, 15, 16, 17, 18, 19, 20, 36, 37, 38, 59, 68, 74, 76], "scaling_typ": [12, 13], "scalingtyp": [12, 13], "scaling_granular": [12, 13], "scalinggranular": [12, 13], "target_dtyp": [12, 13, 27, 28, 71, 76], "sourc": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 74, 81, 83], "mayb": 12, "cast_config_input": 13, "castconfig": 13, "cast_config_input_for_grad_weight": 13, "cast_config_weight": 13, "cast_config_weight_for_grad_input": 13, "cast_config_grad_output": 13, "cast_config_grad_output_for_grad_weight": 13, "gemm_config_output": 13, "float8gemmconfig": 13, "use_fast_accum": 13, "gemm_config_grad_input": 13, "gemm_config_grad_weight": 13, "enable_fsdp_float8_all_gath": 13, "pad_inner_dim": 13, "emul": [13, 56], "force_recompute_fp8_weight_in_bwd": 13, "round_scales_to_power_of_2": 13, "static": [13, 28, 44, 68, 72, 85, 86, 87, 88, 89], "from_recipe_nam": 13, "recipe_nam": [13, 70], "union": [13, 18, 27, 29, 37, 44, 55, 60], "float8linearrecipenam": 13, "qualnam": [14, 15, 25, 26, 47, 56, 57], "boundari": [14, 15, 25, 26, 47, 56, 57], "strategi": 14, "module_filter_fn": [16, 70], "callabl": [16, 55, 66, 67, 80], "float8linearconfig": 16, "float8linear": [16, 70], "instanc": [16, 33, 38, 48, 55, 62, 66, 67, 73, 78, 85, 87, 88, 89], "fqn": [16, 63, 66, 70, 76], "calcul": [17, 18, 25, 27, 28, 37, 71, 75, 85, 89], "It": [17, 72, 75, 78, 89], "sum": [17, 85, 86], "activation_dtyp": [18, 71], "float8_e4m3fn": [18, 20, 37, 71], "weight_dtyp": [18, 20, 71, 74], "pertensor": [18, 24, 37, 76], "perrow": [18, 23, 24, 37, 71], "list": [18, 29, 31, 63, 67, 72, 78, 79, 80, 84, 86, 89], "packing_format": [18, 21], "float8packingformat": 18, "plain": [18, 21, 57, 71, 80], "mm_config": 18, "float8mmconfig": 18, "activation_value_lb": 18, "activation_value_ub": 18, "kernel_prefer": [18, 71], "kernelprefer": 18, "set_inductor_config": [18, 20, 21, 22, 23, 24], "both": [18, 21, 46, 52, 71, 72, 75, 76, 78, 85, 87, 88, 89], "fp8granular": [18, 37], "tupl": [18, 27, 28, 29, 50, 60, 63, 67, 78, 80, 85, 86, 89], "And": [18, 78, 87, 89], "fast": [18, 75], "accumul": 18, "upper": [18, 37], "kernel": [18, 19, 51, 55, 56, 74, 75, 84, 87, 88], "matmul": [18, 20, 71, 75, 78], "defalut": 18, "chosen": [18, 59, 75], "torchinductor": [18, 20, 21, 22, 23, 24, 87, 88], "deprec": [18, 20, 23, 39, 43], "int4_packing_format": [19, 21], "int4packingformat": [19, 21], "preshuffl": [19, 71], "128": [19, 21, 70, 72, 74, 76, 78, 79, 80, 88, 89], "sinc": [19, 33, 38, 48, 62, 71, 73, 74, 75, 76, 78, 85, 86, 87, 88, 89], "underli": [19, 74, 78], "bigger": 19, "channel": [20, 23, 24, 36, 40, 41, 42, 44, 48, 49, 51, 52, 62, 76, 88], "int4_choose_qparams_algorithm": 21, "int4chooseqparamsalgorithm": 21, "tinygemm": [21, 51, 55], "groupwis": 21, "mainli": [21, 71, 84, 87, 89], "distinguish": [21, 71], "layout": [21, 22, 23, 66, 67, 75], "control": [21, 22, 23, 63, 75, 80, 85], "fine": [21, 22, 68, 70, 74, 75], "grain": [21, 22, 78], "256": [21, 40, 41, 42, 51, 52, 74, 85, 86, 89], "64": [21, 36, 73, 74, 76, 78, 80], "variant": [21, 25, 28, 78], "qparam": [21, 27, 29, 60], "hqq": [21, 71], "plainlayout": [22, 23, 67, 76], "mapping_typ": [22, 27, 28, 44], "mappingtyp": [22, 23, 27, 28, 44, 76], "act_mapping_typ": [22, 23], "produc": [22, 72, 84, 85, 86, 87, 88], "backend": [22, 68, 72, 74, 75, 89], "cutlassint4packedlayout": 22, "weight_only_decod": 23, "dim": [23, 24, 37, 76, 78, 80, 85, 86], "store": [23, 58, 62, 71, 75, 79, 80, 85, 86], "around": [23, 70, 71, 72, 73, 85], "zero": [23, 27, 29, 44, 49, 50, 51, 52, 63, 75, 76, 89], "decod": [23, 74], "better": [23, 24, 70, 72, 78, 85, 86, 87, 88, 89], "split": [23, 74, 85, 86], "int8tensor": [23, 71, 72], "otherwis": [24, 31, 44, 86], "point": [25, 29, 37, 44, 49, 50, 51, 52, 70, 71, 72, 73, 75, 76, 78, 85, 89], "number": [25, 36, 49, 51, 52, 63, 74, 75, 78, 86, 87], "sai": [25, 60, 71, 79, 80, 89], "3": [25, 33, 60, 68, 70, 71, 72, 75, 79, 83, 85, 86], "7": [25, 70, 74, 87, 88], "symmetric_no_clipping_err": 25, "smin": 25, "smax": 25, "min_val_neg": [25, 78], "quant_min": [25, 27, 28, 29, 60, 78, 88, 89], "max_val_po": [25, 78], "quant_max": [25, 27, 28, 29, 60, 78, 88, 89], "By": [25, 75], "individu": [25, 75], "less": [25, 75, 78, 85], "round": [25, 78], "error": [25, 44, 70, 78, 85], "neg": 25, "placehold": [26, 71, 88], "core": [26, 55, 76, 80, 85], "block_siz": [27, 28, 29, 60, 71, 76], "ep": [27, 28, 44, 76, 86, 88, 89], "scale_dtyp": [27, 28, 76], "zero_point_dtyp": [27, 28, 76], "int32": [27, 40, 44, 48, 49, 71, 85, 89], "keepdim": [27, 78, 85, 86], "fp32": [27, 29, 44, 52, 76, 78, 85, 87], "fp16": 27, "determin": [27, 46, 70, 75, 80], "element": [27, 29, 36, 49, 51, 52, 60, 67, 71, 75], "share": [27, 29, 60, 75], "minimum": [27, 29, 60], "optioanl": 27, "maximum": [27, 29, 60], "zero_point": [27, 28, 29, 60, 67, 71, 75, 76, 78, 89], "align": 27, "param": [27, 28, 63, 74], "zero_point_domain": [27, 28, 44], "zeropointdomain": [27, 28, 44], "preserve_zero": [27, 28], "preserv": [27, 63, 74, 75, 84], "request": [27, 29, 60], "min_val": [28, 78], "max_val": [28, 78], "choose_qparams_affin": 28, "observ": [28, 62, 71, 75, 76, 84, 85, 86, 87, 88, 89], "obtain": 28, "track": [28, 79, 80], "calibr": [28, 72, 84, 86, 87, 88], "mostli": [28, 46, 72], "input_dtyp": 29, "output_dtyp": [29, 48, 60], "match": [29, 30, 51, 52, 67, 75, 85], "argument": [29, 44, 46, 55, 58, 67, 70, 71, 74, 87], "affin": [29, 60, 71], "uint8": [29, 60, 71, 76, 89], "dequant": [29, 56, 71, 72, 78, 80, 85, 87, 88, 89], "b": [30, 56, 67], "scales1": 30, "multipli": [30, 61, 75], "second": [30, 46, 67, 70, 71, 83, 89], "factor": [30, 70, 75], "rais": [30, 43, 46, 61, 78, 80], "assertionerror": [30, 61, 78], "expect": [30, 70, 75, 78, 84, 85, 87, 88, 89], "qat": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 68, 74, 87], "twostepquant": 31, "easili": [31, 84], "thei": [31, 70, 72, 75, 78, 79, 85, 86, 89], "constructor": [31, 67, 78], "must": [31, 44, 46, 52, 70, 75, 79, 80, 86, 88, 89], "embed": [31, 33, 40, 43, 46, 48, 49], "behavior": [31, 80, 85, 86], "undefin": [31, 63], "my_quant": 31, "qatquantizer1": 31, "qatquantizer2": 31, "qatquantizer3": 31, "num_embed": [33, 48, 49], "embedding_dim": [33, 48, 49], "padding_idx": [33, 48, 49], "max_norm": [33, 48, 49], "norm_typ": [33, 48, 49], "scale_grad_by_freq": [33, 48, 49], "spars": [33, 48, 49, 63, 75], "weight_config": [33, 34, 43, 46], "fakequantizeconfigbas": [33, 34, 43, 46], "intxfakequantizeconfig": [33, 34, 43, 45, 46], "fq_embed": 33, "longtensor": 33, "everi": [33, 38, 48, 62, 75, 78, 85, 86], "overridden": [33, 38, 48, 62], "within": [33, 38, 48, 62, 74, 75, 80, 87, 88], "afterward": [33, 38, 48, 62], "former": [33, 38, 48, 62], "take": [33, 38, 48, 55, 62, 66, 67, 71, 75, 84, 85, 86, 87, 88, 89], "care": [33, 38, 48, 62, 73, 75, 85], "hook": [33, 38, 48, 62, 71], "latter": [33, 38, 48, 62, 86], "silent": [33, 38, 48, 62, 87], "ignor": [33, 38, 48, 62, 70, 85, 86], "in_featur": [34, 51, 52, 70, 72, 73, 76, 78], "out_featur": [34, 51, 52, 70, 76, 78], "activation_config": [34, 43, 46], "per_token": [34, 43, 44, 46], "is_symmetr": [34, 43, 44, 46], "fq_linear": 34, "scale_precis": [36, 40, 44, 48, 49], "rowwis": [36, 71], "hp_value_lb": 37, "hp_value_ub": 37, "float8fakequantizeconfig": 38, "fakequantizedembed": 39, "back": [39, 78], "model_with_fake_quantized_linear": 39, "zero_point_precis": [40, 44, 48, 49], "int4weightonlyqatembed": 40, "int4weightonlyembed": 40, "inner_k_til": [41, 51], "scales_precis": [41, 42, 51, 52], "padding_allow": 42, "valueerror": [43, 46], "torchaodtyp": 44, "is_dynam": [44, 87, 88, 89], "range_learn": 44, "simul": [44, 46, 64, 75], "older": 44, "6": [44, 70, 71, 74, 75, 85, 86, 87], "int1": [44, 71], "int7": [44, 71], "pergroup": [44, 74], "pertoken": 44, "per_channel": 44, "peraxi": [44, 74, 76], "per_group": [44, 60], "combin": [44, 74, 75, 78, 85, 87], "leav": 44, "field": [44, 47, 67, 89], "empti": [44, 71], "prototyp": [44, 50, 71, 89], "keyword": [44, 46, 58, 71], "properti": [44, 45], "throw": 44, "els": [44, 71, 74, 80, 85, 86], "symmetri": 45, "qatstep": 46, "awar": [46, 63, 68, 72, 75, 78], "post": [46, 68, 71, 72, 78, 86, 89], "ptq": [46, 86, 87], "automat": [46, 70, 74, 78, 79, 80, 83], "phase": [46, 89], "int4weightonlyconfig": [46, 55, 73, 79, 80], "experiment": [46, 84], "qat_config": 46, "act_config": 46, "alwai": [46, 74, 78], "One": [46, 75, 78, 80, 89], "enum": [47, 56], "example_input": [50, 72, 73, 76, 84, 85, 86, 87, 88, 89], "intxfakequantizerbas": 50, "weightonlyint4linear": 51, "hardcod": [52, 89], "mod": [53, 54, 70, 75, 78], "disabl": [53, 78, 86], "filter_fn": [55, 66], "_is_linear": [55, 76], "inplac": [55, 63, 72], "fulli": [55, 66, 74, 75, 85], "qualifi": [55, 66, 75], "final": [55, 71, 72, 75, 84, 85, 86, 87, 88, 89], "predefin": [55, 57, 89], "execut": [55, 78, 82], "int8dynamicactivationint8weightconfig": [55, 66, 72, 79], "sequenti": [55, 66, 70], "affect": [56, 75], "select": [56, 85], "found": [56, 71, 72, 74, 75, 76, 78], "nativ": [56, 68, 70, 71, 78, 85], "gemm_lowp": 56, "gemm_fp32": 56, "ci": 56, "product": [56, 63, 72, 74, 80, 87, 89], "logic": [56, 72, 78, 80], "lowp": 56, "gemm": [56, 70, 87, 88], "laid": [57, 71], "opaqu": 57, "decid": [57, 75, 76], "adopt": [57, 71], "creation": [58, 80], "construct": [58, 71, 85, 89], "classmethod": [58, 67, 76, 78, 80], "from_hp": [58, 71], "cl": [58, 67, 76, 78, 80], "quant_kwarg": [58, 59], "quantizetensorkwarg": 59, "given": [59, 70, 75, 80, 89], "flexibl": [59, 75, 78, 84, 87], "variou": 59, "float16": [60, 75], "tabl": [60, 67, 70, 71, 75], "show": [60, 70, 72, 74, 75, 80, 85, 86], "per_tensor": 60, "per_axi": 60, "axi": [60, 76], "mat2": 61, "consid": [61, 75], "cubla": 61, "fallback": [61, 80], "j": 61, "l2": [62, 75], "norm": [62, 63, 75], "buffer": 62, "x_orig": 62, "sparsity_level": [63, 75], "semi_structured_block_s": 63, "wanda": 63, "sparsifi": [63, 68, 73, 75], "prune": 63, "http": [63, 74, 75, 79, 88], "arxiv": [63, 75], "org": [63, 74, 75, 88], "ab": [63, 75], "2306": 63, "11695": 63, "magnitud": [63, 75], "three": [63, 66, 87, 88], "variabl": [63, 67, 75], "block": [63, 75], "dict": [63, 67, 78, 80, 88, 89], "parametr": 63, "deepcopi": [63, 72, 76, 78, 86], "squash_mask": [63, 75], "params_to_keep": 63, "params_to_keep_per_lay": 63, "squash": 63, "mask": [63, 75], "appropri": [63, 84, 85, 86, 87, 88], "sparse_param": 63, "attach": [63, 75, 89], "kei": [63, 75, 83], "xdoctest": 63, "skip": [63, 71, 75], "local": [63, 74, 75], "hasattr": [63, 80], "submodule1": 63, "linear1": [63, 72, 73, 76, 78], "foo": [63, 85], "bar": [63, 85], "submodule2": 63, "linear42": 63, "baz": 63, "42": [63, 76], "24": 63, "ones": [63, 86], "update_mask": 63, "tensor_nam": [63, 80], "statist": [63, 75, 76, 85, 86], "retriev": 63, "act_per_input": 63, "Then": [63, 78, 88, 89], "across": [63, 74, 75, 78, 80], "whole": [63, 89], "alia": [65, 67, 80], "semisparseweightconfig": 65, "sparsify_": 66, "apply_tensor_subclass": 66, "essenti": [66, 80, 84], "semi": [66, 75], "semi_sparse_weight": 66, "semisparselayout": 66, "isinst": [66, 70, 75, 76, 78, 80, 86, 89], "sparse_api": 66, "commonli": [67, 70, 75], "inherit": [67, 78, 80, 87, 88], "includ": [67, 70, 71, 78, 84, 87, 88, 89], "_get_to_kwarg": 67, "register_layout": 67, "plainaqttensorimpl": [67, 76], "get_tensor_impl_constructor": 67, "tensor_impl_ctr": 67, "_layout": [67, 76], "tensor_impl": [67, 76], "simplifi": [67, 84, 85, 87, 88], "implment": 67, "tensor_data": 67, "optional_tensor_data_nam": 67, "boilerpl": 67, "optional_tensor_attribute_nam": 67, "__new__": [67, 78, 80], "exaclti": 67, "present": [67, 75], "__tensor_flatten__": [67, 78, 80], "flatten": 67, "valid": [67, 74, 80, 89], "attribute_nam": 67, "__tensor_unflatten__": [67, 78, 80], "tensor_data_dict": [67, 78, 80], "_apply_fn_to_data": [67, 80], "recreat": 67, "__repr__": [67, 78], "represent": [67, 75, 80, 85, 89], "_same_metadata": 67, "metadata": [67, 71, 74, 78, 80], "between": [67, 71, 75, 78, 80, 84, 86, 87, 89], "__setstate__": 67, "serial": [67, 68, 71, 79, 85, 86], "old": 67, "maintain": [67, 74, 75], "bc": 67, "contigu": [67, 71, 87, 88], "detach": [67, 78, 80], "clone": [67, 74, 80], "copy_": [67, 80], "_to_copi": [67, 80], "c": [67, 72, 78, 87, 88], "f": [67, 70, 71, 72, 73, 74, 75, 76, 78, 80, 85, 86], "h": [67, 74], "layout_class": 67, "tensorimpl": 67, "tensorimplclass": 67, "from_plain": 67, "tensor_class": 67, "impl": 67, "aten_op": 67, "decor": [67, 78, 80], "__torch_dispatch__": [67, 78], "implements_torch_funct": 67, "torch_fn": 67, "__torch_function__": [67, 71, 78], "registr": 67, "aqt": 67, "gradient": [68, 75], "introduct": [68, 71, 74], "highlight": [68, 78, 83], "guid": [68, 71, 74, 84], "contributor": [68, 71, 72], "benchmark": [68, 70, 72, 79, 84, 87, 88], "part": [68, 75, 78, 79, 86], "tune": [68, 70, 74, 75, 84], "qlora": [68, 74], "vllm": [68, 72, 79], "sglang": [68, 79], "hug": [68, 74], "face": [68, 71, 74, 75, 85], "advanc": [68, 76, 78, 84, 87, 88], "export": [68, 71], "x86": [68, 72], "intel": [68, 84, 87], "openvino": [68, 72], "5x": 70, "cluster": [70, 71], "34": 70, "43x": 70, "2k": 70, "h200": 70, "latest": 70, "offic": 70, "offici": [70, 71], "sever": [70, 80, 84, 89], "popular": 70, "flagship": 70, "form": [70, 71, 75], "quickli": [70, 78], "batteri": 70, "fork": 70, "build": [70, 71, 75, 78, 80, 85], "top": [70, 71, 78, 84, 85, 86, 87, 88], "virtual": 70, "environ": [70, 74], "conda": 70, "venv": 70, "download": [70, 74, 81, 83, 85, 86, 88], "job": 70, "below": [70, 71, 75, 78, 79, 80, 83, 84], "root": [70, 74], "launch": 70, "ngpu": 70, "config_fil": 70, "train_config": 70, "llama3_8b": 70, "toml": 70, "run_train": 70, "sh": [70, 74], "hyperparamet": 70, "edit": [70, 74], "line": [70, 75, 79], "flag": [70, 86], "termin": 70, "look": [70, 71, 75, 84, 85, 86, 87, 88], "rank0": 70, "titan": 70, "2025": 70, "06": 70, "04": 70, "08": 70, "51": 70, "48": 70, "info": 70, "2254": 70, "27": 70, "34gib": 70, "28": 70, "78": 70, "tp": [70, 80], "375": 70, "tflop": 70, "21": 70, "73": [70, 76], "mfu": 70, "20": [70, 74, 86], "58": 70, "557": 70, "7069": 70, "99gib": 70, "62": 70, "034": 70, "35": [70, 74, 76], "41": [70, 74], "19": 70, "52": 70, "224": [70, 76, 84, 85, 86, 87, 88], "9196": 70, "022": 70, "406": [70, 85, 86], "65": 70, "904": 70, "1423": 70, "014": 70, "23": [70, 76], "As": [70, 85, 89], "warmup": [70, 72], "7k": 70, "99gb": 70, "peak": [70, 74, 79], "against": 70, "02": 70, "37": 70, "404": 70, "2611": 70, "22gib": 70, "595": 70, "47": 70, "49": [70, 76], "027": 70, "4260": 70, "89gib": 70, "344": 70, "367": 70, "39": 70, "03": 70, "01": 70, "988": 70, "9482": 70, "321": 70, "366": 70, "14": 70, "991": 70, "1183": 70, "300": 70, "364": 70, "89": 70, "40": 70, "4659": 70, "291": 70, "84": 70, "769": 70, "gc": 70, "peform": 70, "period": 70, "collect": [70, 75], "3k": 70, "89gb": 70, "11x": 70, "nearli": 70, "ident": [70, 75], "performan": 70, "v": [70, 75, 85, 89], "curv": [70, 75], "omit": [70, 71, 85, 86, 87], "648": 70, "2648": 70, "28gib": 70, "71": 70, "26": 70, "475": 70, "9106": 70, "91gib": 70, "53": [70, 74], "503": 70, "434": 70, "43": 70, "94": [70, 85], "166": 70, "0774": 70, "663": 70, "443": 70, "44": [70, 76], "87": 70, "50": [70, 75, 76, 84, 85, 87, 88], "885": 70, "3233": 70, "643": 70, "442": 70, "66": [70, 74, 76], "76": 70, "613": 70, "6150": 70, "637": 70, "72": [70, 74], "6k": 70, "91gb": 70, "21x": [70, 74], "tl": 70, "dr": 70, "priorit": 70, "accur": [70, 75, 84], "stabil": 70, "cost": [70, 76], "slightli": [70, 78], "impact": [70, 74, 80], "outlier": 70, "caus": 70, "underflow": 70, "8xh100": 70, "box": [70, 75, 87], "toi": [70, 72, 76, 78, 87], "convert_to_float8_train": 70, "recurs": 70, "kind": [70, 85], "over": [70, 75, 85, 86], "snippet": [70, 85, 86], "float8_linear_util": 70, "float8_linear": 70, "sampl": [70, 85, 87, 88], "adamw": 70, "being": [70, 75, 80, 87, 88], "elig": 70, "last": [70, 84], "divis": 70, "label": 70, "fake_label": 70, "ones_lik": 70, "mse_loss": 70, "model_state_dict": 70, "state_dict": [70, 72, 73, 85, 86], "optimizer_state_dict": 70, "pth": [70, 72, 85, 86], "explor": [70, 72, 88], "few": [70, 78, 85, 86], "lai": 71, "stack": [71, 74], "awq": 71, "gptq": 71, "int4tensor": 71, "int4preshuffledtensor": 71, "uint1": 71, "uint7": 71, "float3": 71, "triton": [71, 87, 88], "overload": [71, 75], "term": [71, 75, 85, 89], "extra": [71, 74], "matter": [71, 75], "float4_e2m1fn_x2": 71, "float8_e4m3fnuz": 71, "float8_e5m2": 71, "float8_e5m2fnuz": 71, "float8_e8m0fnu": 71, "pr": 71, "shell": 71, "dervi": 71, "mxfp8": 71, "preicison": 71, "choose_qparam": 71, "mention": [71, 85], "previou": [71, 74, 85, 86, 87, 88], "accommod": 71, "choose_qparams_affine_with_min_max": 71, "min": [71, 76, 78, 85, 89], "raw": 71, "quantize_fp8_row": 71, "int_matmul": 71, "int_scaled_matmul": 71, "reli": [71, 72, 75, 76, 78], "handwritten": 71, "On": 71, "glue": 71, "everyth": 71, "togeth": [71, 74, 85, 87, 89], "anoth": [71, 75, 78, 85, 89], "side": 71, "swizzl": 71, "dtpype": 71, "float8rowwisetensor": 71, "float8blockwisetensor": 71, "subset": 71, "confus": [71, 75, 85], "close": [71, 75], "low_precision_v": 71, "high_precision_v": 71, "procedur": 71, "especi": [71, 73, 75, 87, 88], "bitwidth": [71, 89], "codebook": 71, "index": [71, 74, 75, 88], "vector": [71, 75, 87], "kmean": 71, "tradition": 71, "explain": [71, 84, 87], "simplest": [71, 75], "easi": [71, 74], "linear_modul": 71, "runtim": [71, 72, 85], "main": [71, 72, 74, 75, 76, 78, 79, 85, 89], "question": [71, 73, 75, 78, 89], "activation_granular": 71, "act_quant_kwarg": 71, "weight_granular": [71, 74], "quantized_weight": [71, 80], "float8_dtyp": 71, "haven": 71, "seen": 71, "pt2": [71, 78, 87], "pattern": [71, 72, 80, 84, 85], "autoround": 71, "multitensor": 71, "sure": [71, 74, 89], "open": [71, 75], "describ": [71, 73, 75, 83, 85, 86], "advis": 71, "finetun": [71, 74], "quantized_train": 71, "extend": [71, 75, 87], "progress": [71, 79, 80], "lot": [71, 75], "connect": [71, 89], "walk": [71, 76, 78, 83, 84, 87], "float8dynamicactivationfloat8weightconfig": [71, 79], "happen": [71, 78, 85, 87], "len": [71, 74, 80, 85, 86, 89], "_choose_quant_func_and_quantize_tensor": 71, "relat": [71, 75], "xq": 71, "reshap": [71, 85, 86], "wq": 71, "x_scale": [71, 85], "w_scale": 71, "out_shap": 71, "entri": 72, "mutat": 72, "simpl": [72, 75, 76, 78, 84, 87, 88], "toylinearmodel": [72, 73, 76], "hidden_dim": 72, "has_bia": 72, "linear2": [72, 73, 76, 78], "eval": [72, 73, 74, 76, 84, 86, 87, 88], "model_w16a16": 72, "model_w8a8": 72, "chapter": 72, "remain": [72, 87, 88], "unchang": 72, "__name__": 72, "approxim": 72, "2x": [72, 74, 75], "reduct": [72, 73, 74, 75, 78], "disk": 72, "o": [72, 85, 86], "original_s": 72, "getsiz": [72, 85, 86], "quantized_s": 72, "2f": [72, 85, 86], "mb": [72, 73, 82, 85, 86], "00x": 72, "00mb": 72, "faster": [72, 75], "time": [72, 75, 78, 79, 83, 84, 85, 86], "synchron": 72, "100": [72, 78, 85, 86], "original_tim": 72, "quantized_tim": 72, "03x": 72, "larger": 72, "best": [72, 75, 87], "enough": 72, "address": [72, 85], "lm": [72, 74], "recogn": [72, 89], "decis": 72, "pt2e": [72, 84, 85, 86, 87, 88], "fuse": [72, 75, 78, 86], "deleg": [72, 85], "x86inductorquant": [72, 87], "quantize_pt2": [72, 84, 85, 86, 87, 88], "prepare_pt2": [72, 84, 85, 87, 88], "x86_inductor_quant": [72, 87], "get_default_x86_inductor_quantization_config": [72, 87], "float_model": [72, 78, 84, 85, 86, 87, 88], "data_load": [72, 85, 86, 87, 88], "no_grad": [72, 78, 84, 85, 86, 87, 88], "imag": [72, 79, 84, 85, 86, 87, 88], "program": [72, 85, 86, 87, 89], "captur": [72, 85, 86, 89], "expos": [72, 85, 86], "set_glob": [72, 85, 86, 87, 88], "xiq": [72, 87], "prepare_qat_pt2": [72, 86, 87], "sample_inference_data": 72, "convert_pt2": [72, 84, 85, 86, 87, 88], "wrapper": [72, 78, 87], "_inductor": [72, 87], "cpp_wrapper": [72, 87], "optimized_model": [72, 84, 87, 88], "converted_model": [72, 87, 88], "xpu": [72, 88], "visit": 72, "would": [72, 75, 78, 86, 88], "forget": 72, "good": [72, 78, 89], "tempfil": [73, 79], "get_model_size_in_byt": 73, "ref": [73, 85], "namedtemporaryfil": 73, "seek": [73, 75], "m_load": 73, "load_state_dict": [73, 85, 86], "assign": 73, "assert": [73, 76, 78, 80, 89], "equal": [73, 75], "thing": [73, 75, 78, 85], "float_weight1": 73, "float_weight2": 73, "quantized_weight1": 73, "quantized_weight2": 73, "go": [73, 78, 89], "techinqu": 73, "4x": [73, 74], "0625": 73, "reason": [73, 75], "avoid": [73, 75], "affine_quantized_tensor": 73, "deploi": 74, "engin": 74, "seamlessli": [74, 78, 87, 88], "seamless": [74, 87], "hf": [74, 79], "signific": [74, 75], "pip": [74, 79, 84, 85], "url": [74, 88], "whl": [74, 88], "nightli": 74, "cu128": 74, "push": [74, 75, 79, 80], "hub": [74, 79, 80], "server": [74, 80], "phi": 74, "fp8": 74, "microsoft": 74, "o3": 74, "client": 74, "curl": 74, "localhost": 74, "8000": 74, "v1": 74, "chat": 74, "content": 74, "applic": 74, "messag": 74, "role": 74, "give": [74, 75, 78], "me": 74, "short": 74, "larg": [74, 78, 87], "languag": 74, "temperatur": 74, "top_p": 74, "95": 74, "top_k": 74, "max_token": 74, "32768": 74, "vram": 74, "15x": 74, "littl": [74, 80], "packag": [74, 79], "git": [74, 79], "com": [74, 79], "acceler": [74, 75, 79], "autotoken": [74, 79], "pipelin": 74, "random": [74, 75, 85, 86], "manual_se": [74, 85, 86], "model_path": 74, "device_map": [74, 79, 80], "trust_remote_cod": 74, "ai": 74, "assist": 74, "eat": 74, "banana": 74, "dragonfruit": 74, "smoothi": 74, "blend": 74, "milk": 74, "honei": 74, "salad": 74, "mix": [74, 84, 87, 88], "slice": [74, 80], "lemon": 74, "juic": 74, "solv": [74, 75, 78], "equat": 74, "pipe": [74, 79], "text": 74, "generation_arg": 74, "max_new_token": 74, "500": 74, "return_full_text": 74, "do_sampl": 74, "generated_text": 74, "design": [74, 80, 84, 85, 89], "lm_head": 74, "those": [74, 75, 76, 78], "ti": 74, "autoprocessor": 74, "modeling_util": 74, "find_tied_paramet": 74, "model_id": [74, 79], "untied_model": 74, "getattr": [74, 80], "get_text_config": 74, "tie_word_embed": 74, "setattr": [74, 78], "_tied_weights_kei": 74, "user_id": 74, "your_user_id": 74, "model_nam": [74, 84, 87, 88], "save_to": [74, 79], "save_to_local_path": 74, "int8dynamicactivationintxweightconfig": [74, 79], "ve": [74, 75], "intxweightonlyconfig": [74, 79], "fqntoconfig": [74, 80], "untied_model_id": 74, "untied_model_local_path": 74, "embedding_config": 74, "linear_config": 74, "weight_scale_dtyp": 74, "quant_config": 74, "_default": [74, 80], "embed_token": 74, "quant_typ": [74, 79, 80], "include_embed": 74, "untie_embedding_weight": 74, "modules_to_not_convert": 74, "quantized_model": [74, 78, 79, 84, 85, 86], "safe_seri": [74, 79, 80], "pte": 74, "cd": 74, "install_requir": 74, "phi_4_mini": 74, "convert_weight": 74, "pytorch_model": 74, "bin": 74, "pytorch_model_convert": 74, "export_llama": 74, "kv": 74, "use_sdpa_with_kv_cach": 74, "get_bos_id": 74, "199999": 74, "get_eos_id": 74, "200020": 74, "max_seq_length": 74, "max_context_length": 74, "output_nam": 74, "phi4": 74, "phone": 74, "io": 74, "2gb": 74, "iphon": 74, "pro": [74, 75], "17": 74, "sec": 74, "test": [74, 79, 83, 85, 87], "har": 74, "eleutherai": 74, "lm_eval": 74, "model_arg": 74, "pretrain": [74, 75, 84, 85, 86, 87], "reset_peak_memory_stat": 74, "prompt": [74, 79], "hei": 74, "consciou": 74, "templated_prompt": 74, "apply_chat_templ": 74, "add_generation_prompt": 74, "templat": [74, 81, 82], "return_tensor": 74, "pt": 74, "generated_id": 74, "output_text": 74, "batch_decod": 74, "skip_special_token": 74, "clean_up_tokenization_spac": 74, "respons": 74, "mem": 74, "max_memory_reserv": 74, "1e9": 74, "02f": 74, "gb": 74, "hello": [74, 79], "ye": 74, "am": 74, "digit": 74, "todai": 74, "70": [74, 76], "bench": 74, "vllm_disable_compile_cach": 74, "project": 74, "vllm_use_precompil": 74, "sharegpt": 74, "wget": 74, "co": 74, "anon8231489123": 74, "sharegpt_vicuna_unfilt": 74, "resolv": 74, "sharegpt_v3_unfiltered_cleaned_split": 74, "tree": 74, "num": 74, "benchmark_serv": 74, "16x": 74, "14x": 74, "num_prompt": 74, "req": 74, "57": [74, 76], "1000": [74, 87], "68": 74, "80": 74, "entir": [74, 85, 86], "ml": 74, "gain": [74, 75, 88], "eas": 74, "accept": [74, 89], "trade": [74, 75], "off": [74, 75], "neural": [75, 84, 87], "network": [75, 78, 84, 87], "latenc": 75, "carefulli": 75, "pai": 75, "low": [75, 78, 79, 84], "price": 75, "f1": 75, "problem": [75, 78], "research": [75, 83], "fragment": 75, "rightfulli": 75, "spent": 75, "figur": [75, 85], "compress": [75, 84], "place": [75, 84, 85, 86, 87, 88], "dens": 75, "focu": [75, 78], "realli": 75, "concret": [75, 89], "hope": 75, "ao": [75, 80], "modular": 75, "nice": 75, "scratch": [75, 83], "minim": [75, 84, 87, 88], "algorthim": 75, "realiz": 75, "theoret": 75, "analog": 75, "fix": [75, 76], "unstructur": 75, "howev": [75, 79, 80, 86, 89], "retrain": 75, "neglig": 75, "area": 75, "agre": 75, "upon": 75, "consensu": 75, "mind": 75, "thought": 75, "subproblem": 75, "satisfi": 75, "my": [75, 86], "independ": 75, "frontend": [75, 87], "arbitrari": 75, "handoff": 75, "piec": 75, "natur": [75, 78, 85, 89], "clear": 75, "contract": 75, "7x": 75, "advantag": 75, "anticip": 75, "solut": 75, "third": 75, "parti": 75, "to_sparse_semi_structur": 75, "sparsesemistructuredtensor": 75, "weightnormsparsifi": 75, "half": 75, "subnetwork": 75, "sparse_config": 75, "named_modul": 75, "tensor_fqn": 75, "sparse_block_shap": 75, "zeros_per_block": 75, "fakespars": 75, "fundament": [75, 86], "manipul": 75, "dictionari": 75, "paramer": 75, "parameter": 75, "necessari": [75, 76, 78, 84, 85, 86, 87, 88], "suitabl": [75, 87], "spot": 75, "definit": [75, 80], "academia": 75, "industri": 75, "often": [75, 78], "interchang": 75, "distinct": 75, "roughli": 75, "idea": 75, "behind": 75, "doesn": [75, 86, 89], "itself": [75, 78], "loos": 75, "speak": 75, "tightli": 75, "coupl": [75, 78], "csc": 75, "qnnpack": 75, "descript": [75, 84], "coo": 75, "sparse_coo": 75, "coordin": 75, "locat": 75, "bsr": 75, "sparse_bsr": 75, "veri": [75, 80, 86], "except": [75, 78, 89], "scalar": [75, 85], "dimension": 75, "csr": 75, "sparse_csr": 75, "sparse_csc": 75, "column": 75, "indic": [75, 89], "compact": 75, "sparse_matrix": 75, "1d": 75, "indexptr": 75, "storag": 75, "\u00bd": 75, "bitmask": 75, "2bit": 75, "unprun": 75, "quit": [75, 78], "broken": 75, "down": 75, "sensit": 75, "effect": [75, 76, 78, 87, 88, 89], "subsequ": [75, 78, 87, 88], "infinit": 75, "lost": 75, "degre": 75, "drop": 75, "proxi": 75, "aforement": 75, "smallest": 75, "absolut": 75, "scope": 75, "impli": 75, "respect": [75, 86], "con": 75, "potenti": [75, 76, 84, 85, 87, 88], "sub": 75, "span": 75, "threshold": 75, "normal": [75, 85, 86], "complex": 75, "constant": [75, 78, 85], "ctr_mobile_fe": 75, "score": 75, "w": [75, 80], "tenosr": 75, "udpat": 75, "cannot": [75, 76, 80], "histori": 75, "regrow": 75, "dw": 75, "via": [75, 84], "backprop": 75, "pat": 75, "unmask": 75, "resid": 75, "salienc": 75, "lowest": 75, "l1": 75, "abl": [75, 78, 80, 85, 89], "repeat": [75, 85, 86], "movement": 75, "2005": 75, "07683": 75, "rank": [75, 78], "wx": 75, "sqx": 75, "q": [75, 85], "usual": 75, "sort": 75, "wise": 75, "reconstruct": [75, 80], "randomli": 75, "tri": 75, "remedi": 75, "sometim": 75, "item": [75, 83], "along": [75, 80, 84], "ultim": [75, 76], "complic": [75, 85], "literatur": 75, "vision": 75, "nlp": [75, 83, 87], "again": [75, 85, 89], "iter": [75, 85, 86], "ctr_feed": 75, "na": 75, "multimask": 75, "search": 75, "pyspeech": 75, "fastna": 75, "approach": [75, 78, 84, 87, 88], "knowledg": [75, 83], "distil": 75, "pdf": 75, "2204": 75, "09656": 75, "arrang": 75, "recal": 75, "counterpart": 75, "slower": 75, "suffici": 75, "At": [75, 85], "98": 75, "special": [75, 84, 85], "exhibit": 75, "penalti": 75, "expens": [75, 78], "dictat": 75, "characterist": 75, "highest": 75, "wouldn": [75, 78], "visual": 75, "fig": 75, "4x4": 75, "benchmak": 75, "fly": [76, 79], "affinequantizedminmaxobserv": 76, "record": 76, "welcom": 76, "desir": 76, "averag": [76, 85, 86], "histogram": [76, 85], "act_ob": 76, "finfo": 76, "weight_ob": 76, "observedlinear": 76, "observed_input": 76, "observed_weight": 76, "from_float": [76, 78], "float_linear": 76, "observed_linear": 76, "_replace_with_custom_fn_if_matches_filt": 76, "insert_observers_": 76, "lambda": [76, 80], "replacement_fn": 76, "copied_act_ob": 76, "copied_weight_ob": 76, "popul": 76, "feed": 76, "simpler": [76, 85], "quantizedlinear": [76, 78], "isn": 76, "strictli": 76, "to_affine_quantized_intx_stat": 76, "act_scal": [76, 89], "act_zero_point": 76, "calculate_qparam": [76, 89], "weight_scal": [76, 85, 89], "weight_zero_point": [76, 85], "qweight": 76, "qinput": 76, "from_observ": 76, "quantized_linear": [76, 85], "begin": [76, 78], "dataclass": [76, 80, 89], "transform_modul": [76, 80], "register_quantize_module_handl": [76, 80], "staticquantconfig": 76, "_apply_static_qu": 76, "associ": 76, "identifi": [76, 89], "is_observed_linear": 76, "optimizedmodul": 76, "_orig_mod": 76, "0237": 76, "142": 76, "31": [76, 89], "113": 76, "157": 76, "59": 76, "160": 76, "150": 76, "67": 76, "241": 76, "238": 76, "235": 76, "228": 76, "255": [76, 89], "201": 76, "114": 76, "236": 76, "88": [76, 85], "83": 76, "109": 76, "209": 76, "92": 76, "184": 76, "141": 76, "110": 76, "0009": 76, "0010": 76, "130": 76, "122": 76, "132": 76, "125": 76, "126": 76, "129": 76, "127": [76, 78, 88, 89], "133": 76, "124": 76, "131": 76, "135": 76, "136": 76, "foundat": 78, "autograd": [78, 89], "interpos": 78, "namespac": 78, "continu": [78, 79, 86, 87, 88, 89], "obviou": 78, "int8quantizedlinear": 78, "finer": 78, "intercept": 78, "contrast": 78, "long": [78, 85], "clunki": 78, "distributedlinear": 78, "duplic": 78, "bypass": 78, "wrap": [78, 87, 88], "outer": 78, "inner": 78, "allgath": 78, "bandwidth": 78, "stai": 78, "exactli": 78, "zoo": 78, "podcast": 78, "edward": 78, "yang": 78, "int8_symmetric_quant": 78, "fp32_tensor": 78, "amin": 78, "amax": 78, "zeros_lik": 78, "view": [78, 85, 86], "clamp": [78, 85], "w_int8": 78, "new_linear": 78, "left": [78, 89], "toymodel": 78, "child": 78, "named_children": 78, "drawback": 78, "won": 78, "suppos": 78, "clean": 78, "eleg": 78, "pretti": 78, "power": [78, 80], "overrid": 78, "almost": 78, "shard": [78, 80], "ragged": 78, "rag": 78, "nestedtensor": 78, "who": 78, "link": [78, 83], "why": [78, 83], "googl": 78, "collab": 78, "flopcount": 78, "memorytrack": 78, "bare": 78, "bone": 78, "int8symmetrictensor": 78, "hold": [78, 79], "int_data": 78, "staticmethod": 78, "_dynamo": 78, "_make_wrapper_subclass": [78, 80], "stride": 78, "storage_offset": 78, "ndim": 78, "extra_metadata": 78, "outer_s": [78, 80], "outer_strid": [78, 80], "undo": 78, "repr": 78, "float_tensor": 78, "ahead": 78, "insid": 78, "int8_tensor": 78, "op_implementations_dict": 78, "conveni": 78, "register_op": 78, "_op": 78, "opoverload": 78, "impl_decor": 78, "op_impl": 78, "done": 78, "particular": 78, "largest": 78, "tell": 78, "desugar": 78, "surfac": 78, "coverag": [78, 84, 85, 87, 88], "brute": 78, "forc": 78, "repeatedli": 78, "log": 78, "loggingtensor": 78, "_python_dispatch": [78, 80], "return_and_correct_alias": [78, 80], "int8_mm": 78, "int8_view_op": 78, "out_data": 78, "out_scal": [78, 85], "notic": 78, "hit": 78, "background": 78, "decomposit": 78, "live": 78, "decomp": 78, "shrink": 78, "author": [78, 83, 84, 85, 86, 87, 88, 89], "But": [78, 80, 89], "pain": 78, "rather": 78, "worth": 78, "written": 78, "differenti": 78, "nuanc": 78, "longer": [78, 85, 86], "had": [78, 85], "transpos": 78, "That": 78, "transposit": 78, "got": [78, 85, 89], "propag": [78, 85, 87, 88], "fact": 78, "themselv": [78, 85], "pointwis": [78, 87, 88], "were": 78, "might": [78, 80, 85, 89], "unwrap": 78, "dim0": 78, "dim1": 78, "confirm": 78, "quantized_model_module_swap": 78, "quantized_model_subclass": 78, "subclass_param": 78, "out_module_swap": 78, "allclos": 78, "out_compil": 78, "seri": 78, "discuss": 78, "float8dynamicactivationint4weightconfig": 79, "use_hqq": [79, 80], "torch_dtyp": 79, "fluxpipelin": 79, "fluxtransformer2dmodel": 79, "black": 79, "forest": 79, "lab": 79, "flux": 79, "dev": 79, "subfold": 79, "cat": [79, 89], "sign": [79, 88], "world": [79, 80], "num_inference_step": 79, "guidance_scal": 79, "png": 79, "temporarydirectori": 79, "tmp_dir": 79, "uncom": 79, "usernam": [79, 80], "statu": [79, 80], "becom": [79, 85], "stabl": 79, "int4wo": 79, "team": [79, 80], "retain": 79, "thoroughli": 79, "e2": 80, "_type": 80, "_data": 80, "capabl": [80, 85, 87], "self_attn": 80, "q_proj": 80, "k_proj": 80, "mlp": 80, "gate_proj": 80, "narrow": 80, "host": 80, "state": 80, "chunk": 80, "heavi": 80, "codebas": 80, "fn": 80, "ctx": 80, "new_tensor": 80, "__class__": 80, "principl": 80, "mynewquantconfig": 80, "classvar": 80, "myquantizedtensor": 80, "tensor_data_attr": 80, "quantized_data": 80, "tensor_attribut": 80, "attr": 80, "fill_default": 80, "notimplementederror": 80, "_my_quant_transform": 80, "my_quantization_funct": 80, "use_cutlass_kernel": 80, "my_cutlass_linear": 80, "use_triton_kernel": 80, "my_triton_linear": 80, "standard": 80, "disappear": 80, "unless": 80, "extrem": 80, "sole": 80, "explicitli": [80, 89], "spooki": 80, "distanc": 80, "due": [80, 84, 89], "workaround": 80, "2338": 80, "detect": 80, "illustr": 80, "tutorials_python": 81, "zip": 81, "jupyt": [81, 83], "notebook": [81, 83], "tutorials_jupyt": 81, "galleri": [81, 83], "sphinx": [81, 83], "00": 82, "004": [82, 83], "total": [82, 83], "template_tutori": [82, 83], "click": 83, "firstnam": 83, "lastnam": 83, "prerequisit": [83, 85], "v2": 83, "topic": 83, "rand": [83, 85, 86], "7696": 83, "1504": 83, "9023": 83, "1417": 83, "5334": 83, "6904": 83, "2747": 83, "2971": 83, "5286": 83, "0304": 83, "2373": 83, "8873": 83, "2114": 83, "3901": 83, "6884": 83, "practic": 83, "summar": 83, "takeawai": 83, "link1": 83, "link2": 83, "minut": 83, "ipynb": 83, "daniil": 84, "lyakhov": 84, "aamir": 84, "nazir": 84, "alexand": 84, "suslov": 84, "yamini": 84, "nimmagadda": 84, "kozlov": 84, "subject": [84, 86], "openvinoquant": 84, "unlock": 84, "placement": 84, "ux": [84, 85, 87], "torchdynamo": [84, 87, 88, 89], "four": 84, "eager": [84, 85, 86, 87, 88, 89], "mechan": [84, 87, 88], "torchvis": [84, 85, 86, 87, 88, 89], "resnet18": [84, 85, 86, 87, 88], "__dict__": [84, 85, 86, 87, 88], "dummi": [84, 87, 88], "traced_b": [84, 87, 88], "exported_model": [84, 85, 86, 87, 88], "preset": 84, "elu": 84, "prelu": 84, "gelu": 84, "quantizationpreset": 84, "bert": [84, 87], "modeltyp": 84, "ignored_scop": 84, "exclud": 84, "layer_1": 84, "layer_2": 84, "layer_3": 84, "ignoredscop": 84, "conv2d": [84, 85, 86, 87, 88, 89], "regex": 84, "layer_": 84, "subgraph": [84, 86], "node": [84, 86, 87, 88, 89], "target_devic": 84, "taken": 84, "account": 84, "cpu_spr": 84, "npu": 84, "targetdevic": 84, "fold": [84, 85, 87, 88], "batchnorm": [84, 85, 86, 87, 88], "preced": [84, 85, 87, 88], "prepared_model": [84, 85, 86, 87, 88], "fold_quant": 84, "finish": [84, 87], "comparison": 84, "smoothquant": 84, "biascorrect": 84, "discrep": 84, "calibration_load": 84, "dataload": [84, 85, 86], "transform_fn": 84, "data_item": 84, "calibration_dataset": 84, "smooth_quant": 84, "fast_bias_correct": 84, "deploy": [84, 87], "jerri": [85, 87, 89], "zhang": [85, 87, 88, 89], "_export": [85, 86], "fx": [85, 89], "14k": 85, "programm": [85, 87, 88], "db": 85, "xnnpack": [85, 86, 89], "xnnpack_quant": [85, 86], "get_symmetric_quantization_config": [85, 86], "xnnpackquant": [85, 86, 89], "prior": 85, "qconfigmap": [85, 89], "backendconfig": [85, 89], "rel": 85, "intent": [85, 89], "qconfig": [85, 89], "3d": [85, 89], "incompat": 85, "great": 85, "ideal": 85, "fake_qu": 85, "hidden": 85, "summari": 85, "interact": 85, "thu": 85, "queri": [85, 89], "previous": 85, "embedding_byt": 85, "executorchquant": 85, "concaten": 85, "prone": 85, "cleaner": 85, "composed_quant": 85, "quantization_cap": 85, "concern": 85, "decoupl": 85, "minmax": 85, "freed": 85, "identitc": 85, "imagenet": [85, 86], "unzip": [85, 86], "data_path": [85, 86], "renam": [85, 86], "resnet18_pretrained_float": [85, 86], "sy": [85, 86], "numpi": [85, 86], "np": [85, 86], "resnet": [85, 86, 87], "warn": [85, 86], "filterwarn": [85, 86], "categori": [85, 86], "deprecationwarn": [85, 86], "r": [85, 86], "seed": [85, 86], "191009": [85, 86], "averagemet": [85, 86], "fmt": [85, 86], "reset": [85, 86], "val": [85, 86], "avg": [85, 86], "count": [85, 86], "__str__": [85, 86], "fmtstr": [85, 86], "topk": [85, 86], "predict": [85, 86], "maxk": [85, 86], "pred": [85, 86], "correct": [85, 86], "eq": [85, 86], "expand_a": [85, 86], "correct_k": [85, 86], "mul_": [85, 86], "criterion": [85, 86], "top1": [85, 86], "top5": [85, 86], "cnt": [85, 86], "acc1": [85, 86], "acc5": [85, 86], "load_model": [85, 86], "model_fil": [85, 86], "weights_onli": [85, 86], "print_size_of_model": [85, 86], "temp": [85, 86], "p": [85, 86], "1e6": [85, 86], "prepare_data_load": [85, 86], "485": [85, 86], "456": [85, 86], "std": [85, 86], "229": [85, 86], "225": [85, 86], "randomresizedcrop": [85, 86], "randomhorizontalflip": [85, 86], "totensor": [85, 86], "dataset_test": [85, 86], "resiz": [85, 86], "centercrop": [85, 86], "train_sampl": [85, 86], "randomsampl": [85, 86], "test_sampl": [85, 86], "sequentialsampl": [85, 86], "train_batch_s": [85, 86], "sampler": [85, 86], "data_loader_test": [85, 86, 87, 88], "eval_batch_s": [85, 86], "saved_model_dir": [85, 86], "float_model_fil": [85, 86], "model_to_quant": [85, 86], "capture_pre_autograd_graph": [85, 86], "dynamic_shap": [85, 86], "dynamic_dim": [85, 86], "constraint": [85, 86, 89], "qconfig_opt": 85, "set_object_typ": 85, "set_module_nam": 85, "workload": 85, "themodel": 85, "feedback": 85, "dq": 85, "fp32_op": 85, "qauntiz": 85, "x_int8": 85, "x_zero_point": 85, "weight_int8": 85, "bias_fp32": 85, "output_scal": 85, "output_zero_point": 85, "x_fp32": 85, "quantized_decompos": 85, "dequantize_per_tensor": 85, "x_i8": 85, "x_quant_min": 85, "x_quant_max": 85, "weight_fp32": 85, "weight_i8": 85, "weight_quant_min": 85, "weight_quant_max": 85, "weight_permut": 85, "permute_copi": 85, "out_fp32": 85, "addmm": 85, "out_i8": 85, "quantize_per_tensor": 85, "out_zero_point": 85, "out_quant_min": 85, "out_quant_max": 85, "float32_op": 85, "decompos": 85, "use_reference_represent": 85, "x_int16": 85, "int16": 85, "weight_int16": 85, "acc_int32": 85, "out_dtyp": 85, "bias_scal": 85, "bias_int32": 85, "div": 85, "mul": 85, "out_int8": 85, "qmin": 85, "qmax": 85, "date": 85, "unus": 85, "serila": 85, "consult": 85, "exportedprogram": 85, "pt2e_quantized_model_file_path": 85, "resnet18_pt2e_quant": 85, "quantized_ep": 85, "loaded_quantized_ep": 85, "loaded_quantized_model": 85, "diff": 85, "79": 85, "82": 85, "55": 85, "edg": [85, 89], "went": 85, "andrew": 86, "Or": 86, "move_exported_model_to_ev": [86, 87], "correctli": 86, "certain": 86, "dropout": 86, "move_exported_model_to_train": 86, "jit": 86, "recursivescriptmodul": 86, "train_one_epoch": 86, "ntrain_batch": 86, "avgloss": 86, "5f": 86, "start_tim": 86, "3f": 86, "global_avg": 86, "is_qat": [86, 87], "fusion": 86, "batchnorm2d": 86, "_native_batch_norm_legit": 86, "cudnn_batch_norm": 86, "mobilenetv2": 86, "manual": 86, "recompil": 86, "consolid": 86, "epoch": 86, "far": 86, "num_epoch": 86, "num_train_batch": 86, "num_eval_batch": 86, "num_observer_update_epoch": 86, "num_batch_norm_update_epoch": 86, "num_epochs_between_ev": 86, "nepoch": 86, "stat": 86, "subseq": 86, "disable_observ": 86, "bn": 86, "running_mean": 86, "running_var": 86, "new_arg": 86, "wish": 86, "prepared_model_copi": 86, "neval_batch": 86, "paus": 86, "resum": 86, "fail": [86, 89], "checkpoint_path": 86, "checkpoint_": 86, "behav": 86, "incorrectli": 86, "lesli": [87, 89], "fang": [87, 89], "weiwen": [87, 89], "xia": [87, 89], "jiong": [87, 89], "gong": [87, 89], "cnn": 87, "rnn": 87, "outstand": 87, "fourth": 87, "spr": 87, "xeon": 87, "processor": 87, "boost": 87, "memory_format": [87, 88], "channels_last": [87, 88], "onednn": [87, 88], "assum": [87, 89], "word": 87, "satur": 87, "extern": 87, "pure": 87, "dedic": 87, "scenario": [87, 88], "plai": [87, 88], "convolut": [87, 88, 89], "absenc": [87, 88], "enhanc": [87, 88], "mirror": [87, 88], "autocast": [87, 88], "device_typ": [87, 88], "turn": [87, 88], "cpp": 87, "qconvolut": [87, 88], "qlinear": [87, 88], "presenc": [87, 88], "pair": [87, 88], "conting": [87, 88], "qmaxpool2d": [87, 88], "torchinductor_freez": [87, 88], "example_x86inductorquantizer_pytorch_2_1": 87, "torchbench": 87, "measur": 87, "proven": 87, "depth": 87, "example_x86inductorquantizer_qat": 87, "yan": 88, "zhiwei": 88, "wang": 88, "eikan": 88, "liangang": 88, "liu": 88, "river": 88, "cui": 88, "yifeng": 88, "xpuinductorquant": 88, "pip3": 88, "torchaudio": 88, "xpu_inductor_quantizer_exampl": 88, "xpu_inductor_quant": 88, "xpuiq": 88, "resnet18_weight": 88, "get_default_xpu_inductor_quantization_config": 88, "wherea": 88, "histogramobserv": [88, 89], "perchannelminmaxobserv": 88, "quantizationspec": [88, 89], "quantizationconfig": [88, 89], "type_check": 88, "observerorfakequantizeconstructor": 88, "get_xpu_inductor_symm_quantization_config": 88, "extra_arg": 88, "act_observer_or_fake_quant_ctr": 88, "act_quantization_spec": [88, 89], "qscheme": [88, 89], "per_tensor_symmetr": [88, 89], "observer_or_fake_quant_ctr": [88, 89], "with_arg": [88, 89], "weight_observer_or_fake_quant_ctr": 88, "weight_quantization_spec": [88, 89], "per_channel_symmetr": 88, "ch_axi": 88, "oc": 88, "ic": 88, "kh": 88, "kw": 88, "conv": [88, 89], "bias_quantization_spec": 88, "amp": 88, "indcutor": 88, "kimish": 89, "patel": 89, "made": 89, "explicit": 89, "quantiat": 89, "encod": 89, "convei": 89, "quantizationannot": 89, "furthermor": 89, "minmaxobserv": 89, "input_qspec_map": 89, "output_qspec": 89, "_annot": 89, "conclud": 89, "matcher": 89, "get_source_partit": 89, "add_partit": 89, "gm": 89, "itertool": 89, "chain": 89, "add_nod": 89, "output_nod": 89, "per_tensor_affin": 89, "input_act_qspec": 89, "output_act_qspec": 89, "input_act0": 89, "input_act1": 89, "quantization_annot": 89, "substitut": 89, "among": 89, "sharedquantizationspec": 89, "maxpool": 89, "average_pool": 89, "concat": 89, "whose": 89, "edgeornod": 89, "transit": 89, "spec": 89, "conv1": 89, "conv2": 89, "fed": 89, "conv1_out": 89, "conv2_out": 89, "qspec1": 89, "cat_input0": 89, "cat_input1": 89, "implicitli": 89, "therefor": 89, "ob": 89, "consum": 89, "rewrit": 89, "share_qparams_with_input_act0_qspec": 89, "known": 89, "beforehand": 89, "sigmoid": 89, "fixedqparamsquantizationspec": 89, "act_qspec": 89, "sigmoid_nod": 89, "input_act": 89, "derivedquantizationspec": 89, "derive_qparams_fn": 89, "observerorfakequant": 89, "observerbas": 89, "fakequantizebas": 89, "heurist": 89, "obejct": 89, "obs_or_fq": 89, "fq": 89, "act_obs_or_fq": 89, "weight_obs_or_fq": 89, "act_zp": 89, "weight_zp": 89, "bias_qspec": 89, "derived_from": 89, "backendquant": 89, "get_input_act_qspec": 89, "get_output_act_qspec": 89, "get_weight_qspec": 89, "get_bias_qspec": 89, "intermedi": 89, "straightforward": 89, "call_funct": 89, "relu_": 89, "relu_nod": 89, "maybe_conv_nod": 89, "conv1d": 89, "unexpect": 89, "recognz": 89, "unquant": 89, "subgraphmatch": 89, "conv_relu_pattern": 89, "name_node_map": 89, "input_nod": 89, "weight_nod": 89, "bias_nod": 89, "caveat": 89, "exhaust": 89, "2d": 89, "4d": 89, "symbol": 89, "outcom": 89}, "objects": {"torchao.float8": [[12, 0, 1, "", "CastConfig"], [13, 0, 1, "", "Float8LinearConfig"], [14, 0, 1, "", "ScalingGranularity"], [15, 0, 1, "", "ScalingType"], [16, 2, 1, "", "convert_to_float8_training"], [17, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[13, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[18, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [19, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [20, 0, 1, "", "Float8WeightOnlyConfig"], [21, 0, 1, "", "Int4WeightOnlyConfig"], [22, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [23, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [24, 0, 1, "", "Int8WeightOnlyConfig"], [25, 0, 1, "", "MappingType"], [26, 0, 1, "", "TorchAODType"], [27, 2, 1, "", "choose_qparams_affine"], [28, 2, 1, "", "choose_qparams_affine_with_min_max"], [29, 2, 1, "", "dequantize_affine"], [30, 2, 1, "", "int_scaled_matmul"], [55, 2, 1, "", "quantize_"], [60, 2, 1, "", "quantize_affine"], [61, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[31, 0, 1, "", "ComposableQATQuantizer"], [32, 0, 1, "", "FakeQuantizeConfigBase"], [33, 0, 1, "", "FakeQuantizedEmbedding"], [34, 0, 1, "", "FakeQuantizedLinear"], [35, 0, 1, "", "FakeQuantizerBase"], [36, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [37, 0, 1, "", "Float8FakeQuantizeConfig"], [38, 0, 1, "", "Float8FakeQuantizer"], [39, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [40, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [41, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [42, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [43, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [44, 0, 1, "", "IntxFakeQuantizeConfig"], [45, 0, 1, "", "IntxFakeQuantizer"], [46, 0, 1, "", "QATConfig"], [47, 0, 1, "", "QATStep"], [50, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[33, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[34, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[36, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[38, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[40, 1, 1, "", "convert"], [40, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[44, 3, 1, "", "group_size"], [44, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[45, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[48, 0, 1, "", "Int4WeightOnlyEmbedding"], [49, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[48, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[51, 0, 1, "", "Int4WeightOnlyQATLinear"], [52, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [53, 2, 1, "", "disable_linear_fake_quant"], [54, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[56, 0, 1, "", "KernelPreference"], [57, 0, 1, "", "PackingFormat"], [58, 0, 1, "", "QuantizeTensorKwargs"], [59, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[56, 4, 1, "", "AUTO"], [56, 4, 1, "", "FBGEMM"], [56, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[57, 4, 1, "", "PLAIN"]], "torchao": [[5, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[62, 0, 1, "", "PerChannelNormObserver"], [63, 0, 1, "", "WandaSparsifier"], [64, 2, 1, "", "apply_fake_sparsity"], [65, 4, 1, "", "semi_sparse_weight"], [66, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[62, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[63, 1, 1, "", "prepare"], [63, 1, 1, "", "squash_mask"], [63, 1, 1, "", "update_mask"]], "torchao.utils": [[67, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[67, 1, 1, "", "get_tensor_impl_constructor"], [67, 1, 1, "", "implements"], [67, 1, 1, "", "implements_torch_function"], [67, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 9, 11, 68, 70, 71, 80], "float8": [0, 11, 70, 71], "main": [0, 3, 4], "train": [0, 11, 70, 71, 74, 84, 85, 86, 87, 88], "api": [0, 1, 3, 4, 6, 7, 11, 68, 70, 89], "other": [0, 9, 71], "type": [0, 79], "refer": [1, 68], "python": 1, "kernel": [2, 9, 69, 71, 80], "quantiz": [3, 4, 6, 11, 55, 68, 71, 72, 74, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89], "qat": [3, 11, 86], "config": 3, "quantize_": [3, 4, 6], "custom": [3, 9], "legaci": 3, "prototyp": 3, "infer": [4, 74], "primit": [4, 71], "sparsiti": [5, 75], "util": 6, "tensor": [6, 9, 71, 77, 78, 80, 89], "subclass": [6, 9, 78, 80], "common": [6, 7, 89], "benchmark": [7, 8, 9, 74], "guid": [7, 8, 9, 72, 80], "add": [7, 80], "an": [7, 73], "recip": [7, 70], "model": [7, 9, 70, 71, 72, 73, 74, 79, 80, 84, 85, 86], "design": [7, 75], "consider": 7, "hf": 7, "ci": 7, "dashboard": 7, "1": [7, 11, 70, 74, 79, 80, 84, 87, 88, 89], "modifi": 7, "exist": 7, "configur": [7, 75, 80, 85, 86], "2": [7, 11, 72, 74, 79, 80, 84, 85, 86, 87, 88, 89], "run": 7, "3": [7, 11, 74, 80, 84, 87, 88, 89], "output": [7, 78], "format": [7, 71], "4": [7, 84, 89], "integr": [7, 11, 79, 80], "pipelin": 7, "troubleshoot": 7, "test": [7, 9], "issu": 7, "best": 7, "practic": 7, "user": 8, "contributor": 9, "gener": 9, "extend": 9, "ad": [9, 80], "new": [9, 80], "effici": [9, 71], "triton": 9, "hand": 9, "written": 9, "us": [9, 89], "kernelprefer": [9, 56], "flow": [9, 71, 73, 80, 89], "torch": [9, 84, 85, 86], "compil": [9, 80, 84], "perform": [9, 69, 74, 85], "serial": [9, 73, 80], "featur": 9, "support": [9, 79, 80], "function": [9, 85, 86], "compos": 9, "microbenchmark": 9, "eval": [9, 85], "dtype": [10, 71], "part": [11, 70, 74], "fine": 11, "tune": 11, "qlora": 11, "awar": [11, 71, 86, 87], "option": [11, 74, 83, 84], "torchtun": 11, "axolotl": 11, "low": [11, 71], "rank": 11, "adapt": 11, "huggingfac": [11, 74, 80], "peft": 11, "castconfig": 12, "float8linearconfig": 13, "scalinggranular": 14, "scalingtyp": 15, "convert_to_float8_train": 16, "precompute_float8_dynamic_scale_for_fsdp": 17, "float8dynamicactivationfloat8weightconfig": 18, "float8dynamicactivationint4weightconfig": 19, "float8weightonlyconfig": 20, "int4weightonlyconfig": 21, "int8dynamicactivationint4weightconfig": 22, "int8dynamicactivationint8weightconfig": 23, "int8weightonlyconfig": 24, "mappingtyp": 25, "torchaodtyp": 26, "choose_qparams_affin": 27, "choose_qparams_affine_with_min_max": 28, "dequantize_affin": 29, "int_scaled_matmul": 30, "composableqatquant": 31, "fakequantizeconfigbas": 32, "fakequantizedembed": 33, "fakequantizedlinear": 34, "fakequantizerbas": 35, "float8actint4weightqatquant": 36, "float8fakequantizeconfig": 37, "float8fakequant": 38, "fromintxquantizationawaretrainingconfig": 39, "int4weightonlyembeddingqatquant": 40, "int4weightonlyqatquant": 41, "int8dynactint4weightqatquant": 42, "intxquantizationawaretrainingconfig": 43, "intxfakequantizeconfig": 44, "intxfakequant": 45, "qatconfig": 46, "qatstep": 47, "int4weightonlyembed": 48, "int4weightonlyqatembed": 49, "initialize_fake_quant": 50, "int4weightonlyqatlinear": 51, "int8dynactint4weightqatlinear": 52, "disable_linear_fake_qu": 53, "enable_linear_fake_qu": 54, "packingformat": 57, "quantizetensorkwarg": 58, "_choose_quant_func_and_quantize_tensor": 59, "quantize_affin": 60, "safe_int_mm": 61, "perchannelnormobserv": 62, "wandasparsifi": 63, "apply_fake_spars": 64, "semi_sparse_weight": 65, "sparsifi": 66, "torchaobasetensor": 67, "welcom": 68, "document": 68, "get": 68, "start": [68, 72, 79], "develop": 68, "note": [68, 70, 89], "eager": 68, "tutori": [68, 83], "pt2e": [68, 89], "pre": 70, "torchtitan": 70, "prerequisit": [70, 84, 87, 88, 89], "rowwis": 70, "scale": 70, "tensorwis": 70, "pick": 70, "import": [70, 85, 86], "directli": [70, 89], "convers": 70, "overview": [71, 75, 83], "basic": 71, "op": 71, "deriv": [71, 89], "pack": 71, "algorithm": 71, "weight": [71, 72, 74], "onli": 71, "dynam": [71, 72], "activ": [71, 72], "static": [71, 76], "bit": [71, 72], "optim": [71, 73, 74], "case": 71, "studi": 71, "how": [71, 85, 86, 89], "work": 71, "dure": 71, "execut": 71, "save": [71, 79, 85, 86], "load": [71, 85, 86], "quick": [72, 79], "first": 72, "exampl": [72, 79, 80, 89], "set": [72, 85], "up": 72, "w8a8": 72, "int": 72, "8": 72, "size": [72, 85], "comparison": 72, "speedup": 72, "pytorch": [72, 84, 85, 86, 87, 88, 89], "export": [72, 74, 84, 85, 86, 87, 88, 89], "next": [72, 78], "step": [72, 74, 78, 80, 83], "deseri": 73, "what": [73, 78], "happen": 73, "when": 73, "serv": [74, 80], "vllm": [74, 80], "sglang": 74, "executorch": 74, "post": [74, 84, 85, 87, 88], "transform": [74, 79, 80], "mobil": 74, "deploy": 74, "unti": 74, "embed": 74, "creat": [74, 80], "characterist": 74, "evalu": [74, 85], "qualiti": 74, "assess": 74, "memori": 74, "latenc": 74, "result": 74, "h100": 74, "machin": 74, "conclus": [74, 83, 84, 85, 86, 87, 88, 89], "goal": 75, "context": 75, "prune": 75, "criteria": 75, "strategi": 75, "pattern": [75, 89], "calibr": [76, 85], "phase": 76, "write": [77, 78, 89], "your": [77, 78, 80], "own": [77, 78], "advanc": 77, "ar": 78, "modul": 78, "swap": 78, "which": 78, "oper": [78, 80, 89], "should": 78, "we": 78, "implement": [78, 80], "compar": 78, "hug": 79, "face": 79, "usag": [79, 80], "diffus": 79, "architectur": 80, "system": 80, "class": 80, "fqn": 80, "method": 80, "minim": 80, "requir": 80, "compat": 80, "why": 80, "regist": 80, "": 80, "kei": 80, "detail": 80, "hardwar": 80, "specif": [80, 85, 86], "linear": 80, "benefit": 80, "trade": 80, "off": 80, "share": [80, 89], "safetensor": 80, "diagram": 80, "high": 80, "level": 80, "point": 80, "dispatch": 80, "bring": 80, "extern": 80, "comput": 82, "time": 82, "templat": 83, "addit": 83, "exercis": 83, "further": 83, "read": 83, "openvino": 84, "backend": [84, 85, 86, 87, 88], "introduct": [84, 87, 88, 89], "nncf": 84, "instal": 84, "captur": [84, 87, 88], "fx": [84, 87, 88], "graph": [84, 87, 88], "appli": [84, 87, 88], "lower": [84, 85, 87, 88], "represent": 84, "improv": 84, "metric": 84, "motiv": [85, 89], "defin": [85, 86], "helper": [85, 86], "prepar": [85, 86], "dataset": [85, 86], "mode": 85, "convert": [85, 86], "check": 85, "accuraci": 85, "debug": 85, "loop": 86, "checkpoint": 86, "x86": 87, "through": [87, 88], "inductor": [87, 88], "intel": 88, "gpu": 88, "annot": 89, "param": 89, "fix": 89, "paramet": 89, "5": 89, "A": 89, "toi": 89, "resnet18": 89, "ir": 89, "problem": 89, "match": 89, "aten": 89, "recommend": 89, "subgraphmatcherwithnamenodemap": 89}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao API Reference": [[1, "torchao-api-reference"]], "Python API Reference": [[1, null]], "torchao.kernel": [[2, "torchao-kernel"]], "torchao.quantization.qat": [[3, "torchao-quantization-qat"]], "Main Config for quantize_": [[3, "main-config-for-quantize"]], "Custom QAT APIs": [[3, "custom-qat-apis"]], "Legacy QAT APIs": [[3, "legacy-qat-apis"]], "Prototype": [[3, "prototype"]], "torchao.quantization": [[4, "torchao-quantization"]], "Main Quantization APIs": [[4, "main-quantization-apis"]], "Inference APIs for quantize_": [[4, "inference-apis-for-quantize"]], "Quantization Primitives": [[4, "quantization-primitives"]], "torchao.sparsity": [[5, "module-torchao.sparsity"]], "torchao.utils": [[6, "torchao-utils"]], "Tensor Subclass Utils": [[6, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[6, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[6, "quantize-api-common-utils"]], "Benchmarking API Guide": [[7, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[7, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[7, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[7, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[7, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[7, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[7, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[7, "run-ci-benchmarks"]], "3. CI Output Format": [[7, "ci-output-format"]], "4. Integration with CI Pipeline": [[7, "integration-with-ci-pipeline"]], "Troubleshooting": [[7, "troubleshooting"]], "Running Tests": [[7, "running-tests"]], "Common Issues": [[7, "common-issues"]], "Best Practices": [[7, "best-practices"]], "Benchmarking User Guide": [[8, "benchmarking-user-guide"]], "Contributor Guide": [[9, "contributor-guide"]], "General Guide on Extending torchao": [[9, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[9, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[9, "adding-efficient-kernels"]], "Custom triton kernels": [[9, "custom-triton-kernels"]], "Custom hand written kernels": [[9, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[9, "using-hand-written-kernels-in-tensor-subclasses"]], "KernelPreference": [[9, "kernelpreference"], [56, "kernelpreference"]], "Flow": [[9, "flow"]], "Using torch.compile for Performance": [[9, "using-torch-compile-for-performance"]], "Serialization": [[9, "serialization"], [73, "serialization"]], "Other Feature Support": [[9, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[9, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[9, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[9, "model-benchmarks-and-eval"]], "Dtypes": [[10, "dtypes"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[11, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[11, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[11, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[11, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[11, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[11, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[11, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[11, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[11, "float8-quantized-fine-tuning"]], "CastConfig": [[12, "castconfig"]], "Float8LinearConfig": [[13, "float8linearconfig"]], "ScalingGranularity": [[14, "scalinggranularity"]], "ScalingType": [[15, "scalingtype"]], "convert_to_float8_training": [[16, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[17, "precompute-float8-dynamic-scale-for-fsdp"]], "Float8DynamicActivationFloat8WeightConfig": [[18, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[19, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[20, "float8weightonlyconfig"]], "Int4WeightOnlyConfig": [[21, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[22, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[23, "int8dynamicactivationint8weightconfig"]], "Int8WeightOnlyConfig": [[24, "int8weightonlyconfig"]], "MappingType": [[25, "mappingtype"]], "TorchAODType": [[26, "torchaodtype"]], "choose_qparams_affine": [[27, "choose-qparams-affine"]], "choose_qparams_affine_with_min_max": [[28, "choose-qparams-affine-with-min-max"]], "dequantize_affine": [[29, "dequantize-affine"]], "int_scaled_matmul": [[30, "int-scaled-matmul"]], "ComposableQATQuantizer": [[31, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[32, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[33, "fakequantizedembedding"]], "FakeQuantizedLinear": [[34, "fakequantizedlinear"]], "FakeQuantizerBase": [[35, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[36, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[37, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[38, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[39, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[40, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[41, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[42, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[43, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[44, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[45, "intxfakequantizer"]], "QATConfig": [[46, "qatconfig"]], "QATStep": [[47, "qatstep"]], "Int4WeightOnlyEmbedding": [[48, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[49, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[50, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[51, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[52, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[53, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[54, "enable-linear-fake-quant"]], "quantize": [[55, "quantize"]], "PackingFormat": [[57, "packingformat"]], "QuantizeTensorKwargs": [[58, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[59, "choose-quant-func-and-quantize-tensor"]], "quantize_affine": [[60, "quantize-affine"]], "safe_int_mm": [[61, "safe-int-mm"]], "PerChannelNormObserver": [[62, "perchannelnormobserver"]], "WandaSparsifier": [[63, "wandasparsifier"]], "apply_fake_sparsity": [[64, "apply-fake-sparsity"]], "semi_sparse_weight": [[65, "semi-sparse-weight"]], "sparsify": [[66, "sparsify"]], "TorchAOBaseTensor": [[67, "torchaobasetensor"]], "Welcome to the torchao Documentation": [[68, "welcome-to-the-torchao-documentation"]], "Getting Started": [[68, null]], "Developer Notes": [[68, null]], "API Reference": [[68, null]], "Eager Quantization Tutorials": [[68, null]], "PT2E Quantization Tutorials": [[68, null]], "Performant Kernels": [[69, "performant-kernels"]], "(Part 1) Pre-training with float8": [[70, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[70, "pre-training-with-torchtitan"]], "Prerequisites": [[70, "prerequisites"], [70, "id1"], [84, "prerequisites"], [87, "prerequisites"], [88, "prerequisites"]], "Rowwise scaling": [[70, "rowwise-scaling"]], "Tensorwise scaling": [[70, "tensorwise-scaling"]], "Picking a recipe": [[70, "picking-a-recipe"]], "Important notes": [[70, "important-notes"]], "Pre-training with torchao directly": [[70, "pre-training-with-torchao-directly"]], "Model conversion API": [[70, "model-conversion-api"]], "Quantization Overview": [[71, "quantization-overview"]], "Basic DTypes": [[71, "basic-dtypes"]], "Quantization Primitive Ops": [[71, "quantization-primitive-ops"]], "Efficient kernels": [[71, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[71, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[71, "quantization-algorithms-flows"]], "Weight Only Quantization": [[71, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[71, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[71, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[71, "other-quantization-flows"]], "Training": [[71, "training"]], "Quantization Aware Training": [[71, "quantization-aware-training"], [87, "quantization-aware-training"]], "Low Bit Optimizers": [[71, "low-bit-optimizers"]], "Quantized Training": [[71, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[71, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[71, "during-quantization"]], "During Model Execution": [[71, "during-model-execution"]], "During Save/Load": [[71, "during-save-load"]], "Quick Start Guide": [[72, "quick-start-guide"]], "First Quantization Example": [[72, "first-quantization-example"]], "Setting Up the Model": [[72, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[72, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[72, "model-size-comparison"]], "Speedup Comparison": [[72, "speedup-comparison"]], "PyTorch 2 Export Quantization": [[72, "pytorch-2-export-quantization"]], "Next Steps": [[72, "next-steps"], [78, "next-steps"]], "Serialization and deserialization flow": [[73, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[73, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[73, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[74, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[74, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[74, "serving-and-inference"]], "Serving and Inference with vLLM": [[74, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[74, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[74, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[74, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[74, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[74, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[74, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[74, "mobile-performance-characteristics"]], "Evaluation": [[74, "evaluation"]], "Model Quality Assessment": [[74, "model-quality-assessment"]], "Memory Benchmarking": [[74, "memory-benchmarking"]], "Performance Benchmarking": [[74, "performance-benchmarking"]], "Latency Benchmarking": [[74, "latency-benchmarking"]], "Serving Benchmarking": [[74, "serving-benchmarking"]], "Results (H100 machine)": [[74, "results-h100-machine"]], "Conclusion": [[74, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [87, "conclusion"], [88, "conclusion"], [89, "conclusion"]], "Sparsity Overview": [[75, "sparsity-overview"]], "Goal": [[75, "goal"]], "Design": [[75, "design"]], "Context": [[75, "context"]], "Pruning Configuration": [[75, "pruning-configuration"]], "Pruning Criteria": [[75, "pruning-criteria"]], "Pruning Strategy": [[75, "pruning-strategy"]], "Sparsity Pattern": [[75, "sparsity-pattern"]], "Static Quantization": [[76, "static-quantization"]], "Calibration Phase": [[76, "calibration-phase"]], "Quantization Phase": [[76, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[77, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[78, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[78, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[78, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[78, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[78, "which-operators-should-we-implement"]], "Comparing the Outputs": [[78, "comparing-the-outputs"]], "Hugging Face Integration": [[79, "hugging-face-integration"]], "Quick Start: Usage Example": [[79, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[79, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[79, "quantizing-models-with-diffusers"]], "Saving the Model": [[79, "saving-the-model"]], "Supported Quantization Types": [[79, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[80, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[80, "configuration-system"]], "1. HuggingFace Model Configuration": [[80, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[80, "torchao-configuration-classes"]], "3. FQN Configuration": [[80, "fqn-configuration"]], "Usage Examples": [[80, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[80, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[80, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[80, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[80, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[80, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[80, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[80, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[80, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[80, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[80, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[80, "hardware-specific-linear-operations"]], "Compilation Benefits": [[80, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[80, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[80, "serialization-and-model-sharing"]], "SafeTensors Support": [[80, "safetensors-support"]], "Integration Architecture Diagrams": [[80, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[80, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[80, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[80, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Computation times": [[82, "computation-times"]], "Template Tutorial": [[83, "template-tutorial"]], "Overview": [[83, "overview"]], "Steps": [[83, "steps"]], "(Optional) Additional Exercises": [[83, "optional-additional-exercises"]], "Further Reading": [[83, "further-reading"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[84, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[84, "introduction"], [87, "introduction"], [88, "introduction"], [89, "introduction"]], "Post Training Quantization": [[84, "post-training-quantization"], [87, "post-training-quantization"], [88, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[84, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[84, "capture-fx-graph"], [87, "capture-fx-graph"], [88, "capture-fx-graph"]], "2. Apply Quantization": [[84, "apply-quantization"], [87, "apply-quantization"], [88, "apply-quantization"]], "3. Lower into OpenVINO representation": [[84, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[84, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[85, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[85, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[85, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[85, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[85, "export-the-model-with-torch-export"], [86, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[85, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [86, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[85, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[85, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[85, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[85, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[85, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[85, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[85, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[86, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[86, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[86, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[86, "training-loop"]], "Saving and Loading Model Checkpoints": [[86, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[86, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[87, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[87, "lower-into-inductor"], [88, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[88, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[89, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[89, "prerequisites"]], "Annotation API": [[89, "annotation-api"]], "1. Annotate Common Operator Patterns": [[89, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[89, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[89, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[89, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[89, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[89, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[89, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[89, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]]}, "indexentries": {"module": [[5, "module-torchao.sparsity"]], "torchao.sparsity": [[5, "module-torchao.sparsity"]], "castconfig (class in torchao.float8)": [[12, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[13, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[13, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[14, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[15, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[16, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[17, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[19, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[20, "torchao.quantization.Float8WeightOnlyConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8WeightOnlyConfig"]], "mappingtype (class in torchao.quantization)": [[25, "torchao.quantization.MappingType"]], "torchaodtype (class in torchao.quantization)": [[26, "torchao.quantization.TorchAODType"]], "choose_qparams_affine() (in module torchao.quantization)": [[27, "torchao.quantization.choose_qparams_affine"]], "choose_qparams_affine_with_min_max() (in module torchao.quantization)": [[28, "torchao.quantization.choose_qparams_affine_with_min_max"]], "dequantize_affine() (in module torchao.quantization)": [[29, "torchao.quantization.dequantize_affine"]], "int_scaled_matmul() (in module torchao.quantization)": [[30, "torchao.quantization.int_scaled_matmul"]], "composableqatquantizer (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[33, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[34, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[36, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[38, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[40, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[40, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[43, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[44, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[44, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[44, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[45, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[45, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[46, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[47, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[48, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[48, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[49, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[50, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[51, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[52, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[53, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[54, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[55, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[56, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "fbgemm (torchao.quantization.quantize_.common.kernelpreference attribute)": [[56, "torchao.quantization.quantize_.common.KernelPreference.FBGEMM"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[56, "torchao.quantization.quantize_.common.KernelPreference"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[56, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[57, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[57, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[58, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[59, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "quantize_affine() (in module torchao.quantization)": [[60, "torchao.quantization.quantize_affine"]], "safe_int_mm() (in module torchao.quantization)": [[61, "torchao.quantization.safe_int_mm"]], "perchannelnormobserver (class in torchao.sparsity)": [[62, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[62, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[63, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[63, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[63, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[63, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[64, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[65, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[66, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[67, "torchao.utils.TorchAOBaseTensor"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[67, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[67, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[67, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[67, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})