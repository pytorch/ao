Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.float8_dynamic_activation_float8_weight", "generated/torchao.quantization.float8_static_activation_float8_weight", "generated/torchao.quantization.float8_weight_only", "generated/torchao.quantization.fpx_weight_only", "generated/torchao.quantization.gemlite_uintx_weight_only", "generated/torchao.quantization.int4_weight_only", "generated/torchao.quantization.int8_dynamic_activation_int4_weight", "generated/torchao.quantization.int8_dynamic_activation_int8_weight", "generated/torchao.quantization.int8_weight_only", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.intx_quantization_aware_training", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.quantization.uintx_weight_only", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "subclass_advanced", "subclass_basic", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.float8_dynamic_activation_float8_weight.rst", "generated/torchao.quantization.float8_static_activation_float8_weight.rst", "generated/torchao.quantization.float8_weight_only.rst", "generated/torchao.quantization.fpx_weight_only.rst", "generated/torchao.quantization.gemlite_uintx_weight_only.rst", "generated/torchao.quantization.int4_weight_only.rst", "generated/torchao.quantization.int8_dynamic_activation_int4_weight.rst", "generated/torchao.quantization.int8_dynamic_activation_int8_weight.rst", "generated/torchao.quantization.int8_weight_only.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.intx_quantization_aware_training.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.quantization.uintx_weight_only.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "subclass_advanced.rst", "subclass_basic.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "MappingType", "TorchAODType", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "float8_dynamic_activation_float8_weight", "float8_static_activation_float8_weight", "float8_weight_only", "fpx_weight_only", "gemlite_uintx_weight_only", "int4_weight_only", "int8_dynamic_activation_int4_weight", "int8_dynamic_activation_int8_weight", "int8_weight_only", "int_scaled_matmul", "intx_quantization_aware_training", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "uintx_weight_only", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "int8_dynamic_activation_int8_semi_sparse_weight", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [1, 5, 7, 16, 17, 18, 19, 21, 29, 32, 33, 35, 37, 39, 40, 52, 53, 60, 61, 62, 65, 68, 69, 70, 72, 74, 77], "section": [1, 5, 68, 72], "introduc": 1, "dive": 1, "detail": [1, 5, 32, 68, 69, 72, 74], "how": [1, 5, 7, 13, 21, 29, 33, 53, 69, 70, 72, 74], "integr": [1, 5, 70, 72, 74], "pytorch": [1, 5, 7, 12, 15, 30, 66, 69, 72, 74, 77], "optim": [1, 5, 16, 32, 36, 52, 66, 72, 74], "your": [1, 5, 66, 68, 69, 72], "machin": 1, "learn": [1, 69, 72, 77], "model": [1, 32, 52, 56, 57, 61, 62, 65, 69, 72, 74], "dtype": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 53, 65, 66, 69, 70, 74], "quantiz": [1, 5, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 22, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 63, 65, 66, 70, 72], "sparsiti": [1, 10, 16, 19, 60, 61, 62, 63, 64, 65, 66, 68, 70], "tba": [2, 6, 67], "For": [5, 7, 33, 68, 69, 70, 72, 74], "new": [5, 7, 68, 74], "case": [5, 32, 55, 72, 74], "exampl": [5, 7, 29, 32, 33, 52, 61, 65, 68, 70, 71, 72, 74, 75, 76, 77], "train": [5, 39, 40, 66, 72, 74], "like": [5, 13, 32, 33, 68, 69, 70, 72, 74], "fp4": 5, "s": [5, 7, 29, 32, 33, 37, 39, 53, 54, 68, 69, 72, 74], "fine": [5, 72], "start": [5, 29, 30, 31, 32, 68, 72, 74], "prototyp": [5, 68], "folder": 5, "you": [5, 61, 68, 69, 70, 72, 74, 77], "could": [5, 68, 74], "also": [5, 32, 52, 68, 69, 70, 72, 74], "take": [5, 17, 52, 60, 65, 68, 72], "look": [5, 7, 68, 72], "affinequantizedtensor": [5, 15, 23, 24, 26, 68, 69, 70, 74], "what": [5, 7, 15, 32, 68, 69, 72, 77], "want": [5, 52, 65, 68, 70, 72, 74], "do": [5, 30, 32, 33, 50, 52, 68, 72, 74], "mostli": [5, 35], "e": [5, 7, 29, 32, 33, 37, 39, 52, 53, 54, 68, 70, 74], "g": [5, 7, 29, 32, 33, 37, 39, 52, 53, 68, 70, 74], "int3": 5, "exact": 5, "same": [5, 7, 33, 35, 37, 39, 40, 53, 55, 65, 68, 72, 74], "affin": [5, 7, 9, 10, 11, 12, 16, 19, 20, 25, 37, 39, 53, 68], "pleas": [5, 7, 15, 66, 68, 72, 74], "feel": [5, 68, 72, 74], "free": [5, 68, 74], "open": [5, 68, 72], "an": [5, 7, 20, 25, 26, 32, 40, 61, 66, 68, 72, 74], "issu": [5, 68, 69, 74], "have": [5, 29, 32, 33, 53, 61, 68, 72, 74], "question": [5, 68, 70, 72, 74], "specif": [5, 13, 16, 18, 19, 61, 68, 69, 70, 72], "more": [5, 7, 32, 40, 68, 69, 72, 74], "refer": [5, 7, 72, 74], "our": [5, 17, 69, 72, 74], "overview": [5, 66, 69], "page": [5, 69], "To": [5, 7, 15, 32, 68, 69, 70, 72], "contribut": [5, 69, 72], "exist": [5, 30, 68, 72, 74], "code": [5, 68, 69, 72, 74, 75, 77], "base": [5, 13, 18, 29, 61, 68, 69, 72, 74], "make": [5, 33, 68, 74], "trainabl": [5, 68, 74], "add": [5, 18, 74, 77], "parallel": [5, 74], "etc": [5, 68], "affine_quantized_tensor": [5, 70], "py": [5, 7, 15, 71, 76, 77], "api": [5, 32, 68, 69, 72, 74], "quant_api": [5, 52, 70], "primit": [5, 7, 15, 74], "op": [5, 7, 15, 32, 33, 39, 40, 52, 72, 74], "slight": [5, 72], "variat": [5, 68], "quant_primit": [5, 7, 15], "autotun": [5, 69], "cpu": [5, 7, 12, 70, 72], "cuda": [5, 7, 36, 52, 69, 70, 72, 74], "mp": 5, "csrc": 5, "mayb": 5, "well": [5, 13, 32, 68, 72], "spars": [5, 8, 16, 19, 61, 68, 72], "marlin": [5, 14, 15, 16, 27], "aqt": 5, "621": 5, "we": [5, 7, 17, 29, 32, 33, 35, 37, 39, 52, 53, 65, 68, 69, 70, 72], "ar": [5, 7, 11, 19, 21, 32, 33, 37, 39, 52, 53, 55, 61, 68, 69, 70, 72], "still": [5, 68, 72], "decid": [5, 68, 72], "split": 5, "can": [5, 20, 29, 32, 52, 53, 68, 69, 70, 72, 74], "implement": [5, 70, 72], "regist": [5, 60, 74], "mai": [5, 35, 68, 70], "need": [5, 33, 60, 61, 68, 69, 70, 72, 74], "defin": [5, 13, 21, 60, 61, 72, 74], "own": [5, 66, 72], "through": [5, 35, 68, 69, 74, 77], "int4": [5, 9, 12, 29, 52, 65, 69, 70], "access": 5, "my_custom_op": 5, "devic": [5, 7, 36, 52, 55, 69, 70, 74], "check": [5, 7, 15, 68, 69, 70, 74], "condit": [5, 68], "__torch_function__": [5, 68, 74], "__torch_dispatch__": [5, 74], "target": [5, 33, 61, 72], "oper": [5, 7, 11, 13, 16, 35], "bfloat16": [5, 17, 39, 53, 68, 69, 70, 72], "activ": [5, 32, 56, 61, 63, 66, 72], "uint4": [5, 68, 69], "weight": [5, 16, 17, 32, 52, 61, 63, 65, 66, 69, 70, 72, 74], "found": [5, 68, 69, 72, 74], "here": [5, 7, 53, 68, 70, 74], "allow": [5, 72, 74], "peopl": [5, 68, 70], "linear": [5, 16, 32, 33, 52, 57, 62, 63, 65, 68, 69, 70, 72, 74], "two": [5, 15, 19, 68, 72, 74], "dispatch_condit": [5, 68], "impl": [5, 7, 68], "actual": [5, 68, 74], "bia": [5, 68, 69, 70, 74], "run": [5, 32, 52, 56, 60, 68, 72, 74, 77], "both": [5, 7, 68, 72, 74], "input_tensor": [5, 17, 68], "weight_tensor": [5, 68], "argument": [5, 7, 20, 32, 37, 52, 68], "register_aqt_quantized_linear_dispatch": 5, "show": [5, 53, 68, 72], "work": [5, 19, 70, 72, 74], "sometim": [5, 72], "ha": [5, 7, 68, 72, 74], "pack": [5, 7, 9, 20, 21, 68], "order": [5, 32, 68, 72, 74], "yield": [5, 72], "And": [5, 17, 68, 74], "abstract": [5, 68], "see": [5, 7, 15, 68, 69, 70, 72, 74], "full": [5, 77], "after": [5, 32, 68, 70, 72], "wrap": [5, 32, 74], "factori": 5, "convert": [5, 7, 15, 17, 22, 25, 27, 28, 52, 54, 65, 68, 72], "from": [5, 7, 17, 18, 23, 24, 26, 33, 35, 37, 39, 52, 53, 65, 68, 69, 70, 71, 72, 74, 76, 77], "float": [5, 7, 15, 17, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 53, 54, 57, 61, 68, 70, 74], "point": [5, 7, 15, 27, 29, 31, 33, 37, 39, 53, 54, 68, 69, 70, 72, 74], "my": [5, 72], "to_my_dtyp": 5, "mydtypetensor": 5, "from_float": [5, 74], "level": [5, 61, 68, 72, 74], "reus": [5, 68, 74], "quantize_": [5, 52, 65, 68, 69, 70], "appli": [5, 7, 32, 52, 63, 65, 68, 69, 72], "convers": [5, 7, 68], "filter": [5, 32], "choos": [5, 68, 72, 74], "which": [5, 15, 21, 32, 68, 69, 70, 72], "modul": [5, 29, 30, 31, 32, 52, 56, 57, 60, 61, 65, 69, 70], "should": [5, 7, 33, 37, 39, 53, 60, 61, 68, 72], "algorithm": [5, 72], "onli": [5, 12, 65, 69, 70, 72, 74], "dynam": [5, 65, 74], "quant": [5, 7, 15, 68], "static": [5, 7, 13, 17, 23, 26, 35], "type": [5, 7, 16, 17, 21, 29, 30, 31, 32, 36, 50, 53, 55, 66, 68, 70, 72, 74], "note": [5, 40, 61, 68, 69, 72, 74], "2": [5, 7, 10, 12, 16, 19, 29, 32, 33, 40, 53, 62, 63, 65, 68, 69, 72, 74, 77], "4": [5, 10, 16, 19, 28, 33, 36, 62, 63, 65, 68, 69, 70, 72, 74], "below": [5, 68, 72, 74, 77], "follow": [5, 68, 69, 72, 74], "util": [5, 68, 69, 70, 74], "import": [5, 33, 52, 65, 69, 70, 72, 74, 77], "unwrap_tensor_subclass": [5, 69], "m_unwrap": 5, "m": [5, 52, 54, 65, 69, 70, 74], "In": [5, 68, 69, 72, 74], "compat": [5, 16, 69], "aim": [5, 68, 72], "fullgraph": [5, 69], "true": [5, 7, 25, 32, 33, 35, 36, 52, 56, 65, 69, 70, 74], "first": [5, 17, 32, 50, 61, 68, 74], "remov": [5, 61, 72], "ani": [5, 18, 32, 58, 61, 68, 72, 74], "unnecessari": 5, "graph": 5, "break": 5, "torch_log": 5, "output_cod": 5, "when": [5, 7, 18, 33, 37, 39, 53, 68, 72], "script": [5, 69, 74, 77], "inductor": [5, 32], "python": [5, 68, 72, 75, 77], "mode": [5, 32, 69], "max": [5, 29, 68, 69, 74], "checkout": [5, 7, 15, 66, 68], "doc": [5, 68, 74], "huggingfac": 5, "transform": [5, 7, 68], "deseri": [5, 68], "save_pretrain": 5, "push_to_hub": 5, "from_pretrain": 5, "http": [5, 7, 15, 32, 61, 69, 72], "co": 5, "main": [5, 7, 15, 68, 69, 72, 74], "en": [5, 32], "anoth": [5, 68, 72, 74], "diffus": 5, "github": [5, 7, 15, 69], "com": [5, 7, 15], "sayakpaul": 5, "blob": [5, 7, 15], "infer": [5, 7, 56, 66, 68, 69, 70, 72, 74], "serialization_and_load": 5, "md": 5, "The": [5, 7, 8, 13, 16, 21, 32, 50, 52, 55, 56, 57, 61, 68, 69, 70, 72, 74], "abov": [5, 29, 68, 70, 72, 74], "just": [5, 29, 68, 70, 72, 74], "talk": [5, 68], "about": [5, 68, 69, 70, 72], "basic": [5, 18, 69, 74], "provid": [5, 13, 16, 19, 20, 32, 33, 68, 72, 74], "fsdp": [5, 68], "ll": [5, 29, 33, 68, 74], "put": [5, 65], "developer_api_guid": 5, "cover": [5, 68, 77], "executorch": [5, 52], "torchchat": 5, "todo": [5, 68], "qat": [5, 39, 40], "suit": 5, "out": [5, 19, 29, 32, 61, 68, 69, 72, 74], "differ": [5, 13, 35, 53, 55, 68, 69, 70, 72, 74], "system": 5, "dtensor": [5, 74], "recommend": [5, 32], "copi": [5, 7, 61, 69, 70, 72, 74], "past": [5, 72], "adapt": 5, "now": [5, 68, 69, 72, 74], "befor": [5, 52, 68, 70, 72, 74], "some": [5, 32, 52, 61, 68, 72, 74], "singl": [5, 32, 35, 69, 72], "comput": [5, 16, 20, 60, 61, 72, 74], "intens": 5, "memori": [5, 7, 40, 69, 72, 74], "input": [5, 7, 16, 17, 19, 32, 33, 35, 37, 39, 40, 50, 52, 53, 55, 61, 65, 68, 74], "dimens": [5, 7, 21, 33, 37, 39, 50, 53, 74], "get": [5, 17, 68, 72], "sens": [5, 68, 74], "speedup": [5, 68, 69, 72], "d": [5, 68], "creat": [5, 7, 23, 24, 26, 68, 72, 74], "file": [5, 71, 74, 76], "benchmark_aq": 5, "shape": [5, 7, 15, 32, 50, 55, 69, 74], "A": [5, 7, 21, 32, 35, 40, 60, 72, 74], "quick": [5, 66], "wai": [5, 7, 32, 68, 72, 74], "relev": [5, 68, 77], "chang": [5, 52, 68, 69, 70, 72, 74], "interest": [5, 68, 72, 74], "tutori": [5, 7, 68, 71, 72, 74, 75, 76], "print_op_and_shap": 5, "output": [5, 32, 33, 37, 39, 53, 68, 72, 77], "torch_func": 5, "built": [5, 74], "k": [5, 55, 69, 70, 74], "n": [5, 69, 70, 74], "10": [5, 29, 53], "method": [5, 13, 16, 19, 20, 32, 52, 61, 72, 74], "_c": 5, "tensorbas": 5, "object": [5, 21, 52, 65, 74], "arg": [5, 7, 61, 74], "0": [5, 7, 32, 33, 53, 57, 61, 69, 70, 71, 72, 74, 76, 77], "size": [5, 7, 8, 15, 17, 33, 37, 39, 53, 69, 70, 72, 74], "all": [5, 29, 32, 35, 60, 61, 62, 68, 69, 70, 71, 72, 74, 75], "under": 5, "benchmark_your_kernel": 5, "helper": 5, "right": [5, 68, 72], "1": [5, 16, 21, 29, 30, 31, 32, 33, 36, 53, 61, 68, 69, 70, 71, 72, 74, 76, 77], "either": [5, 7, 33, 37, 39, 53, 61, 72], "one": [5, 32, 35, 60, 68, 72, 74], "probabl": 5, "keep": [5, 16, 61], "futur": 5, "llama": 5, "llama2": 5, "llama3": 5, "sam": 5, "alreadi": [5, 7, 32, 74], "modifi": [5, 52, 61, 68, 72, 74], "friendli": [5, 68], "compar": [5, 40, 61, 68], "techniqu": [5, 70, 72, 74], "repres": [5, 7, 8, 11, 13, 24, 53, 61, 68, 70, 74], "bound": [5, 72], "help": [5, 68], "option": [5, 7, 11, 15, 22, 25, 26, 27, 32, 33, 35, 37, 39, 40, 52, 53, 56, 57, 58, 61, 65, 69], "each": [5, 17, 32, 56, 60, 68, 72, 74], "understand": 5, "profil": 5, "profile_path": 5, "chrome": 5, "trace": [5, 68], "let": [5, 29, 53, 68, 69, 72, 74], "know": [5, 32, 74], "class": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 31, 32, 60, 61, 68, 69, 70, 74], "torchao": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 72, 74], "tensor_impl": [7, 15, 68], "aqttensorimpl": [7, 15], "block_siz": [7, 13, 15, 17, 22, 23, 25, 26, 27, 28, 33, 35, 37, 39, 40, 53, 69], "tupl": [7, 15, 17, 22, 23, 25, 26, 27, 33, 35, 36, 37, 39, 40, 53, 61, 74], "int": [7, 8, 15, 17, 20, 21, 22, 23, 25, 26, 27, 28, 33, 34, 35, 36, 37, 38, 39, 40, 52, 53, 54, 61, 69, 74], "quant_min": [7, 15, 25, 26, 27, 29, 33, 35, 37, 39, 40, 53, 68, 69, 74], "union": [7, 15, 33, 37, 39, 40, 52, 53], "none": [7, 11, 15, 22, 25, 26, 27, 29, 30, 31, 32, 33, 35, 37, 39, 40, 52, 53, 56, 57, 58, 61, 65, 74], "quant_max": [7, 15, 25, 26, 27, 29, 33, 35, 37, 39, 40, 53, 68, 69, 74], "zero_point_domain": [7, 15, 25, 26, 27, 33, 35, 37, 39, 40, 53], "zeropointdomain": [7, 15, 25, 26, 27, 33, 35, 37, 39, 40, 53], "stride": [7, 15, 68, 74], "sourc": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 65, 75, 77], "tensor": [7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 50, 53, 54, 55, 58, 61, 66, 69, 70, 72, 77], "subclass": [7, 15, 32, 60, 65, 69, 70, 72], "mean": [7, 17, 29, 33, 37, 39, 53, 54, 68, 69, 72], "quantized_tensor": 7, "float_tensor": [7, 74], "scale": [7, 13, 16, 23, 26, 29, 31, 33, 35, 37, 38, 39, 40, 50, 53, 54, 56, 57, 68, 72, 74], "zero_point": [7, 13, 26, 31, 33, 35, 37, 39, 40, 53, 68, 72, 74], "happen": [7, 15, 32, 68, 74], "dure": [7, 15, 32, 33, 37, 39, 53, 57, 72, 74], "choose_qparam": [7, 68], "dequant": [7, 15, 17, 37, 68, 74], "ao": [7, 15, 72], "three": [7, 32, 61, 65, 68], "choose_qparams_affin": [7, 35, 68], "quantize_affin": [7, 39, 40, 68], "qand": 7, "dequantize_affin": [7, 39, 40], "extern": 7, "regardless": 7, "intern": [7, 20], "represent": [7, 13, 24, 33, 68, 72], "orient": 7, "field": 7, "serv": [7, 13, 74], "gener": [7, 39, 40, 68, 69, 72, 74, 75, 77], "storag": [7, 16, 68, 72], "data": [7, 8, 13, 16, 21, 35, 66, 68, 70, 72, 74], "store": [7, 16, 17, 21, 60, 68, 72], "plain": 7, "int_data": [7, 74], "format": [7, 16, 17, 54, 68, 72], "depend": [7, 32, 70, 72, 74], "kernel": [7, 9, 10, 12, 16, 20, 52, 69, 72], "granular": [7, 33, 37, 39, 53, 68], "element": [7, 19, 21, 32, 33, 37, 39, 53, 72], "share": [7, 33, 37, 39, 53, 72], "qparam": [7, 33, 37, 39, 53], "us": [7, 11, 12, 13, 16, 17, 18, 21, 23, 26, 29, 32, 33, 35, 37, 39, 53, 61, 66, 68, 69, 70, 72, 74], "per": [7, 33, 37, 39, 53, 61, 63, 68, 69, 72], "torch": [7, 16, 17, 21, 32, 33, 36, 37, 38, 39, 50, 52, 53, 55, 56, 57, 65, 68, 69, 70, 72, 74, 77], "origin": [7, 17, 39, 53, 61, 68, 69, 70, 72], "high": [7, 22, 23, 24, 25, 26, 54, 68, 72, 74], "precis": [7, 22, 23, 24, 25, 26, 54, 68, 74], "minimum": [7, 32, 33, 37, 39, 53], "valu": [7, 17, 29, 30, 31, 32, 33, 37, 39, 40, 53, 56, 61, 68, 72, 74], "specifi": [7, 39, 52, 53, 61, 65, 72], "deriv": [7, 35, 39, 53], "maximum": [7, 33, 37, 39, 53, 56], "domain": [7, 31, 33, 37, 39, 53], "integ": [7, 25, 26, 29, 31, 33, 37, 39, 50, 53, 55], "zero": [7, 19, 33, 37, 39, 53, 61, 72], "ad": [7, 33, 37, 39, 53, 61, 72, 74], "subtract": [7, 17, 33, 37, 39, 53], "unquant": [7, 33, 37, 39, 53], "default": [7, 8, 11, 18, 20, 21, 32, 33, 37, 39, 52, 53, 56, 57, 74], "float32": [7, 37, 38, 39, 53, 54, 70, 72, 74], "given": [7, 15, 28, 33, 72], "return": [7, 15, 16, 17, 32, 40, 50, 52, 55, 56, 57, 65, 68, 69, 70, 74], "classmethod": [7, 15, 74], "from_hp_to_floatx": 7, "input_float": [7, 15, 22, 23, 24, 25, 26, 27, 58], "target_dtyp": [7, 22, 23, 25, 26, 33, 35, 68], "_layout": [7, 15, 22, 23, 24, 25, 26, 27, 68, 69], "layout": [7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 65, 72], "scale_dtyp": [7, 22, 25, 33, 35], "float8": [7, 10, 11, 22, 23, 68], "from_hp_to_floatx_stat": 7, "paramet": [7, 13, 16, 17, 23, 26, 29, 32, 33, 37, 39, 50, 52, 53, 55, 56, 57, 61, 65, 68, 70, 72, 74], "from_hp_to_fpx": 7, "floatx": [7, 24, 68], "ebit": [7, 24, 34, 38, 54], "mbit": [7, 24, 34, 38, 54], "support": [7, 24, 65, 69, 70, 72, 74], "float1": [7, 24], "float7": [7, 24], "from_hp_to_intx": [7, 15], "mapping_typ": [7, 25, 33, 35], "mappingtyp": [7, 25, 33, 35], "ep": [7, 25, 33, 35], "zero_point_dtyp": [7, 25, 33, 35], "preserve_zero": [7, 25, 33, 35], "bool": [7, 25, 32, 33, 35, 36, 52, 56, 65], "plainlayout": [7, 25, 26], "use_hqq": [7, 25], "fals": [7, 25, 32, 36, 56, 61, 68, 69, 70, 74], "from_hp_to_intx_stat": 7, "kwarg": [7, 60, 61, 62, 74], "perform": [7, 20, 32, 50, 55, 56, 60, 69, 72, 74], "self": [7, 68, 69, 70, 74], "If": [7, 11, 32, 33, 50, 55, 56, 61, 68, 69, 72, 74], "correct": [7, 16], "otherwis": [7, 68], "desir": [7, 32, 39], "call": [7, 32, 39, 40, 60, 68, 69, 70, 72, 74], "non_block": 7, "memory_format": 7, "preserve_format": 7, "set": [7, 11, 32, 35, 52, 56, 61, 69, 72], "function": [7, 20, 32, 36, 52, 60, 61, 62, 65, 69, 70, 72, 74], "attempt": 7, "asynchron": 7, "respect": [7, 72], "host": 7, "possibl": [7, 72], "behavior": [7, 13], "pin": 7, "pageabl": 7, "howev": [7, 72], "caution": 7, "advis": [7, 68], "featur": [7, 74], "inform": [7, 72], "good": [7, 69, 74], "usag": [7, 32], "pin_memori": 7, "even": [7, 72], "match": [7, 37, 50, 72], "other": [7, 13, 61, 70, 72, 74, 77], "randn": [7, 69, 70, 74], "initi": [7, 68, 70], "float64": 7, "5044": 7, "0005": 7, "3310": 7, "0584": 7, "cuda0": 7, "blocksiz": 8, "64": [8, 28, 36, 70, 74], "block": [8, 17, 61, 72], "matrix": [8, 11, 50, 55, 61, 69, 72], "variabl": [8, 11, 20, 21, 61, 72], "cutlass": [9, 10], "mm_config": 11, "float8mmconfig": 11, "configur": [11, 52, 65, 68, 69], "multipl": [11, 32, 50, 55, 69, 72, 74], "involv": [11, 72], "tinygemm": [12, 52, 68, 69], "_weight_int4pack_mm_for_cpu": 12, "version": [12, 69, 74], "least": 12, "6": [12, 68, 69, 72], "It": [13, 16, 18, 20, 72, 74], "pre": [13, 16, 20, 69, 72], "process": [13, 16, 18, 20, 21, 32, 57, 68, 72, 77], "post": [13, 20, 74], "addit": [13, 18, 32, 40, 72, 74], "design": [13, 16, 19], "extend": [13, 68, 72], "conjunct": 13, "tensorimpl": 13, "custom": [13, 60, 66, 68, 69, 72, 74], "interact": [13, 68], "qqq": [14, 15, 27], "marlinqqq": 15, "inherit": [15, 18, 74], "choose_qparams_and_quantize_affine_qqq": 15, "dequantize_affine_qqq": 15, "handl": [16, 19, 20, 32, 68], "pattern": [16, 19, 68], "ensur": 16, "preprocess": [16, 19], "manag": 16, "pre_process": 16, "1\u00ba": 16, "transpos": [16, 68, 74], "sinc": [16, 60, 68, 70, 72, 74], "layer": [16, 32, 56, 57, 61, 62, 63, 72, 74], "2\u00ba": 16, "inject": 16, "3\u00ba": 16, "again": [16, 17, 72], "becaus": [16, 68, 70, 72, 74], "dim": [16, 74], "tensor_meta": 17, "subclasstensorarg": 17, "n_block": 17, "scaler_block_s": [17, 28], "quantized_scal": 17, "quantization_factor": 17, "scaler_mean": 17, "quantized_data": 17, "nf4": 17, "qlora": 17, "convert_to_norm_float_weight": 17, "normal": [17, 28, 32, 72], "dequantize_scal": 17, "unpack": [17, 54, 68], "doubl": 17, "scaler": 17, "int8": [17, 52, 63, 65, 68, 74], "per_scaler_block": 17, "factor": [17, 50, 57, 72], "inpt_weight": 17, "double_quantize_scal": 17, "achiev": [17, 72, 74], "calcul": [17, 29, 33, 35, 56, 68, 72], "absmax": 17, "find": [17, 72], "posit": 17, "typic": [17, 18, 33, 68, 70], "per_block": 17, "int16": 17, "n_scaler_block": 17, "get_original_weight": 17, "quantize_tensor_nearest": 17, "float16": [17, 36, 39, 53, 72], "nearest": 17, "round": [17, 29, 33, 74], "up": [17, 52, 68, 69, 72], "most": [18, 68, 72], "doe": [18, 68, 72, 74], "metadata": [18, 68, 74], "step": [18, 32, 68, 72], "requir": [18, 20, 33, 68, 72, 74], "semi": [19, 65, 72], "structur": [19, 65, 69, 70, 72, 74], "matric": [19, 72], "where": [19, 29, 35, 54, 68, 72], "everi": [19, 60, 72, 74], "four": 19, "prune": [19, 61], "conform": 19, "inner_k_til": [20, 69], "8": [20, 21, 29, 33, 68, 69], "core": [20, 30, 68], "tile": [20, 68], "fit": [20, 68, 70], "effici": [20, 69, 72], "affect": [20, 72], "matmul": [20, 68, 72, 74], "pack_dim": 21, "uintx": [21, 68], "smaller": [21, 69, 70], "bit": [21, 28, 54, 74], "width": 21, "than": [21, 68, 72, 74], "standard": [21, 68], "byte": 21, "uintxtensor": 21, "determin": [21, 33, 39, 72], "along": [21, 72], "indic": [21, 31, 33, 72], "last": 21, "256": 28, "name": [29, 30, 31, 52, 57, 61, 65, 72, 74], "qualnam": [29, 30, 31], "boundari": [29, 30, 31], "number": [29, 32, 54, 61, 72, 74], "map": [29, 33, 68, 74], "symmetr": [29, 33, 63, 74], "rang": [29, 72], "sai": [29, 53, 68], "3": [29, 32, 33, 53, 68, 69, 72, 77], "5": [29, 57, 61, 69, 72, 77], "7": [29, 33], "symmetric_no_clipping_err": 29, "variant": [29, 35, 74], "smin": 29, "smax": 29, "min_val_neg": [29, 74], "max_val_po": [29, 74], "By": [29, 72], "individu": [29, 72], "less": [29, 33, 72, 74], "error": [29, 32, 74], "neg": 29, "asymmetr": [29, 33, 68, 69], "directli": [29, 35, 68, 72, 74], "placehold": 30, "yet": [30, 74], "enum": 31, "whether": [31, 32, 33, 74], "quantized_v": 31, "float_val": 31, "mid_point": 31, "example_input": [32, 69, 70], "qtensor_class_list": 32, "aqdefaultlinearweight": 32, "aqint8weightonlyquantizedlinearweight": 32, "aqint8weightonlyquantizedlinearweight2": 32, "aqint8dynamicallyquantizedlinearweight": 32, "filter_fn": [32, 52, 65], "interpol": 32, "85": 32, "manual": 32, "set_inductor_config": 32, "supress_autoquant_error": 32, "min_sqnr": 32, "aq_kwarg": 32, "autoquant": 32, "identifi": 32, "fastest": 32, "over": [32, 72], "potenti": [32, 72], "qtensor": 32, "prepar": [32, 56, 61, 68, 72], "search": [32, 72], "whose": 32, "exchang": 32, "autoquantizablelinearweight": 32, "calibr": [32, 35], "user": [32, 68, 69, 72, 74, 77], "seen": 32, "record": [32, 68], "so": [32, 68, 69, 70, 72, 74], "final": [32, 40, 52, 68, 69, 72], "benchmark": [32, 56], "member": 32, "pick": 32, "result": [32, 50, 54, 55, 68, 72], "highli": 32, "complet": 32, "simpli": [32, 72, 74], "had": [32, 74], "compil": [32, 52, 55, 68, 69, 74], "them": [32, 60, 68], "onc": [32, 72], "proce": 32, "combin": [32, 72, 74], "finalize_autoqu": 32, "been": [32, 74], "log": [32, 74], "nn": [32, 52, 56, 57, 65, 68, 69, 70, 72, 74], "forward": [32, 60, 68, 69, 70, 72, 74], "pass": [32, 35, 60, 68, 74], "fulli": [32, 52, 57, 65, 72], "unless": 32, "list": [32, 37, 57, 61, 68, 69, 74], "default_autoquant_class_list": 32, "callabl": [32, 36, 52, 58, 65], "contain": [32, 56, 57, 72, 74], "second": [32, 50, 68, 77], "stop": 32, "wait": [32, 68], "sever": 32, "automat": [32, 74, 77], "config": [32, 52, 61, 65, 72], "suppress": 32, "accept": 32, "signal": 32, "nois": 32, "ration": 32, "wikipedia": 32, "org": [32, 61, 68, 69, 72], "wiki": 32, "noise_ratio": 32, "v": 32, "non": [32, 68, 72, 74], "impact": 32, "caus": 32, "too": 32, "larg": [32, 74], "numer": [32, 72], "resaon": 32, "40": 32, "adjust": 32, "keyword": 32, "example_input1": 32, "example_input2": 32, "fp32": [33, 37, 74], "bf16": [33, 68, 69, 72], "fp16": 33, "optioanl": 33, "flag": 33, "exactli": [33, 74], "pad": 33, "convolut": 33, "doesn": [33, 72], "t": [33, 61, 68, 69, 72, 74], "itself": [33, 72, 74], "sure": [33, 68], "correspond": [33, 52, 68, 70, 72, 74], "without": [33, 39, 40, 68, 72], "loss": [33, 72], "But": [33, 68, 74], "won": [33, 74], "gurante": 33, "don": [33, 61, 69, 72], "clamp": [33, 74], "request": [33, 37, 53], "min_val": [35, 68, 74], "max_val": [35, 68, 74], "instead": [35, 60, 68, 69, 72, 74], "observ": [35, 60, 72], "obtain": 35, "track": [35, 68], "param": [35, 40, 61], "nbit": 36, "group_siz": [36, 52, 69], "axi": [36, 53], "compute_dtyp": 36, "str": [36, 52, 57, 58, 61, 65, 74], "verbos": 36, "raw_output": 36, "optimize_weight": 36, "optimize_weights_proximal_legaci": 36, "input_dtyp": 37, "output_dtyp": [37, 38, 53], "uint8": [37, 53, 68], "quant_dtyp": [39, 40], "fake": [39, 40], "awar": [39, 40, 61, 72, 74], "equival": [39, 40, 57, 72], "cast": [39, 40], "valid": 39, "fake_quantize_affin": 40, "consum": 40, "outlier": 40, "mask": [40, 61, 72], "intermedi": 40, "alia": [41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 59, 64], "float8dynamicactivationfloat8weightconfig": 41, "float8staticactivationfloat8weightconfig": 42, "float8weightonlyconfig": 43, "fpxweightonlyconfig": 44, "gemliteuintxweightonlyconfig": 45, "int4weightonlyconfig": 46, "int8dynamicactivationint4weightconfig": 47, "int8dynamicactivationint8weightconfig": 48, "int8weightonlyconfig": 49, "b": 50, "scales1": 50, "multipli": [50, 55, 72], "row": [50, 72], "rais": [50, 55, 74], "assertionerror": [50, 55, 74], "expect": [50, 72, 74], "intxquantizationawaretrainingconfig": 51, "aobaseconfig": [52, 65], "inplac": [52, 61, 69], "workflow": [52, 65, 69, 72], "instanc": [52, 60, 65, 70, 74], "qualifi": [52, 57, 65, 72], "move": [52, 68], "speed": [52, 72], "predefin": 52, "execut": [52, 71, 74, 76], "path": [52, 55, 69], "customiz": 52, "current": [52, 57, 61, 65, 72, 74], "int8_dynamic_activation_int4_weight": 52, "int8_dynamic_activation_int8_weight": [52, 65], "mm": [52, 74], "int4_weight_onli": [52, 68, 69, 70], "int8_weight_onli": 52, "sequenti": [52, 65], "32": [52, 65, 69, 70, 74], "1024": [52, 65, 69, 70], "tabl": [53, 68, 72], "per_tensor": 53, "per_axi": 53, "per_group": 53, "groupsiz": 53, "low": [54, 72, 74], "00seeemm": 54, "fp6_e3m2": 54, "sign": 54, "expon": 54, "mantissa": 54, "mat2": 55, "safe": 55, "consid": [55, 68, 72], "cubla": 55, "fallback": 55, "i": [55, 72], "j": 55, "debug_skip_calibr": 56, "smoothquant": [56, 57], "smoothfakedynamicallyquantizedlinear": [56, 57], "debug": 56, "skip_fqn_list": 57, "cur_fqn": 57, "alpha": 57, "replac": [57, 72], "skip": [57, 61, 72], "being": [57, 68, 72], "input_quant_func": [58, 68], "quant_kwarg": 58, "dict": [58, 61, 74], "uintxweightonlyconfig": 59, "l2": [60, 72], "norm": [60, 61, 72], "channel": [60, 63], "buffer": 60, "x_orig": 60, "overridden": 60, "although": [60, 74], "recip": 60, "within": [60, 72], "afterward": 60, "former": 60, "care": [60, 70, 72], "hook": [60, 68], "while": [60, 61, 72, 74], "latter": 60, "silent": 60, "ignor": 60, "sparsity_level": [61, 72], "semi_structured_block_s": 61, "wanda": 61, "sparsifi": [61, 66, 70, 72], "propos": 61, "arxiv": [61, 72], "ab": [61, 72], "2306": 61, "11695": 61, "product": 61, "magnitud": [61, 72], "control": [61, 72], "parametr": 61, "preserv": [61, 72], "deepcopi": [61, 69, 74], "squash_mask": [61, 72], "params_to_keep": 61, "params_to_keep_per_lay": 61, "squash": 61, "appropri": [61, 68], "sparse_param": 61, "attach": [61, 72], "kei": [61, 72, 77], "save": [61, 69, 70], "fqn": [61, 65], "string": 61, "xdoctest": 61, "local": [61, 72], "undefin": 61, "hasattr": 61, "submodule1": 61, "linear1": [61, 69, 70, 74], "foo": 61, "bar": 61, "submodule2": 61, "linear42": 61, "baz": 61, "print": [61, 69, 70, 74, 77], "42": 61, "24": 61, "ones": [61, 68], "update_mask": 61, "tensor_nam": 61, "statist": [61, 68, 72], "retriev": 61, "act_per_input": 61, "Then": [61, 74], "metric": 61, "across": [61, 72, 74], "whole": 61, "simul": [62, 68, 72], "dnynam": 63, "token": 63, "semisparseweightconfig": 64, "sparsify_": 65, "apply_tensor_subclass": [65, 68], "essenti": 65, "semi_sparse_weight": 65, "semisparselayout": 65, "sparsemarlinlayout": 65, "def": [65, 68, 69, 70, 74], "isinst": [65, 72, 74], "sparse_api": 65, "librari": [66, 70], "gradient": [66, 72], "nativ": [66, 74], "readm": [66, 69, 72], "overal": [66, 69], "introduct": [66, 68], "recent": 66, "highlight": [66, 74, 77], "updat": [66, 69, 70, 72], "guid": [66, 68], "contributor": [66, 69], "serial": [66, 68], "write": 66, "advanc": [66, 74], "lai": 68, "stack": 68, "hqq": 68, "awq": 68, "gptq": 68, "codebookquantizedtensor": 68, "uint1": 68, "uint7": 68, "int1": 68, "float3": 68, "compon": [68, 74], "tensorcoretiledlayout": [68, 69], "compos": [68, 72, 74], "overload": [68, 72], "term": [68, 72], "extra": 68, "empti": 68, "dev": 68, "discuss": [68, 74], "1833": 68, "No": [68, 70, 72], "matter": [68, 72], "end": [68, 72, 74, 77], "avail": 68, "later": [68, 74], "float3_e2_m0": 68, "float4_e2_m1": 68, "float4_e3_m0": 68, "float5_e2_m2": 68, "float5_e3_m1": 68, "float6_e2_m3": 68, "float6_e3_m2": 68, "float8_e4m3fn": 68, "float8_e5m2": 68, "float8_e4m3fnuz": 68, "float8_e5m2fnuz": 68, "plan": 68, "float4": 68, "float6": 68, "thei": [68, 72, 74], "becom": 68, "popular": 68, "hardwar": [68, 72], "part": [68, 72, 74], "uint2": 68, "117208": 68, "outsid": 68, "As": 68, "mention": 68, "criteria": 68, "wide": 68, "adopt": 68, "fundament": [68, 72], "until": 68, "evid": 68, "hopefulli": 68, "amen": 68, "haven": 68, "enough": 68, "ont": 68, "revisit": 68, "intx": 68, "connect": 68, "int4tensor": 68, "previou": 68, "between": [68, 72, 74], "preicison": 68, "mainli": 68, "There": [68, 74], "accommod": 68, "choose_qparams_affine_with_min_max": 68, "min": [68, 74], "_weight_int4pack_mm": 68, "int_matmul": 68, "int32": [68, 69], "int_scaled_matmul": 68, "reli": [68, 72, 74], "triton": 68, "On": [68, 69], "top": [68, 74], "glue": 68, "everyth": 68, "togeth": 68, "build": [68, 72, 74], "construct": 68, "low_precision_v": 68, "high_precision_v": 68, "procedur": 68, "veri": [68, 72], "common": [68, 72], "straightforward": 68, "try": [68, 72, 74], "higher": [68, 74], "lower": [68, 72], "high_preicsion_v": 68, "especi": [68, 70, 72], "bitwidth": 68, "codebook": 68, "hardcod": 68, "select": 68, "multi": 68, "dimension": [68, 72], "view": [68, 74], "mkldnn": 68, "coo": [68, 72], "sparse_coo": [68, 72], "sparsetensorimpl": 68, "idea": [68, 72], "nice": [68, 72], "concept": [68, 77], "why": [68, 74, 77], "c": [68, 74], "conflict": 68, "properti": 68, "quantized_linear": 68, "semant": 68, "stai": [68, 69, 74], "develop": 68, "tradition": 68, "come": [68, 72, 73], "demonstr": [68, 69, 74], "purpos": [68, 74], "to_affine_quant": 68, "simplic": 68, "explain": 68, "simplest": [68, 72], "form": [68, 72], "easi": 68, "linear_modul": 68, "to_affine_quantized_intx": 68, "requires_grad": [68, 74], "runtim": 68, "to_linear_activation_quant": 68, "quantized_weight": 68, "activation_and_weight_quant": 68, "encount": 68, "f": [68, 70, 72, 74], "input_qunat_func": 68, "redispatch": 68, "swap": [68, 72], "fx": 68, "symbolic_trac": 68, "prefer": [68, 69, 74], "easier": 68, "further": [68, 74], "modif": 68, "sampl": 68, "figur": [68, 72], "At": [68, 72], "collect": [68, 72], "thing": [68, 70, 72, 74], "address": 68, "stat": 68, "averag": 68, "calculate_qparam": 68, "affinequantizedminmaxobserv": 68, "insert_observer_": 68, "altern": [68, 74], "observedlinear": 68, "dataset": 68, "complic": [68, 72], "next": 68, "done": [68, 74], "manner": 68, "intend": 68, "autoround": 68, "multitensor": 68, "describ": [68, 70, 72, 77], "focus": [68, 72], "todai": 68, "low_bit_optim": 68, "similar": [68, 72], "quantized_train": 68, "enabl": 68, "progress": 68, "lot": [68, 72], "includ": [68, 74], "walk": [68, 74, 77], "_convert_weight_to_int4pack": 68, "aten": [68, 74], "group": [68, 69], "tensor_core_til": 68, "tensorcoretiledaqttensorimpl": 68, "_quantized_linear_op": 68, "goe": 68, "_aqt_qlinear_dispatch_t": 68, "dispatch": 68, "explan": 68, "wint4": 68, "explor": 69, "instal": 69, "latest": 69, "stabl": 69, "releas": 69, "pip": 69, "nightli": 69, "command": 69, "index": [69, 72], "url": 69, "download": [69, 75, 77], "whl": 69, "cu121": 69, "major": 69, "instruct": 69, "entri": 69, "mutat": 69, "insert": 69, "logic": [69, 74], "toi": [69, 74], "toylinearmodel": [69, 70], "__init__": [69, 70, 74], "super": [69, 70, 74], "linear2": [69, 70, 74], "x": [69, 70, 74, 77], "eval": [69, 70], "faster": [69, 72], "model_bf16": 69, "leverag": [69, 74], "int4mm": 69, "mix": 69, "readi": [69, 74], "in_featur": [69, 70, 74], "out_featur": [69, 74], "tensor_impl_dtyp": 69, "15": 69, "verifi": [69, 70, 74], "roughli": [69, 72], "quarter": 69, "os": 69, "tmp": 69, "int4_model": 69, "pt": 69, "bfloat16_model": 69, "int4_model_size_mb": 69, "getsiz": 69, "bfloat16_model_size_mb": 69, "2f": 69, "mb": [69, 70, 71, 76], "25": 69, "00": [69, 71, 76], "much": [69, 72], "torch_version_at_least_2_5": 69, "benchmark_model": 69, "temporari": 69, "workaround": 69, "num_run": 69, "100": [69, 74], "_dynamo": [69, 74], "reset": 69, "bf16_time": 69, "int4_tim": 69, "time": [69, 72, 74, 77], "3f": 69, "ms": 69, "1fx": 69, "a100": 69, "gpu": [69, 77], "80gb": 69, "30": 69, "393": 69, "410": 69, "9x": 69, "simpl": [69, 72, 74], "visit": 69, "would": [69, 72, 74], "forget": 69, "tempfil": 70, "get_model_size_in_byt": 70, "batch_siz": 70, "ref": 70, "namedtemporaryfil": 70, "state_dict": 70, "seek": [70, 72], "load": 70, "meta": 70, "m_load": 70, "load_state_dict": 70, "assign": 70, "re": [70, 74], "assert": [70, 74], "equal": [70, 72], "float_weight1": 70, "float_weight2": 70, "quantized_weight1": 70, "quantized_weight2": 70, "go": [70, 74, 77], "techinqu": 70, "reduct": [70, 72, 74], "around": 70, "4x": 70, "0625": 70, "reason": [70, 72], "avoid": [70, 72], "properli": 70, "003": [71, 76, 77], "total": [71, 76, 77], "galleri": [71, 75, 77], "mem": [71, 76], "templat": [71, 75, 76], "tutorials_sourc": 71, "template_tutori": [71, 76, 77], "neural": 72, "network": [72, 74], "reduc": 72, "its": [72, 74], "overhead": 72, "latenc": 72, "carefulli": 72, "signific": 72, "pai": 72, "price": 72, "qualiti": 72, "accuraci": 72, "f1": 72, "problem": [72, 74], "research": [72, 77], "face": 72, "fragment": 72, "rightfulli": 72, "spent": 72, "compress": 72, "place": 72, "dens": 72, "solv": [72, 74], "focu": [72, 74], "realli": 72, "push": 72, "accur": 72, "concret": 72, "hope": 72, "modular": 72, "acceler": 72, "scratch": [72, 77], "minim": 72, "recov": 72, "algorthim": 72, "realiz": 72, "improv": 72, "trade": 72, "off": 72, "degrad": 72, "architectur": 72, "theoret": 72, "gain": 72, "2x": 72, "analog": 72, "fix": 72, "50": 72, "unstructur": 72, "One": [72, 74], "chosen": 72, "close": 72, "relat": 72, "mitig": 72, "retrain": 72, "neglig": 72, "area": 72, "agre": 72, "upon": 72, "consensu": 72, "mind": 72, "thought": 72, "separ": 72, "subproblem": 72, "satisfi": 72, "consist": [72, 74], "answer": 72, "independ": 72, "frontend": 72, "arbitrari": 72, "backend": 72, "handoff": 72, "piec": 72, "miss": 72, "natur": [72, 74], "present": 72, "clear": 72, "contract": 72, "7x": 72, "advantag": 72, "fast": 72, "anticip": 72, "mani": [72, 74], "solut": 72, "third": 72, "parti": 72, "to_sparse_semi_structur": 72, "sparsesemistructuredtensor": 72, "weightnormsparsifi": 72, "half": 72, "subnetwork": 72, "sparse_config": 72, "mod": [72, 74], "named_modul": 72, "append": 72, "tensor_fqn": 72, "sparse_block_shap": 72, "zeros_per_block": 72, "fakespars": 72, "flow": 72, "manipul": 72, "dictionari": 72, "paramer": 72, "parameter": 72, "necessari": [72, 74], "ve": 72, "suitabl": 72, "fuse": [72, 74], "0s": 72, "spot": 72, "definit": 72, "academia": 72, "industri": 72, "often": [72, 74], "interchang": 72, "confus": 72, "distinct": 72, "pretrain": 72, "behind": 72, "box": 72, "those": [72, 74], "loos": 72, "speak": 72, "tightli": 72, "coupl": [72, 74], "nvidia": 72, "csc": 72, "fbgemm": 72, "qnnpack": 72, "descript": 72, "coordin": 72, "vector": 72, "locat": 72, "bsr": 72, "sparse_bsr": 72, "except": [72, 74], "scalar": 72, "csr": 72, "sparse_csr": 72, "sparse_csc": 72, "column": 72, "compact": 72, "sparse_matrix": 72, "1d": 72, "indexptr": 72, "\u00bd": 72, "bitmask": 72, "2bit": 72, "unprun": 72, "quit": [72, 74], "must": 72, "successfulli": 72, "These": [72, 74], "broken": 72, "down": 72, "Not": 72, "sensit": 72, "effect": [72, 74], "best": 72, "subsequ": [72, 74], "infinit": 72, "lost": 72, "degre": 72, "analysi": 72, "drop": 72, "give": [72, 74], "curv": 72, "proxi": 72, "aforement": 72, "smallest": 72, "absolut": 72, "vs": 72, "global": [72, 74], "scope": 72, "impli": 72, "pro": 72, "con": 72, "sub": 72, "tradeoff": 72, "span": 72, "threshold": 72, "increas": 72, "complex": 72, "constant": [72, 74], "ctr_mobile_fe": 72, "paper": [72, 77], "score": 72, "w": 72, "tenosr": 72, "udpat": 72, "cannot": 72, "histori": 72, "regrow": 72, "dw": 72, "via": 72, "backprop": 72, "pat": 72, "unmask": 72, "resid": 72, "backward": 72, "salienc": 72, "lowest": 72, "l1": 72, "commonli": 72, "shown": 72, "abl": [72, 74], "ident": 72, "repeat": 72, "loop": 72, "shot": 72, "movement": 72, "tune": 72, "2005": 72, "07683": 72, "rank": [72, 74], "wx": 72, "sqx": 72, "q": 72, "usual": 72, "sort": 72, "wise": 72, "reconstruct": 72, "random": 72, "randomli": 72, "tri": 72, "remedi": 72, "line": 72, "item": [72, 77], "ultim": 72, "literatur": 72, "vision": 72, "nlp": [72, 77], "iter": 72, "ctr_feed": 72, "na": 72, "multimask": 72, "pyspeech": 72, "fastna": 72, "approach": [72, 74], "knowledg": [72, 77], "distil": 72, "pdf": 72, "2204": 72, "09656": 72, "arrang": 72, "recal": 72, "counterpart": 72, "slower": 72, "suffici": 72, "flexibl": [72, 74], "98": 72, "benefit": [72, 74], "special": 72, "exhibit": 72, "maintain": 72, "penalti": 72, "expens": [72, 74], "dictat": 72, "characterist": 72, "highest": 72, "wouldn": [72, 74], "visual": 72, "fig": 72, "4x4": 72, "benchmak": 72, "soon": 73, "foundat": 74, "extens": 74, "autograd": 74, "distribut": 74, "express": 74, "interpos": 74, "namespac": 74, "continu": 74, "seamlessli": 74, "obviou": 74, "int8quantizedlinear": 74, "few": 74, "finer": 74, "grain": 74, "intercept": 74, "slightli": 74, "contrast": 74, "long": 74, "better": 74, "clunki": 74, "distributedlinear": 74, "duplic": 74, "bypass": 74, "offer": 74, "outer": 74, "inner": 74, "allgath": 74, "bandwidth": 74, "rest": 74, "read": 74, "document": 74, "zoo": 74, "podcast": 74, "edward": 74, "yang": 74, "begin": 74, "int8_symmetric_quant": 74, "fp32_tensor": 74, "128": 74, "127": 74, "amin": 74, "keepdim": 74, "amax": 74, "zeros_lik": 74, "quantizedlinear": 74, "w_int8": 74, "cl": 74, "new_linear": 74, "left": 74, "toymodel": 74, "float_model": 74, "quantized_model": 74, "child": 74, "named_children": 74, "setattr": 74, "drawback": 74, "suppos": 74, "clean": 74, "limit": 74, "eleg": 74, "pretti": 74, "power": 74, "overrid": 74, "almost": 74, "shard": 74, "ragged": 74, "rag": 74, "nestedtensor": 74, "resourc": 74, "who": 74, "link": [74, 77], "googl": 74, "collab": 74, "flopcount": 74, "memorytrack": 74, "With": 74, "bare": 74, "bone": 74, "int8symmetrictensor": 74, "hold": 74, "staticmethod": 74, "disabl": 74, "__new__": 74, "_make_wrapper_subclass": 74, "storage_offset": 74, "ndim": 74, "__tensor_flatten__": 74, "attribut": 74, "pt2": 74, "__tensor_unflatten__": 74, "tensor_data_dict": 74, "extra_metadata": 74, "outer_s": 74, "outer_strid": 74, "undo": 74, "back": 74, "__repr__": 74, "repr": 74, "ahead": 74, "insid": 74, "int8_tensor": 74, "func": 74, "op_implementations_dict": 74, "conveni": 74, "register_op": 74, "_op": 74, "opoverload": 74, "impl_decor": 74, "op_impl": 74, "wrapper": 74, "particular": 74, "largest": 74, "tell": 74, "desugar": 74, "decor": 74, "constructor": 74, "surfac": 74, "coverag": 74, "though": 74, "brute": 74, "forc": 74, "repeatedli": 74, "loggingtensor": 74, "_python_dispatch": 74, "return_and_correct_alias": 74, "int8_mm": 74, "detach": 74, "int8_view_op": 74, "out_data": 74, "out_scal": 74, "notic": 74, "quickli": 74, "hit": 74, "background": 74, "decomposit": 74, "live": 74, "decomp": 74, "shrink": 74, "author": [74, 77], "pain": 74, "rather": 74, "underli": 74, "worth": 74, "written": 74, "differenti": 74, "nuanc": 74, "longer": 74, "That": 74, "transposit": 74, "got": 74, "propag": 74, "fact": 74, "themselv": 74, "pointwis": 74, "alwai": 74, "were": 74, "might": 74, "unwrap": 74, "dim0": 74, "dim1": 74, "confirm": 74, "quantized_model_module_swap": 74, "quantized_model_subclass": 74, "subclass_param": 74, "no_grad": 74, "out_module_swap": 74, "allclos": 74, "out_compil": 74, "seri": 74, "wa": 74, "tutorials_python": 75, "zip": [75, 77], "jupyt": [75, 77], "notebook": [75, 77], "tutorials_jupyt": 75, "sphinx": [75, 77], "firstnam": 77, "lastnam": 77, "prerequisit": 77, "v2": 77, "topic": 77, "rand": 77, "9488": 77, "0164": 77, "8921": 77, "6703": 77, "2905": 77, "3592": 77, "1109": 77, "3772": 77, "3536": 77, "3154": 77, "5228": 77, "4557": 77, "4044": 77, "9500": 77, "8541": 77, "practic": 77, "test": 77, "summar": 77, "takeawai": 77, "link1": 77, "link2": 77, "minut": 77, "ipynb": 77}, "objects": {"torchao.dtypes": [[7, 0, 1, "", "AffineQuantizedTensor"], [8, 0, 1, "", "BlockSparseLayout"], [9, 0, 1, "", "CutlassInt4PackedLayout"], [10, 0, 1, "", "CutlassSemiSparseLayout"], [11, 0, 1, "", "Float8Layout"], [12, 0, 1, "", "Int4CPULayout"], [13, 0, 1, "", "Layout"], [14, 0, 1, "", "MarlinQQQLayout"], [15, 0, 1, "", "MarlinQQQTensor"], [16, 0, 1, "", "MarlinSparseLayout"], [17, 0, 1, "", "NF4Tensor"], [18, 0, 1, "", "PlainLayout"], [19, 0, 1, "", "SemiSparseLayout"], [20, 0, 1, "", "TensorCoreTiledLayout"], [21, 0, 1, "", "UintxLayout"], [22, 2, 1, "", "to_affine_quantized_floatx"], [23, 2, 1, "", "to_affine_quantized_floatx_static"], [24, 2, 1, "", "to_affine_quantized_fpx"], [25, 2, 1, "", "to_affine_quantized_intx"], [26, 2, 1, "", "to_affine_quantized_intx_static"], [27, 2, 1, "", "to_marlinqqq_quantized_intx"], [28, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[7, 1, 1, "", "dequantize"], [7, 1, 1, "", "from_hp_to_floatx"], [7, 1, 1, "", "from_hp_to_floatx_static"], [7, 1, 1, "", "from_hp_to_fpx"], [7, 1, 1, "", "from_hp_to_intx"], [7, 1, 1, "", "from_hp_to_intx_static"], [7, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[15, 1, 1, "", "dequantize"], [15, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[16, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[17, 1, 1, "", "convert_to_norm_float_weight"], [17, 1, 1, "", "dequantize"], [17, 1, 1, "", "dequantize_scalers"], [17, 1, 1, "", "double_quantize_scalers"], [17, 1, 1, "", "get_original_weight"], [17, 1, 1, "", "quantize_tensor_nearest"]], "torchao.quantization": [[29, 0, 1, "", "MappingType"], [30, 0, 1, "", "TorchAODType"], [31, 0, 1, "", "ZeroPointDomain"], [32, 2, 1, "", "autoquant"], [33, 2, 1, "", "choose_qparams_affine"], [34, 2, 1, "", "choose_qparams_affine_floatx"], [35, 2, 1, "", "choose_qparams_affine_with_min_max"], [36, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [37, 2, 1, "", "dequantize_affine"], [38, 2, 1, "", "dequantize_affine_floatx"], [39, 2, 1, "", "fake_quantize_affine"], [40, 2, 1, "", "fake_quantize_affine_cachemask"], [41, 3, 1, "", "float8_dynamic_activation_float8_weight"], [42, 3, 1, "", "float8_static_activation_float8_weight"], [43, 3, 1, "", "float8_weight_only"], [44, 3, 1, "", "fpx_weight_only"], [45, 3, 1, "", "gemlite_uintx_weight_only"], [46, 3, 1, "", "int4_weight_only"], [47, 3, 1, "", "int8_dynamic_activation_int4_weight"], [48, 3, 1, "", "int8_dynamic_activation_int8_weight"], [49, 3, 1, "", "int8_weight_only"], [50, 2, 1, "", "int_scaled_matmul"], [51, 3, 1, "", "intx_quantization_aware_training"], [52, 2, 1, "", "quantize_"], [53, 2, 1, "", "quantize_affine"], [54, 2, 1, "", "quantize_affine_floatx"], [55, 2, 1, "", "safe_int_mm"], [56, 2, 1, "", "smooth_fq_linear_to_inference"], [57, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [58, 2, 1, "", "to_linear_activation_quantized"], [59, 3, 1, "", "uintx_weight_only"]], "torchao": [[4, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[60, 0, 1, "", "PerChannelNormObserver"], [61, 0, 1, "", "WandaSparsifier"], [62, 2, 1, "", "apply_fake_sparsity"], [63, 2, 1, "", "int8_dynamic_activation_int8_semi_sparse_weight"], [64, 3, 1, "", "semi_sparse_weight"], [65, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[60, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[61, 1, 1, "", "prepare"], [61, 1, 1, "", "squash_mask"], [61, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:attribute", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 66, 68], "dtype": [0, 6, 68], "layout": [0, 5, 13, 68], "tensor": [0, 5, 68, 73, 74], "subclass": [0, 5, 68, 74], "quantiz": [0, 3, 52, 68, 69, 73, 74], "techniqu": 0, "api": [1, 3, 66], "refer": [1, 66], "python": 1, "kernel": [2, 5, 67, 68], "main": 3, "quantize_": 3, "primit": [3, 68], "other": [3, 5, 68], "sparsiti": [4, 72], "contributor": 5, "guid": [5, 69], "gener": 5, "extend": 5, "ad": [5, 68], "effici": [5, 68], "custom": 5, "triton": 5, "hand": 5, "written": 5, "dispatch": 5, "tensorimpl": [5, 68], "flow": [5, 68, 70], "us": 5, "torch": 5, "compil": 5, "perform": [5, 67], "serial": [5, 70], "featur": 5, "support": [5, 68], "function": [5, 68], "compos": 5, "test": 5, "microbenchmark": 5, "model": [5, 68, 70], "benchmark": 5, "eval": 5, "affinequantizedtensor": 7, "blocksparselayout": 8, "cutlassint4packedlayout": 9, "cutlasssemisparselayout": 10, "float8layout": 11, "int4cpulayout": 12, "marlinqqqlayout": 14, "marlinqqqtensor": 15, "marlinsparselayout": 16, "nf4tensor": 17, "plainlayout": 18, "semisparselayout": 19, "tensorcoretiledlayout": 20, "uintxlayout": 21, "to_affine_quantized_floatx": 22, "to_affine_quantized_floatx_stat": 23, "to_affine_quantized_fpx": 24, "to_affine_quantized_intx": 25, "to_affine_quantized_intx_stat": 26, "to_marlinqqq_quantized_intx": 27, "to_nf4": 28, "mappingtyp": 29, "torchaodtyp": 30, "zeropointdomain": 31, "autoqu": 32, "choose_qparams_affin": 33, "choose_qparams_affine_floatx": 34, "choose_qparams_affine_with_min_max": 35, "choose_qparams_and_quantize_affine_hqq": 36, "dequantize_affin": 37, "dequantize_affine_floatx": 38, "fake_quantize_affin": 39, "fake_quantize_affine_cachemask": 40, "float8_dynamic_activation_float8_weight": 41, "float8_static_activation_float8_weight": 42, "float8_weight_onli": 43, "fpx_weight_onli": 44, "gemlite_uintx_weight_onli": 45, "int4_weight_onli": 46, "int8_dynamic_activation_int4_weight": 47, "int8_dynamic_activation_int8_weight": 48, "int8_weight_onli": 49, "int_scaled_matmul": 50, "intx_quantization_aware_train": 51, "quantize_affin": 53, "quantize_affine_floatx": 54, "safe_int_mm": 55, "smooth_fq_linear_to_infer": 56, "swap_linear_with_smooth_fq_linear": 57, "to_linear_activation_quant": 58, "uintx_weight_onli": 59, "perchannelnormobserv": 60, "wandasparsifi": 61, "apply_fake_spars": 62, "int8_dynamic_activation_int8_semi_sparse_weight": 63, "semi_sparse_weight": 64, "sparsifi": 65, "welcom": 66, "document": 66, "get": 66, "start": [66, 69], "develop": 66, "note": 66, "tutori": [66, 77], "overview": [68, 72, 77], "basic": 68, "current": 68, "placehold": 68, "pytorch": 68, "implement": [68, 74], "oper": [68, 74], "integr": 68, "nativ": 68, "factori": 68, "op": 68, "deriv": 68, "algorithm": 68, "weight": 68, "onli": 68, "dynam": 68, "activ": 68, "static": 68, "insert": 68, "observ": 68, "how": 68, "defin": 68, "modul": [68, 74], "add": 68, "calibr": 68, "train": 68, "awar": 68, "low": 68, "bit": 68, "optim": [68, 70], "case": 68, "studi": 68, "int4": 68, "work": 68, "dure": 68, "execut": 68, "save": 68, "load": 68, "quick": 69, "first": 69, "exampl": 69, "next": [69, 74], "step": [69, 74, 77], "deseri": 70, "what": [70, 74], "happen": 70, "when": 70, "an": 70, "comput": [71, 76], "time": [71, 76], "goal": 72, "design": 72, "context": 72, "prune": 72, "configur": 72, "criteria": 72, "strategi": 72, "pattern": 72, "write": [73, 74], "your": [73, 74], "own": [73, 74], "advanc": 73, "ar": 74, "swap": 74, "which": 74, "should": 74, "we": 74, "compar": 74, "output": 74, "templat": 77, "option": 77, "addit": 77, "exercis": 77, "conclus": 77, "further": 77, "read": 77}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})