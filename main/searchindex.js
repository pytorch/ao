Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.quantization.FPXWeightOnlyConfig", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.UIntXWeightOnlyConfig", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfig", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "pretraining", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.quantization.FPXWeightOnlyConfig.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8StaticActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.GemliteUIntXWeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.UIntXWeightOnlyConfig.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "FPXWeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8StaticActivationFloat8WeightConfig", "Float8WeightOnlyConfig", "GemliteUIntXWeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "UIntXWeightOnlyConfig", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfig", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "initialize_fake_quantizers", "quantize", "quantize_affine", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Pretraining with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 6, 8, 17, 18, 19, 20, 22, 35, 36, 40, 41, 42, 45, 49, 50, 51, 52, 55, 56, 62, 63, 68, 69, 70, 72, 75, 76, 77, 78, 80, 81, 83, 84, 87, 88, 89, 90, 91, 92, 93], "section": [2, 6, 76, 80, 84, 89, 90, 93], "introduc": [2, 88, 89, 91, 92, 93], "dive": 2, "detail": [2, 6, 36, 49, 75, 76, 77, 80, 81, 83, 88, 89, 90, 91], "how": [2, 6, 8, 14, 22, 41, 45, 50, 55, 56, 63, 73, 75, 77, 78, 80, 81, 83, 84, 88, 91, 92], "integr": [2, 6, 73, 75, 78, 80, 83, 91, 93], "pytorch": [2, 6, 8, 13, 16, 46, 55, 73, 75, 80, 83, 84, 87], "optim": [2, 6, 17, 35, 49, 62, 73, 75, 80, 83, 88, 90, 91, 92], "your": [2, 6, 73, 75, 76, 77, 80, 89, 90, 91, 92, 93], "machin": [2, 90], "learn": [2, 41, 55, 77, 80, 87, 89, 91, 92, 93], "model": [2, 35, 40, 42, 49, 54, 56, 57, 58, 59, 61, 62, 65, 66, 69, 70, 72, 77, 80, 81, 83, 91, 92, 93], "dtype": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 46, 47, 49, 50, 51, 52, 55, 57, 58, 59, 63, 72, 73, 75, 77, 78, 81, 83, 84, 89, 91, 92, 93], "quantiz": [2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 26, 28, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 72, 75, 78, 80], "sparsiti": [2, 11, 17, 20, 68, 69, 70, 71, 72, 73, 76, 78], "tba": [3, 7, 74], "For": [6, 8, 36, 55, 76, 77, 78, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "new": [6, 8, 75, 76, 81, 83, 89, 90, 91, 93], "case": [6, 49, 64, 80, 83, 84, 88, 89, 93], "exampl": [6, 8, 35, 45, 49, 54, 55, 56, 61, 62, 69, 72, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92], "train": [6, 31, 54, 55, 73, 75, 77, 80, 83, 93], "like": [6, 14, 49, 75, 76, 77, 78, 80, 83, 84, 88, 89, 90, 91, 92, 93], "fp4": 6, "s": [6, 8, 45, 49, 50, 52, 63, 75, 76, 77, 80, 81, 83, 89, 90, 91, 92, 93], "fine": [6, 40, 41, 42, 47, 80], "start": [6, 32, 33, 45, 46, 48, 49, 75, 76, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "prototyp": [6, 55, 61, 76, 93], "folder": [6, 89, 90], "you": [6, 55, 69, 75, 76, 77, 78, 80, 83, 84, 87, 88, 89, 90, 91, 92, 93], "could": [6, 76, 83, 88, 89, 91, 92, 93], "also": [6, 49, 55, 62, 76, 77, 78, 80, 81, 83, 84, 89, 92, 93], "take": [6, 18, 62, 68, 72, 76, 80, 88, 89, 90, 91, 92, 93], "look": [6, 8, 75, 76, 80, 88, 89, 90, 91, 92], "affinequantizedtensor": [6, 16, 24, 25, 27, 76, 77, 78, 81, 83], "what": [6, 8, 16, 49, 75, 76, 77, 80, 81, 84, 87, 89, 93], "want": [6, 62, 72, 76, 77, 78, 80, 83, 84, 88, 89, 90, 93], "do": [6, 46, 49, 53, 62, 76, 80, 81, 83, 84, 89, 90, 91, 93], "mostli": [6, 51, 77, 91], "e": [6, 8, 36, 45, 49, 50, 52, 54, 55, 62, 63, 75, 76, 78, 81, 83, 88, 93], "g": [6, 8, 36, 45, 49, 50, 52, 54, 55, 62, 63, 76, 78, 81, 83, 88, 93], "int3": 6, "exact": [6, 89, 90], "same": [6, 8, 37, 50, 51, 52, 63, 64, 72, 75, 76, 80, 81, 83, 90, 91, 92, 93], "affin": [6, 8, 10, 11, 12, 13, 17, 20, 21, 26, 52, 63, 76], "pleas": [6, 8, 16, 36, 41, 73, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "feel": [6, 76, 80, 83, 84], "free": [6, 76, 83], "open": [6, 76, 80], "an": [6, 8, 21, 26, 27, 49, 55, 69, 73, 76, 77, 80, 81, 83, 88, 89, 90, 91, 92, 93], "issu": [6, 76, 77, 83, 91], "have": [6, 40, 41, 45, 49, 57, 58, 59, 63, 69, 76, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "question": [6, 76, 78, 80, 83, 93], "specif": [6, 14, 17, 19, 20, 69, 76, 77, 78, 80, 88, 91, 92, 93], "more": [6, 8, 36, 40, 41, 42, 47, 49, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92], "refer": [6, 8, 75, 80, 81, 83, 84, 88, 89, 90, 91], "our": [6, 18, 75, 77, 80, 81, 83, 89, 90], "overview": [6, 73, 77, 84], "page": [6, 77, 91], "To": [6, 8, 16, 49, 75, 76, 77, 78, 80, 81, 84, 89, 90, 91, 93], "contribut": [6, 77, 80], "exist": [6, 46, 75, 76, 80, 81, 83, 89, 93], "code": [6, 41, 75, 76, 77, 80, 81, 83, 85, 87, 89, 90, 91, 92, 93], "base": [6, 14, 19, 45, 61, 69, 76, 77, 80, 83, 84, 88, 89, 90, 91, 92, 93], "make": [6, 76, 77, 83, 84, 89, 93], "trainabl": [6, 76, 83], "add": [6, 19, 83, 87, 91, 93], "parallel": [6, 75, 83, 84], "etc": [6, 76, 88, 93], "affine_quantized_tensor": [6, 78], "py": [6, 8, 16, 79, 86, 87, 91, 92], "api": [6, 49, 60, 76, 77, 80, 81, 83, 88, 89, 90, 91, 92], "quant_api": [6, 62, 78, 81], "primit": [6, 8, 16, 83, 89], "op": [6, 8, 16, 41, 49, 62, 77, 80, 83, 84, 89, 90, 91, 93], "slight": [6, 80], "variat": [6, 76], "quant_primit": [6, 8, 16, 81], "autotun": [6, 77, 81], "cpu": [6, 8, 13, 78, 80, 81, 84, 88, 89, 90, 91], "cuda": [6, 8, 62, 75, 77, 78, 80, 81, 83, 90], "mp": 6, "csrc": 6, "mayb": [6, 30], "well": [6, 14, 49, 76, 77, 80, 89, 90, 93], "spars": [6, 9, 17, 20, 69, 76, 80], "marlin": [6, 15, 16, 17, 28], "aqt": 6, "621": 6, "we": [6, 8, 18, 45, 47, 49, 50, 51, 52, 55, 62, 63, 72, 75, 76, 77, 78, 80, 81, 84, 88, 89, 90, 91, 92, 93], "ar": [6, 8, 12, 20, 22, 34, 36, 37, 40, 41, 49, 50, 52, 54, 62, 63, 64, 69, 75, 76, 77, 78, 80, 81, 84, 88, 89, 90, 91, 92, 93], "still": [6, 76, 80, 89, 93], "decid": [6, 76, 80, 81], "split": [6, 89, 90], "can": [6, 21, 37, 40, 45, 49, 54, 55, 62, 63, 75, 76, 77, 78, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "implement": [6, 31, 78, 80, 81, 88, 89, 93], "regist": [6, 68, 83], "mai": [6, 51, 55, 76, 78, 81, 89, 90, 91, 92, 93], "need": [6, 37, 68, 69, 76, 77, 78, 80, 83, 84, 89, 90, 91, 93], "defin": [6, 14, 22, 32, 36, 68, 69, 77, 80, 81, 83, 84, 88, 91, 92, 93], "own": [6, 73, 75, 77, 80, 81, 89, 90, 93], "through": [6, 51, 73, 76, 77, 81, 83, 84, 87, 88, 89, 93], "int4": [6, 10, 13, 42, 45, 55, 57, 58, 59, 62, 72, 77, 78, 84], "access": [6, 88], "my_custom_op": 6, "devic": [6, 8, 62, 64, 75, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92], "check": [6, 8, 16, 76, 77, 78, 83, 88, 90, 93], "condit": [6, 76], "__torch_function__": [6, 76, 83], "__torch_dispatch__": [6, 83], "target": [6, 37, 38, 39, 41, 50, 69, 77, 80, 88, 89, 90, 91, 92, 93], "oper": [6, 8, 12, 14, 17, 51, 77, 88, 89, 90, 91, 92], "bfloat16": [6, 18, 58, 63, 75, 76, 77, 78, 80, 81, 84, 91, 92], "activ": [6, 37, 38, 40, 42, 43, 49, 55, 59, 65, 69, 73, 77, 80, 81, 84, 88, 91, 92, 93], "uint4": [6, 41, 76, 77], "weight": [6, 17, 18, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 55, 57, 58, 59, 62, 69, 72, 73, 75, 77, 78, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "found": [6, 76, 77, 80, 81, 83], "here": [6, 8, 63, 76, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92, 93], "allow": [6, 77, 80, 83, 88, 89, 90, 91, 93], "peopl": [6, 76, 78, 84, 93], "linear": [6, 17, 31, 34, 37, 39, 41, 42, 43, 44, 47, 49, 54, 58, 59, 62, 66, 70, 72, 75, 76, 77, 78, 80, 81, 83, 88, 89, 90, 91, 93], "two": [6, 16, 20, 37, 76, 77, 80, 83, 88, 89, 90, 91, 93], "dispatch_condit": [6, 76], "impl": [6, 8, 76], "actual": [6, 39, 76, 81, 83, 84, 89, 90, 93], "bia": [6, 76, 77, 78, 81, 83, 84, 90, 93], "run": [6, 35, 49, 62, 65, 68, 75, 76, 77, 80, 83, 87, 88, 89, 90, 91, 92, 93], "both": [6, 8, 37, 76, 77, 80, 81, 83, 89, 91, 92, 93], "input_tensor": [6, 18, 76, 84], "weight_tensor": [6, 76, 84], "argument": [6, 8, 21, 49, 52, 62, 75, 76, 91], "register_aqt_quantized_linear_dispatch": 6, "show": [6, 63, 75, 76, 77, 80, 84, 89, 90], "work": [6, 20, 40, 75, 78, 80, 83, 84, 89, 90, 91], "sometim": [6, 80], "ha": [6, 8, 76, 80, 83, 84, 88, 89, 90, 92, 93], "pack": [6, 8, 10, 21, 22, 36, 40, 47, 76], "order": [6, 49, 54, 76, 80, 83, 93], "yield": [6, 80], "And": [6, 18, 37, 76, 83, 91, 93], "abstract": [6, 76], "see": [6, 8, 16, 36, 75, 76, 77, 78, 80, 81, 83, 84, 88, 89, 93], "full": [6, 77, 81, 87, 88, 90], "after": [6, 35, 49, 76, 78, 80, 88, 89, 90, 91, 92, 93], "wrap": [6, 49, 83, 91, 92], "factori": 6, "convert": [6, 8, 16, 18, 23, 26, 28, 29, 31, 54, 56, 57, 62, 72, 75, 76, 80, 88, 91, 92, 93], "from": [6, 8, 18, 19, 24, 25, 27, 36, 42, 51, 56, 62, 63, 72, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93], "float": [6, 8, 16, 18, 26, 28, 29, 36, 41, 45, 48, 49, 50, 51, 52, 55, 63, 66, 69, 76, 77, 78, 83, 89, 90, 93], "point": [6, 8, 16, 28, 36, 41, 45, 48, 52, 55, 61, 75, 76, 77, 78, 80, 81, 83, 89, 93], "my": [6, 80, 90], "to_my_dtyp": 6, "mydtypetensor": 6, "from_float": [6, 81, 83], "level": [6, 69, 76, 80, 83, 88, 89, 91, 92], "reus": [6, 76, 83], "quantize_": [6, 56, 62, 72, 76, 77, 78, 81], "appli": [6, 8, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 54, 62, 72, 76, 77, 80, 84, 90], "convers": [6, 8, 34, 76], "filter": [6, 34, 49, 75, 81], "choos": [6, 76, 80, 83, 89, 91], "which": [6, 16, 22, 49, 75, 76, 77, 78, 80, 81, 84, 88, 89, 90, 91, 92, 93], "modul": [6, 31, 32, 33, 34, 35, 45, 46, 48, 49, 54, 56, 57, 61, 62, 65, 66, 68, 69, 72, 75, 77, 78, 81, 88, 89, 90, 91, 92, 93], "should": [6, 8, 35, 40, 52, 56, 68, 69, 75, 76, 80, 84, 88, 89, 93], "algorithm": [6, 41, 47, 80, 88], "onli": [6, 13, 34, 37, 39, 40, 41, 42, 44, 47, 72, 75, 77, 78, 80, 83, 84, 88, 89, 91, 92, 93], "dynam": [6, 30, 31, 35, 37, 40, 42, 43, 55, 59, 72, 81, 83, 89, 90, 91], "quant": [6, 8, 16, 36, 76, 84, 89, 92, 93], "static": [6, 8, 14, 18, 24, 27, 31, 38, 51, 55, 73, 77, 89, 90, 91, 92, 93], "type": [6, 8, 17, 18, 22, 31, 32, 33, 34, 37, 38, 39, 41, 42, 45, 46, 48, 49, 53, 55, 63, 64, 73, 76, 78, 80, 83, 84, 88, 89, 91, 92, 93], "note": [6, 54, 69, 76, 77, 80, 83, 84, 90, 91, 92], "2": [6, 8, 11, 13, 17, 20, 41, 45, 49, 55, 63, 70, 72, 73, 75, 76, 80, 81, 83, 87], "4": [6, 11, 17, 20, 29, 40, 70, 72, 76, 77, 78, 80, 83, 89, 90], "below": [6, 75, 76, 80, 83, 84, 87, 88], "follow": [6, 41, 55, 75, 76, 77, 80, 81, 83, 88, 89, 90, 91, 92, 93], "util": [6, 40, 75, 76, 77, 78, 83, 84, 88, 89, 90, 91, 92, 93], "import": [6, 56, 62, 72, 77, 78, 80, 81, 83, 84, 87, 88, 91, 92], "unwrap_tensor_subclass": [6, 77], "m_unwrap": 6, "m": [6, 62, 72, 75, 77, 78, 81, 83, 89, 90, 91], "In": [6, 75, 76, 77, 80, 81, 83, 88, 89, 90, 91, 92, 93], "compat": [6, 17, 55, 77], "aim": [6, 76, 80, 92], "fullgraph": [6, 77], "true": [6, 8, 26, 31, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 55, 62, 65, 72, 75, 77, 78, 81, 83, 84, 88, 89, 90, 91, 93], "first": [6, 18, 49, 53, 69, 76, 81, 83, 84, 89, 90, 93], "remov": [6, 50, 69, 75, 80, 84, 89, 90], "ani": [6, 19, 49, 57, 61, 67, 69, 76, 80, 83, 88, 90, 92], "unnecessari": 6, "graph": [6, 77, 89, 90, 93], "break": 6, "torch_log": 6, "output_cod": 6, "when": [6, 8, 19, 50, 52, 63, 75, 76, 80, 81, 84, 88, 89, 90, 91, 92, 93], "script": [6, 77, 81, 83, 87, 90, 91, 92], "inductor": [6, 49, 73, 77, 88, 89], "python": [6, 76, 77, 80, 85, 87, 88, 89, 91, 92], "mode": [6, 40, 41, 49, 77, 81, 88, 90, 91, 92, 93], "max": [6, 45, 76, 77, 81, 83, 89, 90, 93], "checkout": [6, 8, 16, 73, 76], "doc": [6, 75, 76, 77, 83], "huggingfac": 6, "transform": [6, 8, 76, 81, 88, 89, 90, 91, 92], "deseri": [6, 76, 89, 90], "save_pretrain": 6, "push_to_hub": [6, 84], "from_pretrain": [6, 84], "http": [6, 8, 16, 36, 49, 69, 77, 80, 92], "co": 6, "main": [6, 8, 16, 41, 76, 77, 80, 81, 83, 89, 93], "en": [6, 49], "anoth": [6, 76, 80, 83, 89, 93], "diffus": 6, "github": [6, 8, 16, 36, 77], "com": [6, 8, 16, 36], "sayakpaul": 6, "blob": [6, 8, 16], "infer": [6, 8, 65, 73, 76, 77, 78, 80, 81, 83, 88, 89, 90, 91, 92], "serialization_and_load": 6, "md": 6, "The": [6, 8, 9, 14, 17, 22, 34, 36, 37, 38, 39, 49, 53, 62, 64, 65, 66, 69, 75, 76, 77, 78, 80, 83, 84, 88, 89, 90, 91, 92, 93], "abov": [6, 45, 76, 78, 80, 81, 83, 89, 90, 93], "just": [6, 45, 55, 76, 78, 80, 83, 89, 90, 93], "talk": [6, 76], "about": [6, 41, 76, 77, 78, 80, 89, 90, 91, 93], "basic": [6, 19, 77, 81, 83], "provid": [6, 14, 17, 20, 21, 49, 50, 54, 61, 75, 76, 80, 83, 84, 89, 90, 92, 93], "fsdp": [6, 76], "ll": [6, 45, 75, 76, 83, 89, 90, 93], "put": [6, 72, 91, 93], "developer_api_guid": 6, "cover": [6, 76, 87, 89, 92, 93], "executorch": [6, 42, 62, 77, 89, 90], "torchchat": 6, "todo": [6, 76], "qat": [6, 54, 55, 56, 57, 58, 59, 60, 61, 73, 91], "suit": [6, 89, 91], "out": [6, 20, 45, 49, 69, 75, 76, 77, 80, 83, 88, 89, 90, 91], "differ": [6, 14, 41, 51, 54, 63, 64, 75, 76, 77, 78, 80, 83, 84, 89, 90, 91, 93], "system": 6, "dtensor": [6, 83], "recommend": [6, 37, 38, 39, 40, 41, 42, 47, 49, 75, 88, 91, 92], "copi": [6, 8, 69, 77, 78, 80, 81, 83, 88, 90, 91], "past": [6, 80], "adapt": [6, 81], "now": [6, 36, 42, 50, 75, 76, 77, 80, 81, 83, 88, 89, 91, 93], "befor": [6, 62, 76, 78, 80, 81, 83, 89, 90, 93], "some": [6, 49, 62, 69, 76, 77, 80, 81, 83, 88, 89, 90, 91, 92, 93], "singl": [6, 30, 35, 37, 49, 51, 75, 77, 80, 89, 93], "comput": [6, 17, 21, 35, 39, 68, 69, 80, 81, 83, 89, 90, 91, 92], "intens": 6, "memori": [6, 8, 75, 77, 80, 83, 91, 92], "input": [6, 8, 17, 18, 20, 31, 34, 35, 49, 50, 51, 52, 53, 61, 62, 63, 64, 69, 72, 75, 76, 77, 81, 83, 88, 89, 90, 91, 92, 93], "dimens": [6, 8, 22, 47, 50, 52, 53, 63, 75, 83, 84, 89, 90], "get": [6, 18, 75, 76, 77, 80, 84, 88, 89, 90, 91, 93], "sens": [6, 76, 83], "speedup": [6, 41, 75, 76, 77, 80], "d": [6, 76, 90], "creat": [6, 8, 24, 25, 27, 75, 76, 80, 83, 88, 89, 91, 92, 93], "file": [6, 75, 79, 83, 84, 86, 89, 90], "benchmark_aq": 6, "shape": [6, 8, 16, 49, 53, 64, 77, 81, 83, 84, 89, 92], "A": [6, 8, 22, 49, 51, 68, 80, 83, 84, 89], "quick": [6, 73], "wai": [6, 8, 49, 75, 76, 80, 81, 83, 89, 90, 93], "relev": [6, 41, 76, 87], "chang": [6, 62, 75, 76, 77, 78, 80, 81, 83, 88, 89, 90, 92, 93], "interest": [6, 76, 80, 83], "tutori": [6, 8, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93], "print_op_and_shap": 6, "output": [6, 31, 49, 50, 52, 63, 75, 76, 77, 80, 87, 88, 89, 90, 91, 92, 93], "torch_func": 6, "built": [6, 75, 83], "k": [6, 64, 77, 78, 81, 83, 89, 90], "n": [6, 77, 78, 81, 83, 89, 90, 93], "10": [6, 45, 63, 75, 77, 81, 89, 90], "method": [6, 14, 17, 20, 21, 49, 62, 69, 77, 80, 81, 83, 88, 89, 90, 92, 93], "_c": 6, "tensorbas": 6, "object": [6, 22, 56, 62, 72, 83, 89, 90, 93], "arg": [6, 8, 57, 69, 83, 84, 90, 93], "0": [6, 8, 49, 55, 63, 66, 69, 75, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93], "size": [6, 8, 9, 16, 18, 40, 41, 42, 47, 50, 52, 55, 63, 75, 77, 78, 80, 81, 83, 84, 90], "all": [6, 35, 45, 49, 51, 57, 61, 68, 69, 70, 76, 77, 78, 79, 80, 81, 83, 84, 85, 88, 89, 91, 93], "under": 6, "benchmark_your_kernel": 6, "helper": 6, "right": [6, 76, 80, 89], "1": [6, 17, 22, 32, 33, 41, 45, 46, 47, 48, 49, 63, 69, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 89, 90], "either": [6, 8, 37, 69, 80, 90, 91, 92], "one": [6, 37, 49, 51, 68, 75, 76, 80, 83, 84, 90, 93], "probabl": 6, "keep": [6, 17, 69, 89], "futur": [6, 36, 81, 84, 89, 90, 91, 93], "llama": [6, 84, 88], "llama2": 6, "llama3": [6, 75], "sam": 6, "alreadi": [6, 8, 49, 83, 93], "modifi": [6, 34, 62, 69, 75, 76, 80, 83], "friendli": [6, 76], "compar": [6, 41, 69, 75, 76, 89, 91, 93], "techniqu": [6, 78, 80, 81, 83, 84], "repres": [6, 8, 9, 12, 14, 25, 31, 55, 63, 69, 76, 78, 83, 89, 90], "bound": [6, 80, 84], "help": [6, 75, 76, 84, 88, 89], "option": [6, 8, 12, 16, 23, 26, 27, 28, 30, 31, 34, 37, 38, 40, 41, 43, 44, 49, 50, 51, 52, 55, 58, 60, 62, 63, 65, 66, 67, 69, 72, 75, 77, 84, 89, 90, 91, 92, 93], "each": [6, 18, 49, 55, 65, 68, 76, 80, 81, 83, 84, 89, 90, 93], "understand": [6, 75, 91, 93], "profil": 6, "profile_path": 6, "chrome": 6, "trace": [6, 76], "let": [6, 45, 63, 76, 77, 80, 81, 83, 93], "know": [6, 49, 56, 83], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 68, 69, 76, 77, 78, 81, 83, 89, 90, 91, 93], "torchao": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 80, 81, 83, 88, 89, 90, 91, 92], "tensor_impl": [8, 16, 76, 81], "aqttensorimpl": [8, 16], "block_siz": [8, 14, 16, 18, 23, 24, 26, 27, 28, 29, 50, 51, 52, 63, 77, 81], "tupl": [8, 16, 18, 23, 24, 26, 27, 28, 37, 38, 50, 51, 52, 61, 63, 69, 83, 84, 89, 90, 93], "int": [8, 9, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 36, 40, 41, 42, 44, 47, 50, 51, 52, 55, 57, 58, 59, 62, 63, 69, 77, 81, 83, 84], "quant_min": [8, 16, 26, 27, 28, 45, 50, 51, 52, 63, 76, 77, 83, 92, 93], "union": [8, 16, 31, 37, 38, 50, 52, 55, 62, 63], "none": [8, 12, 16, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 44, 45, 46, 48, 49, 50, 51, 52, 55, 60, 61, 62, 63, 65, 66, 67, 69, 72, 81, 83, 84, 88, 89, 90, 92], "quant_max": [8, 16, 26, 27, 28, 45, 50, 51, 52, 63, 76, 77, 83, 92, 93], "zero_point_domain": [8, 16, 26, 27, 28, 41, 50, 51, 55], "zeropointdomain": [8, 16, 26, 27, 28, 41, 50, 51, 55], "stride": [8, 16, 76, 83], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 85, 87], "tensor": [8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 38, 39, 41, 42, 49, 50, 51, 52, 53, 63, 64, 67, 69, 73, 75, 77, 78, 80, 81, 87, 89, 91, 92], "subclass": [8, 16, 34, 49, 68, 72, 77, 78, 80], "mean": [8, 18, 45, 50, 52, 63, 75, 76, 77, 80, 89, 90, 93], "quantized_tensor": 8, "float_tensor": [8, 83], "scale": [8, 14, 17, 24, 27, 32, 35, 38, 45, 48, 50, 51, 52, 53, 55, 61, 63, 65, 66, 76, 80, 81, 83, 84, 93], "zero_point": [8, 14, 27, 41, 48, 50, 51, 52, 63, 76, 80, 81, 83, 93], "happen": [8, 16, 49, 76, 83, 89, 91], "dure": [8, 16, 49, 52, 55, 66, 75, 77, 80, 81, 83, 88, 90], "choose_qparam": [8, 76], "dequant": [8, 16, 18, 41, 52, 76, 77, 83, 84, 89, 91, 92, 93], "ao": [8, 16, 80, 84], "three": [8, 49, 69, 72, 76, 91, 92], "choose_qparams_affin": [8, 41, 51, 76], "quantize_affin": [8, 41, 76], "qand": 8, "dequantize_affin": [8, 41], "extern": [8, 91], "regardless": 8, "intern": [8, 21], "represent": [8, 14, 25, 41, 76, 80, 84, 89, 93], "orient": 8, "field": [8, 55, 93], "serv": [8, 14, 83, 92], "gener": [8, 76, 77, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 93], "storag": [8, 17, 76, 80], "data": [8, 9, 14, 17, 22, 37, 38, 39, 41, 51, 73, 76, 78, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93], "store": [8, 17, 18, 22, 68, 76, 80, 84, 89, 90], "plain": [8, 84], "int_data": [8, 83], "format": [8, 17, 18, 36, 40, 76, 80, 89, 90, 93], "depend": [8, 40, 49, 78, 80, 83, 89, 90, 92], "kernel": [8, 10, 11, 13, 17, 21, 36, 40, 41, 62, 77, 80, 88, 91, 92], "granular": [8, 32, 37, 38, 40, 41, 42, 47, 50, 52, 55, 63, 75, 76, 81, 84], "element": [8, 20, 22, 49, 50, 52, 63, 80], "share": [8, 50, 52, 63, 80], "qparam": [8, 50, 52, 63], "us": [8, 12, 13, 14, 17, 18, 19, 22, 24, 27, 37, 38, 41, 42, 45, 47, 49, 50, 51, 52, 54, 55, 56, 63, 69, 73, 75, 76, 77, 78, 80, 81, 83, 84, 88, 89, 90, 91, 92], "per": [8, 39, 41, 42, 43, 44, 47, 50, 52, 55, 57, 58, 59, 63, 69, 75, 76, 77, 80, 81, 92], "torch": [8, 17, 18, 22, 24, 31, 34, 37, 38, 39, 41, 47, 49, 50, 52, 53, 55, 57, 58, 59, 62, 63, 64, 65, 66, 72, 75, 76, 77, 78, 80, 81, 83, 84, 87, 91, 92, 93], "origin": [8, 18, 39, 56, 63, 69, 76, 77, 78, 80, 88, 89, 93], "high": [8, 23, 24, 25, 26, 27, 75, 76, 80, 81, 83, 88, 89, 91, 92], "precis": [8, 23, 24, 25, 26, 27, 39, 58, 59, 76, 81, 83, 88, 91, 92], "minimum": [8, 49, 50, 52, 63], "valu": [8, 18, 31, 32, 33, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 52, 63, 65, 69, 76, 80, 81, 83, 88, 89, 90, 93], "specifi": [8, 31, 34, 47, 54, 62, 63, 69, 72, 75, 80, 88, 89, 90, 93], "deriv": [8, 51, 63], "maximum": [8, 50, 52, 63, 65], "domain": [8, 41, 48, 50, 52, 55], "integ": [8, 26, 27, 40, 41, 45, 48, 50, 52, 53, 55, 64, 81, 89, 90, 91], "zero": [8, 20, 41, 50, 52, 55, 61, 69, 80, 81, 93], "ad": [8, 52, 69, 80, 81, 83, 90], "subtract": [8, 18], "unquant": [8, 93], "default": [8, 9, 12, 19, 21, 22, 37, 38, 39, 40, 41, 47, 49, 50, 52, 55, 62, 65, 66, 75, 77, 83, 84, 88, 89, 90, 91, 92, 93], "float32": [8, 24, 52, 55, 57, 59, 63, 78, 80, 81, 83, 91, 92, 93], "given": [8, 16, 29, 75, 80, 84, 93], "return": [8, 16, 17, 18, 34, 49, 53, 55, 62, 64, 65, 66, 72, 75, 76, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92, 93], "classmethod": [8, 16, 81, 83, 84], "from_hp_to_floatx": 8, "input_float": [8, 16, 23, 24, 25, 26, 27, 28, 67], "target_dtyp": [8, 23, 24, 26, 27, 30, 31, 50, 51, 76, 81], "_layout": [8, 16, 23, 24, 25, 26, 27, 28, 76, 77, 81], "layout": [8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 41, 42, 43, 72, 80], "scale_dtyp": [8, 23, 24, 26, 50, 51, 81], "float8": [8, 11, 12, 23, 24, 30, 31, 32, 33, 34, 35, 37, 38, 39, 73, 76, 81], "from_hp_to_floatx_stat": 8, "paramet": [8, 14, 17, 18, 24, 27, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 49, 50, 52, 53, 55, 62, 63, 64, 65, 66, 69, 72, 75, 76, 78, 80, 83, 84, 88, 89], "from_hp_to_fpx": 8, "floatx": [8, 25, 76], "ebit": [8, 25, 36], "mbit": [8, 25, 36], "support": [8, 25, 37, 42, 55, 72, 75, 77, 78, 80, 83, 88, 89, 90, 91, 92, 93], "float1": [8, 25], "float7": [8, 25], "from_hp_to_intx": [8, 16], "mapping_typ": [8, 26, 42, 50, 51, 55], "mappingtyp": [8, 26, 42, 43, 50, 51, 55, 81], "ep": [8, 26, 50, 51, 55, 81, 90, 92, 93], "zero_point_dtyp": [8, 26, 50, 51, 81], "preserve_zero": [8, 26, 41, 50, 51], "bool": [8, 26, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 55, 59, 62, 65, 72, 81], "plainlayout": [8, 26, 27, 42, 43, 81], "use_hqq": [8, 26, 41, 47, 84], "fals": [8, 26, 31, 41, 43, 47, 49, 55, 59, 65, 69, 75, 76, 77, 78, 81, 83, 84, 88, 89, 90, 92, 93], "from_hp_to_intx_stat": 8, "kwarg": [8, 55, 57, 68, 69, 70, 83, 84], "perform": [8, 21, 35, 40, 49, 53, 57, 58, 59, 64, 65, 68, 75, 77, 80, 81, 83, 84, 88, 90, 91, 92], "self": [8, 76, 77, 78, 81, 83, 84, 89, 90, 91], "If": [8, 12, 34, 37, 49, 53, 55, 64, 65, 69, 76, 77, 80, 83, 89, 90], "correct": [8, 17, 89, 90], "otherwis": [8, 54, 55, 76, 90], "desir": [8, 49, 81], "call": [8, 49, 68, 76, 77, 78, 80, 81, 83, 84, 90, 92], "non_block": 8, "memory_format": [8, 91, 92], "preserve_format": 8, "set": [8, 12, 37, 38, 39, 40, 41, 42, 47, 49, 51, 55, 62, 65, 69, 77, 80, 88, 90, 91, 92], "function": [8, 21, 34, 49, 62, 68, 69, 70, 72, 75, 77, 78, 80, 81, 83, 84, 88, 93], "attempt": 8, "asynchron": 8, "respect": [8, 80, 90], "host": [8, 84], "possibl": [8, 80, 89, 90, 91, 93], "behavior": [8, 14, 54, 84, 89, 90], "pin": 8, "pageabl": 8, "howev": [8, 80, 84, 90, 93], "caution": 8, "advis": [8, 76], "featur": [8, 83, 88, 91, 92], "inform": [8, 80, 84, 88, 89], "good": [8, 77, 83, 93], "usag": [8, 35, 49, 54, 55, 56, 73, 75, 91, 92], "pin_memori": 8, "even": [8, 75, 80, 93], "match": [8, 52, 53, 80, 89], "other": [8, 14, 69, 75, 78, 80, 83, 84, 87, 89, 90, 91, 93], "randn": [8, 75, 77, 78, 81, 83, 88, 89, 90, 91, 92], "initi": [8, 61, 76, 77, 78, 90], "float64": 8, "5044": 8, "0005": 8, "3310": 8, "0584": 8, "cuda0": 8, "blocksiz": 9, "64": [9, 29, 41, 47, 78, 81, 83, 84], "block": [9, 18, 69, 80], "matrix": [9, 12, 37, 38, 53, 64, 69, 77, 80, 91], "variabl": [9, 12, 21, 22, 69, 80], "cutlass": [10, 11], "mm_config": [12, 37, 38], "float8mmconfig": [12, 37, 38], "configur": [12, 30, 31, 34, 37, 38, 39, 41, 42, 43, 44, 47, 62, 72, 75, 76, 77, 91, 92, 93], "multipl": [12, 37, 38, 49, 53, 54, 64, 77, 80, 81, 83, 84, 91, 93], "involv": [12, 80], "tinygemm": [13, 41, 62, 76, 77], "_weight_int4pack_mm_for_cpu": [13, 41], "version": [13, 55, 75, 77, 83, 84, 89, 90, 93], "least": 13, "6": [13, 55, 75, 76, 77, 80, 89, 90, 91], "It": [14, 17, 19, 21, 35, 77, 80, 83, 93], "pre": [14, 17, 21, 77, 80, 93], "process": [14, 17, 19, 21, 22, 49, 66, 76, 80, 87, 88, 92], "post": [14, 21, 73, 77, 83, 90, 93], "addit": [14, 19, 49, 75, 80, 83, 88, 89, 92, 93], "design": [14, 17, 20, 84, 88, 89, 93], "extend": [14, 76, 80, 91], "conjunct": 14, "tensorimpl": 14, "custom": [14, 68, 73, 75, 76, 77, 80, 83, 84, 88, 89, 91, 93], "interact": [14, 76, 89], "qqq": [15, 16, 28], "marlinqqq": 16, "inherit": [16, 19, 83, 84, 91, 92], "_choose_qparams_and_quantize_affine_qqq": 16, "_dequantize_affine_qqq": 16, "handl": [17, 20, 21, 49, 76], "pattern": [17, 20, 76, 77, 84, 88, 89], "ensur": [17, 90], "preprocess": [17, 20], "manag": 17, "pre_process": 17, "1\u00ba": 17, "transpos": [17, 76, 83], "sinc": [17, 68, 76, 78, 80, 81, 83, 89, 90, 91, 92, 93], "layer": [17, 34, 37, 39, 41, 43, 44, 47, 49, 57, 58, 59, 65, 66, 69, 70, 75, 80, 81, 83, 84, 88, 93], "2\u00ba": 17, "inject": 17, "3\u00ba": 17, "again": [17, 18, 80, 89, 93], "becaus": [17, 75, 76, 78, 80, 83, 90, 93], "dim": [17, 81, 83, 84, 89, 90], "tensor_meta": 18, "subclasstensorarg": 18, "n_block": 18, "scaler_block_s": [18, 29], "quantized_scal": 18, "quantization_factor": 18, "scaler_mean": 18, "quantized_data": [18, 84], "nf4": 18, "qlora": 18, "convert_to_norm_float_weight": 18, "normal": [18, 29, 49, 80, 89, 90], "dequantize_scal": 18, "unpack": [18, 76], "doubl": 18, "scaler": 18, "int8": [18, 42, 43, 44, 55, 59, 62, 72, 76, 83, 89, 91, 92, 93], "per_scaler_block": 18, "factor": [18, 53, 66, 75, 80], "inpt_weight": 18, "double_quantize_scal": 18, "achiev": [18, 75, 80, 81, 83, 90, 91], "calcul": [18, 35, 45, 50, 51, 65, 76, 80, 89, 93], "absmax": 18, "find": [18, 80, 89, 93], "posit": 18, "typic": [18, 19, 76, 77, 78, 81, 84, 93], "per_block": 18, "int16": [18, 89], "n_scaler_block": 18, "get_original_weight": 18, "quantize_tensor_nearest": 18, "float16": [18, 63, 80], "nearest": 18, "round": [18, 45, 83], "up": [18, 62, 75, 76, 77, 80, 88, 89, 90, 93], "most": [19, 76, 80, 84, 89, 90, 93], "doe": [19, 41, 76, 80, 83, 89, 91, 92], "metadata": [19, 76, 83, 84], "step": [19, 35, 49, 75, 76, 80, 88, 89, 90, 91, 92, 93], "requir": [19, 21, 75, 76, 77, 80, 83, 88, 91, 93], "semi": [20, 72, 80], "structur": [20, 72, 77, 78, 80, 83, 89], "matric": [20, 80], "where": [20, 45, 47, 51, 57, 58, 59, 76, 80, 84, 93], "everi": [20, 68, 80, 83, 89, 90], "four": [20, 88], "prune": [20, 69], "conform": 20, "inner_k_til": [21, 41, 58, 77], "8": [21, 22, 40, 41, 45, 58, 75, 76, 77, 84, 91, 92], "core": [21, 46, 76, 81, 84, 89], "tile": [21, 76], "fit": [21, 76, 78], "effici": [21, 77, 80, 81, 92], "affect": [21, 80], "matmul": [21, 39, 76, 80, 83], "pack_dim": [22, 47], "uintx": [22, 47, 76], "smaller": [22, 40, 41, 42, 47, 77, 78], "bit": [22, 29, 36, 40, 47, 83, 84, 89, 91, 92], "width": [22, 40], "than": [22, 55, 75, 76, 80, 83, 89], "standard": [22, 76, 84], "byte": [22, 36, 47], "uintxtensor": 22, "determin": [22, 50, 75, 80, 84], "along": [22, 80, 84, 88], "indic": [22, 48, 80, 93], "last": [22, 75, 88], "256": [29, 41, 57, 58, 59, 89, 90, 93], "scaling_typ": [30, 31], "scalingtyp": [30, 31], "scaling_granular": [30, 31], "scalinggranular": [30, 31], "tensorwis": [30, 31], "cast": [30, 32], "cast_config_input": 31, "config": [31, 34, 49, 55, 62, 69, 72, 77, 80, 81, 84, 89, 91, 92], "castconfig": 31, "cast_config_input_for_grad_weight": 31, "cast_config_weight": 31, "cast_config_weight_for_grad_input": 31, "cast_config_grad_output": 31, "cast_config_grad_output_for_grad_weight": 31, "gemm_config_output": 31, "float8gemmconfig": 31, "use_fast_accum": 31, "gemm_config_grad_input": 31, "gemm_config_grad_weight": 31, "enable_fsdp_float8_all_gath": 31, "pad_inner_dim": 31, "emul": 31, "force_recompute_fp8_weight_in_bwd": 31, "round_scales_to_power_of_2": 31, "nn": [31, 34, 49, 54, 57, 62, 65, 66, 72, 75, 76, 77, 78, 80, 81, 83, 84, 89, 90, 91, 93], "from_recipe_nam": 31, "recipe_nam": [31, 75], "float8linearrecipenam": 31, "str": [31, 34, 40, 55, 62, 66, 67, 69, 72, 75, 83, 84, 92], "string": [31, 55, 69], "recip": [31, 68], "name": [32, 33, 45, 46, 48, 62, 66, 69, 72, 80, 83, 84, 88, 89, 90, 93], "qualnam": [32, 33, 45, 46, 48], "boundari": [32, 33, 45, 46, 48], "strategi": 32, "module_filter_fn": [34, 75], "callabl": [34, 49, 62, 67, 72, 84], "float8linearconfig": 34, "swap": [34, 57, 75, 76, 80, 81, 90], "float8linear": [34, 75], "pass": [34, 49, 51, 68, 76, 81, 83, 84, 90, 93], "instanc": [34, 62, 68, 72, 78, 83, 89, 91, 92, 93], "fqn": [34, 69, 72, 75, 81], "reduc": [35, 75, 80, 91], "sum": [35, 89, 90], "backward": [35, 75, 80, 90], "set_inductor_config": [36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49], "sub": [36, 47, 80], "expon": 36, "mantissa": 36, "fp6_e3_m2": 36, "fp6_e2_m3": 36, "fp6": 36, "llm": 36, "paper": [36, 80, 87], "arxiv": [36, 69, 80], "org": [36, 49, 69, 76, 77, 80, 92], "ab": [36, 69, 80], "2401": 36, "14112": 36, "repo": 36, "usyd": 36, "fsalab": 36, "fp6_llm": 36, "renam": [36, 89, 90], "fpxtensorcoreaqttensorimpl": 36, "experiment": [36, 88], "merg": 36, "to_affine_quantized_floatx": 36, "activation_dtyp": [37, 38], "float8_e4m3fn": [37, 38, 39, 76], "weight_dtyp": [37, 38, 39], "pertensor": [37, 38, 81], "perrow": [37, 38], "list": [37, 49, 52, 54, 66, 69, 76, 77, 83, 84, 88, 90, 93], "symmetr": [37, 38, 39, 40, 42, 43, 44, 45, 50, 55, 83, 88, 89, 92, 93], "current": [37, 42, 62, 66, 69, 72, 75, 77, 80, 83, 84, 89, 90, 92], "fast": [37, 38, 80], "accumul": [37, 38], "adjust": [37, 38, 39, 40, 41, 42, 47, 49], "torchinductor": [37, 38, 39, 40, 41, 42, 47, 91, 92], "float8_e4m": 38, "channel": [39, 43, 44, 55, 57, 58, 59, 68, 81, 92], "group_siz": [40, 41, 42, 44, 47, 55, 57, 62, 77, 84], "128": [40, 41, 75, 81, 83, 84, 92, 93], "bit_width": 40, "packing_bitwidth": 40, "weight_onli": 40, "gemlit": 40, "triton": [40, 76, 91, 92], "its": [40, 80, 83, 84, 89, 93], "associ": [40, 81], "fp16": [40, 50], "asymmetr": [40, 41, 42, 45, 47, 50, 55, 76, 77, 81, 88, 92, 93], "control": [40, 41, 42, 47, 69, 80, 84, 89], "grain": [40, 41, 42, 47, 83], "32": [40, 41, 42, 55, 62, 72, 75, 77, 78, 81, 83, 90], "impact": [40, 49, 75, 84], "hardwar": [40, 76, 77, 80], "runtim": [40, 76, 89], "tensorcoretiledlayout": [41, 76, 77], "group": [41, 42, 47, 55, 57, 58, 59, 76, 77], "tensor_core_til": [41, 76], "int4mm": [41, 77], "aten": [41, 76, 77, 83, 84, 88, 89, 90, 91, 92], "_weight_int4pack_mm": [41, 76], "tradit": 41, "instead": [41, 51, 55, 68, 75, 76, 77, 80, 83, 90, 91, 92, 93], "exactli": [41, 83], "chosen": [41, 80], "choic": 41, "whether": [41, 47, 48, 49, 50, 55, 83], "hqq": [41, 47, 76], "preserv": [41, 50, 69, 80, 88], "Will": 41, "act_mapping_typ": [42, 43], "token": [42, 43, 55, 59, 75], "produc": [42, 77, 88, 89, 90, 91, 92], "backend": [42, 73, 77, 80, 93], "did": 42, "lower": [42, 76, 77, 80, 81, 90], "flow": [42, 80, 81, 88, 89, 90, 91, 92], "yet": [42, 46, 83, 84, 90, 91, 92], "marlinqqqlayout": 42, "cutlassint4packedlayout": 42, "weight_only_decod": 43, "number": [45, 47, 49, 69, 80, 83, 90, 91], "map": [45, 55, 76, 83, 89, 93], "rang": [45, 75, 80, 81, 89, 90], "sai": [45, 63, 76, 84, 93], "3": [45, 49, 63, 75, 76, 77, 80, 87, 89, 90], "5": [45, 66, 69, 75, 77, 80, 84, 87, 89, 90], "7": [45, 75, 91, 92], "symmetric_no_clipping_err": 45, "variant": [45, 51, 83], "smin": 45, "smax": 45, "min_val_neg": [45, 83], "max_val_po": [45, 83], "By": [45, 80], "individu": [45, 80], "less": [45, 80, 83, 89], "error": [45, 49, 55, 75, 83, 89], "neg": 45, "directli": [45, 51, 76, 80, 81, 83], "placehold": [46, 92], "x": [47, 75, 77, 78, 81, 83, 84, 87, 88, 89, 90, 91, 92], "uint1": [47, 76], "uint7": [47, 76], "enum": 48, "quantized_v": 48, "float_val": 48, "mid_point": 48, "example_input": [49, 61, 77, 78, 81, 88, 89, 90, 91, 92, 93], "qtensor_class_list": 49, "aqdefaultlinearweight": 49, "aqint8weightonlyquantizedlinearweight": 49, "aqint8weightonlyquantizedlinearweight2": 49, "aqint8dynamicallyquantizedlinearweight": 49, "filter_fn": [49, 62, 72], "interpol": 49, "85": 49, "manual": [49, 90], "supress_autoquant_error": 49, "min_sqnr": 49, "aq_kwarg": 49, "autoquant": 49, "identifi": [49, 81, 93], "fastest": 49, "over": [49, 75, 80, 89, 90], "potenti": [49, 80, 81, 88, 89, 91, 92], "qtensor": 49, "prepar": [49, 54, 57, 65, 69, 76, 80, 88, 91, 92, 93], "search": [49, 80], "whose": [49, 93], "exchang": 49, "autoquantizablelinearweight": 49, "calibr": [49, 51, 77, 88, 90, 91, 92], "user": [49, 54, 75, 76, 77, 80, 81, 83, 87, 89, 90, 91, 92, 93], "seen": 49, "record": [49, 76, 81], "so": [49, 75, 76, 77, 78, 80, 83, 89, 90, 93], "final": [49, 62, 76, 77, 80, 88, 89, 90, 91, 92, 93], "benchmark": [49, 65, 75, 77, 88, 91, 92], "member": 49, "pick": 49, "result": [49, 53, 64, 76, 80, 81, 89, 90, 91, 92, 93], "highli": 49, "complet": [49, 88, 92], "simpli": [49, 80, 81, 83], "had": [49, 83, 89], "compil": [49, 62, 64, 75, 76, 77, 81, 83, 91, 92], "them": [49, 68, 76, 93], "onc": [49, 80], "proce": 49, "combin": [49, 55, 80, 83, 89, 91], "finalize_autoqu": 49, "been": [49, 83, 90, 91, 92, 93], "log": [49, 83], "forward": [49, 68, 76, 77, 78, 80, 81, 83, 84, 89, 90, 91], "fulli": [49, 62, 66, 72, 80, 89], "unless": [49, 84], "default_autoquant_class_list": 49, "contain": [49, 65, 66, 80, 83, 90, 93], "second": [49, 53, 75, 76, 87, 93], "stop": 49, "wait": [49, 76], "sever": [49, 75, 84, 88, 93], "automat": [49, 75, 83, 84, 87], "suppress": 49, "accept": [49, 93], "signal": 49, "nois": 49, "ration": 49, "wikipedia": 49, "wiki": 49, "noise_ratio": 49, "v": [49, 93], "non": [49, 76, 80, 83, 88, 91, 92], "caus": [49, 75], "too": 49, "larg": [49, 83, 91], "numer": [49, 75, 80, 89, 90, 91], "resaon": 49, "40": [49, 75], "keyword": 49, "example_input1": 49, "example_input2": 49, "int32": [50, 55, 57, 76, 77, 89, 93], "fp32": [50, 52, 55, 81, 83, 89, 91], "bf16": [50, 76, 77, 80, 91, 92], "optioanl": 50, "param": [50, 51, 69], "request": [50, 52, 63], "min_val": [51, 76, 83], "max_val": [51, 76, 83], "observ": [51, 68, 80, 81, 88, 89, 90, 91, 92, 93], "obtain": 51, "track": [51, 76, 84], "input_dtyp": 52, "output_dtyp": [52, 63], "uint8": [52, 63, 76, 81, 93], "b": 53, "scales1": 53, "multipli": [53, 64, 80], "row": [53, 75, 80], "rais": [53, 64, 75, 83, 84], "assertionerror": [53, 64, 75, 83], "expect": [53, 75, 80, 83, 88, 89, 91, 92, 93], "twostepquant": 54, "compos": [54, 76, 80, 83, 89, 90, 93], "easili": [54, 88], "thei": [54, 75, 76, 77, 80, 83, 89, 90, 93], "constructor": [54, 83], "must": [54, 55, 75, 80, 84, 90, 92, 93], "embed": [54, 57], "undefin": [54, 69], "my_quant": 54, "qatquantizer1": 54, "qatquantizer2": 54, "qatquantizer3": 54, "torchaodtyp": 55, "scale_precis": [55, 57], "zero_point_precis": [55, 57], "is_dynam": [55, 91, 92, 93], "range_learn": 55, "is_symmetr": 55, "fake": [55, 56, 57, 58, 59, 75, 89, 90, 93], "simul": [55, 70, 76, 80], "older": 55, "int1": [55, 76], "int7": 55, "pergroup": 55, "per_token": 55, "equival": [55, 66, 80, 90, 91, 93], "pertoken": 55, "per_channel": 55, "peraxi": [55, 81], "per_group": [55, 63], "separ": [55, 80, 84, 89, 93], "altern": [55, 76, 81, 83, 91, 92], "leav": 55, "empti": [55, 76], "properti": [55, 76], "throw": 55, "els": [55, 84, 89, 90], "fakequantizedlinear": 56, "fakequantizedembed": 56, "back": [56, 83], "correspond": [56, 62, 76, 78, 80, 83, 92, 93], "without": [56, 76, 80, 84, 91, 93], "model_with_fake_quantized_linear": 56, "int4weightonlyqatembed": 57, "int4weightonlyembed": 57, "groupsiz": [58, 59, 63], "scales_precis": [58, 59], "padding_allow": 59, "activation_config": 60, "fakequantizeconfig": 60, "weight_config": 60, "fakequant": 61, "aobaseconfig": [62, 72, 81, 84], "inplac": [62, 69, 77], "workflow": [62, 72, 75, 77, 80, 93], "qualifi": [62, 66, 72, 80], "move": [62, 76, 81, 84, 90, 91], "speed": [62, 80, 88], "predefin": [62, 93], "execut": [62, 79, 83, 86], "path": [62, 64, 77, 88, 89, 90, 91, 93], "customiz": 62, "int8_dynamic_activation_int4_weight": 62, "int8_dynamic_activation_int8_weight": [62, 72], "mm": [62, 83, 89], "int4_weight_onli": 62, "int8_weight_onli": 62, "sequenti": [62, 72, 75], "1024": [62, 72, 77, 78, 91], "tabl": [63, 75, 76, 80], "per_tensor": 63, "per_axi": 63, "axi": [63, 81], "mat2": 64, "safe": 64, "consid": [64, 76, 80], "cubla": 64, "fallback": [64, 84], "i": [64, 75, 80, 88, 89, 90], "j": 64, "debug_skip_calibr": 65, "smoothquant": [65, 66, 88], "smoothfakedynamicallyquantizedlinear": [65, 66], "debug": 65, "skip_fqn_list": 66, "cur_fqn": 66, "alpha": 66, "replac": [66, 80, 84], "skip": [66, 69, 80], "being": [66, 75, 76, 80, 84, 91, 92], "input_quant_func": [67, 76], "quant_kwarg": 67, "dict": [67, 69, 83, 84, 92, 93], "l2": [68, 80], "norm": [68, 69, 80], "buffer": 68, "x_orig": 68, "overridden": 68, "although": [68, 83], "within": [68, 80, 84, 91, 92], "afterward": 68, "former": 68, "care": [68, 78, 80, 89], "hook": [68, 76], "while": [68, 69, 80, 83, 88, 89, 93], "latter": [68, 90], "silent": [68, 91], "ignor": [68, 75, 89, 90], "sparsity_level": [69, 80], "semi_structured_block_s": 69, "wanda": 69, "sparsifi": [69, 73, 78, 80], "propos": 69, "2306": 69, "11695": 69, "awar": [69, 73, 77, 80, 83], "product": [69, 84, 91, 93], "magnitud": [69, 80], "parametr": 69, "deepcopi": [69, 77, 81, 83, 90], "squash_mask": [69, 80], "params_to_keep": 69, "params_to_keep_per_lay": 69, "squash": 69, "mask": [69, 80], "appropri": [69, 76, 88, 89, 90, 91, 92], "sparse_param": 69, "attach": [69, 80, 93], "kei": [69, 80, 87], "save": [69, 75, 77, 78, 84], "xdoctest": 69, "local": [69, 80], "don": [69, 75, 77, 80, 84, 93], "t": [69, 75, 76, 77, 80, 81, 83, 84, 89, 90, 93], "hasattr": [69, 84], "submodule1": 69, "linear1": [69, 77, 78, 81, 83], "foo": [69, 89], "bar": [69, 89], "submodule2": 69, "linear42": 69, "baz": 69, "print": [69, 77, 78, 83, 87, 89, 90], "42": [69, 81], "24": 69, "ones": [69, 76, 90], "update_mask": 69, "tensor_nam": [69, 84], "statist": [69, 76, 80, 81, 89, 90], "retriev": 69, "act_per_input": 69, "Then": [69, 83, 92, 93], "metric": 69, "across": [69, 80, 83, 84], "whole": [69, 93], "alia": [71, 84], "semisparseweightconfig": 71, "sparsify_": 72, "apply_tensor_subclass": [72, 76], "essenti": [72, 84, 88], "semi_sparse_weight": 72, "semisparselayout": 72, "sparsemarlinlayout": 72, "def": [72, 75, 76, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92, 93], "isinst": [72, 75, 80, 81, 83, 84, 90, 93], "sparse_api": 72, "librari": [73, 78], "gradient": [73, 80], "nativ": [73, 75, 83, 89], "readm": [73, 77, 80], "overal": [73, 77, 89, 93], "introduct": [73, 76], "recent": 73, "highlight": [73, 83, 87], "updat": [73, 77, 78, 80, 89, 90, 91, 93], "guid": [73, 76, 88], "contributor": [73, 77], "serial": [73, 76, 89, 90], "write": [73, 77, 88, 89, 90], "advanc": [73, 81, 83, 88, 91, 92], "pretrain": [73, 80, 88, 89, 90, 91], "vllm": 73, "architectur": [73, 80, 88, 89, 91, 92], "export": 73, "x86": [73, 77], "intel": [73, 88, 91], "gpu": [73, 75, 77, 84, 87, 88], "5x": 75, "512": 75, "cluster": 75, "34": 75, "43x": 75, "2k": 75, "h200": 75, "latest": [75, 77], "offic": 75, "framework": [75, 88], "8b": 75, "offici": 75, "popular": [75, 76], "flagship": 75, "common": [75, 76, 80], "form": [75, 76, 80], "distribut": [75, 81, 83, 84, 88], "checkpoint": [75, 84], "quickli": [75, 83], "batteri": 75, "includ": [75, 76, 83, 88, 91, 92, 93], "experi": [75, 92], "commonli": [75, 80], "fork": 75, "build": [75, 76, 80, 83, 84, 89], "top": [75, 76, 83, 88, 89, 90, 91, 92], "re": [75, 78, 83, 89, 90], "readi": [75, 77, 81, 83, 90], "virtual": 75, "environ": 75, "conda": 75, "venv": 75, "instal": [75, 77, 89, 92], "download": [75, 77, 85, 87, 89, 90, 92], "job": 75, "command": [75, 77], "root": 75, "directori": 75, "launch": 75, "ngpu": 75, "config_fil": 75, "train_config": 75, "llama3_8b": 75, "toml": 75, "run_train": 75, "sh": 75, "fsdp2": 75, "hyperparamet": 75, "edit": 75, "line": [75, 80], "flag": [75, 90], "termin": 75, "rank0": 75, "titan": 75, "2025": 75, "06": 75, "04": 75, "08": 75, "51": 75, "48": 75, "074": 75, "info": 75, "loss": [75, 80, 89, 90], "12": [75, 92, 93], "2254": 75, "27": 75, "34gib": 75, "28": 75, "78": 75, "tp": [75, 84], "375": 75, "tflop": 75, "21": 75, "73": [75, 81], "mfu": 75, "20": [75, 90], "58": 75, "557": 75, "7069": 75, "30": [75, 77, 89], "99gib": 75, "62": 75, "034": 75, "407": 75, "35": [75, 81], "41": 75, "19": 75, "52": 75, "224": [75, 81, 88, 89, 90, 91, 92], "9196": 75, "022": 75, "406": [75, 89, 90], "65": 75, "904": 75, "1423": 75, "014": 75, "23": [75, 81], "As": [75, 76, 89, 93], "warmup": 75, "around": [75, 77, 78, 89], "7k": 75, "99gb": 75, "peak": 75, "against": 75, "baselin": [75, 89], "11": 75, "02": 75, "37": 75, "404": 75, "2611": 75, "22gib": 75, "595": 75, "47": 75, "49": [75, 81], "027": 75, "4260": 75, "89gib": 75, "344": 75, "367": 75, "39": 75, "15": [75, 77], "03": 75, "01": 75, "988": 75, "9482": 75, "321": 75, "366": 75, "14": 75, "991": 75, "1183": 75, "300": 75, "364": 75, "89": 75, "36": 75, "013": 75, "4659": 75, "291": 75, "84": 75, "769": 75, "gc": 75, "peform": 75, "period": 75, "collect": [75, 76, 80], "3k": 75, "89gb": 75, "11x": 75, "higher": [75, 76, 83, 88, 89, 91, 92], "throughput": 75, "nearli": 75, "ident": [75, 80], "improv": [75, 80, 89, 92, 93], "performan": 75, "vs": [75, 80, 89, 93], "accuraci": [75, 80, 81, 88, 90, 91], "curv": [75, 80], "omit": [75, 89, 90, 91], "648": 75, "2648": 75, "28gib": 75, "71": 75, "29": 75, "26": 75, "475": 75, "9106": 75, "91gib": 75, "53": 75, "503": 75, "434": 75, "43": 75, "94": [75, 89], "166": 75, "9": 75, "0774": 75, "663": 75, "443": 75, "44": [75, 81], "87": 75, "50": [75, 80, 81, 88, 89, 91, 92], "885": 75, "3233": 75, "643": 75, "442": 75, "66": [75, 81], "76": 75, "613": 75, "6150": 75, "637": 75, "72": 75, "6k": 75, "91gb": 75, "21x": 75, "tl": 75, "dr": 75, "better": [75, 83, 89, 90, 91, 92, 93], "priorit": 75, "accur": [75, 80, 88], "stabil": 75, "come": [75, 76, 80, 81, 82, 90, 91, 92], "cost": [75, 81], "slightli": [75, 83], "limit": [75, 83, 84, 89], "outlier": 75, "underflow": 75, "8xh100": 75, "box": [75, 80, 91], "toi": [75, 77, 81, 83, 91], "convert_to_float8_train": 75, "recurs": 75, "kind": [75, 89], "gemm": [75, 91, 92], "snippet": [75, 89, 90], "f": [75, 76, 78, 80, 81, 83, 84, 89, 90], "float8_linear_util": 75, "float8_linear": 75, "torch_version_at_least_2_5": [75, 77], "greater": 75, "sampl": [75, 76, 89, 91, 92], "2048": 75, "4096": 75, "adamw": 75, "lr": 75, "1e": 75, "elig": 75, "mod": [75, 80, 83], "divis": 75, "16": 75, "in_featur": [75, 77, 78, 81, 83], "out_featur": [75, 77, 81, 83], "enabl": [75, 76, 84, 91], "competit": 75, "loop": [75, 80], "_": [75, 81, 84, 88, 89, 90, 91], "zero_grad": [75, 90], "label": 75, "demonstr": [75, 76, 77, 83, 88, 90], "purpos": [75, 76, 83, 89], "fake_label": 75, "ones_lik": 75, "mse_loss": 75, "model_state_dict": 75, "state_dict": [75, 78, 89, 90], "optimizer_state_dict": 75, "pth": [75, 89, 90], "lai": 76, "stack": 76, "awq": 76, "gptq": 76, "codebookquantizedtensor": 76, "float3": 76, "compon": [76, 83, 84], "overload": [76, 80], "term": [76, 80, 89, 93], "extra": 76, "dev": 76, "discuss": [76, 83], "1833": 76, "No": [76, 78, 80], "matter": [76, 80], "end": [76, 80, 83, 84, 87, 90, 93], "avail": [76, 88, 89, 90, 91, 92], "later": [76, 83, 89, 90, 92], "float3_e2_m0": 76, "float4_e2_m1": 76, "float4_e3_m0": 76, "float5_e2_m2": 76, "float5_e3_m1": 76, "float6_e2_m3": 76, "float6_e3_m2": 76, "float8_e5m2": 76, "float8_e4m3fnuz": 76, "float8_e5m2fnuz": 76, "plan": [76, 90], "float4": 76, "float6": 76, "becom": [76, 89], "part": [76, 80, 83, 90], "uint2": 76, "117208": 76, "outsid": 76, "mention": [76, 89], "criteria": 76, "wide": 76, "adopt": 76, "fundament": [76, 80, 90], "until": 76, "evid": 76, "hopefulli": 76, "amen": 76, "haven": 76, "enough": 76, "ont": 76, "revisit": 76, "intx": 76, "connect": [76, 93], "int4tensor": 76, "previou": [76, 89, 90, 91, 92], "between": [76, 80, 83, 84, 88, 90, 91, 93], "preicison": 76, "mainli": [76, 88, 91, 93], "There": [76, 81, 83, 89, 93], "accommod": 76, "choose_qparams_affine_with_min_max": 76, "min": [76, 81, 83, 89, 93], "int_matmul": 76, "int_scaled_matmul": 76, "reli": [76, 77, 80, 81, 83], "On": [76, 77], "glue": 76, "everyth": 76, "togeth": [76, 89, 91, 93], "construct": [76, 89, 93], "low_precision_v": 76, "high_precision_v": 76, "procedur": 76, "veri": [76, 80, 84, 90], "straightforward": [76, 93], "try": [76, 80, 83, 89], "high_preicsion_v": 76, "especi": [76, 78, 80, 91, 92], "bitwidth": [76, 93], "codebook": 76, "hardcod": [76, 93], "select": [76, 89], "multi": 76, "dimension": [76, 80], "view": [76, 83, 89, 90], "mkldnn": 76, "coo": [76, 80], "sparse_coo": [76, 80], "sparsetensorimpl": 76, "idea": [76, 80], "nice": [76, 80], "concept": [76, 87, 89, 91, 92, 93], "why": [76, 83, 87], "c": [76, 77, 83, 91, 92], "conflict": 76, "quantized_linear": [76, 81, 89], "semant": 76, "stai": [76, 77, 83, 91], "develop": [76, 77, 89, 90, 93], "tradition": 76, "to_affine_quant": 76, "simplic": 76, "explain": [76, 88, 91], "simplest": [76, 80], "easi": 76, "linear_modul": 76, "to_affine_quantized_intx": 76, "requires_grad": [76, 81, 83, 84], "to_linear_activation_quant": 76, "quantized_weight": [76, 84], "activation_and_weight_quant": 76, "encount": 76, "input_qunat_func": 76, "redispatch": 76, "fx": [76, 89, 93], "symbolic_trac": 76, "But": [76, 83, 84, 93], "prefer": [76, 77, 83], "easier": [76, 93], "further": [76, 83, 88, 89, 90, 91], "modif": 76, "figur": [76, 80, 89], "At": [76, 80, 89], "thing": [76, 78, 80, 83, 89], "address": [76, 89], "stat": [76, 90], "averag": [76, 81, 89, 90], "calculate_qparam": [76, 81, 93], "affinequantizedminmaxobserv": [76, 81], "insert_observer_": 76, "observedlinear": [76, 81], "dataset": [76, 88, 91, 92], "complic": [76, 80, 89], "next": [76, 81, 89, 90, 91, 92], "done": [76, 83], "manner": 76, "intend": [76, 89], "autoround": 76, "multitensor": 76, "sure": [76, 93], "describ": [76, 78, 80, 87, 89, 90], "focus": [76, 80], "todai": 76, "low_bit_optim": 76, "similar": [76, 80, 81, 90, 91], "quantized_train": 76, "progress": [76, 84], "lot": [76, 80], "walk": [76, 81, 83, 87, 88, 91], "int4weightonlyconfig": [76, 77, 78, 84], "_convert_weight_to_int4pack": 76, "tensorcoretiledaqttensorimpl": 76, "_quantized_linear_op": 76, "goe": 76, "_aqt_qlinear_dispatch_t": 76, "dispatch": 76, "explan": 76, "wint4": 76, "explor": [77, 92], "stabl": 77, "releas": [77, 91], "pip": [77, 88, 89], "nightli": 77, "index": [77, 80, 92], "url": [77, 92], "whl": [77, 92], "cu121": 77, "major": 77, "instruct": [77, 89, 90, 91], "entri": 77, "mutat": 77, "insert": [77, 81, 88, 89, 90, 91, 92, 93], "logic": [77, 83, 84], "toylinearmodel": [77, 78, 81], "__init__": [77, 78, 81, 83, 84, 89, 90, 91], "super": [77, 78, 81, 83, 89, 90, 91], "linear2": [77, 78, 81, 83], "eval": [77, 78, 81, 88, 90, 91, 92], "faster": [77, 80], "model_bf16": 77, "leverag": [77, 83, 91, 92], "mix": [77, 88, 91, 92], "tensor_impl_dtyp": 77, "verifi": [77, 78, 83], "roughli": [77, 80], "quarter": 77, "os": [77, 89, 90], "tmp": 77, "int4_model": 77, "pt": 77, "bfloat16_model": 77, "int4_model_size_mb": 77, "getsiz": [77, 89, 90], "bfloat16_model_size_mb": 77, "2f": [77, 89, 90], "mb": [77, 78, 79, 86, 89, 90], "25": 77, "00": [77, 79, 86], "much": [77, 80, 93], "benchmark_model": 77, "temporari": 77, "workaround": [77, 84], "num_run": 77, "100": [77, 83, 89, 90], "_dynamo": [77, 83], "reset": [77, 89, 90], "bf16_time": 77, "int4_tim": 77, "time": [77, 80, 83, 87, 88, 89, 90], "3f": [77, 90], "ms": 77, "1fx": 77, "a100": 77, "80gb": 77, "393": 77, "410": 77, "9x": 77, "recogn": [77, 93], "decis": 77, "relu": [77, 88, 93], "pt2e": [77, 88, 89, 90, 91, 92], "fuse": [77, 80, 83, 90], "real": [77, 89, 93], "deleg": [77, 89], "x86inductorquant": [77, 91], "quantize_pt2": [77, 88, 89, 90, 91, 92], "prepare_pt2": [77, 88, 89, 91, 92], "x86_inductor_quant": [77, 91], "get_default_x86_inductor_quantization_config": [77, 91], "float_model": [77, 83, 88, 89, 90, 91], "data_load": [77, 89, 90, 91, 92], "no_grad": [77, 83, 88, 89, 90, 91, 92], "imag": [77, 88, 89, 90, 91, 92], "program": [77, 89, 90, 91, 93], "captur": [77, 89, 90, 93], "expos": [77, 89, 90], "express": [77, 83, 88, 89, 90, 93], "set_glob": [77, 89, 90, 91, 92], "xiq": [77, 91], "prepare_qat_pt2": [77, 90, 91], "sample_inference_data": 77, "convert_pt2": [77, 88, 89, 90, 91, 92], "wrapper": [77, 83, 91], "_inductor": [77, 91], "cpp_wrapper": [77, 91], "optimized_model": [77, 88, 91, 92], "converted_model": [77, 91, 92], "xpu": [77, 92], "openvino": 77, "simpl": [77, 80, 81, 83, 88, 91, 92], "visit": 77, "would": [77, 80, 83, 90, 92], "forget": 77, "tempfil": 78, "get_model_size_in_byt": 78, "batch_siz": [78, 81, 89, 90], "ref": [78, 89], "namedtemporaryfil": 78, "seek": [78, 80], "load": [78, 84], "meta": [78, 84, 93], "m_load": 78, "load_state_dict": [78, 89, 90], "assign": 78, "assert": [78, 81, 83, 84, 93], "equal": [78, 80], "float_weight1": 78, "float_weight2": 78, "quantized_weight1": 78, "quantized_weight2": 78, "go": [78, 83, 87, 93], "techinqu": 78, "reduct": [78, 80, 83], "4x": 78, "0625": 78, "reason": [78, 80], "avoid": [78, 80], "properli": 78, "003": [79, 86, 87], "total": [79, 86, 87], "galleri": [79, 85, 87], "mem": [79, 86], "templat": [79, 85, 86], "tutorials_sourc": 79, "template_tutori": [79, 86, 87], "neural": [80, 88, 91], "network": [80, 83, 88, 91], "overhead": [80, 84, 91], "latenc": 80, "carefulli": 80, "signific": 80, "pai": 80, "low": [80, 83, 88], "price": 80, "qualiti": 80, "f1": 80, "problem": [80, 83], "research": [80, 87], "face": [80, 89], "fragment": 80, "rightfulli": 80, "spent": 80, "compress": [80, 88], "place": [80, 88, 89, 90, 91, 92], "dens": 80, "solv": [80, 83], "focu": [80, 83], "realli": 80, "push": [80, 84], "concret": [80, 93], "hope": 80, "modular": 80, "acceler": 80, "scratch": [80, 87], "minim": [80, 88, 91, 92], "recov": [80, 90], "algorthim": 80, "realiz": 80, "trade": 80, "off": 80, "degrad": 80, "theoret": 80, "gain": [80, 92], "2x": 80, "analog": 80, "fix": [80, 81], "unstructur": 80, "One": [80, 83, 84, 93], "close": 80, "relat": 80, "mitig": 80, "retrain": 80, "neglig": 80, "area": 80, "agre": 80, "upon": 80, "consensu": 80, "mind": 80, "thought": 80, "subproblem": 80, "satisfi": 80, "consist": [80, 83, 91, 92, 93], "answer": 80, "independ": 80, "frontend": [80, 91], "arbitrari": 80, "handoff": 80, "piec": 80, "miss": 80, "natur": [80, 83, 89, 93], "present": 80, "clear": 80, "contract": 80, "7x": 80, "advantag": 80, "anticip": 80, "mani": [80, 83], "solut": 80, "third": 80, "parti": 80, "to_sparse_semi_structur": 80, "sparsesemistructuredtensor": 80, "weightnormsparsifi": 80, "half": 80, "subnetwork": 80, "sparse_config": 80, "named_modul": 80, "append": [80, 89, 90], "tensor_fqn": 80, "sparse_block_shap": 80, "zeros_per_block": 80, "fakespars": 80, "manipul": 80, "dictionari": 80, "paramer": 80, "parameter": 80, "necessari": [80, 81, 83, 88, 89, 90, 91, 92], "ve": 80, "suitabl": [80, 91], "0s": 80, "spot": 80, "definit": [80, 84], "academia": 80, "industri": 80, "often": [80, 83], "interchang": 80, "confus": [80, 89], "distinct": 80, "behind": 80, "doesn": [80, 90, 93], "itself": [80, 83], "those": [80, 81, 83], "loos": 80, "speak": 80, "tightli": 80, "coupl": [80, 83], "nvidia": 80, "csc": 80, "fbgemm": 80, "qnnpack": 80, "descript": [80, 88], "coordin": 80, "vector": [80, 91], "locat": 80, "bsr": 80, "sparse_bsr": 80, "except": [80, 83, 93], "scalar": [80, 89], "csr": 80, "sparse_csr": 80, "sparse_csc": 80, "column": 80, "compact": 80, "sparse_matrix": 80, "1d": 80, "indexptr": 80, "\u00bd": 80, "bitmask": 80, "2bit": 80, "unprun": 80, "quit": [80, 83], "successfulli": 80, "These": [80, 83, 88, 89, 90, 93], "broken": 80, "down": 80, "Not": 80, "sensit": 80, "effect": [80, 81, 83, 91, 92, 93], "best": [80, 91], "subsequ": [80, 83, 91, 92], "infinit": 80, "lost": 80, "degre": 80, "analysi": 80, "drop": 80, "give": [80, 83], "proxi": 80, "aforement": 80, "smallest": 80, "absolut": 80, "global": [80, 83], "scope": 80, "impli": 80, "pro": 80, "con": 80, "tradeoff": 80, "span": 80, "threshold": 80, "increas": [80, 89], "complex": 80, "constant": [80, 83, 89], "ctr_mobile_fe": 80, "score": 80, "w": [80, 84], "tenosr": 80, "udpat": 80, "cannot": [80, 81, 84], "histori": 80, "regrow": 80, "dw": 80, "via": [80, 88], "backprop": 80, "pat": 80, "unmask": 80, "resid": 80, "salienc": 80, "lowest": 80, "l1": 80, "shown": [80, 90, 93], "abl": [80, 83, 84, 89, 93], "repeat": [80, 89, 90], "shot": 80, "movement": 80, "tune": [80, 88], "2005": 80, "07683": 80, "rank": [80, 83], "wx": 80, "sqx": 80, "q": [80, 89], "usual": 80, "sort": 80, "wise": 80, "reconstruct": [80, 84], "random": [80, 89, 90], "randomli": 80, "tri": 80, "remedi": 80, "item": [80, 87], "ultim": [80, 81], "literatur": 80, "vision": 80, "nlp": [80, 87, 91], "iter": [80, 89, 90], "ctr_feed": 80, "na": 80, "multimask": 80, "pyspeech": 80, "fastna": 80, "approach": [80, 83, 88, 91, 92], "knowledg": [80, 87], "distil": 80, "pdf": 80, "2204": 80, "09656": 80, "arrang": 80, "recal": 80, "counterpart": 80, "slower": 80, "suffici": 80, "flexibl": [80, 83, 88, 91], "98": 80, "benefit": [80, 83, 89, 92], "special": [80, 88, 89], "exhibit": 80, "maintain": 80, "penalti": 80, "expens": [80, 83], "dictat": 80, "characterist": 80, "highest": 80, "wouldn": [80, 83], "visual": 80, "fig": 80, "4x4": 80, "benchmak": 80, "unlik": 81, "batch": [81, 90], "fly": 81, "welcom": 81, "histogram": [81, 89], "act_ob": 81, "finfo": 81, "weight_ob": 81, "observed_input": 81, "observed_weight": 81, "cl": [81, 83, 84], "float_linear": 81, "observed_linear": 81, "_replace_with_custom_fn_if_matches_filt": 81, "insert_observers_": 81, "_is_linear": 81, "lambda": [81, 84], "replacement_fn": 81, "copied_act_ob": 81, "copied_weight_ob": 81, "popul": 81, "feed": 81, "simpler": [81, 89], "quantizedlinear": [81, 83], "isn": 81, "strictli": 81, "to_affine_quantized_intx_stat": 81, "act_scal": [81, 93], "act_zero_point": 81, "weight_scal": [81, 89, 93], "weight_zero_point": [81, 89], "qweight": 81, "qinput": 81, "from_observ": 81, "begin": [81, 83], "dataclass": [81, 84, 93], "transform_modul": [81, 84], "register_quantize_module_handl": [81, 84], "staticquantconfig": 81, "_apply_static_qu": 81, "is_observed_linear": 81, "optimizedmodul": 81, "_orig_mod": 81, "0237": 81, "plainaqttensorimpl": 81, "142": 81, "31": [81, 93], "113": 81, "157": 81, "57": 81, "59": 81, "160": 81, "70": 81, "150": 81, "67": 81, "241": 81, "238": 81, "69": 81, "235": 81, "228": 81, "255": [81, 93], "201": 81, "114": 81, "236": 81, "88": [81, 89], "83": 81, "109": 81, "209": 81, "92": 81, "184": 81, "141": 81, "110": 81, "0009": 81, "0010": 81, "130": 81, "122": 81, "132": 81, "125": 81, "126": 81, "129": 81, "127": [81, 83, 92, 93], "133": 81, "124": 81, "131": 81, "135": 81, "136": 81, "soon": [82, 90], "foundat": 83, "extens": [83, 89, 91], "autograd": [83, 93], "interpos": 83, "namespac": 83, "continu": [83, 90, 91, 92, 93], "seamlessli": [83, 91, 92], "obviou": 83, "int8quantizedlinear": 83, "few": [83, 89, 90], "finer": 83, "intercept": 83, "contrast": 83, "long": [83, 89], "clunki": 83, "distributedlinear": 83, "duplic": 83, "bypass": 83, "offer": [83, 89], "outer": 83, "inner": 83, "allgath": 83, "bandwidth": 83, "rest": [83, 90], "read": 83, "document": [83, 84, 88, 89, 91], "zoo": 83, "podcast": 83, "edward": 83, "yang": 83, "int8_symmetric_quant": 83, "fp32_tensor": 83, "amin": 83, "keepdim": [83, 89, 90], "amax": 83, "zeros_lik": 83, "clamp": [83, 89], "w_int8": 83, "new_linear": 83, "left": [83, 93], "toymodel": 83, "quantized_model": [83, 88, 89, 90], "child": 83, "named_children": 83, "setattr": 83, "drawback": 83, "won": 83, "suppos": 83, "clean": 83, "eleg": 83, "pretti": 83, "power": [83, 84], "overrid": 83, "almost": 83, "shard": [83, 84], "ragged": 83, "rag": 83, "nestedtensor": 83, "resourc": 83, "who": 83, "link": [83, 87], "googl": 83, "collab": 83, "flopcount": 83, "memorytrack": 83, "With": [83, 89, 91, 93], "bare": 83, "bone": 83, "int8symmetrictensor": 83, "hold": 83, "staticmethod": 83, "disabl": [83, 90], "__new__": [83, 84], "_make_wrapper_subclass": [83, 84], "storage_offset": 83, "ndim": 83, "__tensor_flatten__": [83, 84], "attribut": [83, 84, 91, 92], "pt2": [83, 91], "__tensor_unflatten__": [83, 84], "tensor_data_dict": [83, 84], "extra_metadata": 83, "outer_s": [83, 84], "outer_strid": [83, 84], "undo": 83, "__repr__": 83, "repr": 83, "ahead": 83, "insid": 83, "int8_tensor": 83, "func": [83, 84], "op_implementations_dict": 83, "conveni": 83, "register_op": 83, "_op": 83, "opoverload": 83, "impl_decor": 83, "op_impl": 83, "particular": 83, "largest": 83, "tell": 83, "desugar": 83, "decor": [83, 84], "surfac": 83, "coverag": [83, 88, 89, 91, 92], "though": 83, "brute": 83, "forc": 83, "repeatedli": 83, "loggingtensor": 83, "_python_dispatch": [83, 84], "return_and_correct_alias": [83, 84], "int8_mm": 83, "detach": [83, 84], "int8_view_op": 83, "out_data": 83, "out_scal": [83, 89], "notic": 83, "hit": 83, "background": 83, "decomposit": 83, "live": 83, "decomp": 83, "shrink": 83, "author": [83, 87, 88, 89, 90, 91, 92, 93], "pain": 83, "rather": 83, "underli": 83, "worth": 83, "written": 83, "differenti": 83, "nuanc": 83, "longer": [83, 89, 90], "That": 83, "transposit": 83, "got": [83, 89, 93], "propag": [83, 89, 91, 92], "fact": 83, "themselv": [83, 89], "pointwis": [83, 91, 92], "alwai": 83, "were": 83, "might": [83, 84, 89, 93], "unwrap": 83, "dim0": 83, "dim1": 83, "confirm": 83, "quantized_model_module_swap": 83, "quantized_model_subclass": 83, "subclass_param": 83, "out_module_swap": 83, "allclos": 83, "out_compil": 83, "seri": 83, "wa": [83, 90], "comprehens": [84, 91], "e2": 84, "json": 84, "model_typ": [84, 88], "quant_typ": 84, "_type": 84, "_data": 84, "valid": [84, 93], "capabl": [84, 89, 91], "modulefqntoconfig": 84, "int8weightonlyconfig": 84, "self_attn": 84, "q_proj": 84, "k_proj": 84, "mlp": 84, "gate_proj": 84, "_default": 84, "torchaoconfig": 84, "automodelforcausallm": 84, "quantization_config": [84, 92], "1b": 84, "torch_dtyp": 84, "auto": 84, "device_map": 84, "safe_seri": 84, "usernam": 84, "server": 84, "narrow": 84, "copy_": 84, "state": 84, "slice": 84, "chunk": 84, "_apply_fn_to_data": 84, "heavi": 84, "codebas": 84, "fn": 84, "ctx": 84, "new_tensor": 84, "getattr": 84, "__class__": 84, "principl": 84, "torchaobasetensor": 84, "mynewquantconfig": 84, "classvar": 84, "myquantizedtensor": 84, "fbgemmfp8tensor": 84, "tensor_data_attr": 84, "tensor_attribut": 84, "attr": 84, "_to_copi": 84, "clone": 84, "fill_default": 84, "notimplementederror": 84, "_my_quant_transform": 84, "my_quantization_funct": 84, "len": [84, 89, 90, 93], "use_cutlass_kernel": 84, "my_cutlass_linear": 84, "elif": 84, "use_triton_kernel": 84, "my_triton_linear": 84, "disappear": 84, "extrem": 84, "sole": 84, "think": 84, "littl": 84, "world": 84, "explicitli": [84, 93], "spooki": 84, "action": [84, 89, 90], "distanc": 84, "statu": 84, "due": [84, 88, 93], "hub": 84, "team": 84, "2338": 84, "creation": 84, "detect": 84, "illustr": 84, "tutorials_python": 85, "zip": [85, 87], "jupyt": [85, 87], "notebook": [85, 87], "tutorials_jupyt": 85, "sphinx": [85, 87], "firstnam": 87, "lastnam": 87, "prerequisit": [87, 89], "v2": 87, "topic": 87, "rand": [87, 89, 90], "5980": 87, "2736": 87, "4593": 87, "6149": 87, "3079": 87, "3214": 87, "4509": 87, "1836": 87, "3013": 87, "5663": 87, "9567": 87, "6641": 87, "1065": 87, "6193": 87, "8687": 87, "practic": 87, "test": [87, 89, 91], "summar": 87, "takeawai": 87, "link1": 87, "link2": 87, "minut": 87, "ipynb": 87, "daniil": 88, "lyakhov": 88, "aamir": 88, "nazir": 88, "alexand": 88, "suslov": 88, "yamini": 88, "nimmagadda": 88, "kozlov": 88, "subject": [88, 90], "openvinoquant": 88, "unlock": 88, "placement": 88, "significantli": [88, 89, 91, 92], "simplifi": [88, 89, 91, 92], "ux": [88, 89, 91], "torchdynamo": [88, 91, 92, 93], "eager": [88, 89, 90, 91, 92, 93], "mechan": [88, 91, 92], "torchvis": [88, 89, 90, 91, 92, 93], "resnet18": [88, 89, 90, 91, 92], "u": 88, "model_nam": [88, 91, 92], "__dict__": [88, 89, 90, 91, 92], "dummi": [88, 91, 92], "traced_b": [88, 91, 92], "disable_patch": 88, "exported_model": [88, 89, 90, 91, 92], "preset": 88, "scheme": 88, "elu": 88, "prelu": 88, "gelu": 88, "quantizationpreset": 88, "bert": [88, 91], "modeltyp": 88, "ignored_scop": 88, "exclud": 88, "layer_1": 88, "layer_2": 88, "layer_3": 88, "ignoredscop": 88, "conv2d": [88, 89, 90, 91, 92, 93], "regular": [88, 91, 92], "regex": 88, "layer_": 88, "subgraph": [88, 90], "node": [88, 90, 91, 92, 93], "target_devic": 88, "taken": 88, "account": 88, "cpu_spr": 88, "npu": 88, "targetdevic": 88, "fold": [88, 89, 91, 92], "batchnorm": [88, 89, 90, 91, 92], "preced": [88, 89, 91, 92], "prepared_model": [88, 89, 90, 91, 92], "fold_quant": 88, "finish": [88, 91], "comparison": 88, "biascorrect": 88, "discrep": 88, "calibration_load": 88, "dataload": [88, 89, 90], "transform_fn": 88, "data_item": 88, "calibration_dataset": 88, "smooth_quant": 88, "fast_bias_correct": 88, "deploy": [88, 91], "jerri": [89, 91, 93], "zhang": [89, 91, 92, 93], "_export": [89, 90, 91], "14k": 89, "programm": [89, 91, 92], "db": 89, "xnnpack": [89, 90, 93], "xnnpack_quant": [89, 90], "get_symmetric_quantization_config": [89, 90], "xnnpackquant": [89, 90, 93], "prior": 89, "qconfigmap": [89, 93], "backendconfig": [89, 93], "rel": 89, "intent": [89, 93], "qconfig": [89, 93], "3d": [89, 93], "incompat": 89, "great": 89, "ideal": 89, "fake_qu": 89, "hidden": 89, "summari": 89, "thu": 89, "queri": [89, 93], "previous": 89, "embedding_byt": 89, "executorchquant": 89, "concaten": 89, "prone": 89, "cleaner": 89, "composed_quant": 89, "quantization_cap": 89, "concern": 89, "decoupl": 89, "minmax": 89, "freed": 89, "identitc": 89, "entir": [89, 90], "imagenet": [89, 90], "unzip": [89, 90], "data_path": [89, 90], "resnet18_pretrained_float": [89, 90], "sy": [89, 90], "numpi": [89, 90], "np": [89, 90], "resnet": [89, 90, 91], "warn": [89, 90], "filterwarn": [89, 90], "categori": [89, 90], "deprecationwarn": [89, 90], "r": [89, 90], "seed": [89, 90], "manual_se": [89, 90], "191009": [89, 90], "averagemet": [89, 90], "fmt": [89, 90], "val": [89, 90], "avg": [89, 90], "count": [89, 90], "__str__": [89, 90], "fmtstr": [89, 90], "topk": [89, 90], "predict": [89, 90], "maxk": [89, 90], "pred": [89, 90], "eq": [89, 90], "expand_a": [89, 90], "correct_k": [89, 90], "reshap": [89, 90], "mul_": [89, 90], "criterion": [89, 90], "top1": [89, 90], "acc": [89, 90], "top5": [89, 90], "cnt": [89, 90], "acc1": [89, 90], "acc5": [89, 90], "load_model": [89, 90], "model_fil": [89, 90], "weights_onli": [89, 90], "print_size_of_model": [89, 90], "temp": [89, 90], "p": [89, 90], "1e6": [89, 90], "prepare_data_load": [89, 90], "485": [89, 90], "456": [89, 90], "std": [89, 90], "229": [89, 90], "225": [89, 90], "randomresizedcrop": [89, 90], "randomhorizontalflip": [89, 90], "totensor": [89, 90], "dataset_test": [89, 90], "resiz": [89, 90], "centercrop": [89, 90], "train_sampl": [89, 90], "randomsampl": [89, 90], "test_sampl": [89, 90], "sequentialsampl": [89, 90], "train_batch_s": [89, 90], "sampler": [89, 90], "data_loader_test": [89, 90, 91, 92], "eval_batch_s": [89, 90], "saved_model_dir": [89, 90], "float_model_fil": [89, 90], "crossentropyloss": [89, 90], "model_to_quant": [89, 90], "capture_pre_autograd_graph": [89, 90, 91], "dynamic_shap": [89, 90], "export_for_train": 89, "vari": [89, 90, 91, 92], "dynamic_dim": [89, 90], "constraint": [89, 90, 93], "qconfig_opt": 89, "set_object_typ": 89, "set_module_nam": 89, "workload": 89, "themodel": 89, "feedback": 89, "dq": 89, "fp32_op": 89, "qauntiz": 89, "x_int8": 89, "x_scale": 89, "x_zero_point": 89, "weight_int8": 89, "bias_fp32": 89, "output_scal": 89, "output_zero_point": 89, "x_fp32": 89, "quantized_decompos": 89, "dequantize_per_tensor": 89, "x_i8": 89, "x_quant_min": 89, "x_quant_max": 89, "weight_fp32": 89, "weight_i8": 89, "weight_quant_min": 89, "weight_quant_max": 89, "weight_permut": 89, "permute_copi": 89, "out_fp32": 89, "addmm": 89, "out_i8": 89, "quantize_per_tensor": 89, "out_zero_point": 89, "out_quant_min": 89, "out_quant_max": 89, "float32_op": 89, "decompos": 89, "use_reference_represent": 89, "x_int16": 89, "weight_int16": 89, "acc_int32": 89, "out_dtyp": 89, "bias_scal": 89, "bias_int32": 89, "div": 89, "mul": 89, "out_int8": 89, "qmin": 89, "qmax": 89, "date": 89, "unus": 89, "serila": 89, "consult": 89, "exportedprogram": 89, "pt2e_quantized_model_file_path": 89, "resnet18_pt2e_quant": 89, "quantized_ep": 89, "loaded_quantized_ep": 89, "loaded_quantized_model": 89, "diff": 89, "79": 89, "82": 89, "55": 89, "edg": [89, 93], "went": 89, "andrew": 90, "Or": 90, "ptq": [90, 91], "move_exported_model_to_ev": [90, 91], "correctli": 90, "certain": 90, "dropout": 90, "move_exported_model_to_train": 90, "evalu": 90, "jit": 90, "recursivescriptmodul": 90, "train_one_epoch": 90, "ntrain_batch": 90, "avgloss": 90, "5f": 90, "start_tim": 90, "global_avg": 90, "is_qat": [90, 91], "fusion": 90, "batchnorm2d": 90, "_native_batch_norm_legit": 90, "cudnn_batch_norm": 90, "mobilenetv2": 90, "recompil": 90, "consolid": 90, "epoch": 90, "far": 90, "num_epoch": 90, "num_train_batch": 90, "num_eval_batch": 90, "num_observer_update_epoch": 90, "num_batch_norm_update_epoch": 90, "num_epochs_between_ev": 90, "nepoch": 90, "subseq": 90, "disable_observ": 90, "freez": [90, 91, 92], "bn": 90, "running_mean": 90, "running_var": 90, "momentum": 90, "new_arg": 90, "wish": 90, "prepared_model_copi": 90, "neval_batch": 90, "paus": 90, "resum": 90, "fail": [90, 93], "checkpoint_path": 90, "checkpoint_": 90, "behav": 90, "incorrectli": 90, "lesli": [91, 93], "fang": [91, 93], "weiwen": [91, 93], "xia": [91, 93], "jiong": [91, 93], "gong": [91, 93], "cnn": 91, "rnn": 91, "outstand": 91, "fourth": 91, "spr": 91, "xeon": 91, "processor": 91, "boost": 91, "contigu": [91, 92], "channels_last": [91, 92], "onednn": [91, 92], "assum": [91, 93], "word": 91, "satur": 91, "invok": 91, "addition": [91, 92], "pure": 91, "seamless": 91, "dedic": 91, "scenario": [91, 92], "plai": [91, 92], "convolut": [91, 92, 93], "absenc": [91, 92], "enhanc": [91, 92], "mirror": [91, 92], "autocast": [91, 92], "context": [91, 92], "device_typ": [91, 92], "turn": [91, 92], "cpp": 91, "qconvolut": [91, 92], "qlinear": [91, 92], "presenc": [91, 92], "pair": [91, 92], "remain": [91, 92], "conting": [91, 92], "qmaxpool2d": [91, 92], "torchinductor_freez": [91, 92], "example_x86inductorquantizer_pytorch_2_1": 91, "torchbench": 91, "measur": 91, "proven": 91, "depth": 91, "1000": 91, "shoud": 91, "example_x86inductorquantizer_qat": 91, "yan": 92, "zhiwei": 92, "wang": 92, "eikan": 92, "liangang": 92, "liu": 92, "river": 92, "cui": 92, "yifeng": 92, "xpuinductorquant": 92, "pip3": 92, "torchaudio": 92, "xpu_inductor_quantizer_exampl": 92, "xpu_inductor_quant": 92, "xpuiq": 92, "resnet18_weight": 92, "get_default_xpu_inductor_quantization_config": 92, "sign": 92, "wherea": 92, "histogramobserv": [92, 93], "perchannelminmaxobserv": 92, "quantizationspec": [92, 93], "quantizationconfig": [92, 93], "type_check": 92, "observerorfakequantizeconstructor": 92, "get_xpu_inductor_symm_quantization_config": 92, "extra_arg": 92, "act_observer_or_fake_quant_ctr": 92, "act_quantization_spec": [92, 93], "qscheme": [92, 93], "per_tensor_symmetr": [92, 93], "observer_or_fake_quant_ctr": [92, 93], "with_arg": [92, 93], "weight_observer_or_fake_quant_ctr": 92, "weight_quantization_spec": [92, 93], "per_channel_symmetr": 92, "ch_axi": 92, "oc": 92, "ic": 92, "kh": 92, "kw": 92, "conv": [92, 93], "bias_quantization_spec": 92, "amp": 92, "indcutor": 92, "kimish": 93, "patel": 93, "made": 93, "explicit": 93, "quantiat": 93, "encod": 93, "qnnpackquant": 93, "convei": 93, "quantizationannot": 93, "furthermor": 93, "minmaxobserv": 93, "input_qspec_map": 93, "output_qspec": 93, "_annot": 93, "conclud": 93, "matcher": 93, "get_source_partit": 93, "add_partit": 93, "gm": 93, "itertool": 93, "chain": 93, "add_nod": 93, "output_nod": 93, "per_tensor_affin": 93, "input_act_qspec": 93, "output_act_qspec": 93, "input_act0": 93, "input_act1": 93, "quantization_annot": 93, "phase": 93, "substitut": 93, "among": 93, "sharedquantizationspec": 93, "maxpool": 93, "average_pool": 93, "concat": 93, "edgeornod": 93, "transit": 93, "spec": 93, "conv1": 93, "conv2": 93, "fed": 93, "cat": 93, "conv1_out": 93, "conv2_out": 93, "qspec1": 93, "cat_input0": 93, "cat_input1": 93, "implicitli": 93, "therefor": 93, "ob": 93, "consum": 93, "rewrit": 93, "share_qparams_with_input_act0_qspec": 93, "known": 93, "beforehand": 93, "sigmoid": 93, "fixedqparamsquantizationspec": 93, "act_qspec": 93, "sigmoid_nod": 93, "input_act": 93, "derivedquantizationspec": 93, "derive_qparams_fn": 93, "observerorfakequant": 93, "observerbas": 93, "fakequantizebas": 93, "heurist": 93, "obejct": 93, "obs_or_fq": 93, "fq": 93, "act_obs_or_fq": 93, "weight_obs_or_fq": 93, "act_zp": 93, "weight_zp": 93, "bias_qspec": 93, "derived_from": 93, "backendquant": 93, "get_input_act_qspec": 93, "get_output_act_qspec": 93, "get_weight_qspec": 93, "get_bias_qspec": 93, "intermedi": 93, "call_funct": 93, "relu_": 93, "relu_nod": 93, "maybe_conv_nod": 93, "conv1d": 93, "unexpect": 93, "recognz": 93, "subgraphmatch": 93, "conv_relu_pattern": 93, "name_node_map": 93, "input_nod": 93, "weight_nod": 93, "bias_nod": 93, "caveat": 93, "exhaust": 93, "2d": 93, "4d": 93, "symbol": 93, "outcom": 93}, "objects": {"torchao.dtypes": [[8, 0, 1, "", "AffineQuantizedTensor"], [9, 0, 1, "", "BlockSparseLayout"], [10, 0, 1, "", "CutlassInt4PackedLayout"], [11, 0, 1, "", "CutlassSemiSparseLayout"], [12, 0, 1, "", "Float8Layout"], [13, 0, 1, "", "Int4CPULayout"], [14, 0, 1, "", "Layout"], [15, 0, 1, "", "MarlinQQQLayout"], [16, 0, 1, "", "MarlinQQQTensor"], [17, 0, 1, "", "MarlinSparseLayout"], [18, 0, 1, "", "NF4Tensor"], [19, 0, 1, "", "PlainLayout"], [20, 0, 1, "", "SemiSparseLayout"], [21, 0, 1, "", "TensorCoreTiledLayout"], [22, 0, 1, "", "UintxLayout"], [23, 2, 1, "", "to_affine_quantized_floatx"], [24, 2, 1, "", "to_affine_quantized_floatx_static"], [25, 2, 1, "", "to_affine_quantized_fpx"], [26, 2, 1, "", "to_affine_quantized_intx"], [27, 2, 1, "", "to_affine_quantized_intx_static"], [28, 2, 1, "", "to_marlinqqq_quantized_intx"], [29, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[8, 1, 1, "", "dequantize"], [8, 1, 1, "", "from_hp_to_floatx"], [8, 1, 1, "", "from_hp_to_floatx_static"], [8, 1, 1, "", "from_hp_to_fpx"], [8, 1, 1, "", "from_hp_to_intx"], [8, 1, 1, "", "from_hp_to_intx_static"], [8, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[17, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[18, 1, 1, "", "convert_to_norm_float_weight"], [18, 1, 1, "", "dequantize"], [18, 1, 1, "", "dequantize_scalers"], [18, 1, 1, "", "double_quantize_scalers"], [18, 1, 1, "", "get_original_weight"], [18, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[30, 0, 1, "", "CastConfig"], [31, 0, 1, "", "Float8LinearConfig"], [32, 0, 1, "", "ScalingGranularity"], [33, 0, 1, "", "ScalingType"], [34, 2, 1, "", "convert_to_float8_training"], [35, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[31, 1, 1, "", "from_recipe_name"]], "torchao.quantization": [[36, 0, 1, "", "FPXWeightOnlyConfig"], [37, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [38, 0, 1, "", "Float8StaticActivationFloat8WeightConfig"], [39, 0, 1, "", "Float8WeightOnlyConfig"], [40, 0, 1, "", "GemliteUIntXWeightOnlyConfig"], [41, 0, 1, "", "Int4WeightOnlyConfig"], [42, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [43, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [44, 0, 1, "", "Int8WeightOnlyConfig"], [45, 0, 1, "", "MappingType"], [46, 0, 1, "", "TorchAODType"], [47, 0, 1, "", "UIntXWeightOnlyConfig"], [48, 0, 1, "", "ZeroPointDomain"], [49, 2, 1, "", "autoquant"], [50, 2, 1, "", "choose_qparams_affine"], [51, 2, 1, "", "choose_qparams_affine_with_min_max"], [52, 2, 1, "", "dequantize_affine"], [53, 2, 1, "", "int_scaled_matmul"], [62, 2, 1, "", "quantize_"], [63, 2, 1, "", "quantize_affine"], [64, 2, 1, "", "safe_int_mm"], [65, 2, 1, "", "smooth_fq_linear_to_inference"], [66, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [67, 2, 1, "", "to_linear_activation_quantized"]], "torchao.quantization.qat": [[54, 0, 1, "", "ComposableQATQuantizer"], [55, 0, 1, "", "FakeQuantizeConfig"], [56, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [57, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [58, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [59, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [60, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [61, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizeConfig": [[55, 3, 1, "", "group_size"], [55, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[57, 1, 1, "", "convert"], [57, 1, 1, "", "prepare"]], "torchao": [[5, 4, 0, "-", "sparsity"]], "torchao.sparsity": [[68, 0, 1, "", "PerChannelNormObserver"], [69, 0, 1, "", "WandaSparsifier"], [70, 2, 1, "", "apply_fake_sparsity"], [71, 5, 1, "", "semi_sparse_weight"], [72, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[68, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[69, 1, 1, "", "prepare"], [69, 1, 1, "", "squash_mask"], [69, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:module", "5": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "module", "Python module"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 73, 75, 76, 84], "dtype": [0, 7, 76], "layout": [0, 6, 14, 76], "tensor": [0, 6, 76, 82, 83, 84, 93], "subclass": [0, 6, 76, 83, 84], "quantiz": [0, 4, 62, 73, 76, 77, 81, 82, 83, 84, 88, 89, 90, 91, 92, 93], "techniqu": 0, "float8": [1, 75], "main": [1, 4], "train": [1, 76, 88, 89, 90, 91, 92], "api": [1, 2, 4, 73, 75, 93], "other": [1, 4, 6, 76], "type": 1, "refer": [2, 73], "python": 2, "kernel": [3, 6, 74, 76, 84], "infer": 4, "quantize_": 4, "qat": [4, 90], "primit": [4, 76], "sparsiti": [5, 80], "contributor": 6, "guid": [6, 77, 84], "gener": 6, "extend": 6, "ad": [6, 76, 84], "effici": [6, 76], "custom": 6, "triton": 6, "hand": 6, "written": 6, "dispatch": [6, 84], "tensorimpl": [6, 76], "flow": [6, 76, 78, 84, 93], "us": [6, 93], "torch": [6, 88, 89, 90], "compil": [6, 84, 88], "perform": [6, 74, 89], "serial": [6, 78, 84], "featur": 6, "support": [6, 76, 84], "function": [6, 76, 89, 90], "compos": 6, "test": 6, "microbenchmark": 6, "model": [6, 75, 76, 78, 84, 88, 89, 90], "benchmark": 6, "eval": [6, 89], "affinequantizedtensor": 8, "blocksparselayout": 9, "cutlassint4packedlayout": 10, "cutlasssemisparselayout": 11, "float8layout": 12, "int4cpulayout": 13, "marlinqqqlayout": 15, "marlinqqqtensor": 16, "marlinsparselayout": 17, "nf4tensor": 18, "plainlayout": 19, "semisparselayout": 20, "tensorcoretiledlayout": 21, "uintxlayout": 22, "to_affine_quantized_floatx": 23, "to_affine_quantized_floatx_stat": 24, "to_affine_quantized_fpx": 25, "to_affine_quantized_intx": 26, "to_affine_quantized_intx_stat": 27, "to_marlinqqq_quantized_intx": 28, "to_nf4": 29, "castconfig": 30, "float8linearconfig": 31, "scalinggranular": 32, "scalingtyp": 33, "convert_to_float8_train": 34, "precompute_float8_dynamic_scale_for_fsdp": 35, "fpxweightonlyconfig": 36, "float8dynamicactivationfloat8weightconfig": 37, "float8staticactivationfloat8weightconfig": 38, "float8weightonlyconfig": 39, "gemliteuintxweightonlyconfig": 40, "int4weightonlyconfig": 41, "int8dynamicactivationint4weightconfig": 42, "int8dynamicactivationint8weightconfig": 43, "int8weightonlyconfig": 44, "mappingtyp": 45, "torchaodtyp": 46, "uintxweightonlyconfig": 47, "zeropointdomain": 48, "autoqu": 49, "choose_qparams_affin": 50, "choose_qparams_affine_with_min_max": 51, "dequantize_affin": 52, "int_scaled_matmul": 53, "composableqatquant": 54, "fakequantizeconfig": 55, "fromintxquantizationawaretrainingconfig": 56, "int4weightonlyembeddingqatquant": 57, "int4weightonlyqatquant": 58, "int8dynactint4weightqatquant": 59, "intxquantizationawaretrainingconfig": 60, "initialize_fake_quant": 61, "quantize_affin": 63, "safe_int_mm": 64, "smooth_fq_linear_to_infer": 65, "swap_linear_with_smooth_fq_linear": 66, "to_linear_activation_quant": 67, "perchannelnormobserv": 68, "wandasparsifi": 69, "apply_fake_spars": 70, "semi_sparse_weight": 71, "sparsifi": 72, "welcom": 73, "document": 73, "get": 73, "start": [73, 77], "develop": 73, "note": [73, 75, 93], "eager": 73, "tutori": [73, 87], "pt2e": [73, 93], "pretrain": 75, "torchtitan": 75, "prerequisit": [75, 88, 91, 92, 93], "rowwis": 75, "scale": 75, "tensorwis": 75, "pick": 75, "recip": 75, "import": [75, 89, 90], "directli": [75, 93], "convers": 75, "overview": [76, 80, 87], "basic": 76, "current": 76, "placehold": 76, "pytorch": [76, 77, 88, 89, 90, 91, 92, 93], "implement": [76, 83, 84], "oper": [76, 83, 84, 93], "integr": [76, 84], "nativ": 76, "factori": 76, "op": 76, "deriv": [76, 93], "algorithm": 76, "weight": 76, "onli": 76, "dynam": 76, "activ": 76, "static": [76, 81], "insert": 76, "observ": 76, "how": [76, 89, 90, 93], "defin": [76, 89, 90], "modul": [76, 83, 84], "add": [76, 84], "calibr": [76, 81, 89], "awar": [76, 90, 91], "low": 76, "bit": 76, "optim": [76, 78], "case": 76, "studi": 76, "int4": 76, "work": 76, "dure": 76, "execut": 76, "save": [76, 89, 90], "load": [76, 89, 90], "quick": 77, "first": 77, "exampl": [77, 84, 93], "2": [77, 84, 88, 89, 90, 91, 92, 93], "export": [77, 88, 89, 90, 91, 92, 93], "next": [77, 83], "step": [77, 83, 84, 87], "deseri": 78, "what": [78, 83], "happen": 78, "when": 78, "an": 78, "comput": [79, 86], "time": [79, 86], "goal": 80, "design": 80, "context": 80, "prune": 80, "configur": [80, 84, 89, 90], "criteria": 80, "strategi": 80, "pattern": [80, 93], "phase": 81, "write": [82, 83, 93], "your": [82, 83, 84], "own": [82, 83], "advanc": 82, "ar": 83, "swap": 83, "which": 83, "should": 83, "we": 83, "compar": 83, "output": 83, "vllm": 84, "architectur": 84, "usag": 84, "system": 84, "1": [84, 88, 91, 92, 93], "huggingfac": 84, "class": 84, "3": [84, 88, 91, 92, 93], "level": 84, "serv": 84, "new": 84, "method": 84, "minim": 84, "requir": 84, "compat": 84, "why": 84, "creat": 84, "regist": 84, "s": 84, "kei": 84, "detail": 84, "hardwar": 84, "specif": [84, 89, 90], "linear": 84, "benefit": 84, "trade": 84, "off": 84, "share": [84, 93], "safetensor": 84, "diagram": 84, "high": 84, "transform": 84, "point": 84, "bring": 84, "extern": 84, "templat": 87, "option": [87, 88], "addit": 87, "exercis": 87, "conclus": [87, 88, 89, 90, 91, 92, 93], "further": 87, "read": 87, "openvino": 88, "backend": [88, 89, 90, 91, 92], "introduct": [88, 91, 92, 93], "post": [88, 89, 91, 92], "nncf": 88, "instal": 88, "captur": [88, 91, 92], "fx": [88, 91, 92], "graph": [88, 91, 92], "appli": [88, 91, 92], "lower": [88, 89, 91, 92], "represent": 88, "4": [88, 93], "improv": 88, "metric": 88, "motiv": [89, 93], "helper": [89, 90], "prepar": [89, 90], "dataset": [89, 90], "set": 89, "mode": 89, "convert": [89, 90], "check": 89, "size": 89, "accuraci": 89, "evalu": 89, "debug": 89, "loop": 90, "checkpoint": 90, "x86": 91, "through": [91, 92], "inductor": [91, 92], "intel": 92, "gpu": 92, "annot": 93, "common": 93, "param": 93, "fix": 93, "paramet": 93, "5": 93, "A": 93, "toi": 93, "resnet18": 93, "ir": 93, "problem": 93, "match": 93, "aten": 93, "recommend": 93, "subgraphmatcherwithnamenodemap": 93}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})