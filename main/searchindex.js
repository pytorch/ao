Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_float8", "api_ref_intro", "api_ref_kernel", "api_ref_qat", "api_ref_quantization", "api_ref_sparsity", "api_ref_utils", "benchmarking_api_guide", "benchmarking_user_guide", "contributor_guide", "dtypes", "finetuning", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.CutlassSemiSparseLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_nf4", "generated/torchao.float8.CastConfig", "generated/torchao.float8.Float8LinearConfig", "generated/torchao.float8.ScalingGranularity", "generated/torchao.float8.ScalingType", "generated/torchao.float8.convert_to_float8_training", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "generated/torchao.prototype.dtypes.BlockSparseLayout", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout", "generated/torchao.prototype.dtypes.UintxLayout", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Float8WeightOnlyConfig", "generated/torchao.quantization.Int4WeightOnlyConfig", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "generated/torchao.quantization.Int8WeightOnlyConfig", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.qat.ComposableQATQuantizer", "generated/torchao.quantization.qat.FakeQuantizeConfigBase", "generated/torchao.quantization.qat.FakeQuantizedEmbedding", "generated/torchao.quantization.qat.FakeQuantizedLinear", "generated/torchao.quantization.qat.FakeQuantizerBase", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "generated/torchao.quantization.qat.Float8FakeQuantizer", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "generated/torchao.quantization.qat.IntxFakeQuantizer", "generated/torchao.quantization.qat.QATConfig", "generated/torchao.quantization.qat.QATStep", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "generated/torchao.quantization.qat.initialize_fake_quantizers", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_.common.KernelPreference", "generated/torchao.quantization.quantize_.common.PackingFormat", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.safe_int_mm", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "generated/torchao.utils.TorchAOBaseTensor", "index", "performant_kernels", "pretraining", "quantization_overview", "quick_start", "serialization", "serving", "sparsity", "static_quantization", "subclass_advanced", "subclass_basic", "torchao_hf_integration", "torchao_vllm_integration", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "tutorials_source/pt2e_quant_openvino_inductor", "tutorials_source/pt2e_quant_ptq", "tutorials_source/pt2e_quant_qat", "tutorials_source/pt2e_quant_x86_inductor", "tutorials_source/pt2e_quant_xpu_inductor", "tutorials_source/pt2e_quantizer"], "filenames": ["api_ref_dtypes.rst", "api_ref_float8.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_qat.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "api_ref_utils.rst", "benchmarking_api_guide.md", "benchmarking_user_guide.md", "contributor_guide.rst", "dtypes.rst", "finetuning.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.CutlassSemiSparseLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.float8.CastConfig.rst", "generated/torchao.float8.Float8LinearConfig.rst", "generated/torchao.float8.ScalingGranularity.rst", "generated/torchao.float8.ScalingType.rst", "generated/torchao.float8.convert_to_float8_training.rst", "generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "generated/torchao.prototype.dtypes.BlockSparseLayout.rst", "generated/torchao.prototype.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout.rst", "generated/torchao.prototype.dtypes.UintxLayout.rst", "generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Float8WeightOnlyConfig.rst", "generated/torchao.quantization.Int4WeightOnlyConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt4WeightConfig.rst", "generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "generated/torchao.quantization.Int8WeightOnlyConfig.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "generated/torchao.quantization.qat.FakeQuantizerBase.rst", "generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "generated/torchao.quantization.qat.QATConfig.rst", "generated/torchao.quantization.qat.QATStep.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_.common.KernelPreference.rst", "generated/torchao.quantization.quantize_.common.PackingFormat.rst", "generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "generated/torchao.utils.TorchAOBaseTensor.rst", "index.rst", "performant_kernels.rst", "pretraining.rst", "quantization_overview.rst", "quick_start.rst", "serialization.rst", "serving.rst", "sparsity.rst", "static_quantization.rst", "subclass_advanced.rst", "subclass_basic.rst", "torchao_hf_integration.md", "torchao_vllm_integration.md", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "tutorials_source/pt2e_quant_openvino_inductor.rst", "tutorials_source/pt2e_quant_ptq.rst", "tutorials_source/pt2e_quant_qat.rst", "tutorials_source/pt2e_quant_x86_inductor.rst", "tutorials_source/pt2e_quant_xpu_inductor.rst", "tutorials_source/pt2e_quantizer.rst"], "titles": ["torchao.dtypes", "torchao.float8", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.utils", "Benchmarking API Guide", "Benchmarking User Guide", "Contributor Guide", "Dtypes", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "AffineQuantizedTensor", "CutlassSemiSparseLayout", "Float8Layout", "Int4CPULayout", "Layout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_nf4", "CastConfig", "Float8LinearConfig", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "BlockSparseLayout", "CutlassInt4PackedLayout", "Int8DynamicActInt4WeightCPULayout", "UintxLayout", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt4WeightConfig", "Int8DynamicActivationInt8WeightConfig", "Int8WeightOnlyConfig", "MappingType", "TorchAODType", "choose_qparams_affine", "choose_qparams_affine_with_min_max", "dequantize_affine", "int_scaled_matmul", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "quantize_affine", "safe_int_mm", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "Welcome to the torchao Documentation", "Performant Kernels", "(Part 1) Pre-training with float8", "Quantization Overview", "Quick Start Guide", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Sparsity Overview", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "&lt;no title&gt;", "Computation times", "Template Tutorial", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization"], "terms": {"thi": [2, 8, 9, 10, 12, 13, 18, 19, 20, 32, 36, 37, 40, 41, 42, 43, 44, 46, 47, 48, 52, 57, 58, 63, 65, 67, 68, 70, 71, 74, 77, 78, 79, 81, 82, 83, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108], "section": [2, 10, 90, 94, 99, 104, 105, 108], "introduc": [2, 12, 103, 104, 106, 107, 108], "dive": 2, "detail": [2, 8, 10, 12, 40, 89, 90, 91, 93, 94, 95, 97, 103, 104, 105, 106], "how": [2, 4, 10, 12, 13, 17, 36, 38, 42, 44, 46, 63, 75, 76, 79, 87, 89, 91, 92, 93, 94, 95, 97, 98, 99, 103, 106, 107], "integr": [2, 10, 87, 89, 92, 93, 94, 97, 106, 108], "pytorch": [2, 8, 12, 13, 16, 45, 63, 87, 89, 90, 93, 94, 97, 99, 102], "optim": [2, 10, 12, 32, 74, 87, 89, 94, 97, 103, 105, 106, 107], "your": [2, 8, 10, 12, 87, 89, 90, 91, 93, 94, 98, 104, 105, 106, 107, 108], "machin": [2, 105], "learn": [2, 63, 91, 94, 102, 104, 106, 107, 108], "model": [2, 12, 32, 41, 50, 55, 58, 59, 60, 61, 62, 65, 69, 74, 82, 83, 85, 91, 94, 95, 97, 106, 107, 108], "dtype": [2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 39, 45, 46, 47, 48, 52, 53, 55, 56, 59, 60, 61, 63, 67, 68, 70, 71, 78, 79, 85, 87, 89, 91, 92, 93, 95, 97, 98, 99, 104, 106, 107, 108], "quantiz": [2, 8, 10, 13, 14, 15, 16, 18, 20, 21, 22, 24, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 85, 89, 92, 94], "sparsiti": [2, 8, 12, 14, 20, 81, 82, 83, 84, 85, 87, 89, 92, 93], "tba": [3, 11, 88], "For": [4, 8, 10, 12, 13, 40, 63, 90, 91, 92, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108], "full": [4, 12, 91, 95, 98, 102, 103, 105], "exampl": [4, 8, 10, 12, 13, 32, 44, 50, 52, 53, 58, 62, 63, 65, 69, 74, 75, 82, 85, 86, 90, 92, 93, 94, 95, 97, 100, 102, 103, 104, 105, 106, 107], "us": [4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 23, 25, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 55, 58, 62, 63, 65, 70, 71, 75, 76, 79, 82, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107], "our": [4, 10, 12, 18, 89, 91, 93, 94, 95, 97, 104, 105], "pleas": [4, 9, 10, 12, 13, 58, 62, 87, 90, 91, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108], "refer": [4, 8, 12, 13, 65, 71, 89, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106], "readm": [4, 8, 12, 87, 91, 94], "tutori": [8, 10, 12, 13, 89, 90, 91, 93, 94, 95, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108], "you": [8, 9, 10, 12, 63, 82, 86, 89, 90, 91, 92, 93, 94, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108], "through": [8, 10, 12, 47, 52, 53, 87, 90, 91, 93, 95, 97, 99, 102, 103, 104, 108], "torchao": [8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91, 92, 93, 94, 95, 97, 98, 103, 104, 105, 106, 107], "framework": [8, 10, 12, 89, 93, 103], "The": [8, 10, 12, 13, 17, 31, 33, 36, 37, 39, 49, 65, 74, 80, 82, 89, 90, 91, 92, 93, 94, 97, 98, 99, 103, 104, 105, 106, 107, 108], "contain": [8, 77, 78, 94, 97, 105, 108], "new": [8, 12, 13, 86, 89, 90, 95, 97, 104, 105, 106, 108], "architectur": [8, 87, 93, 94, 103, 104, 106, 107], "micro": 8, "current": [8, 37, 40, 41, 55, 56, 65, 74, 82, 85, 89, 90, 91, 94, 97, 98, 99, 104, 105, 107], "support": [8, 12, 37, 38, 40, 41, 55, 62, 63, 65, 75, 77, 78, 85, 89, 90, 91, 92, 93, 94, 97, 103, 104, 105, 106, 107, 108], "which": [8, 10, 12, 36, 65, 70, 75, 89, 90, 92, 93, 94, 95, 99, 103, 104, 105, 106, 107, 108], "can": [8, 10, 12, 13, 21, 37, 44, 50, 63, 74, 75, 79, 86, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108], "quantize_": [8, 10, 12, 58, 62, 65, 74, 75, 76, 77, 78, 85, 87, 90, 91, 92, 93, 95], "sparsity_": 8, "function": [8, 12, 13, 21, 31, 52, 57, 67, 72, 73, 74, 81, 82, 83, 85, 86, 89, 90, 91, 92, 94, 95, 97, 99, 103, 108], "To": [8, 10, 12, 13, 71, 89, 90, 91, 92, 93, 94, 95, 99, 104, 105, 106, 108], "correspond": [8, 12, 58, 65, 74, 90, 92, 94, 97, 107, 108], "string": [8, 28, 63, 82, 86], "string_to_config": 8, "microbenchmark": 8, "util": [8, 10, 86, 87, 90, 91, 92, 97, 99, 103, 104, 105, 106, 107, 108], "py": [8, 10, 86, 101, 102, 106, 107], "def": [8, 10, 12, 77, 85, 86, 89, 90, 91, 92, 95, 97, 99, 103, 104, 105, 106, 107, 108], "option": [8, 10, 13, 15, 22, 24, 25, 27, 28, 31, 37, 40, 42, 43, 46, 47, 48, 52, 53, 55, 56, 60, 62, 63, 65, 67, 68, 74, 75, 78, 79, 82, 85, 86, 89, 90, 91, 98, 99, 104, 105, 106, 107, 108], "str": [8, 28, 31, 63, 65, 74, 82, 85, 86, 89, 97, 99, 107], "kwarg": [8, 10, 13, 52, 53, 54, 55, 59, 63, 68, 78, 81, 82, 83, 86, 90, 97, 99], "aobaseconfig": [8, 65, 74, 85, 95, 99], "code": [8, 10, 89, 90, 91, 93, 94, 95, 97, 100, 102, 104, 105, 106, 107, 108], "elif": [8, 99], "my_new_quant": 8, "If": [8, 9, 10, 12, 13, 15, 31, 37, 42, 43, 49, 62, 63, 65, 80, 82, 86, 90, 93, 94, 97, 104, 105], "addit": [8, 12, 17, 19, 86, 89, 90, 94, 97, 98, 103, 104, 107, 108], "inform": [8, 13, 37, 90, 93, 94, 99, 103, 104], "need": [8, 10, 12, 37, 52, 57, 67, 76, 77, 78, 81, 82, 86, 90, 92, 93, 94, 97, 99, 104, 105, 106, 108], "pass": [8, 31, 42, 47, 52, 53, 57, 65, 67, 81, 86, 90, 95, 97, 99, 105, 108], "process": [8, 12, 17, 19, 21, 36, 90, 94, 102, 103, 107], "here": [8, 9, 13, 65, 71, 79, 90, 91, 92, 93, 95, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108], "return": [8, 10, 12, 13, 18, 31, 49, 63, 74, 80, 85, 86, 89, 90, 91, 92, 95, 97, 99, 103, 104, 105, 106, 107, 108], "mynewquantizationconfig": 8, "my_new_spars": 8, "mynewsparsityconfig": 8, "rest": [8, 76, 97, 105], "now": [8, 10, 12, 38, 40, 41, 46, 89, 90, 91, 94, 95, 97, 98, 103, 104, 106, 108], "we": [8, 10, 12, 13, 18, 40, 42, 44, 46, 47, 48, 62, 63, 65, 71, 74, 79, 85, 86, 89, 90, 91, 92, 93, 94, 95, 98, 99, 103, 104, 105, 106, 107, 108], "throughout": 8, "note": [8, 10, 12, 40, 50, 62, 71, 82, 86, 90, 91, 93, 94, 97, 99, 105, 106, 107], "input": [8, 10, 13, 18, 20, 28, 31, 32, 46, 47, 48, 49, 65, 69, 74, 79, 80, 82, 85, 89, 90, 91, 93, 95, 97, 103, 104, 105, 106, 107, 108], "paramet": [8, 12, 13, 17, 18, 23, 25, 31, 32, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 55, 56, 63, 65, 68, 70, 71, 74, 79, 80, 82, 85, 86, 89, 90, 92, 93, 94, 97, 99, 103, 104], "like": [8, 10, 12, 17, 37, 89, 90, 91, 92, 94, 97, 98, 99, 103, 104, 105, 106, 107, 108], "bit": [8, 12, 26, 36, 64, 93, 97, 98, 99, 104, 106, 107], "width": [8, 36, 64], "group": [8, 10, 12, 37, 38, 41, 43, 55, 59, 60, 61, 63, 67, 68, 70, 71, 75, 91], "size": [8, 10, 13, 18, 33, 40, 41, 43, 46, 48, 63, 79, 89, 91, 92, 93, 94, 95, 97, 99, 105], "etc": [8, 10, 37, 52, 53, 76, 78, 90, 103, 108], "them": [8, 12, 52, 57, 67, 81, 108], "append": [8, 94, 104, 105], "config": [8, 12, 28, 31, 37, 39, 40, 42, 51, 52, 53, 54, 56, 57, 58, 62, 63, 64, 65, 74, 82, 85, 90, 91, 93, 94, 95, 98, 99, 104, 106, 107], "gemliteuintxweightonlyconfig": 8, "gemlitewo": 8, "bit_width": 8, "group_siz": [8, 12, 38, 40, 41, 43, 52, 53, 55, 59, 62, 63, 65, 67, 68, 74, 91, 98, 99], "system": [8, 10, 76, 93], "model_architectur": 8, "type": [8, 10, 12, 13, 18, 28, 29, 30, 31, 36, 37, 39, 40, 41, 42, 44, 45, 49, 63, 66, 74, 75, 76, 77, 78, 79, 80, 86, 87, 90, 92, 93, 94, 97, 99, 103, 104, 106, 107, 108], "defin": [8, 10, 17, 29, 36, 52, 57, 67, 81, 82, 86, 90, 91, 94, 95, 97, 99, 103, 106, 107, 108], "class": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 75, 76, 77, 81, 82, 86, 91, 92, 95, 97, 104, 105, 106, 108], "mycustommodel": 8, "torch": [8, 12, 13, 18, 23, 28, 31, 36, 37, 39, 46, 48, 49, 52, 53, 55, 56, 59, 60, 61, 62, 63, 65, 67, 68, 70, 71, 74, 75, 79, 80, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 106, 107, 108], "nn": [8, 10, 12, 28, 31, 50, 55, 59, 62, 65, 74, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 99, 104, 105, 106, 108], "modul": [8, 10, 12, 28, 29, 30, 31, 32, 44, 45, 50, 52, 54, 55, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 81, 82, 85, 89, 90, 91, 92, 95, 99, 103, 104, 105, 106, 107, 108], "__init__": [8, 12, 86, 91, 92, 95, 97, 99, 104, 105, 106], "self": [8, 12, 13, 86, 91, 92, 95, 97, 99, 104, 105, 106], "input_dim": 8, "output_dim": 8, "bfloat16": [8, 18, 55, 60, 70, 79, 89, 90, 91, 92, 93, 94, 95, 98, 99, 106, 107], "super": [8, 12, 91, 92, 95, 97, 104, 105, 106], "layer1": 8, "linear": [8, 10, 12, 28, 31, 37, 38, 39, 41, 42, 43, 50, 53, 55, 60, 61, 62, 65, 70, 71, 72, 73, 74, 83, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 103, 104, 105, 106, 108], "512": [8, 89], "bia": [8, 12, 53, 70, 71, 90, 91, 92, 95, 97, 99, 105, 108], "fals": [8, 12, 13, 24, 28, 40, 42, 46, 52, 53, 61, 62, 63, 65, 67, 68, 70, 71, 82, 89, 90, 91, 92, 93, 95, 97, 98, 99, 103, 104, 105, 107, 108], "activ": [8, 12, 37, 41, 42, 52, 53, 55, 61, 62, 63, 65, 71, 77, 78, 82, 87, 91, 93, 94, 95, 98, 99, 103, 106, 107, 108], "relu": [8, 91, 103, 108], "layer2": 8, "forward": [8, 42, 52, 53, 57, 64, 67, 70, 81, 91, 92, 94, 95, 97, 99, 104, 105, 106], "x": [8, 52, 53, 57, 64, 67, 89, 91, 92, 93, 95, 97, 99, 102, 103, 104, 105, 106, 107], "updat": [8, 87, 91, 92, 94, 104, 105, 108], "create_model_and_input_data": 8, "handl": [8, 10, 20, 21], "model_typ": [8, 12, 99, 103], "m": [8, 10, 12, 74, 85, 89, 91, 92, 93, 95, 97, 104, 105, 106], "int": [8, 12, 13, 18, 21, 22, 23, 24, 25, 26, 33, 36, 37, 39, 40, 41, 42, 43, 46, 47, 48, 52, 53, 55, 59, 60, 61, 63, 67, 68, 70, 71, 74, 79, 82, 86, 91, 95, 97, 99], "k": [8, 10, 80, 91, 92, 95, 97, 104, 105], "n": [8, 10, 12, 91, 92, 95, 97, 104, 105, 108], "high_precision_dtyp": 8, "devic": [8, 10, 12, 13, 67, 70, 71, 74, 80, 89, 91, 92, 93, 95, 97, 99, 103, 104, 105, 106, 107], "cuda": [8, 10, 12, 13, 74, 89, 91, 92, 93, 94, 95, 97, 98, 105], "my_custom_model": 8, "input_data": 8, "randn": [8, 12, 13, 53, 89, 91, 92, 95, 97, 103, 104, 105, 106, 107], "when": [8, 10, 12, 13, 19, 46, 48, 65, 79, 86, 89, 90, 93, 94, 95, 98, 99, 103, 104, 105, 106, 107, 108], "ad": [8, 12, 13, 48, 82, 86, 90, 94, 95, 97, 105], "dimens": [8, 10, 13, 36, 46, 48, 49, 79, 89, 90, 97, 99, 104, 105], "ensur": [8, 93, 105], "convent": 8, "where": [8, 20, 44, 47, 59, 60, 61, 90, 94, 99, 108], "batch": [8, 93, 95, 105], "sequenc": 8, "length": 8, "featur": [8, 12, 13, 97, 103, 106, 107], "data": [8, 12, 13, 17, 33, 36, 37, 39, 40, 42, 47, 76, 86, 87, 90, 92, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108], "typic": [8, 12, 18, 19, 90, 91, 92, 95, 99, 108], "compat": [8, 10, 63, 91], "work": [8, 10, 12, 20, 89, 92, 94, 97, 98, 99, 104, 105, 106], "cpu": [8, 10, 13, 16, 35, 92, 94, 95, 98, 99, 103, 104, 105, 106], "other": [8, 12, 13, 17, 37, 40, 64, 75, 82, 89, 92, 93, 94, 97, 99, 102, 104, 105, 106, 108], "target": [8, 10, 12, 13, 37, 39, 40, 46, 52, 53, 56, 63, 82, 91, 94, 103, 104, 105, 106, 107, 108], "method": [8, 10, 17, 20, 21, 74, 82, 91, 94, 95, 97, 98, 103, 104, 105, 107, 108], "come": [8, 9, 89, 90, 93, 94, 95, 96, 98, 105, 106, 107], "soon": [8, 9, 93, 96, 105], "file": [8, 10, 89, 93, 97, 99, 101, 104, 105], "microbenchmark_quantization_config": 8, "yml": 8, "benchmark_mod": 8, "infer": [8, 12, 13, 65, 87, 90, 91, 92, 94, 95, 97, 98, 103, 104, 105, 106, 107], "quantization_config_recipe_nam": 8, "int8wo": [8, 98], "int8dq": 8, "float8dq": [8, 93], "tensor": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 35, 36, 39, 40, 41, 42, 43, 46, 47, 48, 49, 52, 53, 54, 56, 57, 64, 75, 76, 77, 78, 79, 80, 82, 86, 87, 89, 91, 92, 94, 95, 98, 102, 104, 106, 107], "row": [8, 10, 38, 49, 89, 90, 94], "float8wo": 8, "output_dir": [8, 98], "result": [8, 12, 13, 49, 80, 90, 94, 95, 98, 104, 105, 106, 107, 108], "model_param": 8, "name": [8, 10, 29, 30, 44, 45, 66, 74, 75, 76, 82, 85, 86, 90, 93, 94, 97, 99, 103, 104, 105, 108], "small_bf16_linear": 8, "matrix_shap": 8, "small_sweep": 8, "min_pow": 8, "10": [8, 10, 12, 44, 52, 79, 89, 91, 93, 95, 104, 105], "max_pow": 8, "15": [8, 40, 89, 91, 93], "torch_compile_mod": 8, "max": [8, 10, 44, 90, 91, 95, 97, 104, 105, 108], "autotun": [8, 10, 91, 95], "runner": 8, "gener": [8, 12, 13, 52, 53, 54, 57, 64, 90, 91, 93, 94, 95, 97, 99, 100, 102, 103, 105, 106, 107, 108], "oss": 8, "databas": 8, "python": [8, 10, 91, 93, 94, 100, 102, 103, 104, 106, 107], "ci_microbenchmark_runn": 8, "benchmark_result": 8, "json": [8, 93, 99], "specif": [8, 10, 12, 17, 19, 20, 52, 53, 71, 76, 82, 89, 90, 91, 92, 93, 94, 98, 103, 106, 107, 108], "requir": [8, 12, 13, 19, 21, 75, 86, 90, 91, 93, 94, 97, 98, 103, 106, 108], "mode": [8, 10, 40, 91, 95, 103, 105, 106, 107, 108], "extra_info": 8, "arch": 8, "nvidia": [8, 94], "a100": [8, 12, 91, 98], "sxm4": 8, "80gb": [8, 91], "1024": [8, 74, 85, 91, 92, 106], "custom": [8, 12, 17, 65, 81, 87, 89, 90, 91, 94, 97, 99, 103, 104, 106, 108], "layer": [8, 31, 37, 39, 42, 43, 52, 53, 55, 59, 60, 61, 67, 68, 70, 71, 82, 83, 89, 93, 94, 95, 97, 99, 103, 108], "origin": [8, 12, 13, 18, 39, 42, 58, 79, 82, 90, 91, 92, 93, 94, 103, 104, 108], "metric": [8, 12, 82], "speedup": [8, 10, 12, 89, 90, 91, 93, 94], "wrt": 8, "bf16": [8, 12, 46, 65, 91, 94, 106, 107], "benchmark_valu": 8, "25": [8, 91], "target_valu": 8, "0": [8, 10, 12, 13, 40, 52, 63, 67, 68, 79, 82, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 105, 107, 108], "depend": [8, 13, 92, 94, 97, 104, 105, 107], "step": [8, 12, 19, 32, 65, 66, 89, 90, 94, 103, 104, 105, 106, 107, 108], "workflow": [8, 10, 74, 75, 85, 89, 91, 94, 108], "github": [8, 91, 93, 98], "action": [8, 99, 104, 105], "upload": 8, "verifi": [8, 91, 92, 97], "setup": [8, 93], "suit": [8, 10, 104, 106], "unittest": 8, "discov": 8, "out": [8, 10, 12, 20, 44, 76, 82, 89, 90, 91, 93, 94, 97, 103, 104, 105, 106], "memori": [8, 10, 12, 13, 89, 90, 91, 94, 97, 98, 106, 107], "reduc": [8, 10, 12, 32, 65, 89, 93, 94, 106], "matrix": [8, 15, 33, 37, 49, 75, 80, 82, 90, 91, 94, 106], "miss": [8, 94], "i": [8, 9, 10, 12, 13, 17, 18, 19, 20, 21, 33, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 62, 63, 65, 74, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108], "properli": [8, 92], "instal": [8, 10, 89, 90, 91, 93, 98, 104, 107], "Not": [8, 94], "avail": [8, 10, 76, 90, 93, 103, 104, 105, 106, 107], "check": [8, 10, 12, 13, 90, 91, 92, 93, 97, 103, 105, 108], "driver": 8, "basic": [8, 10, 19, 91, 95, 97], "shape": [8, 10, 13, 49, 76, 80, 90, 91, 95, 97, 99, 104, 107], "comprehens": [8, 99, 106], "analysi": [8, 94], "enabl": [8, 10, 73, 86, 89, 90, 93, 99, 106], "profil": [8, 10], "onli": [8, 10, 12, 13, 16, 31, 37, 38, 39, 40, 41, 42, 43, 55, 65, 71, 89, 91, 92, 93, 94, 97, 98, 99, 103, 104, 106, 107, 108], "overhead": [8, 94, 98, 99, 106], "multipl": [8, 10, 12, 15, 37, 49, 50, 75, 77, 80, 90, 91, 94, 95, 97, 99, 106, 108], "possibl": [8, 13, 90, 94, 104, 105, 106, 108], "consist": [8, 93, 94, 97, 106, 107, 108], "reproduc": [8, 93], "differ": [8, 10, 12, 17, 40, 47, 50, 79, 80, 89, 90, 91, 92, 93, 94, 97, 98, 99, 104, 105, 106, 108], "case": [8, 9, 10, 65, 75, 80, 93, 94, 97, 99, 103, 104, 108], "user": [8, 10, 12, 37, 50, 65, 71, 87, 89, 90, 91, 93, 94, 95, 97, 102, 104, 105, 106, 107, 108], "more": [8, 10, 12, 13, 40, 41, 89, 90, 91, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107], "about": [8, 10, 12, 90, 91, 92, 93, 94, 104, 105, 106, 108], "compon": [8, 90, 97, 99], "see": [8, 10, 12, 13, 40, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 103, 104, 108], "directori": [8, 89], "intend": [9, 75, 90, 104], "provid": [9, 10, 12, 17, 20, 21, 46, 50, 69, 86, 89, 90, 93, 94, 97, 99, 104, 105, 107, 108], "instruct": [9, 12, 90, 93, 104, 105, 106], "most": [9, 10, 19, 65, 90, 93, 94, 99, 104, 105, 108], "fequent": 9, "have": [9, 10, 12, 44, 59, 60, 61, 76, 79, 82, 86, 90, 94, 95, 97, 99, 103, 104, 105, 106, 107, 108], "ani": [9, 10, 19, 55, 59, 69, 82, 90, 94, 97, 103, 105, 107], "answer": [9, 94], "creat": [9, 10, 13, 23, 25, 89, 94, 97, 98, 103, 104, 106, 107, 108], "an": [9, 12, 13, 21, 24, 25, 62, 63, 65, 71, 82, 87, 89, 90, 91, 93, 94, 95, 97, 98, 103, 104, 105, 106, 107, 108], "issu": [9, 75, 90, 91, 97, 106], "start": [10, 12, 29, 30, 44, 45, 66, 75, 76, 89, 90, 93, 94, 95, 97, 99, 103, 104, 105, 106, 107, 108], "read": [10, 97], "overview": [10, 87, 91, 99], "page": [10, 91, 106], "first": [10, 18, 49, 65, 82, 86, 90, 93, 95, 97, 98, 99, 104, 105, 108], "contribut": [10, 91, 94], "exist": [10, 45, 65, 89, 90, 94, 95, 97, 104, 108], "base": [10, 17, 19, 37, 44, 51, 64, 65, 69, 77, 78, 82, 86, 90, 91, 94, 97, 98, 99, 103, 104, 105, 106, 107, 108], "api": [10, 90, 91, 94, 95, 97, 103, 104, 105, 106, 107], "quant_api": [10, 74, 92, 93, 95], "float8tensor": [10, 37, 39, 56, 77, 90, 99], "e": [10, 12, 13, 44, 46, 48, 50, 63, 65, 74, 77, 79, 86, 89, 90, 92, 95, 97, 98, 103, 108], "g": [10, 12, 13, 44, 46, 48, 50, 63, 65, 74, 77, 79, 86, 90, 92, 95, 97, 103, 108], "oper": [10, 12, 13, 15, 17, 42, 47, 90, 91, 93, 103, 104, 105, 106, 107], "make": [10, 38, 40, 90, 91, 97, 99, 104, 108], "trainabl": [10, 12, 90, 97], "add": [10, 19, 86, 97, 98, 102, 106, 108], "parallel": [10, 89, 97, 99], "primit": [10, 13, 97, 104], "op": [10, 12, 13, 37, 74, 75, 86, 91, 94, 97, 99, 104, 105, 106, 108], "slight": [10, 94], "variat": [10, 90], "quant_primit": [10, 95], "mp": 10, "csrc": 10, "ar": [10, 12, 13, 15, 20, 31, 36, 37, 40, 46, 48, 50, 52, 53, 62, 65, 74, 75, 76, 79, 80, 82, 86, 89, 90, 91, 92, 93, 94, 95, 99, 103, 104, 105, 106, 107, 108], "structur": [10, 12, 20, 85, 90, 91, 92, 94, 97, 104], "deriv": [10, 13, 47, 78, 79], "pack": [10, 13, 21, 34, 36, 38, 40, 76], "format": [10, 13, 18, 40, 76, 93, 94, 104, 105, 108], "understand": [10, 76, 89, 106, 108], "concept": [10, 90, 102, 104, 106, 107, 108], "doe": [10, 12, 19, 65, 75, 76, 90, 94, 97, 104, 106, 107], "alreadi": [10, 13, 97, 108], "could": [10, 90, 97, 103, 104, 106, 107, 108], "context": [10, 106, 107], "also": [10, 12, 63, 74, 90, 91, 92, 94, 95, 97, 98, 99, 104, 107, 108], "write": [10, 87, 91, 103, 104, 105], "own": [10, 12, 87, 89, 91, 94, 95, 104, 105, 108], "torchaobasetensor": [10, 99], "help": [10, 12, 89, 90, 93, 99, 103, 104], "common": [10, 65, 75, 76, 77, 78, 87, 89, 90, 94], "specifi": [10, 12, 13, 28, 31, 43, 50, 52, 53, 54, 57, 64, 65, 71, 74, 75, 79, 82, 85, 89, 90, 94, 103, 104, 105, 108], "non": [10, 86, 94, 97, 103, 106, 107], "attribut": [10, 12, 86, 90, 97, 99, 106, 107], "mytensor": [10, 86], "tensor_data_nam": [10, 86], "qdata": [10, 90], "scale": [10, 13, 17, 23, 25, 29, 32, 37, 44, 46, 47, 48, 49, 55, 56, 63, 68, 69, 70, 71, 78, 79, 86, 90, 94, 95, 97, 99, 108], "tensor_attribute_nam": [10, 86], "With": [10, 97, 104, 106, 108], "abov": [10, 12, 38, 40, 44, 90, 92, 94, 95, 97, 104, 105, 108], "ll": [10, 44, 89, 90, 97, 104, 105, 108], "doc": [10, 89, 90, 91, 93, 97, 98], "mani": [10, 90, 94, 97], "still": [10, 12, 90, 94, 104, 108], "affinequantizedtensor": [10, 23, 25, 42, 91, 92, 95, 97], "plan": [10, 40, 42, 105], "move": [10, 74, 95, 99, 105, 106], "awai": 10, "from": [10, 12, 13, 18, 19, 23, 25, 41, 47, 58, 62, 65, 74, 75, 79, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108], "abstract": [10, 90], "easier": [10, 108], "peopl": [10, 90, 92, 99, 108], "implement": [10, 12, 28, 40, 67, 68, 70, 71, 75, 86, 90, 92, 94, 95, 103, 104, 108], "regist": [10, 52, 57, 67, 81, 86, 90, 97], "mai": [10, 13, 47, 63, 76, 90, 92, 95, 98, 104, 105, 106, 107, 108], "well": [10, 17, 90, 91, 94, 104, 105, 108], "int4": [10, 12, 16, 34, 38, 40, 41, 44, 52, 53, 55, 59, 60, 61, 62, 63, 65, 67, 68, 70, 71, 74, 90, 91, 92, 93, 98, 99], "access": [10, 42, 103], "my_custom_op": 10, "call": [10, 12, 13, 52, 57, 67, 81, 90, 91, 92, 94, 95, 97, 99, 105, 107], "want": [10, 74, 85, 90, 91, 92, 94, 97, 99, 103, 104, 105, 108], "my_mm_for_mp": 10, "aten": [10, 86, 90, 91, 97, 99, 103, 104, 105, 106, 107], "default": [10, 12, 13, 15, 19, 21, 33, 36, 37, 39, 40, 46, 48, 55, 63, 71, 74, 86, 89, 90, 91, 97, 99, 103, 104, 105, 106, 107, 108], "_": [10, 86, 89, 90, 95, 99, 103, 104, 105, 106], "func": [10, 86, 90, 97, 99], "arg": [10, 13, 40, 52, 53, 54, 55, 59, 68, 82, 86, 90, 97, 99, 105, 108], "re": [10, 89, 90, 92, 93, 97, 104, 105], "input_tensor": [10, 18, 90, 99], "weight_tensor": [10, 90, 99], "some": [10, 74, 82, 86, 90, 91, 93, 94, 95, 97, 103, 104, 105, 106, 107, 108], "choic": [10, 40], "mm": [10, 74, 75, 97, 104], "recommend": [10, 12, 37, 39, 40, 41, 42, 43, 89, 90, 98, 103, 106, 107], "wai": [10, 13, 65, 89, 90, 93, 94, 95, 97, 104, 105, 108], "repres": [10, 13, 15, 17, 28, 33, 51, 63, 76, 79, 82, 90, 92, 97, 104, 105], "group_mm": 10, "auto": [10, 37, 75, 93, 98, 99], "develop": [10, 91, 104, 105, 108], "choos": [10, 40, 78, 90, 94, 97, 104, 106], "whatev": 10, "think": [10, 99], "fastest": 10, "under": [10, 12, 75, 93], "condit": 10, "so": [10, 12, 89, 90, 91, 92, 94, 97, 98, 104, 105, 108], "don": [10, 82, 89, 90, 91, 94, 98, 99, 108], "t": [10, 82, 86, 89, 90, 91, 94, 95, 97, 98, 99, 104, 105, 108], "worri": 10, "debug": [10, 75], "purpos": [10, 89, 90, 97, 104], "ha": [10, 12, 13, 65, 93, 94, 97, 99, 103, 104, 105, 107, 108], "hardwar": [10, 37, 75, 76, 91, 93, 94, 98], "h100": [10, 90, 98], "sm89": 10, "sm90": 10, "librari": [10, 75, 76, 87, 90, 92], "whether": [10, 12, 40, 46, 63, 86, 97], "fbgemm_gpu_genai": [10, 75, 90], "granular": [10, 13, 29, 37, 40, 41, 42, 43, 46, 48, 52, 53, 55, 56, 63, 64, 79, 89, 90, 93, 95, 99], "per": [10, 12, 13, 38, 39, 41, 42, 43, 46, 48, 55, 59, 60, 61, 63, 67, 68, 70, 71, 79, 82, 89, 90, 91, 94, 95, 107], "_choose_scale_float8": [10, 46, 90], "_quantize_affine_float8": [10, 90], "_scaled_mm": [10, 90], "kerenel": 10, "fbgemm": [10, 75, 90, 94], "f8f8bf16_rowwis": [10, 90], "level": [10, 82, 90, 94, 97, 103, 104, 106, 107], "reus": [10, 97], "allow": [10, 71, 90, 91, 94, 97, 103, 104, 105, 106, 108], "appli": [10, 12, 13, 37, 38, 39, 41, 42, 43, 50, 54, 55, 57, 62, 64, 65, 74, 85, 86, 90, 91, 93, 94, 99, 105], "convers": [10, 12, 13, 31], "weight": [10, 12, 18, 32, 37, 38, 39, 40, 41, 42, 43, 52, 53, 55, 59, 60, 61, 63, 65, 67, 68, 70, 71, 74, 77, 82, 85, 87, 89, 91, 92, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108], "filter": [10, 12, 31, 89, 95], "should": [10, 12, 13, 32, 48, 52, 57, 58, 65, 67, 81, 82, 86, 89, 94, 99, 103, 104, 108], "algorithm": [10, 40, 93, 94, 103], "dynam": [10, 12, 27, 28, 32, 37, 38, 41, 42, 55, 61, 63, 71, 85, 93, 95, 97, 98, 104, 105, 106], "quant": [10, 13, 90, 93, 99, 104, 107, 108], "In": [10, 12, 40, 65, 89, 90, 91, 94, 95, 97, 103, 104, 105, 106, 107, 108], "order": [10, 50, 86, 94, 97, 108], "aim": [10, 94, 107], "run": [10, 12, 32, 52, 53, 57, 67, 74, 75, 81, 89, 90, 91, 93, 94, 97, 102, 103, 104, 105, 106, 107, 108], "fullgraph": [10, 91], "true": [10, 12, 13, 24, 28, 37, 39, 40, 41, 42, 43, 46, 47, 52, 53, 62, 63, 65, 73, 74, 85, 89, 91, 92, 93, 95, 97, 98, 99, 103, 104, 105, 106, 108], "remov": [10, 46, 82, 89, 94, 99, 104, 105], "unnecessari": 10, "graph": [10, 91, 104, 105, 108], "break": 10, "torch_log": 10, "output_cod": 10, "script": [10, 91, 93, 95, 97, 102, 105, 106, 107], "inductor": [10, 87, 91, 103, 104], "save": [10, 12, 82, 86, 89, 91, 92, 93, 99], "load": [10, 86, 92, 93, 98, 99], "relev": [10, 90, 102], "object": [10, 36, 74, 85, 90, 97, 104, 105, 108], "safe": [10, 80], "global": [10, 94, 97], "after": [10, 12, 32, 89, 90, 92, 94, 98, 103, 104, 105, 106, 107, 108], "2": [10, 13, 14, 16, 20, 37, 39, 40, 42, 43, 44, 52, 63, 67, 68, 79, 83, 85, 87, 89, 90, 94, 95, 97, 102], "5": [10, 12, 44, 52, 82, 91, 93, 94, 99, 102, 104, 105], "add_safe_glob": 10, "quantizetensortofloat8kwarg": [10, 90], "checkout": [10, 13, 87, 90], "huggingfac": [10, 98], "transform": [10, 12, 13, 86, 95, 103, 104, 105, 106, 107], "deseri": [10, 104, 105], "save_pretrain": [10, 93, 98], "push_to_hub": [10, 93, 98, 99], "from_pretrain": [10, 12, 93, 98, 99], "diffus": [10, 93], "just": [10, 44, 63, 90, 92, 94, 97, 104, 105, 108], "talk": [10, 90, 93], "train": [10, 28, 50, 63, 65, 87, 91, 94, 97, 108], "fsdp": [10, 90], "mydtypetensor": 10, "put": [10, 85, 106, 108], "developer_api_guid": 10, "folder": [10, 93, 104, 105], "cover": [10, 102, 104, 107, 108], "follow": [10, 12, 63, 65, 86, 89, 90, 91, 93, 94, 95, 97, 98, 103, 104, 105, 106, 107, 108], "executorch": [10, 41, 87, 91, 98, 104, 105], "torchchat": 10, "dtensor": [10, 97], "copi": [10, 13, 82, 91, 92, 94, 95, 97, 105, 106], "past": [10, 94], "adapt": [10, 89, 95], "befor": [10, 12, 65, 74, 90, 92, 93, 94, 95, 97, 104, 105, 108], "do": [10, 45, 49, 74, 90, 93, 94, 95, 97, 99, 104, 105, 106, 108], "singl": [10, 12, 27, 32, 37, 47, 89, 91, 94, 104, 108], "comput": [10, 21, 32, 39, 52, 57, 67, 75, 81, 82, 90, 94, 95, 97, 98, 104, 105, 106, 107], "intens": 10, "get": [10, 12, 18, 71, 86, 89, 90, 91, 93, 94, 99, 103, 104, 105, 106, 108], "sens": [10, 90, 97], "d": [10, 86, 93, 105], "benchmark_aq": 10, "": [10, 12, 13, 44, 46, 48, 75, 76, 79, 86, 89, 90, 91, 93, 94, 95, 97, 104, 105, 106, 107, 108], "import": [10, 12, 58, 62, 65, 74, 85, 91, 92, 93, 94, 95, 97, 98, 99, 102, 103, 106, 107], "A": [10, 12, 13, 36, 47, 75, 81, 86, 90, 94, 97, 98, 99, 104], "quick": [10, 87], "chang": [10, 74, 89, 91, 92, 93, 94, 95, 97, 103, 104, 105, 107, 108], "interest": [10, 94, 97], "print_op_and_shap": 10, "output": [10, 12, 28, 46, 48, 79, 89, 90, 91, 93, 94, 98, 102, 103, 104, 105, 106, 107, 108], "torch_func": 10, "built": [10, 89, 97], "_c": 10, "tensorbas": 10, "all": [10, 32, 40, 44, 47, 52, 55, 57, 59, 67, 69, 81, 82, 83, 86, 90, 91, 92, 93, 94, 95, 97, 99, 100, 103, 104, 106, 108], "benchmark_your_kernel": 10, "helper": [10, 72, 73, 86], "right": [10, 38, 40, 94, 104], "1": [10, 29, 30, 36, 37, 39, 40, 42, 43, 44, 45, 46, 56, 66, 74, 75, 76, 78, 79, 82, 87, 90, 91, 92, 94, 95, 97, 102, 104, 105], "feel": [10, 90, 94, 97, 99], "free": [10, 90, 97], "either": [10, 13, 37, 56, 65, 82, 93, 94, 105, 106, 107], "one": [10, 37, 47, 52, 57, 65, 67, 81, 89, 90, 94, 97, 99, 105, 108], "probabl": 10, "keep": [10, 42, 46, 82, 90, 104], "futur": [10, 95, 98, 99, 104, 105, 106, 108], "llama": [10, 12, 93, 98, 99, 103], "llama2": 10, "llama3": [10, 12, 89, 98], "sam": 10, "modifi": [10, 31, 74, 82, 89, 94, 97], "friendli": 10, "compar": [10, 12, 82, 89, 90, 93, 104, 106, 108], "techniqu": [10, 12, 89, 92, 93, 94, 95, 97, 99], "bound": [10, 37, 56, 93, 94, 99], "each": [10, 18, 55, 63, 68, 70, 71, 81, 86, 90, 94, 95, 97, 99, 104, 105, 108], "profile_path": 10, "chrome": 10, "trace": 10, "let": [10, 44, 79, 90, 91, 94, 95, 97, 108], "u": [10, 94, 103], "know": [10, 97], "end": [12, 89, 90, 93, 94, 97, 98, 99, 105, 108], "pre": [12, 17, 21, 87, 93, 94, 108], "serv": [12, 13, 17, 87, 89, 97, 98, 107], "flow": [12, 41, 89, 93, 94, 95, 103, 104, 105, 106, 107], "leverag": [12, 89, 91, 93, 97, 106, 107], "partner": [12, 89, 93], "showcas": [12, 89, 93], "focus": [12, 89, 90, 93, 94], "domain": [12, 13, 46, 48, 63, 89], "demonstr": [12, 89, 90, 91, 93, 97, 103, 105], "dure": [12, 13, 42, 48, 63, 65, 89, 91, 93, 94, 95, 97, 103, 105], "numer": [12, 65, 70, 71, 75, 89, 94, 104, 105, 106], "goal": [12, 65], "mitig": [12, 94], "degrad": [12, 65, 94], "eventu": [12, 65, 89], "blog": 12, "resourc": [12, 97], "small": 12, "matric": [12, 20, 94], "freez": [12, 105, 106, 107], "checkpoint": [12, 86, 89, 93, 99], "effici": [12, 21, 70, 91, 94, 95, 107], "paper": [12, 94, 102], "speed": [12, 74, 93, 94, 103], "up": [12, 18, 63, 74, 89, 90, 91, 94, 103, 104, 105, 108], "high": [12, 13, 22, 23, 24, 25, 56, 65, 89, 90, 93, 94, 95, 97, 103, 104, 106, 107], "precis": [12, 13, 22, 23, 24, 25, 39, 42, 55, 56, 60, 61, 65, 68, 70, 71, 90, 95, 97, 98, 103, 106, 107], "similar": [12, 94, 95, 105, 106], "inevit": 12, "actual": [12, 39, 65, 75, 90, 95, 97, 99, 104, 105, 108], "presum": 12, "been": [12, 86, 97, 105, 106, 107, 108], "successfulli": [12, 94], "recent": [12, 87], "releas": [12, 106], "1b": [12, 98, 99], "3b": 12, "llamaguard": 12, "8b": [12, 89, 98], "improv": [12, 89, 93, 94, 104, 107, 108], "qualiti": [12, 94, 98], "involv": [12, 15, 65, 94], "two": [12, 20, 37, 65, 86, 90, 91, 94, 97, 103, 104, 105, 106, 108], "separ": [12, 52, 53, 63, 94, 99, 104, 108], "prepar": [12, 50, 55, 59, 65, 82, 94, 103, 106, 107, 108], "convert": [12, 13, 18, 22, 24, 26, 28, 50, 58, 59, 65, 74, 85, 89, 90, 93, 94, 103, 106, 107, 108], "fake": [12, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 89, 104, 105, 108], "mean": [12, 13, 18, 44, 46, 48, 79, 86, 89, 90, 91, 94, 104, 105, 108], "valu": [12, 13, 18, 28, 29, 30, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 56, 66, 75, 76, 79, 82, 90, 94, 95, 97, 103, 104, 105, 108], "map": [12, 42, 44, 63, 86, 90, 97, 104, 108], "without": [12, 58, 90, 94, 99, 106, 108], "cast": [12, 13, 27, 29], "lower": [12, 37, 41, 56, 90, 91, 93, 94, 95, 98, 105], "replac": [12, 94, 99], "real": [12, 90, 91, 104, 108], "perform": [12, 13, 21, 32, 42, 43, 49, 52, 57, 59, 60, 61, 67, 80, 81, 89, 91, 94, 95, 97, 98, 99, 103, 105, 106, 107], "There": [12, 65, 90, 95, 97, 104, 108], "directli": [12, 44, 47, 65, 90, 94, 95, 97], "loop": [12, 89, 94], "distribut": [12, 89, 95, 97, 99, 103], "recip": [12, 28, 52, 57, 67, 81], "instead": [12, 47, 52, 57, 58, 62, 63, 65, 67, 81, 89, 91, 94, 97, 105, 106, 107, 108], "command": [12, 89], "regular": [12, 103, 106, 107], "nnode": 12, "nproc_per_nod": 12, "4": [12, 14, 20, 26, 83, 85, 90, 91, 92, 93, 94, 97, 98, 104, 105], "full_finetune_distribut": 12, "llama3_2": 12, "3b_full": 12, "batch_siz": [12, 92, 93, 95, 104, 105], "16": [12, 53, 89], "equival": [12, 63, 94, 105, 106, 108], "asymmetr": [12, 41, 44, 46, 63, 91, 95, 103, 107, 108], "token": [12, 41, 42, 61, 63, 71, 89, 93, 98], "int8": [12, 18, 41, 42, 43, 53, 61, 62, 63, 65, 71, 74, 78, 85, 90, 93, 97, 104, 106, 107, 108], "symmetr": [12, 37, 39, 41, 42, 43, 44, 46, 52, 55, 63, 97, 103, 104, 107, 108], "configur": [12, 15, 27, 28, 31, 37, 38, 39, 40, 41, 42, 43, 74, 85, 89, 90, 91, 93, 98, 106, 107, 108], "_component_": 12, "qat_distribut": 12, "3b_qat_ful": 12, "evalu": [12, 105], "same": [12, 13, 37, 40, 46, 47, 48, 71, 79, 80, 85, 86, 89, 90, 94, 95, 97, 105, 107, 108], "wa": [12, 97, 105], "llama3_2_3b": 12, "fullmodelhfcheckpoint": 12, "checkpoint_fil": 12, "00001": 12, "00002": 12, "safetensor": [12, 98], "int8dynactint4weightquant": 12, "groupsiz": [12, 60, 61, 70, 71, 79], "32": [12, 40, 41, 53, 62, 63, 65, 67, 68, 74, 85, 89, 91, 92, 93, 95, 97, 105], "hellaswag": [12, 93], "wikitext": 12, "eleuther_ev": 12, "eleuther_evalu": 12, "task": [12, 93], "fullmodeltorchtunecheckpoint": 12, "8da4w": [12, 93], "ckpt": 12, "llama3_token": 12, "path": [12, 74, 80, 91, 93, 103, 104, 105, 106, 108], "tmp": [12, 91], "meta": [12, 92, 98, 99, 108], "print": [12, 82, 91, 92, 93, 97, 102, 104, 105], "version": [12, 16, 37, 39, 40, 42, 43, 63, 74, 90, 92, 97, 99, 104, 105, 108], "shot": [12, 94], "stderr": 12, "none": [12, 13, 15, 22, 24, 25, 27, 28, 29, 30, 31, 32, 37, 40, 43, 44, 45, 46, 47, 48, 52, 53, 55, 56, 62, 63, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 78, 79, 82, 85, 86, 90, 95, 97, 99, 103, 104, 105, 107], "acc": [12, 104, 105], "5021": 12, "0050": 12, "acc_norm": 12, "6797": 12, "0047": 12, "bits_per_byt": 12, "6965": 12, "byte_perplex": 12, "6206": 12, "word_perplex": 12, "13": 12, "2199": 12, "much": [12, 91, 94, 108], "openassist": 12, "oasst1": 12, "dataset": [12, 89, 93, 103, 106, 107], "find": [12, 18, 94, 104, 108], "achiev": [12, 18, 89, 94, 95, 97, 105, 106], "higher": [12, 89, 97, 98, 103, 104, 106, 107], "accuraci": [12, 89, 93, 94, 95, 103, 105, 106], "than": [12, 36, 63, 89, 90, 94, 97, 104], "recov": [12, 94, 105], "69": [12, 95], "8": [12, 21, 36, 40, 44, 52, 53, 60, 70, 89, 90, 91, 93, 99, 106, 107], "overal": [12, 87, 91, 104, 108], "vanilla": 12, "compos": [12, 50, 90, 94, 97, 104, 105, 108], "lora": 12, "yield": [12, 94], "89x": 12, "usag": [12, 13, 32, 50, 52, 53, 58, 62, 63, 65, 86, 87, 89, 93, 106, 107], "36": [12, 89, 93], "qat_lora_finetune_distribut": 12, "3b_qat_lora": 12, "set": [12, 13, 15, 37, 39, 40, 41, 42, 43, 47, 63, 74, 82, 86, 91, 94, 103, 105, 106, 107], "try": [12, 94, 97, 104], "fsdp2": [12, 89], "yaml": 12, "onc": [12, 94], "complet": [12, 93, 103, 107], "qat_out": 12, "quatiz": 12, "document": [12, 97, 99, 103, 104, 106], "prefer": [12, 37, 90, 97], "These": [12, 94, 97, 103, 104, 105, 108], "what": [12, 13, 89, 90, 91, 93, 94, 95, 99, 102, 104, 108], "hood": 12, "mini": [12, 93], "gpu": [12, 87, 89, 91, 98, 99, 102, 103], "smaller": [12, 36, 40, 41, 91, 92], "fit": [12, 13, 21, 90, 92], "adjust": [12, 37, 39, 40, 41, 42, 43], "accordingli": 12, "get_model": 12, "vocab_s": 12, "4096": [12, 89], "num_lay": 12, "num_head": 12, "num_kv_head": 12, "embed_dim": 12, "2048": [12, 89], "max_seq_len": 12, "train_loop": [12, 65], "sgd": 12, "lr": [12, 89], "001": 12, "momentum": [12, 105], "9": [12, 89], "weight_decai": 12, "1e": [12, 89], "loss_fn": 12, "crossentropyloss": [12, 104, 105], "rang": [12, 44, 89, 94, 95, 104, 105], "randint": 12, "loss": [12, 89, 94, 104, 105], "backward": [12, 32, 89, 94, 105], "zero_grad": [12, 89, 105], "next": [12, 89, 95, 104, 105, 106, 107], "scheme": [12, 42, 43, 52, 53, 65, 93, 103], "although": [12, 40, 52, 57, 67, 81, 97], "integ": [12, 13, 24, 25, 44, 46, 48, 49, 63, 64, 80, 95, 104, 105, 106], "arithmet": [12, 65], "float": [12, 13, 18, 24, 26, 37, 40, 44, 46, 47, 48, 52, 56, 63, 67, 68, 79, 82, 90, 91, 92, 97, 104, 105, 108], "float32": [12, 13, 23, 48, 59, 61, 63, 67, 68, 71, 79, 92, 93, 94, 95, 97, 106, 107, 108], "becaus": [12, 13, 89, 92, 94, 97, 105, 108], "int8dynamicactivationint4weightconfig": [12, 65, 71], "qatconfig": [12, 58, 62, 66], "swap": [12, 31, 55, 59, 89, 94, 95, 105], "fakequantizedlinear": [12, 55, 58, 72, 73], "base_config": [12, 65], "exact": [12, 71, 104, 105], "attun": 12, "benefici": 12, "later": [12, 90, 97, 104, 105, 107], "readi": [12, 89, 91, 93, 95, 97, 105], "did": [12, 41], "altern": [12, 63, 95, 97, 106, 107], "legaci": [12, 40], "offer": [12, 97, 104], "customiz": [12, 74], "unlik": [12, 95], "int8dynactint4weightqatquant": 12, "qat_quant": 12, "insert": [12, 91, 95, 103, 104, 105, 106, 107, 108], "int8dynactint4weightqatlinear": 12, "int8dynactint4weightlinear": 12, "fraction": [12, 13], "therebi": 12, "significantli": [12, 103, 104, 106, 107], "footprint": 12, "extens": [12, 97, 104, 106], "addition": [12, 106, 107], "frozen": 12, "further": [12, 97, 103, 104, 105, 106], "nf4": [12, 18], "propos": [12, 82], "express": [12, 91, 97, 103, 104, 105, 108], "subclass": [12, 13, 31, 52, 57, 67, 75, 76, 81, 85, 86, 90, 91, 92, 94, 98], "nf4tensor": 12, "cleanli": 12, "compil": [12, 74, 80, 87, 89, 90, 91, 95, 97, 106, 107], "simpli": [12, 94, 95, 97], "to_nf4": 12, "frozennf4linear": 12, "in_dim": 12, "out_dim": 12, "bool": [12, 13, 24, 28, 31, 37, 39, 40, 41, 42, 43, 46, 47, 52, 53, 61, 63, 67, 68, 70, 71, 73, 74, 85, 95], "quantization_kwarg": 12, "No": [12, 90, 92, 94], "requires_grad_": 12, "nf4_weight": 12, "requires_grad": [12, 13, 90, 95, 97, 99], "though": [12, 97], "shown": [12, 93, 94, 105, 108], "competit": [12, 89], "baselin": [12, 89, 93, 104], "while": [12, 52, 57, 65, 67, 77, 81, 82, 93, 94, 97, 98, 103, 104, 108], "even": [12, 13, 89, 94, 108], "newer": 12, "mxfp4": [12, 90], "nvfp4": [12, 90], "blackwel": 12, "reap": 12, "benefit": [12, 38, 94, 97, 104, 107], "vari": [12, 13, 104, 105, 106, 107], "tradeoff": [12, 94, 98], "incorpor": 12, "its": [12, 94, 97, 99, 104, 108], "loralinear": 12, "lora_finetune_single_devic": 12, "3b_qlora_single_devic": 12, "limit": [12, 89, 90, 97, 99, 104], "yet": [12, 41, 45, 65, 97, 99, 105, 106, 107], "invok": [12, 106], "loraconfig": 12, "get_peft_model": 12, "automodelforcausallm": [12, 93, 98, 99], "torchaoconfig": [12, 93, 98, 99], "int8weightonlyconfig": [12, 74, 98, 99], "base_model": 12, "quantization_config": [12, 93, 98, 99, 107], "peft_config": 12, "throughput": [12, 89, 93], "increas": [12, 94, 104], "torchtitan": 12, "enable_fp8_train": 12, "fp8_recipe_nam": 12, "tensorwis": [12, 27, 28, 90], "initi": [12, 13, 69, 90, 91, 92, 105], "experi": [12, 89, 107], "saw": 12, "experiment_nam": 12, "tok": 12, "peak_mem_reserv": 12, "6502": 12, "143": 12, "000": 12, "30": [12, 89, 91, 104], "090": 12, "fp8_nonam": 12, "7205": 12, "386": 12, "816": 12, "010": 12, "266": 12, "fp8_tensorwis": 12, "7222": 12, "198": 12, "11": [12, 89], "074": [12, 89], "fp8_rowwis": 12, "6387": 12, "968": 12, "756": 12, "29": [12, 89], "158": 12, "096": 12, "fp8_rowwise_with_gw_hp": 12, "7573": 12, "698": 12, "480": 12, "516": 12, "908": 12, "hellaswag_acc": 12, "wikitext_word_perplex": 12, "533": 12, "12": [12, 89, 107, 108], "407": [12, 89], "414": 12, "007": 12, "412": 12, "005": 12, "420": 12, "013": [12, 89], "534": 12, "416": 12, "009": 12, "tensor_impl": [13, 86, 95], "aqttensorimpl": 13, "block_siz": [13, 17, 18, 22, 23, 24, 25, 26, 46, 47, 48, 79, 90, 91, 95], "tupl": [13, 18, 22, 23, 24, 25, 37, 46, 47, 48, 69, 79, 82, 86, 97, 99, 104, 105, 108], "quant_min": [13, 24, 25, 44, 46, 47, 48, 79, 91, 97, 107, 108], "union": [13, 28, 37, 46, 48, 56, 63, 74, 79], "quant_max": [13, 24, 25, 44, 46, 47, 48, 79, 91, 97, 107, 108], "zero_point_domain": [13, 24, 25, 40, 46, 47, 63], "zeropointdomain": [13, 24, 25, 40, 46, 47, 63], "stride": [13, 97], "sourc": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 93, 100, 102], "affin": [13, 14, 15, 16, 20, 21, 24, 34, 35, 48, 79, 90], "point": [13, 40, 44, 48, 56, 63, 68, 69, 70, 71, 89, 90, 91, 92, 94, 95, 97, 104, 108], "quantized_tensor": 13, "float_tensor": [13, 97], "zero_point": [13, 17, 25, 46, 47, 48, 79, 86, 90, 94, 95, 97, 108], "happen": [13, 90, 97, 104, 106], "choose_qparam": [13, 90], "dequant": [13, 18, 48, 75, 90, 91, 97, 99, 104, 106, 107, 108], "ao": [13, 94, 99], "three": [13, 82, 85, 106, 107], "choose_qparams_affin": [13, 47], "quantize_affin": 13, "qand": 13, "dequantize_affin": 13, "look": [13, 89, 90, 94, 103, 104, 105, 106, 107], "extern": [13, 106], "regardless": 13, "intern": [13, 21], "represent": [13, 17, 86, 94, 99, 104, 108], "orient": 13, "field": [13, 63, 66, 86, 108], "impl": [13, 86], "storag": [13, 94], "store": [13, 18, 36, 42, 77, 81, 90, 94, 98, 99, 104, 105], "plain": [13, 37, 40, 76, 90, 99], "int_data": [13, 97], "kernel": [13, 14, 16, 21, 34, 37, 38, 70, 74, 75, 91, 93, 94, 103, 106, 107], "element": [13, 20, 36, 46, 48, 55, 68, 70, 71, 79, 86, 90, 94], "share": [13, 46, 48, 79, 94], "qparam": [13, 40, 46, 48, 79], "minimum": [13, 46, 48, 79], "maximum": [13, 46, 48, 79], "zero": [13, 20, 40, 42, 46, 48, 63, 68, 69, 70, 71, 82, 94, 95, 108], "subtract": [13, 18], "unquant": [13, 108], "given": [13, 26, 78, 89, 94, 99, 108], "classmethod": [13, 77, 86, 95, 97, 99], "from_hp_to_floatx": 13, "input_float": [13, 22, 23, 24, 25], "target_dtyp": [13, 22, 23, 24, 25, 27, 28, 46, 47, 90, 95], "_layout": [13, 22, 23, 24, 25, 86, 91, 95], "layout": [13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 33, 34, 35, 36, 40, 41, 42, 85, 86, 94], "scale_dtyp": [13, 22, 23, 24, 46, 47, 95], "float8": [13, 14, 15, 22, 23, 27, 28, 29, 30, 31, 32, 37, 38, 39, 55, 56, 57, 78, 87, 93, 95], "from_hp_to_floatx_stat": 13, "static": [13, 17, 18, 23, 25, 28, 47, 63, 87, 91, 104, 105, 106, 107, 108], "from_hp_to_intx": 13, "mapping_typ": [13, 24, 41, 46, 47, 63], "mappingtyp": [13, 24, 41, 42, 46, 47, 63, 95], "ep": [13, 24, 46, 47, 63, 95, 105, 107, 108], "zero_point_dtyp": [13, 24, 46, 47, 95], "preserve_zero": [13, 24, 40, 46, 47], "plainlayout": [13, 24, 25, 41, 42, 86, 95], "use_hqq": [13, 24, 40, 98, 99], "custom_scal": [13, 24], "custom_zero_point": [13, 24], "from_hp_to_intx_stat": 13, "argument": [13, 21, 48, 63, 65, 74, 77, 86, 89, 90, 93, 106], "correct": [13, 104, 105], "otherwis": [13, 43, 50, 63, 105], "desir": [13, 95], "gradient": [13, 87, 94], "implicitli": [13, 108], "complex": [13, 94], "non_block": 13, "memory_format": [13, 106, 107], "preserve_format": 13, "accord": 13, "c": [13, 86, 91, 97, 106, 107], "rule": 13, "truncat": 13, "part": [13, 87, 94, 97, 98, 105], "cannot": [13, 94, 95, 99], "inf": 13, "long": [13, 97, 104], "behavior": [13, 17, 50, 99, 104, 105], "undefin": [13, 50, 82], "across": [13, 82, 93, 94, 97, 99], "platform": 13, "attempt": 13, "asynchron": 13, "respect": [13, 94, 105], "host": [13, 99], "both": [13, 37, 40, 65, 71, 90, 91, 94, 95, 97, 104, 106, 107, 108], "pin": 13, "pageabl": 13, "howev": [13, 94, 98, 99, 105, 108], "caution": 13, "advis": [13, 90], "good": [13, 91, 97, 108], "pin_memori": 13, "match": [13, 48, 49, 70, 71, 86, 94, 104], "float64": 13, "5044": 13, "0005": 13, "3310": 13, "0584": 13, "cuda0": 13, "cutlass": [14, 34], "mm_config": [15, 37], "float8mmconfig": [15, 37], "variabl": [15, 21, 33, 36, 82, 86, 94], "tinygemm": [16, 40, 70, 74, 91], "_weight_int4pack_mm_for_cpu": 16, "least": 16, "6": [16, 63, 89, 90, 91, 93, 94, 104, 105, 106], "It": [17, 19, 21, 32, 91, 94, 97, 108], "post": [17, 21, 65, 87, 90, 91, 97, 105, 108], "design": [17, 20, 93, 99, 103, 104, 108], "extend": [17, 90, 94, 106], "conjunct": 17, "tensorimpl": [17, 86], "interact": [17, 104], "tensor_meta": 18, "subclasstensorarg": 18, "n_block": 18, "scaler_block_s": [18, 26], "quantized_scal": 18, "quantization_factor": 18, "scaler_mean": 18, "quantized_data": [18, 99], "qlora": [18, 87, 93], "convert_to_norm_float_weight": 18, "normal": [18, 26, 94, 104, 105], "dequantize_scal": 18, "unpack": 18, "doubl": 18, "scaler": 18, "per_scaler_block": 18, "factor": [18, 49, 89, 94], "inpt_weight": 18, "block": [18, 33, 82, 94], "double_quantize_scal": 18, "take": [18, 52, 57, 67, 74, 81, 85, 86, 90, 94, 103, 104, 105, 106, 107, 108], "calcul": [18, 32, 37, 44, 46, 47, 56, 90, 94, 104, 108], "absmax": 18, "posit": 18, "And": [18, 37, 97, 106, 108], "again": [18, 94, 104, 108], "per_block": 18, "int16": [18, 104], "n_scaler_block": 18, "get_original_weight": 18, "quantize_tensor_nearest": 18, "float16": [18, 79, 94], "nearest": 18, "round": [18, 44, 97], "inherit": [19, 86, 97, 99, 106, 107], "metadata": [19, 86, 90, 93, 97, 99], "semi": [20, 85, 94], "spars": [20, 33, 52, 67, 68, 82, 94], "pattern": [20, 90, 91, 99, 103, 104], "everi": [20, 52, 57, 67, 81, 94, 97, 104, 105], "four": [20, 103], "prune": [20, 82], "preprocess": 20, "conform": 20, "inner_k_til": [21, 40, 60, 70, 91], "core": [21, 45, 74, 95, 99, 104], "tile": 21, "affect": [21, 75, 94], "matmul": [21, 37, 39, 90, 94, 97], "64": [26, 33, 40, 55, 92, 93, 95, 97, 99], "256": [26, 40, 59, 60, 61, 70, 71, 93, 104, 105, 108], "scaling_typ": [27, 28], "scalingtyp": [27, 28], "scaling_granular": [27, 28], "scalinggranular": [27, 28], "mayb": 27, "cast_config_input": 28, "castconfig": 28, "cast_config_input_for_grad_weight": 28, "cast_config_weight": 28, "cast_config_weight_for_grad_input": 28, "cast_config_grad_output": 28, "cast_config_grad_output_for_grad_weight": 28, "gemm_config_output": 28, "float8gemmconfig": 28, "use_fast_accum": 28, "gemm_config_grad_input": 28, "gemm_config_grad_weight": 28, "enable_fsdp_float8_all_gath": 28, "pad_inner_dim": 28, "emul": [28, 75], "force_recompute_fp8_weight_in_bwd": 28, "round_scales_to_power_of_2": 28, "from_recipe_nam": 28, "recipe_nam": [28, 89], "float8linearrecipenam": 28, "qualnam": [29, 30, 44, 45, 66, 75, 76], "boundari": [29, 30, 44, 45, 66, 75, 76], "strategi": 29, "module_filter_fn": [31, 89], "callabl": [31, 74, 85, 86, 99], "float8linearconfig": 31, "float8linear": [31, 89], "instanc": [31, 52, 57, 67, 74, 81, 85, 86, 92, 97, 104, 106, 107, 108], "fqn": [31, 82, 85, 89, 95], "sum": [32, 104, 105], "prototyp": [33, 34, 35, 36, 63, 69, 90, 108], "blocksiz": 33, "da8w4": 35, "pack_dim": 36, "uintx": 36, "standard": [36, 99], "byte": 36, "uintxtensor": 36, "determin": [36, 46, 65, 89, 94, 99], "along": [36, 94, 99, 103], "indic": [36, 94, 108], "last": [36, 89, 103], "activation_dtyp": [37, 90], "float8_e4m3fn": [37, 39, 56, 90], "weight_dtyp": [37, 39, 90, 93], "pertensor": [37, 43, 56, 95], "perrow": [37, 42, 43, 56, 90], "list": [37, 48, 50, 82, 86, 91, 97, 98, 99, 103, 105, 108], "packing_format": [37, 40], "float8packingformat": 37, "activation_value_lb": 37, "activation_value_ub": 37, "kernel_prefer": [37, 90], "kernelprefer": 37, "set_inductor_config": [37, 39, 40, 41, 42, 43], "fp8granular": [37, 56], "fast": [37, 94], "accumul": 37, "upper": [37, 56], "defalut": 37, "chosen": [37, 78, 94], "torchinductor": [37, 39, 40, 41, 42, 43, 106, 107], "deprec": [37, 39, 40, 42, 58, 62], "int4_packing_format": [38, 40, 91], "int4packingformat": [38, 40], "preshuffl": [38, 90], "128": [38, 40, 89, 93, 95, 97, 98, 99, 107, 108], "sinc": [38, 52, 57, 67, 81, 90, 92, 93, 94, 95, 97, 104, 105, 106, 107, 108], "underli": [38, 93, 97], "bigger": 38, "channel": [39, 42, 43, 55, 59, 60, 61, 63, 67, 68, 70, 71, 81, 95, 107], "tensorcoretiledlayout": [40, 91], "int4_choose_qparams_algorithm": [40, 91], "int4chooseqparamsalgorithm": 40, "groupwis": 40, "mainli": [40, 90, 103, 106, 108], "distinguish": [40, 90], "control": [40, 41, 42, 82, 94, 99, 104], "fine": [40, 41, 87, 89, 93, 94], "grain": [40, 41, 97], "variant": [40, 44, 47, 97], "hqq": [40, 90, 91], "preserv": [40, 46, 82, 93, 94, 103], "Will": 40, "subset": [40, 90], "valid": [40, 86, 93, 99, 108], "state": [40, 99], "v1": [40, 93], "v2": [40, 102], "ignor": [40, 52, 57, 67, 81, 89, 104, 105], "less": [40, 44, 94, 97, 104], "confus": [40, 90, 94, 104], "act_mapping_typ": [41, 42], "produc": [41, 91, 103, 104, 105, 106, 107], "backend": [41, 87, 91, 93, 94, 108], "cutlassint4packedlayout": 41, "weight_only_decod": 42, "dim": [42, 43, 56, 95, 97, 99, 104, 105], "around": [42, 89, 90, 91, 92, 104], "decod": [42, 93], "better": [42, 43, 89, 97, 104, 105, 106, 107, 108], "split": [42, 93, 104, 105], "int8tensor": [42, 90], "number": [44, 55, 68, 70, 71, 82, 93, 94, 97, 105, 106], "sai": [44, 79, 90, 98, 99, 108], "3": [44, 52, 79, 87, 89, 90, 91, 94, 98, 102, 104, 105], "7": [44, 89, 93, 106, 107], "symmetric_no_clipping_err": 44, "smin": 44, "smax": 44, "min_val_neg": [44, 97], "max_val_po": [44, 97], "By": [44, 94], "individu": [44, 94], "error": [44, 63, 89, 97, 104], "neg": 44, "placehold": [45, 90, 107], "int32": [46, 59, 63, 67, 68, 90, 91, 104, 108], "keepdim": [46, 97, 104, 105], "fp32": [46, 48, 63, 71, 95, 97, 104, 106], "fp16": 46, "optioanl": 46, "align": 46, "param": [46, 47, 82, 93], "request": [46, 48, 79], "min_val": [47, 97], "max_val": [47, 97], "observ": [47, 81, 90, 94, 95, 103, 104, 105, 106, 107, 108], "obtain": 47, "track": [47, 98, 99], "calibr": [47, 91, 103, 105, 106, 107], "mostli": [47, 65, 91], "input_dtyp": 48, "output_dtyp": [48, 67, 79], "uint8": [48, 79, 90, 95, 108], "b": [49, 75, 86], "scales1": 49, "multipli": [49, 80, 94], "second": [49, 65, 86, 89, 90, 102, 108], "rais": [49, 62, 65, 80, 97, 99], "assertionerror": [49, 80, 97], "expect": [49, 89, 94, 97, 103, 104, 106, 107, 108], "qat": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 87, 93, 106], "twostepquant": 50, "easili": [50, 103], "thei": [50, 89, 91, 94, 97, 98, 104, 105, 108], "constructor": [50, 86, 97], "must": [50, 63, 65, 71, 89, 94, 98, 99, 105, 107, 108], "embed": [50, 52, 59, 62, 65, 67, 68], "my_quant": 50, "qatquantizer1": 50, "qatquantizer2": 50, "qatquantizer3": 50, "num_embed": [52, 67, 68], "embedding_dim": [52, 67, 68], "padding_idx": [52, 67, 68], "max_norm": [52, 67, 68], "norm_typ": [52, 67, 68], "scale_grad_by_freq": [52, 67, 68], "weight_config": [52, 53, 62, 65], "fakequantizeconfigbas": [52, 53, 62, 65], "intxfakequantizeconfig": [52, 53, 62, 64, 65], "fq_embed": 52, "longtensor": 52, "overridden": [52, 57, 67, 81], "within": [52, 57, 67, 81, 93, 94, 99, 106, 107], "afterward": [52, 57, 67, 81], "former": [52, 57, 67, 81], "care": [52, 57, 67, 81, 92, 94, 104], "hook": [52, 57, 67, 81, 90], "latter": [52, 57, 67, 81, 105], "silent": [52, 57, 67, 81, 106], "in_featur": [53, 70, 71, 89, 91, 92, 95, 97], "out_featur": [53, 70, 71, 89, 91, 95, 97], "activation_config": [53, 62, 65], "per_token": [53, 62, 63, 65], "is_symmetr": [53, 62, 63, 65], "fq_linear": 53, "scale_precis": [55, 59, 63, 67, 68], "rowwis": [55, 90], "hp_value_lb": 56, "hp_value_ub": 56, "float8fakequantizeconfig": 57, "fakequantizedembed": 58, "back": [58, 97], "model_with_fake_quantized_linear": 58, "zero_point_precis": [59, 63, 67, 68], "int4weightonlyqatembed": 59, "int4weightonlyembed": 59, "scales_precis": [60, 61, 70, 71], "padding_allow": 61, "valueerror": [62, 65], "torchaodtyp": 63, "is_dynam": [63, 106, 107, 108], "range_learn": 63, "simul": [63, 65, 83, 94], "older": 63, "int1": [63, 90], "int7": [63, 90], "pergroup": [63, 93], "pertoken": 63, "per_channel": 63, "peraxi": [63, 93, 95], "per_group": [63, 79], "combin": [63, 93, 94, 97, 104, 106], "leav": 63, "empti": [63, 90], "keyword": [63, 65, 77, 90], "properti": [63, 64], "throw": 63, "els": [63, 90, 93, 99, 104, 105], "symmetri": 64, "qatstep": 65, "awar": [65, 82, 87, 91, 94, 97], "ptq": [65, 105, 106], "automat": [65, 89, 93, 97, 98, 99, 102], "phase": [65, 108], "int4weightonlyconfig": [65, 74, 91, 92, 98, 99], "experiment": [65, 103], "qat_config": 65, "act_config": 65, "alwai": [65, 93, 97], "One": [65, 94, 97, 99, 108], "enum": [66, 75], "example_input": [69, 91, 92, 95, 103, 104, 105, 106, 107, 108], "intxfakequantizerbas": 69, "weightonlyint4linear": 70, "hardcod": [71, 108], "mod": [72, 73, 89, 94, 97], "disabl": [72, 97, 105], "filter_fn": [74, 85], "_is_linear": [74, 95], "inplac": [74, 82, 91], "fulli": [74, 85, 93, 94, 104], "qualifi": [74, 85, 94], "final": [74, 90, 91, 94, 103, 104, 105, 106, 107, 108], "predefin": [74, 76, 108], "execut": [74, 97, 101], "int8dynamicactivationint8weightconfig": [74, 85, 98], "sequenti": [74, 85, 89], "select": [75, 104], "found": [75, 90, 91, 93, 94, 95, 97], "nativ": [75, 87, 89, 90, 97, 104], "gemm_lowp": 75, "gemm_fp32": 75, "ci": 75, "product": [75, 82, 93, 99, 106, 108], "logic": [75, 91, 97, 99], "lowp": 75, "gemm": [75, 89, 106, 107], "laid": [76, 90], "opaqu": 76, "decid": [76, 94, 95], "adopt": [76, 90], "creation": [77, 99], "construct": [77, 90, 104, 108], "from_hp": [77, 90], "cl": [77, 86, 95, 97, 99], "quant_kwarg": [77, 78], "quantizetensorkwarg": 78, "flexibl": [78, 94, 97, 103, 106], "variou": 78, "tabl": [79, 86, 89, 90, 94], "show": [79, 89, 91, 93, 94, 99, 104, 105], "per_tensor": 79, "per_axi": 79, "axi": [79, 95], "mat2": 80, "consid": [80, 94], "cubla": 80, "fallback": [80, 99], "j": 80, "l2": [81, 94], "norm": [81, 82, 94], "buffer": 81, "x_orig": 81, "sparsity_level": [82, 94], "semi_structured_block_s": 82, "wanda": 82, "sparsifi": [82, 87, 92, 94], "http": [82, 93, 94, 98, 107], "arxiv": [82, 94], "org": [82, 93, 94, 107], "ab": [82, 94], "2306": 82, "11695": 82, "magnitud": [82, 94], "dict": [82, 86, 97, 99, 107, 108], "parametr": 82, "deepcopi": [82, 91, 95, 97, 105], "squash_mask": [82, 94], "params_to_keep": 82, "params_to_keep_per_lay": 82, "squash": 82, "mask": [82, 94], "appropri": [82, 103, 104, 105, 106, 107], "sparse_param": 82, "attach": [82, 94, 108], "kei": [82, 94, 102], "xdoctest": 82, "skip": [82, 90, 94], "local": [82, 93, 94], "hasattr": [82, 99], "submodule1": 82, "linear1": [82, 91, 92, 95, 97], "foo": [82, 104], "bar": [82, 104], "submodule2": 82, "linear42": 82, "baz": 82, "42": [82, 95], "24": 82, "ones": [82, 105], "update_mask": 82, "tensor_nam": [82, 99], "statist": [82, 94, 95, 104, 105], "retriev": 82, "act_per_input": 82, "Then": [82, 97, 107, 108], "whole": [82, 108], "alia": [84, 86, 99], "semisparseweightconfig": 84, "sparsify_": 85, "apply_tensor_subclass": 85, "essenti": [85, 99, 103], "semi_sparse_weight": 85, "semisparselayout": 85, "isinst": [85, 89, 94, 95, 97, 99, 105, 108], "sparse_api": 85, "commonli": [86, 89, 94], "includ": [86, 89, 90, 97, 103, 106, 107, 108], "_get_to_kwarg": 86, "register_layout": 86, "plainaqttensorimpl": [86, 95], "get_tensor_impl_constructor": 86, "tensor_impl_ctr": 86, "simplifi": [86, 103, 104, 106, 107], "implment": 86, "tensor_data": 86, "optional_tensor_data_nam": 86, "boilerpl": 86, "optional_tensor_attribute_nam": 86, "__new__": [86, 97, 99], "exaclti": 86, "present": [86, 94], "__tensor_flatten__": [86, 97, 99], "flatten": 86, "attribute_nam": 86, "__tensor_unflatten__": [86, 97, 99], "tensor_data_dict": [86, 97, 99], "_apply_fn_to_data": [86, 99], "recreat": 86, "__repr__": [86, 97], "_same_metadata": 86, "between": [86, 90, 94, 97, 99, 103, 105, 106, 108], "__setstate__": 86, "serial": [86, 87, 90, 98, 104, 105], "old": 86, "maintain": [86, 93, 94], "bc": 86, "contigu": [86, 90, 106, 107], "detach": [86, 97, 99], "clone": [86, 93, 99], "copy_": [86, 99], "_to_copi": [86, 99], "f": [86, 89, 90, 92, 93, 94, 95, 97, 99, 104, 105], "h": [86, 93], "layout_class": 86, "tensorimplclass": 86, "from_plain": 86, "tensor_class": 86, "aten_op": 86, "decor": [86, 97, 99], "__torch_dispatch__": [86, 97], "implements_torch_funct": 86, "torch_fn": 86, "__torch_function__": [86, 90, 97], "registr": 86, "aqt": 86, "introduct": [87, 90, 93], "highlight": [87, 97, 102], "guid": [87, 90, 93, 103], "contributor": [87, 90, 91], "benchmark": [87, 89, 91, 98, 103, 106, 107], "tune": [87, 89, 93, 94, 103], "vllm": [87, 98], "sglang": [87, 98], "hug": [87, 93], "face": [87, 90, 93, 94, 104], "advanc": [87, 95, 97, 103, 106, 107], "export": [87, 90], "x86": [87, 91], "intel": [87, 103, 106], "openvino": [87, 91], "5x": 89, "cluster": [89, 90], "34": 89, "43x": 89, "2k": 89, "h200": 89, "latest": 89, "offic": 89, "offici": [89, 90], "sever": [89, 99, 103, 108], "popular": 89, "flagship": 89, "form": [89, 90, 94], "quickli": [89, 97], "batteri": 89, "fork": 89, "build": [89, 90, 94, 97, 99, 104], "top": [89, 90, 97, 103, 104, 105, 106, 107], "virtual": 89, "environ": [89, 93], "conda": 89, "venv": 89, "download": [89, 93, 100, 102, 104, 105, 107], "job": 89, "below": [89, 90, 94, 97, 98, 99, 102, 103], "root": [89, 93], "launch": 89, "ngpu": 89, "config_fil": 89, "train_config": 89, "llama3_8b": 89, "toml": 89, "run_train": 89, "sh": [89, 93], "hyperparamet": 89, "edit": [89, 93], "line": [89, 94, 98], "flag": [89, 105], "termin": 89, "rank0": 89, "titan": 89, "2025": 89, "06": 89, "04": 89, "08": 89, "51": 89, "48": 89, "info": 89, "2254": 89, "27": 89, "34gib": 89, "28": 89, "78": 89, "tp": [89, 99], "375": 89, "tflop": 89, "21": 89, "73": [89, 95], "mfu": 89, "20": [89, 93, 105], "58": 89, "557": 89, "7069": 89, "99gib": 89, "62": 89, "034": 89, "35": [89, 93, 95], "41": [89, 93], "19": 89, "52": 89, "224": [89, 95, 103, 104, 105, 106, 107], "9196": 89, "022": 89, "406": [89, 104, 105], "65": 89, "904": 89, "1423": 89, "014": 89, "23": [89, 95], "As": [89, 104, 108], "warmup": 89, "7k": 89, "99gb": 89, "peak": [89, 93, 98], "against": 89, "02": 89, "37": 89, "404": 89, "2611": 89, "22gib": 89, "595": 89, "47": 89, "49": [89, 95], "027": 89, "4260": 89, "89gib": 89, "344": 89, "367": 89, "39": 89, "03": 89, "01": 89, "988": 89, "9482": 89, "321": 89, "366": 89, "14": 89, "991": 89, "1183": 89, "300": 89, "364": 89, "89": 89, "40": 89, "4659": 89, "291": 89, "84": 89, "769": 89, "gc": 89, "peform": 89, "period": 89, "collect": [89, 94], "3k": 89, "89gb": 89, "11x": 89, "nearli": 89, "ident": [89, 94], "performan": 89, "v": [89, 94, 104, 108], "curv": [89, 94], "omit": [89, 90, 104, 105, 106], "648": 89, "2648": 89, "28gib": 89, "71": 89, "26": 89, "475": 89, "9106": 89, "91gib": 89, "53": [89, 93], "503": 89, "434": 89, "43": 89, "94": [89, 104], "166": 89, "0774": 89, "663": 89, "443": 89, "44": [89, 95], "87": 89, "50": [89, 94, 95, 103, 104, 106, 107], "885": 89, "3233": 89, "643": 89, "442": 89, "66": [89, 93, 95], "76": 89, "613": 89, "6150": 89, "637": 89, "72": [89, 93], "6k": 89, "91gb": 89, "21x": [89, 93], "tl": 89, "dr": 89, "priorit": 89, "accur": [89, 94, 103], "stabil": 89, "cost": [89, 95], "slightli": [89, 97], "impact": [89, 93, 99], "outlier": 89, "caus": 89, "underflow": 89, "8xh100": 89, "box": [89, 94, 106], "toi": [89, 91, 95, 97, 106], "convert_to_float8_train": 89, "recurs": 89, "kind": [89, 104], "over": [89, 94, 104, 105], "snippet": [89, 104, 105], "float8_linear_util": 89, "float8_linear": 89, "sampl": [89, 104, 106, 107], "adamw": 89, "being": [89, 94, 99, 106, 107], "elig": 89, "divis": 89, "label": 89, "fake_label": 89, "ones_lik": 89, "mse_loss": 89, "model_state_dict": 89, "state_dict": [89, 92, 104, 105], "optimizer_state_dict": 89, "pth": [89, 104, 105], "explor": [89, 91, 107], "few": [89, 97, 104, 105], "lai": 90, "stack": [90, 93], "awq": 90, "gptq": 90, "int4tensor": 90, "int4preshuffledtensor": 90, "uint1": 90, "uint7": 90, "float3": 90, "triton": [90, 106, 107], "overload": [90, 94], "term": [90, 94, 104, 108], "extra": [90, 93], "matter": [90, 94], "float4_e2m1fn_x2": 90, "float8_e4m3fnuz": 90, "float8_e5m2": 90, "float8_e5m2fnuz": 90, "float8_e8m0fnu": 90, "pr": 90, "shell": 90, "dervi": 90, "mxfp8": 90, "preicison": 90, "mention": [90, 104], "previou": [90, 93, 104, 105, 106, 107], "accommod": 90, "choose_qparams_affine_with_min_max": 90, "min": [90, 95, 97, 104, 108], "raw": 90, "quantize_fp8_row": 90, "int_matmul": 90, "int_scaled_matmul": 90, "reli": [90, 91, 94, 95, 97], "handwritten": 90, "On": [90, 91], "glue": 90, "everyth": 90, "togeth": [90, 93, 104, 106, 108], "anoth": [90, 94, 97, 104, 108], "side": 90, "swizzl": 90, "dtpype": 90, "float8rowwisetensor": 90, "float8blockwisetensor": 90, "close": [90, 94], "low_precision_v": 90, "high_precision_v": 90, "procedur": 90, "especi": [90, 92, 94, 106, 107], "bitwidth": [90, 108], "codebook": 90, "index": [90, 93, 94, 107], "vector": [90, 94, 106], "kmean": 90, "tradition": 90, "explain": [90, 103, 106], "simplest": [90, 94], "easi": [90, 93], "linear_modul": 90, "runtim": [90, 104], "main": [90, 91, 93, 94, 95, 97, 98, 104, 108], "question": [90, 92, 94, 97, 108], "activation_granular": 90, "act_quant_kwarg": 90, "weight_granular": [90, 93], "quantized_weight": [90, 99], "float8_dtyp": 90, "haven": 90, "seen": 90, "pt2": [90, 97, 106], "autoround": 90, "multitensor": 90, "sure": [90, 93, 108], "open": [90, 94], "describ": [90, 92, 94, 102, 104, 105], "finetun": [90, 93], "quantized_train": 90, "progress": [90, 98, 99], "lot": [90, 94], "connect": [90, 108], "walk": [90, 95, 97, 102, 103, 106], "float8dynamicactivationfloat8weightconfig": [90, 98], "len": [90, 93, 99, 104, 105, 108], "_choose_quant_func_and_quantize_tensor": 90, "relat": [90, 94], "xq": 90, "reshap": [90, 104, 105], "wq": 90, "x_scale": [90, 104], "w_scale": 90, "out_shap": 90, "entri": 91, "mutat": 91, "toylinearmodel": [91, 92, 95], "linear2": [91, 92, 95, 97], "eval": [91, 92, 93, 95, 103, 105, 106, 107], "faster": [91, 94], "model_bf16": 91, "uint4": 91, "int4mm": 91, "mix": [91, 93, 103, 106, 107], "tile_packed_to_4d": 91, "stai": [91, 97], "tensor_impl_dtyp": 91, "roughli": [91, 94], "quarter": 91, "o": [91, 104, 105], "int4_model": 91, "pt": [91, 93], "bfloat16_model": 91, "int4_model_size_mb": 91, "getsiz": [91, 104, 105], "bfloat16_model_size_mb": 91, "2f": [91, 104, 105], "mb": [91, 92, 101, 104, 105], "00": [91, 101], "benchmark_model": 91, "unwrap_tensor_subclass": 91, "num_run": 91, "100": [91, 97, 104, 105], "_dynamo": [91, 97], "reset": [91, 104, 105], "bf16_time": 91, "int4_tim": 91, "time": [91, 94, 97, 98, 102, 103, 104, 105], "3f": [91, 105], "1fx": 91, "393": 91, "410": 91, "9x": 91, "recogn": [91, 108], "decis": 91, "pt2e": [91, 103, 104, 105, 106, 107], "fuse": [91, 94, 97, 105], "deleg": [91, 104], "x86inductorquant": [91, 106], "quantize_pt2": [91, 103, 104, 105, 106, 107], "prepare_pt2": [91, 103, 104, 106, 107], "x86_inductor_quant": [91, 106], "get_default_x86_inductor_quantization_config": [91, 106], "float_model": [91, 97, 103, 104, 105, 106, 107], "data_load": [91, 104, 105, 106, 107], "no_grad": [91, 97, 103, 104, 105, 106, 107], "imag": [91, 98, 103, 104, 105, 106, 107], "program": [91, 104, 105, 106, 108], "captur": [91, 104, 105, 108], "expos": [91, 104, 105], "set_glob": [91, 104, 105, 106, 107], "xiq": [91, 106], "prepare_qat_pt2": [91, 105, 106], "sample_inference_data": 91, "convert_pt2": [91, 103, 104, 105, 106, 107], "wrapper": [91, 97, 106], "_inductor": [91, 106], "cpp_wrapper": [91, 106], "optimized_model": [91, 103, 106, 107], "converted_model": [91, 106, 107], "xpu": [91, 107], "simpl": [91, 94, 95, 97, 103, 106, 107], "visit": 91, "would": [91, 94, 97, 105, 107], "forget": 91, "tempfil": [92, 98], "get_model_size_in_byt": 92, "ref": [92, 104], "namedtemporaryfil": 92, "seek": [92, 94], "m_load": 92, "load_state_dict": [92, 104, 105], "assign": 92, "assert": [92, 95, 97, 99, 108], "equal": [92, 94], "thing": [92, 94, 97, 104], "float_weight1": 92, "float_weight2": 92, "quantized_weight1": 92, "quantized_weight2": 92, "go": [92, 97, 108], "techinqu": 92, "reduct": [92, 93, 94, 97], "4x": [92, 93], "0625": 92, "reason": [92, 94], "avoid": [92, 94], "affine_quantized_tensor": 92, "deploi": 93, "engin": 93, "seamlessli": [93, 97, 106, 107], "seamless": [93, 106], "hf": [93, 98], "signific": [93, 94], "pip": [93, 98, 103, 104], "url": [93, 107], "whl": [93, 107], "nightli": 93, "cu128": 93, "push": [93, 94, 98, 99], "hub": [93, 98, 99], "server": [93, 99], "phi": 93, "fp8": 93, "microsoft": 93, "o3": 93, "client": 93, "curl": 93, "localhost": 93, "8000": 93, "chat": 93, "content": 93, "applic": 93, "messag": 93, "role": 93, "give": [93, 94, 97], "me": 93, "short": 93, "larg": [93, 97, 106], "languag": 93, "temperatur": 93, "top_p": 93, "95": 93, "top_k": 93, "max_token": 93, "32768": 93, "vram": 93, "15x": 93, "2x": [93, 94], "littl": [93, 99], "packag": [93, 98], "git": [93, 98], "com": [93, 98], "acceler": [93, 94, 98], "autotoken": [93, 98], "pipelin": 93, "random": [93, 94, 104, 105], "manual_se": [93, 104, 105], "model_path": 93, "device_map": [93, 98, 99], "trust_remote_cod": 93, "ai": 93, "assist": 93, "eat": 93, "banana": 93, "dragonfruit": 93, "smoothi": 93, "blend": 93, "milk": 93, "honei": 93, "salad": 93, "slice": [93, 99], "lemon": 93, "juic": 93, "solv": [93, 94, 97], "equat": 93, "pipe": [93, 98], "text": 93, "generation_arg": 93, "max_new_token": 93, "500": 93, "return_full_text": 93, "do_sampl": 93, "generated_text": 93, "lm_head": 93, "those": [93, 94, 95, 97], "ti": 93, "autoprocessor": 93, "modeling_util": 93, "find_tied_paramet": 93, "model_id": [93, 98], "untied_model": 93, "getattr": [93, 99], "get_text_config": 93, "tie_word_embed": 93, "setattr": [93, 97], "_tied_weights_kei": 93, "user_id": 93, "your_user_id": 93, "model_nam": [93, 103, 106, 107], "save_to": [93, 98], "save_to_local_path": 93, "int8dynamicactivationintxweightconfig": [93, 98], "ve": [93, 94], "intxweightonlyconfig": [93, 98], "fqntoconfig": [93, 99], "untied_model_id": 93, "untied_model_local_path": 93, "embedding_config": 93, "linear_config": 93, "weight_scale_dtyp": 93, "quant_config": 93, "_default": [93, 99], "embed_token": 93, "quant_typ": [93, 98, 99], "include_embed": 93, "untie_embedding_weight": 93, "modules_to_not_convert": 93, "quantized_model": [93, 97, 98, 103, 104, 105], "safe_seri": [93, 98, 99], "pte": 93, "cd": 93, "install_requir": 93, "phi_4_mini": 93, "convert_weight": 93, "pytorch_model": 93, "bin": 93, "pytorch_model_convert": 93, "export_llama": 93, "kv": 93, "use_sdpa_with_kv_cach": 93, "get_bos_id": 93, "199999": 93, "get_eos_id": 93, "200020": 93, "max_seq_length": 93, "max_context_length": 93, "output_nam": 93, "phi4": 93, "phone": 93, "io": 93, "2gb": 93, "iphon": 93, "pro": [93, 94], "17": 93, "sec": 93, "test": [93, 98, 102, 104, 106], "lm": 93, "har": 93, "eleutherai": 93, "lm_eval": 93, "model_arg": 93, "pretrain": [93, 94, 103, 104, 105, 106], "reset_peak_memory_stat": 93, "prompt": [93, 98], "hei": 93, "consciou": 93, "templated_prompt": 93, "apply_chat_templ": 93, "add_generation_prompt": 93, "templat": [93, 100, 101], "return_tensor": 93, "generated_id": 93, "output_text": 93, "batch_decod": 93, "skip_special_token": 93, "clean_up_tokenization_spac": 93, "respons": 93, "mem": 93, "max_memory_reserv": 93, "1e9": 93, "02f": 93, "gb": 93, "hello": [93, 98], "ye": 93, "am": 93, "digit": 93, "todai": 93, "70": [93, 95], "bench": 93, "vllm_disable_compile_cach": 93, "project": 93, "vllm_use_precompil": 93, "sharegpt": 93, "wget": 93, "co": 93, "anon8231489123": 93, "sharegpt_vicuna_unfilt": 93, "resolv": 93, "sharegpt_v3_unfiltered_cleaned_split": 93, "tree": 93, "num": 93, "benchmark_serv": 93, "16x": 93, "14x": 93, "num_prompt": 93, "req": 93, "57": [93, 95], "1000": [93, 106], "68": 93, "80": 93, "entir": [93, 104, 105], "ml": 93, "gain": [93, 94, 107], "eas": 93, "accept": [93, 108], "trade": [93, 94], "off": [93, 94], "neural": [94, 103, 106], "network": [94, 97, 103, 106], "latenc": 94, "carefulli": 94, "pai": 94, "low": [94, 97, 98, 103], "price": 94, "f1": 94, "problem": [94, 97], "research": [94, 102], "fragment": 94, "rightfulli": 94, "spent": 94, "figur": [94, 104], "compress": [94, 103], "place": [94, 103, 104, 105, 106, 107], "dens": 94, "focu": [94, 97], "realli": 94, "concret": [94, 108], "hope": 94, "modular": 94, "nice": 94, "scratch": [94, 102], "minim": [94, 103, 106, 107], "algorthim": 94, "realiz": 94, "theoret": 94, "analog": 94, "fix": [94, 95], "unstructur": 94, "retrain": 94, "neglig": 94, "area": 94, "agre": 94, "upon": 94, "consensu": 94, "mind": 94, "thought": 94, "subproblem": 94, "satisfi": 94, "my": [94, 105], "independ": 94, "frontend": [94, 106], "arbitrari": 94, "handoff": 94, "piec": 94, "natur": [94, 97, 104, 108], "clear": 94, "contract": 94, "7x": 94, "advantag": 94, "anticip": 94, "solut": 94, "third": 94, "parti": 94, "to_sparse_semi_structur": 94, "sparsesemistructuredtensor": 94, "weightnormsparsifi": 94, "half": 94, "subnetwork": 94, "sparse_config": 94, "named_modul": 94, "tensor_fqn": 94, "sparse_block_shap": 94, "zeros_per_block": 94, "fakespars": 94, "fundament": [94, 105], "manipul": 94, "dictionari": 94, "paramer": 94, "parameter": 94, "necessari": [94, 95, 97, 103, 104, 105, 106, 107], "suitabl": [94, 106], "spot": 94, "definit": [94, 99], "academia": 94, "industri": 94, "often": [94, 97], "interchang": 94, "distinct": 94, "idea": 94, "behind": 94, "doesn": [94, 105, 108], "itself": [94, 97], "loos": 94, "speak": 94, "tightli": 94, "coupl": [94, 97], "csc": 94, "qnnpack": 94, "descript": [94, 103], "coo": 94, "sparse_coo": 94, "coordin": 94, "locat": 94, "bsr": 94, "sparse_bsr": 94, "veri": [94, 99, 105], "except": [94, 97, 108], "scalar": [94, 104], "dimension": 94, "csr": 94, "sparse_csr": 94, "sparse_csc": 94, "column": 94, "compact": 94, "sparse_matrix": 94, "1d": 94, "indexptr": 94, "\u00bd": 94, "bitmask": 94, "2bit": 94, "unprun": 94, "quit": [94, 97], "broken": 94, "down": 94, "sensit": 94, "effect": [94, 95, 97, 106, 107, 108], "best": [94, 106], "subsequ": [94, 97, 106, 107], "infinit": 94, "lost": 94, "degre": 94, "drop": 94, "proxi": 94, "aforement": 94, "smallest": 94, "absolut": 94, "scope": 94, "impli": 94, "con": 94, "potenti": [94, 95, 103, 104, 106, 107], "sub": 94, "span": 94, "threshold": 94, "constant": [94, 97, 104], "ctr_mobile_fe": 94, "score": 94, "w": [94, 99], "tenosr": 94, "udpat": 94, "histori": 94, "regrow": 94, "dw": 94, "via": [94, 103], "backprop": 94, "pat": 94, "unmask": 94, "resid": 94, "salienc": 94, "lowest": 94, "l1": 94, "abl": [94, 97, 99, 104, 108], "repeat": [94, 104, 105], "movement": 94, "2005": 94, "07683": 94, "rank": [94, 97], "wx": 94, "sqx": 94, "q": [94, 104], "usual": 94, "sort": 94, "wise": 94, "reconstruct": [94, 99], "randomli": 94, "tri": 94, "remedi": 94, "sometim": 94, "item": [94, 102], "ultim": [94, 95], "complic": [94, 104], "literatur": 94, "vision": 94, "nlp": [94, 102, 106], "iter": [94, 104, 105], "ctr_feed": 94, "na": 94, "multimask": 94, "search": 94, "pyspeech": 94, "fastna": 94, "approach": [94, 97, 103, 106, 107], "knowledg": [94, 102], "distil": 94, "pdf": 94, "2204": 94, "09656": 94, "arrang": 94, "recal": 94, "counterpart": 94, "slower": 94, "suffici": 94, "At": [94, 104], "98": 94, "special": [94, 103, 104], "exhibit": 94, "penalti": 94, "expens": [94, 97], "dictat": 94, "characterist": 94, "highest": 94, "wouldn": [94, 97], "visual": 94, "fig": 94, "4x4": 94, "benchmak": 94, "fly": [95, 98], "affinequantizedminmaxobserv": 95, "record": 95, "welcom": 95, "averag": [95, 104, 105], "histogram": [95, 104], "act_ob": 95, "finfo": 95, "weight_ob": 95, "observedlinear": 95, "observed_input": 95, "observed_weight": 95, "from_float": [95, 97], "float_linear": 95, "observed_linear": 95, "_replace_with_custom_fn_if_matches_filt": 95, "insert_observers_": 95, "lambda": [95, 99], "replacement_fn": 95, "copied_act_ob": 95, "copied_weight_ob": 95, "popul": 95, "feed": 95, "simpler": [95, 104], "quantizedlinear": [95, 97], "isn": 95, "strictli": 95, "to_affine_quantized_intx_stat": 95, "act_scal": [95, 108], "act_zero_point": 95, "calculate_qparam": [95, 108], "weight_scal": [95, 104, 108], "weight_zero_point": [95, 104], "qweight": 95, "qinput": 95, "from_observ": 95, "quantized_linear": [95, 104], "begin": [95, 97], "dataclass": [95, 99, 108], "transform_modul": [95, 99], "register_quantize_module_handl": [95, 99], "staticquantconfig": 95, "_apply_static_qu": 95, "associ": 95, "identifi": [95, 108], "is_observed_linear": 95, "optimizedmodul": 95, "_orig_mod": 95, "0237": 95, "142": 95, "31": [95, 108], "113": 95, "157": 95, "59": 95, "160": 95, "150": 95, "67": 95, "241": 95, "238": 95, "235": 95, "228": 95, "255": [95, 108], "201": 95, "114": 95, "236": 95, "88": [95, 104], "83": 95, "109": 95, "209": 95, "92": 95, "184": 95, "141": 95, "110": 95, "0009": 95, "0010": 95, "130": 95, "122": 95, "132": 95, "125": 95, "126": 95, "129": 95, "127": [95, 97, 107, 108], "133": 95, "124": 95, "131": 95, "135": 95, "136": 95, "foundat": 97, "autograd": [97, 108], "interpos": 97, "namespac": 97, "continu": [97, 98, 105, 106, 107, 108], "obviou": 97, "int8quantizedlinear": 97, "finer": 97, "intercept": 97, "contrast": 97, "clunki": 97, "distributedlinear": 97, "duplic": 97, "bypass": 97, "wrap": [97, 106, 107], "outer": 97, "inner": 97, "allgath": 97, "bandwidth": 97, "exactli": 97, "zoo": 97, "podcast": 97, "edward": 97, "yang": 97, "int8_symmetric_quant": 97, "fp32_tensor": 97, "amin": 97, "amax": 97, "zeros_lik": 97, "view": [97, 104, 105], "clamp": [97, 104], "w_int8": 97, "new_linear": 97, "left": [97, 108], "toymodel": 97, "child": 97, "named_children": 97, "drawback": 97, "won": 97, "suppos": 97, "clean": 97, "eleg": 97, "pretti": 97, "power": [97, 99], "overrid": 97, "almost": 97, "shard": [97, 99], "ragged": 97, "rag": 97, "nestedtensor": 97, "who": 97, "link": [97, 102], "why": [97, 102], "googl": 97, "collab": 97, "flopcount": 97, "memorytrack": 97, "bare": 97, "bone": 97, "int8symmetrictensor": 97, "hold": [97, 98], "staticmethod": 97, "_make_wrapper_subclass": [97, 99], "storage_offset": 97, "ndim": 97, "extra_metadata": 97, "outer_s": [97, 99], "outer_strid": [97, 99], "undo": 97, "repr": 97, "ahead": 97, "insid": 97, "int8_tensor": 97, "op_implementations_dict": 97, "conveni": 97, "register_op": 97, "_op": 97, "opoverload": 97, "impl_decor": 97, "op_impl": 97, "done": 97, "particular": 97, "largest": 97, "tell": 97, "desugar": 97, "surfac": 97, "coverag": [97, 103, 104, 106, 107], "brute": 97, "forc": 97, "repeatedli": 97, "log": 97, "loggingtensor": 97, "_python_dispatch": [97, 99], "return_and_correct_alias": [97, 99], "int8_mm": 97, "int8_view_op": 97, "out_data": 97, "out_scal": [97, 104], "notic": 97, "hit": 97, "background": 97, "decomposit": 97, "live": 97, "decomp": 97, "shrink": 97, "author": [97, 102, 103, 104, 105, 106, 107, 108], "But": [97, 99, 108], "pain": 97, "rather": 97, "worth": 97, "written": 97, "differenti": 97, "nuanc": 97, "longer": [97, 104, 105], "had": [97, 104], "transpos": 97, "That": 97, "transposit": 97, "got": [97, 104, 108], "propag": [97, 104, 106, 107], "fact": 97, "themselv": [97, 104], "pointwis": [97, 106, 107], "were": 97, "might": [97, 99, 104, 108], "unwrap": 97, "dim0": 97, "dim1": 97, "confirm": 97, "quantized_model_module_swap": 97, "quantized_model_subclass": 97, "subclass_param": 97, "out_module_swap": 97, "allclos": 97, "out_compil": 97, "seri": 97, "discuss": 97, "float8dynamicactivationint4weightconfig": 98, "torch_dtyp": 98, "fluxpipelin": 98, "fluxtransformer2dmodel": 98, "black": 98, "forest": 98, "lab": 98, "flux": 98, "dev": 98, "subfold": 98, "cat": [98, 108], "sign": [98, 107], "world": [98, 99], "num_inference_step": 98, "guidance_scal": 98, "png": 98, "temporarydirectori": 98, "tmp_dir": 98, "uncom": 98, "usernam": [98, 99], "statu": [98, 99], "becom": [98, 104], "stabl": 98, "int4wo": 98, "team": [98, 99], "retain": 98, "thoroughli": 98, "e2": 99, "_type": 99, "_data": 99, "capabl": [99, 104, 106], "self_attn": 99, "q_proj": 99, "k_proj": 99, "mlp": 99, "gate_proj": 99, "narrow": 99, "chunk": 99, "heavi": 99, "codebas": 99, "fn": 99, "ctx": 99, "new_tensor": 99, "__class__": 99, "principl": 99, "mynewquantconfig": 99, "classvar": 99, "myquantizedtensor": 99, "tensor_data_attr": 99, "tensor_attribut": 99, "attr": 99, "fill_default": 99, "notimplementederror": 99, "_my_quant_transform": 99, "my_quantization_funct": 99, "use_cutlass_kernel": 99, "my_cutlass_linear": 99, "use_triton_kernel": 99, "my_triton_linear": 99, "disappear": 99, "unless": 99, "extrem": 99, "sole": 99, "explicitli": [99, 108], "spooki": 99, "distanc": 99, "due": [99, 103, 108], "workaround": 99, "2338": 99, "detect": 99, "illustr": 99, "tutorials_python": 100, "zip": 100, "jupyt": [100, 102], "notebook": [100, 102], "tutorials_jupyt": 100, "galleri": [100, 102], "sphinx": [100, 102], "004": [101, 102], "total": [101, 102], "template_tutori": [101, 102], "click": 102, "firstnam": 102, "lastnam": 102, "prerequisit": [102, 104], "topic": 102, "rand": [102, 104, 105], "1579": 102, "4609": 102, "0919": 102, "9954": 102, "8368": 102, "5514": 102, "1453": 102, "6407": 102, "7218": 102, "2994": 102, "3712": 102, "9924": 102, "5169": 102, "8998": 102, "8343": 102, "practic": 102, "summar": 102, "takeawai": 102, "link1": 102, "link2": 102, "minut": 102, "ipynb": 102, "daniil": 103, "lyakhov": 103, "aamir": 103, "nazir": 103, "alexand": 103, "suslov": 103, "yamini": 103, "nimmagadda": 103, "kozlov": 103, "subject": [103, 105], "openvinoquant": 103, "unlock": 103, "placement": 103, "ux": [103, 104, 106], "torchdynamo": [103, 106, 107, 108], "eager": [103, 104, 105, 106, 107, 108], "mechan": [103, 106, 107], "torchvis": [103, 104, 105, 106, 107, 108], "resnet18": [103, 104, 105, 106, 107], "__dict__": [103, 104, 105, 106, 107], "dummi": [103, 106, 107], "traced_b": [103, 106, 107], "exported_model": [103, 104, 105, 106, 107], "preset": 103, "elu": 103, "prelu": 103, "gelu": 103, "quantizationpreset": 103, "bert": [103, 106], "modeltyp": 103, "ignored_scop": 103, "exclud": 103, "layer_1": 103, "layer_2": 103, "layer_3": 103, "ignoredscop": 103, "conv2d": [103, 104, 105, 106, 107, 108], "regex": 103, "layer_": 103, "subgraph": [103, 105], "node": [103, 105, 106, 107, 108], "target_devic": 103, "taken": 103, "account": 103, "cpu_spr": 103, "npu": 103, "targetdevic": 103, "fold": [103, 104, 106, 107], "batchnorm": [103, 104, 105, 106, 107], "preced": [103, 104, 106, 107], "prepared_model": [103, 104, 105, 106, 107], "fold_quant": 103, "finish": [103, 106], "comparison": 103, "smoothquant": 103, "biascorrect": 103, "discrep": 103, "calibration_load": 103, "dataload": [103, 104, 105], "transform_fn": 103, "data_item": 103, "calibration_dataset": 103, "smooth_quant": 103, "fast_bias_correct": 103, "deploy": [103, 106], "jerri": [104, 106, 108], "zhang": [104, 106, 107, 108], "_export": [104, 105], "fx": [104, 108], "14k": 104, "programm": [104, 106, 107], "db": 104, "xnnpack": [104, 105, 108], "xnnpack_quant": [104, 105], "get_symmetric_quantization_config": [104, 105], "xnnpackquant": [104, 105, 108], "prior": 104, "qconfigmap": [104, 108], "backendconfig": [104, 108], "rel": 104, "intent": [104, 108], "qconfig": [104, 108], "3d": [104, 108], "incompat": 104, "great": 104, "ideal": 104, "fake_qu": 104, "hidden": 104, "summari": 104, "address": 104, "thu": 104, "queri": [104, 108], "previous": 104, "embedding_byt": 104, "executorchquant": 104, "concaten": 104, "prone": 104, "cleaner": 104, "composed_quant": 104, "quantization_cap": 104, "concern": 104, "decoupl": 104, "minmax": 104, "freed": 104, "identitc": 104, "imagenet": [104, 105], "unzip": [104, 105], "data_path": [104, 105], "renam": [104, 105], "resnet18_pretrained_float": [104, 105], "sy": [104, 105], "numpi": [104, 105], "np": [104, 105], "resnet": [104, 105, 106], "warn": [104, 105], "filterwarn": [104, 105], "categori": [104, 105], "deprecationwarn": [104, 105], "r": [104, 105], "seed": [104, 105], "191009": [104, 105], "averagemet": [104, 105], "fmt": [104, 105], "val": [104, 105], "avg": [104, 105], "count": [104, 105], "__str__": [104, 105], "fmtstr": [104, 105], "topk": [104, 105], "predict": [104, 105], "maxk": [104, 105], "pred": [104, 105], "eq": [104, 105], "expand_a": [104, 105], "correct_k": [104, 105], "mul_": [104, 105], "criterion": [104, 105], "top1": [104, 105], "top5": [104, 105], "cnt": [104, 105], "acc1": [104, 105], "acc5": [104, 105], "load_model": [104, 105], "model_fil": [104, 105], "weights_onli": [104, 105], "print_size_of_model": [104, 105], "temp": [104, 105], "p": [104, 105], "1e6": [104, 105], "prepare_data_load": [104, 105], "485": [104, 105], "456": [104, 105], "std": [104, 105], "229": [104, 105], "225": [104, 105], "randomresizedcrop": [104, 105], "randomhorizontalflip": [104, 105], "totensor": [104, 105], "dataset_test": [104, 105], "resiz": [104, 105], "centercrop": [104, 105], "train_sampl": [104, 105], "randomsampl": [104, 105], "test_sampl": [104, 105], "sequentialsampl": [104, 105], "train_batch_s": [104, 105], "sampler": [104, 105], "data_loader_test": [104, 105, 106, 107], "eval_batch_s": [104, 105], "saved_model_dir": [104, 105], "float_model_fil": [104, 105], "model_to_quant": [104, 105], "capture_pre_autograd_graph": [104, 105], "dynamic_shap": [104, 105], "dynamic_dim": [104, 105], "constraint": [104, 105, 108], "qconfig_opt": 104, "set_object_typ": 104, "set_module_nam": 104, "workload": 104, "themodel": 104, "feedback": 104, "dq": 104, "fp32_op": 104, "qauntiz": 104, "x_int8": 104, "x_zero_point": 104, "weight_int8": 104, "bias_fp32": 104, "output_scal": 104, "output_zero_point": 104, "x_fp32": 104, "quantized_decompos": 104, "dequantize_per_tensor": 104, "x_i8": 104, "x_quant_min": 104, "x_quant_max": 104, "weight_fp32": 104, "weight_i8": 104, "weight_quant_min": 104, "weight_quant_max": 104, "weight_permut": 104, "permute_copi": 104, "out_fp32": 104, "addmm": 104, "out_i8": 104, "quantize_per_tensor": 104, "out_zero_point": 104, "out_quant_min": 104, "out_quant_max": 104, "float32_op": 104, "decompos": 104, "use_reference_represent": 104, "x_int16": 104, "weight_int16": 104, "acc_int32": 104, "out_dtyp": 104, "bias_scal": 104, "bias_int32": 104, "div": 104, "mul": 104, "out_int8": 104, "qmin": 104, "qmax": 104, "date": 104, "unus": 104, "serila": 104, "consult": 104, "exportedprogram": 104, "pt2e_quantized_model_file_path": 104, "resnet18_pt2e_quant": 104, "quantized_ep": 104, "loaded_quantized_ep": 104, "loaded_quantized_model": 104, "diff": 104, "79": 104, "82": 104, "55": 104, "edg": [104, 108], "went": 104, "andrew": 105, "Or": 105, "move_exported_model_to_ev": [105, 106], "correctli": 105, "certain": 105, "dropout": 105, "move_exported_model_to_train": 105, "jit": 105, "recursivescriptmodul": 105, "train_one_epoch": 105, "ntrain_batch": 105, "avgloss": 105, "5f": 105, "start_tim": 105, "global_avg": 105, "is_qat": [105, 106], "fusion": 105, "batchnorm2d": 105, "_native_batch_norm_legit": 105, "cudnn_batch_norm": 105, "mobilenetv2": 105, "manual": 105, "recompil": 105, "consolid": 105, "epoch": 105, "far": 105, "num_epoch": 105, "num_train_batch": 105, "num_eval_batch": 105, "num_observer_update_epoch": 105, "num_batch_norm_update_epoch": 105, "num_epochs_between_ev": 105, "nepoch": 105, "stat": 105, "subseq": 105, "disable_observ": 105, "bn": 105, "running_mean": 105, "running_var": 105, "new_arg": 105, "wish": 105, "prepared_model_copi": 105, "neval_batch": 105, "paus": 105, "resum": 105, "fail": [105, 108], "checkpoint_path": 105, "checkpoint_": 105, "behav": 105, "incorrectli": 105, "lesli": [106, 108], "fang": [106, 108], "weiwen": [106, 108], "xia": [106, 108], "jiong": [106, 108], "gong": [106, 108], "cnn": 106, "rnn": 106, "outstand": 106, "fourth": 106, "spr": 106, "xeon": 106, "processor": 106, "boost": 106, "channels_last": [106, 107], "onednn": [106, 107], "assum": [106, 108], "word": 106, "satur": 106, "pure": 106, "dedic": 106, "scenario": [106, 107], "plai": [106, 107], "convolut": [106, 107, 108], "absenc": [106, 107], "enhanc": [106, 107], "mirror": [106, 107], "autocast": [106, 107], "device_typ": [106, 107], "turn": [106, 107], "cpp": 106, "qconvolut": [106, 107], "qlinear": [106, 107], "presenc": [106, 107], "pair": [106, 107], "remain": [106, 107], "conting": [106, 107], "qmaxpool2d": [106, 107], "torchinductor_freez": [106, 107], "example_x86inductorquantizer_pytorch_2_1": 106, "torchbench": 106, "measur": 106, "proven": 106, "depth": 106, "example_x86inductorquantizer_qat": 106, "yan": 107, "zhiwei": 107, "wang": 107, "eikan": 107, "liangang": 107, "liu": 107, "river": 107, "cui": 107, "yifeng": 107, "xpuinductorquant": 107, "pip3": 107, "torchaudio": 107, "xpu_inductor_quantizer_exampl": 107, "xpu_inductor_quant": 107, "xpuiq": 107, "resnet18_weight": 107, "get_default_xpu_inductor_quantization_config": 107, "wherea": 107, "histogramobserv": [107, 108], "perchannelminmaxobserv": 107, "quantizationspec": [107, 108], "quantizationconfig": [107, 108], "type_check": 107, "observerorfakequantizeconstructor": 107, "get_xpu_inductor_symm_quantization_config": 107, "extra_arg": 107, "act_observer_or_fake_quant_ctr": 107, "act_quantization_spec": [107, 108], "qscheme": [107, 108], "per_tensor_symmetr": [107, 108], "observer_or_fake_quant_ctr": [107, 108], "with_arg": [107, 108], "weight_observer_or_fake_quant_ctr": 107, "weight_quantization_spec": [107, 108], "per_channel_symmetr": 107, "ch_axi": 107, "oc": 107, "ic": 107, "kh": 107, "kw": 107, "conv": [107, 108], "bias_quantization_spec": 107, "amp": 107, "indcutor": 107, "kimish": 108, "patel": 108, "made": 108, "explicit": 108, "quantiat": 108, "encod": 108, "convei": 108, "quantizationannot": 108, "furthermor": 108, "minmaxobserv": 108, "input_qspec_map": 108, "output_qspec": 108, "_annot": 108, "conclud": 108, "matcher": 108, "get_source_partit": 108, "add_partit": 108, "gm": 108, "itertool": 108, "chain": 108, "add_nod": 108, "output_nod": 108, "per_tensor_affin": 108, "input_act_qspec": 108, "output_act_qspec": 108, "input_act0": 108, "input_act1": 108, "quantization_annot": 108, "substitut": 108, "among": 108, "sharedquantizationspec": 108, "maxpool": 108, "average_pool": 108, "concat": 108, "whose": 108, "edgeornod": 108, "transit": 108, "spec": 108, "conv1": 108, "conv2": 108, "fed": 108, "conv1_out": 108, "conv2_out": 108, "qspec1": 108, "cat_input0": 108, "cat_input1": 108, "therefor": 108, "ob": 108, "consum": 108, "rewrit": 108, "share_qparams_with_input_act0_qspec": 108, "known": 108, "beforehand": 108, "sigmoid": 108, "fixedqparamsquantizationspec": 108, "act_qspec": 108, "sigmoid_nod": 108, "input_act": 108, "derivedquantizationspec": 108, "derive_qparams_fn": 108, "observerorfakequant": 108, "observerbas": 108, "fakequantizebas": 108, "heurist": 108, "obejct": 108, "obs_or_fq": 108, "fq": 108, "act_obs_or_fq": 108, "weight_obs_or_fq": 108, "act_zp": 108, "weight_zp": 108, "bias_qspec": 108, "derived_from": 108, "backendquant": 108, "get_input_act_qspec": 108, "get_output_act_qspec": 108, "get_weight_qspec": 108, "get_bias_qspec": 108, "intermedi": 108, "straightforward": 108, "call_funct": 108, "relu_": 108, "relu_nod": 108, "maybe_conv_nod": 108, "conv1d": 108, "unexpect": 108, "recognz": 108, "subgraphmatch": 108, "conv_relu_pattern": 108, "name_node_map": 108, "input_nod": 108, "weight_nod": 108, "bias_nod": 108, "caveat": 108, "exhaust": 108, "2d": 108, "4d": 108, "symbol": 108, "outcom": 108}, "objects": {"torchao.dtypes": [[13, 0, 1, "", "AffineQuantizedTensor"], [14, 0, 1, "", "CutlassSemiSparseLayout"], [15, 0, 1, "", "Float8Layout"], [16, 0, 1, "", "Int4CPULayout"], [17, 0, 1, "", "Layout"], [18, 0, 1, "", "NF4Tensor"], [19, 0, 1, "", "PlainLayout"], [20, 0, 1, "", "SemiSparseLayout"], [21, 0, 1, "", "TensorCoreTiledLayout"], [22, 2, 1, "", "to_affine_quantized_floatx"], [23, 2, 1, "", "to_affine_quantized_floatx_static"], [24, 2, 1, "", "to_affine_quantized_intx"], [25, 2, 1, "", "to_affine_quantized_intx_static"], [26, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[13, 1, 1, "", "dequantize"], [13, 1, 1, "", "from_hp_to_floatx"], [13, 1, 1, "", "from_hp_to_floatx_static"], [13, 1, 1, "", "from_hp_to_intx"], [13, 1, 1, "", "from_hp_to_intx_static"], [13, 1, 1, "", "to"]], "torchao.dtypes.NF4Tensor": [[18, 1, 1, "", "convert_to_norm_float_weight"], [18, 1, 1, "", "dequantize"], [18, 1, 1, "", "dequantize_scalers"], [18, 1, 1, "", "double_quantize_scalers"], [18, 1, 1, "", "get_original_weight"], [18, 1, 1, "", "quantize_tensor_nearest"]], "torchao.float8": [[27, 0, 1, "", "CastConfig"], [28, 0, 1, "", "Float8LinearConfig"], [29, 0, 1, "", "ScalingGranularity"], [30, 0, 1, "", "ScalingType"], [31, 2, 1, "", "convert_to_float8_training"], [32, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[28, 1, 1, "", "from_recipe_name"]], "torchao.prototype.dtypes": [[33, 0, 1, "", "BlockSparseLayout"], [34, 0, 1, "", "CutlassInt4PackedLayout"], [35, 0, 1, "", "Int8DynamicActInt4WeightCPULayout"], [36, 0, 1, "", "UintxLayout"]], "torchao.quantization": [[37, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [38, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [39, 0, 1, "", "Float8WeightOnlyConfig"], [40, 0, 1, "", "Int4WeightOnlyConfig"], [41, 0, 1, "", "Int8DynamicActivationInt4WeightConfig"], [42, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [43, 0, 1, "", "Int8WeightOnlyConfig"], [44, 0, 1, "", "MappingType"], [45, 0, 1, "", "TorchAODType"], [46, 2, 1, "", "choose_qparams_affine"], [47, 2, 1, "", "choose_qparams_affine_with_min_max"], [48, 2, 1, "", "dequantize_affine"], [49, 2, 1, "", "int_scaled_matmul"], [74, 2, 1, "", "quantize_"], [79, 2, 1, "", "quantize_affine"], [80, 2, 1, "", "safe_int_mm"]], "torchao.quantization.qat": [[50, 0, 1, "", "ComposableQATQuantizer"], [51, 0, 1, "", "FakeQuantizeConfigBase"], [52, 0, 1, "", "FakeQuantizedEmbedding"], [53, 0, 1, "", "FakeQuantizedLinear"], [54, 0, 1, "", "FakeQuantizerBase"], [55, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [56, 0, 1, "", "Float8FakeQuantizeConfig"], [57, 0, 1, "", "Float8FakeQuantizer"], [58, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [59, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [60, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [61, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [62, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [63, 0, 1, "", "IntxFakeQuantizeConfig"], [64, 0, 1, "", "IntxFakeQuantizer"], [65, 0, 1, "", "QATConfig"], [66, 0, 1, "", "QATStep"], [69, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[52, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[53, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[55, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[57, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[59, 1, 1, "", "convert"], [59, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[63, 3, 1, "", "group_size"], [63, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[64, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[67, 0, 1, "", "Int4WeightOnlyEmbedding"], [68, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[67, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[70, 0, 1, "", "Int4WeightOnlyQATLinear"], [71, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [72, 2, 1, "", "disable_linear_fake_quant"], [73, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[75, 0, 1, "", "KernelPreference"], [76, 0, 1, "", "PackingFormat"], [77, 0, 1, "", "QuantizeTensorKwargs"], [78, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[75, 4, 1, "", "AUTO"], [75, 4, 1, "", "FBGEMM"], [75, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[76, 4, 1, "", "PLAIN"]], "torchao": [[6, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[81, 0, 1, "", "PerChannelNormObserver"], [82, 0, 1, "", "WandaSparsifier"], [83, 2, 1, "", "apply_fake_sparsity"], [84, 4, 1, "", "semi_sparse_weight"], [85, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[81, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[82, 1, 1, "", "prepare"], [82, 1, 1, "", "squash_mask"], [82, 1, 1, "", "update_mask"]], "torchao.utils": [[86, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[86, 1, 1, "", "get_tensor_impl_constructor"], [86, 1, 1, "", "implements"], [86, 1, 1, "", "implements_torch_function"], [86, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 87, 89, 90, 99], "dtype": [0, 11, 90], "layout": [0, 17], "tensor": [0, 7, 10, 90, 96, 97, 99, 108], "subclass": [0, 7, 10, 97, 99], "quantiz": [0, 4, 5, 7, 12, 74, 87, 90, 91, 93, 95, 96, 97, 98, 99, 103, 104, 105, 106, 107, 108], "techniqu": 0, "prototyp": [0, 4], "float8": [1, 12, 89, 90], "main": [1, 4, 5], "train": [1, 12, 89, 90, 93, 103, 104, 105, 106, 107], "api": [1, 2, 4, 5, 7, 8, 12, 87, 89, 108], "other": [1, 10, 90], "type": [1, 98], "refer": [2, 87], "python": 2, "kernel": [3, 10, 88, 90, 99], "qat": [4, 12, 105], "config": 4, "quantize_": [4, 5, 7], "custom": [4, 10], "legaci": 4, "infer": [5, 93], "primit": [5, 90], "sparsiti": [6, 94], "util": 7, "common": [7, 8, 108], "benchmark": [8, 9, 10, 93], "guid": [8, 9, 10, 91, 99], "add": [8, 99], "an": [8, 92], "recip": [8, 89], "model": [8, 10, 89, 90, 92, 93, 98, 99, 103, 104, 105], "design": [8, 94], "consider": 8, "hf": 8, "ci": 8, "dashboard": 8, "1": [8, 12, 89, 93, 98, 99, 103, 106, 107, 108], "modifi": 8, "exist": 8, "configur": [8, 94, 99, 104, 105], "2": [8, 12, 91, 93, 98, 99, 103, 104, 105, 106, 107, 108], "run": 8, "3": [8, 12, 93, 99, 103, 106, 107, 108], "output": [8, 97], "format": [8, 90], "4": [8, 103, 108], "integr": [8, 12, 98, 99], "pipelin": 8, "troubleshoot": 8, "test": [8, 10], "issu": 8, "best": 8, "practic": 8, "user": 9, "contributor": 10, "gener": 10, "extend": 10, "ad": [10, 99], "new": [10, 99], "effici": [10, 90], "triton": 10, "hand": 10, "written": 10, "us": [10, 108], "kernelprefer": [10, 75], "flow": [10, 90, 92, 99, 108], "torch": [10, 103, 104, 105], "compil": [10, 99, 103], "perform": [10, 88, 93, 104], "serial": [10, 92, 99], "featur": 10, "support": [10, 98, 99], "function": [10, 104, 105], "compos": 10, "microbenchmark": 10, "eval": [10, 104], "part": [12, 89, 93], "fine": 12, "tune": 12, "qlora": 12, "awar": [12, 90, 105, 106], "option": [12, 93, 102, 103], "torchtun": 12, "axolotl": 12, "low": [12, 90], "rank": 12, "adapt": 12, "huggingfac": [12, 93, 99], "peft": 12, "affinequantizedtensor": 13, "cutlasssemisparselayout": 14, "float8layout": 15, "int4cpulayout": 16, "nf4tensor": 18, "plainlayout": 19, "semisparselayout": 20, "tensorcoretiledlayout": 21, "to_affine_quantized_floatx": 22, "to_affine_quantized_floatx_stat": 23, "to_affine_quantized_intx": 24, "to_affine_quantized_intx_stat": 25, "to_nf4": 26, "castconfig": 27, "float8linearconfig": 28, "scalinggranular": 29, "scalingtyp": 30, "convert_to_float8_train": 31, "precompute_float8_dynamic_scale_for_fsdp": 32, "blocksparselayout": 33, "cutlassint4packedlayout": 34, "int8dynamicactint4weightcpulayout": 35, "uintxlayout": 36, "float8dynamicactivationfloat8weightconfig": 37, "float8dynamicactivationint4weightconfig": 38, "float8weightonlyconfig": 39, "int4weightonlyconfig": 40, "int8dynamicactivationint4weightconfig": 41, "int8dynamicactivationint8weightconfig": 42, "int8weightonlyconfig": 43, "mappingtyp": 44, "torchaodtyp": 45, "choose_qparams_affin": 46, "choose_qparams_affine_with_min_max": 47, "dequantize_affin": 48, "int_scaled_matmul": 49, "composableqatquant": 50, "fakequantizeconfigbas": 51, "fakequantizedembed": 52, "fakequantizedlinear": 53, "fakequantizerbas": 54, "float8actint4weightqatquant": 55, "float8fakequantizeconfig": 56, "float8fakequant": 57, "fromintxquantizationawaretrainingconfig": 58, "int4weightonlyembeddingqatquant": 59, "int4weightonlyqatquant": 60, "int8dynactint4weightqatquant": 61, "intxquantizationawaretrainingconfig": 62, "intxfakequantizeconfig": 63, "intxfakequant": 64, "qatconfig": 65, "qatstep": 66, "int4weightonlyembed": 67, "int4weightonlyqatembed": 68, "initialize_fake_quant": 69, "int4weightonlyqatlinear": 70, "int8dynactint4weightqatlinear": 71, "disable_linear_fake_qu": 72, "enable_linear_fake_qu": 73, "packingformat": 76, "quantizetensorkwarg": 77, "_choose_quant_func_and_quantize_tensor": 78, "quantize_affin": 79, "safe_int_mm": 80, "perchannelnormobserv": 81, "wandasparsifi": 82, "apply_fake_spars": 83, "semi_sparse_weight": 84, "sparsifi": 85, "torchaobasetensor": 86, "welcom": 87, "document": 87, "get": 87, "start": [87, 91, 98], "develop": 87, "note": [87, 89, 108], "eager": 87, "tutori": [87, 102], "pt2e": [87, 108], "pre": 89, "torchtitan": 89, "prerequisit": [89, 103, 106, 107, 108], "rowwis": 89, "scale": 89, "tensorwis": 89, "pick": 89, "import": [89, 104, 105], "directli": [89, 108], "convers": 89, "overview": [90, 94, 102], "basic": 90, "op": 90, "deriv": [90, 108], "pack": 90, "algorithm": 90, "weight": [90, 93], "onli": 90, "dynam": 90, "activ": 90, "static": [90, 95], "bit": 90, "optim": [90, 92, 93], "case": 90, "studi": 90, "how": [90, 104, 105, 108], "work": 90, "dure": 90, "execut": 90, "save": [90, 98, 104, 105], "load": [90, 104, 105], "quick": [91, 98], "first": 91, "exampl": [91, 98, 99, 108], "pytorch": [91, 103, 104, 105, 106, 107, 108], "export": [91, 93, 103, 104, 105, 106, 107, 108], "next": [91, 97], "step": [91, 93, 97, 99, 102], "deseri": 92, "what": [92, 97], "happen": 92, "when": 92, "serv": [93, 99], "vllm": [93, 99], "sglang": 93, "executorch": 93, "post": [93, 103, 104, 106, 107], "transform": [93, 98, 99], "mobil": 93, "deploy": 93, "unti": 93, "embed": 93, "creat": [93, 99], "characterist": 93, "evalu": [93, 104], "qualiti": 93, "assess": 93, "memori": 93, "latenc": 93, "result": 93, "h100": 93, "machin": 93, "conclus": [93, 102, 103, 104, 105, 106, 107, 108], "goal": 94, "context": 94, "prune": 94, "criteria": 94, "strategi": 94, "pattern": [94, 108], "calibr": [95, 104], "phase": 95, "write": [96, 97, 108], "your": [96, 97, 99], "own": [96, 97], "advanc": 96, "ar": 97, "modul": 97, "swap": 97, "which": 97, "oper": [97, 99, 108], "should": 97, "we": 97, "implement": [97, 99], "compar": 97, "hug": 98, "face": 98, "usag": [98, 99], "diffus": 98, "architectur": 99, "system": 99, "class": 99, "fqn": 99, "method": 99, "minim": 99, "requir": 99, "compat": 99, "why": 99, "regist": 99, "": 99, "kei": 99, "detail": 99, "hardwar": 99, "specif": [99, 104, 105], "linear": 99, "benefit": 99, "trade": 99, "off": 99, "share": [99, 108], "safetensor": 99, "diagram": 99, "high": 99, "level": 99, "point": 99, "dispatch": 99, "bring": 99, "extern": 99, "comput": 101, "time": 101, "templat": 102, "addit": 102, "exercis": 102, "further": 102, "read": 102, "openvino": 103, "backend": [103, 104, 105, 106, 107], "introduct": [103, 106, 107, 108], "nncf": 103, "instal": 103, "captur": [103, 106, 107], "fx": [103, 106, 107], "graph": [103, 106, 107], "appli": [103, 106, 107], "lower": [103, 104, 106, 107], "represent": 103, "improv": 103, "metric": 103, "motiv": [104, 108], "defin": [104, 105], "helper": [104, 105], "prepar": [104, 105], "dataset": [104, 105], "set": 104, "mode": 104, "convert": [104, 105], "check": 104, "size": 104, "accuraci": 104, "debug": 104, "loop": 105, "checkpoint": 105, "x86": 106, "through": [106, 107], "inductor": [106, 107], "intel": 107, "gpu": 107, "annot": 108, "param": 108, "fix": 108, "paramet": 108, "5": 108, "A": 108, "toi": 108, "resnet18": 108, "ir": 108, "problem": 108, "match": 108, "aten": 108, "recommend": 108, "subgraphmatcherwithnamenodemap": 108}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torchao.dtypes": [[0, "torchao-dtypes"]], "Layouts and Tensor Subclasses": [[0, "layouts-and-tensor-subclasses"]], "Quantization techniques": [[0, "quantization-techniques"]], "Prototype": [[0, "prototype"], [4, "prototype"]], "torchao.float8": [[1, "torchao-float8"]], "Main float8 training APIs": [[1, "main-float8-training-apis"]], "Other float8 training types": [[1, "other-float8-training-types"]], "torchao API Reference": [[2, "torchao-api-reference"]], "Python API Reference": [[2, null]], "torchao.kernel": [[3, "torchao-kernel"]], "torchao.quantization.qat": [[4, "torchao-quantization-qat"]], "Main Config for quantize_": [[4, "main-config-for-quantize"]], "Custom QAT APIs": [[4, "custom-qat-apis"]], "Legacy QAT APIs": [[4, "legacy-qat-apis"]], "torchao.quantization": [[5, "torchao-quantization"]], "Main Quantization APIs": [[5, "main-quantization-apis"]], "Inference APIs for quantize_": [[5, "inference-apis-for-quantize"]], "Quantization Primitives": [[5, "quantization-primitives"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "torchao.utils": [[7, "torchao-utils"]], "Tensor Subclass Utils": [[7, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[7, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[7, "quantize-api-common-utils"]], "Benchmarking API Guide": [[8, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[8, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[8, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[8, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[8, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[8, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[8, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[8, "run-ci-benchmarks"]], "3. CI Output Format": [[8, "ci-output-format"]], "4. Integration with CI Pipeline": [[8, "integration-with-ci-pipeline"]], "Troubleshooting": [[8, "troubleshooting"]], "Running Tests": [[8, "running-tests"]], "Common Issues": [[8, "common-issues"]], "Best Practices": [[8, "best-practices"]], "Benchmarking User Guide": [[9, "benchmarking-user-guide"]], "Contributor Guide": [[10, "contributor-guide"]], "General Guide on Extending torchao": [[10, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[10, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[10, "adding-efficient-kernels"]], "Custom triton kernels": [[10, "custom-triton-kernels"]], "Custom hand written kernels": [[10, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[10, "using-hand-written-kernels-in-tensor-subclasses"]], "KernelPreference": [[10, "kernelpreference"], [75, "kernelpreference"]], "Flow": [[10, "flow"]], "Using torch.compile for Performance": [[10, "using-torch-compile-for-performance"]], "Serialization": [[10, "serialization"], [92, "serialization"]], "Other Feature Support": [[10, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[10, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[10, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[10, "model-benchmarks-and-eval"]], "Dtypes": [[11, "dtypes"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[12, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[12, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[12, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[12, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[12, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[12, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[12, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[12, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[12, "float8-quantized-fine-tuning"]], "AffineQuantizedTensor": [[13, "affinequantizedtensor"]], "CutlassSemiSparseLayout": [[14, "cutlasssemisparselayout"]], "Float8Layout": [[15, "float8layout"]], "Int4CPULayout": [[16, "int4cpulayout"]], "Layout": [[17, "layout"]], "NF4Tensor": [[18, "nf4tensor"]], "PlainLayout": [[19, "plainlayout"]], "SemiSparseLayout": [[20, "semisparselayout"]], "TensorCoreTiledLayout": [[21, "tensorcoretiledlayout"]], "to_affine_quantized_floatx": [[22, "to-affine-quantized-floatx"]], "to_affine_quantized_floatx_static": [[23, "to-affine-quantized-floatx-static"]], "to_affine_quantized_intx": [[24, "to-affine-quantized-intx"]], "to_affine_quantized_intx_static": [[25, "to-affine-quantized-intx-static"]], "to_nf4": [[26, "to-nf4"]], "CastConfig": [[27, "castconfig"]], "Float8LinearConfig": [[28, "float8linearconfig"]], "ScalingGranularity": [[29, "scalinggranularity"]], "ScalingType": [[30, "scalingtype"]], "convert_to_float8_training": [[31, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[32, "precompute-float8-dynamic-scale-for-fsdp"]], "BlockSparseLayout": [[33, "blocksparselayout"]], "CutlassInt4PackedLayout": [[34, "cutlassint4packedlayout"]], "Int8DynamicActInt4WeightCPULayout": [[35, "int8dynamicactint4weightcpulayout"]], "UintxLayout": [[36, "uintxlayout"]], "Float8DynamicActivationFloat8WeightConfig": [[37, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[38, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[39, "float8weightonlyconfig"]], "Int4WeightOnlyConfig": [[40, "int4weightonlyconfig"]], "Int8DynamicActivationInt4WeightConfig": [[41, "int8dynamicactivationint4weightconfig"]], "Int8DynamicActivationInt8WeightConfig": [[42, "int8dynamicactivationint8weightconfig"]], "Int8WeightOnlyConfig": [[43, "int8weightonlyconfig"]], "MappingType": [[44, "mappingtype"]], "TorchAODType": [[45, "torchaodtype"]], "choose_qparams_affine": [[46, "choose-qparams-affine"]], "choose_qparams_affine_with_min_max": [[47, "choose-qparams-affine-with-min-max"]], "dequantize_affine": [[48, "dequantize-affine"]], "int_scaled_matmul": [[49, "int-scaled-matmul"]], "ComposableQATQuantizer": [[50, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[51, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[52, "fakequantizedembedding"]], "FakeQuantizedLinear": [[53, "fakequantizedlinear"]], "FakeQuantizerBase": [[54, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[55, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[56, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[57, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[58, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[59, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[60, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[61, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[62, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[63, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[64, "intxfakequantizer"]], "QATConfig": [[65, "qatconfig"]], "QATStep": [[66, "qatstep"]], "Int4WeightOnlyEmbedding": [[67, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[68, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[69, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[70, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[71, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[72, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[73, "enable-linear-fake-quant"]], "quantize": [[74, "quantize"]], "PackingFormat": [[76, "packingformat"]], "QuantizeTensorKwargs": [[77, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[78, "choose-quant-func-and-quantize-tensor"]], "quantize_affine": [[79, "quantize-affine"]], "safe_int_mm": [[80, "safe-int-mm"]], "PerChannelNormObserver": [[81, "perchannelnormobserver"]], "WandaSparsifier": [[82, "wandasparsifier"]], "apply_fake_sparsity": [[83, "apply-fake-sparsity"]], "semi_sparse_weight": [[84, "semi-sparse-weight"]], "sparsify": [[85, "sparsify"]], "TorchAOBaseTensor": [[86, "torchaobasetensor"]], "Welcome to the torchao Documentation": [[87, "welcome-to-the-torchao-documentation"]], "Getting Started": [[87, null]], "Developer Notes": [[87, null]], "API Reference": [[87, null]], "Eager Quantization Tutorials": [[87, null]], "PT2E Quantization Tutorials": [[87, null]], "Performant Kernels": [[88, "performant-kernels"]], "(Part 1) Pre-training with float8": [[89, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[89, "pre-training-with-torchtitan"]], "Prerequisites": [[89, "prerequisites"], [89, "id1"], [103, "prerequisites"], [106, "prerequisites"], [107, "prerequisites"]], "Rowwise scaling": [[89, "rowwise-scaling"]], "Tensorwise scaling": [[89, "tensorwise-scaling"]], "Picking a recipe": [[89, "picking-a-recipe"]], "Important notes": [[89, "important-notes"]], "Pre-training with torchao directly": [[89, "pre-training-with-torchao-directly"]], "Model conversion API": [[89, "model-conversion-api"]], "Quantization Overview": [[90, "quantization-overview"]], "Basic DTypes": [[90, "basic-dtypes"]], "Quantization Primitive Ops": [[90, "quantization-primitive-ops"]], "Efficient kernels": [[90, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[90, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[90, "quantization-algorithms-flows"]], "Weight Only Quantization": [[90, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[90, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[90, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[90, "other-quantization-flows"]], "Training": [[90, "training"]], "Quantization Aware Training": [[90, "quantization-aware-training"], [106, "quantization-aware-training"]], "Low Bit Optimizers": [[90, "low-bit-optimizers"]], "Quantized Training": [[90, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[90, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[90, "during-quantization"]], "During Model Execution": [[90, "during-model-execution"]], "During Save/Load": [[90, "during-save-load"]], "Quick Start Guide": [[91, "quick-start-guide"]], "First Quantization Example": [[91, "first-quantization-example"]], "PyTorch 2 Export Quantization": [[91, "pytorch-2-export-quantization"]], "Next Steps": [[91, "next-steps"], [97, "next-steps"]], "Serialization and deserialization flow": [[92, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[92, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[92, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[93, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[93, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[93, "serving-and-inference"]], "Serving and Inference with vLLM": [[93, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[93, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[93, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[93, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[93, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[93, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[93, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[93, "mobile-performance-characteristics"]], "Evaluation": [[93, "evaluation"]], "Model Quality Assessment": [[93, "model-quality-assessment"]], "Memory Benchmarking": [[93, "memory-benchmarking"]], "Performance Benchmarking": [[93, "performance-benchmarking"]], "Latency Benchmarking": [[93, "latency-benchmarking"]], "Serving Benchmarking": [[93, "serving-benchmarking"]], "Results (H100 machine)": [[93, "results-h100-machine"]], "Conclusion": [[93, "conclusion"], [102, "conclusion"], [103, "conclusion"], [104, "conclusion"], [105, "conclusion"], [106, "conclusion"], [107, "conclusion"], [108, "conclusion"]], "Sparsity Overview": [[94, "sparsity-overview"]], "Goal": [[94, "goal"]], "Design": [[94, "design"]], "Context": [[94, "context"]], "Pruning Configuration": [[94, "pruning-configuration"]], "Pruning Criteria": [[94, "pruning-criteria"]], "Pruning Strategy": [[94, "pruning-strategy"]], "Sparsity Pattern": [[94, "sparsity-pattern"]], "Static Quantization": [[95, "static-quantization"]], "Calibration Phase": [[95, "calibration-phase"]], "Quantization Phase": [[95, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[96, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[97, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[97, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[97, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[97, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[97, "which-operators-should-we-implement"]], "Comparing the Outputs": [[97, "comparing-the-outputs"]], "Hugging Face Integration": [[98, "hugging-face-integration"]], "Quick Start: Usage Example": [[98, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[98, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[98, "quantizing-models-with-diffusers"]], "Saving the Model": [[98, "saving-the-model"]], "Supported Quantization Types": [[98, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[99, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[99, "configuration-system"]], "1. HuggingFace Model Configuration": [[99, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[99, "torchao-configuration-classes"]], "3. FQN Configuration": [[99, "fqn-configuration"]], "Usage Examples": [[99, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[99, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[99, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[99, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[99, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[99, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[99, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[99, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[99, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[99, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[99, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[99, "hardware-specific-linear-operations"]], "Compilation Benefits": [[99, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[99, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[99, "serialization-and-model-sharing"]], "SafeTensors Support": [[99, "safetensors-support"]], "Integration Architecture Diagrams": [[99, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[99, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[99, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[99, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Computation times": [[101, "computation-times"]], "Template Tutorial": [[102, "template-tutorial"]], "Overview": [[102, "overview"]], "Steps": [[102, "steps"]], "(Optional) Additional Exercises": [[102, "optional-additional-exercises"]], "Further Reading": [[102, "further-reading"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[103, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[103, "introduction"], [106, "introduction"], [107, "introduction"], [108, "introduction"]], "Post Training Quantization": [[103, "post-training-quantization"], [106, "post-training-quantization"], [107, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[103, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[103, "capture-fx-graph"], [106, "capture-fx-graph"], [107, "capture-fx-graph"]], "2. Apply Quantization": [[103, "apply-quantization"], [106, "apply-quantization"], [107, "apply-quantization"]], "3. Lower into OpenVINO representation": [[103, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[103, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[104, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[104, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[104, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[104, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[104, "export-the-model-with-torch-export"], [105, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[104, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [105, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[104, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[104, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[104, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[104, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[104, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[104, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[104, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[105, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[105, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[105, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[105, "training-loop"]], "Saving and Loading Model Checkpoints": [[105, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[105, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[106, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[106, "lower-into-inductor"], [107, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[107, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[108, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[108, "prerequisites"]], "Annotation API": [[108, "annotation-api"]], "1. Annotate Common Operator Patterns": [[108, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[108, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[108, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[108, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[108, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[108, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[108, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[108, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]]}, "indexentries": {"module": [[6, "module-torchao.sparsity"]], "torchao.sparsity": [[6, "module-torchao.sparsity"]], "affinequantizedtensor (class in torchao.dtypes)": [[13, "torchao.dtypes.AffineQuantizedTensor"]], "dequantize() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.dequantize"]], "from_hp_to_floatx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx"]], "from_hp_to_floatx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_floatx_static"]], "from_hp_to_intx() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx"]], "from_hp_to_intx_static() (torchao.dtypes.affinequantizedtensor class method)": [[13, "torchao.dtypes.AffineQuantizedTensor.from_hp_to_intx_static"]], "to() (torchao.dtypes.affinequantizedtensor method)": [[13, "torchao.dtypes.AffineQuantizedTensor.to"]], "cutlasssemisparselayout (class in torchao.dtypes)": [[14, "torchao.dtypes.CutlassSemiSparseLayout"]], "float8layout (class in torchao.dtypes)": [[15, "torchao.dtypes.Float8Layout"]], "int4cpulayout (class in torchao.dtypes)": [[16, "torchao.dtypes.Int4CPULayout"]], "layout (class in torchao.dtypes)": [[17, "torchao.dtypes.Layout"]], "nf4tensor (class in torchao.dtypes)": [[18, "torchao.dtypes.NF4Tensor"]], "convert_to_norm_float_weight() (torchao.dtypes.nf4tensor static method)": [[18, "torchao.dtypes.NF4Tensor.convert_to_norm_float_weight"]], "dequantize() (torchao.dtypes.nf4tensor static method)": [[18, "torchao.dtypes.NF4Tensor.dequantize"]], "dequantize_scalers() (torchao.dtypes.nf4tensor method)": [[18, "torchao.dtypes.NF4Tensor.dequantize_scalers"]], "double_quantize_scalers() (torchao.dtypes.nf4tensor static method)": [[18, "torchao.dtypes.NF4Tensor.double_quantize_scalers"]], "get_original_weight() (torchao.dtypes.nf4tensor method)": [[18, "torchao.dtypes.NF4Tensor.get_original_weight"]], "quantize_tensor_nearest() (torchao.dtypes.nf4tensor static method)": [[18, "torchao.dtypes.NF4Tensor.quantize_tensor_nearest"]], "plainlayout (class in torchao.dtypes)": [[19, "torchao.dtypes.PlainLayout"]], "semisparselayout (class in torchao.dtypes)": [[20, "torchao.dtypes.SemiSparseLayout"]], "tensorcoretiledlayout (class in torchao.dtypes)": [[21, "torchao.dtypes.TensorCoreTiledLayout"]], "to_affine_quantized_floatx() (in module torchao.dtypes)": [[22, "torchao.dtypes.to_affine_quantized_floatx"]], "to_affine_quantized_floatx_static() (in module torchao.dtypes)": [[23, "torchao.dtypes.to_affine_quantized_floatx_static"]], "to_affine_quantized_intx() (in module torchao.dtypes)": [[24, "torchao.dtypes.to_affine_quantized_intx"]], "to_affine_quantized_intx_static() (in module torchao.dtypes)": [[25, "torchao.dtypes.to_affine_quantized_intx_static"]], "to_nf4() (in module torchao.dtypes)": [[26, "torchao.dtypes.to_nf4"]], "castconfig (class in torchao.float8)": [[27, "torchao.float8.CastConfig"]], "float8linearconfig (class in torchao.float8)": [[28, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[28, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "scalinggranularity (class in torchao.float8)": [[29, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[30, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[31, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[32, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "blocksparselayout (class in torchao.prototype.dtypes)": [[33, "torchao.prototype.dtypes.BlockSparseLayout"]], "cutlassint4packedlayout (class in torchao.prototype.dtypes)": [[34, "torchao.prototype.dtypes.CutlassInt4PackedLayout"]], "int8dynamicactint4weightcpulayout (class in torchao.prototype.dtypes)": [[35, "torchao.prototype.dtypes.Int8DynamicActInt4WeightCPULayout"]], "uintxlayout (class in torchao.prototype.dtypes)": [[36, "torchao.prototype.dtypes.UintxLayout"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[37, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[38, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[39, "torchao.quantization.Float8WeightOnlyConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[40, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint4weightconfig (class in torchao.quantization)": [[41, "torchao.quantization.Int8DynamicActivationInt4WeightConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[42, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[43, "torchao.quantization.Int8WeightOnlyConfig"]], "mappingtype (class in torchao.quantization)": [[44, "torchao.quantization.MappingType"]], "torchaodtype (class in torchao.quantization)": [[45, "torchao.quantization.TorchAODType"]], "choose_qparams_affine() (in module torchao.quantization)": [[46, "torchao.quantization.choose_qparams_affine"]], "choose_qparams_affine_with_min_max() (in module torchao.quantization)": [[47, "torchao.quantization.choose_qparams_affine_with_min_max"]], "dequantize_affine() (in module torchao.quantization)": [[48, "torchao.quantization.dequantize_affine"]], "int_scaled_matmul() (in module torchao.quantization)": [[49, "torchao.quantization.int_scaled_matmul"]], "composableqatquantizer (class in torchao.quantization.qat)": [[50, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[51, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[52, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[52, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[53, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[53, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[54, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[55, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[55, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[56, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[57, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[57, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[58, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[59, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[59, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[59, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[60, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[61, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[62, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[63, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[63, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[63, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[64, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[64, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[65, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[66, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[67, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[67, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[68, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[69, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[70, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[71, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[72, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[73, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[74, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[75, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "fbgemm (torchao.quantization.quantize_.common.kernelpreference attribute)": [[75, "torchao.quantization.quantize_.common.KernelPreference.FBGEMM"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[75, "torchao.quantization.quantize_.common.KernelPreference"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[75, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[76, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[76, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[77, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[78, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "quantize_affine() (in module torchao.quantization)": [[79, "torchao.quantization.quantize_affine"]], "safe_int_mm() (in module torchao.quantization)": [[80, "torchao.quantization.safe_int_mm"]], "perchannelnormobserver (class in torchao.sparsity)": [[81, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[81, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[82, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[82, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[82, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[82, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[83, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[84, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[85, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[86, "torchao.utils.TorchAOBaseTensor"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[86, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[86, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[86, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[86, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})