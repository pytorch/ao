Search.setIndex({"docnames": ["api_reference/api_ref_float8", "api_reference/api_ref_qat", "api_reference/api_ref_quantization", "api_reference/api_ref_sparsity", "api_reference/api_ref_utils", "api_reference/generated/torchao.core.config.AOBaseConfig", "api_reference/generated/torchao.float8.CastConfig", "api_reference/generated/torchao.float8.Float8GemmConfig", "api_reference/generated/torchao.float8.Float8LinearConfig", "api_reference/generated/torchao.float8.Float8LinearRecipeName", "api_reference/generated/torchao.float8.ScalingGranularity", "api_reference/generated/torchao.float8.ScalingType", "api_reference/generated/torchao.float8.convert_to_float8_training", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig", "api_reference/generated/torchao.quantization.FqnToConfig", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer", "api_reference/generated/torchao.quantization.qat.QATConfig", "api_reference/generated/torchao.quantization.qat.QATStep", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant", "api_reference/generated/torchao.quantization.quantize_", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor", "api_reference/generated/torchao.sparsity.PerChannelNormObserver", "api_reference/generated/torchao.sparsity.WandaSparsifier", "api_reference/generated/torchao.sparsity.apply_fake_sparsity", "api_reference/generated/torchao.sparsity.semi_sparse_weight", "api_reference/generated/torchao.sparsity.sparsify_", "api_reference/generated/torchao.utils.TorchAOBaseTensor", "api_reference/index", "contributing/benchmarking_api_guide", "contributing/contributor_guide", "contributing/index", "contributing/quantization_overview", "contributing/sparsity", "eager_tutorials/finetuning", "eager_tutorials/first_quantization_example", "eager_tutorials/index", "eager_tutorials/mxfp8_expert_parallel_training", "eager_tutorials/pretraining", "eager_tutorials/serialization", "eager_tutorials/serving", "eager_tutorials/static_quantization", "eager_tutorials/subclass_advanced", "eager_tutorials/subclass_basic", "eager_tutorials/torchao_hf_integration", "eager_tutorials/torchao_vllm_integration", "index", "performant_kernels", "pt2e_quantization/index", "pt2e_quantization/pt2e_quant_openvino_inductor", "pt2e_quantization/pt2e_quant_ptq", "pt2e_quantization/pt2e_quant_qat", "pt2e_quantization/pt2e_quant_x86_inductor", "pt2e_quantization/pt2e_quant_xpu_inductor", "pt2e_quantization/pt2e_quantizer", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial", "workflows/index", "workflows/inference", "workflows/qat", "workflows/training"], "filenames": ["api_reference/api_ref_float8.rst", "api_reference/api_ref_qat.rst", "api_reference/api_ref_quantization.rst", "api_reference/api_ref_sparsity.rst", "api_reference/api_ref_utils.rst", "api_reference/generated/torchao.core.config.AOBaseConfig.rst", "api_reference/generated/torchao.float8.CastConfig.rst", "api_reference/generated/torchao.float8.Float8GemmConfig.rst", "api_reference/generated/torchao.float8.Float8LinearConfig.rst", "api_reference/generated/torchao.float8.Float8LinearRecipeName.rst", "api_reference/generated/torchao.float8.ScalingGranularity.rst", "api_reference/generated/torchao.float8.ScalingType.rst", "api_reference/generated/torchao.float8.convert_to_float8_training.rst", "api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.rst", "api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.rst", "api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.rst", "api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.FqnToConfig.rst", "api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.rst", "api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.rst", "api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.rst", "api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.rst", "api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.rst", "api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.rst", "api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.rst", "api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.rst", "api_reference/generated/torchao.quantization.qat.QATConfig.rst", "api_reference/generated/torchao.quantization.qat.QATStep.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.rst", "api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.rst", "api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.rst", "api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.rst", "api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.rst", "api_reference/generated/torchao.quantization.quantize_.rst", "api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.rst", "api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.rst", "api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.rst", "api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.rst", "api_reference/generated/torchao.sparsity.PerChannelNormObserver.rst", "api_reference/generated/torchao.sparsity.WandaSparsifier.rst", "api_reference/generated/torchao.sparsity.apply_fake_sparsity.rst", "api_reference/generated/torchao.sparsity.semi_sparse_weight.rst", "api_reference/generated/torchao.sparsity.sparsify_.rst", "api_reference/generated/torchao.utils.TorchAOBaseTensor.rst", "api_reference/index.rst", "contributing/benchmarking_api_guide.md", "contributing/contributor_guide.rst", "contributing/index.rst", "contributing/quantization_overview.rst", "contributing/sparsity.rst", "eager_tutorials/finetuning.rst", "eager_tutorials/first_quantization_example.rst", "eager_tutorials/index.rst", "eager_tutorials/mxfp8_expert_parallel_training.rst", "eager_tutorials/pretraining.rst", "eager_tutorials/serialization.rst", "eager_tutorials/serving.rst", "eager_tutorials/static_quantization.rst", "eager_tutorials/subclass_advanced.rst", "eager_tutorials/subclass_basic.rst", "eager_tutorials/torchao_hf_integration.md", "eager_tutorials/torchao_vllm_integration.md", "index.rst", "performant_kernels.rst", "pt2e_quantization/index.rst", "pt2e_quantization/pt2e_quant_openvino_inductor.rst", "pt2e_quantization/pt2e_quant_ptq.rst", "pt2e_quantization/pt2e_quant_qat.rst", "pt2e_quantization/pt2e_quant_x86_inductor.rst", "pt2e_quantization/pt2e_quant_xpu_inductor.rst", "pt2e_quantization/pt2e_quantizer.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst", "workflows/index.md", "workflows/inference.md", "workflows/qat.md", "workflows/training.md"], "titles": ["torchao.float8", "torchao.quantization.qat", "torchao.quantization", "torchao.sparsity", "torchao.core", "AOBaseConfig", "CastConfig", "Float8GemmConfig", "Float8LinearConfig", "Float8LinearRecipeName", "ScalingGranularity", "ScalingType", "convert_to_float8_training", "precompute_float8_dynamic_scale_for_fsdp", "MXDynamicActivationMXWeightConfig", "NVFP4DynamicActivationNVFP4WeightConfig", "NVFP4WeightOnlyConfig", "Float8DynamicActivationFloat8WeightConfig", "Float8DynamicActivationInt4WeightConfig", "Float8WeightOnlyConfig", "FqnToConfig", "Int4WeightOnlyConfig", "Int8DynamicActivationInt8WeightConfig", "Int8DynamicActivationIntxWeightConfig", "Int8WeightOnlyConfig", "IntxWeightOnlyConfig", "ComposableQATQuantizer", "FakeQuantizeConfigBase", "FakeQuantizedEmbedding", "FakeQuantizedLinear", "FakeQuantizerBase", "Float8ActInt4WeightQATQuantizer", "Float8FakeQuantizeConfig", "Float8FakeQuantizer", "FromIntXQuantizationAwareTrainingConfig", "Int4WeightOnlyEmbeddingQATQuantizer", "Int4WeightOnlyQATQuantizer", "Int8DynActInt4WeightQATQuantizer", "IntXQuantizationAwareTrainingConfig", "IntxFakeQuantizeConfig", "IntxFakeQuantizer", "QATConfig", "QATStep", "Int4WeightOnlyEmbedding", "Int4WeightOnlyQATEmbedding", "initialize_fake_quantizers", "Int4WeightOnlyQATLinear", "Int8DynActInt4WeightQATLinear", "disable_linear_fake_quant", "enable_linear_fake_quant", "quantize", "KernelPreference", "PackingFormat", "QuantizeTensorKwargs", "_choose_quant_func_and_quantize_tensor", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "semi_sparse_weight", "sparsify", "TorchAOBaseTensor", "API Reference", "Benchmarking API Guide", "Contributor Guide", "Contributing", "Quantization Overview", "Sparsity Overview", "(Part 2) Fine-tuning with QAT, QLoRA, and float8", "First Quantization Example", "Tutorials", "MXFP8 Expert Parallel Training", "(Part 1) Pre-training with float8", "Serialization", "(Part 3) Serving on vLLM, SGLang, ExecuTorch", "Static Quantization", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "Hugging Face Integration", "Integration with VLLM: Architecture and Usage Guide", "Welcome to the torchao Documentation", "Performant Kernels", "PT2E Quantization", "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend", "PyTorch 2 Export Post Training Quantization", "PyTorch 2 Export Quantization-Aware Training (QAT)", "PyTorch 2 Export Quantization with X86 Backend through Inductor", "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor", "How to Write a <code class=\"docutils literal notranslate\"><span class=\"pre\">Quantizer</span></code> for PyTorch 2 Export Quantization", "&lt;no title&gt;", "Computation times", "Template Tutorial", "Workflows", "Quantized Inference", "Quantization-Aware Training (QAT)", "Quantized Training"], "terms": {"For": [1, 5, 39, 60, 62, 63, 65, 66, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 92, 93, 94], "full": [1, 60, 67, 74, 77, 81, 82, 84, 90, 93], "exampl": [1, 5, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 34, 38, 39, 41, 45, 50, 51, 56, 59, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 76, 79, 81, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94], "how": [1, 5, 18, 22, 39, 51, 52, 60, 63, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 85, 86, 91], "us": [1, 6, 7, 9, 11, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 31, 34, 38, 39, 41, 46, 47, 51, 52, 56, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 91, 92, 93, 94], "our": [1, 63, 66, 67, 68, 71, 73, 74, 76, 79, 83, 84, 91, 93, 94], "pleas": [1, 34, 38, 60, 63, 65, 66, 67, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 93, 94], "refer": [1, 41, 47, 66, 67, 70, 71, 73, 74, 76, 77, 78, 82, 83, 84, 85, 93, 94], "readm": [1, 62, 66, 67, 68, 79, 91], "class": [5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 51, 52, 53, 55, 56, 60, 62, 63, 67, 68, 70, 72, 74, 76, 81, 83, 84, 85, 87, 93], "torchao": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 72, 73, 74, 76, 77, 81, 82, 83, 84, 85, 86, 91, 92, 94], "core": [5, 20, 50, 61, 74, 78, 83, 92], "config": [5, 8, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 38, 39, 40, 41, 50, 56, 59, 62, 65, 66, 67, 68, 73, 74, 77, 78, 81, 83, 85, 86, 92, 93, 94], "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 73, 88, 90, 94], "If": [5, 7, 12, 17, 22, 24, 38, 39, 41, 56, 60, 62, 63, 65, 66, 67, 73, 76, 83, 84], "workflow": [5, 50, 51, 59, 62, 63, 66, 68, 70, 71, 81, 87, 94], "inherit": [5, 60, 76, 78, 85, 86], "from": [5, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 38, 41, 50, 51, 59, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 90, 93, 94], "thi": [5, 7, 11, 13, 14, 15, 16, 17, 22, 23, 24, 28, 33, 34, 39, 41, 43, 44, 46, 47, 50, 53, 54, 55, 56, 57, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 90, 91, 93, 94], "quantize_": [5, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 34, 38, 41, 50, 51, 52, 53, 54, 59, 61, 62, 63, 65, 67, 68, 72, 73, 74, 79, 92, 94], "know": [5, 63, 76, 94], "appli": [5, 16, 17, 18, 19, 20, 22, 24, 26, 30, 31, 33, 38, 40, 41, 50, 59, 60, 63, 65, 66, 67, 70, 73, 78, 84, 92, 93], "model": [5, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 31, 34, 35, 36, 37, 38, 41, 45, 50, 56, 57, 59, 60, 66, 67, 70, 74, 76, 81, 85, 86, 87, 91, 92, 93], "user": [5, 17, 26, 41, 47, 51, 60, 63, 65, 66, 67, 71, 73, 74, 76, 81, 83, 84, 85, 86, 87, 90, 93], "face": [5, 60, 65, 66, 69, 73, 83], "code": [5, 62, 63, 65, 66, 68, 70, 71, 73, 74, 76, 83, 84, 85, 86, 87, 88, 90], "workflowfooconfig": 5, "configur": [5, 6, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 50, 59, 65, 67, 71, 73, 77, 85, 86, 87, 92, 93, 94], "foo": [5, 56, 83], "i": [5, 14, 15, 17, 18, 19, 20, 21, 22, 23, 38, 39, 41, 50, 53, 54, 56, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94], "defin": [5, 10, 11, 28, 33, 43, 55, 56, 60, 62, 63, 65, 66, 70, 74, 76, 78, 81, 82, 85, 86, 87], "here": [5, 41, 47, 62, 65, 70, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 93, 94], "bar": [5, 56, 83], "baz": [5, 56], "non": [5, 60, 63, 66, 76, 82, 85, 86], "register_quantize_module_handl": [5, 74, 78], "def": [5, 12, 53, 59, 60, 62, 63, 65, 67, 68, 70, 71, 72, 74, 76, 78, 81, 82, 83, 84, 85, 86, 87, 93, 94], "_transform": 5, "mod": [5, 12, 48, 49, 66, 70, 71, 76, 94], "torch": [5, 6, 8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 29, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 51, 59, 60, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 85, 86, 87, 90, 92, 93, 94], "nn": [5, 8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 31, 35, 38, 41, 50, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 78, 81, 83, 84, 85, 87, 92, 93, 94], "modul": [5, 8, 9, 10, 11, 12, 13, 14, 20, 26, 28, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 59, 62, 63, 65, 67, 68, 70, 71, 72, 74, 78, 81, 82, 83, 84, 85, 86, 87, 93, 94], "transform": [5, 60, 63, 67, 74, 82, 83, 84, 85, 86, 93, 94], "implement": [5, 8, 21, 43, 44, 46, 47, 51, 60, 63, 65, 66, 67, 70, 72, 74, 82, 83, 87, 94], "usual": [5, 66], "tensor": [5, 6, 9, 10, 11, 15, 19, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 40, 51, 52, 53, 54, 56, 60, 62, 66, 67, 68, 69, 70, 71, 72, 74, 77, 83, 85, 86, 90, 91, 92], "sublass": 5, "weight": [5, 9, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 41, 43, 44, 46, 47, 50, 53, 56, 59, 63, 66, 67, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 91, 92, 93, 94], "swap": [5, 12, 31, 35, 66, 67, 70, 71, 74, 84, 93], "call": [5, 28, 33, 43, 55, 60, 63, 65, 66, 67, 72, 74, 76, 78, 84, 86, 93], "under": [5, 51, 63, 67, 73, 92], "hood": [5, 67, 92], "float8": [6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 31, 32, 33, 54, 61, 69, 73, 74, 79, 91, 92], "scaling_typ": [6, 8], "scalingtyp": [6, 8], "dynam": [6, 8, 9, 11, 13, 15, 17, 18, 22, 23, 31, 37, 39, 47, 59, 63, 67, 70, 73, 74, 76, 77, 83, 84, 85, 92, 93, 94], "scaling_granular": [6, 8], "scalinggranular": [6, 8], "tensorwis": [6, 8, 9, 10, 12, 17, 65, 67], "target_dtyp": [6, 8, 65, 74], "dtype": [6, 12, 14, 15, 16, 17, 19, 23, 25, 28, 29, 31, 32, 35, 36, 37, 39, 43, 44, 46, 47, 54, 59, 62, 63, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 83, 85, 86, 87, 92, 93, 94], "none": [6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 22, 23, 24, 25, 28, 29, 31, 32, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 56, 59, 60, 65, 67, 70, 74, 76, 78, 82, 83, 84, 86, 94], "cast": [6, 10, 11, 67, 70, 93, 94], "singl": [6, 10, 13, 17, 22, 63, 66, 67, 70, 71, 83, 87, 92, 93, 94], "paramet": [6, 7, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 31, 32, 39, 41, 44, 46, 47, 50, 56, 59, 60, 62, 65, 66, 67, 70, 71, 72, 73, 76, 78, 82, 83, 93, 94], "The": [6, 12, 13, 15, 17, 19, 20, 22, 23, 25, 41, 50, 56, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92, 93, 94], "type": [6, 9, 10, 11, 12, 17, 19, 20, 22, 23, 25, 39, 42, 50, 51, 52, 53, 54, 60, 62, 63, 65, 66, 67, 68, 72, 73, 76, 78, 79, 82, 83, 85, 86, 87, 93], "scale": [6, 9, 10, 11, 13, 15, 17, 23, 25, 31, 32, 39, 44, 45, 46, 47, 54, 63, 65, 66, 70, 74, 76, 78, 87, 92, 93], "see": [6, 23, 25, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 83, 87, 91, 93, 94], "default": [6, 7, 9, 15, 17, 19, 21, 22, 23, 31, 39, 47, 50, 60, 63, 65, 67, 71, 76, 78, 81, 82, 83, 84, 85, 86, 87, 94], "granular": [6, 10, 17, 21, 22, 23, 24, 25, 28, 29, 31, 32, 39, 40, 63, 65, 70, 71, 73, 74, 78, 92, 94], "target": [6, 17, 19, 21, 28, 29, 32, 39, 56, 62, 63, 66, 67, 81, 82, 83, 84, 85, 86, 87, 93], "e": [6, 20, 26, 39, 41, 50, 53, 60, 63, 65, 67, 71, 72, 74, 76, 77, 79, 82, 87, 92, 93], "g": [6, 20, 26, 39, 41, 50, 53, 60, 63, 65, 67, 72, 74, 76, 82, 87, 92, 93], "float8_e4m3fn": [6, 14, 15, 17, 19, 32, 65, 94], "set": [6, 15, 17, 19, 21, 22, 24, 39, 50, 56, 60, 66, 67, 70, 82, 84, 85, 86, 93, 94], "base": [6, 11, 15, 17, 20, 23, 25, 27, 40, 41, 45, 51, 53, 54, 56, 60, 63, 65, 66, 68, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92, 93, 94], "recip": [6, 8, 9, 12, 28, 33, 43, 55, 67, 93, 94], "use_fast_accum": [7, 8], "bool": [7, 8, 12, 15, 16, 17, 19, 21, 22, 24, 28, 29, 37, 39, 43, 44, 46, 47, 49, 50, 59, 67, 74], "fals": [7, 8, 12, 14, 15, 16, 22, 28, 29, 37, 38, 39, 41, 43, 44, 46, 47, 56, 62, 65, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 86, 87, 92, 93, 94], "gemm": [7, 51, 71, 85, 86], "true": [7, 8, 12, 14, 15, 16, 17, 19, 21, 22, 24, 28, 29, 38, 39, 41, 49, 50, 59, 60, 63, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 87, 94], "fast": [7, 17, 66], "accumul": [7, 17, 70, 93], "lower": [7, 17, 32, 65, 66, 67, 73, 74, 77, 81, 84, 93], "precis": [7, 9, 11, 16, 19, 22, 31, 32, 36, 37, 41, 44, 46, 47, 65, 67, 74, 76, 77, 82, 85, 86, 92, 94], "can": [7, 15, 17, 22, 26, 39, 50, 51, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 92, 93, 94], "improv": [7, 66, 67, 70, 71, 73, 83, 86, 87, 91], "perform": [7, 12, 13, 22, 23, 24, 28, 33, 35, 36, 37, 43, 55, 66, 67, 68, 70, 71, 74, 76, 77, 78, 82, 84, 85, 86, 93], "mai": [7, 20, 39, 52, 63, 65, 70, 72, 74, 77, 83, 84, 85, 86, 87, 93], "reduc": [7, 13, 41, 62, 63, 66, 67, 68, 71, 73, 85], "numer": [7, 41, 46, 47, 51, 66, 67, 70, 71, 83, 84, 85, 93, 94], "accuraci": [7, 9, 66, 67, 68, 70, 71, 73, 74, 79, 82, 84, 85, 91, 93, 94], "cast_config_input": 8, "castconfig": 8, "cast_config_input_for_grad_weight": 8, "cast_config_weight": 8, "cast_config_weight_for_grad_input": 8, "cast_config_grad_output": 8, "cast_config_grad_output_for_grad_weight": 8, "gemm_config_output": 8, "float8gemmconfig": 8, "gemm_config_grad_input": 8, "gemm_config_grad_weight": 8, "enable_fsdp_float8_all_gath": 8, "pad_inner_dim": 8, "emul": [8, 51, 94], "force_recompute_fp8_weight_in_bwd": 8, "round_scales_to_power_of_2": 8, "convert": [8, 12, 15, 26, 34, 35, 41, 50, 59, 65, 66, 67, 70, 71, 73, 82, 85, 86, 87, 93, 94], "linear": [8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 29, 31, 36, 37, 38, 41, 46, 47, 48, 49, 50, 57, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 81, 82, 83, 84, 85, 87, 92, 93, 94], "train": [8, 9, 12, 26, 39, 41, 63, 66, 69, 76, 81, 87], "static": [8, 15, 39, 69, 81, 83, 84, 85, 86, 87, 94], "from_recipe_nam": [8, 12, 94], "recipe_nam": [8, 70, 71], "float8linearrecipenam": 8, "str": [8, 12, 20, 39, 41, 50, 56, 59, 60, 62, 70, 71, 76, 78, 86, 94], "input": [8, 12, 13, 15, 41, 45, 50, 56, 59, 62, 63, 65, 68, 70, 71, 73, 74, 76, 81, 82, 83, 84, 85, 86, 87, 94], "valu": [8, 9, 10, 11, 17, 18, 19, 21, 22, 24, 32, 42, 51, 52, 56, 65, 66, 67, 74, 76, 82, 83, 84, 87, 93], "string": [8, 39, 56, 60, 62], "repres": [8, 27, 39, 52, 56, 63, 65, 72, 76, 83, 84, 93], "output": [8, 63, 65, 66, 67, 68, 71, 73, 77, 81, 82, 83, 84, 85, 86, 87, 90, 93, 94], "specifi": [8, 12, 15, 20, 23, 24, 25, 26, 28, 29, 30, 33, 40, 41, 47, 50, 51, 56, 59, 63, 65, 66, 67, 71, 82, 83, 84, 87, 93, 94], "name": [9, 10, 11, 12, 20, 42, 50, 51, 52, 56, 59, 60, 62, 63, 65, 66, 70, 73, 76, 78, 82, 83, 84, 87, 94], "qualnam": [9, 10, 11, 42, 51, 52], "start": [9, 10, 11, 20, 42, 51, 52, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 78, 82, 83, 84, 85, 86, 87], "1": [9, 10, 11, 12, 17, 19, 20, 21, 22, 23, 24, 25, 32, 42, 51, 52, 54, 56, 60, 63, 65, 66, 68, 69, 70, 72, 74, 76, 79, 81, 83, 84, 90, 91, 92, 93], "boundari": [9, 10, 11, 42, 51, 52], "pre": [9, 66, 67, 69, 70, 73, 79, 87], "made": [9, 87], "common": [9, 14, 41, 51, 52, 53, 54, 61, 63, 65, 66, 71, 94], "per": [9, 15, 18, 19, 22, 23, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 56, 63, 65, 66, 67, 71, 74, 86, 92, 93, 94], "cubla": [9, 94], "kernel": [9, 15, 17, 18, 46, 50, 51, 66, 70, 73, 82, 85, 86, 92, 93], "fastest": [9, 63, 94], "option": [9, 12, 15, 17, 20, 22, 31, 32, 41, 50, 51, 59, 60, 62, 63, 65, 68, 70, 71, 77, 78, 79, 81, 83, 84, 85, 86, 87], "rowwis": [9, 10, 12, 17, 31, 65, 91, 92], "cutlass": 9, "e4m3": 9, "activ": [9, 15, 16, 17, 22, 23, 28, 29, 31, 37, 38, 39, 41, 47, 53, 54, 56, 62, 66, 67, 70, 73, 74, 77, 78, 79, 81, 82, 85, 86, 87, 91, 92, 93, 94], "gradient": [9, 66, 79, 93], "ar": [9, 12, 15, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 38, 41, 50, 51, 52, 56, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 78, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94], "round": [9, 76, 93, 94], "floor": [9, 94], "nearest": 9, "power": [9, 76, 78, 94], "two": [9, 15, 17, 22, 41, 60, 65, 66, 67, 76, 81, 82, 83, 84, 85, 87, 93, 94], "increas": [9, 66, 67, 70, 83, 94], "rowwise_with_gw_hp": [9, 12], "A": [9, 10, 15, 51, 55, 60, 63, 65, 66, 67, 76, 77, 78, 83, 93, 94], "modif": 9, "grad_weight": 9, "keep": [9, 16, 22, 56, 63, 65, 83], "comput": [9, 10, 11, 13, 15, 19, 28, 33, 43, 51, 55, 56, 63, 65, 66, 70, 74, 76, 77, 83, 84, 85, 86, 92], "high": [9, 32, 41, 65, 66, 67, 71, 73, 74, 76, 82, 83, 85, 86, 92, 94], "most": [9, 41, 51, 63, 65, 66, 73, 78, 83, 84, 87, 93, 94], "accur": [9, 66, 71, 82, 94], "strategi": [10, 94], "factor": [10, 11, 66, 70, 71], "entir": [10, 70, 73, 83, 84], "axiswis": 10, "along": [10, 15, 66, 70, 78, 82], "one": [10, 17, 23, 25, 28, 33, 41, 43, 55, 63, 65, 66, 70, 71, 76, 78, 84, 87, 93], "axi": [10, 23, 25, 74], "": [11, 15, 20, 51, 52, 60, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 83, 84, 85, 86, 87, 92, 93, 94], "disabl": [11, 48, 76, 84], "skip": [11, 56, 65, 66], "leav": [11, 39], "its": [11, 60, 66, 67, 76, 78, 83, 87, 94], "origin": [11, 16, 19, 22, 34, 56, 62, 65, 66, 67, 68, 70, 72, 73, 82, 83, 87, 92], "module_filter_fn": [12, 71, 94], "callabl": [12, 50, 59, 60, 78], "float8linearconfig": [12, 94], "float8linear": [12, 71, 94], "modifi": [12, 50, 56, 63, 66, 71, 76], "onli": [12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 31, 41, 47, 60, 62, 63, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 85, 86, 87, 92, 93, 94], "subclass": [12, 28, 33, 43, 51, 52, 55, 59, 60, 65, 66, 67, 68, 70, 72, 77], "pass": [12, 22, 28, 29, 33, 41, 43, 55, 60, 62, 65, 70, 74, 76, 78, 84, 87, 94], "filter": [12, 20, 63, 67, 71, 74, 93, 94], "function": [12, 28, 33, 43, 48, 49, 50, 55, 56, 57, 59, 60, 62, 65, 66, 67, 68, 70, 71, 72, 74, 76, 78, 81, 82, 87, 93, 94], "instanc": [12, 28, 33, 43, 50, 55, 59, 60, 72, 76, 83, 85, 86, 87], "fqn": [12, 20, 56, 59, 70, 71, 74, 94], "convers": [12, 63, 67, 93, 94], "return": [12, 39, 50, 59, 60, 62, 63, 65, 67, 68, 70, 71, 72, 74, 76, 78, 81, 82, 83, 84, 85, 86, 87, 93, 94], "layer": [12, 17, 19, 20, 22, 24, 28, 29, 31, 35, 36, 37, 43, 44, 46, 47, 56, 57, 60, 62, 66, 70, 71, 73, 74, 76, 78, 82, 87, 93, 94], "import": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 34, 38, 41, 50, 59, 63, 66, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 81, 82, 85, 86, 90, 93, 94], "creat": [12, 63, 66, 68, 70, 71, 76, 77, 82, 83, 85, 86, 87, 94], "sampl": [12, 70, 71, 83, 85, 86, 94], "m": [12, 15, 50, 59, 62, 63, 67, 71, 72, 73, 74, 76, 81, 83, 84, 85, 93, 94], "sequenti": [12, 17, 18, 19, 21, 22, 23, 24, 25, 50, 59, 71, 94], "8192": [12, 70, 94], "4096": [12, 67, 71, 92, 93, 94], "bia": [12, 14, 15, 16, 29, 46, 47, 62, 65, 67, 68, 72, 74, 76, 78, 84, 87, 94], "128": [12, 14, 15, 16, 18, 21, 68, 71, 73, 74, 76, 77, 78, 86, 87, 92, 93, 94], "bfloat16": [12, 14, 15, 16, 31, 36, 46, 62, 65, 66, 68, 70, 71, 72, 73, 74, 77, 78, 85, 86, 91, 92, 93, 94], "cuda": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 50, 62, 63, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 79, 84, 92, 93, 94], "optim": [12, 13, 23, 50, 63, 66, 67, 70, 71, 76, 82, 84, 85, 86, 92, 93, 94], "sgd": [12, 67, 93, 94], "lr": [12, 67, 71, 93, 94], "0": [12, 15, 20, 23, 25, 28, 39, 43, 44, 56, 60, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 79, 83, 84, 86, 87, 89, 90, 92, 93, 94], "being": [12, 15, 66, 71, 78, 85, 86, 94], "elig": [12, 71, 94], "don": [12, 20, 56, 63, 65, 66, 68, 70, 71, 77, 78, 87, 94], "t": [12, 15, 20, 56, 60, 63, 65, 66, 68, 70, 71, 74, 76, 77, 78, 83, 84, 87, 92, 94], "last": [12, 71, 82, 94], "dimens": [12, 15, 62, 63, 65, 70, 71, 76, 78, 83, 84, 94], "divis": [12, 70, 71, 94], "16": [12, 15, 29, 67, 70, 71, 92, 93, 94], "isinst": [12, 59, 66, 70, 71, 74, 76, 78, 84, 87, 93, 94], "in_featur": [12, 29, 46, 47, 68, 71, 72, 74, 76, 94], "out_featur": [12, 29, 46, 47, 71, 74, 76, 94], "valid": [12, 23, 25, 60, 70, 73, 78, 87, 94], "enabl": [12, 49, 60, 62, 63, 65, 68, 70, 71, 73, 78, 85, 94], "compil": [12, 14, 15, 16, 50, 65, 67, 68, 70, 71, 74, 76, 81, 85, 86, 92, 94], "competit": [12, 67, 70, 71, 94], "loop": [12, 66, 67, 71, 93, 94], "x": [12, 23, 25, 28, 29, 33, 40, 43, 62, 68, 70, 71, 72, 73, 74, 76, 78, 81, 82, 83, 84, 85, 86, 90, 94], "randn": [12, 29, 62, 67, 68, 70, 71, 72, 74, 76, 82, 83, 84, 85, 86, 93, 94], "devic": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 43, 46, 47, 50, 62, 63, 67, 68, 70, 71, 72, 73, 74, 76, 78, 82, 83, 84, 85, 86, 92, 94], "_": [12, 60, 63, 65, 68, 70, 71, 74, 78, 82, 83, 84, 85, 93, 94], "rang": [12, 66, 67, 68, 70, 71, 74, 83, 84, 93, 94], "10": [12, 28, 62, 63, 67, 68, 70, 71, 73, 74, 81, 83, 84, 92, 93, 94], "zero_grad": [12, 67, 71, 84, 93, 94], "y": [12, 94], "sum": [12, 13, 70, 83, 84, 94], "backward": [12, 13, 66, 67, 70, 71, 84, 93, 94], "step": [12, 13, 15, 41, 42, 62, 65, 66, 67, 70, 71, 81, 82, 83, 84, 85, 86, 87, 93, 94], "calcul": [13, 15, 17, 32, 65, 66, 70, 83, 87], "all": [13, 20, 28, 31, 33, 35, 43, 45, 55, 56, 57, 60, 63, 65, 66, 68, 72, 73, 74, 76, 78, 81, 82, 83, 85, 87, 88, 92, 94], "should": [13, 20, 28, 33, 34, 41, 43, 55, 56, 60, 63, 66, 67, 70, 71, 78, 82, 83, 87, 93], "run": [13, 14, 15, 28, 29, 33, 43, 50, 51, 55, 63, 65, 66, 67, 71, 73, 76, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94], "after": [13, 15, 63, 65, 66, 67, 71, 72, 77, 82, 83, 84, 85, 86, 87, 91, 93, 94], "It": [13, 66, 76, 81, 87], "contain": [13, 53, 54, 62, 66, 76, 84, 87], "prototyp": [14, 15, 16, 39, 45, 60, 65, 70, 87, 91, 92, 94], "mx_format": [14, 15, 16, 94], "block_siz": [14, 15, 65, 74, 94], "int": [14, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 35, 36, 37, 39, 43, 44, 46, 47, 50, 56, 60, 62, 67, 70, 74, 76, 78], "32": [14, 15, 16, 21, 23, 29, 38, 39, 41, 43, 44, 50, 59, 67, 70, 71, 72, 73, 74, 76, 79, 84, 92, 93, 94], "activation_dtyp": [14, 17, 65], "weight_dtyp": [14, 17, 19, 23, 25, 65, 73], "kernel_prefer": [14, 17, 65, 94], "kernelprefer": [14, 17, 94], "auto": [14, 17, 51, 63, 73, 77, 78, 94], "scaling_mod": 14, "scalecalculationmod": [14, 94], "rceil": [14, 94], "mx": [14, 70, 94], "format": [14, 15, 20, 21, 23, 25, 52, 60, 63, 66, 73, 83, 84, 87, 94], "infer": [14, 15, 41, 62, 65, 66, 67, 68, 72, 74, 76, 77, 79, 82, 83, 84, 85, 86, 93], "quantiz": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 59, 61, 62, 63, 64, 66, 69, 70, 71, 72, 91], "provid": [14, 26, 45, 60, 63, 65, 66, 67, 68, 71, 73, 76, 78, 83, 84, 86, 87, 91, 93], "support": [14, 17, 18, 20, 21, 22, 23, 31, 38, 39, 41, 51, 53, 54, 59, 60, 62, 65, 66, 67, 68, 70, 71, 72, 73, 76, 82, 83, 84, 85, 86, 87, 91, 92, 93, 94], "requir": [14, 23, 51, 60, 62, 65, 66, 67, 68, 70, 73, 76, 77, 79, 81, 82, 85, 87, 92, 94], "nvidia": [14, 15, 16, 62, 66], "sm100": [14, 92], "hardwar": [14, 17, 51, 52, 63, 66, 68, 73, 77, 81, 94], "blackwel": [14, 67, 92], "newer": [14, 67], "execut": [14, 50, 69, 76, 89], "pytorch": [14, 39, 60, 62, 65, 66, 67, 70, 71, 73, 76, 78, 81, 90, 92, 94], "2": [14, 17, 19, 20, 21, 22, 23, 24, 25, 28, 39, 43, 44, 57, 59, 63, 65, 66, 68, 69, 70, 71, 74, 76, 81, 90, 91, 92, 93], "5": [14, 28, 56, 63, 66, 67, 73, 78, 81, 83, 84, 90, 92, 93, 94], "proper": 14, "serial": [14, 60, 65, 69, 77, 83, 84], "mxfp8": [14, 65, 69, 91, 92], "inference_workflow": [14, 15, 16], "fullgraph": [14, 15, 16, 63, 68, 94], "mxfp4": [14, 65, 67, 91, 92], "float4_e2m1fn_x2": [14, 15, 65, 94], "use_triton_kernel": [15, 78], "use_dynamic_per_tensor_scal": [15, 16], "quantizationstep": 15, "fp4": [15, 16, 94], "nvfp4": [15, 16, 65, 67, 91, 92, 93], "special": [15, 66, 82, 83], "doubl": [15, 92], "level": [15, 56, 63, 65, 66, 76, 82, 83, 85, 86], "global": [15, 63, 66, 76], "per_tensor_scal": 15, "float32": [15, 35, 37, 39, 43, 44, 47, 66, 67, 72, 73, 74, 76, 85, 86, 87, 94], "block": [15, 56, 66, 70, 91, 92, 94], "alwai": [15, 41, 73, 76], "determin": [15, 41, 66, 71, 78], "wai": [15, 41, 63, 65, 66, 70, 71, 73, 74, 76, 83, 84, 87, 93, 94], "both": [15, 17, 21, 22, 41, 47, 65, 66, 68, 70, 74, 76, 81, 83, 85, 86, 87, 92, 93, 94], "runtim": [15, 65, 68, 83], "amax": [15, 76], "via": [15, 66, 70, 82, 94], "observ": [15, 55, 65, 66, 74, 82, 83, 84, 85, 86, 87, 94], "flow": [15, 66, 67, 71, 73, 74, 82, 83, 84, 85, 86], "prepar": [15, 26, 31, 35, 41, 56, 66, 67, 82, 85, 86, 87, 93], "time": [15, 66, 68, 76, 77, 82, 83, 84, 90, 94], "dure": [15, 22, 39, 41, 66, 67, 70, 71, 73, 74, 76, 81, 82, 84, 93], "calibr": [15, 81, 82, 84, 85, 86], "insert": [15, 67, 68, 74, 81, 82, 83, 84, 85, 86, 87, 93], "data": [15, 17, 19, 22, 52, 60, 62, 65, 66, 67, 70, 72, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 91], "extract": 15, "bake": 15, "At": [15, 66, 83], "read": [15, 63, 76, 93], "instead": [15, 28, 33, 34, 38, 39, 41, 43, 55, 66, 67, 70, 71, 76, 81, 84, 85, 86, 87], "note": [15, 20, 23, 25, 26, 38, 47, 56, 60, 62, 63, 65, 66, 67, 68, 70, 73, 76, 78, 79, 84, 85, 86, 94], "still": [15, 63, 65, 66, 67, 68, 70, 83, 87, 93], "when": [15, 20, 23, 41, 60, 62, 63, 65, 66, 67, 70, 71, 73, 74, 77, 78, 82, 83, 84, 85, 86, 87, 94], "automat": [15, 41, 60, 70, 71, 73, 76, 77, 78, 90, 93], "whether": [15, 39, 60, 63, 67, 76], "fuse": [15, 66, 76, 81, 84, 93], "triton": [15, 65, 70, 85, 86, 94], "size": [15, 21, 24, 39, 62, 63, 66, 70, 71, 72, 73, 74, 76, 78, 84, 92, 93, 94], "reduct": [15, 66, 68, 72, 73, 76], "dim": [15, 22, 24, 32, 70, 74, 76, 78, 83, 84], "work": [15, 62, 63, 64, 66, 67, 71, 72, 76, 77, 78, 83, 84, 85, 92], "mode": [15, 62, 63, 68, 69, 70, 74, 82, 84, 85, 86, 87, 94], "ha": [15, 41, 60, 63, 66, 67, 70, 73, 76, 78, 82, 83, 84, 86, 87], "constraint": [15, 83, 84, 87], "must": [15, 20, 23, 25, 26, 39, 41, 47, 66, 70, 71, 77, 78, 84, 86, 87], "satisfi": [15, 66], "k": [15, 62, 63, 72, 74, 76, 83, 84, 94], "64": [15, 21, 31, 72, 73, 74, 76, 78, 92, 93], "Will": 15, "fallback": [15, 20, 78], "aren": 15, "met": 15, "pertensor": [17, 22, 24, 32, 74, 92, 94], "perrow": [17, 22, 24, 32, 65, 92], "list": [17, 22, 26, 56, 60, 68, 70, 76, 77, 78, 82, 84, 87], "packing_format": [17, 21], "float8packingformat": 17, "plain": [17, 18, 21, 52, 60, 65, 78], "mm_config": 17, "float8mmconfig": 17, "activation_value_lb": 17, "float": [17, 28, 32, 39, 43, 44, 56, 65, 67, 72, 76, 81, 83, 84, 87, 93, 94], "activation_value_ub": 17, "set_inductor_config": [17, 19, 21, 22, 24], "version": [17, 19, 20, 21, 22, 23, 24, 25, 39, 51, 60, 65, 67, 70, 76, 78, 79, 83, 84, 87, 93, 94], "symmetr": [17, 19, 22, 23, 24, 25, 28, 31, 39, 67, 76, 82, 83, 86, 87, 92, 93], "union": [17, 22], "fp8granular": [17, 32], "either": [17, 22, 32, 41, 56, 63, 66, 73, 84, 85, 86], "tupl": [17, 22, 45, 56, 60, 70, 76, 78, 83, 84, 87], "current": [17, 21, 31, 32, 41, 50, 56, 59, 62, 65, 66, 70, 71, 76, 77, 78, 81, 83, 84, 86, 93, 94], "need": [17, 28, 33, 43, 52, 53, 54, 55, 56, 60, 62, 63, 65, 66, 67, 70, 72, 73, 76, 78, 83, 84, 85, 87, 94], "same": [17, 21, 23, 47, 59, 60, 65, 66, 67, 71, 74, 76, 84, 86, 87, 93], "And": [17, 76, 85, 87], "matrix": [17, 51, 56, 62, 65, 66, 70, 85, 94], "multipl": [17, 26, 51, 53, 60, 62, 63, 65, 66, 67, 70, 74, 76, 78, 85, 87, 93], "bound": [17, 32, 63, 66, 73, 78, 94], "upper": [17, 32], "prefer": [17, 65, 67, 76], "op": [17, 50, 51, 60, 63, 66, 67, 70, 76, 78, 81, 83, 84, 85, 87, 93, 94], "like": [17, 23, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 76, 77, 78, 82, 83, 84, 85, 86, 87], "matmul": [17, 19, 65, 66, 76, 92], "group": [17, 18, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 51, 62, 63, 67, 92, 93], "etc": [17, 28, 29, 51, 52, 54, 62, 63, 65, 82, 87], "defalut": 17, "chosen": [17, 51, 54, 66], "other": [17, 23, 40, 51, 56, 60, 62, 66, 67, 71, 72, 73, 76, 78, 79, 83, 84, 85, 87, 90, 94], "inform": [17, 60, 62, 65, 66, 73, 78, 82, 83], "adjust": [17, 19, 21, 22, 24, 67, 70], "torchinductor": [17, 19, 21, 22, 24, 85, 86], "recommend": [17, 19, 21, 22, 24, 63, 65, 67, 68, 70, 71, 77, 79, 82, 85, 86, 91], "deprec": [17, 19, 20, 22, 34, 38, 60], "float8tensor": [17, 19, 32, 53, 63, 65, 78], "2048": [17, 18, 19, 21, 22, 23, 24, 25, 67, 70, 71, 92, 93, 94], "int4_packing_format": [18, 21, 79], "int4packingformat": [18, 21], "preshuffl": [18, 65], "row": [18, 62, 63, 65, 66, 71, 92], "int4": [18, 21, 23, 28, 29, 31, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 50, 63, 65, 67, 72, 73, 77, 78, 79, 91, 92, 93], "group_siz": [18, 21, 23, 24, 28, 29, 31, 35, 38, 39, 41, 43, 44, 50, 62, 67, 77, 78, 79, 93], "right": [18, 21, 63, 66, 70, 83], "now": [18, 21, 62, 63, 65, 66, 67, 68, 70, 71, 74, 76, 77, 82, 83, 85, 87, 93, 94], "sinc": [18, 20, 28, 33, 43, 55, 60, 65, 66, 72, 73, 74, 76, 83, 84, 85, 86, 87], "underli": [18, 73, 76], "abov": [18, 23, 25, 60, 63, 65, 66, 67, 70, 72, 74, 76, 83, 84, 87, 92, 93, 94], "benefit": [18, 66, 67, 70, 76, 83, 86], "make": [18, 63, 65, 76, 78, 81, 83, 87, 94], "bigger": 18, "pack": [18, 21, 23, 25, 52, 63], "channel": [19, 22, 24, 31, 35, 36, 37, 39, 43, 44, 46, 47, 55, 74, 86, 92], "actual": [19, 41, 51, 65, 67, 70, 74, 76, 78, 83, 84, 87, 92, 93], "fqn_to_config": 20, "ordereddict": 20, "aobaseconfig": [20, 41, 50, 59, 62, 74, 78], "factori": 20, "module_fqn_to_config": 20, "differ": [20, 21, 26, 63, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 83, 84, 85, 87, 91, 93, 94], "fulli": [20, 50, 59, 66, 73, 83], "qualifi": [20, 50, 59, 66], "an": [20, 38, 39, 41, 47, 56, 60, 65, 66, 67, 71, 73, 74, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 91, 92, 94], "order": [20, 26, 60, 63, 66, 70, 76, 87], "dictionari": [20, 66], "regex": [20, 82], "python": [20, 60, 62, 63, 66, 73, 81, 82, 83, 85, 86, 88, 90, 94], "re": [20, 63, 65, 70, 71, 72, 73, 76, 83, 84], "prefix": 20, "3": [20, 28, 65, 66, 69, 70, 71, 77, 79, 81, 83, 84, 90, 92, 93, 94], "_default": [20, 73, 78], "we": [20, 21, 22, 38, 39, 41, 47, 50, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 91, 92, 94], "want": [20, 50, 59, 63, 65, 66, 72, 76, 78, 81, 82, 83, 84, 87, 94], "param": [20, 25, 56, 70, 73], "kei": [20, 56, 66, 70, 90], "preced": [20, 70, 82, 83, 85, 86], "languag": [20, 73], "q_proj": [20, 78, 93], "first": [20, 22, 41, 56, 60, 63, 65, 69, 70, 73, 74, 76, 77, 78, 79, 83, 84, 87, 93, 94], "match": [20, 46, 47, 60, 66, 83], "whichev": 20, "kept": 20, "consist": [20, 62, 66, 73, 76, 85, 86, 87], "previou": [20, 65, 73, 83, 84, 85, 86], "subset": [20, 23, 25, 65], "some": [20, 50, 56, 60, 63, 65, 66, 70, 73, 74, 76, 81, 82, 83, 84, 85, 86, 87], "better": [20, 22, 24, 68, 71, 76, 83, 84, 85, 86, 87, 94], "befor": [20, 41, 50, 63, 65, 66, 67, 70, 72, 73, 74, 76, 83, 84, 87, 93, 94], "hand": [20, 70], "them": [20, 28, 33, 43, 55, 62, 67, 87, 93], "norm": [20, 55, 56, 66], "linear_config": [20, 73], "filter_fn": [20, 50, 59, 93], "To": [20, 47, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 78, 79, 83, 84, 85, 87, 92, 93, 94], "maintain": [20, 60, 66, 73], "bc": [20, 60], "modulefqntoconfig": 20, "later": [20, 60, 65, 67, 70, 76, 83, 84, 86], "pattern": [20, 65, 70, 78, 81, 82, 83], "matter": [20, 65, 66], "ignor": [20, 28, 33, 43, 55, 71, 83, 84], "replac": [20, 66, 67, 78], "int4_choose_qparams_algorithm": [21, 79], "int4chooseqparamsalgorithm": 21, "tinygemm": [21, 46, 50, 93], "groupwis": [21, 23, 25, 92], "although": [21, 28, 33, 43, 55, 67, 76], "In": [21, 41, 63, 65, 66, 67, 68, 70, 71, 74, 76, 82, 83, 84, 85, 86, 87, 92, 93, 94], "mainli": [21, 65, 82, 85, 87], "distinguish": [21, 65], "arg": [21, 23, 25, 28, 29, 30, 31, 35, 44, 56, 60, 63, 65, 76, 78, 84, 87], "layout": [21, 22, 23, 59, 60, 66, 70], "control": [21, 22, 56, 66, 78, 83], "smaller": [21, 67, 68, 72, 93], "more": [21, 23, 25, 62, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 93, 94], "fine": [21, 66, 69, 70, 71, 73, 93], "grain": [21, 76], "choic": [21, 63], "256": [21, 35, 36, 37, 46, 47, 73, 83, 84, 87, 92], "variant": [21, 76], "choos": [21, 23, 25, 54, 63, 65, 66, 76, 83, 85], "qparam": 21, "algorithm": [21, 23, 25, 63, 66, 73, 82, 91], "hqq": [21, 65, 79, 91], "tile_packed_to_4d": [21, 79], "plainlayout": [22, 60, 74], "act_mapping_typ": [22, 23], "mappingtyp": [22, 23, 25, 39, 74], "weight_only_decod": 22, "int8": [22, 23, 24, 25, 29, 37, 38, 39, 41, 47, 50, 54, 59, 65, 67, 68, 73, 76, 83, 85, 86, 87, 91, 92, 93, 94], "token": [22, 23, 37, 39, 47, 67, 70, 71, 73, 77, 92, 93, 94], "store": [22, 53, 55, 60, 65, 66, 77, 78, 83, 84], "access": [22, 63, 82], "second": [22, 41, 60, 65, 70, 71, 87, 90, 92, 94], "map": [22, 23, 25, 39, 60, 65, 67, 76, 83, 87], "around": [22, 65, 71, 72, 81, 83], "zero": [22, 23, 25, 39, 44, 45, 46, 47, 56, 66, 70, 74, 87, 93], "forward": [22, 28, 29, 33, 40, 43, 46, 55, 62, 66, 68, 70, 72, 74, 76, 78, 81, 83, 84, 85, 94], "decod": [22, 73, 92], "oper": [22, 63, 65, 67, 73, 81, 82, 83, 84, 85, 86, 93], "scheme": [22, 24, 28, 29, 41, 67, 73, 82], "affinequantizedtensor": [22, 63, 72, 74, 76], "plan": [22, 63, 84, 91], "split": [22, 70, 73, 83, 84], "int8tensor": [22, 65, 68], "weight_granular": [23, 65, 73], "pergroup": [23, 25, 39, 73], "weight_mapping_typ": 23, "weight_scale_dtyp": [23, 73], "asymmetr": [23, 25, 39, 67, 74, 82, 86, 87, 93], "intx_packing_format": [23, 25], "intxpackingformat": [23, 25], "unpacked_to_int8": [23, 25], "intx_choose_qparams_algorithm": [23, 25], "intxchooseqparamsalgorithm": [23, 25], "affin": [23, 25, 65, 70], "intx": [23, 25, 91, 92], "8": [23, 25, 28, 29, 36, 46, 65, 67, 70, 71, 73, 78, 85, 86, 92, 93, 94], "specif": [23, 28, 29, 47, 52, 56, 60, 62, 63, 65, 66, 67, 70, 71, 72, 73, 77, 82, 85, 86, 87, 93, 94], "bit": [23, 25, 40, 62, 67, 73, 76, 77, 78, 83, 85, 86, 92, 93], "channelwis": [23, 25], "manner": [23, 25], "number": [23, 25, 31, 44, 46, 47, 56, 66, 73, 76, 84, 85], "ident": [23, 66, 71], "int8dynamicactivationint4weightconfig": [23, 41, 47, 67, 93], "howev": [23, 66, 70, 77, 78, 84, 87], "gener": [23, 28, 29, 30, 33, 40, 62, 65, 66, 67, 68, 73, 74, 76, 78, 82, 84, 85, 86, 87, 88, 90, 92, 93], "where": [23, 25, 35, 36, 37, 62, 65, 66, 70, 78, 87], "peraxi": [23, 25, 39, 73, 74], "zeropointdomain": [23, 39], "intend": [23, 51, 65, 70, 83], "export": [23, 65, 81], "applic": [23, 73], "executorch": [23, 63, 69, 77, 81, 83, 84], "opaque_torchao_auto": 23, "cpu": [23, 62, 63, 66, 70, 72, 74, 77, 78, 79, 82, 83, 84, 85, 92], "detail": [23, 25, 62, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 79, 82, 83, 84, 85, 91, 93, 94], "otherwis": [24, 26, 39, 84], "mapping_typ": [25, 39], "scale_dtyp": [25, 74], "qat": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 61, 69, 73, 79, 81, 85, 94], "twostepquant": 26, "compos": [26, 65, 66, 67, 76, 83, 84, 87, 94], "easili": [26, 82], "thei": [26, 66, 70, 71, 76, 77, 81, 83, 84, 87], "constructor": [26, 60, 76], "embed": [26, 28, 35, 38, 41, 43, 44, 93], "behavior": [26, 78, 83, 84, 94], "undefin": [26, 56], "usag": [26, 28, 29, 34, 38, 39, 41, 60, 67, 69, 70, 71, 73, 85, 86, 93], "my_quant": 26, "qatquantizer1": 26, "qatquantizer2": 26, "qatquantizer3": 26, "fake": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 67, 70, 71, 83, 84, 87, 93, 94], "num_embed": [28, 43, 44], "embedding_dim": [28, 43, 44], "padding_idx": [28, 43, 44], "max_norm": [28, 43, 44], "norm_typ": [28, 43, 44], "scale_grad_by_freq": [28, 43, 44], "spars": [28, 43, 44, 56, 66], "weight_config": [28, 29, 38, 41, 93], "fakequantizeconfigbas": [28, 29, 38, 41], "kwarg": [28, 29, 30, 31, 35, 39, 44, 54, 55, 56, 57, 60, 62, 63, 65, 76, 78], "through": [28, 29, 62, 63, 65, 67, 68, 73, 74, 76, 78, 81, 82, 83, 87, 90, 93, 94], "separ": [28, 29, 39, 66, 67, 78, 83, 87], "intxfakequantizeconfig": [28, 29, 38, 40, 41, 93], "fq_embed": 28, "longtensor": 28, "everi": [28, 33, 43, 55, 66, 76, 83, 84], "overridden": [28, 33, 43, 55], "within": [28, 33, 43, 55, 66, 73, 78, 85, 86], "afterward": [28, 33, 43, 55], "former": [28, 33, 43, 55], "take": [28, 33, 43, 50, 55, 59, 60, 65, 66, 82, 83, 84, 85, 86, 87], "care": [28, 33, 43, 55, 66, 72, 83], "regist": [28, 33, 43, 55, 60, 63, 65, 76], "hook": [28, 33, 43, 55, 65], "while": [28, 33, 41, 43, 53, 55, 56, 66, 67, 68, 73, 76, 77, 82, 83, 87, 93], "latter": [28, 33, 43, 55, 84], "silent": [28, 33, 43, 55, 85], "activation_config": [29, 38, 41, 93], "per_token": [29, 38, 39, 41, 93], "is_symmetr": [29, 38, 39, 41, 93], "fq_linear": 29, "ani": [30, 31, 35, 45, 56, 63, 65, 66, 76, 82, 84, 86], "scale_precis": [31, 35, 39, 43, 44], "element": [31, 44, 46, 47, 60, 65, 66], "each": [31, 39, 44, 46, 47, 55, 60, 63, 65, 66, 74, 76, 78, 83, 84, 87, 93], "fakequantizedlinear": [31, 34, 48, 49, 67, 93], "hp_value_lb": 32, "hp_value_ub": 32, "point": [32, 39, 44, 45, 46, 47, 65, 66, 68, 71, 72, 74, 76, 81, 83, 87, 93, 94], "float8fakequantizeconfig": 33, "qatconfig": [34, 38, 42, 67, 93], "fakequantizedembed": 34, "back": [34, 70, 76, 94], "correspond": [34, 41, 50, 62, 65, 66, 67, 72, 76, 86, 87, 93], "without": [34, 65, 66, 67, 70, 78, 85, 87, 93], "model_with_fake_quantized_linear": 34, "zero_point_precis": [35, 39, 43, 44], "int32": [35, 39, 43, 44, 65, 70, 83, 87], "have": [35, 36, 37, 52, 56, 63, 65, 66, 67, 70, 74, 76, 78, 82, 83, 84, 85, 86, 87, 91, 92, 93, 94], "int4weightonlyqatembed": 35, "int4weightonlyembed": 35, "groupsiz": [36, 37, 46, 47, 67, 93], "inner_k_til": [36, 46], "scales_precis": [36, 37, 46, 47], "padding_allow": 37, "rais": [38, 41, 76, 78], "valueerror": [38, 41], "torchaodtyp": 39, "zero_point_domain": 39, "is_dynam": [39, 85, 86, 87], "range_learn": 39, "ep": [39, 70, 74, 84, 86, 87], "integ": [39, 40, 67, 74, 83, 84, 85], "up": [39, 50, 65, 66, 67, 70, 71, 82, 83, 84, 87, 93, 94], "simul": [39, 41, 57, 66, 93], "older": [39, 60], "than": [39, 65, 66, 67, 68, 70, 71, 76, 83, 94], "6": [39, 65, 66, 70, 71, 73, 79, 83, 84, 85, 92], "you": [39, 56, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94], "int1": [39, 65], "int7": [39, 65], "also": [39, 50, 63, 65, 66, 67, 68, 70, 72, 74, 76, 77, 78, 83, 86, 87, 91, 93], "follow": [39, 41, 60, 63, 65, 66, 67, 70, 71, 73, 74, 76, 77, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94], "equival": [39, 66, 67, 70, 84, 85, 87, 93, 94], "pertoken": 39, "per_channel": 39, "per_group": 39, "combin": [39, 66, 73, 76, 83, 85, 94], "altern": [39, 67, 74, 76, 85, 86, 93], "just": [39, 63, 65, 66, 70, 72, 76, 83, 84, 87], "field": [39, 42, 87], "empti": [39, 65, 70], "fp32": [39, 47, 74, 76, 83, 85], "domain": [39, 67, 71], "learn": [39, 66, 68, 83, 85, 86, 87, 90, 93], "compat": [39, 62, 63, 79, 94], "keyword": [39, 41, 53, 65], "argument": [39, 41, 50, 53, 60, 65, 71, 73, 85], "properti": [39, 40], "throw": 39, "error": [39, 71, 76, 83], "els": [39, 65, 70, 73, 78, 83, 84], "width": [40, 62, 93], "symmetri": 40, "base_config": [41, 67, 93], "qatstep": 41, "awar": [41, 56, 66, 76, 81, 91], "arithmet": [41, 67], "bf16": [41, 62, 66, 67, 85, 86, 92, 93, 94], "goal": [41, 67], "eventu": [41, 67, 71], "degrad": [41, 66, 67, 79], "There": [41, 65, 67, 70, 74, 76, 83, 87, 94], "involv": [41, 66, 67, 70, 93], "post": [41, 65, 68, 70, 76, 81, 84, 87, 93], "ptq": [41, 84, 85, 91, 93], "which": [41, 46, 51, 60, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 78, 82, 83, 84, 85, 86, 87, 93], "phase": [41, 87], "case": [41, 51, 63, 66, 73, 76, 78, 82, 83, 87, 92, 93], "train_loop": [41, 67, 93], "int4weightonlyconfig": [41, 50, 72, 77, 78, 79, 92, 93], "directli": [41, 65, 66, 67, 74, 76], "mostli": [41, 81], "experiment": [41, 82, 92, 93], "doe": [41, 51, 52, 60, 63, 65, 66, 67, 70, 76, 83, 85, 86, 93], "exist": [41, 63, 65, 66, 71, 74, 76, 83, 87], "yet": [41, 67, 70, 76, 78, 84, 85, 86, 94], "qat_config": [41, 93], "act_config": 41, "custom": [41, 55, 60, 62, 65, 66, 67, 70, 71, 76, 78, 79, 82, 83, 85, 87, 93], "One": [41, 66, 76, 78, 87], "enum": [42, 51, 60], "output_dtyp": 43, "example_input": [45, 68, 72, 74, 81, 82, 83, 84, 85, 86, 87], "initi": [45, 65, 67, 70, 72, 81, 84], "intxfakequantizerbas": 45, "weightonlyint4linear": 46, "effici": [46, 51, 66, 67, 70, 74, 86, 92, 93], "hardcod": [47, 87, 93], "allow": [47, 63, 65, 66, 76, 81, 82, 83, 84, 85, 87, 93], "get": [47, 60, 63, 65, 66, 67, 68, 71, 73, 78, 81, 82, 83, 84, 85, 87], "exact": [47, 67, 83, 84], "helper": [48, 49, 60, 63], "_is_linear": [50, 74], "inplac": [50, 56, 68], "object": [50, 59, 60, 63, 65, 76, 83, 84, 87], "move": [50, 63, 70, 74, 78, 84, 85], "speed": [50, 66, 67, 73, 82], "final": [50, 65, 66, 68, 82, 83, 84, 85, 86, 87, 93], "do": [50, 63, 65, 66, 70, 73, 74, 76, 78, 83, 84, 85, 87, 92], "chang": [50, 63, 66, 68, 71, 72, 73, 74, 76, 82, 83, 84, 86, 87], "predefin": [50, 52, 60, 87], "method": [50, 56, 60, 62, 63, 66, 70, 74, 76, 77, 81, 82, 83, 84, 86, 87], "path": [50, 67, 68, 73, 81, 82, 83, 84, 85, 87, 94], "customiz": [50, 67], "int8dynamicactivationint8weightconfig": [50, 59, 68, 77, 92], "mm": [50, 51, 63, 70, 76, 83], "int8weightonlyconfig": [50, 67, 77, 78, 92], "quant_api": [50, 63, 72, 73, 74, 94], "1024": [50, 59, 62, 68, 72, 85], "affect": [51, 60, 66], "select": [51, 83], "found": [51, 65, 66, 68, 73, 74, 76, 92], "librari": [51, 52, 63, 65, 72, 79], "avail": [51, 52, 62, 63, 65, 73, 82, 83, 84, 85, 86, 91], "gemm_lowp": 51, "b": [51, 60], "gemm_fp32": 51, "dequant": [51, 65, 70, 76, 78, 81, 83, 85, 86, 87, 93], "ci": 51, "product": [51, 56, 68, 73, 78, 85, 87], "logic": [51, 68, 76, 78], "lowp": 51, "debug": [51, 63, 70], "issu": [51, 65, 68, 70, 76, 85, 92, 94], "mslk": [51, 63, 65], "nativ": [51, 65, 70, 71, 76, 83, 94], "laid": [52, 65], "out": [52, 56, 62, 63, 65, 66, 67, 68, 70, 71, 73, 76, 81, 82, 83, 84, 85, 92, 94], "opaqu": 52, "decid": [52, 66, 74], "shape": [52, 60, 62, 63, 65, 70, 74, 76, 78, 83, 86, 94], "rest": [52, 62, 76, 84], "system": [52, 62, 63, 73, 94], "understand": [52, 63, 71, 85, 87], "adopt": [52, 65], "creation": [53, 78], "construct": [53, 65, 83, 87], "classmethod": [53, 60, 74, 76, 78], "from_hp": [53, 65], "cl": [53, 60, 74, 76, 78], "quant_kwarg": [53, 54], "quantizetensorkwarg": 54, "given": [54, 66, 70, 71, 78, 87, 94], "deriv": [54, 63], "flexibl": [54, 66, 76, 82, 85, 93], "variou": [54, 91, 92, 94], "sparsiti": [55, 56, 57, 58, 59, 61, 62, 64, 67, 70, 71, 72, 73, 91], "l2": [55, 66], "buffer": 55, "x_orig": 55, "sparsity_level": [56, 66], "semi_structured_block_s": 56, "wanda": 56, "sparsifi": [56, 66, 72, 79], "prune": 56, "propos": [56, 67], "http": [56, 60, 66, 73, 77, 79, 86, 92, 93, 94], "arxiv": [56, 66], "org": [56, 60, 66, 73, 79, 86], "ab": [56, 66], "2306": 56, "11695": 56, "remov": [56, 63, 66, 70, 71, 78, 83, 84, 93], "magnitud": [56, 66, 94], "three": [56, 59, 85, 86, 91, 94], "variabl": [56, 66], "dict": [56, 60, 76, 78, 86, 87], "ad": [56, 60, 62, 65, 66, 67, 74, 76, 84], "parametr": 56, "preserv": [56, 66, 73, 82], "copi": [56, 63, 66, 68, 72, 74, 76, 84, 85], "deepcopi": [56, 68, 74, 76, 84], "squash_mask": [56, 66], "params_to_keep": 56, "params_to_keep_per_lay": 56, "squash": 56, "mask": [56, 66], "appropri": [56, 70, 82, 83, 84, 85, 86], "sparse_param": 56, "attach": [56, 66, 87], "save": [56, 60, 63, 67, 68, 70, 71, 72, 73, 78, 93], "xdoctest": 56, "local": [56, 66, 70, 73, 94], "hasattr": [56, 78], "submodule1": 56, "linear1": [56, 68, 72, 74, 76], "submodule2": 56, "linear42": 56, "print": [56, 67, 68, 70, 72, 73, 76, 83, 84, 90, 94], "42": [56, 74], "24": [56, 70, 92], "ones": [56, 84], "update_mask": 56, "tensor_nam": [56, 78], "statist": [56, 66, 74, 83, 84], "retriev": 56, "act_per_input": 56, "Then": [56, 76, 86, 87, 93], "metric": [56, 62, 67, 70], "compar": [56, 63, 65, 67, 68, 70, 71, 73, 83, 85, 87, 93], "across": [56, 66, 70, 73, 76, 78, 92], "whole": [56, 87], "4": [57, 59, 65, 66, 67, 68, 70, 72, 73, 76, 77, 83, 84, 91, 92, 93, 94], "alia": [58, 60, 78], "semisparseweightconfig": 58, "sparsify_": 59, "apply_tensor_subclass": 59, "essenti": [59, 78, 82], "put": [59, 63, 70, 85, 87], "semi": [59, 66], "structur": [59, 63, 65, 66, 67, 68, 72, 76, 83], "semi_sparse_weight": 59, "semisparselayout": 59, "sparse_api": 59, "util": [60, 61, 62, 63, 65, 72, 76, 78, 82, 83, 84, 85, 86, 87], "commonli": [60, 66, 71], "new": [60, 62, 65, 67, 70, 71, 74, 76, 83, 84, 85, 87], "attribut": [60, 63, 65, 67, 76, 78, 85, 86], "tensor_data_nam": [60, 63], "tensor_data": 60, "__init__": [60, 62, 67, 68, 70, 72, 74, 76, 78, 81, 83, 84, 85], "been": [60, 67, 70, 76, 84, 85, 86, 87, 94], "section": [60, 63, 65, 66, 78, 83, 84, 87], "tensor_attribute_nam": [60, 63], "optional_tensor_data_nam": 60, "addit": [60, 62, 65, 66, 67, 71, 76, 77, 82, 83, 86, 87, 93], "optional_tensor_attribute_nam": 60, "__new__": [60, 76, 78], "exaclti": 60, "present": [60, 66, 70], "includ": [60, 65, 70, 71, 76, 82, 85, 86, 87, 91, 94], "__tensor_flatten__": [60, 76, 78], "flatten": 60, "attribute_nam": 60, "__tensor_unflatten__": [60, 76, 78], "tensor_data_dict": [60, 76, 78], "_apply_fn_to_data": [60, 78], "recreat": 60, "__repr__": [60, 76], "represent": [60, 66, 78, 83, 87], "_same_metadata": 60, "metadata": [60, 65, 73, 76, 78], "between": [60, 65, 66, 76, 78, 82, 84, 85, 87, 93, 94], "__setstate__": 60, "load": [60, 63, 70, 72, 73, 77, 78], "checkpoint": [60, 67, 71, 73, 78, 92], "old": 60, "add": [60, 63, 70, 76, 77, 85, 87, 90], "__torch_function__": [60, 65, 76], "contigu": [60, 65, 85, 86], "aten": [60, 63, 65, 76, 78, 81, 82, 83, 84, 85, 86], "__torch_dispatch__": [60, 76], "detach": [60, 76, 78], "clone": [60, 73, 78, 94], "copy_": [60, 78], "_to_copi": [60, 78], "parent": 60, "own": [60, 63, 66, 67, 69, 70, 71, 74, 81, 83, 84, 87], "independ": [60, 66], "dispatch": [60, 70], "tabl": [60, 65, 66, 70, 71, 79, 94], "so": [60, 63, 65, 66, 67, 68, 70, 71, 72, 76, 77, 83, 84, 87, 94], "child": [60, 76], "vice": 60, "versa": 60, "overrid": [60, 76], "childclass": 60, "c": [60, 76, 81, 85, 86], "mro": 60, "resolut": 60, "prioriti": 60, "qdata": [60, 63, 65], "attr": [60, 78], "r": [60, 83, 84, 93], "_make_wrapper_subclass": [60, 76, 78], "self": [60, 62, 67, 68, 70, 72, 74, 76, 78, 81, 83, 84, 85], "cat": [60, 77, 87], "parent_cat": 60, "func": [60, 63, 65, 70, 76, 78], "child_cat": 60, "safetensor": [60, 67, 77], "decompos": [60, 83], "constitu": 60, "plu": 60, "json": [60, 62, 73, 78], "reconstruct": [60, 66, 78], "alreadi": [60, 63, 70, 76, 87], "safetensors_util": 60, "py": [60, 62, 63, 70, 85, 86, 89, 90, 92, 94], "allowed_tensors_subclass": 60, "classnam": 60, "entri": [60, 68], "allowed_class": 60, "dataclass": [60, 74, 78, 87], "those": [60, 66, 70, 73, 74, 76], "well": [60, 63, 65, 66, 70, 81, 83, 84, 87], "onc": [60, 66, 67, 93], "hug": [60, 69, 73], "save_pretrain": [60, 63, 73, 77], "push_to_hub": [60, 63, 73, 77, 78], "safe_seri": [60, 73, 77, 78], "doc": [60, 63, 65, 70, 71, 73, 76, 77, 81, 94], "ao": [60, 66, 70, 78, 92, 94], "main": [60, 65, 66, 68, 70, 73, 74, 76, 77, 83, 87, 91, 93, 94], "eager_tutori": 60, "torchao_hf_integr": 60, "html": 60, "end": [60, 65, 66, 67, 70, 71, 73, 76, 77, 78, 84, 87], "mytensor": [60, 63], "d": [60, 63, 73, 84], "f": [60, 65, 66, 68, 70, 71, 72, 73, 74, 76, 78, 83, 84, 94], "h": [60, 70, 73], "get_layout": 60, "15": [60, 62, 70, 71, 73, 92], "part": [60, 66, 69, 70, 76, 77, 84], "develop": [60, 63, 70, 79, 81, 83, 84, 87], "stack": [60, 65, 73], "about": [60, 62, 63, 65, 66, 67, 68, 72, 73, 83, 84, 85, 87, 93, 94], "dev": [60, 70, 77], "check": [60, 62, 63, 65, 67, 68, 72, 73, 76, 81, 82, 84, 87], "quantization_overview": 60, "contributor_guid": 60, "get_tensor_impl_constructor": 60, "layout_class": 60, "tensorimpl": 60, "tensorimplclass": 60, "from_plain": 60, "tensor_class": 60, "mean": [60, 65, 66, 67, 71, 83, 84, 87], "impl": 60, "aten_op": 60, "decor": [60, 76, 78], "callback": 60, "implements_torch_funct": 60, "torch_fn": 60, "register_layout": 60, "registr": 60, "aqt": 60, "comprehens": [61, 62, 68, 78, 85], "document": [61, 64, 67, 76, 78, 82, 83, 85, 91, 93], "tutori": [62, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93], "framework": [62, 63, 67, 70, 71, 73, 82, 94], "architectur": [62, 66, 69, 73, 82, 83, 85, 86], "micro": 62, "sparsity_": 62, "string_to_config": 62, "microbenchmark": 62, "elif": [62, 78, 79], "my_new_quant": 62, "process": [62, 65, 66, 67, 70, 82, 86, 90, 93], "mynewquantizationconfig": 62, "my_new_spars": 62, "mynewsparsityconfig": 62, "throughout": 62, "append": [62, 66, 83, 84], "gemliteuintxweightonlyconfig": 62, "gemlitewo": 62, "bit_width": 62, "model_architectur": 62, "your": [62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 77, 79, 83, 84, 85, 86, 87, 93, 94], "mycustommodel": 62, "input_dim": [62, 68], "output_dim": [62, 68], "super": [62, 67, 68, 70, 72, 74, 76, 81, 83, 84, 85], "layer1": 62, "512": [62, 70, 71, 94], "relu": [62, 81, 82, 87], "layer2": 62, "updat": [62, 66, 68, 72, 79, 83, 84, 87], "create_model_and_input_data": 62, "handl": [62, 63, 70, 94], "model_typ": [62, 67, 78, 82], "n": [62, 63, 67, 72, 74, 76, 83, 84, 87, 94], "high_precision_dtyp": 62, "my_custom_model": 62, "input_data": 62, "ensur": [62, 70, 73, 84], "convent": 62, "batch": [62, 73, 74, 84, 93, 94], "sequenc": [62, 94], "length": [62, 94], "featur": [62, 67, 70, 76, 82, 85, 86, 91], "typic": [62, 65, 67, 72, 74, 78, 81, 87, 93], "come": [62, 65, 66, 70, 71, 73, 74, 75, 77, 84, 85, 86, 93], "soon": [62, 73, 75, 84, 93], "file": [62, 63, 68, 71, 73, 76, 78, 83, 84, 89], "microbenchmark_quantization_config": 62, "yml": 62, "benchmark_mod": 62, "quantization_config_recipe_nam": 62, "int8wo": [62, 77], "int8dq": 62, "float8dq": [62, 73], "float8wo": 62, "output_dir": [62, 77], "result": [62, 65, 66, 67, 68, 70, 74, 77, 83, 84, 85, 86, 87, 94], "model_param": 62, "small_bf16_linear": 62, "matrix_shap": 62, "small_sweep": 62, "min_pow": 62, "max_pow": 62, "torch_compile_mod": 62, "max": [62, 63, 65, 68, 74, 76, 83, 84, 87], "autotun": [62, 63, 68, 74], "runner": 62, "oss": 62, "databas": 62, "ci_microbenchmark_runn": 62, "benchmark_result": 62, "extra_info": 62, "arch": 62, "a100": [62, 67, 77, 91], "sxm4": 62, "80gb": 62, "speedup": [62, 63, 65, 66, 67, 70, 71, 73, 94], "wrt": 62, "benchmark_valu": 62, "25": [62, 70, 94], "target_valu": 62, "depend": [62, 66, 72, 76, 79, 83, 84, 86, 94], "github": [62, 68, 73, 77, 92, 93, 94], "action": [62, 78, 83, 84], "upload": 62, "verifi": [62, 68, 72, 76], "setup": [62, 73], "suit": [62, 63, 83, 85], "unittest": 62, "discov": 62, "memori": [62, 63, 65, 66, 67, 70, 71, 76, 77, 79, 85, 86, 92, 93, 94], "miss": [62, 66], "properli": [62, 72], "instal": [62, 63, 65, 70, 71, 73, 77, 83, 86, 94], "Not": [62, 66], "driver": 62, "basic": [62, 63, 74, 76], "analysi": [62, 66], "profil": [62, 63], "overhead": [62, 66, 68, 70, 77, 78, 85, 94], "possibl": [62, 65, 66, 83, 84, 85, 87], "reproduc": [62, 73, 92, 94], "compon": [62, 65, 70, 76, 78, 94], "directori": [62, 70, 71, 94], "overview": [63, 64, 68, 78], "page": [63, 68, 85, 91], "contribut": [63, 66, 68], "api": [63, 64, 65, 66, 68, 74, 76, 81, 82, 83, 84, 85, 86, 92], "trainabl": [63, 65, 67, 76], "parallel": [63, 69, 71, 76, 78], "primit": [63, 70, 76, 83], "slight": [63, 66], "variat": [63, 65], "quant_primit": [63, 74], "mp": 63, "csrc": 63, "concept": [63, 65, 83, 85, 86, 87, 90], "could": [63, 65, 70, 76, 82, 83, 85, 86, 87], "context": [63, 85, 86], "write": [63, 69, 81, 82, 83, 84], "torchaobasetensor": [63, 78], "help": [63, 65, 67, 71, 73, 78, 82, 83], "With": [63, 70, 76, 83, 85, 87, 94], "ll": [63, 65, 70, 71, 76, 83, 84, 87], "mani": [63, 65, 66, 76], "awai": 63, "abstract": [63, 65], "easier": [63, 87], "peopl": [63, 65, 72, 78, 87], "my_custom_op": 63, "my_mm_for_mp": 63, "input_tensor": [63, 65, 78], "weight_tensor": [63, 65, 78], "group_mm": 63, "whatev": 63, "think": [63, 78], "condit": 63, "worri": 63, "purpos": [63, 65, 70, 71, 76, 83, 93, 94], "h100": [63, 65, 77, 91, 93], "sm89": 63, "sm90": 63, "_choose_scale_float8": [63, 65], "_quantize_affine_float8": [63, 65], "_scaled_mm": [63, 65, 94], "kerenel": 63, "f8f8bf16_rowwis": [63, 65], "reus": [63, 76], "quant": [63, 65, 73, 78, 83, 86, 87], "aim": [63, 66, 86], "unnecessari": 63, "graph": [63, 81, 83, 84, 87], "break": [63, 70], "torch_log": 63, "output_cod": 63, "script": [63, 68, 73, 74, 76, 84, 85, 86, 90, 94], "inductor": [63, 81, 82, 83], "relev": [63, 65, 90], "safe": 63, "add_safe_glob": 63, "quantizetensortofloat8kwarg": [63, 65], "checkout": [63, 65, 79], "integr": [63, 66, 69, 70, 71, 72, 73, 76, 85, 87, 94], "huggingfac": [63, 77], "deseri": [63, 83, 84], "from_pretrain": [63, 67, 73, 77, 78, 93], "diffus": [63, 73], "talk": [63, 65, 73], "fsdp": [63, 65, 70, 94], "mydtypetensor": 63, "developer_api_guid": 63, "folder": [63, 73, 83, 84, 91], "cover": [63, 83, 86, 87, 90], "torchchat": 63, "dtensor": [63, 70, 76, 94], "past": [63, 66], "adapt": [63, 71, 74], "intens": 63, "sens": [63, 65, 76], "benchmark_aq": 63, "quick": 63, "interest": [63, 66, 70, 76], "print_op_and_shap": 63, "torch_func": 63, "built": [63, 71, 76], "_c": 63, "tensorbas": 63, "benchmark_your_kernel": 63, "feel": [63, 65, 66, 76, 78], "free": [63, 65, 76], "probabl": 63, "futur": [63, 70, 74, 77, 78, 83, 84, 85, 87, 94], "llama": [63, 67, 73, 77, 78, 79, 82, 92, 93], "llama2": 63, "llama3": [63, 67, 71, 77, 93, 94], "sam": 63, "friendli": 63, "techniqu": [63, 66, 67, 70, 71, 72, 73, 74, 76, 78, 91], "profile_path": 63, "chrome": 63, "trace": 63, "let": [63, 65, 66, 68, 70, 74, 76, 87], "u": [63, 66, 82], "technic": 64, "contributor": [64, 65, 68], "guid": [64, 65, 68, 69, 73, 82, 94], "benchmark": [64, 68, 70, 71, 77, 81, 82, 85, 86], "lai": 65, "awq": [65, 91], "gptq": 65, "int4tensor": 65, "int4preshuffledtensor": 65, "uint1": 65, "uint7": 65, "float3": 65, "overload": [65, 66], "term": [65, 66, 83, 87], "extra": [65, 73], "No": [65, 66, 67, 70, 72], "what": [65, 66, 67, 70, 71, 73, 74, 78, 83, 87, 90], "float8_e4m3fnuz": 65, "float8_e5m2": [65, 94], "float8_e5m2fnuz": 65, "float8_e8m0fnu": 65, "placehold": [65, 86], "real": [65, 67, 70, 81, 83, 87, 94], "pr": 65, "shell": 65, "limit": [65, 67, 71, 76, 78, 83, 94], "offici": [65, 70, 71], "dervi": 65, "preicison": 65, "choose_qparam": 65, "zero_point": [65, 66, 74, 76, 87], "mention": [65, 83], "accommod": 65, "choose_qparams_affine_with_min_max": 65, "min": [65, 74, 76, 83, 87], "raw": 65, "quantize_fp8_row": 65, "int_matmul": 65, "int_scaled_matmul": 65, "reli": [65, 66, 74, 76, 81], "handwritten": 65, "On": [65, 94], "top": [65, 71, 76, 82, 83, 84, 85, 86], "glue": 65, "everyth": 65, "togeth": [65, 70, 73, 83, 85, 87], "build": [65, 66, 70, 71, 76, 78, 79, 83, 94], "anoth": [65, 66, 76, 83, 87], "side": [65, 70], "uint8": [65, 74, 87], "swizzl": 65, "dtpype": 65, "float8rowwisetensor": 65, "float8blockwisetensor": 65, "confus": [65, 66, 83], "close": [65, 66], "low_precision_v": 65, "high_precision_v": 65, "procedur": 65, "especi": [65, 66, 72, 85, 86], "bitwidth": [65, 87], "codebook": 65, "look": [65, 66, 71, 82, 83, 84, 85, 86], "index": [65, 66, 73, 79, 86], "vector": [65, 66, 85], "kmean": 65, "cluster": [65, 70, 71], "tradition": 65, "demonstr": [65, 67, 68, 70, 71, 73, 76, 82, 84, 94], "sai": [65, 77, 78, 87], "below": [65, 66, 70, 71, 76, 77, 78, 82, 90, 92, 94], "explain": [65, 82, 85], "introduct": [65, 73, 79], "simplest": [65, 66], "form": [65, 66, 70, 71], "easi": [65, 73], "linear_modul": 65, "requires_grad": [65, 67, 74, 76, 78], "question": [65, 66, 72, 76, 87, 94], "activation_granular": 65, "act_quant_kwarg": 65, "quantized_weight": [65, 78], "float8_dtyp": 65, "instruct": [65, 67, 73, 83, 84, 85, 93], "haven": 65, "seen": [65, 70], "pt2": [65, 76, 85], "fit": [65, 67, 72, 93], "autoround": 65, "multitensor": 65, "sure": [65, 73, 87], "open": [65, 66], "describ": [65, 66, 72, 83, 84, 90], "advis": 65, "focus": [65, 66, 67, 71, 73], "finetun": [65, 73], "quantized_train": [65, 94], "extend": [65, 66, 85], "progress": [65, 77, 78], "lot": [65, 66], "connect": [65, 70, 87], "walk": [65, 74, 76, 82, 85, 90], "float8dynamicactivationfloat8weightconfig": [65, 77, 92, 94], "happen": [65, 70, 76, 83, 85], "len": [65, 73, 78, 83, 84, 87], "_choose_quant_func_and_quantize_tensor": 65, "omit": [65, 71, 83, 84, 85], "relat": [65, 66], "xq": 65, "reshap": [65, 83, 84], "wq": 65, "x_scale": [65, 83], "w_scale": 65, "out_shap": 65, "neural": [66, 82, 85], "network": [66, 70, 76, 82, 85], "latenc": 66, "By": 66, "carefulli": 66, "achiev": [66, 67, 68, 70, 71, 74, 76, 84, 85], "signific": [66, 73], "pai": 66, "reason": [66, 72, 93], "low": [66, 70, 76, 77, 82, 94], "price": 66, "qualiti": [66, 67, 77], "f1": 66, "problem": [66, 76], "research": [66, 90, 93], "fragment": 66, "rightfulli": 66, "show": [66, 70, 71, 73, 78, 81, 83, 84], "spent": [66, 94], "figur": [66, 83], "compress": [66, 82], "place": [66, 82, 83, 84, 85, 86], "dens": [66, 70, 91], "solv": [66, 73, 76], "focu": [66, 76], "realli": 66, "push": [66, 73, 77, 78], "concret": [66, 87], "hope": 66, "modular": 66, "acceler": [66, 73, 77, 94], "nice": 66, "scratch": [66, 90], "minim": [66, 82, 85, 86], "loss": [66, 67, 70, 71, 83, 84, 93, 94], "recov": [66, 67, 79, 84, 93], "algorthim": 66, "realiz": 66, "trade": [66, 70, 73, 94], "off": [66, 70, 73, 94], "theoret": 66, "gain": [66, 73, 86], "float16": [66, 91], "yield": [66, 67], "2x": [66, 68, 70, 73, 94], "analog": 66, "would": [66, 68, 70, 76, 84, 86], "fix": [66, 74], "50": [66, 71, 74, 82, 83, 85, 86], "expect": [66, 71, 76, 82, 83, 85, 86, 87], "matric": [66, 67], "unstructur": 66, "share": 66, "mitig": [66, 67], "retrain": 66, "neglig": 66, "even": [66, 67, 71, 87, 94], "area": 66, "agre": 66, "upon": 66, "consensu": 66, "mind": 66, "thought": 66, "subproblem": 66, "find": [66, 67, 83, 87], "my": [66, 84], "answer": 66, "frontend": [66, 85], "arbitrari": 66, "backend": [66, 70, 73, 81, 87], "collect": [66, 70, 71], "handoff": 66, "piec": 66, "natur": [66, 76, 83, 87], "becaus": [66, 67, 68, 70, 71, 72, 76, 84, 87], "clear": 66, "contract": 66, "7x": 66, "advantag": 66, "anticip": 66, "solut": 66, "third": 66, "parti": 66, "to_sparse_semi_structur": 66, "sparsesemistructuredtensor": 66, "weightnormsparsifi": 66, "half": 66, "subnetwork": 66, "sparse_config": 66, "named_modul": 66, "tensor_fqn": 66, "sparse_block_shap": 66, "zeros_per_block": 66, "fakespars": 66, "fundament": [66, 84], "manipul": 66, "paramer": 66, "parameter": 66, "necessari": [66, 74, 76, 82, 83, 84, 85, 86], "ve": [66, 73], "suitabl": [66, 85], "spot": 66, "definit": [66, 78], "academia": 66, "industri": 66, "often": [66, 76], "interchang": 66, "thing": [66, 72, 76, 83], "distinct": 66, "pretrain": [66, 73, 82, 83, 84, 85, 94], "avoid": [66, 70, 72], "try": [66, 67, 76, 83, 92], "roughli": 66, "idea": 66, "behind": 66, "doesn": [66, 84, 87], "box": [66, 71, 85], "itself": [66, 70, 76], "multipli": [66, 94], "loos": 66, "speak": 66, "tightli": 66, "coupl": [66, 76], "csc": 66, "fbgemm": 66, "qnnpack": 66, "descript": [66, 82], "coo": 66, "sparse_coo": 66, "coordin": 66, "locat": [66, 70], "bsr": 66, "sparse_bsr": 66, "veri": [66, 78, 84], "similar": [66, 67, 70, 74, 84, 85, 94], "except": [66, 76, 87], "individu": 66, "scalar": [66, 83], "dimension": 66, "csr": 66, "sparse_csr": 66, "sparse_csc": 66, "column": 66, "indic": [66, 70, 87], "compact": 66, "sparse_matrix": 66, "1d": 66, "indexptr": 66, "storag": 66, "\u00bd": 66, "bitmask": 66, "2bit": 66, "unprun": 66, "quit": [66, 76], "simpl": [66, 68, 74, 76, 82, 85, 86], "successfulli": [66, 67], "These": [66, 67, 70, 76, 82, 83, 84, 87, 92], "broken": 66, "down": [66, 70], "equal": [66, 72], "sensit": 66, "effect": [66, 74, 76, 85, 86, 87], "best": [66, 68, 85, 94], "subsequ": [66, 76, 85, 86], "infinit": 66, "lost": 66, "degre": 66, "drop": 66, "give": [66, 73, 76], "curv": [66, 71, 94], "proxi": 66, "much": [66, 67, 70, 87], "aforement": 66, "less": [66, 76, 79, 83], "smallest": 66, "absolut": 66, "consid": 66, "v": [66, 71, 83, 87, 94], "scope": 66, "impli": 66, "respect": [66, 84], "pro": [66, 73, 92, 93], "con": 66, "potenti": [66, 74, 82, 83, 85, 86], "sub": 66, "tradeoff": [66, 67, 77], "span": 66, "over": [66, 70, 71, 83, 84, 94], "threshold": 66, "normal": [66, 83, 84], "complex": 66, "constant": [66, 76, 83, 94], "ctr_mobile_fe": 66, "paper": [66, 67, 90], "score": [66, 70], "w": [66, 78], "tenosr": 66, "udpat": 66, "cannot": [66, 74, 78], "histori": 66, "regrow": 66, "dw": 66, "backprop": 66, "pat": 66, "unmask": 66, "resid": 66, "salienc": 66, "lowest": 66, "l1": 66, "shown": [66, 67, 70, 73, 84, 87, 92, 93, 94], "abl": [66, 76, 78, 83, 87], "repeat": [66, 83, 84], "shot": [66, 67], "movement": 66, "tune": [66, 69, 71, 73, 82, 93], "2005": 66, "07683": 66, "rank": [66, 70, 76], "wx": 66, "sqx": 66, "q": [66, 83], "sort": 66, "wise": 66, "seek": [66, 72], "random": [66, 73, 83, 84], "randomli": 66, "tri": 66, "remedi": 66, "line": [66, 71, 77], "sometim": 66, "item": [66, 90], "ultim": [66, 74], "complic": [66, 83], "literatur": 66, "vision": 66, "nlp": [66, 85, 90], "simpli": [66, 67, 74, 76], "again": [66, 83, 87], "iter": [66, 83, 84], "ctr_feed": 66, "na": [66, 92], "multimask": 66, "search": 66, "pyspeech": 66, "fastna": 66, "approach": [66, 70, 76, 82, 85, 86, 94], "knowledg": [66, 90], "distil": 66, "pdf": 66, "2204": 66, "09656": 66, "arrang": [66, 70], "recal": 66, "faster": [66, 68, 70, 79, 93, 94], "counterpart": 66, "slower": 66, "suffici": 66, "98": [66, 92], "exhibit": [66, 93], "penalti": 66, "expens": [66, 70, 76], "dictat": 66, "characterist": [66, 70], "highest": 66, "wouldn": [66, 76], "visual": 66, "fig": 66, "4x4": 66, "benchmak": 66, "serv": [67, 68, 69, 71, 76, 77, 86, 94], "leverag": [67, 71, 73, 76, 85, 86, 93], "partner": [67, 71, 73], "showcas": [67, 71, 73], "blog": [67, 93], "resourc": [67, 76], "introduc": [67, 70, 82, 83, 85, 86, 87], "small": [67, 68, 94], "freez": [67, 84, 85, 86], "inevit": 67, "presum": 67, "recent": [67, 79], "releas": [67, 85], "1b": [67, 77, 78], "3b": [67, 93], "llamaguard": 67, "8b": [67, 68, 71, 77, 79, 92, 93, 94], "distribut": [67, 70, 71, 74, 76, 78, 82, 93, 94], "command": [67, 70, 71, 92, 93, 94], "regular": [67, 70, 82, 85, 86], "nnode": [67, 93], "nproc_per_nod": [67, 70, 93], "full_finetune_distribut": 67, "llama3_2": 67, "3b_full": 67, "batch_siz": [67, 68, 70, 72, 73, 74, 83, 84], "_component_": 67, "qat_distribut": [67, 93], "3b_qat_ful": 67, "evalu": [67, 68, 70, 84], "wa": [67, 76, 84, 92, 93, 94], "llama3_2_3b": 67, "fullmodelhfcheckpoint": 67, "checkpoint_fil": 67, "00001": 67, "00002": 67, "int8dynactint4weightquant": 67, "hellaswag": [67, 73], "wikitext": [67, 92, 93], "eleuther_ev": 67, "eleuther_evalu": 67, "task": [67, 73, 93], "fullmodeltorchtunecheckpoint": 67, "8da4w": [67, 73], "ckpt": 67, "llama3_token": 67, "tmp": 67, "meta": [67, 72, 77, 78, 87, 92], "stderr": 67, "acc": [67, 83, 84], "5021": 67, "0050": 67, "acc_norm": 67, "6797": 67, "0047": 67, "bits_per_byt": 67, "6965": 67, "byte_perplex": 67, "6206": 67, "word_perplex": 67, "13": [67, 70, 92, 93, 94], "2199": 67, "openassist": 67, "oasst1": 67, "dataset": [67, 71, 73, 82, 85, 86, 93], "higher": [67, 71, 76, 77, 82, 83, 85, 86, 93], "69": [67, 74], "overal": [67, 68, 79, 83, 87], "vanilla": [67, 93], "lora": [67, 93], "89x": [67, 79, 93], "36": [67, 71, 73, 92, 93], "qat_lora_finetune_distribut": [67, 93], "3b_qat_lora": 67, "fsdp2": [67, 71, 93, 94], "yaml": [67, 93], "complet": [67, 73, 82, 86, 93], "qat_out": [67, 93], "quatiz": [67, 93], "mini": [67, 73], "gpu": [67, 68, 70, 71, 77, 78, 81, 82, 90, 92, 93], "accordingli": 67, "get_model": [67, 93], "vocab_s": [67, 93], "num_lay": [67, 93], "num_head": [67, 93], "num_kv_head": [67, 93], "embed_dim": [67, 93], "max_seq_len": [67, 93], "001": [67, 93], "momentum": [67, 84, 93], "9": [67, 70, 71, 79, 92, 93, 94], "weight_decai": [67, 93], "1e": [67, 71, 93, 94], "loss_fn": [67, 93], "crossentropyloss": [67, 83, 84, 93], "randint": [67, 93], "next": [67, 70, 71, 74, 83, 84, 85, 86], "attun": 67, "benefici": 67, "readi": [67, 68, 70, 71, 73, 74, 76, 84], "did": 67, "legaci": [67, 93], "offer": [67, 68, 76, 83], "unlik": [67, 74], "int8dynactint4weightqatquant": [67, 93], "qat_quant": [67, 93], "int8dynactint4weightqatlinear": [67, 93], "int8dynactint4weightlinear": [67, 93], "fraction": 67, "therebi": [67, 93], "significantli": [67, 68, 82, 83, 85, 86], "footprint": 67, "extens": [67, 76, 83, 85], "addition": [67, 85, 86, 93], "frozen": 67, "further": [67, 76, 82, 83, 84, 85], "nf4": 67, "express": [67, 76, 81, 82, 83, 84, 87], "nf4tensor": 67, "cleanli": 67, "to_nf4": 67, "frozennf4linear": 67, "in_dim": 67, "out_dim": 67, "quantization_kwarg": 67, "requires_grad_": 67, "nf4_weight": 67, "though": [67, 76], "baselin": [67, 71, 73, 83, 92, 93, 94], "reap": 67, "vari": [67, 68, 83, 84, 85, 86], "incorpor": 67, "loralinear": 67, "lora_finetune_single_devic": 67, "3b_qlora_single_devic": 67, "invok": [67, 85], "loraconfig": 67, "get_peft_model": [67, 93], "automodelforcausallm": [67, 73, 77, 78], "torchaoconfig": [67, 73, 77, 78], "base_model": 67, "quantization_config": [67, 73, 77, 78, 86], "peft_config": 67, "throughput": [67, 68, 71, 73, 92, 94], "torchtitan": [67, 94], "enable_fp8_train": 67, "fp8_recipe_nam": 67, "experi": [67, 71, 86, 93], "saw": 67, "experiment_nam": 67, "tok": [67, 92], "peak_mem_reserv": 67, "6502": 67, "143": 67, "000": 67, "30": [67, 70, 71, 83], "090": 67, "fp8_nonam": 67, "7205": 67, "386": 67, "816": 67, "010": 67, "266": 67, "fp8_tensorwis": 67, "7222": [67, 93], "198": 67, "11": [67, 70, 71, 92], "074": [67, 71], "fp8_rowwis": [67, 94], "6387": 67, "968": 67, "756": 67, "29": [67, 70, 71], "158": 67, "096": 67, "fp8_rowwise_with_gw_hp": 67, "7573": 67, "698": 67, "480": 67, "516": 67, "908": 67, "hellaswag_acc": 67, "wikitext_word_perplex": 67, "533": [67, 92], "12": [67, 70, 71, 79, 86, 87, 93], "407": [67, 71], "414": 67, "007": 67, "412": 67, "005": 67, "420": [67, 93], "013": [67, 71], "534": 67, "416": 67, "009": 67, "mutat": 68, "toylinearmodel": [68, 72, 74], "hidden_dim": [68, 70], "has_bia": 68, "linear2": [68, 72, 74, 76], "eval": [68, 72, 73, 74, 81, 82, 84, 85, 86, 92, 93], "model_w16a16": 68, "model_w8a8": 68, "chapter": 68, "remain": [68, 85, 86], "unchang": 68, "__name__": [68, 70], "approxim": 68, "disk": 68, "o": [68, 70, 83, 84], "state_dict": [68, 71, 72, 83, 84, 94], "pth": [68, 71, 83, 84, 94], "original_s": 68, "getsiz": [68, 83, 84], "quantized_s": 68, "2f": [68, 83, 84], "mb": [68, 72, 83, 84, 89], "00x": 68, "00mb": 68, "warmup": [68, 71], "synchron": 68, "100": [68, 76, 83, 84, 94], "original_tim": 68, "quantized_tim": 68, "03x": 68, "larger": [68, 70, 94], "enough": 68, "toi": [68, 71, 74, 76, 85, 94], "address": [68, 83], "vllm": [68, 69, 77, 92], "lm": [68, 73, 92], "visit": 68, "forget": 68, "good": [68, 70, 76, 87], "eager": [69, 82, 83, 84, 85, 86, 87], "qlora": [69, 73], "sglang": [69, 77], "advanc": [69, 74, 76, 82, 85, 86], "expert": 69, "mixtur": 70, "moe": [70, 91, 94], "microsc": 70, "fp8": [70, 73, 92], "larg": [70, 73, 76, 85, 94], "shard": [70, 76, 78], "commun": 70, "deepseekv3": 70, "16b": 70, "node": [70, 82, 84, 85, 86, 87, 94], "8xb200": 70, "nvlink": 70, "intra": 70, "inter": 70, "multi": 70, "b200": [70, 91, 93], "ib": 70, "moe_train": [70, 94], "differenti": [70, 76], "autograd": [70, 76, 87, 94], "chain": [70, 87], "a2a_dispatch_mxfp8_fwd_hp_bwd": 70, "permute_mxfp8_fwd_hp_bwd": 70, "permut": 70, "pad": 70, "_to_mxfp8_then_scaled_grouped_mm": 70, "rout": 70, "accept": [70, 73, 87, 93], "produc": [70, 81, 82, 83, 84, 85, 86, 93], "unpermute_hp_fwd_mxfp8_bwd": 70, "unpermut": 70, "a2a_combine_hp_fwd_mxfp8_bwd": 70, "aggreg": 70, "all2al": [70, 94], "immediatlei": 70, "deepseek": 70, "v3": 70, "virtual": [70, 71], "environ": [70, 71, 73], "conda": [70, 71, 94], "venv": [70, 71], "nightli": [70, 73, 79, 94], "download": [70, 71, 73, 79, 83, 84, 86, 88, 90, 94], "job": [70, 71], "root": [70, 71, 73], "launch": [70, 71], "config_fil": [70, 71], "home": 70, "deepseek_v3": 70, "train_config": [70, 71], "deepseek_v3_16b": 70, "toml": [70, 71], "run_train": [70, 71], "sh": [70, 71, 73, 92, 94], "log_freq": 70, "1500": 70, "data_parallel_shard_degre": 70, "expert_parallel_degre": 70, "tensor_parallel_degre": 70, "expert_tensor_parallel_degre": 70, "seq_len": 70, "activation_checkpoint": 70, "print_after_convers": 70, "local_batch_s": 70, "mxfp8_dim0_cast_kernel_choic": 70, "mxfp8_dim1_cast_kernel_choic": 70, "grouped_mm": 70, "mxfp8_wgrad_with_hp": 70, "moe_force_load_bal": 70, "forc": [70, 76], "balanc": 70, "termin": [70, 71], "rank0": [70, 71], "titan": [70, 71], "2026": 70, "01": [70, 71, 92], "145": 70, "info": [70, 71], "8432": 70, "45": [70, 93], "23gib": 70, "47": [70, 71, 94], "65": [70, 71, 92, 94], "tp": [70, 71, 78, 94], "267": 70, "3421": 70, "48": [70, 71], "91gib": [70, 71], "51": [70, 71], "52": [70, 71], "21": [70, 71], "734": 70, "58": [70, 71, 79], "891": 70, "20": [70, 71, 73, 84, 94], "7": [70, 71, 73, 85, 86, 91, 92, 94], "8234": 70, "902": 70, "523": [70, 93], "9123": 70, "511": 70, "reader": 70, "why": [70, 76, 90], "1x32": 70, "transpos": [70, 76], "wgrad": 70, "grad_out": 70, "operand": 70, "thu": [70, 83], "32x1": 70, "requant": 70, "impact": [70, 71, 73, 78], "v0": 70, "stick": 70, "wgrad_with_hp": 70, "trend": 70, "toward": 70, "difficult": 70, "attent": 70, "ffn": 70, "pipelin": [70, 73], "pipeline_parallel_degre": 70, "lbalanc": 70, "critic": 70, "workload": [70, 83], "simplifi": [70, 82, 83, 85, 86], "router": 70, "3d": [70, 83, 87], "scaled_grouped_mm": 70, "groupedexpert": 70, "num_expert": 70, "w1": 70, "w2": 70, "w3": 70, "num_tokens_per_expert": 70, "to_loc": 70, "offset": 70, "cumsum": 70, "mxtensor": 70, "prior": [70, 83], "mxfp8_gmm": 70, "silu": 70, "type_a": 70, "simplifiedmo": 70, "routed_input": 70, "parallelstyl": 70, "mxfp8expertparallel": 70, "input_split": 70, "output_split": 70, "input_shap": 70, "permuted_indic": 70, "_partition_fn": 70, "device_mesh": 70, "devicemesh": 70, "param_nam": 70, "named_paramet": 70, "recurs": [70, 71], "dist_param": 70, "distribute_tensor": 70, "register_paramet": 70, "_token_dispatch": 70, "correct": [70, 83, 84], "count": [70, 83, 84, 94], "ep_degre": 70, "num_local_expert": 70, "no_grad": [70, 76, 81, 82, 83, 84, 85, 86], "num_tokens_per_expert_group": 70, "all_to_all_singl": 70, "get_group": 70, "wait": 70, "async": [70, 94], "_c10d_function": 70, "wait_tensor": 70, "view": [70, 76, 83, 84], "non_block": 70, "tolist": 70, "consum": [70, 87], "send": 70, "byte": 70, "incom": 70, "upstream": 70, "came": 70, "group_nam": 70, "_token_combin": 70, "routed_output": 70, "reorder": 70, "revers": 70, "receiv": 70, "opportun": 70, "big": 70, "immedi": 70, "net": 70, "perf": [70, 92], "pair": [70, 85, 86], "lossless": 70, "implic": 70, "stai": [70, 76, 94], "earlier": 70, "due": [70, 78, 82, 87], "comm": 70, "_appli": 70, "style": 70, "distribute_modul": 70, "partition_fn": 70, "input_fn": 70, "output_fn": 70, "apply_mxfp8_expert_parallel": 70, "moe_lay": 70, "ep_mesh": 70, "experts_plan": 70, "parallelize_modul": 70, "parallelize_plan": 70, "usr": 70, "bin": [70, 73], "env": 70, "python3": 70, "standalon": 70, "torchrun": 70, "mxfp8_expert_parallel_exampl": 70, "init_process_group": 70, "destroy_process_group": 70, "_functional_collect": 70, "nccl": 70, "local_rank": 70, "world_siz": 70, "set_devic": 70, "7168": 70, "mesh": 70, "mesh_dim_nam": 70, "practic": [70, 90], "num_token": 70, "int64": 70, "grad_output": 70, "randn_lik": 70, "done": [70, 76, 93], "__main__": 70, "world": [70, 77, 78], "fwd_bf16_m": 70, "fwd_mxfp8_m": 70, "fwd_speedup": 70, "bwd_bf16_m": 70, "bwd_mxfp8_m": 70, "bwd_speedup": 70, "total_speedup": 70, "131072": 70, "5120": 70, "18": [70, 92, 94], "037": 70, "49x": 70, "485": [70, 83, 84, 92], "839": 70, "40x": 70, "43x": [70, 71], "394": 70, "424": 70, "46x": 70, "762": 70, "306": 70, "34x": 70, "38x": 70, "1408": 70, "368": 70, "952": 70, "14x": [70, 73], "982": 70, "877": 70, "29x": 70, "22x": 70, "22": 70, "total": [70, 89, 90], "largest": [70, 76], "nvl8": 70, "14": [70, 71, 94], "28": [70, 71], "348": 70, "16x": [70, 73], "812": 70, "897": 70, "13x": 70, "283": 70, "548": 70, "299": 70, "25x": [70, 94], "278": 70, "913": 70, "934": 70, "881": [70, 93], "27x": 70, "21x": [70, 71, 73], "As": [70, 71, 83, 87], "versu": 70, "conclus": 70, "5x": [71, 79, 94], "34": [71, 94], "2k": [71, 94], "h200": 71, "latest": [71, 79], "offic": 71, "sever": [71, 78, 82, 87], "popular": 71, "flagship": 71, "quickli": [71, 76], "batteri": 71, "fork": 71, "ngpu": 71, "llama3_8b": 71, "hyperparamet": 71, "edit": [71, 73], "flag": [71, 79, 84], "2025": 71, "06": 71, "04": 71, "08": 71, "2254": 71, "27": 71, "34gib": 71, "78": 71, "375": 71, "tflop": 71, "73": [71, 74, 92], "mfu": 71, "557": 71, "7069": 71, "99gib": 71, "62": [71, 92], "034": 71, "35": [71, 73, 74, 92], "41": [71, 73], "19": [71, 92], "224": [71, 74, 82, 83, 84, 85, 86], "9196": 71, "022": 71, "406": [71, 83, 84], "904": 71, "1423": 71, "014": 71, "23": [71, 74, 92, 94], "7k": 71, "99gb": 71, "peak": [71, 73, 77, 92, 94], "against": 71, "02": 71, "37": 71, "404": 71, "2611": 71, "22gib": 71, "595": 71, "49": [71, 74], "027": 71, "4260": 71, "89gib": 71, "344": 71, "367": 71, "39": [71, 93, 94], "03": [71, 92, 94], "988": 71, "9482": 71, "321": 71, "366": 71, "991": 71, "1183": 71, "300": 71, "364": 71, "89": 71, "40": [71, 93], "4659": 71, "291": 71, "84": 71, "769": 71, "gc": 71, "peform": 71, "period": 71, "3k": 71, "89gb": 71, "11x": 71, "nearli": 71, "performan": 71, "648": 71, "2648": 71, "28gib": 71, "71": [71, 92, 94], "26": [71, 93], "475": 71, "9106": 71, "53": [71, 73], "503": 71, "434": 71, "43": 71, "94": [71, 83, 92], "166": 71, "0774": 71, "663": 71, "443": 71, "44": [71, 74], "87": 71, "885": 71, "3233": 71, "643": 71, "442": 71, "66": [71, 73, 74, 93], "76": 71, "613": 71, "6150": [71, 94], "637": 71, "72": [71, 73, 94], "6k": 71, "91gb": 71, "tl": 71, "dr": 71, "priorit": 71, "stabil": 71, "cost": [71, 74], "slightli": [71, 76], "outlier": [71, 94], "caus": 71, "underflow": 71, "8xh100": [71, 94], "convert_to_float8_train": [71, 94], "kind": [71, 83], "snippet": [71, 83, 84], "float8_linear_util": [71, 94], "float8_linear": [71, 94], "adamw": [71, 94], "label": [71, 94], "fake_label": [71, 94], "ones_lik": [71, 94], "mse_loss": [71, 94], "model_state_dict": [71, 94], "optimizer_state_dict": [71, 94], "explor": [71, 86], "few": [71, 76, 83, 84, 93], "tempfil": [72, 77], "get_model_size_in_byt": 72, "ref": [72, 83], "namedtemporaryfil": 72, "m_load": 72, "load_state_dict": [72, 83, 84, 94], "assign": 72, "assert": [72, 74, 76, 78, 87], "float_weight1": 72, "float_weight2": 72, "quantized_weight1": 72, "quantized_weight2": 72, "go": [72, 76, 87], "techinqu": 72, "4x": [72, 73], "0625": 72, "affine_quantized_tensor": 72, "deploi": 73, "engin": 73, "seamlessli": [73, 76, 85, 86], "seamless": [73, 85, 94], "hf": [73, 77], "pip": [73, 77, 79, 82, 83], "url": [73, 79, 86], "whl": [73, 79, 86], "cu128": [73, 79, 94], "hub": [73, 77, 78], "server": [73, 78], "phi": 73, "microsoft": 73, "o3": 73, "client": 73, "curl": 73, "localhost": 73, "8000": 73, "v1": 73, "chat": 73, "content": 73, "messag": 73, "role": 73, "me": 73, "short": 73, "temperatur": 73, "top_p": 73, "95": [73, 92], "top_k": 73, "max_token": 73, "32768": 73, "vram": 73, "15x": 73, "littl": [73, 78], "packag": [73, 77], "git": [73, 77], "com": [73, 77, 92, 93, 94], "autotoken": [73, 77], "manual_se": [73, 83, 84], "model_path": 73, "device_map": [73, 77, 78], "trust_remote_cod": 73, "ai": 73, "assist": 73, "eat": 73, "banana": 73, "dragonfruit": 73, "smoothi": 73, "blend": 73, "milk": 73, "honei": 73, "salad": 73, "mix": [73, 82, 85, 86], "slice": [73, 78], "lemon": 73, "juic": 73, "equat": 73, "pipe": [73, 77], "text": 73, "generation_arg": 73, "max_new_token": 73, "500": 73, "return_full_text": 73, "do_sampl": 73, "generated_text": 73, "design": [73, 78, 82, 83, 87], "lm_head": 73, "ti": 73, "autoprocessor": 73, "modeling_util": 73, "find_tied_paramet": 73, "model_id": [73, 77], "untied_model": 73, "getattr": [73, 78], "get_text_config": 73, "tie_word_embed": 73, "setattr": [73, 76], "_tied_weights_kei": 73, "user_id": 73, "your_user_id": 73, "model_nam": [73, 82, 85, 86], "save_to": [73, 77], "save_to_local_path": 73, "int8dynamicactivationintxweightconfig": [73, 77], "intxweightonlyconfig": [73, 77, 92], "fqntoconfig": [73, 78], "untied_model_id": 73, "untied_model_local_path": 73, "embedding_config": 73, "quant_config": 73, "embed_token": 73, "quant_typ": [73, 77, 78], "include_embed": 73, "untie_embedding_weight": 73, "modules_to_not_convert": 73, "quantized_model": [73, 76, 77, 82, 83, 84], "pte": 73, "cd": 73, "install_requir": 73, "phi_4_mini": 73, "convert_weight": 73, "pytorch_model": 73, "pytorch_model_convert": 73, "export_llama": 73, "kv": 73, "use_sdpa_with_kv_cach": 73, "get_bos_id": 73, "199999": 73, "get_eos_id": 73, "200020": 73, "max_seq_length": 73, "max_context_length": 73, "output_nam": 73, "phi4": 73, "phone": 73, "io": 73, "2gb": 73, "iphon": 73, "17": [73, 92, 93, 94], "sec": 73, "test": [73, 77, 83, 85, 90], "har": 73, "eleutherai": 73, "lm_eval": 73, "model_arg": 73, "reset_peak_memory_stat": 73, "prompt": [73, 77], "hei": 73, "consciou": 73, "templated_prompt": 73, "apply_chat_templ": 73, "add_generation_prompt": 73, "templat": [73, 88, 89], "return_tensor": 73, "pt": 73, "generated_id": 73, "output_text": 73, "batch_decod": 73, "skip_special_token": 73, "clean_up_tokenization_spac": 73, "respons": 73, "mem": 73, "max_memory_reserv": 73, "1e9": 73, "02f": 73, "gb": [73, 92, 94], "hello": [73, 77], "ye": 73, "am": 73, "digit": 73, "todai": 73, "70": [73, 74, 92], "bench": [73, 92], "vllm_disable_compile_cach": 73, "project": 73, "vllm_use_precompil": 73, "sharegpt": 73, "wget": 73, "co": 73, "anon8231489123": 73, "sharegpt_vicuna_unfilt": 73, "resolv": 73, "sharegpt_v3_unfiltered_cleaned_split": 73, "tree": [73, 94], "num": 73, "benchmark_serv": 73, "num_prompt": [73, 92], "req": 73, "57": [73, 74, 94], "1000": [73, 85], "68": [73, 94], "80": 73, "ml": 73, "eas": 73, "fly": [74, 77], "affinequantizedminmaxobserv": 74, "record": 74, "welcom": 74, "desir": 74, "averag": [74, 83, 84], "histogram": [74, 83], "act_ob": 74, "finfo": 74, "zero_point_dtyp": 74, "weight_ob": 74, "observedlinear": 74, "observed_input": 74, "observed_weight": 74, "from_float": [74, 76], "float_linear": 74, "observed_linear": 74, "_replace_with_custom_fn_if_matches_filt": 74, "insert_observers_": 74, "lambda": [74, 78, 93], "replacement_fn": 74, "copied_act_ob": 74, "copied_weight_ob": 74, "popul": 74, "feed": 74, "simpler": [74, 83], "quantizedlinear": [74, 76], "isn": 74, "strictli": 74, "to_affine_quantized_intx_stat": 74, "act_scal": [74, 87], "act_zero_point": 74, "calculate_qparam": [74, 87], "weight_scal": [74, 83, 87], "weight_zero_point": [74, 83], "qweight": 74, "qinput": 74, "from_observ": 74, "quantized_linear": [74, 83], "begin": [74, 76], "transform_modul": [74, 78], "staticquantconfig": 74, "_apply_static_qu": 74, "associ": 74, "identifi": [74, 87], "is_observed_linear": 74, "optimizedmodul": 74, "_orig_mod": 74, "0237": 74, "tensor_impl": 74, "plainaqttensorimpl": 74, "142": [74, 94], "31": [74, 87], "113": 74, "157": 74, "59": [74, 92], "160": 74, "150": [74, 94], "67": [74, 79], "241": 74, "238": 74, "235": 74, "228": 74, "255": [74, 87], "201": 74, "114": 74, "236": 74, "88": [74, 83, 94], "83": [74, 94], "109": 74, "209": 74, "92": [74, 94], "184": 74, "141": 74, "110": 74, "0009": 74, "0010": 74, "130": 74, "122": 74, "132": 74, "125": [74, 94], "126": 74, "129": 74, "127": [74, 76, 86, 87], "133": 74, "124": 74, "131": 74, "135": 74, "136": 74, "_layout": 74, "foundat": 76, "highlight": [76, 79, 90], "interpos": 76, "namespac": 76, "continu": [76, 77, 84, 85, 86, 87], "obviou": 76, "int8quantizedlinear": 76, "finer": 76, "intercept": 76, "contrast": [76, 93], "long": [76, 83], "clunki": 76, "distributedlinear": 76, "duplic": 76, "bypass": 76, "wrap": [76, 85, 86], "outer": 76, "inner": 76, "allgath": 76, "bandwidth": [76, 92, 94], "exactli": [76, 93], "zoo": 76, "podcast": 76, "edward": 76, "yang": 76, "int8_symmetric_quant": 76, "fp32_tensor": 76, "quant_min": [76, 86, 87], "quant_max": [76, 86, 87], "min_val": 76, "amin": 76, "keepdim": [76, 83, 84], "max_val": 76, "min_val_neg": 76, "zeros_lik": 76, "max_val_po": 76, "clamp": [76, 83, 93], "w_int8": 76, "new_linear": 76, "left": [76, 87], "toymodel": 76, "float_model": [76, 81, 82, 83, 84, 85, 86], "named_children": 76, "drawback": 76, "won": 76, "suppos": 76, "clean": [76, 93], "eleg": 76, "pretti": 76, "almost": 76, "ragged": 76, "rag": 76, "nestedtensor": 76, "who": 76, "link": [76, 90, 91], "googl": [76, 93], "collab": 76, "flopcount": 76, "memorytrack": 76, "bare": 76, "bone": 76, "int8symmetrictensor": 76, "hold": [76, 77], "int_data": 76, "staticmethod": 76, "_dynamo": 76, "stride": 76, "storage_offset": 76, "ndim": 76, "extra_metadata": 76, "outer_s": [76, 78], "outer_strid": [76, 78], "undo": 76, "repr": 76, "float_tensor": 76, "ahead": 76, "insid": 76, "int8_tensor": 76, "op_implementations_dict": 76, "assertionerror": 76, "conveni": 76, "register_op": 76, "_op": 76, "opoverload": 76, "impl_decor": 76, "op_impl": 76, "wrapper": [76, 81, 85], "particular": 76, "tell": 76, "desugar": 76, "surfac": 76, "coverag": [76, 82, 83, 85, 86], "brute": 76, "repeatedli": 76, "log": 76, "loggingtensor": 76, "_python_dispatch": [76, 78], "return_and_correct_alias": [76, 78], "int8_mm": 76, "int8_view_op": 76, "out_data": 76, "out_scal": [76, 83], "notic": 76, "hit": 76, "background": 76, "decomposit": 76, "live": 76, "decomp": 76, "shrink": 76, "author": [76, 82, 83, 84, 85, 86, 87, 90], "But": [76, 78, 87], "pain": 76, "rather": 76, "worth": 76, "written": 76, "nuanc": 76, "longer": [76, 83, 84], "had": [76, 83], "That": 76, "transposit": 76, "got": [76, 83, 87], "propag": [76, 83, 85, 86], "fact": 76, "themselv": [76, 83], "pointwis": [76, 85, 86], "were": [76, 92], "might": [76, 78, 83, 87], "unwrap": 76, "dim0": 76, "dim1": 76, "confirm": 76, "quantized_model_module_swap": 76, "quantized_model_subclass": 76, "subclass_param": 76, "out_module_swap": 76, "allclos": 76, "out_compil": 76, "seri": 76, "discuss": 76, "float8dynamicactivationint4weightconfig": [77, 92], "use_hqq": [77, 78], "torch_dtyp": 77, "fluxpipelin": 77, "fluxtransformer2dmodel": 77, "black": 77, "forest": 77, "lab": 77, "flux": 77, "subfold": 77, "sign": [77, 86], "imag": [77, 81, 82, 83, 84, 85, 86], "num_inference_step": 77, "guidance_scal": 77, "png": 77, "temporarydirectori": 77, "tmp_dir": 77, "uncom": 77, "usernam": [77, 78], "statu": [77, 78], "becom": [77, 83], "stabl": [77, 79, 91, 92, 94], "int4wo": 77, "team": [77, 78], "track": [77, 78], "retain": 77, "thoroughli": 77, "e2": 78, "_type": 78, "_data": 78, "capabl": [78, 83, 85, 94], "self_attn": 78, "k_proj": [78, 93], "mlp": 78, "gate_proj": [78, 93], "narrow": 78, "host": 78, "state": 78, "chunk": 78, "heavi": 78, "codebas": [78, 94], "fn": 78, "ctx": 78, "new_tensor": 78, "__class__": 78, "principl": 78, "mynewquantconfig": 78, "classvar": 78, "myquantizedtensor": 78, "tensor_data_attr": 78, "quantized_data": 78, "tensor_attribut": 78, "fill_default": 78, "notimplementederror": 78, "_my_quant_transform": 78, "my_quantization_funct": 78, "use_cutlass_kernel": 78, "my_cutlass_linear": 78, "my_triton_linear": 78, "standard": 78, "disappear": 78, "unless": 78, "extrem": 78, "sole": 78, "explicitli": [78, 87], "spooki": 78, "distanc": 78, "workaround": 78, "2338": 78, "detect": 78, "illustr": 78, "70b": 79, "gemma3": [79, 93], "4b": [79, 93], "is_avail": 79, "xpu": [79, 81, 86, 92], "plain_int32": 79, "cu126": 79, "cu129": 79, "isol": 79, "use_cuda": 79, "use_xpu": 79, "use_cpp": 79, "tba": 80, "recogn": [81, 87], "decis": 81, "deleg": [81, 83], "x86inductorquant": [81, 85], "quantize_pt2": [81, 82, 83, 84, 85, 86], "prepare_pt2": [81, 82, 83, 85, 86], "x86_inductor_quant": [81, 85], "get_default_x86_inductor_quantization_config": [81, 85], "data_load": [81, 83, 84, 85, 86], "program": [81, 83, 84, 85, 87], "captur": [81, 83, 84, 87], "expos": [81, 83, 84, 94], "set_glob": [81, 83, 84, 85, 86], "xiq": [81, 85], "prepare_qat_pt2": [81, 84, 85], "sample_inference_data": 81, "convert_pt2": [81, 82, 83, 84, 85, 86], "_inductor": [81, 85], "cpp_wrapper": [81, 85], "optimized_model": [81, 82, 85, 86], "converted_model": [81, 85, 86], "x86": 81, "openvino": 81, "intel": [81, 82, 85, 92], "daniil": 82, "lyakhov": 82, "aamir": 82, "nazir": 82, "alexand": 82, "suslov": 82, "yamini": 82, "nimmagadda": 82, "kozlov": 82, "subject": [82, 84], "openvinoquant": 82, "unlock": 82, "placement": 82, "ux": [82, 83, 85], "torchdynamo": [82, 85, 86, 87], "four": 82, "mechan": [82, 85, 86], "torchvis": [82, 83, 84, 85, 86, 87], "resnet18": [82, 83, 84, 85, 86], "pt2e": [82, 83, 84, 85, 86], "__dict__": [82, 83, 84, 85, 86], "dummi": [82, 85, 86], "traced_b": [82, 85, 86], "exported_model": [82, 83, 84, 85, 86], "preset": 82, "elu": 82, "prelu": 82, "gelu": 82, "quantizationpreset": 82, "bert": [82, 85], "modeltyp": 82, "ignored_scop": 82, "exclud": 82, "layer_1": 82, "layer_2": 82, "layer_3": 82, "ignoredscop": 82, "conv2d": [82, 83, 84, 85, 86, 87, 92], "layer_": 82, "subgraph": [82, 84], "target_devic": 82, "taken": 82, "account": [82, 94], "cpu_spr": 82, "npu": 82, "targetdevic": 82, "fold": [82, 83, 85, 86], "batchnorm": [82, 83, 84, 85, 86], "prepared_model": [82, 83, 84, 85, 86], "fold_quant": 82, "finish": [82, 85], "comparison": 82, "smoothquant": 82, "biascorrect": 82, "discrep": 82, "calibration_load": 82, "dataload": [82, 83, 84], "transform_fn": 82, "data_item": 82, "calibration_dataset": 82, "smooth_quant": 82, "fast_bias_correct": 82, "deploy": [82, 85], "jerri": [83, 85, 87], "zhang": [83, 85, 86, 87], "_export": [83, 84], "fx": [83, 87], "14k": 83, "programm": [83, 85, 86], "prerequisit": [83, 90], "db": 83, "xnnpack": [83, 84, 87], "xnnpack_quant": [83, 84], "get_symmetric_quantization_config": [83, 84], "xnnpackquant": [83, 84, 87], "qconfigmap": [83, 87], "backendconfig": [83, 87], "rel": 83, "intent": [83, 87], "qconfig": [83, 87], "incompat": 83, "great": 83, "ideal": 83, "fake_qu": 83, "hidden": 83, "summari": [83, 92], "interact": 83, "queri": [83, 87], "previous": 83, "embedding_byt": 83, "executorchquant": 83, "concaten": 83, "prone": 83, "cleaner": 83, "composed_quant": 83, "quantization_cap": 83, "concern": 83, "decoupl": 83, "minmax": 83, "freed": 83, "identitc": 83, "imagenet": [83, 84], "unzip": [83, 84], "data_path": [83, 84], "renam": [83, 84], "resnet18_pretrained_float": [83, 84], "sy": [83, 84], "numpi": [83, 84], "np": [83, 84], "resnet": [83, 84, 85], "warn": [83, 84, 94], "filterwarn": [83, 84], "categori": [83, 84], "deprecationwarn": [83, 84], "seed": [83, 84], "191009": [83, 84], "averagemet": [83, 84], "fmt": [83, 84], "reset": [83, 84], "val": [83, 84], "avg": [83, 84], "__str__": [83, 84], "fmtstr": [83, 84], "topk": [83, 84], "predict": [83, 84], "maxk": [83, 84], "pred": [83, 84], "eq": [83, 84], "expand_a": [83, 84], "correct_k": [83, 84], "mul_": [83, 84], "criterion": [83, 84], "top1": [83, 84], "top5": [83, 84], "cnt": [83, 84], "acc1": [83, 84], "acc5": [83, 84], "load_model": [83, 84], "model_fil": [83, 84], "weights_onli": [83, 84, 94], "print_size_of_model": [83, 84], "temp": [83, 84], "p": [83, 84], "1e6": [83, 84], "prepare_data_load": [83, 84], "456": [83, 84], "std": [83, 84], "229": [83, 84], "225": [83, 84], "randomresizedcrop": [83, 84], "randomhorizontalflip": [83, 84], "totensor": [83, 84], "dataset_test": [83, 84], "resiz": [83, 84], "centercrop": [83, 84], "train_sampl": [83, 84], "randomsampl": [83, 84], "test_sampl": [83, 84], "sequentialsampl": [83, 84], "train_batch_s": [83, 84], "sampler": [83, 84], "data_loader_test": [83, 84, 85, 86], "eval_batch_s": [83, 84], "saved_model_dir": [83, 84], "float_model_fil": [83, 84], "model_to_quant": [83, 84], "rand": [83, 84, 90], "capture_pre_autograd_graph": [83, 84], "dynamic_shap": [83, 84], "dynamic_dim": [83, 84], "qconfig_opt": 83, "set_object_typ": 83, "set_module_nam": 83, "themodel": 83, "feedback": 83, "dq": 83, "fp32_op": 83, "qauntiz": 83, "x_int8": 83, "x_zero_point": 83, "weight_int8": 83, "bias_fp32": 83, "output_scal": 83, "output_zero_point": 83, "x_fp32": 83, "quantized_decompos": 83, "dequantize_per_tensor": 83, "x_i8": 83, "x_quant_min": 83, "x_quant_max": 83, "weight_fp32": 83, "weight_i8": 83, "weight_quant_min": 83, "weight_quant_max": 83, "weight_permut": 83, "permute_copi": 83, "out_fp32": 83, "addmm": 83, "out_i8": 83, "quantize_per_tensor": 83, "out_zero_point": 83, "out_quant_min": 83, "out_quant_max": 83, "float32_op": 83, "use_reference_represent": 83, "x_int16": 83, "int16": 83, "weight_int16": 83, "acc_int32": 83, "out_dtyp": 83, "bias_scal": 83, "bias_int32": 83, "div": 83, "mul": 83, "out_int8": 83, "qmin": [83, 93], "qmax": [83, 93], "date": 83, "unus": 83, "serila": 83, "consult": 83, "exportedprogram": 83, "pt2e_quantized_model_file_path": 83, "resnet18_pt2e_quant": 83, "quantized_ep": 83, "loaded_quantized_ep": 83, "loaded_quantized_model": 83, "diff": 83, "79": [83, 94], "82": 83, "55": 83, "edg": [83, 87], "went": 83, "andrew": 84, "Or": [84, 94], "move_exported_model_to_ev": [84, 85], "correctli": 84, "certain": 84, "dropout": 84, "move_exported_model_to_train": 84, "jit": 84, "recursivescriptmodul": 84, "train_one_epoch": 84, "ntrain_batch": 84, "avgloss": 84, "5f": 84, "start_tim": 84, "3f": 84, "global_avg": 84, "is_qat": [84, 85], "fusion": 84, "batchnorm2d": 84, "_native_batch_norm_legit": 84, "cudnn_batch_norm": 84, "mobilenetv2": 84, "manual": 84, "recompil": 84, "consolid": 84, "epoch": 84, "far": 84, "num_epoch": 84, "num_train_batch": 84, "num_eval_batch": 84, "num_observer_update_epoch": 84, "num_batch_norm_update_epoch": 84, "num_epochs_between_ev": 84, "nepoch": 84, "stat": 84, "subseq": 84, "disable_observ": 84, "bn": 84, "running_mean": 84, "running_var": 84, "new_arg": 84, "wish": 84, "prepared_model_copi": 84, "neval_batch": 84, "paus": 84, "resum": 84, "fail": [84, 87], "machin": [84, 94], "checkpoint_path": 84, "checkpoint_": 84, "behav": 84, "incorrectli": 84, "lesli": [85, 87], "fang": [85, 87], "weiwen": [85, 87], "xia": [85, 87], "jiong": [85, 87], "gong": [85, 87], "cnn": 85, "rnn": 85, "outstand": 85, "fourth": 85, "spr": 85, "xeon": 85, "processor": 85, "boost": 85, "memory_format": [85, 86], "channels_last": [85, 86], "onednn": [85, 86], "assum": [85, 87, 94], "word": 85, "satur": 85, "extern": 85, "pure": 85, "dedic": 85, "scenario": [85, 86], "plai": [85, 86], "convolut": [85, 86, 87], "absenc": [85, 86], "enhanc": [85, 86], "mirror": [85, 86], "autocast": [85, 86], "device_typ": [85, 86], "turn": [85, 86], "cpp": 85, "qconvolut": [85, 86], "qlinear": [85, 86], "presenc": [85, 86], "conting": [85, 86], "qmaxpool2d": [85, 86], "torchinductor_freez": [85, 86], "example_x86inductorquantizer_pytorch_2_1": 85, "torchbench": 85, "measur": [85, 94], "proven": 85, "depth": 85, "example_x86inductorquantizer_qat": 85, "yan": 86, "zhiwei": 86, "wang": 86, "eikan": 86, "liangang": 86, "liu": 86, "river": 86, "cui": 86, "yifeng": 86, "xpuinductorquant": 86, "pip3": 86, "torchaudio": 86, "xpu_inductor_quantizer_exampl": 86, "xpu_inductor_quant": 86, "xpuiq": 86, "resnet18_weight": 86, "get_default_xpu_inductor_quantization_config": 86, "wherea": 86, "histogramobserv": [86, 87], "perchannelminmaxobserv": 86, "quantizationspec": [86, 87], "quantizationconfig": [86, 87], "type_check": 86, "observerorfakequantizeconstructor": 86, "get_xpu_inductor_symm_quantization_config": 86, "extra_arg": 86, "act_observer_or_fake_quant_ctr": 86, "act_quantization_spec": [86, 87], "qscheme": [86, 87], "per_tensor_symmetr": [86, 87], "observer_or_fake_quant_ctr": [86, 87], "with_arg": [86, 87], "weight_observer_or_fake_quant_ctr": 86, "weight_quantization_spec": [86, 87], "per_channel_symmetr": 86, "ch_axi": 86, "oc": 86, "ic": 86, "kh": 86, "kw": 86, "conv": [86, 87], "bias_quantization_spec": 86, "amp": 86, "indcutor": 86, "kimish": 87, "patel": 87, "explicit": 87, "quantiat": 87, "encod": 87, "convei": 87, "quantizationannot": 87, "furthermor": 87, "minmaxobserv": 87, "input_qspec_map": 87, "output_qspec": 87, "_annot": 87, "conclud": 87, "matcher": 87, "get_source_partit": 87, "add_partit": 87, "gm": 87, "itertool": 87, "add_nod": 87, "output_nod": 87, "per_tensor_affin": 87, "input_act_qspec": 87, "output_act_qspec": 87, "input_act0": 87, "input_act1": 87, "quantization_annot": 87, "substitut": 87, "among": 87, "sharedquantizationspec": 87, "maxpool": 87, "average_pool": 87, "concat": 87, "whose": 87, "edgeornod": 87, "transit": 87, "spec": [87, 94], "conv1": 87, "conv2": 87, "fed": 87, "conv1_out": 87, "conv2_out": 87, "qspec1": 87, "cat_input0": 87, "cat_input1": 87, "implicitli": 87, "therefor": 87, "ob": 87, "rewrit": 87, "share_qparams_with_input_act0_qspec": 87, "known": 87, "beforehand": 87, "sigmoid": 87, "fixedqparamsquantizationspec": 87, "act_qspec": 87, "sigmoid_nod": 87, "input_act": 87, "derivedquantizationspec": 87, "derive_qparams_fn": 87, "observerorfakequant": 87, "observerbas": 87, "fakequantizebas": 87, "heurist": 87, "obejct": 87, "obs_or_fq": 87, "fq": 87, "act_obs_or_fq": 87, "weight_obs_or_fq": 87, "act_zp": 87, "weight_zp": 87, "bias_qspec": 87, "derived_from": 87, "backendquant": 87, "get_input_act_qspec": 87, "get_output_act_qspec": 87, "get_weight_qspec": 87, "get_bias_qspec": 87, "intermedi": 87, "straightforward": 87, "call_funct": 87, "relu_": 87, "relu_nod": 87, "maybe_conv_nod": 87, "conv1d": 87, "unexpect": 87, "recognz": 87, "unquant": 87, "subgraphmatch": 87, "conv_relu_pattern": 87, "name_node_map": 87, "input_nod": 87, "weight_nod": 87, "bias_nod": 87, "caveat": 87, "exhaust": 87, "2d": 87, "4d": 87, "symbol": 87, "outcom": 87, "tutorials_python": 88, "zip": 88, "jupyt": [88, 90], "notebook": [88, 90, 93], "tutorials_jupyt": 88, "galleri": [88, 90], "sphinx": [88, 90], "00": [89, 94], "004": [89, 90], "template_tutori": [89, 90], "click": 90, "firstnam": 90, "lastnam": 90, "v2": 90, "topic": 90, "1459": 90, "0416": 90, "8543": 90, "9240": 90, "9190": 90, "3877": 90, "0916": 90, "2491": 90, "2846": 90, "3390": 90, "3593": 90, "1091": 90, "4111": 90, "9156": 90, "8190": 90, "summar": 90, "takeawai": 90, "link1": 90, "link2": 90, "minut": 90, "ipynb": [90, 93], "128x128": 91, "blockwis": 91, "1x128": 91, "mi350x": 91, "bmg": 91, "md": 91, "funtion": 92, "pseudocod": [92, 94], "output_bf16": [92, 94], "input_bf16": [92, 94], "weight_bf16": [92, 94], "to_fp8": [92, 94], "weight_fp8": 92, "weight_int4": 92, "act": 92, "amd": 92, "mi350": 92, "float8weightonlyconfig": 92, "mxdynamicactivationmxweightconfig": 92, "nvfp4weightonlyconfig": 92, "nvfp4dynamicactivationnvfp4weightconfig": 92, "perplex": [92, 93], "winogrand": 92, "3315": 92, "7380": 92, "float8_rowwis": 92, "4197": 92, "7388": 92, "int8_rowwis": 92, "3451": 92, "7340": 92, "4535": 92, "7285": 92, "6034": 92, "7316": 92, "4459": 92, "7135": 92, "05": [92, 94], "skip_vllm": 92, "measure_accuracy_and_perform": 92, "prefil": 92, "prefill_speedup": 92, "decode_speedup": 92, "59099": 92, "14380": 92, "todo": 92, "3549": 92, "102786": 92, "15218": 92, "739": 92, "058": 92, "69313": 92, "15984": 92, "173": 92, "112": 92, "30946": 92, "6612": 92, "45312": 92, "8025": 92, "464": 92, "214": 92, "int8_rowwwis": 92, "28231": 92, "4309": 92, "912": 92, "652": 92, "3550": 92, "skip_lm_ev": 92, "input_len": 92, "output_len": 92, "max_model_len": 92, "4128": 92, "2080": 92, "uintx": 92, "arm": 92, "mac": 92, "appl": 92, "silicon": 92, "m1": 92, "32gb": 92, "ram": 92, "int8_dynamic_activation_intx_weight": 92, "81": 92, "97": 92, "alongsid": 92, "_model": 92, "a6000": 92, "590": 92, "713": 92, "482": 92, "095": 92, "63": 92, "codebookweightonlyconfig": 92, "x_q": 93, "zp": 93, "x_float": 93, "x_fq": 93, "proce": 93, "torchtun": 93, "int8dynactint4qatquant": 93, "int4weightonlyqatquant": 93, "int4weightonlyembeddingqatquant": 93, "composableqatquant": 93, "fastlanguagemodel": 93, "qwen3": 93, "2507": 93, "load_in_4bit": 93, "full_finetun": 93, "target_modul": 93, "v_proj": 93, "o_proj": 93, "up_proj": 93, "down_proj": 93, "lora_alpha": 93, "qat_schem": 93, "colab": 93, "unslothai": 93, "blob": [93, 94], "nb": 93, "qwen3_": 93, "14b": 93, "8b_qat_ful": 93, "earli": 93, "8b_qat_lora": 93, "mlabonn": 93, "finetom": 93, "100k": 93, "rate": 93, "2e": 93, "12b": 93, "1477": 93, "7745": 93, "5631": 93, "33": [93, 94], "727": 93, "bbh": 93, "8079": 93, "7624": 93, "7831": 93, "495": 93, "1155": 93, "247": 93, "797": 93, "770": 93, "7074": 93, "6415": 93, "6666": 93, "38": [93, 94], "088": 93, "gpqa": 93, "3232": 93, "3081": 93, "3182": 93, "887": 93, "mmlu": 93, "4909": 93, "4328": 93, "4524": 93, "735": 93, "1322": 93, "3459": 93, "8796": 93, "5483": 93, "4967": 93, "5174": 93, "116": 93, "3333": 93, "2879": 93, "303": 93, "260": 93, "2771": 93, "2562": 93, "2629": 93, "057": 93, "8x": [93, 94], "yahma": 93, "alpaca": 93, "7527": 93, "7068": 93, "551": 93, "4074": 93, "3621": 93, "3702": 93, "7771": 93, "7262": 93, "7397": 93, "4929": 93, "4519": 93, "4686": 93, "732": 93, "_grouped_mm": 94, "grad_input_bf16": 94, "grad_output_bf16": 94, "grad_weight_bf16": 94, "405b": 94, "strive": 94, "hackabl": 94, "debugg": 94, "tool": 94, "gather": 94, "ac": 94, "\u2139": 94, "tracker": 94, "upcom": 94, "sac": 94, "0a0": 94, "gitb98af95": 94, "git890e0ac8": 94, "median": 94, "77": 94, "7689": 94, "6768": 94, "8xmi300x": 94, "dev20250811": 94, "rocm6": 94, "git4fc4068d6": 94, "commit": 94, "2c8b5947991239913d67e2f7d22a255c3e2a9694": 94, "09": 94, "5376": 94, "07": 94, "6166": 94, "6100": 94, "46": 94, "5891": 94, "torchtitan_root": 94, "float8_recipe_with_best_set": 94, "sp": 94, "repositori": 94, "estim": 94, "reproduct": 94, "float8_rooflin": 94, "your_output_filenam": 94, "csv": 94, "shape_gen_nam": 94, "sweep": 94, "float8_recipe_nam": 94, "max_ab": 94, "bf16_gemm_tim": 94, "fp8_gemm_tim": 94, "fp8_overhead_tim": 94, "formula": 94, "lh": 94, "rh": 94, "lead": 94, "medium": 94, "unit": 94, "pytest": 94, "test_bas": 94, "test_compil": 94, "test_numerics_integr": 94, "test_fsdp": 94, "test_dtensor": 94, "test_fsdp2": 94, "test_everyth": 94, "benchmrk": 94, "inference_mod": 94, "ocp": 94, "polish": 94, "grouped_gemm": 94, "nvpf4": 94, "stochast": 94, "hadamard": 94, "dev20250815": 94, "gite4e681be6": 94, "6fc499f6f5b32151a799188be2208cfb09faed30": 94, "8307": 94, "f8": 94, "10417": 94, "mxfp8_cubla": 94, "9969": 94, "mxfp8_cublas_rceil": 94, "9642": 94, "8640": 94, "mx_recip": 94, "2932": 94, "mxlinearconfig": 94, "scale_calculation_mod": 94, "ceil": 94, "elem_dtyp": 94, "mx_tensor": 94, "dtype_fp6_e2m3": 94, "dtype_fp6_e3m2": 94, "x_mx": 94, "to_mx": 94, "x_hp": 94, "to_dtyp": 94, "bench_matmul": 94, "gist": 94, "vkuzo": 94, "a1ddb782e6e1c2aef0c726b3df99efbc": 94, "16384x16384": 94, "1000w": 94, "suppli": 94, "\u03bc": 94, "dim0_mxfp8_floor": 94, "6462": 94, "dim0_mxfp8_rceil": 94, "220": 94, "3697": 94, "170635": 94, "dim0_mxfp8_triton_floor": 94, "139": 94, "5844": 94, "dim0_mxfp8_triton_rceil": 94, "138": 94, "5888": 94, "dim1_mxfp8_cuda_floor": 94, "56": 94, "5404": 94, "dim1_mxfp8_cuda_rceil": 94, "5716": 94, "cast_bench": 94, "16384": 94}, "objects": {"torchao.core.config": [[5, 0, 1, "", "AOBaseConfig"]], "torchao.float8": [[6, 0, 1, "", "CastConfig"], [7, 0, 1, "", "Float8GemmConfig"], [8, 0, 1, "", "Float8LinearConfig"], [9, 0, 1, "", "Float8LinearRecipeName"], [10, 0, 1, "", "ScalingGranularity"], [11, 0, 1, "", "ScalingType"], [12, 2, 1, "", "convert_to_float8_training"], [13, 2, 1, "", "precompute_float8_dynamic_scale_for_fsdp"]], "torchao.float8.Float8LinearConfig": [[8, 1, 1, "", "from_recipe_name"]], "torchao.prototype.mx_formats": [[14, 0, 1, "", "MXDynamicActivationMXWeightConfig"], [15, 0, 1, "", "NVFP4DynamicActivationNVFP4WeightConfig"], [16, 0, 1, "", "NVFP4WeightOnlyConfig"]], "torchao.quantization": [[17, 0, 1, "", "Float8DynamicActivationFloat8WeightConfig"], [18, 0, 1, "", "Float8DynamicActivationInt4WeightConfig"], [19, 0, 1, "", "Float8WeightOnlyConfig"], [20, 0, 1, "", "FqnToConfig"], [21, 0, 1, "", "Int4WeightOnlyConfig"], [22, 0, 1, "", "Int8DynamicActivationInt8WeightConfig"], [23, 0, 1, "", "Int8DynamicActivationIntxWeightConfig"], [24, 0, 1, "", "Int8WeightOnlyConfig"], [25, 0, 1, "", "IntxWeightOnlyConfig"], [50, 2, 1, "", "quantize_"]], "torchao.quantization.qat": [[26, 0, 1, "", "ComposableQATQuantizer"], [27, 0, 1, "", "FakeQuantizeConfigBase"], [28, 0, 1, "", "FakeQuantizedEmbedding"], [29, 0, 1, "", "FakeQuantizedLinear"], [30, 0, 1, "", "FakeQuantizerBase"], [31, 0, 1, "", "Float8ActInt4WeightQATQuantizer"], [32, 0, 1, "", "Float8FakeQuantizeConfig"], [33, 0, 1, "", "Float8FakeQuantizer"], [34, 0, 1, "", "FromIntXQuantizationAwareTrainingConfig"], [35, 0, 1, "", "Int4WeightOnlyEmbeddingQATQuantizer"], [36, 0, 1, "", "Int4WeightOnlyQATQuantizer"], [37, 0, 1, "", "Int8DynActInt4WeightQATQuantizer"], [38, 0, 1, "", "IntXQuantizationAwareTrainingConfig"], [39, 0, 1, "", "IntxFakeQuantizeConfig"], [40, 0, 1, "", "IntxFakeQuantizer"], [41, 0, 1, "", "QATConfig"], [42, 0, 1, "", "QATStep"], [45, 2, 1, "", "initialize_fake_quantizers"]], "torchao.quantization.qat.FakeQuantizedEmbedding": [[28, 1, 1, "", "forward"]], "torchao.quantization.qat.FakeQuantizedLinear": [[29, 1, 1, "", "forward"]], "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer": [[31, 1, 1, "", "prepare"]], "torchao.quantization.qat.Float8FakeQuantizer": [[33, 1, 1, "", "forward"]], "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer": [[35, 1, 1, "", "convert"], [35, 1, 1, "", "prepare"]], "torchao.quantization.qat.IntxFakeQuantizeConfig": [[39, 3, 1, "", "group_size"], [39, 3, 1, "", "is_symmetric"]], "torchao.quantization.qat.IntxFakeQuantizer": [[40, 1, 1, "", "forward"]], "torchao.quantization.qat.embedding": [[43, 0, 1, "", "Int4WeightOnlyEmbedding"], [44, 0, 1, "", "Int4WeightOnlyQATEmbedding"]], "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding": [[43, 1, 1, "", "forward"]], "torchao.quantization.qat.linear": [[46, 0, 1, "", "Int4WeightOnlyQATLinear"], [47, 0, 1, "", "Int8DynActInt4WeightQATLinear"], [48, 2, 1, "", "disable_linear_fake_quant"], [49, 2, 1, "", "enable_linear_fake_quant"]], "torchao.quantization.quantize_.common": [[51, 0, 1, "", "KernelPreference"], [52, 0, 1, "", "PackingFormat"], [53, 0, 1, "", "QuantizeTensorKwargs"], [54, 2, 1, "", "_choose_quant_func_and_quantize_tensor"]], "torchao.quantization.quantize_.common.KernelPreference": [[51, 4, 1, "", "AUTO"], [51, 4, 1, "", "EMULATED"], [51, 4, 1, "", "MSLK"], [51, 4, 1, "", "TORCH"]], "torchao.quantization.quantize_.common.PackingFormat": [[52, 4, 1, "", "PLAIN"]], "torchao": [[3, 5, 0, "-", "sparsity"]], "torchao.sparsity": [[55, 0, 1, "", "PerChannelNormObserver"], [56, 0, 1, "", "WandaSparsifier"], [57, 2, 1, "", "apply_fake_sparsity"], [58, 4, 1, "", "semi_sparse_weight"], [59, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[55, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[56, 1, 1, "", "prepare"], [56, 1, 1, "", "squash_mask"], [56, 1, 1, "", "update_mask"]], "torchao.utils": [[60, 0, 1, "", "TorchAOBaseTensor"]], "torchao.utils.TorchAOBaseTensor": [[60, 1, 1, "", "get_layout"], [60, 1, 1, "", "get_tensor_impl_constructor"], [60, 1, 1, "", "implements"], [60, 1, 1, "", "implements_torch_function"], [60, 1, 1, "", "register_layout"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property", "4": "py:attribute", "5": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 63, 65, 67, 70, 71, 78, 79, 93], "float8": [0, 2, 65, 67, 71, 94], "main": [0, 1, 2], "train": [0, 65, 67, 70, 71, 73, 79, 82, 83, 84, 85, 86, 91, 93, 94], "api": [0, 1, 2, 4, 61, 62, 67, 70, 71, 79, 87, 93, 94], "other": [0, 63, 65, 70, 91, 92], "type": [0, 77], "quantiz": [1, 2, 4, 50, 65, 67, 68, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94], "qat": [1, 67, 84, 91, 93], "config": [1, 2], "quantize_": [1, 4, 93], "custom": [1, 63], "legaci": 1, "prototyp": [1, 2], "workflow": [2, 79, 91, 92], "weight": [2, 65, 68, 70, 73], "int8": 2, "int4": 2, "intx": 2, "mx": 2, "nvfp4": [2, 94], "sparsiti": [3, 66], "core": 4, "util": 4, "tensor": [4, 63, 65, 75, 76, 78, 87], "subclass": [4, 63, 76, 78], "common": [4, 62, 87], "aobaseconfig": 5, "castconfig": 6, "float8gemmconfig": 7, "float8linearconfig": 8, "float8linearrecipenam": 9, "scalinggranular": 10, "scalingtyp": 11, "convert_to_float8_train": 12, "precompute_float8_dynamic_scale_for_fsdp": 13, "mxdynamicactivationmxweightconfig": 14, "nvfp4dynamicactivationnvfp4weightconfig": 15, "nvfp4weightonlyconfig": 16, "float8dynamicactivationfloat8weightconfig": 17, "float8dynamicactivationint4weightconfig": 18, "float8weightonlyconfig": 19, "fqntoconfig": 20, "int4weightonlyconfig": 21, "int8dynamicactivationint8weightconfig": 22, "int8dynamicactivationintxweightconfig": [23, 92], "int8weightonlyconfig": 24, "intxweightonlyconfig": 25, "composableqatquant": 26, "fakequantizeconfigbas": 27, "fakequantizedembed": 28, "fakequantizedlinear": 29, "fakequantizerbas": 30, "float8actint4weightqatquant": 31, "float8fakequantizeconfig": 32, "float8fakequant": 33, "fromintxquantizationawaretrainingconfig": 34, "int4weightonlyembeddingqatquant": 35, "int4weightonlyqatquant": 36, "int8dynactint4weightqatquant": 37, "intxquantizationawaretrainingconfig": 38, "intxfakequantizeconfig": 39, "intxfakequant": 40, "qatconfig": 41, "qatstep": 42, "int4weightonlyembed": 43, "int4weightonlyqatembed": 44, "initialize_fake_quant": 45, "int4weightonlyqatlinear": 46, "int8dynactint4weightqatlinear": 47, "disable_linear_fake_qu": 48, "enable_linear_fake_qu": 49, "kernelprefer": [51, 63], "packingformat": 52, "quantizetensorkwarg": 53, "_choose_quant_func_and_quantize_tensor": 54, "perchannelnormobserv": 55, "wandasparsifi": 56, "apply_fake_spars": 57, "semi_sparse_weight": 58, "sparsifi": 59, "torchaobasetensor": 60, "refer": [61, 79], "benchmark": [62, 63, 73, 92, 94], "guid": [62, 63, 78], "add": [62, 78], "an": [62, 72], "recip": [62, 70, 71], "model": [62, 63, 65, 68, 71, 72, 73, 77, 78, 79, 82, 83, 84, 94], "design": [62, 66], "consider": 62, "hf": 62, "ci": 62, "dashboard": 62, "1": [62, 67, 71, 73, 77, 78, 82, 85, 86, 87, 94], "modifi": 62, "exist": 62, "configur": [62, 66, 70, 78, 83, 84], "2": [62, 67, 73, 77, 78, 82, 83, 84, 85, 86, 87, 94], "run": [62, 70], "3": [62, 67, 73, 78, 82, 85, 86, 87], "output": [62, 70, 76], "format": [62, 65], "4": [62, 82, 87], "integr": [62, 67, 77, 78, 93], "pipelin": 62, "troubleshoot": 62, "test": [62, 63, 94], "issu": 62, "best": 62, "practic": 62, "contributor": 63, "gener": 63, "extend": 63, "ad": [63, 78], "new": [63, 78], "effici": [63, 65], "kernel": [63, 65, 78, 80, 94], "triton": 63, "hand": 63, "written": 63, "us": [63, 87], "flow": [63, 65, 72, 78, 87, 94], "torch": [63, 82, 83, 84], "compil": [63, 78, 82], "perform": [63, 73, 80, 83, 92, 94], "serial": [63, 72, 78], "featur": [63, 94], "support": [63, 77, 78], "function": [63, 83, 84], "compos": 63, "microbenchmark": [63, 70, 94], "eval": [63, 83], "contribut": [64, 79], "overview": [65, 66, 90, 91], "basic": 65, "dtype": [65, 91], "primit": 65, "op": 65, "deriv": [65, 87, 94], "pack": 65, "algorithm": 65, "onli": 65, "dynam": [65, 68], "activ": [65, 68], "static": [65, 74], "awar": [65, 67, 84, 85, 93], "low": [65, 67], "bit": [65, 68], "optim": [65, 72, 73, 79], "case": 65, "studi": 65, "how": [65, 83, 84, 87], "work": 65, "dure": 65, "execut": 65, "save": [65, 77, 83, 84, 94], "load": [65, 83, 84, 94], "goal": 66, "context": 66, "prune": 66, "criteria": 66, "strategi": [66, 70], "pattern": [66, 87], "part": [67, 71, 73], "fine": 67, "tune": 67, "qlora": 67, "option": [67, 73, 82, 90, 94], "torchtun": 67, "axolotl": [67, 93], "rank": 67, "adapt": 67, "huggingfac": [67, 73, 78], "peft": 67, "first": 68, "exampl": [68, 70, 77, 78, 87], "set": [68, 83], "up": 68, "w8a8": 68, "int": 68, "8": 68, "size": [68, 83], "comparison": [68, 70], "speedup": 68, "next": [68, 76], "step": [68, 73, 76, 78, 90], "tutori": [69, 79, 90], "mxfp8": [70, 94], "expert": 70, "parallel": 70, "torchtitan": [70, 71], "prerequisit": [70, 71, 82, 85, 86, 87], "understand": 70, "expect": 70, "select": 70, "gradient": 70, "high": [70, 78], "precis": 70, "combin": 70, "directli": [70, 71, 87], "complet": 70, "against": 70, "full": 70, "bf16": 70, "baselin": 70, "all": 70, "group": 70, "gemm": [70, 94], "pre": 71, "rowwis": [71, 94], "scale": [71, 94], "tensorwis": [71, 94], "pick": 71, "import": [71, 83, 84], "note": [71, 87], "convers": 71, "deseri": 72, "what": [72, 76], "happen": 72, "when": 72, "serv": [73, 78, 79], "vllm": [73, 78], "sglang": 73, "executorch": 73, "post": [73, 82, 83, 85, 86], "infer": [73, 91, 92, 94], "transform": [73, 77, 78], "mobil": 73, "deploy": 73, "unti": 73, "embed": 73, "creat": [73, 78], "export": [73, 82, 83, 84, 85, 86, 87], "characterist": 73, "evalu": [73, 83, 93], "qualiti": 73, "assess": 73, "memori": 73, "latenc": 73, "result": [73, 93], "h100": [73, 92, 94], "machin": 73, "conclus": [73, 82, 83, 84, 85, 86, 87, 90], "calibr": [74, 83], "phase": 74, "write": [75, 76, 87], "your": [75, 76, 78], "own": [75, 76], "advanc": 75, "ar": 76, "modul": 76, "swap": 76, "which": 76, "oper": [76, 78, 87], "should": 76, "we": 76, "implement": [76, 78], "compar": 76, "hug": 77, "face": 77, "quick": [77, 79, 81, 94], "start": [77, 79, 81, 94], "usag": [77, 78], "diffus": 77, "architectur": 78, "system": 78, "class": 78, "fqn": 78, "method": 78, "minim": 78, "requir": 78, "compat": 78, "why": 78, "regist": 78, "": 78, "kei": [78, 94], "detail": 78, "hardwar": [78, 91], "specif": [78, 83, 84], "linear": 78, "benefit": 78, "trade": 78, "off": 78, "share": [78, 87], "safetensor": 78, "diagram": 78, "level": 78, "point": 78, "dispatch": 78, "bring": 78, "extern": 78, "welcom": 79, "document": 79, "pytorch": [79, 82, 83, 84, 85, 86, 87], "nativ": 79, "instal": [79, 82], "pt2e": [79, 81, 87], "openvino": 82, "backend": [82, 83, 84, 85, 86], "introduct": [82, 85, 86, 87], "nncf": 82, "captur": [82, 85, 86], "fx": [82, 85, 86], "graph": [82, 85, 86], "appli": [82, 85, 86, 94], "lower": [82, 83, 85, 86], "represent": 82, "improv": [82, 94], "metric": 82, "motiv": [83, 87], "defin": [83, 84], "helper": [83, 84], "prepar": [83, 84], "dataset": [83, 84], "mode": 83, "convert": [83, 84], "check": 83, "accuraci": [83, 92], "debug": 83, "loop": 84, "checkpoint": [84, 94], "x86": 85, "through": [85, 86], "inductor": [85, 86], "intel": [86, 91], "gpu": [86, 94], "annot": 87, "param": 87, "fix": 87, "paramet": 87, "5": 87, "A": 87, "toi": 87, "resnet18": 87, "ir": 87, "problem": 87, "match": 87, "aten": 87, "recommend": [87, 93], "subgraphmatcherwithnamenodemap": 87, "comput": 89, "time": 89, "templat": 90, "addit": 90, "exercis": 90, "further": 90, "read": 90, "statu": [91, 94], "nvidia": [91, 92, 94], "cuda": 91, "edg": 91, "rocm": 91, "b200": [92, 94], "avail": 92, "techniqu": 92, "codebook": 92, "unsloth": 93, "e2": 94, "amd": 94, "mi300x": 94, "multi": 94, "user": 94, "rowwise_with_gw_hp": 94, "overal": 94, "mxfp4": 94, "plan": 94, "mxtensor": 94}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"torchao.float8": [[0, "torchao-float8"]], "Main float8 training APIs": [[0, "main-float8-training-apis"]], "Other float8 training types": [[0, "other-float8-training-types"]], "torchao.quantization.qat": [[1, "torchao-quantization-qat"]], "Main config for quantize_": [[1, "main-config-for-quantize"]], "Custom QAT APIs": [[1, "custom-qat-apis"]], "Legacy QAT APIs": [[1, "legacy-qat-apis"]], "Prototype": [[1, "prototype"]], "torchao.quantization": [[2, "torchao-quantization"]], "Main Quantization APIs": [[2, "main-quantization-apis"]], "Workflow Configs": [[2, "workflow-configs"]], "float8 weight configs": [[2, "float8-weight-configs"]], "int8 weight configs": [[2, "int8-weight-configs"]], "int4 weight configs": [[2, "int4-weight-configs"]], "intx weight configs": [[2, "intx-weight-configs"]], "mx weight configs (prototype)": [[2, "mx-weight-configs-prototype"]], "nvfp4 weight configs (prototype)": [[2, "nvfp4-weight-configs-prototype"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "torchao.core": [[4, "torchao-core"]], "torchao.utils": [[4, "torchao-utils"]], "Tensor Subclass Utils": [[4, "tensor-subclass-utils"]], "torchao.quantization.quantize_.common": [[4, "torchao-quantization-quantize-common"]], "quantize_ API Common Utils": [[4, "quantize-api-common-utils"]], "AOBaseConfig": [[5, "aobaseconfig"]], "CastConfig": [[6, "castconfig"]], "Float8GemmConfig": [[7, "float8gemmconfig"]], "Float8LinearConfig": [[8, "float8linearconfig"]], "Float8LinearRecipeName": [[9, "float8linearrecipename"]], "ScalingGranularity": [[10, "scalinggranularity"]], "ScalingType": [[11, "scalingtype"]], "convert_to_float8_training": [[12, "convert-to-float8-training"]], "precompute_float8_dynamic_scale_for_fsdp": [[13, "precompute-float8-dynamic-scale-for-fsdp"]], "MXDynamicActivationMXWeightConfig": [[14, "mxdynamicactivationmxweightconfig"]], "NVFP4DynamicActivationNVFP4WeightConfig": [[15, "nvfp4dynamicactivationnvfp4weightconfig"]], "NVFP4WeightOnlyConfig": [[16, "nvfp4weightonlyconfig"]], "Float8DynamicActivationFloat8WeightConfig": [[17, "float8dynamicactivationfloat8weightconfig"]], "Float8DynamicActivationInt4WeightConfig": [[18, "float8dynamicactivationint4weightconfig"]], "Float8WeightOnlyConfig": [[19, "float8weightonlyconfig"]], "FqnToConfig": [[20, "fqntoconfig"]], "Int4WeightOnlyConfig": [[21, "int4weightonlyconfig"]], "Int8DynamicActivationInt8WeightConfig": [[22, "int8dynamicactivationint8weightconfig"]], "Int8DynamicActivationIntxWeightConfig": [[23, "int8dynamicactivationintxweightconfig"]], "Int8WeightOnlyConfig": [[24, "int8weightonlyconfig"]], "IntxWeightOnlyConfig": [[25, "intxweightonlyconfig"]], "ComposableQATQuantizer": [[26, "composableqatquantizer"]], "FakeQuantizeConfigBase": [[27, "fakequantizeconfigbase"]], "FakeQuantizedEmbedding": [[28, "fakequantizedembedding"]], "FakeQuantizedLinear": [[29, "fakequantizedlinear"]], "FakeQuantizerBase": [[30, "fakequantizerbase"]], "Float8ActInt4WeightQATQuantizer": [[31, "float8actint4weightqatquantizer"]], "Float8FakeQuantizeConfig": [[32, "float8fakequantizeconfig"]], "Float8FakeQuantizer": [[33, "float8fakequantizer"]], "FromIntXQuantizationAwareTrainingConfig": [[34, "fromintxquantizationawaretrainingconfig"]], "Int4WeightOnlyEmbeddingQATQuantizer": [[35, "int4weightonlyembeddingqatquantizer"]], "Int4WeightOnlyQATQuantizer": [[36, "int4weightonlyqatquantizer"]], "Int8DynActInt4WeightQATQuantizer": [[37, "int8dynactint4weightqatquantizer"]], "IntXQuantizationAwareTrainingConfig": [[38, "intxquantizationawaretrainingconfig"]], "IntxFakeQuantizeConfig": [[39, "intxfakequantizeconfig"]], "IntxFakeQuantizer": [[40, "intxfakequantizer"]], "QATConfig": [[41, "qatconfig"]], "QATStep": [[42, "qatstep"]], "Int4WeightOnlyEmbedding": [[43, "int4weightonlyembedding"]], "Int4WeightOnlyQATEmbedding": [[44, "int4weightonlyqatembedding"]], "initialize_fake_quantizers": [[45, "initialize-fake-quantizers"]], "Int4WeightOnlyQATLinear": [[46, "int4weightonlyqatlinear"]], "Int8DynActInt4WeightQATLinear": [[47, "int8dynactint4weightqatlinear"]], "disable_linear_fake_quant": [[48, "disable-linear-fake-quant"]], "enable_linear_fake_quant": [[49, "enable-linear-fake-quant"]], "quantize": [[50, "quantize"]], "KernelPreference": [[51, "kernelpreference"], [63, "kernelpreference"]], "PackingFormat": [[52, "packingformat"]], "QuantizeTensorKwargs": [[53, "quantizetensorkwargs"]], "_choose_quant_func_and_quantize_tensor": [[54, "choose-quant-func-and-quantize-tensor"]], "PerChannelNormObserver": [[55, "perchannelnormobserver"]], "WandaSparsifier": [[56, "wandasparsifier"]], "apply_fake_sparsity": [[57, "apply-fake-sparsity"]], "semi_sparse_weight": [[58, "semi-sparse-weight"]], "sparsify": [[59, "sparsify"]], "TorchAOBaseTensor": [[60, "torchaobasetensor"]], "API Reference": [[61, "api-reference"], [79, null]], "Benchmarking API Guide": [[62, "benchmarking-api-guide"]], "Add an API to Benchmarking Recipes": [[62, "add-an-api-to-benchmarking-recipes"]], "Add a Model to Benchmarking Recipes": [[62, "add-a-model-to-benchmarking-recipes"]], "Model Design Considerations": [[62, "model-design-considerations"]], "Add an HF model to benchmarking recipes": [[62, "add-an-hf-model-to-benchmarking-recipes"]], "Add an API to Benchmarking CI Dashboard": [[62, "add-an-api-to-benchmarking-ci-dashboard"]], "1. Modify Existing CI Configuration": [[62, "modify-existing-ci-configuration"]], "2. Run CI Benchmarks": [[62, "run-ci-benchmarks"]], "3. CI Output Format": [[62, "ci-output-format"]], "4. Integration with CI Pipeline": [[62, "integration-with-ci-pipeline"]], "Troubleshooting": [[62, "troubleshooting"]], "Running Tests": [[62, "running-tests"]], "Common Issues": [[62, "common-issues"]], "Best Practices": [[62, "best-practices"]], "Contributor Guide": [[63, "contributor-guide"]], "General Guide on Extending torchao": [[63, "general-guide-on-extending-torchao"]], "Adding New Tensor Subclasses": [[63, "adding-new-tensor-subclasses"]], "Adding Efficient Kernels": [[63, "adding-efficient-kernels"]], "Custom triton kernels": [[63, "custom-triton-kernels"]], "Custom hand written kernels": [[63, "custom-hand-written-kernels"]], "Using hand written kernels in Tensor Subclasses": [[63, "using-hand-written-kernels-in-tensor-subclasses"]], "Flow": [[63, "flow"]], "Using torch.compile for Performance": [[63, "using-torch-compile-for-performance"]], "Serialization": [[63, "serialization"], [72, "serialization"]], "Other Feature Support": [[63, "other-feature-support"]], "Tensor Subclass Functionality/Composability Testing": [[63, "tensor-subclass-functionality-composability-testing"]], "Kernel Microbenchmarks": [[63, "kernel-microbenchmarks"]], "Model Benchmarks and Eval": [[63, "model-benchmarks-and-eval"]], "Contributing": [[64, "contributing"], [79, null]], "Quantization Overview": [[65, "quantization-overview"]], "Basic DTypes": [[65, "basic-dtypes"]], "Quantization Primitive Ops": [[65, "quantization-primitive-ops"]], "Efficient kernels": [[65, "efficient-kernels"]], "Quantized Tensors (derived dtypes and packing format)": [[65, "quantized-tensors-derived-dtypes-and-packing-format"]], "Quantization Algorithms/Flows": [[65, "quantization-algorithms-flows"]], "Weight Only Quantization": [[65, "weight-only-quantization"]], "Dynamic Activation and Weight Quantization": [[65, "dynamic-activation-and-weight-quantization"]], "Static Activation Quantization and Weight Quantization": [[65, "static-activation-quantization-and-weight-quantization"]], "Other Quantization Flows": [[65, "other-quantization-flows"]], "Training": [[65, "training"]], "Quantization Aware Training": [[65, "quantization-aware-training"], [85, "quantization-aware-training"]], "Low Bit Optimizers": [[65, "low-bit-optimizers"]], "Quantized Training": [[65, "quantized-training"], [94, "quantized-training"]], "Case Study: How float8 dynamic activation and float8 weight quantization works in torchao?": [[65, "case-study-how-float8-dynamic-activation-and-float8-weight-quantization-works-in-torchao"]], "During Quantization": [[65, "during-quantization"]], "During Model Execution": [[65, "during-model-execution"]], "During Save/Load": [[65, "during-save-load"]], "Sparsity Overview": [[66, "sparsity-overview"]], "Goal": [[66, "goal"]], "Design": [[66, "design"]], "Context": [[66, "context"]], "Pruning Configuration": [[66, "pruning-configuration"]], "Pruning Criteria": [[66, "pruning-criteria"]], "Pruning Strategy": [[66, "pruning-strategy"]], "Sparsity Pattern": [[66, "sparsity-pattern"]], "(Part 2) Fine-tuning with QAT, QLoRA, and float8": [[67, "part-2-fine-tuning-with-qat-qlora-and-float8"]], "Quantization-Aware Training (QAT)": [[67, "quantization-aware-training-qat"], [93, "quantization-aware-training-qat"]], "Option 1: TorchTune QAT Integration": [[67, "option-1-torchtune-qat-integration"]], "Option 2: Axolotl QAT Integration": [[67, "option-2-axolotl-qat-integration"]], "Option 3: TorchAO QAT API": [[67, "option-3-torchao-qat-api"]], "Quantized Low-Rank Adaptation (QLoRA)": [[67, "quantized-low-rank-adaptation-qlora"]], "Option 1: TorchTune Integration": [[67, "option-1-torchtune-integration"]], "Option 2: HuggingFace PEFT Integration": [[67, "option-2-huggingface-peft-integration"]], "Float8 Quantized Fine-tuning": [[67, "float8-quantized-fine-tuning"]], "First Quantization Example": [[68, "first-quantization-example"]], "Setting Up the Model": [[68, "setting-up-the-model"]], "W8A8-INT: 8-bit Dynamic Activation and Weight Quantization": [[68, "w8a8-int-8-bit-dynamic-activation-and-weight-quantization"]], "Model Size Comparison": [[68, "model-size-comparison"]], "Speedup Comparison": [[68, "speedup-comparison"]], "Next Steps": [[68, "next-steps"], [76, "next-steps"]], "Tutorials": [[69, "tutorials"], [79, null]], "MXFP8 Expert Parallel Training": [[70, "mxfp8-expert-parallel-training"], [70, "id1"]], "MXFP8 Expert Parallel APIs": [[70, "mxfp8-expert-parallel-apis"]], "Training with torchtitan": [[70, "training-with-torchtitan"]], "Prerequisites": [[70, "prerequisites"], [70, "mxfp8-torchao-prerequisites"], [71, "prerequisites"], [71, "pretraining-torchao-prerequisites"], [82, "prerequisites"], [85, "prerequisites"], [86, "prerequisites"]], "Understanding the Configuration": [[70, "understanding-the-configuration"]], "Expected Output": [[70, "expected-output"]], "Recipe Selection: MXFP8 Weight Gradient with High Precision": [[70, "recipe-selection-mxfp8-weight-gradient-with-high-precision"]], "Combining with Other Parallelism Strategies": [[70, "combining-with-other-parallelism-strategies"]], "Training with torchao directly": [[70, "training-with-torchao-directly"]], "Complete Example": [[70, "complete-example"]], "Running the Example": [[70, "running-the-example"]], "Microbenchmarks": [[70, "microbenchmarks"]], "Comparison Against Full BF16 Baseline": [[70, "comparison-against-full-bf16-baseline"]], "Comparison Against BF16 All-to-Alls + MXFP8 Grouped GEMM": [[70, "comparison-against-bf16-all-to-alls-mxfp8-grouped-gemm"]], "(Part 1) Pre-training with float8": [[71, "part-1-pre-training-with-float8"]], "Pre-training with torchtitan": [[71, "pre-training-with-torchtitan"]], "Rowwise scaling": [[71, "rowwise-scaling"]], "Tensorwise scaling": [[71, "tensorwise-scaling"]], "Picking a recipe": [[71, "picking-a-recipe"]], "Important notes": [[71, "important-notes"]], "Pre-training with torchao directly": [[71, "pre-training-with-torchao-directly"]], "Model conversion API": [[71, "model-conversion-api"]], "Serialization and deserialization flow": [[72, "serialization-and-deserialization-flow"]], "What happens when serializing an optimized model?": [[72, "what-happens-when-serializing-an-optimized-model"]], "What happens when deserializing an optimized model?": [[72, "what-happens-when-deserializing-an-optimized-model"]], "(Part 3) Serving on vLLM, SGLang, ExecuTorch": [[73, "part-3-serving-on-vllm-sglang-executorch"]], "Post-training Quantization with HuggingFace": [[73, "post-training-quantization-with-huggingface"]], "Serving and Inference": [[73, "serving-and-inference"]], "Serving and Inference with vLLM": [[73, "serving-and-inference-with-vllm"]], "Serving and Inference with SGLang": [[73, "serving-and-inference-with-sglang"]], "Inference with Transformers": [[73, "inference-with-transformers"]], "Mobile Deployment with ExecuTorch": [[73, "mobile-deployment-with-executorch"]], "[Optional] Untie Embedding Weights": [[73, "optional-untie-embedding-weights"]], "Step 1: Create Mobile-Optimized Quantization": [[73, "step-1-create-mobile-optimized-quantization"]], "Step 2: Export to ExecuTorch": [[73, "step-2-export-to-executorch"]], "Mobile Performance Characteristics": [[73, "mobile-performance-characteristics"]], "Evaluation": [[73, "evaluation"]], "Model Quality Assessment": [[73, "model-quality-assessment"]], "Memory Benchmarking": [[73, "memory-benchmarking"]], "Performance Benchmarking": [[73, "performance-benchmarking"]], "Latency Benchmarking": [[73, "latency-benchmarking"]], "Serving Benchmarking": [[73, "serving-benchmarking"]], "Results (H100 machine)": [[73, "results-h100-machine"]], "Conclusion": [[73, "conclusion"], [82, "conclusion"], [83, "conclusion"], [84, "conclusion"], [85, "conclusion"], [86, "conclusion"], [87, "conclusion"], [90, "conclusion"]], "Static Quantization": [[74, "static-quantization"]], "Calibration Phase": [[74, "calibration-phase"]], "Quantization Phase": [[74, "quantization-phase"]], "Writing Your Own Quantized Tensor (advanced)": [[75, "writing-your-own-quantized-tensor-advanced"]], "Writing Your Own Quantized Tensor": [[76, "writing-your-own-quantized-tensor"]], "What are Tensor Subclasses?": [[76, "what-are-tensor-subclasses"]], "Quantization with Module Swaps": [[76, "quantization-with-module-swaps"]], "Quantization with Tensor Subclasses": [[76, "quantization-with-tensor-subclasses"]], "Which operators should we implement?": [[76, "which-operators-should-we-implement"]], "Comparing the Outputs": [[76, "comparing-the-outputs"]], "Hugging Face Integration": [[77, "hugging-face-integration"]], "Quick Start: Usage Example": [[77, "quick-start-usage-example"]], "1. Quantizing Models with Transformers": [[77, "quantizing-models-with-transformers"]], "2. Quantizing Models with Diffusers": [[77, "quantizing-models-with-diffusers"]], "Saving the Model": [[77, "saving-the-model"]], "Supported Quantization Types": [[77, "supported-quantization-types"]], "Integration with VLLM: Architecture and Usage Guide": [[78, "integration-with-vllm-architecture-and-usage-guide"]], "Configuration System": [[78, "configuration-system"]], "1. HuggingFace Model Configuration": [[78, "huggingface-model-configuration"]], "2. TorchAO Configuration Classes": [[78, "torchao-configuration-classes"]], "3. FQN Configuration": [[78, "fqn-configuration"]], "Usage Examples": [[78, "usage-examples"]], "1. Quantizing Models with HuggingFace Integration": [[78, "quantizing-models-with-huggingface-integration"]], "2. Serving with VLLM": [[78, "serving-with-vllm"]], "Adding New Quantization Methods to VLLM": [[78, "adding-new-quantization-methods-to-vllm"]], "Minimal Requirements for VLLM Compatibility": [[78, "minimal-requirements-for-vllm-compatibility"]], "Why these ?": [[78, "why-these"]], "Step-by-Step Guide to Add a New Quantization Method": [[78, "step-by-step-guide-to-add-a-new-quantization-method"]], "1. Create Your Tensor Subclass": [[78, "create-your-tensor-subclass"]], "2. Implement Required VLLM Operations": [[78, "implement-required-vllm-operations"]], "3. Register with TorchAO\u2019s Quantization System": [[78, "register-with-torchao-s-quantization-system"]], "Key Implementation Details": [[78, "key-implementation-details"]], "Hardware-Specific Linear Operations": [[78, "hardware-specific-linear-operations"]], "Compilation Benefits": [[78, "compilation-benefits"]], "Trade Off of Tensor Subclasses": [[78, "trade-off-of-tensor-subclasses"]], "Serialization and Model Sharing": [[78, "serialization-and-model-sharing"]], "SafeTensors Support": [[78, "safetensors-support"]], "Integration Architecture Diagrams": [[78, "integration-architecture-diagrams"]], "1. High-Level Model Flow: Transformers \u2192 VLLM + TorchAO": [[78, "high-level-model-flow-transformers-vllm-torchao"]], "2. TorchAO Integration Points in VLLM": [[78, "torchao-integration-points-in-vllm"]], "3. Kernel Dispatch: Bringing External Kernels to VLLM": [[78, "kernel-dispatch-bringing-external-kernels-to-vllm"]], "Welcome to the torchao Documentation": [[79, "welcome-to-the-torchao-documentation"]], "PyTorch-Native Training-to-Serving Model Optimization": [[79, "pytorch-native-training-to-serving-model-optimization"]], "Quick Start": [[79, "quick-start"], [81, "quick-start"], [94, "quick-start"]], "Installation": [[79, "installation"]], "Workflows": [[79, null], [91, "workflows"]], "PT2E Quantization": [[79, null], [81, "pt2e-quantization"]], "Performant Kernels": [[80, "performant-kernels"]], "PyTorch 2 Export Quantization for OpenVINO torch.compile Backend": [[82, "pytorch-2-export-quantization-for-openvino-torch-compile-backend"]], "Introduction": [[82, "introduction"], [85, "introduction"], [86, "introduction"], [87, "introduction"]], "Post Training Quantization": [[82, "post-training-quantization"], [85, "post-training-quantization"], [86, "post-training-quantization"]], "Prerequisite: OpenVINO and NNCF installation": [[82, "prerequisite-openvino-and-nncf-installation"]], "1. Capture FX Graph": [[82, "capture-fx-graph"], [85, "capture-fx-graph"], [86, "capture-fx-graph"]], "2. Apply Quantization": [[82, "apply-quantization"], [85, "apply-quantization"], [86, "apply-quantization"]], "3. Lower into OpenVINO representation": [[82, "lower-into-openvino-representation"]], "4. Optional: Improve quantized model metrics": [[82, "optional-improve-quantized-model-metrics"]], "PyTorch 2 Export Post Training Quantization": [[83, "pytorch-2-export-post-training-quantization"]], "Motivation of PyTorch 2 Export Quantization": [[83, "motivation-of-pytorch-2-export-quantization"]], "Define Helper Functions and Prepare Dataset": [[83, "define-helper-functions-and-prepare-dataset"]], "Set the model to eval mode": [[83, "set-the-model-to-eval-mode"]], "Export the model with torch.export": [[83, "export-the-model-with-torch-export"], [84, "export-the-model-with-torch-export"]], "Import the Backend Specific Quantizer and Configure how to Quantize the Model": [[83, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"], [84, "import-the-backend-specific-quantizer-and-configure-how-to-quantize-the-model"]], "Prepare the Model for Post Training Quantization": [[83, "prepare-the-model-for-post-training-quantization"]], "Calibration": [[83, "calibration"]], "Convert the Calibrated Model to a Quantized Model": [[83, "convert-the-calibrated-model-to-a-quantized-model"]], "Checking Model Size and Accuracy Evaluation": [[83, "checking-model-size-and-accuracy-evaluation"]], "Save and Load Quantized Model": [[83, "save-and-load-quantized-model"]], "Debugging the Quantized Model": [[83, "debugging-the-quantized-model"]], "Lowering and Performance Evaluation": [[83, "lowering-and-performance-evaluation"]], "PyTorch 2 Export Quantization-Aware Training (QAT)": [[84, "pytorch-2-export-quantization-aware-training-qat"]], "Define Helper Functions and Prepare the Dataset": [[84, "define-helper-functions-and-prepare-the-dataset"]], "Prepare the Model for Quantization-Aware Training": [[84, "prepare-the-model-for-quantization-aware-training"]], "Training Loop": [[84, "training-loop"]], "Saving and Loading Model Checkpoints": [[84, "saving-and-loading-model-checkpoints"]], "Convert the Trained Model to a Quantized Model": [[84, "convert-the-trained-model-to-a-quantized-model"]], "PyTorch 2 Export Quantization with X86 Backend through Inductor": [[85, "pytorch-2-export-quantization-with-x86-backend-through-inductor"]], "3. Lower into Inductor": [[85, "lower-into-inductor"], [86, "lower-into-inductor"]], "PyTorch 2 Export Quantization with Intel GPU Backend through Inductor": [[86, "pytorch-2-export-quantization-with-intel-gpu-backend-through-inductor"]], "How to Write a Quantizer for PyTorch 2 Export Quantization": [[87, "how-to-write-a-quantizer-for-pytorch-2-export-quantization"]], "Prerequisites:": [[87, "prerequisites"]], "Annotation API": [[87, "annotation-api"]], "1. Annotate Common Operator Patterns": [[87, "annotate-common-operator-patterns"]], "2. Annotate Operators that Shares Quantization Params": [[87, "annotate-operators-that-shares-quantization-params"]], "3. Annotate Operators with Fixed Quantization Parameters": [[87, "annotate-operators-with-fixed-quantization-parameters"]], "4. Annotate Tensors with Derived Quantization Parameters": [[87, "annotate-tensors-with-derived-quantization-parameters"]], "5. A Toy Example with Resnet18": [[87, "a-toy-example-with-resnet18"]], "A Note on IR for PT2E Quantization Flow": [[87, "a-note-on-ir-for-pt2e-quantization-flow"]], "Motivation: Problem of Matching aten IR directly": [[87, "motivation-problem-of-matching-aten-ir-directly"]], "Recommendation: Use SubgraphMatcherWithNameNodeMap for pattern matching": [[87, "recommendation-use-subgraphmatcherwithnamenodemap-for-pattern-matching"]], "Computation times": [[89, "computation-times"]], "Template Tutorial": [[90, "template-tutorial"]], "Overview": [[90, "overview"]], "Steps": [[90, "steps"]], "(Optional) Additional Exercises": [[90, "optional-additional-exercises"]], "Further Reading": [[90, "further-reading"]], "Workflow overview by training/QAT/inference": [[91, "workflow-overview-by-training-qat-inference"]], "Workflows status by dtype + hardware": [[91, "workflows-status-by-dtype-hardware"]], "NVIDIA CUDA": [[91, "nvidia-cuda"]], "Edge": [[91, "edge"]], "ROCM": [[91, "rocm"]], "Intel": [[91, "intel"]], "Other": [[91, "other"]], "Quantized Inference": [[92, "quantized-inference"]], "Inference Workflows": [[92, "inference-workflows"]], "Accuracy benchmarks": [[92, "accuracy-benchmarks"]], "Performance benchmarks": [[92, "performance-benchmarks"]], "NVIDIA B200": [[92, "nvidia-b200"]], "NVIDIA H100": [[92, "nvidia-h100"], [94, "nvidia-h100"]], "Other Available Quantization Techniques": [[92, "other-available-quantization-techniques"]], "Int8DynamicActivationIntxWeightConfig Quantization": [[92, "int8dynamicactivationintxweightconfig-quantization"]], "Codebook Quantization": [[92, "codebook-quantization"]], "torchao APIs": [[93, "torchao-apis"]], "quantize_ API (recommended)": [[93, "quantize-api-recommended"]], "Axolotl integration": [[93, "axolotl-integration"]], "Unsloth integration": [[93, "unsloth-integration"]], "Evaluation Results": [[93, "evaluation-results"]], "float8": [[94, "float8"]], "Key features": [[94, "key-features"]], "e2e training benchmarks": [[94, "e2e-training-benchmarks"]], "AMD MI300x": [[94, "amd-mi300x"]], "Multi GPU User API": [[94, "multi-gpu-user-api"]], "Performance": [[94, "performance"]], "tensorwise scaling": [[94, "tensorwise-scaling"]], "rowwise scaling": [[94, "rowwise-scaling"]], "rowwise_with_gw_hp scaling": [[94, "rowwise-with-gw-hp-scaling"]], "Derivation": [[94, "derivation"]], "Testing": [[94, "testing"]], "E2E training + inference flow": [[94, "e2e-training-inference-flow"]], "1. Train model and save checkpoint": [[94, "train-model-and-save-checkpoint"]], "2. Load checkpoint and optionally apply inference quantization": [[94, "load-checkpoint-and-optionally-apply-inference-quantization"]], "mxfp8": [[94, "mxfp8"], [94, "id1"]], "Overall status": [[94, "overall-status"]], "nvfp4": [[94, "nvfp4"]], "mxfp4": [[94, "mxfp4"]], "planned improvements": [[94, "planned-improvements"]], "Training e2e benchmarks on NVIDIA B200": [[94, "training-e2e-benchmarks-on-nvidia-b200"]], "User API": [[94, "user-api"]], "MXTensor": [[94, "mxtensor"]], "performance": [[94, "id2"]], "mxfp8 gemm": [[94, "mxfp8-gemm"]], "quantization kernel microbenchmarks": [[94, "quantization-kernel-microbenchmarks"]]}, "indexentries": {"module": [[3, "module-torchao.sparsity"]], "torchao.sparsity": [[3, "module-torchao.sparsity"]], "aobaseconfig (class in torchao.core.config)": [[5, "torchao.core.config.AOBaseConfig"]], "castconfig (class in torchao.float8)": [[6, "torchao.float8.CastConfig"]], "float8gemmconfig (class in torchao.float8)": [[7, "torchao.float8.Float8GemmConfig"]], "float8linearconfig (class in torchao.float8)": [[8, "torchao.float8.Float8LinearConfig"]], "from_recipe_name() (torchao.float8.float8linearconfig static method)": [[8, "torchao.float8.Float8LinearConfig.from_recipe_name"]], "float8linearrecipename (class in torchao.float8)": [[9, "torchao.float8.Float8LinearRecipeName"]], "scalinggranularity (class in torchao.float8)": [[10, "torchao.float8.ScalingGranularity"]], "scalingtype (class in torchao.float8)": [[11, "torchao.float8.ScalingType"]], "convert_to_float8_training() (in module torchao.float8)": [[12, "torchao.float8.convert_to_float8_training"]], "precompute_float8_dynamic_scale_for_fsdp() (in module torchao.float8)": [[13, "torchao.float8.precompute_float8_dynamic_scale_for_fsdp"]], "mxdynamicactivationmxweightconfig (class in torchao.prototype.mx_formats)": [[14, "torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig"]], "nvfp4dynamicactivationnvfp4weightconfig (class in torchao.prototype.mx_formats)": [[15, "torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig"]], "nvfp4weightonlyconfig (class in torchao.prototype.mx_formats)": [[16, "torchao.prototype.mx_formats.NVFP4WeightOnlyConfig"]], "float8dynamicactivationfloat8weightconfig (class in torchao.quantization)": [[17, "torchao.quantization.Float8DynamicActivationFloat8WeightConfig"]], "float8dynamicactivationint4weightconfig (class in torchao.quantization)": [[18, "torchao.quantization.Float8DynamicActivationInt4WeightConfig"]], "float8weightonlyconfig (class in torchao.quantization)": [[19, "torchao.quantization.Float8WeightOnlyConfig"]], "fqntoconfig (class in torchao.quantization)": [[20, "torchao.quantization.FqnToConfig"]], "int4weightonlyconfig (class in torchao.quantization)": [[21, "torchao.quantization.Int4WeightOnlyConfig"]], "int8dynamicactivationint8weightconfig (class in torchao.quantization)": [[22, "torchao.quantization.Int8DynamicActivationInt8WeightConfig"]], "int8dynamicactivationintxweightconfig (class in torchao.quantization)": [[23, "torchao.quantization.Int8DynamicActivationIntxWeightConfig"]], "int8weightonlyconfig (class in torchao.quantization)": [[24, "torchao.quantization.Int8WeightOnlyConfig"]], "intxweightonlyconfig (class in torchao.quantization)": [[25, "torchao.quantization.IntxWeightOnlyConfig"]], "composableqatquantizer (class in torchao.quantization.qat)": [[26, "torchao.quantization.qat.ComposableQATQuantizer"]], "fakequantizeconfigbase (class in torchao.quantization.qat)": [[27, "torchao.quantization.qat.FakeQuantizeConfigBase"]], "fakequantizedembedding (class in torchao.quantization.qat)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding"]], "forward() (torchao.quantization.qat.fakequantizedembedding method)": [[28, "torchao.quantization.qat.FakeQuantizedEmbedding.forward"]], "fakequantizedlinear (class in torchao.quantization.qat)": [[29, "torchao.quantization.qat.FakeQuantizedLinear"]], "forward() (torchao.quantization.qat.fakequantizedlinear method)": [[29, "torchao.quantization.qat.FakeQuantizedLinear.forward"]], "fakequantizerbase (class in torchao.quantization.qat)": [[30, "torchao.quantization.qat.FakeQuantizerBase"]], "float8actint4weightqatquantizer (class in torchao.quantization.qat)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer"]], "prepare() (torchao.quantization.qat.float8actint4weightqatquantizer method)": [[31, "torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.prepare"]], "float8fakequantizeconfig (class in torchao.quantization.qat)": [[32, "torchao.quantization.qat.Float8FakeQuantizeConfig"]], "float8fakequantizer (class in torchao.quantization.qat)": [[33, "torchao.quantization.qat.Float8FakeQuantizer"]], "forward() (torchao.quantization.qat.float8fakequantizer method)": [[33, "torchao.quantization.qat.Float8FakeQuantizer.forward"]], "fromintxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[34, "torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig"]], "int4weightonlyembeddingqatquantizer (class in torchao.quantization.qat)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer"]], "convert() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.convert"]], "prepare() (torchao.quantization.qat.int4weightonlyembeddingqatquantizer method)": [[35, "torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.prepare"]], "int4weightonlyqatquantizer (class in torchao.quantization.qat)": [[36, "torchao.quantization.qat.Int4WeightOnlyQATQuantizer"]], "int8dynactint4weightqatquantizer (class in torchao.quantization.qat)": [[37, "torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer"]], "intxquantizationawaretrainingconfig (class in torchao.quantization.qat)": [[38, "torchao.quantization.qat.IntXQuantizationAwareTrainingConfig"]], "intxfakequantizeconfig (class in torchao.quantization.qat)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig"]], "group_size (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.group_size"]], "is_symmetric (torchao.quantization.qat.intxfakequantizeconfig property)": [[39, "torchao.quantization.qat.IntxFakeQuantizeConfig.is_symmetric"]], "intxfakequantizer (class in torchao.quantization.qat)": [[40, "torchao.quantization.qat.IntxFakeQuantizer"]], "forward() (torchao.quantization.qat.intxfakequantizer method)": [[40, "torchao.quantization.qat.IntxFakeQuantizer.forward"]], "qatconfig (class in torchao.quantization.qat)": [[41, "torchao.quantization.qat.QATConfig"]], "qatstep (class in torchao.quantization.qat)": [[42, "torchao.quantization.qat.QATStep"]], "int4weightonlyembedding (class in torchao.quantization.qat.embedding)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding"]], "forward() (torchao.quantization.qat.embedding.int4weightonlyembedding method)": [[43, "torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.forward"]], "int4weightonlyqatembedding (class in torchao.quantization.qat.embedding)": [[44, "torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding"]], "initialize_fake_quantizers() (in module torchao.quantization.qat)": [[45, "torchao.quantization.qat.initialize_fake_quantizers"]], "int4weightonlyqatlinear (class in torchao.quantization.qat.linear)": [[46, "torchao.quantization.qat.linear.Int4WeightOnlyQATLinear"]], "int8dynactint4weightqatlinear (class in torchao.quantization.qat.linear)": [[47, "torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear"]], "disable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[48, "torchao.quantization.qat.linear.disable_linear_fake_quant"]], "enable_linear_fake_quant() (in module torchao.quantization.qat.linear)": [[49, "torchao.quantization.qat.linear.enable_linear_fake_quant"]], "quantize_() (in module torchao.quantization)": [[50, "torchao.quantization.quantize_"]], "auto (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.AUTO"]], "emulated (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.EMULATED"]], "kernelpreference (class in torchao.quantization.quantize_.common)": [[51, "torchao.quantization.quantize_.common.KernelPreference"]], "mslk (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.MSLK"]], "torch (torchao.quantization.quantize_.common.kernelpreference attribute)": [[51, "torchao.quantization.quantize_.common.KernelPreference.TORCH"]], "plain (torchao.quantization.quantize_.common.packingformat attribute)": [[52, "torchao.quantization.quantize_.common.PackingFormat.PLAIN"]], "packingformat (class in torchao.quantization.quantize_.common)": [[52, "torchao.quantization.quantize_.common.PackingFormat"]], "quantizetensorkwargs (class in torchao.quantization.quantize_.common)": [[53, "torchao.quantization.quantize_.common.QuantizeTensorKwargs"]], "_choose_quant_func_and_quantize_tensor() (in module torchao.quantization.quantize_.common)": [[54, "torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor"]], "perchannelnormobserver (class in torchao.sparsity)": [[55, "torchao.sparsity.PerChannelNormObserver"]], "forward() (torchao.sparsity.perchannelnormobserver method)": [[55, "torchao.sparsity.PerChannelNormObserver.forward"]], "wandasparsifier (class in torchao.sparsity)": [[56, "torchao.sparsity.WandaSparsifier"]], "prepare() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.prepare"]], "squash_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.squash_mask"]], "update_mask() (torchao.sparsity.wandasparsifier method)": [[56, "torchao.sparsity.WandaSparsifier.update_mask"]], "apply_fake_sparsity() (in module torchao.sparsity)": [[57, "torchao.sparsity.apply_fake_sparsity"]], "semi_sparse_weight (in module torchao.sparsity)": [[58, "torchao.sparsity.semi_sparse_weight"]], "sparsify_() (in module torchao.sparsity)": [[59, "torchao.sparsity.sparsify_"]], "torchaobasetensor (class in torchao.utils)": [[60, "torchao.utils.TorchAOBaseTensor"]], "get_layout() (torchao.utils.torchaobasetensor method)": [[60, "torchao.utils.TorchAOBaseTensor.get_layout"]], "get_tensor_impl_constructor() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.get_tensor_impl_constructor"]], "implements() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements"]], "implements_torch_function() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.implements_torch_function"]], "register_layout() (torchao.utils.torchaobasetensor class method)": [[60, "torchao.utils.TorchAOBaseTensor.register_layout"]]}})