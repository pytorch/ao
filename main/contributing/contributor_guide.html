
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
  <meta name="robots" content="noindex">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Contributor Guide" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://pytorch.org/contributing/contributor_guide.html" />
<meta property="og:site_name" content="torchao" />
<meta property="og:description" content="General Guide on Extending torchao: Please start by reading our quantization overview page first. To contribute to existing code base: Adding a new Tensor: torchao/quantization/quantize_/workflows,..." />
<meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
<meta property="og:image:alt" content="torchao" />
<meta name="description" content="General Guide on Extending torchao: Please start by reading our quantization overview page first. To contribute to existing code base: Adding a new Tensor: torchao/quantization/quantize_/workflows,..." />

    <title>Contributor Guide &#8212; torchao main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=b417fedc" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=ca3c1c84" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=e5fbc548" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=f533b996" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contributing/contributor_guide';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://raw.githubusercontent.com/pytorch/ao/gh-pages/torchao-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="canonical" href="https://pytorch.org/ao/contributing/contributor_guide.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sparsity Overview" href="sparsity.html" />
    <link rel="prev" title="Quantization Overview" href="quantization_overview.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main (0.17.0+git1a9a884 )');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->


<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="" class="pytorch-body">
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">

<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>

  
  <div class="navbar-header-items__mobile-logo">
    







  
  
  
  


<a class="navbar-brand logo" href="../index.html">
  
    
    <img src="../_static/img/logo-dark.svg" class="logo__image only-light" alt="torchao - Home"/>
    
    
    <script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="torchao - Home"/>`);</script>
    
  
</a>
  </div>

  
  
  <div class=" navbar-header-items__start">
    
      
      
        <div class="navbar-item">
          







  
  
  
  


<a class="navbar-brand logo" href="../index.html">
  
    
    <img src="../_static/img/logo-dark.svg" class="logo__image only-light" alt="torchao - Home"/>
    
    
    <script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="torchao - Home"/>`);</script>
    
  
</a>
        </div>
      
    
      
      
        
        <div class="navbar-item desktop-only-version">
          
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script>
        </div>
      
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">














<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../workflows/index.html">
              Workflows
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-1">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/training.html">
                  Quantized Training
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/qat.html">
                  Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/inference.html">
                  Quantized Inference
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../api_reference/index.html">
              API Reference
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-2">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_quantization.html">
                  torchao.quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_qat.html">
                  torchao.quantization.qat
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_sparsity.html">
                  torchao.sparsity
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_float8.html">
                  torchao.float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_utils.html">
                  torchao.core
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../eager_tutorials/index.html">
              Tutorials
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-3">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/first_quantization_example.html">
                  First Quantization Example
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/pretraining.html">
                  (Part 1) Pre-training with float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/finetuning.html">
                  (Part 2) Fine-tuning with QAT, QLoRA, and float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serving.html">
                  (Part 3) Serving on vLLM, SGLang, ExecuTorch
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_vllm_integration.html">
                  Integration with VLLM: Architecture and Usage Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_hf_integration.html">
                  Hugging Face Integration
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serialization.html">
                  Serialization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/static_quantization.html">
                  Static Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_basic.html">
                  Writing Your Own Quantized Tensor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_advanced.html">
                  Writing Your Own Quantized Tensor (advanced)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/mxfp8_expert_parallel_training.html">
                  MXFP8 Expert Parallel Training
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown current active">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal active" href="index.html">
              Contributing
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-4">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="quantization_overview.html">
                  Quantization Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="#">
                  Contributor Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="sparsity.html">
                  Sparsity Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="benchmarking_api_guide.html">
                  Benchmarking API Guide
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../pt2e_quantization/index.html">
              PT2E Quantization
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-5">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_ptq.html">
                  PyTorch 2 Export Post Training Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_qat.html">
                  PyTorch 2 Export Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_x86_inductor.html">
                  PyTorch 2 Export Quantization with X86 Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_xpu_inductor.html">
                  PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_openvino_inductor.html">
                  PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quantizer.html">
                  How to Write a Quantizer for PyTorch 2 Export Quantization
                </a>
              </li>
            
          </ul>
        
      </li>
    

    
    
  </ul>
</nav>
</div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
      
        <div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a href="https://pytorch.org" class="pytorch-site-link nav-link nav-external" data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org">
  <span class="pytorch-site-link-text">
    <span>Go to</span>
    <span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
  </span>
</a></div>
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        




  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    <div class="sidebar-header-items__start">
      <div class="navbar-item">
        
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script>
      </div>
    </div>
    

    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">














<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../workflows/index.html">
              Workflows
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-1">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/training.html">
                  Quantized Training
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/qat.html">
                  Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../workflows/inference.html">
                  Quantized Inference
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../api_reference/index.html">
              API Reference
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-2">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_quantization.html">
                  torchao.quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_qat.html">
                  torchao.quantization.qat
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_sparsity.html">
                  torchao.sparsity
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_float8.html">
                  torchao.float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../api_reference/api_ref_utils.html">
                  torchao.core
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../eager_tutorials/index.html">
              Tutorials
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-3">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/first_quantization_example.html">
                  First Quantization Example
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/pretraining.html">
                  (Part 1) Pre-training with float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/finetuning.html">
                  (Part 2) Fine-tuning with QAT, QLoRA, and float8
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serving.html">
                  (Part 3) Serving on vLLM, SGLang, ExecuTorch
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_vllm_integration.html">
                  Integration with VLLM: Architecture and Usage Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/torchao_hf_integration.html">
                  Hugging Face Integration
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/serialization.html">
                  Serialization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/static_quantization.html">
                  Static Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_basic.html">
                  Writing Your Own Quantized Tensor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/subclass_advanced.html">
                  Writing Your Own Quantized Tensor (advanced)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../eager_tutorials/mxfp8_expert_parallel_training.html">
                  MXFP8 Expert Parallel Training
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown current active">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal active" href="index.html">
              Contributing
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-4">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="quantization_overview.html">
                  Quantization Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="#">
                  Contributor Guide
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="sparsity.html">
                  Sparsity Overview
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="benchmarking_api_guide.html">
                  Benchmarking API Guide
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li class="nav-item dropdown">
        
          
          <div class="nav-item-with-toggle">
            <a class="nav-link nav-internal" href="../pt2e_quantization/index.html">
              PT2E Quantization
            </a>
          </div>
          <ul class="dropdown-menu" id="dropdown-5">
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_ptq.html">
                  PyTorch 2 Export Post Training Quantization
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_qat.html">
                  PyTorch 2 Export Quantization-Aware Training (QAT)
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_x86_inductor.html">
                  PyTorch 2 Export Quantization with X86 Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_xpu_inductor.html">
                  PyTorch 2 Export Quantization with Intel GPU Backend through Inductor
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quant_openvino_inductor.html">
                  PyTorch 2 Export Quantization for OpenVINO torch.compile Backend
                </a>
              </li>
            
              <li class=" ">
                <a class="nav-link dropdown-item nav-internal" href="../pt2e_quantization/pt2e_quantizer.html">
                  How to Write a Quantizer for PyTorch 2 Export Quantization
                </a>
              </li>
            
          </ul>
        
      </li>
    

    
    
  </ul>
</nav>
</div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
        
          <div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a href="https://pytorch.org" class="pytorch-site-link nav-link nav-external" data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org">
  <span class="pytorch-site-link-text">
    <span>Go to</span>
    <span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
  </span>
</a></div>
        
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/ao" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchao/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="quantization_overview.html">Quantization Overview</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparsity.html">Sparsity Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking_api_guide.html">Benchmarking API Guide</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



<div id="rtd-footer-container"></div>
      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Contributing</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Contributor Guide</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              

<div id="searchbox"></div>
<div id="pytorch-article">
  <!-- Hidden breadcrumb schema for SEO only -->
  <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
    
    <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <link itemprop="item" href="index.html">
      <meta itemprop="name" content="Contributing">
      <meta itemprop="position" content="1">
    </div>
    
    <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <meta itemprop="name" content="Contributor Guide">
      <meta itemprop="position" content="2">
    </div>
  </div>

  
  

  
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="contributor-guide">
<h1>Contributor Guide<a class="headerlink" href="#contributor-guide" title="Link to this heading">#</a></h1>
<p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Feb 24, 2026 | Last Updated On: Feb 24, 2026</p>
<section id="general-guide-on-extending-torchao">
<h2>General Guide on Extending torchao<a class="headerlink" href="#general-guide-on-extending-torchao" title="Link to this heading">#</a></h2>
<p>Please start by reading our <a class="reference external" href="quantization_overview.html">quantization overview page</a> first.</p>
<p>To contribute to existing code base:</p>
<ul class="simple">
<li><p>Adding a new Tensor: <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/quantization/quantize_/workflows">torchao/quantization/quantize_/workflows</a></p></li>
<li><p>Adding new quantization APIs: <a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/quantization/quant_api.py">torchao/quantization/quant_api.py</a></p></li>
<li><p>Adding features to existing Tensor subclasses like <code class="docutils literal notranslate"><span class="pre">Float8Tensor</span></code>, e.g. adding new operator support, making it trainable, add tensor parallelism support etc., <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/quantization/quantize_/workflows">tensor subclasses</a>, <a class="reference external" href="https://github.com/pytorch/ao/tree/main/test/quantization/quantize_/workflows">tests</a></p></li>
<li><p>Adding new quantization primitive ops, e.g. slight variations of existing quantization primitive ops: <a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/quantization/quant_primitives.py">torchao/quantization/quant_primitives.py</a></p></li>
<li><p>Adding new autotuned triton kernels: <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/kernel">torchao/kernel</a></p></li>
<li><p>Adding new custom cpu/cuda/mps kernels: <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/csrc">torchao/csrc</a></p></li>
</ul>
</section>
<section id="adding-new-tensor-subclasses">
<h2>Adding New Tensor Subclasses<a class="headerlink" href="#adding-new-tensor-subclasses" title="Link to this heading">#</a></h2>
<p>torchao Tensor subclasses are structured by <code class="docutils literal notranslate"><span class="pre">derived</span> <span class="pre">dtype</span></code> and <code class="docutils literal notranslate"><span class="pre">packing</span> <span class="pre">format</span></code>, please check out the <a class="reference external" href="quantization_overview.html">quantization overview page</a> to understand these concepts. If a new tensor subclass is needed for your use case, i.e. a new dtype, or a new packing format that does not already exist, we could define a new Tensor.</p>
<p>To understand how to use tensor subclass in the context of quantization, please also check <a class="reference external" href="https://docs.pytorch.org/ao/main/subclass_basic.html">Writing Your Own Quantized Tensor</a>.</p>
<p>We have utility base class: <code class="docutils literal notranslate"><span class="pre">torchao.utils.TorchAOBaseTensor</span></code> that can help define common util functions and methods for you, if you specified the names of Tensor and non-Tensor attributes of the tensor subclass. for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyTensor</span><span class="p">(</span><span class="n">TorchAOBaseTensor</span><span class="p">):</span>
    <span class="n">tensor_data_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;qdata&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">]</span>
    <span class="n">tensor_attribute_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>With the above, we’ll have multiple methods and functions available to use for this Tensor, for more details please check the docs for <a class="reference external" href="https://docs.pytorch.org/ao/main/generated/torchao.utils.TorchAOBaseTensor.html#torchao.utils.TorchAOBaseTensor">TorchAOBaseTensor</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Many of the existing use cases in torchao still uses AffineQuantizedTensor, but we plan to move away from it to reduce the abstractions and make it easier for people to contribute to torchao.</p>
</div>
</section>
<section id="adding-efficient-kernels">
<h2>Adding Efficient Kernels<a class="headerlink" href="#adding-efficient-kernels" title="Link to this heading">#</a></h2>
<section id="custom-triton-kernels">
<h3>Custom triton kernels<a class="headerlink" href="#custom-triton-kernels" title="Link to this heading">#</a></h3>
<p>Custom triton kernels can be implemented and registered in <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/kernel">torchao/kernel</a></p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/0bdde92114b470823aa24725bf3b0811e980c8ce/torchao/kernel/intmm_triton.py#L270-L302">Implementation Example</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/0bdde92114b470823aa24725bf3b0811e980c8ce/torchao/kernel/intmm_triton.py#L337-L364">Register as a custom op</a></p></li>
</ul>
<p>You may need to define you own <a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/kernel/autotuner.py">autotuner</a> as well.</p>
</section>
<section id="custom-hand-written-kernels">
<h3>Custom hand written kernels<a class="headerlink" href="#custom-hand-written-kernels" title="Link to this heading">#</a></h3>
<p>Custom kernels (implementations) for cpu/cuda/mps can be implemented through <a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/csrc">torchao/csrc</a> e.g. int4 cuda, and accessible through torch.ops.my_custom_op</p>
</section>
</section>
<section id="using-hand-written-kernels-in-tensor-subclasses">
<h2>Using hand written kernels in Tensor Subclasses<a class="headerlink" href="#using-hand-written-kernels-in-tensor-subclasses" title="Link to this heading">#</a></h2>
<p>For calling optimized kernels, we have <code class="docutils literal notranslate"><span class="pre">implements</span></code> from the tensor subclass, for example, if we want to call into a new custom op: <code class="docutils literal notranslate"><span class="pre">torch.ops.torchao.my_mm_for_mps</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Float8Tensor</span><span class="p">(</span><span class="n">TorchAOBaseTensor</span><span class="p">):</span>
    <span class="o">...</span>

<span class="n">implements</span> <span class="o">=</span> <span class="n">Float8Tensor</span><span class="o">.</span><span class="n">implements</span>

<span class="nd">@implements</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">aten</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">default</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="c1"># call into the custom op</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">torchao</span><span class="o">.</span><span class="n">my_mm_for_mps</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">qdata</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">qdata</span><span class="p">,</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<section id="kernelpreference">
<h3>KernelPreference<a class="headerlink" href="#kernelpreference" title="Link to this heading">#</a></h3>
<p>For some tensor subclasses, there could be multiple kernel choices for quantize and mm etc. The recommended way to handle this in torchao tensor subclasses is through <code class="docutils literal notranslate"><span class="pre">KernelPreference</span></code>, that represents which group of kernels we want to use for quantize, mm, group_mm etc. We can use use <code class="docutils literal notranslate"><span class="pre">KernelPreference.AUTO</span></code> as default option, as the option for developers to choose whatever we think is the fastest under different conditions for user, so user don’t need to worry about the details, and we can have other more specific kernel options for debugging purposes.</p>
<p><code class="docutils literal notranslate"><span class="pre">Float8Tensor</span></code> for example, has:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">KernelPreference.AUTO</span></code> that will choose the most performant quantize and mm kernel based on hardware (H100 SM89 or SM90+), availability of libraries (whether <code class="docutils literal notranslate"><span class="pre">mslk</span></code> is installed), granularity (per row or per tensor)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">KernelPreference.TORCH</span></code> will use torchao quantize op (<code class="docutils literal notranslate"><span class="pre">_choose_scale_float8</span></code> and <code class="docutils literal notranslate"><span class="pre">_quantize_affine_float8</span></code>) and <code class="docutils literal notranslate"><span class="pre">_scaled_mm</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Kerenel.MSLK</span></code> uses MSLK quantize and mm op (<code class="docutils literal notranslate"><span class="pre">torch.ops.mslk.f8f8bf16_rowwise</span></code>)</p></li>
</ul>
</section>
</section>
<section id="flow">
<h2>Flow<a class="headerlink" href="#flow" title="Link to this heading">#</a></h2>
<p>For model level API, people can reuse <code class="docutils literal notranslate"><span class="pre">torchao.quantize_</span></code> that allows people to apply a tensor subclass conversion to weight of linear, and allows <a class="reference external" href="https://docs.pytorch.org/ao/main/generated/torchao.quantization.quantize_.html#torchao.quantization.quantize_">filtering function</a> to choose which module the tensor subclass conversion should be applied to.</p>
<p>See Quantization Algorithms/Flows section for examples of weight only/dynamic quant and other types of model level APIs.</p>
</section>
<section id="using-torch-compile-for-performance">
<h2>Using torch.compile for Performance<a class="headerlink" href="#using-torch-compile-for-performance" title="Link to this heading">#</a></h2>
<p>In order to be compatible with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>, to aim for performance optimization, we should run through <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> with <code class="docutils literal notranslate"><span class="pre">fullgraph=True</span></code> first, and remove any unnecessary graph breaks. You can add <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;output_code&quot;</span></code> when you run the script in order to see the inductor generated code. e.g. <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;output_code&quot;</span> <span class="pre">python</span> <span class="pre">example.py</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max-autotune&quot;</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="serialization">
<h2>Serialization<a class="headerlink" href="#serialization" title="Link to this heading">#</a></h2>
<dl class="simple">
<dt>To enable support for serialization (torch.save and torch.load with tensor subclasses as weights), we need to add the tensor subclass and the relevant object to safe globals (available after torch 2.5), e.g.::</dt><dd><p>torch.serialization.add_safe_globals([Float8Tensor, QuantizeTensorToFloat8Kwargs])</p>
</dd>
</dl>
<p>Please checkout the <a class="reference external" href="serialization.html">serialization doc</a> for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/quantization/torchao">integrated</a> with huggingface transformer and supports serialization and deserialization through the huggingface <code class="docutils literal notranslate"><span class="pre">save_pretrained</span></code>, <code class="docutils literal notranslate"><span class="pre">push_to_hub</span></code> and <code class="docutils literal notranslate"><span class="pre">from_pretrained</span></code> APIs. We also have <a class="reference external" href="https://github.com/sayakpaul/diffusers-torchao/blob/main/inference/serialization_and_loading.md">serialization examples</a> with diffuser models.</p>
</div>
</section>
<section id="other-feature-support">
<h2>Other Feature Support<a class="headerlink" href="#other-feature-support" title="Link to this heading">#</a></h2>
<p>The above just talks about basic feature support, we also provide examples on how to add supports for training, tensor parallel, FSDP by extending the <a class="reference external" href="https://github.com/pytorch/ao/blob/main/tutorials/developer_api_guide/my_dtype_tensor_subclass.py">MyDTypeTensor</a>, we’ll put more examples in <a class="reference external" href="https://github.com/pytorch/ao/tree/main/tutorials/developer_api_guide">developer_api_guide</a> folder covering the following use cases.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/tutorials/developer_api_guide/my_trainable_tensor_subclass.py">Quantized Training</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/tutorials/developer_api_guide/tensor_parallel.py">Tensor Parallel Support for Quantized Tensor</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/tutorials/developer_api_guide/export_to_executorch.py">Compatibility with executorch / torchchat</a></p></li>
</ul>
</section>
<section id="tensor-subclass-functionality-composability-testing">
<h2>Tensor Subclass Functionality/Composability Testing<a class="headerlink" href="#tensor-subclass-functionality-composability-testing" title="Link to this heading">#</a></h2>
<p>We are also working on test suites to test out the functionalities of tensor subclass and the composability with different systems like torch.compile, DTensor etc. (we recommend to copy paste the tests and adapt to test your own tensor subclass for now):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/17a0a96d24ebfc154a23342b84e788d9ed6776f4/torchao/testing/utils.py#L74">Basic Test</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/17a0a96d24ebfc154a23342b84e788d9ed6776f4/torchao/testing/utils.py#L147">Compile Test</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/17a0a96d24ebfc154a23342b84e788d9ed6776f4/torchao/testing/utils.py#L227">Tensor Parallel Test</a></p></li>
</ul>
</section>
<section id="kernel-microbenchmarks">
<h2>Kernel Microbenchmarks<a class="headerlink" href="#kernel-microbenchmarks" title="Link to this heading">#</a></h2>
<p>Before we test performance on models, we can also do some microbenchmarks on single linear operator (or other compute intensive/memory intensive) operators with different input dimensions to get a sense of speedup. For a specific kernel that you’d like to benchmark, you can create a benchmark file like <a class="reference external" href="https://github.com/pytorch/ao/blob/main/benchmarks/benchmark_aq.py">benchmarks/benchmark_aq.py</a> and run benchmark with different shapes that’s important for target model. A quick way to get the relevant shape for linear op and other ops is by running the example with <a class="reference external" href="https://github.com/pytorch/ao/blob/main/tutorials/developer_api_guide/print_op_and_shapes.py">this</a>.</p>
<p>Change the model with the model you are interested in optimizing, and run the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">tutorials</span><span class="o">/</span><span class="n">developer_api_guide</span><span class="o">/</span><span class="n">print_op_and_shapes</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TORCH_FUNC</span><span class="o">=&lt;</span><span class="n">built</span><span class="o">-</span><span class="ow">in</span> <span class="n">function</span> <span class="n">linear</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span> <span class="mi">10</span> <span class="mi">10</span> <span class="mi">10</span>
<span class="n">TORCH_FUNC</span><span class="o">=&lt;</span><span class="n">method</span> <span class="s1">&#39;add&#39;</span> <span class="n">of</span> <span class="s1">&#39;torch._C.TensorBase&#39;</span> <span class="n">objects</span><span class="o">&gt;</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="nb">all</span> <span class="n">linear</span> <span class="n">shapes</span> <span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span> <span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
</pre></div>
</div>
<p>The output of all linear shapes can be copy pasted to microbenchmarking script code under <code class="docutils literal notranslate"><span class="pre">benchmarks/benchmark_your_kernel.py</span></code> for benchmarking.</p>
<p>For benchmark helper functions, right now we have <a class="reference external" href="https://github.com/pytorch/ao/blob/0bdde92114b470823aa24725bf3b0811e980c8ce/torchao/utils.py#L55">1</a> and <a class="reference external" href="https://github.com/pytorch/ao/blob/0bdde92114b470823aa24725bf3b0811e980c8ce/torchao/utils.py#L139">2</a>, feel free to use either one for now, but we’ll probably keep one in the future.</p>
</section>
<section id="model-benchmarks-and-eval">
<h2>Model Benchmarks and Eval<a class="headerlink" href="#model-benchmarks-and-eval" title="Link to this heading">#</a></h2>
<p>After you have the quantization flow implemented, you can run benchmark and eval on llama (llama2/llama3) or sam models that are already modified to be friendly to torch.compile, and compare with existing techniques in torchao.</p>
<p>Note: llama model (llama2/llama3) is our representative model for memory bound models and sam is our representative model for compute bound models.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/_models/llama">llama</a></p>
<ul>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/_models/llama/generate.py">benchmark</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/_models/llama/eval.py">eval</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/tree/main/torchao/_models/sam">sam</a></p>
<ul>
<li><p><a class="reference external" href="https://github.com/pytorch/ao/blob/main/torchao/_models/sam/eval_combo.py">benchmark and eval</a></p></li>
</ul>
</li>
</ul>
<p>Please checkout the <code class="docutils literal notranslate"><span class="pre">--help</span></code> option for each of the script to understand the supported options, e.g. you can use <code class="docutils literal notranslate"><span class="pre">--profile=profile_path</span></code> to get the chrome trace of the run to understand detailed <a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html#using-tracing-functionality">chrome trace</a>.</p>
<p>Please let us know if there are any new important models that makes sense to be added to torchao model benchmark/eval folder.</p>
<p>Please also check out <a class="reference external" href="https://docs.pytorch.org/ao/main/benchmarking_user_guide.html">Benchmarking User Guide</a> and <a class="reference external" href="https://docs.pytorch.org/ao/main/benchmarking_api_guide.html">Benchmarking API Guide</a> to understand how to use our benchmarking framework.</p>
</section>
</section>


                </article>
              
</div>

              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="quantization_overview.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quantization Overview</p>
      </div>
    </a>
    <a class="right-next"
       href="sparsity.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Sparsity Overview</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="quantization_overview.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quantization Overview</p>
      </div>
    </a>
    <a class="right-next"
       href="sparsity.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Sparsity Overview</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#general-guide-on-extending-torchao">General Guide on Extending torchao</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-tensor-subclasses">Adding New Tensor Subclasses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-efficient-kernels">Adding Efficient Kernels</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-triton-kernels">Custom triton kernels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-hand-written-kernels">Custom hand written kernels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-hand-written-kernels-in-tensor-subclasses">Using hand written kernels in Tensor Subclasses</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernelpreference">KernelPreference</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#flow">Flow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-torch-compile-for-performance">Using torch.compile for Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serialization">Serialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-feature-support">Other Feature Support</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-subclass-functionality-composability-testing">Tensor Subclass Functionality/Composability Testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-microbenchmarks">Kernel Microbenchmarks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-benchmarks-and-eval">Model Benchmarks and Eval</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/ao/edit/main/docs/source/contributing/contributor_guide.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/contributing/contributor_guide.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024-present, torchao Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Contributor Guide",
       "headline": "Contributor Guide",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/contributing/contributor_guide.html",
       "articleBody": "Contributor Guide# Created On: Feb 24, 2026 | Last Updated On: Feb 24, 2026 General Guide on Extending torchao# Please start by reading our quantization overview page first. To contribute to existing code base: Adding a new Tensor: torchao/quantization/quantize_/workflows Adding new quantization APIs: torchao/quantization/quant_api.py Adding features to existing Tensor subclasses like Float8Tensor, e.g. adding new operator support, making it trainable, add tensor parallelism support etc., tensor subclasses, tests Adding new quantization primitive ops, e.g. slight variations of existing quantization primitive ops: torchao/quantization/quant_primitives.py Adding new autotuned triton kernels: torchao/kernel Adding new custom cpu/cuda/mps kernels: torchao/csrc Adding New Tensor Subclasses# torchao Tensor subclasses are structured by derived dtype and packing format, please check out the quantization overview page to understand these concepts. If a new tensor subclass is needed for your use case, i.e. a new dtype, or a new packing format that does not already exist, we could define a new Tensor. To understand how to use tensor subclass in the context of quantization, please also check Writing Your Own Quantized Tensor. We have utility base class: torchao.utils.TorchAOBaseTensor that can help define common util functions and methods for you, if you specified the names of Tensor and non-Tensor attributes of the tensor subclass. for example: class MyTensor(TorchAOBaseTensor): tensor_data_names = [\"qdata\", \"scale\"] tensor_attribute_names = [\"device\", \"dtype\"] With the above, we\u2019ll have multiple methods and functions available to use for this Tensor, for more details please check the docs for TorchAOBaseTensor Note Many of the existing use cases in torchao still uses AffineQuantizedTensor, but we plan to move away from it to reduce the abstractions and make it easier for people to contribute to torchao. Adding Efficient Kernels# Custom triton kernels# Custom triton kernels can be implemented and registered in torchao/kernel Implementation Example Register as a custom op You may need to define you own autotuner as well. Custom hand written kernels# Custom kernels (implementations) for cpu/cuda/mps can be implemented through torchao/csrc e.g. int4 cuda, and accessible through torch.ops.my_custom_op Using hand written kernels in Tensor Subclasses# For calling optimized kernels, we have implements from the tensor subclass, for example, if we want to call into a new custom op: torch.ops.torchao.my_mm_for_mps: class Float8Tensor(TorchAOBaseTensor): ... implements = Float8Tensor.implements @implements([torch.nn.functional.linear, aten.linear.default]) def _(func, types, args, kwargs): ... # call into the custom op res = torch.ops.torchao.my_mm_for_mps(input_tensor.qdata, weight_tensor.qdata, input_tensor.scale, weight_tensor.scale) return res KernelPreference# For some tensor subclasses, there could be multiple kernel choices for quantize and mm etc. The recommended way to handle this in torchao tensor subclasses is through KernelPreference, that represents which group of kernels we want to use for quantize, mm, group_mm etc. We can use use KernelPreference.AUTO as default option, as the option for developers to choose whatever we think is the fastest under different conditions for user, so user don\u2019t need to worry about the details, and we can have other more specific kernel options for debugging purposes. Float8Tensor for example, has: KernelPreference.AUTO that will choose the most performant quantize and mm kernel based on hardware (H100 SM89 or SM90+), availability of libraries (whether mslk is installed), granularity (per row or per tensor) KernelPreference.TORCH will use torchao quantize op (_choose_scale_float8 and _quantize_affine_float8) and _scaled_mm Kerenel.MSLK uses MSLK quantize and mm op (torch.ops.mslk.f8f8bf16_rowwise) Flow# For model level API, people can reuse torchao.quantize_ that allows people to apply a tensor subclass conversion to weight of linear, and allows filtering function to choose which module the tensor subclass conversion should be applied to. See Quantization Algorithms/Flows section for examples of weight only/dynamic quant and other types of model level APIs. Using torch.compile for Performance# In order to be compatible with torch.compile, to aim for performance optimization, we should run through torch.compile with fullgraph=True first, and remove any unnecessary graph breaks. You can add TORCH_LOGS=\"output_code\" when you run the script in order to see the inductor generated code. e.g. TORCH_LOGS=\"output_code\" python example.py: model = torch.compile(model, mode=\"max-autotune\", fullgraph=True) Serialization# To enable support for serialization (torch.save and torch.load with tensor subclasses as weights), we need to add the tensor subclass and the relevant object to safe globals (available after torch 2.5), e.g.::torch.serialization.add_safe_globals([Float8Tensor, QuantizeTensorToFloat8Kwargs]) Please checkout the serialization doc for more details. Note We are integrated with huggingface transformer and supports serialization and deserialization through the huggingface save_pretrained, push_to_hub and from_pretrained APIs. We also have serialization examples with diffuser models. Other Feature Support# The above just talks about basic feature support, we also provide examples on how to add supports for training, tensor parallel, FSDP by extending the MyDTypeTensor, we\u2019ll put more examples in developer_api_guide folder covering the following use cases. Quantized Training Tensor Parallel Support for Quantized Tensor Compatibility with executorch / torchchat Tensor Subclass Functionality/Composability Testing# We are also working on test suites to test out the functionalities of tensor subclass and the composability with different systems like torch.compile, DTensor etc. (we recommend to copy paste the tests and adapt to test your own tensor subclass for now): Basic Test Compile Test Tensor Parallel Test Kernel Microbenchmarks# Before we test performance on models, we can also do some microbenchmarks on single linear operator (or other compute intensive/memory intensive) operators with different input dimensions to get a sense of speedup. For a specific kernel that you\u2019d like to benchmark, you can create a benchmark file like benchmarks/benchmark_aq.py and run benchmark with different shapes that\u2019s important for target model. A quick way to get the relevant shape for linear op and other ops is by running the example with this. Change the model with the model you are interested in optimizing, and run the following: python tutorials/developer_api_guide/print_op_and_shapes.py Example output: TORCH_FUNC=\u003cbuilt-in function linear\u003e (M, K, N): 10 10 10 TORCH_FUNC=\u003cmethod \u0027add\u0027 of \u0027torch._C.TensorBase\u0027 objects\u003e args[0] shape: torch.Size([10, 10]) all linear shapes (M, K, N): [(10, 10, 10)] The output of all linear shapes can be copy pasted to microbenchmarking script code under benchmarks/benchmark_your_kernel.py for benchmarking. For benchmark helper functions, right now we have 1 and 2, feel free to use either one for now, but we\u2019ll probably keep one in the future. Model Benchmarks and Eval# After you have the quantization flow implemented, you can run benchmark and eval on llama (llama2/llama3) or sam models that are already modified to be friendly to torch.compile, and compare with existing techniques in torchao. Note: llama model (llama2/llama3) is our representative model for memory bound models and sam is our representative model for compute bound models. llama benchmark eval sam benchmark and eval Please checkout the --help option for each of the script to understand the supported options, e.g. you can use --profile=profile_path to get the chrome trace of the run to understand detailed chrome trace. Please let us know if there are any new important models that makes sense to be added to torchao model benchmark/eval folder. Please also check out Benchmarking User Guide and Benchmarking API Guide to understand how to use our benchmarking framework.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/contributing/contributor_guide.html"
       },
       "datePublished": "Feb 24, 2026T00:00:00Z",
       "dateModified": "Feb 24, 2026T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>