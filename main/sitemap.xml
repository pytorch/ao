<?xml version='1.0' encoding='utf-8'?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/api_ref_float8.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/api_ref_qat.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/api_ref_quantization.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/api_ref_sparsity.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/api_ref_utils.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.core.config.AOBaseConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.CastConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.Float8GemmConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.Float8LinearConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.Float8LinearRecipeName.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.ScalingGranularity.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.ScalingType.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.convert_to_float8_training.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.float8.precompute_float8_dynamic_scale_for_fsdp.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.prototype.mx_formats.MXDynamicActivationMXWeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.prototype.mx_formats.NVFP4DynamicActivationNVFP4WeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.prototype.mx_formats.NVFP4WeightOnlyConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Float8DynamicActivationFloat8WeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Float8DynamicActivationInt4WeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Float8WeightOnlyConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.FqnToConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Int4WeightOnlyConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Int8DynamicActivationInt8WeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Int8DynamicActivationIntxWeightConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.Int8WeightOnlyConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.IntxWeightOnlyConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.ComposableQATQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.FakeQuantizeConfigBase.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.FakeQuantizedEmbedding.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.FakeQuantizedLinear.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.FakeQuantizerBase.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Float8ActInt4WeightQATQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Float8FakeQuantizeConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Float8FakeQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.FromIntXQuantizationAwareTrainingConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Int4WeightOnlyEmbeddingQATQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Int4WeightOnlyQATQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.Int8DynActInt4WeightQATQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.IntXQuantizationAwareTrainingConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.IntxFakeQuantizeConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.IntxFakeQuantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.QATConfig.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.QATStep.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyEmbedding.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.embedding.Int4WeightOnlyQATEmbedding.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.initialize_fake_quantizers.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.linear.Int4WeightOnlyQATLinear.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.linear.Int8DynActInt4WeightQATLinear.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.linear.disable_linear_fake_quant.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.qat.linear.enable_linear_fake_quant.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.quantize_.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.quantize_.common.KernelPreference.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.quantize_.common.PackingFormat.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.quantize_.common.QuantizeTensorKwargs.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.quantization.quantize_.common._choose_quant_func_and_quantize_tensor.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.sparsity.PerChannelNormObserver.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.sparsity.WandaSparsifier.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.sparsity.apply_fake_sparsity.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.sparsity.semi_sparse_weight.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.sparsity.sparsify_.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/generated/torchao.utils.TorchAOBaseTensor.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/api_reference/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/contributing/benchmarking_api_guide.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/contributing/contributor_guide.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/contributing/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/contributing/quantization_overview.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/contributing/sparsity.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/finetuning.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/first_quantization_example.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/mxfp8_expert_parallel_training.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/pretraining.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/serialization.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/serving.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/static_quantization.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/subclass_advanced.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/subclass_basic.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/torchao_hf_integration.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/eager_tutorials/torchao_vllm_integration.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/performant_kernels.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quant_openvino_inductor.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quant_ptq.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quant_qat.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quant_x86_inductor.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quant_xpu_inductor.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/pt2e_quantization/pt2e_quantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/tutorials/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/tutorials/sg_execution_times.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/tutorials/template_tutorial.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/workflows/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/workflows/inference.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/workflows/qat.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/workflows/training.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/genindex.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/py-modindex.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/core/config.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/float8/config.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/float8/float8_linear_utils.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/float8/fsdp_utils.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/prototype/mx_formats/inference_workflow.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/qat/api.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/qat/embedding.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/qat/fake_quantize_config.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/qat/fake_quantizer.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/qat/linear.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/quant_api.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/quantize_/common/kernel_preference.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/quantize_/common/packing_format.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/quantization/quantize_/common/quantize_tensor_kwargs.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/sparsity/sparse_api.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/sparsity/utils.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/sparsity/wanda.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/torchao/utils.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/_modules/index.html</loc></url><url><loc>https://pytorch.org/ao/en/main (0.17.0+gitf47b5a5 )/search.html</loc></url></urlset>